{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import collections\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "\n",
    "from model_pytorch import EfficientNet\n",
    "from utils import Bar,Logger, AverageMeter, accuracy, mkdir_p, savefig\n",
    "from warmup_scheduler import GradualWarmupScheduler\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "import cv2\n",
    "\n",
    "from PIL import ImageFile, ImageOps\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU device 3: True\n"
     ]
    }
   ],
   "source": [
    "# GPU Device\n",
    "gpu_id = 3\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(\"GPU device %d:\" %(gpu_id), use_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = '/media/data2/dataset/GAN_ImageData/PGGAN_128/'\n",
    "target_dir = '/media/data2/dataset/GAN_ImageData/StyleGAN2_256/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained = './log/pggan/128/b0/aug/checkpoint.pth.tar'\n",
    "resume = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model_name = 'efficientnet-b0' # b0-b7 scale\n",
    "\n",
    "# Optimization\n",
    "num_classes = 2\n",
    "epochs = 1000\n",
    "start_epoch = 0\n",
    "train_batch = 250\n",
    "test_batch = 250\n",
    "lr = 0.1\n",
    "schedule = [50, 250, 500, 750]\n",
    "momentum = 0.1\n",
    "gamma = 0.1 # LR is multiplied by gamma on schedule\n",
    "\n",
    "# CheckPoint\n",
    "checkpoint = './log/pggan/128/b0/to_style2/1000shot' # dir\n",
    "if not os.path.isdir(checkpoint):\n",
    "    os.makedirs(checkpoint)\n",
    "num_workers = 8\n",
    "\n",
    "# Seed\n",
    "manual_seed = 7\n",
    "random.seed(manual_seed)\n",
    "torch.cuda.manual_seed_all(manual_seed)\n",
    "\n",
    "# Image\n",
    "size = (128, 128)\n",
    "\n",
    "# cutmix\n",
    "cm_prob = 0.5\n",
    "cm_beta = 1.0\n",
    "\n",
    "# augmentation\n",
    "blur_prob = 0.2\n",
    "blog_sig = 0.5\n",
    "jpg_prob = 0.2\n",
    "\n",
    "best_acc = 0\n",
    "\n",
    "# sp\n",
    "sp_alpha = 0.1\n",
    "sp_beta = 0.01\n",
    "fc_name = '_fc.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {}\n",
    "state['num_classes'] = num_classes\n",
    "state['epochs'] = epochs\n",
    "state['start_epoch'] = start_epoch\n",
    "state['train_batch'] = train_batch\n",
    "state['test_batch'] = test_batch\n",
    "state['lr'] = lr\n",
    "state['schedule'] = schedule\n",
    "state['momentum'] = momentum\n",
    "state['gamma'] = gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_augment(img):\n",
    "    img = np.array(img)\n",
    "\n",
    "    if random.random() < blur_prob:\n",
    "        sig = np.random.uniform(0.0, 3.0)\n",
    "        gaussian_blur(img, sig)\n",
    "\n",
    "    if random.random() < jpg_prob:\n",
    "        qual = np.random.uniform(30.0, 100.0)\n",
    "        img = cv2_jpg(img, qual)\n",
    "\n",
    "    return Image.fromarray(img)\n",
    "\n",
    "\n",
    "def gaussian_blur(img, sigma):\n",
    "    gaussian_filter(img[:,:,0], output=img[:,:,0], sigma=sigma)\n",
    "    gaussian_filter(img[:,:,1], output=img[:,:,1], sigma=sigma)\n",
    "    gaussian_filter(img[:,:,2], output=img[:,:,2], sigma=sigma)\n",
    "\n",
    "\n",
    "def cv2_jpg(img, compress_val):\n",
    "    img_cv2 = img[:,:,::-1]\n",
    "    encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), compress_val]\n",
    "    result, encimg = cv2.imencode('.jpg', img_cv2, encode_param)\n",
    "    decimg = cv2.imdecode(encimg, 1)\n",
    "    return decimg[:,:,::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_bbox(size, lam):\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = np.int(W * cut_rat)\n",
    "    cut_h = np.int(H * cut_rat)\n",
    "\n",
    "    # uniform\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join(source_dir, 'style2/1000_shot_only')\n",
    "val_target_dir = os.path.join(target_dir, 'validation')\n",
    "val_source_dir = os.path.join(source_dir, 'validation')\n",
    "\n",
    "train_aug = transforms.Compose([\n",
    "    transforms.Lambda(lambda img: data_augment(img)),\n",
    "    transforms.Resize(size),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "#     transforms.RandomErasing(p=0.3, scale=(0.02, 0.10), ratio=(0.3, 3.3), value=0, inplace=True),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "val_aug = transforms.Compose([\n",
    "    transforms.Resize(size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# pin_memory : cuda pin memeory use\n",
    "train_loader = DataLoader(datasets.ImageFolder(train_dir, transform=train_aug),\n",
    "                          batch_size=train_batch, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "val_target_loader = DataLoader(datasets.ImageFolder(val_target_dir, val_aug),\n",
    "                       batch_size=test_batch, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "val_source_loader = DataLoader(datasets.ImageFolder(val_source_dir, val_aug),\n",
    "                       batch_size=test_batch, shuffle=True, num_workers=num_workers, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> using pre-trained model './log/pggan/128/b0/aug/checkpoint.pth.tar'\n"
     ]
    }
   ],
   "source": [
    "teacher_model = EfficientNet.from_name(model_name, num_classes=num_classes,\n",
    "                              override_params={'dropout_rate':0.2, 'drop_connect_rate':0.2})\n",
    "student_model = EfficientNet.from_name(model_name, num_classes=num_classes,\n",
    "                              override_params={'dropout_rate':0.2, 'drop_connect_rate':0.2})\n",
    "\n",
    "# Pre-trained\n",
    "if pretrained:\n",
    "    print(\"=> using pre-trained model '{}'\".format(pretrained))\n",
    "    teacher_model.load_state_dict(torch.load(pretrained)['state_dict'])\n",
    "    student_model.load_state_dict(torch.load(pretrained)['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Total params: 4.01M\n"
     ]
    }
   ],
   "source": [
    "teacher_model.to('cuda')\n",
    "student_model.to('cuda')\n",
    "cudnn.benchmark = True\n",
    "print('    Total params: %.2fM' % (sum(p.numel() for p in teacher_model.parameters())/1000000.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = optim.SGD(student_model.parameters(), lr=lr, momentum=momentum)\n",
    "# optimizer = optim.Adam(student_model.parameters())\n",
    "scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)\n",
    "scheduler_warmup = GradualWarmupScheduler(optimizer, multiplier=4, total_epoch=10, after_scheduler=scheduler_cosine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resume\n",
    "if resume:\n",
    "    print('==> Resuming from checkpoint..')\n",
    "    checkpoint = os.path.dirname(resume)\n",
    "#     checkpoint = torch.load(resume)\n",
    "    resume = torch.load(resume)\n",
    "    best_acc = resume['best_acc']\n",
    "    start_epoch = resume['epoch']\n",
    "    student_model.load_state_dict(resume['state_dict'])\n",
    "    optimizer.load_state_dict(resume['optimizer'])\n",
    "    logger = Logger(os.path.join(checkpoint, 'log.txt'), resume=True)\n",
    "else:\n",
    "    logger = Logger(os.path.join(checkpoint, 'log.txt'))\n",
    "    logger.set_names(['Learning Rate', 'Train Loss', 'Valid Loss', 'Source Loss', 'Train Acc.', 'Valid Acc.', 'Source ACC.', 'Train AUROC', 'Valid AUROC', 'Source AUROC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EfficientNet(\n",
       "  (_conv_stem): Conv2dStaticSamePadding(\n",
       "    3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
       "    (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "  )\n",
       "  (_gn0): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "  (_blocks): ModuleList(\n",
       "    (0): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        32, 32, kernel_size=(3, 3), stride=[1, 1], groups=32, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        32, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        8, 32, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 16, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (1): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 96, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        96, 96, kernel_size=(3, 3), stride=[2, 2], groups=96, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 96, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        96, 4, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        4, 96, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 24, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (2): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 144, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 144, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 24, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (3): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 144, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        144, 144, kernel_size=(5, 5), stride=[2, 2], groups=144, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 144, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 40, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (4): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 240, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        240, 240, kernel_size=(5, 5), stride=(1, 1), groups=240, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 240, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 40, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (5): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 240, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        240, 240, kernel_size=(3, 3), stride=[2, 2], groups=240, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 240, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 80, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (6): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 480, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 480, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 80, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (7): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 480, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 480, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 80, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (8): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 480, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        480, 480, kernel_size=(5, 5), stride=[1, 1], groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 480, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 112, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (9): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 672, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 672, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 112, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (10): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 672, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 672, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 112, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (11): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 672, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5), stride=[2, 2], groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 672, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 192, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (12): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 1152, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 1152, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 192, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (13): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 1152, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 1152, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 192, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (14): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 1152, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 1152, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 192, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (15): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 1152, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(3, 3), stride=[1, 1], groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 1152, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 320, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "  )\n",
       "  (_conv_head): Conv2dStaticSamePadding(\n",
       "    320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "    (static_padding): Identity()\n",
       "  )\n",
       "  (_gn1): GroupNorm(8, 1280, eps=1e-05, affine=True)\n",
       "  (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n",
       "  (_dropout): Dropout(p=0.2, inplace=False)\n",
       "  (_fc): Linear(in_features=1280, out_features=2, bias=True)\n",
       "  (_swish): MemoryEfficientSwish()\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for param in teacher_model.parameters():\n",
    "    param.requires_grad = False\n",
    "teacher_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_model_weights = {}\n",
    "for name, param in teacher_model.named_parameters():\n",
    "    teacher_model_weights[name] = param.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_cls(model):\n",
    "    l2_cls = torch.tensor(0.).cuda()\n",
    "    for name, param in model.named_parameters():\n",
    "        if name.startswith(fc_name):\n",
    "            l2_cls += 0.5 * torch.norm(param) ** 2\n",
    "    return l2_cls\n",
    "\n",
    "def reg_l2sp(model):\n",
    "    sp_loss = torch.tensor(0.).cuda()\n",
    "    for name, param in model.named_parameters():\n",
    "        if not name.startswith(fc_name):\n",
    "            sp_loss += 0.5 * torch.norm(param - teacher_model_weights[name]) ** 2\n",
    "    return sp_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch, use_cuda):\n",
    "    model.train()\n",
    "    \n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    arc = AverageMeter()\n",
    "    end = time.time()\n",
    "    cls_losses = AverageMeter()\n",
    "    sp_losses = AverageMeter()\n",
    "    main_losses = AverageMeter()\n",
    "    \n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        batch_size = inputs.size(0)\n",
    "        if batch_size < train_batch:\n",
    "            continue\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            \n",
    "        r = np.random.rand(1)\n",
    "        if cm_beta > 0 and r < cm_prob:\n",
    "            \n",
    "            rand_index = torch.randperm(inputs.size()[0]).cuda()\n",
    "            tt= targets[rand_index]\n",
    "            boolean = targets==tt\n",
    "            rand_index = rand_index[boolean]\n",
    "            lam = np.random.beta(cm_beta, cm_beta)\n",
    "            bbx1, bby1, bbx2, bby2 = rand_bbox(inputs.size(), lam)\n",
    "            inputs[boolean, :, bbx1:bbx2, bby1:bby2] = inputs[rand_index, :, bbx1:bbx2, bby1:bby2]\n",
    "\n",
    "        # compute output\n",
    "        outputs = model(inputs)\n",
    "        loss_main = criterion(outputs, targets)\n",
    "        loss_cls = 0\n",
    "        loss_sp = 0\n",
    "        loss_cls = reg_cls(model)\n",
    "        loss_sp = reg_l2sp(model)\n",
    "        loss =  loss_main + sp_alpha*loss_sp + sp_beta*loss_cls\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1 = accuracy(outputs.data, targets.data)\n",
    "#         auroc = roc_auc_score(targets.cpu().detach().numpy(), outputs.cpu().detach().numpy()[:,1])\n",
    "        losses.update(loss.data.tolist(), inputs.size(0))\n",
    "        top1.update(prec1[0], inputs.size(0))\n",
    "#         arc.update(auroc, inputs.size(0))\n",
    "        cls_losses.update(loss_cls, inputs.size(0))\n",
    "        sp_losses.update(loss_sp, inputs.size(0))\n",
    "        main_losses.update(loss_main.tolist(), inputs.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        \n",
    "#         if batch_idx % 100 == 0:\n",
    "#             print('{batch}/{size} | Loss:{loss:.4f} | MainLoss:{main:.4f} | SPLoss:{sp:.4f} | CLSLoss:{cls:.4f} | top1:{tp1:.4f} | AUROC:{ac:.4f}'.format(\n",
    "#                      batch=batch_idx+1, size=len(train_loader), loss=losses.avg, main=main_losses.avg, sp=sp_losses.avg, cls=cls_losses.avg, tp1=top1.avg, ac=arc.avg))\n",
    "    print('Train | {batch}/{size} | Loss:{loss:.4f} | MainLoss:{main:.4f} | SPLoss:{sp:.4f} | CLSLoss:{cls:.4f} | top1:{tp1:.4f} | AUROC:{ac:.4f}'.format(\n",
    "                     batch=batch_idx+1, size=len(train_loader), loss=losses.avg, main=main_losses.avg, sp=sp_losses.avg, cls=cls_losses.avg, tp1=top1.avg, ac=arc.avg))\n",
    "    return (losses.avg, top1.avg, arc.avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(val_loader, model, criterion, epoch, use_cuda):\n",
    "    global best_acc\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    arc = AverageMeter()\n",
    "    cls_losses = AverageMeter()\n",
    "    sp_losses = AverageMeter()\n",
    "    main_losses = AverageMeter()\n",
    "\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(val_loader):\n",
    "            # measure data loading time\n",
    "            data_time.update(time.time() - end)\n",
    "\n",
    "            if use_cuda:\n",
    "                inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "            # compute output\n",
    "            outputs = model(inputs)\n",
    "            loss_main = criterion(outputs, targets)\n",
    "            loss_cls = 0\n",
    "            loss_sp = 0\n",
    "            loss_cls = reg_cls(model)\n",
    "            loss_sp = reg_l2sp(model)\n",
    "            loss = loss_main + sp_alpha*loss_sp + sp_beta*loss_cls\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            prec1 = accuracy(outputs.data, targets.data)\n",
    "            auroc = roc_auc_score(targets.cpu().detach().numpy(), outputs.cpu().detach().numpy()[:,1])\n",
    "            losses.update(loss.data.tolist(), inputs.size(0))\n",
    "            top1.update(prec1[0], inputs.size(0))\n",
    "            arc.update(auroc, inputs.size(0))\n",
    "            cls_losses.update(loss_cls, inputs.size(0))\n",
    "            sp_losses.update(loss_sp, inputs.size(0))\n",
    "            main_losses.update(loss_main.tolist(), inputs.size(0))\n",
    "\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "    print('Test | {batch}/{size} | Loss:{loss:.4f} | MainLoss:{main:.4f} | SPLoss:{sp:.4f} | CLSLoss:{cls:.4f} | top1:{tp1:.4f} | AUROC:{ac:.4f}'.format(\n",
    "                     batch=batch_idx+1, size=len(train_loader), loss=losses.avg, main=main_losses.avg, sp=sp_losses.avg, cls=cls_losses.avg, tp1=top1.avg, ac=arc.avg))\n",
    "    return (losses.avg, top1.avg, arc.avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, checkpoint='checkpoint', filename='checkpoint.pth.tar'):\n",
    "    filepath = os.path.join(checkpoint, filename)\n",
    "    torch.save(state, filepath)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filepath, os.path.join(checkpoint, 'model_best.pth.tar'))\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    global state\n",
    "    lr_set = [1, 1e-1, 1e-2, 1e-3, 1e-4, 1e-5]\n",
    "    lr_list = schedule.copy()\n",
    "    lr_list.append(epoch)\n",
    "    lr_list.sort()\n",
    "    idx = lr_list.index(epoch)\n",
    "    state['lr'] *= lr_set[idx]\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = state['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [1 | 1000] LR: 0.100000\n",
      "Train | 16/16 | Loss:1.0880 | MainLoss:0.9324 | SPLoss:1.4076 | CLSLoss:1.4923 | top1:50.1600 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.8361 | MainLoss:0.6915 | SPLoss:1.3033 | CLSLoss:1.4289 | top1:55.0000 | AUROC:0.5710\n",
      "Test | 129/16 | Loss:0.7838 | MainLoss:0.6392 | SPLoss:1.3033 | CLSLoss:1.4289 | top1:97.9595 | AUROC:1.0000\n",
      "\n",
      "Epoch: [2 | 1000] LR: 0.130000\n",
      "Train | 16/16 | Loss:0.8118 | MainLoss:0.6908 | SPLoss:1.0695 | CLSLoss:1.4007 | top1:52.2133 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.7882 | MainLoss:0.6920 | SPLoss:0.8241 | CLSLoss:1.3715 | top1:50.6026 | AUROC:0.5737\n",
      "Test | 129/16 | Loss:0.6097 | MainLoss:0.5136 | SPLoss:0.8241 | CLSLoss:1.3715 | top1:99.8847 | AUROC:1.0000\n",
      "\n",
      "Epoch: [3 | 1000] LR: 0.160000\n",
      "Train | 16/16 | Loss:0.7667 | MainLoss:0.6874 | SPLoss:0.6599 | CLSLoss:1.3382 | top1:54.3467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.7452 | MainLoss:0.6829 | SPLoss:0.4934 | CLSLoss:1.3026 | top1:56.2179 | AUROC:0.5946\n",
      "Test | 129/16 | Loss:0.3393 | MainLoss:0.2769 | SPLoss:0.4934 | CLSLoss:1.3026 | top1:99.6822 | AUROC:1.0000\n",
      "\n",
      "Epoch: [4 | 1000] LR: 0.190000\n",
      "Train | 16/16 | Loss:0.7633 | MainLoss:0.7009 | SPLoss:0.5018 | CLSLoss:1.2179 | top1:52.1333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.7408 | MainLoss:0.6889 | SPLoss:0.4043 | CLSLoss:1.1486 | top1:56.7692 | AUROC:0.5958\n",
      "Test | 129/16 | Loss:0.5970 | MainLoss:0.5451 | SPLoss:0.4043 | CLSLoss:1.1486 | top1:99.8536 | AUROC:1.0000\n",
      "\n",
      "Epoch: [5 | 1000] LR: 0.220000\n",
      "Train | 16/16 | Loss:0.7224 | MainLoss:0.6823 | SPLoss:0.2894 | CLSLoss:1.1188 | top1:57.0933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.7031 | MainLoss:0.6700 | SPLoss:0.2232 | CLSLoss:1.0849 | top1:58.8974 | AUROC:0.6323\n",
      "Test | 129/16 | Loss:0.1684 | MainLoss:0.1353 | SPLoss:0.2232 | CLSLoss:1.0849 | top1:99.7072 | AUROC:1.0000\n",
      "\n",
      "Epoch: [6 | 1000] LR: 0.250000\n",
      "Train | 16/16 | Loss:0.7410 | MainLoss:0.6878 | SPLoss:0.4347 | CLSLoss:0.9700 | top1:57.3067 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.7314 | MainLoss:0.6848 | SPLoss:0.3782 | CLSLoss:0.8839 | top1:52.8205 | AUROC:0.6401\n",
      "Test | 129/16 | Loss:0.5245 | MainLoss:0.4779 | SPLoss:0.3782 | CLSLoss:0.8839 | top1:97.4642 | AUROC:1.0000\n",
      "\n",
      "Epoch: [7 | 1000] LR: 0.280000\n",
      "Train | 16/16 | Loss:0.6989 | MainLoss:0.6544 | SPLoss:0.3592 | CLSLoss:0.8586 | top1:61.1467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.9231 | MainLoss:0.8472 | SPLoss:0.6798 | CLSLoss:0.7935 | top1:50.2949 | AUROC:0.7402\n",
      "Test | 129/16 | Loss:0.1903 | MainLoss:0.1144 | SPLoss:0.6798 | CLSLoss:0.7935 | top1:99.1059 | AUROC:1.0000\n",
      "\n",
      "Epoch: [8 | 1000] LR: 0.310000\n",
      "Train | 16/16 | Loss:0.7532 | MainLoss:0.6767 | SPLoss:0.6978 | CLSLoss:0.6733 | top1:57.2800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6501 | MainLoss:0.5942 | SPLoss:0.4906 | CLSLoss:0.6878 | top1:68.4615 | AUROC:0.7539\n",
      "Test | 129/16 | Loss:0.1843 | MainLoss:0.1284 | SPLoss:0.4906 | CLSLoss:0.6878 | top1:99.7196 | AUROC:1.0000\n",
      "\n",
      "Epoch: [9 | 1000] LR: 0.340000\n",
      "Train | 16/16 | Loss:0.8010 | MainLoss:0.6842 | SPLoss:1.1145 | CLSLoss:0.5310 | top1:57.3333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.8414 | MainLoss:0.7456 | SPLoss:0.9121 | CLSLoss:0.4646 | top1:50.0000 | AUROC:0.7450\n",
      "Test | 129/16 | Loss:0.6871 | MainLoss:0.5912 | SPLoss:0.9121 | CLSLoss:0.4646 | top1:50.0467 | AUROC:1.0000\n",
      "\n",
      "Epoch: [10 | 1000] LR: 0.370000\n",
      "Train | 16/16 | Loss:0.8026 | MainLoss:0.6931 | SPLoss:1.0577 | CLSLoss:0.3716 | top1:55.7600 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.8087 | MainLoss:0.6888 | SPLoss:1.1736 | CLSLoss:0.2588 | top1:50.0000 | AUROC:0.7306\n",
      "Test | 129/16 | Loss:0.7668 | MainLoss:0.6469 | SPLoss:1.1736 | CLSLoss:0.2588 | top1:89.3551 | AUROC:1.0000\n",
      "\n",
      "Epoch: [11 | 1000] LR: 0.400000\n",
      "Train | 16/16 | Loss:0.7616 | MainLoss:0.6783 | SPLoss:0.8080 | CLSLoss:0.2560 | top1:59.6000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.7266 | MainLoss:0.6604 | SPLoss:0.6389 | CLSLoss:0.2254 | top1:62.6026 | AUROC:0.7106\n",
      "Test | 129/16 | Loss:0.3981 | MainLoss:0.3319 | SPLoss:0.6389 | CLSLoss:0.2254 | top1:99.4050 | AUROC:1.0000\n",
      "\n",
      "Epoch: [12 | 1000] LR: 0.400000\n",
      "Train | 16/16 | Loss:0.7755 | MainLoss:0.6817 | SPLoss:0.9224 | CLSLoss:0.1528 | top1:58.5600 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.7515 | MainLoss:0.6840 | SPLoss:0.6656 | CLSLoss:0.0922 | top1:65.4615 | AUROC:0.7398\n",
      "Test | 129/16 | Loss:0.6774 | MainLoss:0.6099 | SPLoss:0.6656 | CLSLoss:0.0922 | top1:99.8318 | AUROC:1.0000\n",
      "\n",
      "Epoch: [13 | 1000] LR: 0.399999\n",
      "Train | 16/16 | Loss:120.3060 | MainLoss:0.6624 | SPLoss:1196.4252 | CLSLoss:0.1158 | top1:63.3867 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:226.0841 | MainLoss:0.6230 | SPLoss:2254.5989 | CLSLoss:0.1232 | top1:68.3718 | AUROC:0.7653\n",
      "Test | 129/16 | Loss:225.7906 | MainLoss:0.3295 | SPLoss:2254.5955 | CLSLoss:0.1232 | top1:98.6480 | AUROC:0.9994\n",
      "\n",
      "Epoch: [14 | 1000] LR: 0.399996\n",
      "Train | 16/16 | Loss:132.4768 | MainLoss:0.6380 | SPLoss:1318.3782 | CLSLoss:0.1061 | top1:63.6800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:62.1888 | MainLoss:0.5198 | SPLoss:616.6768 | CLSLoss:0.1296 | top1:76.3205 | AUROC:0.8470\n",
      "Test | 129/16 | Loss:62.1249 | MainLoss:0.4559 | SPLoss:616.6768 | CLSLoss:0.1296 | top1:80.1651 | AUROC:0.9373\n",
      "\n",
      "Epoch: [15 | 1000] LR: 0.399991\n",
      "Train | 16/16 | Loss:35.8889 | MainLoss:0.5834 | SPLoss:353.0392 | CLSLoss:0.1650 | top1:72.0800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:16.4181 | MainLoss:0.4177 | SPLoss:159.9760 | CLSLoss:0.2786 | top1:81.0769 | AUROC:0.9151\n",
      "Test | 129/16 | Loss:16.7408 | MainLoss:0.7404 | SPLoss:159.9760 | CLSLoss:0.2786 | top1:59.9221 | AUROC:0.7645\n",
      "\n",
      "Epoch: [16 | 1000] LR: 0.399984\n",
      "Train | 16/16 | Loss:9.9322 | MainLoss:0.4860 | SPLoss:94.4364 | CLSLoss:0.2583 | top1:77.4933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:4.8443 | MainLoss:0.4543 | SPLoss:43.8600 | CLSLoss:0.4096 | top1:80.6923 | AUROC:0.9519\n",
      "Test | 129/16 | Loss:5.1145 | MainLoss:0.7244 | SPLoss:43.8600 | CLSLoss:0.4096 | top1:64.4143 | AUROC:0.6959\n",
      "\n",
      "Epoch: [17 | 1000] LR: 0.399975\n",
      "Train | 16/16 | Loss:34.1626 | MainLoss:0.4842 | SPLoss:336.7473 | CLSLoss:0.3633 | top1:76.9333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:76.2697 | MainLoss:0.6422 | SPLoss:756.2606 | CLSLoss:0.1517 | top1:67.9744 | AUROC:0.8577\n",
      "Test | 129/16 | Loss:76.3397 | MainLoss:0.7121 | SPLoss:756.2614 | CLSLoss:0.1517 | top1:49.6916 | AUROC:0.4711\n",
      "\n",
      "Epoch: [18 | 1000] LR: 0.399964\n",
      "Train | 16/16 | Loss:48.7227 | MainLoss:0.5042 | SPLoss:482.1509 | CLSLoss:0.3409 | top1:77.1200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:32.2022 | MainLoss:0.5203 | SPLoss:316.7740 | CLSLoss:0.4497 | top1:74.3333 | AUROC:0.9244\n",
      "Test | 129/16 | Loss:32.4451 | MainLoss:0.7632 | SPLoss:316.7736 | CLSLoss:0.4497 | top1:55.5888 | AUROC:0.5745\n",
      "\n",
      "Epoch: [19 | 1000] LR: 0.399952\n",
      "Train | 16/16 | Loss:41.9634 | MainLoss:0.4641 | SPLoss:414.9459 | CLSLoss:0.4656 | top1:78.8800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:32.5034 | MainLoss:0.4210 | SPLoss:320.7733 | CLSLoss:0.5090 | top1:82.6667 | AUROC:0.9406\n",
      "Test | 129/16 | Loss:32.9702 | MainLoss:0.8878 | SPLoss:320.7733 | CLSLoss:0.5090 | top1:54.3302 | AUROC:0.5617\n",
      "\n",
      "Epoch: [20 | 1000] LR: 0.399937\n",
      "Train | 16/16 | Loss:19.0358 | MainLoss:0.4307 | SPLoss:186.0041 | CLSLoss:0.4720 | top1:81.4400 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:8.9057 | MainLoss:0.3931 | SPLoss:85.0856 | CLSLoss:0.4108 | top1:84.3077 | AUROC:0.9318\n",
      "Test | 129/16 | Loss:9.4844 | MainLoss:0.9717 | SPLoss:85.0856 | CLSLoss:0.4108 | top1:49.5358 | AUROC:0.4836\n",
      "\n",
      "Epoch: [21 | 1000] LR: 0.399920\n",
      "Train | 16/16 | Loss:5.8550 | MainLoss:0.3701 | SPLoss:54.8015 | CLSLoss:0.4811 | top1:84.3200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:3.3644 | MainLoss:0.2561 | SPLoss:31.0299 | CLSLoss:0.5314 | top1:90.2051 | AUROC:0.9610\n",
      "Test | 129/16 | Loss:4.2124 | MainLoss:1.1041 | SPLoss:31.0300 | CLSLoss:0.5314 | top1:53.2648 | AUROC:0.5938\n",
      "\n",
      "Epoch: [22 | 1000] LR: 0.399901\n",
      "Train | 16/16 | Loss:3.9037 | MainLoss:0.3304 | SPLoss:35.6809 | CLSLoss:0.5275 | top1:86.1333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:2.5316 | MainLoss:0.3003 | SPLoss:22.2591 | CLSLoss:0.5378 | top1:87.7179 | AUROC:0.9543\n",
      "Test | 129/16 | Loss:3.5653 | MainLoss:1.3340 | SPLoss:22.2592 | CLSLoss:0.5378 | top1:50.8692 | AUROC:0.5303\n",
      "\n",
      "Epoch: [23 | 1000] LR: 0.399881\n",
      "Train | 16/16 | Loss:33.9486 | MainLoss:0.4552 | SPLoss:334.8872 | CLSLoss:0.4586 | top1:78.6400 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:130.3940 | MainLoss:0.3952 | SPLoss:1299.9517 | CLSLoss:0.3581 | top1:84.7051 | AUROC:0.9325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 129/16 | Loss:130.7483 | MainLoss:0.7495 | SPLoss:1299.9519 | CLSLoss:0.3581 | top1:54.9221 | AUROC:0.5841\n",
      "\n",
      "Epoch: [24 | 1000] LR: 0.399858\n",
      "Train | 16/16 | Loss:74.9576 | MainLoss:0.3852 | SPLoss:745.6807 | CLSLoss:0.4358 | top1:83.7333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:34.8661 | MainLoss:0.3695 | SPLoss:344.9193 | CLSLoss:0.4733 | top1:83.7436 | AUROC:0.9474\n",
      "Test | 129/16 | Loss:35.8477 | MainLoss:1.3511 | SPLoss:344.9197 | CLSLoss:0.4733 | top1:50.2866 | AUROC:0.4839\n",
      "\n",
      "Epoch: [25 | 1000] LR: 0.399833\n",
      "Train | 16/16 | Loss:22.4154 | MainLoss:0.3699 | SPLoss:220.4109 | CLSLoss:0.4448 | top1:84.1333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:22.0054 | MainLoss:0.3250 | SPLoss:216.7620 | CLSLoss:0.4152 | top1:87.1923 | AUROC:0.9509\n",
      "Test | 129/16 | Loss:22.5113 | MainLoss:0.8309 | SPLoss:216.7620 | CLSLoss:0.4152 | top1:56.4953 | AUROC:0.6460\n",
      "\n",
      "Epoch: [26 | 1000] LR: 0.399807\n",
      "Train | 16/16 | Loss:19.7422 | MainLoss:0.3672 | SPLoss:193.7091 | CLSLoss:0.4166 | top1:83.6533 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:13.3733 | MainLoss:0.3105 | SPLoss:130.5808 | CLSLoss:0.4696 | top1:86.9103 | AUROC:0.9607\n",
      "Test | 129/16 | Loss:14.0507 | MainLoss:0.9879 | SPLoss:130.5809 | CLSLoss:0.4696 | top1:55.3645 | AUROC:0.6017\n",
      "\n",
      "Epoch: [27 | 1000] LR: 0.399778\n",
      "Train | 16/16 | Loss:8.7866 | MainLoss:0.3553 | SPLoss:84.2692 | CLSLoss:0.4381 | top1:84.6400 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:5.4059 | MainLoss:0.2441 | SPLoss:51.5711 | CLSLoss:0.4691 | top1:90.1923 | AUROC:0.9636\n",
      "Test | 129/16 | Loss:6.5064 | MainLoss:1.3446 | SPLoss:51.5711 | CLSLoss:0.4691 | top1:50.4237 | AUROC:0.5018\n",
      "\n",
      "Epoch: [28 | 1000] LR: 0.399747\n",
      "Train | 16/16 | Loss:5.7285 | MainLoss:0.4029 | SPLoss:53.2141 | CLSLoss:0.4129 | top1:82.0267 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:5.2655 | MainLoss:0.3390 | SPLoss:49.2302 | CLSLoss:0.3484 | top1:87.5385 | AUROC:0.9464\n",
      "Test | 129/16 | Loss:5.7964 | MainLoss:0.8699 | SPLoss:49.2301 | CLSLoss:0.3484 | top1:50.9844 | AUROC:0.5529\n",
      "\n",
      "Epoch: [29 | 1000] LR: 0.399715\n",
      "Train | 16/16 | Loss:7.1199 | MainLoss:0.3727 | SPLoss:67.4309 | CLSLoss:0.4168 | top1:84.4267 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:57.2200 | MainLoss:0.8069 | SPLoss:564.1011 | CLSLoss:0.3017 | top1:51.8590 | AUROC:0.5169\n",
      "Test | 129/16 | Loss:57.2061 | MainLoss:0.7930 | SPLoss:564.1010 | CLSLoss:0.3017 | top1:50.5358 | AUROC:0.6038\n",
      "\n",
      "Epoch: [30 | 1000] LR: 0.399680\n",
      "Train | 16/16 | Loss:36.2896 | MainLoss:0.5705 | SPLoss:357.1656 | CLSLoss:0.2543 | top1:70.6667 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:17.3340 | MainLoss:0.4276 | SPLoss:169.0352 | CLSLoss:0.2857 | top1:80.7436 | AUROC:0.8879\n",
      "Test | 129/16 | Loss:17.7227 | MainLoss:0.8163 | SPLoss:169.0353 | CLSLoss:0.2857 | top1:55.0312 | AUROC:0.6007\n",
      "\n",
      "Epoch: [31 | 1000] LR: 0.399644\n",
      "Train | 16/16 | Loss:31.7991 | MainLoss:0.4888 | SPLoss:313.0752 | CLSLoss:0.2757 | top1:77.4400 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:41.3414 | MainLoss:0.4126 | SPLoss:409.2630 | CLSLoss:0.2479 | top1:82.1538 | AUROC:0.9078\n",
      "Test | 129/16 | Loss:41.8679 | MainLoss:0.9391 | SPLoss:409.2630 | CLSLoss:0.2479 | top1:50.6916 | AUROC:0.5522\n",
      "\n",
      "Epoch: [32 | 1000] LR: 0.399605\n",
      "Train | 16/16 | Loss:24.1229 | MainLoss:0.4205 | SPLoss:236.9944 | CLSLoss:0.3040 | top1:81.3600 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:12.1918 | MainLoss:0.3376 | SPLoss:118.5101 | CLSLoss:0.3164 | top1:86.0128 | AUROC:0.9482\n",
      "Test | 129/16 | Loss:12.7630 | MainLoss:0.9088 | SPLoss:118.5100 | CLSLoss:0.3164 | top1:51.3707 | AUROC:0.5311\n",
      "\n",
      "Epoch: [33 | 1000] LR: 0.399565\n",
      "Train | 16/16 | Loss:7.5473 | MainLoss:0.3990 | SPLoss:71.4487 | CLSLoss:0.3433 | top1:82.6400 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:4.9928 | MainLoss:0.7710 | SPLoss:42.1764 | CLSLoss:0.4126 | top1:69.0897 | AUROC:0.9445\n",
      "Test | 129/16 | Loss:5.0039 | MainLoss:0.7822 | SPLoss:42.1765 | CLSLoss:0.4126 | top1:62.9564 | AUROC:0.6778\n",
      "\n",
      "Epoch: [34 | 1000] LR: 0.399523\n",
      "Train | 16/16 | Loss:4.0819 | MainLoss:0.4690 | SPLoss:36.0962 | CLSLoss:0.3292 | top1:78.5600 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:3.7378 | MainLoss:0.4229 | SPLoss:33.1118 | CLSLoss:0.3760 | top1:80.1410 | AUROC:0.9382\n",
      "Test | 129/16 | Loss:4.5479 | MainLoss:1.2329 | SPLoss:33.1118 | CLSLoss:0.3760 | top1:50.4143 | AUROC:0.5474\n",
      "\n",
      "Epoch: [35 | 1000] LR: 0.399478\n",
      "Train | 16/16 | Loss:6.8138 | MainLoss:0.3857 | SPLoss:64.2428 | CLSLoss:0.3820 | top1:83.2800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:6.9690 | MainLoss:0.4985 | SPLoss:64.6703 | CLSLoss:0.3463 | top1:74.8718 | AUROC:0.9475\n",
      "Test | 129/16 | Loss:7.4549 | MainLoss:0.9844 | SPLoss:64.6704 | CLSLoss:0.3463 | top1:50.0498 | AUROC:0.4882\n",
      "\n",
      "Epoch: [36 | 1000] LR: 0.399432\n",
      "Train | 16/16 | Loss:5.3397 | MainLoss:0.3817 | SPLoss:49.5438 | CLSLoss:0.3627 | top1:84.0267 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:4.8942 | MainLoss:0.2479 | SPLoss:46.4197 | CLSLoss:0.4313 | top1:90.3718 | AUROC:0.9642\n",
      "Test | 129/16 | Loss:5.9191 | MainLoss:1.2728 | SPLoss:46.4197 | CLSLoss:0.4313 | top1:51.2056 | AUROC:0.5597\n",
      "\n",
      "Epoch: [37 | 1000] LR: 0.399383\n",
      "Train | 16/16 | Loss:3.6830 | MainLoss:0.4201 | SPLoss:32.5902 | CLSLoss:0.3903 | top1:81.6800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:12.7505 | MainLoss:0.5019 | SPLoss:122.4663 | CLSLoss:0.1981 | top1:80.5769 | AUROC:0.8879\n",
      "Test | 129/16 | Loss:12.9764 | MainLoss:0.7278 | SPLoss:122.4662 | CLSLoss:0.1981 | top1:50.7041 | AUROC:0.5275\n",
      "\n",
      "Epoch: [38 | 1000] LR: 0.399333\n",
      "Train | 16/16 | Loss:18.6967 | MainLoss:0.4364 | SPLoss:182.5693 | CLSLoss:0.3352 | top1:81.2267 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:17.5058 | MainLoss:0.3215 | SPLoss:171.8057 | CLSLoss:0.3732 | top1:86.8974 | AUROC:0.9428\n",
      "Test | 129/16 | Loss:18.1708 | MainLoss:0.9865 | SPLoss:171.8058 | CLSLoss:0.3732 | top1:50.7882 | AUROC:0.5344\n",
      "\n",
      "Epoch: [39 | 1000] LR: 0.399281\n",
      "Train | 16/16 | Loss:10.3025 | MainLoss:0.3743 | SPLoss:99.2414 | CLSLoss:0.4064 | top1:83.8933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:5.0834 | MainLoss:0.3636 | SPLoss:47.1635 | CLSLoss:0.3430 | top1:87.4103 | AUROC:0.9388\n",
      "Test | 129/16 | Loss:5.6449 | MainLoss:0.9251 | SPLoss:47.1635 | CLSLoss:0.3430 | top1:50.4891 | AUROC:0.5024\n",
      "\n",
      "Epoch: [40 | 1000] LR: 0.399227\n",
      "Train | 16/16 | Loss:3.9083 | MainLoss:0.3679 | SPLoss:35.3641 | CLSLoss:0.3993 | top1:84.1067 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:2.8390 | MainLoss:0.2300 | SPLoss:26.0447 | CLSLoss:0.4551 | top1:90.8974 | AUROC:0.9680\n",
      "Test | 129/16 | Loss:3.9192 | MainLoss:1.3102 | SPLoss:26.0448 | CLSLoss:0.4551 | top1:51.8069 | AUROC:0.5629\n",
      "\n",
      "Epoch: [41 | 1000] LR: 0.399171\n",
      "Train | 16/16 | Loss:2.2800 | MainLoss:0.3710 | SPLoss:19.0487 | CLSLoss:0.4110 | top1:83.7867 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:1.4499 | MainLoss:0.2476 | SPLoss:11.9784 | CLSLoss:0.4454 | top1:90.1026 | AUROC:0.9693\n",
      "Test | 129/16 | Loss:2.2782 | MainLoss:1.0759 | SPLoss:11.9784 | CLSLoss:0.4454 | top1:53.7913 | AUROC:0.6003\n",
      "\n",
      "Epoch: [42 | 1000] LR: 0.399112\n",
      "Train | 16/16 | Loss:1.6496 | MainLoss:0.3984 | SPLoss:12.4695 | CLSLoss:0.4246 | top1:82.9867 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:3.9919 | MainLoss:0.4409 | SPLoss:35.4857 | CLSLoss:0.2465 | top1:86.5513 | AUROC:0.9417\n",
      "Test | 129/16 | Loss:4.2857 | MainLoss:0.7347 | SPLoss:35.4857 | CLSLoss:0.2465 | top1:52.3551 | AUROC:0.5457\n",
      "\n",
      "Epoch: [43 | 1000] LR: 0.399052\n",
      "Train | 16/16 | Loss:6.7094 | MainLoss:0.3369 | SPLoss:63.6837 | CLSLoss:0.4154 | top1:86.3733 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:7.4460 | MainLoss:0.2238 | SPLoss:72.1766 | CLSLoss:0.4546 | top1:91.0128 | AUROC:0.9753\n",
      "Test | 129/16 | Loss:8.5384 | MainLoss:1.3162 | SPLoss:72.1766 | CLSLoss:0.4546 | top1:50.8598 | AUROC:0.5215\n",
      "\n",
      "Epoch: [44 | 1000] LR: 0.398990\n",
      "Train | 16/16 | Loss:43.6197 | MainLoss:0.3922 | SPLoss:432.2341 | CLSLoss:0.4153 | top1:82.9600 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:34.0375 | MainLoss:0.3015 | SPLoss:337.3261 | CLSLoss:0.3349 | top1:89.1154 | AUROC:0.9565\n",
      "Test | 129/16 | Loss:34.7055 | MainLoss:0.9695 | SPLoss:337.3265 | CLSLoss:0.3349 | top1:50.9097 | AUROC:0.5102\n",
      "\n",
      "Epoch: [45 | 1000] LR: 0.398926\n",
      "Train | 16/16 | Loss:68.3659 | MainLoss:0.3410 | SPLoss:680.2102 | CLSLoss:0.3901 | top1:85.4400 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:62.3843 | MainLoss:0.3055 | SPLoss:620.7418 | CLSLoss:0.4669 | top1:87.4359 | AUROC:0.9627\n",
      "Test | 129/16 | Loss:63.5706 | MainLoss:1.4917 | SPLoss:620.7415 | CLSLoss:0.4669 | top1:51.2586 | AUROC:0.5448\n",
      "\n",
      "Epoch: [46 | 1000] LR: 0.398860\n",
      "Train | 16/16 | Loss:37.4931 | MainLoss:0.3737 | SPLoss:371.1558 | CLSLoss:0.3892 | top1:85.0400 | AUROC:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 32/16 | Loss:18.6560 | MainLoss:0.2602 | SPLoss:183.9115 | CLSLoss:0.4691 | top1:89.4231 | AUROC:0.9627\n",
      "Test | 129/16 | Loss:19.6209 | MainLoss:1.2251 | SPLoss:183.9118 | CLSLoss:0.4691 | top1:54.2118 | AUROC:0.6114\n",
      "\n",
      "Epoch: [47 | 1000] LR: 0.398792\n",
      "Train | 16/16 | Loss:11.5977 | MainLoss:0.3713 | SPLoss:112.2231 | CLSLoss:0.4109 | top1:84.2933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:8.8656 | MainLoss:0.2612 | SPLoss:85.9993 | CLSLoss:0.4449 | top1:90.7692 | AUROC:0.9677\n",
      "Test | 129/16 | Loss:9.7300 | MainLoss:1.1256 | SPLoss:85.9993 | CLSLoss:0.4449 | top1:50.3863 | AUROC:0.4824\n",
      "\n",
      "Epoch: [48 | 1000] LR: 0.398722\n",
      "Train | 16/16 | Loss:8.4806 | MainLoss:0.3792 | SPLoss:80.9690 | CLSLoss:0.4498 | top1:84.5067 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:8.1159 | MainLoss:0.8016 | SPLoss:73.1143 | CLSLoss:0.2849 | top1:50.2821 | AUROC:0.7830\n",
      "Test | 129/16 | Loss:8.2837 | MainLoss:0.9694 | SPLoss:73.1144 | CLSLoss:0.2849 | top1:49.9782 | AUROC:0.3827\n",
      "\n",
      "Epoch: [49 | 1000] LR: 0.398650\n",
      "Train | 16/16 | Loss:4.8507 | MainLoss:0.4404 | SPLoss:44.0673 | CLSLoss:0.3570 | top1:79.7600 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:2.6299 | MainLoss:0.2760 | SPLoss:23.4937 | CLSLoss:0.4507 | top1:89.3333 | AUROC:0.9561\n",
      "Test | 129/16 | Loss:3.3946 | MainLoss:1.0407 | SPLoss:23.4937 | CLSLoss:0.4507 | top1:53.2555 | AUROC:0.6390\n",
      "\n",
      "Epoch: [50 | 1000] LR: 0.398577\n",
      "Train | 16/16 | Loss:3917.1501 | MainLoss:0.3867 | SPLoss:39167.5938 | CLSLoss:0.4134 | top1:83.5733 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:2324.0753 | MainLoss:0.2308 | SPLoss:23238.3965 | CLSLoss:0.4701 | top1:90.8718 | AUROC:0.9701\n",
      "Test | 129/16 | Loss:2325.0184 | MainLoss:1.1739 | SPLoss:23238.3984 | CLSLoss:0.4701 | top1:53.4206 | AUROC:0.6030\n",
      "\n",
      "Epoch: [51 | 1000] LR: 0.398501\n",
      "Train | 16/16 | Loss:1326.4808 | MainLoss:0.3046 | SPLoss:13261.7158 | CLSLoss:0.4564 | top1:87.1200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:593.8813 | MainLoss:0.3973 | SPLoss:5934.7896 | CLSLoss:0.4898 | top1:83.6667 | AUROC:0.9551\n",
      "Test | 129/16 | Loss:595.1119 | MainLoss:1.6278 | SPLoss:5934.7856 | CLSLoss:0.4898 | top1:50.3240 | AUROC:0.4827\n",
      "\n",
      "Epoch: [52 | 1000] LR: 0.039842\n",
      "Train | 16/16 | Loss:558.3660 | MainLoss:0.2432 | SPLoss:5581.1792 | CLSLoss:0.4903 | top1:90.5067 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:519.6751 | MainLoss:0.1942 | SPLoss:5194.7578 | CLSLoss:0.5016 | top1:92.3846 | AUROC:0.9788\n",
      "Test | 129/16 | Loss:520.7661 | MainLoss:1.2852 | SPLoss:5194.7534 | CLSLoss:0.5016 | top1:52.7414 | AUROC:0.5657\n",
      "\n",
      "Epoch: [53 | 1000] LR: 0.039834\n",
      "Train | 16/16 | Loss:488.7402 | MainLoss:0.1883 | SPLoss:4885.4678 | CLSLoss:0.5114 | top1:92.7467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:454.9149 | MainLoss:0.1775 | SPLoss:4547.3208 | CLSLoss:0.5189 | top1:93.1923 | AUROC:0.9818\n",
      "Test | 129/16 | Loss:456.0969 | MainLoss:1.3595 | SPLoss:4547.3262 | CLSLoss:0.5189 | top1:52.8131 | AUROC:0.5725\n",
      "\n",
      "Epoch: [54 | 1000] LR: 0.039826\n",
      "Train | 16/16 | Loss:427.8520 | MainLoss:0.1809 | SPLoss:4276.6587 | CLSLoss:0.5265 | top1:93.0933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:398.2452 | MainLoss:0.1671 | SPLoss:3980.7273 | CLSLoss:0.5336 | top1:93.4744 | AUROC:0.9839\n",
      "Test | 129/16 | Loss:399.4682 | MainLoss:1.3902 | SPLoss:3980.7297 | CLSLoss:0.5336 | top1:53.3458 | AUROC:0.5937\n",
      "\n",
      "Epoch: [55 | 1000] LR: 0.039818\n",
      "Train | 16/16 | Loss:374.5482 | MainLoss:0.1577 | SPLoss:3743.8501 | CLSLoss:0.5409 | top1:94.0800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:348.6501 | MainLoss:0.1592 | SPLoss:3484.8538 | CLSLoss:0.5478 | top1:93.7821 | AUROC:0.9846\n",
      "Test | 129/16 | Loss:350.0201 | MainLoss:1.5292 | SPLoss:3484.8564 | CLSLoss:0.5478 | top1:52.3302 | AUROC:0.5756\n",
      "\n",
      "Epoch: [56 | 1000] LR: 0.039809\n",
      "Train | 16/16 | Loss:327.9184 | MainLoss:0.1585 | SPLoss:3277.5435 | CLSLoss:0.5533 | top1:93.8933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:305.2635 | MainLoss:0.1691 | SPLoss:3050.8884 | CLSLoss:0.5562 | top1:93.4872 | AUROC:0.9849\n",
      "Test | 129/16 | Loss:306.5302 | MainLoss:1.4357 | SPLoss:3050.8884 | CLSLoss:0.5562 | top1:53.3209 | AUROC:0.5791\n",
      "\n",
      "Epoch: [57 | 1000] LR: 0.039800\n",
      "Train | 16/16 | Loss:287.0940 | MainLoss:0.1446 | SPLoss:2869.4380 | CLSLoss:0.5610 | top1:94.5067 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:267.2787 | MainLoss:0.1679 | SPLoss:2671.0510 | CLSLoss:0.5685 | top1:93.5513 | AUROC:0.9846\n",
      "Test | 129/16 | Loss:268.6091 | MainLoss:1.4983 | SPLoss:2671.0503 | CLSLoss:0.5685 | top1:53.4642 | AUROC:0.5966\n",
      "\n",
      "Epoch: [58 | 1000] LR: 0.039792\n",
      "Train | 16/16 | Loss:251.3704 | MainLoss:0.1379 | SPLoss:2512.2678 | CLSLoss:0.5734 | top1:94.9333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:234.0385 | MainLoss:0.1681 | SPLoss:2338.6467 | CLSLoss:0.5795 | top1:93.4487 | AUROC:0.9837\n",
      "Test | 129/16 | Loss:235.4733 | MainLoss:1.6029 | SPLoss:2338.6450 | CLSLoss:0.5795 | top1:52.9720 | AUROC:0.5840\n",
      "\n",
      "Epoch: [59 | 1000] LR: 0.039782\n",
      "Train | 16/16 | Loss:220.0923 | MainLoss:0.1226 | SPLoss:2199.6387 | CLSLoss:0.5837 | top1:95.7867 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:204.9520 | MainLoss:0.1803 | SPLoss:2047.6570 | CLSLoss:0.5890 | top1:93.1026 | AUROC:0.9832\n",
      "Test | 129/16 | Loss:206.3456 | MainLoss:1.5739 | SPLoss:2047.6602 | CLSLoss:0.5890 | top1:54.0156 | AUROC:0.6071\n",
      "\n",
      "Epoch: [60 | 1000] LR: 0.039773\n",
      "Train | 16/16 | Loss:192.7375 | MainLoss:0.1321 | SPLoss:1925.9950 | CLSLoss:0.5931 | top1:94.9333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:179.4766 | MainLoss:0.1726 | SPLoss:1792.9808 | CLSLoss:0.5915 | top1:93.3846 | AUROC:0.9837\n",
      "Test | 129/16 | Loss:180.8747 | MainLoss:1.5706 | SPLoss:1792.9799 | CLSLoss:0.5915 | top1:53.5078 | AUROC:0.6042\n",
      "\n",
      "Epoch: [61 | 1000] LR: 0.039763\n",
      "Train | 16/16 | Loss:168.7800 | MainLoss:0.1250 | SPLoss:1686.4899 | CLSLoss:0.5981 | top1:95.2800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:157.1891 | MainLoss:0.1768 | SPLoss:1570.0638 | CLSLoss:0.6005 | top1:93.1667 | AUROC:0.9825\n",
      "Test | 129/16 | Loss:158.6245 | MainLoss:1.6122 | SPLoss:1570.0640 | CLSLoss:0.6005 | top1:53.7134 | AUROC:0.6121\n",
      "\n",
      "Epoch: [62 | 1000] LR: 0.039754\n",
      "Train | 16/16 | Loss:147.8205 | MainLoss:0.1301 | SPLoss:1476.8440 | CLSLoss:0.6020 | top1:95.0933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:137.6768 | MainLoss:0.1787 | SPLoss:1374.9198 | CLSLoss:0.6034 | top1:93.1026 | AUROC:0.9836\n",
      "Test | 129/16 | Loss:139.0604 | MainLoss:1.5624 | SPLoss:1374.9181 | CLSLoss:0.6034 | top1:54.3925 | AUROC:0.6150\n",
      "\n",
      "Epoch: [63 | 1000] LR: 0.039744\n",
      "Train | 16/16 | Loss:129.4573 | MainLoss:0.1204 | SPLoss:1293.3085 | CLSLoss:0.6082 | top1:95.6000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:120.5941 | MainLoss:0.1770 | SPLoss:1204.1096 | CLSLoss:0.6083 | top1:92.9744 | AUROC:0.9842\n",
      "Test | 129/16 | Loss:121.9124 | MainLoss:1.4954 | SPLoss:1204.1107 | CLSLoss:0.6083 | top1:55.1122 | AUROC:0.6180\n",
      "\n",
      "Epoch: [64 | 1000] LR: 0.039734\n",
      "Train | 16/16 | Loss:113.4018 | MainLoss:0.1256 | SPLoss:1132.7008 | CLSLoss:0.6112 | top1:95.3333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:105.6553 | MainLoss:0.1850 | SPLoss:1054.6421 | CLSLoss:0.6119 | top1:93.0513 | AUROC:0.9818\n",
      "Test | 129/16 | Loss:106.9780 | MainLoss:1.5077 | SPLoss:1054.6415 | CLSLoss:0.6119 | top1:54.9844 | AUROC:0.6327\n",
      "\n",
      "Epoch: [65 | 1000] LR: 0.039723\n",
      "Train | 16/16 | Loss:99.3329 | MainLoss:0.1171 | SPLoss:992.0964 | CLSLoss:0.6167 | top1:95.7867 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:92.5880 | MainLoss:0.2087 | SPLoss:923.7304 | CLSLoss:0.6198 | top1:92.1923 | AUROC:0.9831\n",
      "Test | 129/16 | Loss:93.7548 | MainLoss:1.3755 | SPLoss:923.7299 | CLSLoss:0.6198 | top1:58.1464 | AUROC:0.6841\n",
      "\n",
      "Epoch: [66 | 1000] LR: 0.039713\n",
      "Train | 16/16 | Loss:87.0232 | MainLoss:0.1180 | SPLoss:868.9893 | CLSLoss:0.6224 | top1:95.6533 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:81.0860 | MainLoss:0.1663 | SPLoss:809.1355 | CLSLoss:0.6231 | top1:93.7692 | AUROC:0.9834\n",
      "Test | 129/16 | Loss:82.6986 | MainLoss:1.7789 | SPLoss:809.1359 | CLSLoss:0.6231 | top1:53.1651 | AUROC:0.6109\n",
      "\n",
      "Epoch: [67 | 1000] LR: 0.039702\n",
      "Train | 16/16 | Loss:76.2464 | MainLoss:0.1186 | SPLoss:761.2159 | CLSLoss:0.6255 | top1:95.7867 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:71.0449 | MainLoss:0.1579 | SPLoss:708.8067 | CLSLoss:0.6262 | top1:94.0897 | AUROC:0.9847\n",
      "Test | 129/16 | Loss:72.5948 | MainLoss:1.7079 | SPLoss:708.8074 | CLSLoss:0.6262 | top1:53.7196 | AUROC:0.6266\n",
      "\n",
      "Epoch: [68 | 1000] LR: 0.039691\n",
      "Train | 16/16 | Loss:66.8075 | MainLoss:0.1172 | SPLoss:666.8403 | CLSLoss:0.6270 | top1:95.8667 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:62.3022 | MainLoss:0.2013 | SPLoss:620.9468 | CLSLoss:0.6259 | top1:92.1154 | AUROC:0.9842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 129/16 | Loss:63.5483 | MainLoss:1.4474 | SPLoss:620.9468 | CLSLoss:0.6259 | top1:56.8474 | AUROC:0.6654\n",
      "\n",
      "Epoch: [69 | 1000] LR: 0.039680\n",
      "Train | 16/16 | Loss:58.5368 | MainLoss:0.1098 | SPLoss:584.2076 | CLSLoss:0.6301 | top1:96.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:54.5897 | MainLoss:0.1786 | SPLoss:544.0479 | CLSLoss:0.6316 | top1:93.2821 | AUROC:0.9849\n",
      "Test | 129/16 | Loss:55.9823 | MainLoss:1.5712 | SPLoss:544.0479 | CLSLoss:0.6316 | top1:55.5078 | AUROC:0.6550\n",
      "\n",
      "Epoch: [70 | 1000] LR: 0.039669\n",
      "Train | 16/16 | Loss:51.3220 | MainLoss:0.1276 | SPLoss:511.8808 | CLSLoss:0.6315 | top1:95.3867 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:47.8520 | MainLoss:0.1736 | SPLoss:476.7202 | CLSLoss:0.6317 | top1:93.2821 | AUROC:0.9834\n",
      "Test | 129/16 | Loss:49.3282 | MainLoss:1.6499 | SPLoss:476.7201 | CLSLoss:0.6317 | top1:53.0841 | AUROC:0.5899\n",
      "\n",
      "Epoch: [71 | 1000] LR: 0.039657\n",
      "Train | 16/16 | Loss:44.9737 | MainLoss:0.1108 | SPLoss:448.5657 | CLSLoss:0.6345 | top1:95.8400 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:41.9573 | MainLoss:0.1739 | SPLoss:417.7701 | CLSLoss:0.6370 | top1:93.4487 | AUROC:0.9826\n",
      "Test | 129/16 | Loss:43.5132 | MainLoss:1.7298 | SPLoss:417.7708 | CLSLoss:0.6370 | top1:54.3489 | AUROC:0.6094\n",
      "\n",
      "Epoch: [72 | 1000] LR: 0.039646\n",
      "Train | 16/16 | Loss:39.4219 | MainLoss:0.1049 | SPLoss:393.1057 | CLSLoss:0.6390 | top1:96.0800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:36.8214 | MainLoss:0.2018 | SPLoss:366.1311 | CLSLoss:0.6434 | top1:92.5128 | AUROC:0.9830\n",
      "Test | 129/16 | Loss:38.1585 | MainLoss:1.5389 | SPLoss:366.1317 | CLSLoss:0.6434 | top1:56.9595 | AUROC:0.6670\n",
      "\n",
      "Epoch: [73 | 1000] LR: 0.039634\n",
      "Train | 16/16 | Loss:34.5635 | MainLoss:0.1020 | SPLoss:344.5502 | CLSLoss:0.6456 | top1:96.3200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:32.2878 | MainLoss:0.1866 | SPLoss:320.9476 | CLSLoss:0.6463 | top1:92.9615 | AUROC:0.9822\n",
      "Test | 129/16 | Loss:33.7101 | MainLoss:1.6089 | SPLoss:320.9479 | CLSLoss:0.6463 | top1:55.5514 | AUROC:0.6296\n",
      "\n",
      "Epoch: [74 | 1000] LR: 0.039622\n",
      "Train | 16/16 | Loss:30.3278 | MainLoss:0.1125 | SPLoss:302.0881 | CLSLoss:0.6454 | top1:96.1600 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:28.3172 | MainLoss:0.1709 | SPLoss:281.3987 | CLSLoss:0.6458 | top1:93.6154 | AUROC:0.9831\n",
      "Test | 129/16 | Loss:29.9414 | MainLoss:1.7951 | SPLoss:281.3985 | CLSLoss:0.6458 | top1:54.3738 | AUROC:0.6496\n",
      "\n",
      "Epoch: [75 | 1000] LR: 0.039610\n",
      "Train | 16/16 | Loss:26.6231 | MainLoss:0.1290 | SPLoss:264.8771 | CLSLoss:0.6443 | top1:94.8000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:24.8668 | MainLoss:0.1724 | SPLoss:246.8804 | CLSLoss:0.6433 | top1:93.4487 | AUROC:0.9838\n",
      "Test | 129/16 | Loss:26.2263 | MainLoss:1.5318 | SPLoss:246.8801 | CLSLoss:0.6433 | top1:56.5296 | AUROC:0.6959\n",
      "\n",
      "Epoch: [76 | 1000] LR: 0.039597\n",
      "Train | 16/16 | Loss:23.3516 | MainLoss:0.1072 | SPLoss:232.3785 | CLSLoss:0.6468 | top1:95.9467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:21.8275 | MainLoss:0.1686 | SPLoss:216.5235 | CLSLoss:0.6493 | top1:93.6154 | AUROC:0.9848\n",
      "Test | 129/16 | Loss:23.3240 | MainLoss:1.6651 | SPLoss:216.5239 | CLSLoss:0.6493 | top1:55.5452 | AUROC:0.6567\n",
      "\n",
      "Epoch: [77 | 1000] LR: 0.039584\n",
      "Train | 16/16 | Loss:20.5030 | MainLoss:0.1157 | SPLoss:203.8079 | CLSLoss:0.6495 | top1:95.7600 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:19.1600 | MainLoss:0.1642 | SPLoss:189.8925 | CLSLoss:0.6481 | top1:93.6282 | AUROC:0.9847\n",
      "Test | 129/16 | Loss:20.5604 | MainLoss:1.5646 | SPLoss:189.8925 | CLSLoss:0.6481 | top1:56.1526 | AUROC:0.6919\n",
      "\n",
      "Epoch: [78 | 1000] LR: 0.039572\n",
      "Train | 16/16 | Loss:17.9860 | MainLoss:0.1037 | SPLoss:178.7580 | CLSLoss:0.6513 | top1:95.9467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:16.8386 | MainLoss:0.1735 | SPLoss:166.5850 | CLSLoss:0.6531 | top1:93.5897 | AUROC:0.9852\n",
      "Test | 129/16 | Loss:18.2608 | MainLoss:1.5958 | SPLoss:166.5852 | CLSLoss:0.6531 | top1:56.4486 | AUROC:0.6807\n",
      "\n",
      "Epoch: [79 | 1000] LR: 0.039559\n",
      "Train | 16/16 | Loss:15.7849 | MainLoss:0.0949 | SPLoss:156.8342 | CLSLoss:0.6566 | top1:96.7200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:14.8158 | MainLoss:0.1882 | SPLoss:146.2101 | CLSLoss:0.6556 | top1:92.9231 | AUROC:0.9810\n",
      "Test | 129/16 | Loss:16.2447 | MainLoss:1.6171 | SPLoss:146.2100 | CLSLoss:0.6556 | top1:56.5171 | AUROC:0.6770\n",
      "\n",
      "Epoch: [80 | 1000] LR: 0.039545\n",
      "Train | 16/16 | Loss:13.8849 | MainLoss:0.1116 | SPLoss:137.6679 | CLSLoss:0.6551 | top1:95.7867 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:13.0059 | MainLoss:0.1674 | SPLoss:128.3204 | CLSLoss:0.6516 | top1:93.6667 | AUROC:0.9843\n",
      "Test | 129/16 | Loss:14.4681 | MainLoss:1.6295 | SPLoss:128.3203 | CLSLoss:0.6516 | top1:55.3551 | AUROC:0.6532\n",
      "\n",
      "Epoch: [81 | 1000] LR: 0.039532\n",
      "Train | 16/16 | Loss:12.2142 | MainLoss:0.1171 | SPLoss:120.9066 | CLSLoss:0.6523 | top1:95.7600 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:11.4511 | MainLoss:0.1629 | SPLoss:112.8171 | CLSLoss:0.6501 | top1:93.9231 | AUROC:0.9837\n",
      "Test | 129/16 | Loss:12.9951 | MainLoss:1.7069 | SPLoss:112.8170 | CLSLoss:0.6501 | top1:54.5670 | AUROC:0.6413\n",
      "\n",
      "Epoch: [82 | 1000] LR: 0.039518\n",
      "Train | 16/16 | Loss:10.7483 | MainLoss:0.1166 | SPLoss:106.2513 | CLSLoss:0.6512 | top1:95.8400 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:10.0913 | MainLoss:0.1775 | SPLoss:99.0727 | CLSLoss:0.6494 | top1:93.3205 | AUROC:0.9835\n",
      "Test | 129/16 | Loss:11.5278 | MainLoss:1.6140 | SPLoss:99.0728 | CLSLoss:0.6494 | top1:55.5950 | AUROC:0.6421\n",
      "\n",
      "Epoch: [83 | 1000] LR: 0.039505\n",
      "Train | 16/16 | Loss:9.4891 | MainLoss:0.1209 | SPLoss:93.6168 | CLSLoss:0.6500 | top1:95.6267 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:9.0317 | MainLoss:0.1758 | SPLoss:88.4940 | CLSLoss:0.6480 | top1:93.2051 | AUROC:0.9830\n",
      "Test | 129/16 | Loss:10.4320 | MainLoss:1.5762 | SPLoss:88.4940 | CLSLoss:0.6480 | top1:55.9782 | AUROC:0.6749\n",
      "\n",
      "Epoch: [84 | 1000] LR: 0.039491\n",
      "Train | 16/16 | Loss:8.4749 | MainLoss:0.1296 | SPLoss:83.3880 | CLSLoss:0.6470 | top1:94.6933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:7.9592 | MainLoss:0.1742 | SPLoss:77.7856 | CLSLoss:0.6453 | top1:93.1795 | AUROC:0.9846\n",
      "Test | 129/16 | Loss:9.3229 | MainLoss:1.5379 | SPLoss:77.7856 | CLSLoss:0.6453 | top1:56.3863 | AUROC:0.6983\n",
      "\n",
      "Epoch: [85 | 1000] LR: 0.039476\n",
      "Train | 16/16 | Loss:7.4407 | MainLoss:0.1048 | SPLoss:73.2933 | CLSLoss:0.6490 | top1:95.9733 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:7.0211 | MainLoss:0.1764 | SPLoss:68.3820 | CLSLoss:0.6526 | top1:93.0128 | AUROC:0.9831\n",
      "Test | 129/16 | Loss:8.5104 | MainLoss:1.6656 | SPLoss:68.3820 | CLSLoss:0.6526 | top1:55.4050 | AUROC:0.6731\n",
      "\n",
      "Epoch: [86 | 1000] LR: 0.039462\n",
      "Train | 16/16 | Loss:6.5592 | MainLoss:0.1079 | SPLoss:64.4469 | CLSLoss:0.6533 | top1:95.9733 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:6.2236 | MainLoss:0.2021 | SPLoss:60.1497 | CLSLoss:0.6559 | top1:92.5897 | AUROC:0.9817\n",
      "Test | 129/16 | Loss:7.6035 | MainLoss:1.5820 | SPLoss:60.1499 | CLSLoss:0.6560 | top1:57.2336 | AUROC:0.7126\n",
      "\n",
      "Epoch: [87 | 1000] LR: 0.039447\n",
      "Train | 16/16 | Loss:5.9021 | MainLoss:0.1122 | SPLoss:57.8329 | CLSLoss:0.6559 | top1:95.8933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:5.7271 | MainLoss:0.1904 | SPLoss:55.3009 | CLSLoss:0.6539 | top1:92.8462 | AUROC:0.9806\n",
      "Test | 129/16 | Loss:7.3024 | MainLoss:1.7658 | SPLoss:55.3010 | CLSLoss:0.6539 | top1:54.9626 | AUROC:0.6804\n",
      "\n",
      "Epoch: [88 | 1000] LR: 0.039433\n",
      "Train | 16/16 | Loss:5.3405 | MainLoss:0.1184 | SPLoss:52.1557 | CLSLoss:0.6534 | top1:95.6800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:5.0583 | MainLoss:0.1787 | SPLoss:48.7301 | CLSLoss:0.6536 | top1:93.1538 | AUROC:0.9816\n",
      "Test | 129/16 | Loss:6.6671 | MainLoss:1.7876 | SPLoss:48.7301 | CLSLoss:0.6536 | top1:54.4704 | AUROC:0.6814\n",
      "\n",
      "Epoch: [89 | 1000] LR: 0.039418\n",
      "Train | 16/16 | Loss:4.7110 | MainLoss:0.1082 | SPLoss:45.9630 | CLSLoss:0.6552 | top1:95.7867 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:4.4789 | MainLoss:0.1797 | SPLoss:42.9269 | CLSLoss:0.6559 | top1:93.2564 | AUROC:0.9819\n",
      "Test | 129/16 | Loss:6.1037 | MainLoss:1.8044 | SPLoss:42.9270 | CLSLoss:0.6559 | top1:54.6106 | AUROC:0.6682\n",
      "\n",
      "Epoch: [90 | 1000] LR: 0.039403\n",
      "Train | 16/16 | Loss:4.1850 | MainLoss:0.1263 | SPLoss:40.5218 | CLSLoss:0.6526 | top1:95.2000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:3.9606 | MainLoss:0.1686 | SPLoss:37.8547 | CLSLoss:0.6521 | top1:93.7564 | AUROC:0.9831\n",
      "Test | 129/16 | Loss:5.4800 | MainLoss:1.6880 | SPLoss:37.8547 | CLSLoss:0.6521 | top1:55.2336 | AUROC:0.6871\n",
      "\n",
      "Epoch: [91 | 1000] LR: 0.039387\n",
      "Train | 16/16 | Loss:3.6865 | MainLoss:0.1067 | SPLoss:35.7325 | CLSLoss:0.6548 | top1:95.7867 | AUROC:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 32/16 | Loss:3.5272 | MainLoss:0.1793 | SPLoss:33.4135 | CLSLoss:0.6534 | top1:93.0385 | AUROC:0.9834\n",
      "Test | 129/16 | Loss:4.9057 | MainLoss:1.5578 | SPLoss:33.4135 | CLSLoss:0.6534 | top1:56.9097 | AUROC:0.7070\n",
      "\n",
      "Epoch: [92 | 1000] LR: 0.039372\n",
      "Train | 16/16 | Loss:3.2601 | MainLoss:0.1007 | SPLoss:31.5282 | CLSLoss:0.6566 | top1:96.3200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:3.1258 | MainLoss:0.1716 | SPLoss:29.4771 | CLSLoss:0.6544 | top1:93.5385 | AUROC:0.9831\n",
      "Test | 129/16 | Loss:4.6881 | MainLoss:1.7338 | SPLoss:29.4772 | CLSLoss:0.6544 | top1:54.5763 | AUROC:0.6600\n",
      "\n",
      "Epoch: [93 | 1000] LR: 0.039356\n",
      "Train | 16/16 | Loss:2.9036 | MainLoss:0.1111 | SPLoss:27.8595 | CLSLoss:0.6539 | top1:95.8400 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:2.7918 | MainLoss:0.1775 | SPLoss:26.0773 | CLSLoss:0.6542 | top1:93.3205 | AUROC:0.9843\n",
      "Test | 129/16 | Loss:4.1674 | MainLoss:1.5532 | SPLoss:26.0773 | CLSLoss:0.6542 | top1:56.7508 | AUROC:0.7022\n",
      "\n",
      "Epoch: [94 | 1000] LR: 0.039340\n",
      "Train | 16/16 | Loss:2.5887 | MainLoss:0.1166 | SPLoss:24.6554 | CLSLoss:0.6542 | top1:95.9200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:2.4919 | MainLoss:0.1735 | SPLoss:23.1181 | CLSLoss:0.6549 | top1:93.6154 | AUROC:0.9842\n",
      "Test | 129/16 | Loss:3.8819 | MainLoss:1.5636 | SPLoss:23.1180 | CLSLoss:0.6549 | top1:56.5296 | AUROC:0.6891\n",
      "\n",
      "Epoch: [95 | 1000] LR: 0.039324\n",
      "Train | 16/16 | Loss:2.2955 | MainLoss:0.1016 | SPLoss:21.8735 | CLSLoss:0.6570 | top1:96.2933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:2.2995 | MainLoss:0.2259 | SPLoss:20.6704 | CLSLoss:0.6570 | top1:91.8205 | AUROC:0.9844\n",
      "Test | 129/16 | Loss:3.4271 | MainLoss:1.3535 | SPLoss:20.6704 | CLSLoss:0.6570 | top1:59.8660 | AUROC:0.7253\n",
      "\n",
      "Epoch: [96 | 1000] LR: 0.039308\n",
      "Train | 16/16 | Loss:2.0544 | MainLoss:0.0943 | SPLoss:19.5358 | CLSLoss:0.6601 | top1:96.4533 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:2.0241 | MainLoss:0.1859 | SPLoss:18.3153 | CLSLoss:0.6599 | top1:93.0769 | AUROC:0.9842\n",
      "Test | 129/16 | Loss:3.3372 | MainLoss:1.4990 | SPLoss:18.3153 | CLSLoss:0.6599 | top1:58.3084 | AUROC:0.7160\n",
      "\n",
      "Epoch: [97 | 1000] LR: 0.039291\n",
      "Train | 16/16 | Loss:1.8403 | MainLoss:0.0980 | SPLoss:17.3569 | CLSLoss:0.6623 | top1:96.5600 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:1.8319 | MainLoss:0.1881 | SPLoss:16.3713 | CLSLoss:0.6615 | top1:92.9487 | AUROC:0.9834\n",
      "Test | 129/16 | Loss:3.1984 | MainLoss:1.5547 | SPLoss:16.3713 | CLSLoss:0.6615 | top1:57.7664 | AUROC:0.7063\n",
      "\n",
      "Epoch: [98 | 1000] LR: 0.039274\n",
      "Train | 16/16 | Loss:1.6833 | MainLoss:0.0926 | SPLoss:15.8409 | CLSLoss:0.6654 | top1:96.6133 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:1.7273 | MainLoss:0.1777 | SPLoss:15.4293 | CLSLoss:0.6627 | top1:93.2436 | AUROC:0.9826\n",
      "Test | 129/16 | Loss:3.1885 | MainLoss:1.6390 | SPLoss:15.4293 | CLSLoss:0.6627 | top1:56.3925 | AUROC:0.6944\n",
      "\n",
      "Epoch: [99 | 1000] LR: 0.039258\n",
      "Train | 16/16 | Loss:1.5744 | MainLoss:0.1047 | SPLoss:14.6298 | CLSLoss:0.6648 | top1:96.4267 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:1.5590 | MainLoss:0.1772 | SPLoss:13.7518 | CLSLoss:0.6622 | top1:93.4231 | AUROC:0.9830\n",
      "Test | 129/16 | Loss:2.9824 | MainLoss:1.6006 | SPLoss:13.7519 | CLSLoss:0.6622 | top1:56.7757 | AUROC:0.7123\n",
      "\n",
      "Epoch: [100 | 1000] LR: 0.039241\n",
      "Train | 16/16 | Loss:1.4055 | MainLoss:0.0952 | SPLoss:13.0357 | CLSLoss:0.6649 | top1:96.4800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:1.4088 | MainLoss:0.1770 | SPLoss:12.2514 | CLSLoss:0.6684 | top1:93.5513 | AUROC:0.9825\n",
      "Test | 129/16 | Loss:3.0460 | MainLoss:1.8142 | SPLoss:12.2514 | CLSLoss:0.6684 | top1:54.9470 | AUROC:0.7004\n",
      "\n",
      "Epoch: [101 | 1000] LR: 0.039223\n",
      "Train | 16/16 | Loss:1.2779 | MainLoss:0.1061 | SPLoss:11.6505 | CLSLoss:0.6690 | top1:96.0800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:1.3025 | MainLoss:0.1962 | SPLoss:10.9964 | CLSLoss:0.6652 | top1:92.6667 | AUROC:0.9817\n",
      "Test | 129/16 | Loss:2.5978 | MainLoss:1.4915 | SPLoss:10.9964 | CLSLoss:0.6652 | top1:57.8567 | AUROC:0.7154\n",
      "\n",
      "Epoch: [102 | 1000] LR: 0.039206\n",
      "Train | 16/16 | Loss:2.2513 | MainLoss:0.1449 | SPLoss:20.9978 | CLSLoss:0.6605 | top1:94.7467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:4.0561 | MainLoss:0.1970 | SPLoss:38.5248 | CLSLoss:0.6551 | top1:92.3718 | AUROC:0.9772\n",
      "Test | 129/16 | Loss:5.3918 | MainLoss:1.5327 | SPLoss:38.5248 | CLSLoss:0.6551 | top1:56.5452 | AUROC:0.8345\n",
      "\n",
      "Epoch: [103 | 1000] LR: 0.039188\n",
      "Train | 16/16 | Loss:3.7653 | MainLoss:0.1210 | SPLoss:36.3777 | CLSLoss:0.6583 | top1:95.2267 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:3.5888 | MainLoss:0.1805 | SPLoss:34.0168 | CLSLoss:0.6605 | top1:93.2308 | AUROC:0.9814\n",
      "Test | 129/16 | Loss:5.0439 | MainLoss:1.6356 | SPLoss:34.0168 | CLSLoss:0.6605 | top1:55.8536 | AUROC:0.7683\n",
      "\n",
      "Epoch: [104 | 1000] LR: 0.039170\n",
      "Train | 16/16 | Loss:3.3323 | MainLoss:0.1139 | SPLoss:32.1181 | CLSLoss:0.6616 | top1:95.8933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:3.2009 | MainLoss:0.1895 | SPLoss:30.0484 | CLSLoss:0.6619 | top1:92.7821 | AUROC:0.9800\n",
      "Test | 129/16 | Loss:4.6826 | MainLoss:1.6712 | SPLoss:30.0483 | CLSLoss:0.6619 | top1:56.2430 | AUROC:0.8068\n",
      "\n",
      "Epoch: [105 | 1000] LR: 0.039152\n",
      "Train | 16/16 | Loss:2.9643 | MainLoss:0.1124 | SPLoss:28.4525 | CLSLoss:0.6613 | top1:95.9200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:2.8478 | MainLoss:0.1753 | SPLoss:26.6586 | CLSLoss:0.6625 | top1:93.3974 | AUROC:0.9828\n",
      "Test | 129/16 | Loss:4.2905 | MainLoss:1.6180 | SPLoss:26.6586 | CLSLoss:0.6625 | top1:56.9003 | AUROC:0.7639\n",
      "\n",
      "Epoch: [106 | 1000] LR: 0.039134\n",
      "Train | 16/16 | Loss:2.6385 | MainLoss:0.1124 | SPLoss:25.1939 | CLSLoss:0.6636 | top1:95.6267 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:2.5490 | MainLoss:0.1814 | SPLoss:23.6101 | CLSLoss:0.6637 | top1:93.0897 | AUROC:0.9824\n",
      "Test | 129/16 | Loss:3.8691 | MainLoss:1.5014 | SPLoss:23.6100 | CLSLoss:0.6637 | top1:58.5545 | AUROC:0.8053\n",
      "\n",
      "Epoch: [107 | 1000] LR: 0.039116\n",
      "Train | 16/16 | Loss:2.3436 | MainLoss:0.1051 | SPLoss:22.3184 | CLSLoss:0.6637 | top1:96.2667 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:2.3287 | MainLoss:0.2297 | SPLoss:20.9231 | CLSLoss:0.6634 | top1:91.3974 | AUROC:0.9823\n",
      "Test | 129/16 | Loss:3.2992 | MainLoss:1.2002 | SPLoss:20.9231 | CLSLoss:0.6634 | top1:63.1776 | AUROC:0.8035\n",
      "\n",
      "Epoch: [108 | 1000] LR: 0.039097\n",
      "Train | 16/16 | Loss:2.0812 | MainLoss:0.0944 | SPLoss:19.8020 | CLSLoss:0.6656 | top1:96.4267 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:2.0469 | MainLoss:0.1838 | SPLoss:18.5645 | CLSLoss:0.6691 | top1:93.4359 | AUROC:0.9827\n",
      "Test | 129/16 | Loss:3.4149 | MainLoss:1.5517 | SPLoss:18.5645 | CLSLoss:0.6691 | top1:58.7570 | AUROC:0.8040\n",
      "\n",
      "Epoch: [109 | 1000] LR: 0.039079\n",
      "Train | 16/16 | Loss:2.0350 | MainLoss:0.1054 | SPLoss:19.2300 | CLSLoss:0.6684 | top1:96.2667 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:3.4738 | MainLoss:0.1801 | SPLoss:32.8709 | CLSLoss:0.6674 | top1:93.0769 | AUROC:0.9826\n",
      "Test | 129/16 | Loss:4.8770 | MainLoss:1.5833 | SPLoss:32.8708 | CLSLoss:0.6674 | top1:57.6854 | AUROC:0.7668\n",
      "\n",
      "Epoch: [110 | 1000] LR: 0.039060\n",
      "Train | 16/16 | Loss:3.2295 | MainLoss:0.0939 | SPLoss:31.2887 | CLSLoss:0.6687 | top1:96.6133 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:3.1509 | MainLoss:0.2152 | SPLoss:29.2900 | CLSLoss:0.6692 | top1:91.9359 | AUROC:0.9823\n",
      "Test | 129/16 | Loss:4.2985 | MainLoss:1.3628 | SPLoss:29.2900 | CLSLoss:0.6692 | top1:60.6885 | AUROC:0.7782\n",
      "\n",
      "Epoch: [111 | 1000] LR: 0.039040\n",
      "Train | 16/16 | Loss:2.8891 | MainLoss:0.1141 | SPLoss:27.6832 | CLSLoss:0.6668 | top1:96.0533 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:2.7926 | MainLoss:0.1936 | SPLoss:25.9239 | CLSLoss:0.6642 | top1:92.5641 | AUROC:0.9815\n",
      "Test | 129/16 | Loss:4.0679 | MainLoss:1.4688 | SPLoss:25.9238 | CLSLoss:0.6642 | top1:58.5296 | AUROC:0.7675\n",
      "\n",
      "Epoch: [112 | 1000] LR: 0.039021\n",
      "Train | 16/16 | Loss:2.5522 | MainLoss:0.0950 | SPLoss:24.5053 | CLSLoss:0.6669 | top1:96.5067 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:2.4798 | MainLoss:0.1787 | SPLoss:22.9438 | CLSLoss:0.6680 | top1:93.3077 | AUROC:0.9827\n",
      "Test | 129/16 | Loss:4.0290 | MainLoss:1.7279 | SPLoss:22.9438 | CLSLoss:0.6680 | top1:56.5109 | AUROC:0.7514\n",
      "\n",
      "Epoch: [113 | 1000] LR: 0.039002\n",
      "Train | 16/16 | Loss:2.2746 | MainLoss:0.0971 | SPLoss:21.7091 | CLSLoss:0.6682 | top1:96.3467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:2.2158 | MainLoss:0.1727 | SPLoss:20.3640 | CLSLoss:0.6675 | top1:93.5897 | AUROC:0.9835\n",
      "Test | 129/16 | Loss:3.7744 | MainLoss:1.7313 | SPLoss:20.3640 | CLSLoss:0.6675 | top1:56.1371 | AUROC:0.7375\n",
      "\n",
      "Epoch: [114 | 1000] LR: 0.038982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 16/16 | Loss:2.0423 | MainLoss:0.1074 | SPLoss:19.2826 | CLSLoss:0.6651 | top1:96.0800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:1.9906 | MainLoss:0.1762 | SPLoss:18.0776 | CLSLoss:0.6672 | top1:93.3590 | AUROC:0.9830\n",
      "Test | 129/16 | Loss:3.4584 | MainLoss:1.6440 | SPLoss:18.0776 | CLSLoss:0.6672 | top1:57.2212 | AUROC:0.7686\n",
      "\n",
      "Epoch: [115 | 1000] LR: 0.038962\n",
      "Train | 16/16 | Loss:1.8084 | MainLoss:0.0904 | SPLoss:17.1130 | CLSLoss:0.6694 | top1:96.8800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:1.7988 | MainLoss:0.1865 | SPLoss:16.0567 | CLSLoss:0.6685 | top1:93.1154 | AUROC:0.9812\n",
      "Test | 129/16 | Loss:3.2289 | MainLoss:1.6165 | SPLoss:16.0566 | CLSLoss:0.6685 | top1:57.7788 | AUROC:0.7822\n",
      "\n",
      "Epoch: [116 | 1000] LR: 0.038942\n",
      "Train | 16/16 | Loss:1.6430 | MainLoss:0.1051 | SPLoss:15.3122 | CLSLoss:0.6684 | top1:96.1333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:1.6331 | MainLoss:0.1814 | SPLoss:14.4501 | CLSLoss:0.6676 | top1:93.2308 | AUROC:0.9814\n",
      "Test | 129/16 | Loss:3.0660 | MainLoss:1.6143 | SPLoss:14.4500 | CLSLoss:0.6676 | top1:57.5265 | AUROC:0.7709\n",
      "\n",
      "Epoch: [117 | 1000] LR: 0.038922\n",
      "Train | 16/16 | Loss:1.4871 | MainLoss:0.1042 | SPLoss:13.7618 | CLSLoss:0.6690 | top1:95.9733 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:1.6028 | MainLoss:0.2636 | SPLoss:13.3263 | CLSLoss:0.6668 | top1:89.9615 | AUROC:0.9792\n",
      "Test | 129/16 | Loss:2.5107 | MainLoss:1.1714 | SPLoss:13.3263 | CLSLoss:0.6668 | top1:63.8006 | AUROC:0.8073\n",
      "\n",
      "Epoch: [118 | 1000] LR: 0.038901\n",
      "Train | 16/16 | Loss:1.4036 | MainLoss:0.1294 | SPLoss:12.6758 | CLSLoss:0.6647 | top1:95.0933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:1.3894 | MainLoss:0.1862 | SPLoss:11.9661 | CLSLoss:0.6615 | top1:92.8718 | AUROC:0.9809\n",
      "Test | 129/16 | Loss:2.7252 | MainLoss:1.5219 | SPLoss:11.9661 | CLSLoss:0.6615 | top1:57.0156 | AUROC:0.7767\n",
      "\n",
      "Epoch: [119 | 1000] LR: 0.038881\n",
      "Train | 16/16 | Loss:1.2638 | MainLoss:0.1215 | SPLoss:11.3568 | CLSLoss:0.6620 | top1:95.7067 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:1.2777 | MainLoss:0.2008 | SPLoss:10.7027 | CLSLoss:0.6633 | top1:92.3333 | AUROC:0.9814\n",
      "Test | 129/16 | Loss:2.5725 | MainLoss:1.4956 | SPLoss:10.7027 | CLSLoss:0.6633 | top1:58.0935 | AUROC:0.7737\n",
      "\n",
      "Epoch: [120 | 1000] LR: 0.038860\n",
      "Train | 16/16 | Loss:1.1246 | MainLoss:0.1007 | SPLoss:10.1725 | CLSLoss:0.6659 | top1:96.3467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:1.1335 | MainLoss:0.1677 | SPLoss:9.5905 | CLSLoss:0.6669 | top1:93.8333 | AUROC:0.9828\n",
      "Test | 129/16 | Loss:2.8114 | MainLoss:1.8457 | SPLoss:9.5905 | CLSLoss:0.6669 | top1:54.4206 | AUROC:0.7159\n",
      "\n",
      "Epoch: [121 | 1000] LR: 0.038839\n",
      "Train | 16/16 | Loss:1.0373 | MainLoss:0.1125 | SPLoss:9.1814 | CLSLoss:0.6668 | top1:95.7333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:1.1005 | MainLoss:0.1872 | SPLoss:9.0663 | CLSLoss:0.6636 | top1:92.8974 | AUROC:0.9828\n",
      "Test | 129/16 | Loss:2.5284 | MainLoss:1.6151 | SPLoss:9.0663 | CLSLoss:0.6636 | top1:56.0312 | AUROC:0.7269\n",
      "\n",
      "Epoch: [122 | 1000] LR: 0.038818\n",
      "Train | 16/16 | Loss:0.9757 | MainLoss:0.0961 | SPLoss:8.7296 | CLSLoss:0.6688 | top1:96.5333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:1.0808 | MainLoss:0.1980 | SPLoss:8.7612 | CLSLoss:0.6688 | top1:92.7308 | AUROC:0.9831\n",
      "Test | 129/16 | Loss:2.5127 | MainLoss:1.6299 | SPLoss:8.7612 | CLSLoss:0.6688 | top1:57.2087 | AUROC:0.7651\n",
      "\n",
      "Epoch: [123 | 1000] LR: 0.038796\n",
      "Train | 16/16 | Loss:0.9672 | MainLoss:0.1252 | SPLoss:8.3539 | CLSLoss:0.6643 | top1:95.2800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.9693 | MainLoss:0.1719 | SPLoss:7.9073 | CLSLoss:0.6653 | top1:93.2179 | AUROC:0.9843\n",
      "Test | 129/16 | Loss:2.5037 | MainLoss:1.7064 | SPLoss:7.9073 | CLSLoss:0.6653 | top1:55.9190 | AUROC:0.7652\n",
      "\n",
      "Epoch: [124 | 1000] LR: 0.038775\n",
      "Train | 16/16 | Loss:0.8715 | MainLoss:0.1101 | SPLoss:7.5472 | CLSLoss:0.6673 | top1:96.0267 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.9000 | MainLoss:0.1756 | SPLoss:7.1775 | CLSLoss:0.6657 | top1:93.4231 | AUROC:0.9838\n",
      "Test | 129/16 | Loss:2.4380 | MainLoss:1.7136 | SPLoss:7.1775 | CLSLoss:0.6657 | top1:55.4174 | AUROC:0.7299\n",
      "\n",
      "Epoch: [125 | 1000] LR: 0.038753\n",
      "Train | 16/16 | Loss:0.8040 | MainLoss:0.1124 | SPLoss:6.8488 | CLSLoss:0.6666 | top1:95.6800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.8621 | MainLoss:0.2049 | SPLoss:6.5055 | CLSLoss:0.6659 | top1:92.2308 | AUROC:0.9849\n",
      "Test | 129/16 | Loss:2.1722 | MainLoss:1.5150 | SPLoss:6.5055 | CLSLoss:0.6659 | top1:56.9875 | AUROC:0.7227\n",
      "\n",
      "Epoch: [126 | 1000] LR: 0.038731\n",
      "Train | 16/16 | Loss:0.7242 | MainLoss:0.0945 | SPLoss:6.2297 | CLSLoss:0.6704 | top1:96.8000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.7800 | MainLoss:0.1788 | SPLoss:5.9444 | CLSLoss:0.6719 | top1:93.2179 | AUROC:0.9842\n",
      "Test | 129/16 | Loss:2.3927 | MainLoss:1.7916 | SPLoss:5.9444 | CLSLoss:0.6719 | top1:55.8131 | AUROC:0.7513\n",
      "\n",
      "Epoch: [127 | 1000] LR: 0.038709\n",
      "Train | 16/16 | Loss:0.6884 | MainLoss:0.1052 | SPLoss:5.7644 | CLSLoss:0.6708 | top1:96.2400 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.7372 | MainLoss:0.1793 | SPLoss:5.5115 | CLSLoss:0.6704 | top1:93.2692 | AUROC:0.9833\n",
      "Test | 129/16 | Loss:2.3135 | MainLoss:1.7557 | SPLoss:5.5115 | CLSLoss:0.6704 | top1:55.6324 | AUROC:0.7277\n",
      "\n",
      "Epoch: [128 | 1000] LR: 0.038687\n",
      "Train | 16/16 | Loss:0.6244 | MainLoss:0.0891 | SPLoss:5.2849 | CLSLoss:0.6749 | top1:96.7733 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6849 | MainLoss:0.1748 | SPLoss:5.0332 | CLSLoss:0.6738 | top1:93.6923 | AUROC:0.9829\n",
      "Test | 129/16 | Loss:2.4729 | MainLoss:1.9628 | SPLoss:5.0332 | CLSLoss:0.6738 | top1:54.0000 | AUROC:0.6862\n",
      "\n",
      "Epoch: [129 | 1000] LR: 0.038664\n",
      "Train | 16/16 | Loss:0.6103 | MainLoss:0.1193 | SPLoss:4.8422 | CLSLoss:0.6735 | top1:95.7600 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6389 | MainLoss:0.1605 | SPLoss:4.7178 | CLSLoss:0.6614 | top1:93.7949 | AUROC:0.9844\n",
      "Test | 129/16 | Loss:2.1387 | MainLoss:1.6603 | SPLoss:4.7178 | CLSLoss:0.6614 | top1:55.2835 | AUROC:0.7212\n",
      "\n",
      "Epoch: [130 | 1000] LR: 0.038641\n",
      "Train | 16/16 | Loss:0.5509 | MainLoss:0.0907 | SPLoss:4.5353 | CLSLoss:0.6664 | top1:96.8800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6181 | MainLoss:0.1760 | SPLoss:4.3541 | CLSLoss:0.6690 | top1:93.3462 | AUROC:0.9834\n",
      "Test | 129/16 | Loss:2.2175 | MainLoss:1.7753 | SPLoss:4.3541 | CLSLoss:0.6690 | top1:56.2555 | AUROC:0.7593\n",
      "\n",
      "Epoch: [131 | 1000] LR: 0.038619\n",
      "Train | 16/16 | Loss:0.5253 | MainLoss:0.0995 | SPLoss:4.1912 | CLSLoss:0.6678 | top1:96.5067 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.5760 | MainLoss:0.1681 | SPLoss:4.0125 | CLSLoss:0.6688 | top1:93.9359 | AUROC:0.9841\n",
      "Test | 129/16 | Loss:2.4127 | MainLoss:2.0047 | SPLoss:4.0125 | CLSLoss:0.6688 | top1:53.7041 | AUROC:0.7058\n",
      "\n",
      "Epoch: [132 | 1000] LR: 0.038596\n",
      "Train | 16/16 | Loss:0.5417 | MainLoss:0.1030 | SPLoss:4.3199 | CLSLoss:0.6679 | top1:96.2933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6939 | MainLoss:0.2030 | SPLoss:4.8422 | CLSLoss:0.6666 | top1:92.2821 | AUROC:0.9821\n",
      "Test | 129/16 | Loss:2.0874 | MainLoss:1.5965 | SPLoss:4.8422 | CLSLoss:0.6666 | top1:56.8318 | AUROC:0.7109\n",
      "\n",
      "Epoch: [133 | 1000] LR: 0.038572\n",
      "Train | 16/16 | Loss:0.5671 | MainLoss:0.0958 | SPLoss:4.6466 | CLSLoss:0.6680 | top1:96.7733 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6277 | MainLoss:0.1759 | SPLoss:4.4514 | CLSLoss:0.6695 | top1:93.3333 | AUROC:0.9839\n",
      "Test | 129/16 | Loss:2.3562 | MainLoss:1.9044 | SPLoss:4.4514 | CLSLoss:0.6695 | top1:54.4704 | AUROC:0.6971\n",
      "\n",
      "Epoch: [134 | 1000] LR: 0.038549\n",
      "Train | 16/16 | Loss:0.5883 | MainLoss:0.1096 | SPLoss:4.7201 | CLSLoss:0.6673 | top1:96.1067 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.8821 | MainLoss:0.2146 | SPLoss:6.6087 | CLSLoss:0.6649 | top1:91.6282 | AUROC:0.9818\n",
      "Test | 129/16 | Loss:2.2760 | MainLoss:1.6085 | SPLoss:6.6087 | CLSLoss:0.6649 | top1:57.5265 | AUROC:0.7587\n",
      "\n",
      "Epoch: [135 | 1000] LR: 0.038525\n",
      "Train | 16/16 | Loss:0.8056 | MainLoss:0.1425 | SPLoss:6.5653 | CLSLoss:0.6591 | top1:94.3733 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.8088 | MainLoss:0.1703 | SPLoss:6.3194 | CLSLoss:0.6574 | top1:93.3974 | AUROC:0.9830\n",
      "Test | 129/16 | Loss:2.4382 | MainLoss:1.7997 | SPLoss:6.3194 | CLSLoss:0.6574 | top1:53.8100 | AUROC:0.7036\n",
      "\n",
      "Epoch: [136 | 1000] LR: 0.038502\n",
      "Train | 16/16 | Loss:0.7129 | MainLoss:0.1013 | SPLoss:6.0502 | CLSLoss:0.6610 | top1:96.4000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.7633 | MainLoss:0.1790 | SPLoss:5.7771 | CLSLoss:0.6609 | top1:93.2051 | AUROC:0.9831\n",
      "Test | 129/16 | Loss:2.2597 | MainLoss:1.6753 | SPLoss:5.7771 | CLSLoss:0.6610 | top1:55.4268 | AUROC:0.7156\n",
      "\n",
      "Epoch: [137 | 1000] LR: 0.038478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 16/16 | Loss:0.6441 | MainLoss:0.0849 | SPLoss:5.5252 | CLSLoss:0.6645 | top1:96.9333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.7128 | MainLoss:0.1796 | SPLoss:5.2652 | CLSLoss:0.6677 | top1:93.4744 | AUROC:0.9831\n",
      "Test | 129/16 | Loss:2.3459 | MainLoss:1.8127 | SPLoss:5.2652 | CLSLoss:0.6677 | top1:55.3645 | AUROC:0.7337\n",
      "\n",
      "Epoch: [138 | 1000] LR: 0.038453\n",
      "Train | 16/16 | Loss:0.6435 | MainLoss:0.1304 | SPLoss:5.0644 | CLSLoss:0.6626 | top1:95.1467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6670 | MainLoss:0.1741 | SPLoss:4.8636 | CLSLoss:0.6569 | top1:93.4103 | AUROC:0.9832\n",
      "Test | 129/16 | Loss:2.1860 | MainLoss:1.6931 | SPLoss:4.8636 | CLSLoss:0.6569 | top1:54.7726 | AUROC:0.6914\n",
      "\n",
      "Epoch: [139 | 1000] LR: 0.038429\n",
      "Train | 16/16 | Loss:0.5694 | MainLoss:0.0964 | SPLoss:4.6642 | CLSLoss:0.6604 | top1:96.6933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6297 | MainLoss:0.1782 | SPLoss:4.4490 | CLSLoss:0.6620 | top1:93.3974 | AUROC:0.9832\n",
      "Test | 129/16 | Loss:2.1689 | MainLoss:1.7173 | SPLoss:4.4490 | CLSLoss:0.6620 | top1:55.7134 | AUROC:0.7350\n",
      "\n",
      "Epoch: [140 | 1000] LR: 0.038405\n",
      "Train | 16/16 | Loss:0.5410 | MainLoss:0.1036 | SPLoss:4.3079 | CLSLoss:0.6599 | top1:96.1067 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.5894 | MainLoss:0.1694 | SPLoss:4.1339 | CLSLoss:0.6619 | top1:93.7436 | AUROC:0.9835\n",
      "Test | 129/16 | Loss:2.2057 | MainLoss:1.7857 | SPLoss:4.1339 | CLSLoss:0.6619 | top1:55.2368 | AUROC:0.7391\n",
      "\n",
      "Epoch: [141 | 1000] LR: 0.038380\n",
      "Train | 16/16 | Loss:0.4958 | MainLoss:0.0908 | SPLoss:3.9839 | CLSLoss:0.6642 | top1:96.5600 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.5890 | MainLoss:0.1992 | SPLoss:3.8310 | CLSLoss:0.6637 | top1:92.7308 | AUROC:0.9831\n",
      "Test | 129/16 | Loss:1.9590 | MainLoss:1.5693 | SPLoss:3.8310 | CLSLoss:0.6637 | top1:57.7601 | AUROC:0.7692\n",
      "\n",
      "Epoch: [142 | 1000] LR: 0.038355\n",
      "Train | 16/16 | Loss:0.4863 | MainLoss:0.1086 | SPLoss:3.7108 | CLSLoss:0.6638 | top1:96.1067 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.5399 | MainLoss:0.1707 | SPLoss:3.6261 | CLSLoss:0.6617 | top1:93.3590 | AUROC:0.9833\n",
      "Test | 129/16 | Loss:2.2520 | MainLoss:1.8828 | SPLoss:3.6261 | CLSLoss:0.6617 | top1:53.9875 | AUROC:0.7309\n",
      "\n",
      "Epoch: [143 | 1000] LR: 0.038330\n",
      "Train | 16/16 | Loss:0.4612 | MainLoss:0.1010 | SPLoss:3.5352 | CLSLoss:0.6631 | top1:96.2133 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.5334 | MainLoss:0.1804 | SPLoss:3.4641 | CLSLoss:0.6616 | top1:93.2949 | AUROC:0.9828\n",
      "Test | 129/16 | Loss:2.0149 | MainLoss:1.6618 | SPLoss:3.4641 | CLSLoss:0.6616 | top1:56.0997 | AUROC:0.7547\n",
      "\n",
      "Epoch: [144 | 1000] LR: 0.038305\n",
      "Train | 16/16 | Loss:0.4314 | MainLoss:0.0876 | SPLoss:3.3719 | CLSLoss:0.6651 | top1:96.8800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.5159 | MainLoss:0.1802 | SPLoss:3.2908 | CLSLoss:0.6663 | top1:93.3846 | AUROC:0.9837\n",
      "Test | 129/16 | Loss:2.0857 | MainLoss:1.7500 | SPLoss:3.2908 | CLSLoss:0.6663 | top1:55.8474 | AUROC:0.7261\n",
      "\n",
      "Epoch: [145 | 1000] LR: 0.038279\n",
      "Train | 16/16 | Loss:0.4152 | MainLoss:0.0906 | SPLoss:3.1791 | CLSLoss:0.6670 | top1:96.6933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.4930 | MainLoss:0.1802 | SPLoss:3.0613 | CLSLoss:0.6678 | top1:93.1667 | AUROC:0.9830\n",
      "Test | 129/16 | Loss:2.2215 | MainLoss:1.9086 | SPLoss:3.0613 | CLSLoss:0.6678 | top1:54.9221 | AUROC:0.7333\n",
      "\n",
      "Epoch: [146 | 1000] LR: 0.038254\n",
      "Train | 16/16 | Loss:0.3915 | MainLoss:0.0858 | SPLoss:2.9903 | CLSLoss:0.6702 | top1:96.8267 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.4813 | MainLoss:0.1833 | SPLoss:2.9133 | CLSLoss:0.6688 | top1:93.2436 | AUROC:0.9813\n",
      "Test | 129/16 | Loss:2.1894 | MainLoss:1.8914 | SPLoss:2.9133 | CLSLoss:0.6688 | top1:54.7882 | AUROC:0.7027\n",
      "\n",
      "Epoch: [147 | 1000] LR: 0.038228\n",
      "Train | 16/16 | Loss:0.3855 | MainLoss:0.0951 | SPLoss:2.8368 | CLSLoss:0.6685 | top1:96.4800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.4640 | MainLoss:0.1826 | SPLoss:2.7466 | CLSLoss:0.6692 | top1:93.1923 | AUROC:0.9822\n",
      "Test | 129/16 | Loss:2.2571 | MainLoss:1.9758 | SPLoss:2.7466 | CLSLoss:0.6692 | top1:54.1246 | AUROC:0.7031\n",
      "\n",
      "Epoch: [148 | 1000] LR: 0.038202\n",
      "Train | 16/16 | Loss:0.4677 | MainLoss:0.1458 | SPLoss:3.1525 | CLSLoss:0.6640 | top1:94.2133 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.5166 | MainLoss:0.1733 | SPLoss:3.3676 | CLSLoss:0.6519 | top1:93.2051 | AUROC:0.9817\n",
      "Test | 129/16 | Loss:1.9401 | MainLoss:1.5968 | SPLoss:3.3676 | CLSLoss:0.6519 | top1:54.4455 | AUROC:0.6934\n",
      "\n",
      "Epoch: [149 | 1000] LR: 0.038176\n",
      "Train | 16/16 | Loss:0.4410 | MainLoss:0.1077 | SPLoss:3.2678 | CLSLoss:0.6563 | top1:95.9467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.5262 | MainLoss:0.2053 | SPLoss:3.1430 | CLSLoss:0.6598 | top1:92.3974 | AUROC:0.9831\n",
      "Test | 129/16 | Loss:1.8577 | MainLoss:1.5368 | SPLoss:3.1430 | CLSLoss:0.6598 | top1:57.7850 | AUROC:0.7357\n",
      "\n",
      "Epoch: [150 | 1000] LR: 0.038150\n",
      "Train | 16/16 | Loss:0.4181 | MainLoss:0.1029 | SPLoss:3.0862 | CLSLoss:0.6614 | top1:96.2133 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.4760 | MainLoss:0.1702 | SPLoss:2.9912 | CLSLoss:0.6608 | top1:93.6026 | AUROC:0.9835\n",
      "Test | 129/16 | Loss:2.2014 | MainLoss:1.8957 | SPLoss:2.9912 | CLSLoss:0.6608 | top1:53.7414 | AUROC:0.7081\n",
      "\n",
      "Epoch: [151 | 1000] LR: 0.038123\n",
      "Train | 16/16 | Loss:0.4050 | MainLoss:0.1057 | SPLoss:2.9272 | CLSLoss:0.6623 | top1:96.0267 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.4654 | MainLoss:0.1750 | SPLoss:2.8376 | CLSLoss:0.6636 | top1:93.6923 | AUROC:0.9837\n",
      "Test | 129/16 | Loss:2.3399 | MainLoss:2.0495 | SPLoss:2.8376 | CLSLoss:0.6636 | top1:53.1028 | AUROC:0.7307\n",
      "\n",
      "Epoch: [152 | 1000] LR: 0.038097\n",
      "Train | 16/16 | Loss:0.3693 | MainLoss:0.0861 | SPLoss:2.7651 | CLSLoss:0.6645 | top1:97.0933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.4400 | MainLoss:0.1655 | SPLoss:2.6780 | CLSLoss:0.6664 | top1:94.1795 | AUROC:0.9847\n",
      "Test | 129/16 | Loss:2.1689 | MainLoss:1.8944 | SPLoss:2.6780 | CLSLoss:0.6664 | top1:54.8723 | AUROC:0.7442\n",
      "\n",
      "Epoch: [153 | 1000] LR: 0.038070\n",
      "Train | 16/16 | Loss:0.3447 | MainLoss:0.0769 | SPLoss:2.6109 | CLSLoss:0.6688 | top1:97.1467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.4498 | MainLoss:0.1901 | SPLoss:2.5303 | CLSLoss:0.6703 | top1:93.4744 | AUROC:0.9835\n",
      "Test | 129/16 | Loss:2.4866 | MainLoss:2.2268 | SPLoss:2.5303 | CLSLoss:0.6703 | top1:52.9502 | AUROC:0.7246\n",
      "\n",
      "Epoch: [154 | 1000] LR: 0.038043\n",
      "Train | 16/16 | Loss:0.3500 | MainLoss:0.0951 | SPLoss:2.4827 | CLSLoss:0.6667 | top1:96.7467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.4289 | MainLoss:0.1790 | SPLoss:2.4330 | CLSLoss:0.6673 | top1:93.7308 | AUROC:0.9827\n",
      "Test | 129/16 | Loss:2.2339 | MainLoss:1.9839 | SPLoss:2.4330 | CLSLoss:0.6673 | top1:53.9875 | AUROC:0.7206\n",
      "\n",
      "Epoch: [155 | 1000] LR: 0.038015\n",
      "Train | 16/16 | Loss:0.3197 | MainLoss:0.0760 | SPLoss:2.3696 | CLSLoss:0.6696 | top1:97.4133 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.4227 | MainLoss:0.1849 | SPLoss:2.3105 | CLSLoss:0.6704 | top1:93.7051 | AUROC:0.9826\n",
      "Test | 129/16 | Loss:2.2005 | MainLoss:1.9628 | SPLoss:2.3105 | CLSLoss:0.6704 | top1:54.9813 | AUROC:0.7361\n",
      "\n",
      "Epoch: [156 | 1000] LR: 0.037988\n",
      "Train | 16/16 | Loss:0.3299 | MainLoss:0.0941 | SPLoss:2.2912 | CLSLoss:0.6685 | top1:96.6400 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.4103 | MainLoss:0.1796 | SPLoss:2.2402 | CLSLoss:0.6684 | top1:93.4359 | AUROC:0.9826\n",
      "Test | 129/16 | Loss:2.2769 | MainLoss:2.0462 | SPLoss:2.2402 | CLSLoss:0.6684 | top1:53.7041 | AUROC:0.7326\n",
      "\n",
      "Epoch: [157 | 1000] LR: 0.037961\n",
      "Train | 16/16 | Loss:0.3236 | MainLoss:0.0946 | SPLoss:2.2229 | CLSLoss:0.6695 | top1:96.6933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3891 | MainLoss:0.1624 | SPLoss:2.2013 | CLSLoss:0.6646 | top1:94.0256 | AUROC:0.9846\n",
      "Test | 129/16 | Loss:2.0535 | MainLoss:1.8267 | SPLoss:2.2013 | CLSLoss:0.6646 | top1:54.6262 | AUROC:0.7185\n",
      "\n",
      "Epoch: [158 | 1000] LR: 0.037933\n",
      "Train | 16/16 | Loss:0.3041 | MainLoss:0.0820 | SPLoss:2.1548 | CLSLoss:0.6678 | top1:96.9867 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3816 | MainLoss:0.1640 | SPLoss:2.1093 | CLSLoss:0.6706 | top1:94.0641 | AUROC:0.9852\n",
      "Test | 129/16 | Loss:2.1065 | MainLoss:1.8889 | SPLoss:2.1093 | CLSLoss:0.6706 | top1:55.5545 | AUROC:0.7535\n",
      "\n",
      "Epoch: [159 | 1000] LR: 0.037905\n",
      "Train | 16/16 | Loss:0.3022 | MainLoss:0.0865 | SPLoss:2.0894 | CLSLoss:0.6706 | top1:96.6400 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3815 | MainLoss:0.1678 | SPLoss:2.0699 | CLSLoss:0.6709 | top1:93.7821 | AUROC:0.9848\n",
      "Test | 129/16 | Loss:2.1225 | MainLoss:1.9088 | SPLoss:2.0699 | CLSLoss:0.6709 | top1:55.1589 | AUROC:0.7430\n",
      "\n",
      "Epoch: [160 | 1000] LR: 0.037877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 16/16 | Loss:0.3047 | MainLoss:0.0945 | SPLoss:2.0343 | CLSLoss:0.6707 | top1:96.9600 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3883 | MainLoss:0.1826 | SPLoss:1.9897 | CLSLoss:0.6681 | top1:93.0897 | AUROC:0.9844\n",
      "Test | 129/16 | Loss:1.8926 | MainLoss:1.6870 | SPLoss:1.9897 | CLSLoss:0.6680 | top1:57.2523 | AUROC:0.7628\n",
      "\n",
      "Epoch: [161 | 1000] LR: 0.037849\n",
      "Train | 16/16 | Loss:0.3145 | MainLoss:0.1098 | SPLoss:1.9799 | CLSLoss:0.6678 | top1:95.8133 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3720 | MainLoss:0.1637 | SPLoss:2.0163 | CLSLoss:0.6612 | top1:93.8462 | AUROC:0.9845\n",
      "Test | 129/16 | Loss:1.9982 | MainLoss:1.7900 | SPLoss:2.0163 | CLSLoss:0.6612 | top1:54.9564 | AUROC:0.7283\n",
      "\n",
      "Epoch: [162 | 1000] LR: 0.037820\n",
      "Train | 16/16 | Loss:0.2901 | MainLoss:0.0856 | SPLoss:1.9782 | CLSLoss:0.6639 | top1:96.9867 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3821 | MainLoss:0.1825 | SPLoss:1.9290 | CLSLoss:0.6670 | top1:93.4487 | AUROC:0.9857\n",
      "Test | 129/16 | Loss:1.8892 | MainLoss:1.6896 | SPLoss:1.9290 | CLSLoss:0.6670 | top1:57.7321 | AUROC:0.7674\n",
      "\n",
      "Epoch: [163 | 1000] LR: 0.037792\n",
      "Train | 16/16 | Loss:0.3150 | MainLoss:0.1097 | SPLoss:1.9871 | CLSLoss:0.6646 | top1:96.2133 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.4282 | MainLoss:0.1651 | SPLoss:2.5656 | CLSLoss:0.6580 | top1:93.7949 | AUROC:0.9838\n",
      "Test | 129/16 | Loss:2.0772 | MainLoss:1.8141 | SPLoss:2.5656 | CLSLoss:0.6580 | top1:54.5826 | AUROC:0.7312\n",
      "\n",
      "Epoch: [164 | 1000] LR: 0.037763\n",
      "Train | 16/16 | Loss:0.5042 | MainLoss:0.1196 | SPLoss:3.7797 | CLSLoss:0.6599 | top1:95.7867 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:1.4980 | MainLoss:0.1811 | SPLoss:13.1031 | CLSLoss:0.6509 | top1:92.8077 | AUROC:0.9799\n",
      "Test | 129/16 | Loss:3.0581 | MainLoss:1.7413 | SPLoss:13.1031 | CLSLoss:0.6509 | top1:53.7757 | AUROC:0.6809\n",
      "\n",
      "Epoch: [165 | 1000] LR: 0.037734\n",
      "Train | 16/16 | Loss:1.4303 | MainLoss:0.1117 | SPLoss:13.1207 | CLSLoss:0.6544 | top1:95.6800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:1.4271 | MainLoss:0.1781 | SPLoss:12.4248 | CLSLoss:0.6582 | top1:93.0000 | AUROC:0.9827\n",
      "Test | 129/16 | Loss:3.1097 | MainLoss:1.8607 | SPLoss:12.4248 | CLSLoss:0.6582 | top1:54.4268 | AUROC:0.6844\n",
      "\n",
      "Epoch: [166 | 1000] LR: 0.037705\n",
      "Train | 16/16 | Loss:1.2976 | MainLoss:0.1060 | SPLoss:11.8505 | CLSLoss:0.6579 | top1:95.8667 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:1.3078 | MainLoss:0.1763 | SPLoss:11.2489 | CLSLoss:0.6602 | top1:93.4615 | AUROC:0.9834\n",
      "Test | 129/16 | Loss:2.9874 | MainLoss:1.8559 | SPLoss:11.2489 | CLSLoss:0.6602 | top1:54.9626 | AUROC:0.7192\n",
      "\n",
      "Epoch: [167 | 1000] LR: 0.037675\n",
      "Train | 16/16 | Loss:1.4250 | MainLoss:0.2886 | SPLoss:11.2995 | CLSLoss:0.6400 | top1:90.5067 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:1.4619 | MainLoss:0.2587 | SPLoss:11.9712 | CLSLoss:0.6030 | top1:89.0128 | AUROC:0.9638\n",
      "Test | 129/16 | Loss:2.1027 | MainLoss:0.8996 | SPLoss:11.9711 | CLSLoss:0.6030 | top1:60.7445 | AUROC:0.7439\n",
      "\n",
      "Epoch: [168 | 1000] LR: 0.037646\n",
      "Train | 16/16 | Loss:1.3219 | MainLoss:0.1766 | SPLoss:11.3912 | CLSLoss:0.6168 | top1:93.2533 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:1.3033 | MainLoss:0.2211 | SPLoss:10.7592 | CLSLoss:0.6258 | top1:91.1795 | AUROC:0.9778\n",
      "Test | 129/16 | Loss:2.2380 | MainLoss:1.1558 | SPLoss:10.7592 | CLSLoss:0.6258 | top1:61.8505 | AUROC:0.8009\n",
      "\n",
      "Epoch: [169 | 1000] LR: 0.037616\n",
      "Train | 16/16 | Loss:1.1604 | MainLoss:0.1301 | SPLoss:10.2399 | CLSLoss:0.6302 | top1:94.9067 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:1.1500 | MainLoss:0.1750 | SPLoss:9.6860 | CLSLoss:0.6327 | top1:93.2949 | AUROC:0.9814\n",
      "Test | 129/16 | Loss:2.4703 | MainLoss:1.4954 | SPLoss:9.6860 | CLSLoss:0.6327 | top1:57.4891 | AUROC:0.7758\n",
      "\n",
      "Epoch: [170 | 1000] LR: 0.037586\n",
      "Train | 16/16 | Loss:1.0500 | MainLoss:0.1194 | SPLoss:9.2424 | CLSLoss:0.6351 | top1:95.5467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:1.0715 | MainLoss:0.1892 | SPLoss:8.7595 | CLSLoss:0.6400 | top1:92.7692 | AUROC:0.9828\n",
      "Test | 129/16 | Loss:2.3374 | MainLoss:1.4550 | SPLoss:8.7594 | CLSLoss:0.6400 | top1:59.0997 | AUROC:0.7785\n",
      "\n",
      "Epoch: [171 | 1000] LR: 0.037556\n",
      "Train | 16/16 | Loss:2.9591 | MainLoss:0.1325 | SPLoss:28.2019 | CLSLoss:0.6393 | top1:94.9600 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:4.9614 | MainLoss:0.2285 | SPLoss:47.2652 | CLSLoss:0.6372 | top1:91.4103 | AUROC:0.9729\n",
      "Test | 129/16 | Loss:5.8132 | MainLoss:1.0803 | SPLoss:47.2652 | CLSLoss:0.6372 | top1:65.0717 | AUROC:0.8551\n",
      "\n",
      "Epoch: [172 | 1000] LR: 0.037526\n",
      "Train | 16/16 | Loss:4.6645 | MainLoss:0.1578 | SPLoss:45.0037 | CLSLoss:0.6342 | top1:93.8667 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:4.4573 | MainLoss:0.2141 | SPLoss:42.3688 | CLSLoss:0.6343 | top1:91.8974 | AUROC:0.9778\n",
      "Test | 129/16 | Loss:5.5112 | MainLoss:1.2680 | SPLoss:42.3689 | CLSLoss:0.6343 | top1:61.2399 | AUROC:0.7998\n",
      "\n",
      "Epoch: [173 | 1000] LR: 0.037496\n",
      "Train | 16/16 | Loss:4.1597 | MainLoss:0.1424 | SPLoss:40.1098 | CLSLoss:0.6336 | top1:94.4000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:3.9502 | MainLoss:0.1821 | SPLoss:37.6175 | CLSLoss:0.6328 | top1:92.9744 | AUROC:0.9806\n",
      "Test | 129/16 | Loss:5.2914 | MainLoss:1.5234 | SPLoss:37.6175 | CLSLoss:0.6328 | top1:57.1402 | AUROC:0.7825\n",
      "\n",
      "Epoch: [174 | 1000] LR: 0.037465\n",
      "Train | 16/16 | Loss:3.6910 | MainLoss:0.1240 | SPLoss:35.6070 | CLSLoss:0.6319 | top1:95.1733 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:3.5855 | MainLoss:0.2400 | SPLoss:33.3913 | CLSLoss:0.6332 | top1:91.0897 | AUROC:0.9812\n",
      "Test | 129/16 | Loss:4.4700 | MainLoss:1.1246 | SPLoss:33.3913 | CLSLoss:0.6332 | top1:63.7882 | AUROC:0.8093\n",
      "\n",
      "Epoch: [175 | 1000] LR: 0.037435\n",
      "Train | 16/16 | Loss:3.2843 | MainLoss:0.1158 | SPLoss:31.6221 | CLSLoss:0.6357 | top1:95.8133 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:3.1423 | MainLoss:0.1670 | SPLoss:29.6896 | CLSLoss:0.6346 | top1:93.6154 | AUROC:0.9836\n",
      "Test | 129/16 | Loss:4.4356 | MainLoss:1.4603 | SPLoss:29.6896 | CLSLoss:0.6346 | top1:58.8816 | AUROC:0.8147\n",
      "\n",
      "Epoch: [176 | 1000] LR: 0.037404\n",
      "Train | 16/16 | Loss:2.9314 | MainLoss:0.1116 | SPLoss:28.1345 | CLSLoss:0.6360 | top1:95.9467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:2.8319 | MainLoss:0.1752 | SPLoss:26.5039 | CLSLoss:0.6346 | top1:93.3462 | AUROC:0.9831\n",
      "Test | 129/16 | Loss:4.0892 | MainLoss:1.4325 | SPLoss:26.5039 | CLSLoss:0.6346 | top1:59.4860 | AUROC:0.8104\n",
      "\n",
      "Epoch: [177 | 1000] LR: 0.037373\n",
      "Train | 16/16 | Loss:2.6140 | MainLoss:0.0964 | SPLoss:25.1127 | CLSLoss:0.6384 | top1:96.4800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:2.5511 | MainLoss:0.1856 | SPLoss:23.5916 | CLSLoss:0.6391 | top1:93.1026 | AUROC:0.9822\n",
      "Test | 129/16 | Loss:3.8727 | MainLoss:1.5071 | SPLoss:23.5915 | CLSLoss:0.6391 | top1:59.3022 | AUROC:0.7932\n",
      "\n",
      "Epoch: [178 | 1000] LR: 0.037341\n",
      "Train | 16/16 | Loss:2.7328 | MainLoss:0.0888 | SPLoss:26.3753 | CLSLoss:0.6414 | top1:96.6133 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:3.1646 | MainLoss:0.1958 | SPLoss:29.6238 | CLSLoss:0.6418 | top1:92.8846 | AUROC:0.9817\n",
      "Test | 129/16 | Loss:4.4241 | MainLoss:1.4553 | SPLoss:29.6238 | CLSLoss:0.6418 | top1:60.7788 | AUROC:0.8585\n",
      "\n",
      "Epoch: [179 | 1000] LR: 0.037310\n",
      "Train | 16/16 | Loss:2.9225 | MainLoss:0.1088 | SPLoss:28.0729 | CLSLoss:0.6412 | top1:95.9200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:2.8134 | MainLoss:0.1700 | SPLoss:26.3701 | CLSLoss:0.6394 | top1:93.5513 | AUROC:0.9833\n",
      "Test | 129/16 | Loss:4.2153 | MainLoss:1.5718 | SPLoss:26.3702 | CLSLoss:0.6394 | top1:58.0561 | AUROC:0.8121\n",
      "\n",
      "Epoch: [180 | 1000] LR: 0.037278\n",
      "Train | 16/16 | Loss:2.6018 | MainLoss:0.0961 | SPLoss:24.9929 | CLSLoss:0.6407 | top1:96.5333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:2.5339 | MainLoss:0.1791 | SPLoss:23.4836 | CLSLoss:0.6406 | top1:93.1538 | AUROC:0.9836\n",
      "Test | 129/16 | Loss:3.8532 | MainLoss:1.4984 | SPLoss:23.4835 | CLSLoss:0.6406 | top1:59.5171 | AUROC:0.8103\n",
      "\n",
      "Epoch: [181 | 1000] LR: 0.037247\n",
      "Train | 16/16 | Loss:2.3123 | MainLoss:0.0816 | SPLoss:22.2432 | CLSLoss:0.6447 | top1:96.8800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:2.3073 | MainLoss:0.2109 | SPLoss:20.8989 | CLSLoss:0.6433 | top1:92.2308 | AUROC:0.9825\n",
      "Test | 129/16 | Loss:3.3660 | MainLoss:1.2697 | SPLoss:20.8989 | CLSLoss:0.6433 | top1:63.7975 | AUROC:0.8613\n",
      "\n",
      "Epoch: [182 | 1000] LR: 0.037215\n",
      "Train | 16/16 | Loss:2.0866 | MainLoss:0.0965 | SPLoss:19.8368 | CLSLoss:0.6437 | top1:96.5333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:2.0672 | MainLoss:0.1930 | SPLoss:18.6776 | CLSLoss:0.6434 | top1:92.9359 | AUROC:0.9818\n",
      "Test | 129/16 | Loss:3.4203 | MainLoss:1.5461 | SPLoss:18.6775 | CLSLoss:0.6434 | top1:59.6822 | AUROC:0.8066\n",
      "\n",
      "Epoch: [183 | 1000] LR: 0.037183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 16/16 | Loss:1.8576 | MainLoss:0.0790 | SPLoss:17.7212 | CLSLoss:0.6457 | top1:97.2000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:1.8634 | MainLoss:0.1887 | SPLoss:16.6820 | CLSLoss:0.6497 | top1:93.1795 | AUROC:0.9816\n",
      "Test | 129/16 | Loss:3.3751 | MainLoss:1.7004 | SPLoss:16.6820 | CLSLoss:0.6497 | top1:58.6386 | AUROC:0.8277\n",
      "\n",
      "Epoch: [184 | 1000] LR: 0.037151\n",
      "Train | 16/16 | Loss:1.7046 | MainLoss:0.1131 | SPLoss:15.8503 | CLSLoss:0.6466 | top1:95.3067 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:1.6813 | MainLoss:0.1791 | SPLoss:14.9574 | CLSLoss:0.6454 | top1:93.2949 | AUROC:0.9816\n",
      "Test | 129/16 | Loss:3.0606 | MainLoss:1.5584 | SPLoss:14.9574 | CLSLoss:0.6454 | top1:59.0000 | AUROC:0.8348\n",
      "\n",
      "Epoch: [185 | 1000] LR: 0.037118\n",
      "Train | 16/16 | Loss:1.5207 | MainLoss:0.0917 | SPLoss:14.2253 | CLSLoss:0.6490 | top1:96.9600 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:1.5393 | MainLoss:0.1897 | SPLoss:13.4315 | CLSLoss:0.6469 | top1:93.0256 | AUROC:0.9810\n",
      "Test | 129/16 | Loss:2.8569 | MainLoss:1.5073 | SPLoss:13.4315 | CLSLoss:0.6469 | top1:60.1495 | AUROC:0.8233\n",
      "\n",
      "Epoch: [186 | 1000] LR: 0.037086\n",
      "Train | 16/16 | Loss:1.3733 | MainLoss:0.0916 | SPLoss:12.7527 | CLSLoss:0.6467 | top1:96.9067 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:1.4034 | MainLoss:0.1945 | SPLoss:12.0242 | CLSLoss:0.6447 | top1:92.7308 | AUROC:0.9816\n",
      "Test | 129/16 | Loss:2.6535 | MainLoss:1.4446 | SPLoss:12.0242 | CLSLoss:0.6447 | top1:60.8442 | AUROC:0.8230\n",
      "\n",
      "Epoch: [187 | 1000] LR: 0.037053\n",
      "Train | 16/16 | Loss:1.2480 | MainLoss:0.0946 | SPLoss:11.4702 | CLSLoss:0.6460 | top1:96.5867 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:1.2739 | MainLoss:0.1809 | SPLoss:10.8654 | CLSLoss:0.6449 | top1:93.3846 | AUROC:0.9817\n",
      "Test | 129/16 | Loss:2.7565 | MainLoss:1.6635 | SPLoss:10.8654 | CLSLoss:0.6449 | top1:57.8754 | AUROC:0.8082\n",
      "\n",
      "Epoch: [188 | 1000] LR: 0.037020\n",
      "Train | 16/16 | Loss:1.1252 | MainLoss:0.0831 | SPLoss:10.3562 | CLSLoss:0.6472 | top1:96.9867 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:1.1909 | MainLoss:0.2037 | SPLoss:9.8073 | CLSLoss:0.6485 | top1:93.0256 | AUROC:0.9814\n",
      "Test | 129/16 | Loss:2.5076 | MainLoss:1.5203 | SPLoss:9.8073 | CLSLoss:0.6485 | top1:60.6417 | AUROC:0.8225\n",
      "\n",
      "Epoch: [189 | 1000] LR: 0.036987\n",
      "Train | 16/16 | Loss:1.0264 | MainLoss:0.0863 | SPLoss:9.3356 | CLSLoss:0.6481 | top1:97.0133 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:1.0853 | MainLoss:0.1956 | SPLoss:8.8328 | CLSLoss:0.6449 | top1:93.2051 | AUROC:0.9813\n",
      "Test | 129/16 | Loss:2.4043 | MainLoss:1.5145 | SPLoss:8.8328 | CLSLoss:0.6449 | top1:60.6012 | AUROC:0.8479\n",
      "\n",
      "Epoch: [190 | 1000] LR: 0.036954\n",
      "Train | 16/16 | Loss:0.9296 | MainLoss:0.0784 | SPLoss:8.4475 | CLSLoss:0.6456 | top1:97.2000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.9951 | MainLoss:0.1883 | SPLoss:8.0036 | CLSLoss:0.6471 | top1:93.5513 | AUROC:0.9818\n",
      "Test | 129/16 | Loss:2.4766 | MainLoss:1.6697 | SPLoss:8.0036 | CLSLoss:0.6471 | top1:58.3240 | AUROC:0.8184\n",
      "\n",
      "Epoch: [191 | 1000] LR: 0.036920\n",
      "Train | 16/16 | Loss:0.8592 | MainLoss:0.0871 | SPLoss:7.6557 | CLSLoss:0.6473 | top1:96.9600 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.9163 | MainLoss:0.1831 | SPLoss:7.2670 | CLSLoss:0.6487 | top1:93.6410 | AUROC:0.9822\n",
      "Test | 129/16 | Loss:2.4691 | MainLoss:1.7359 | SPLoss:7.2670 | CLSLoss:0.6487 | top1:57.7414 | AUROC:0.8166\n",
      "\n",
      "Epoch: [192 | 1000] LR: 0.036887\n",
      "Train | 16/16 | Loss:0.7845 | MainLoss:0.0822 | SPLoss:6.9574 | CLSLoss:0.6492 | top1:97.0133 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.8662 | MainLoss:0.1983 | SPLoss:6.6145 | CLSLoss:0.6478 | top1:93.0513 | AUROC:0.9812\n",
      "Test | 129/16 | Loss:2.2273 | MainLoss:1.5594 | SPLoss:6.6145 | CLSLoss:0.6478 | top1:59.9128 | AUROC:0.8386\n",
      "\n",
      "Epoch: [193 | 1000] LR: 0.036853\n",
      "Train | 16/16 | Loss:0.7507 | MainLoss:0.1077 | SPLoss:6.3653 | CLSLoss:0.6465 | top1:96.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.7987 | MainLoss:0.1837 | SPLoss:6.0854 | CLSLoss:0.6437 | top1:93.2436 | AUROC:0.9817\n",
      "Test | 129/16 | Loss:2.1422 | MainLoss:1.5272 | SPLoss:6.0854 | CLSLoss:0.6437 | top1:58.3645 | AUROC:0.8223\n",
      "\n",
      "Epoch: [194 | 1000] LR: 0.036819\n",
      "Train | 16/16 | Loss:0.6807 | MainLoss:0.0915 | SPLoss:5.8277 | CLSLoss:0.6458 | top1:96.7200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.7641 | MainLoss:0.2014 | SPLoss:5.5619 | CLSLoss:0.6469 | top1:92.8205 | AUROC:0.9810\n",
      "Test | 129/16 | Loss:2.1011 | MainLoss:1.5384 | SPLoss:5.5619 | CLSLoss:0.6469 | top1:60.0000 | AUROC:0.8424\n",
      "\n",
      "Epoch: [195 | 1000] LR: 0.036785\n",
      "Train | 16/16 | Loss:0.6347 | MainLoss:0.0945 | SPLoss:5.3381 | CLSLoss:0.6444 | top1:96.6667 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.7115 | MainLoss:0.1954 | SPLoss:5.0970 | CLSLoss:0.6445 | top1:92.8205 | AUROC:0.9819\n",
      "Test | 129/16 | Loss:2.0053 | MainLoss:1.4892 | SPLoss:5.0970 | CLSLoss:0.6445 | top1:60.7227 | AUROC:0.8402\n",
      "\n",
      "Epoch: [196 | 1000] LR: 0.036751\n",
      "Train | 16/16 | Loss:0.6088 | MainLoss:0.1104 | SPLoss:4.9200 | CLSLoss:0.6416 | top1:96.0533 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6709 | MainLoss:0.1930 | SPLoss:4.7158 | CLSLoss:0.6393 | top1:92.8718 | AUROC:0.9821\n",
      "Test | 129/16 | Loss:2.3487 | MainLoss:1.8707 | SPLoss:4.7158 | CLSLoss:0.6393 | top1:55.0312 | AUROC:0.8189\n",
      "\n",
      "Epoch: [197 | 1000] LR: 0.036716\n",
      "Train | 16/16 | Loss:0.5409 | MainLoss:0.0787 | SPLoss:4.5576 | CLSLoss:0.6431 | top1:97.2533 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6321 | MainLoss:0.1889 | SPLoss:4.3670 | CLSLoss:0.6475 | top1:93.2692 | AUROC:0.9824\n",
      "Test | 129/16 | Loss:2.1675 | MainLoss:1.7243 | SPLoss:4.3671 | CLSLoss:0.6475 | top1:58.3676 | AUROC:0.8186\n",
      "\n",
      "Epoch: [198 | 1000] LR: 0.036682\n",
      "Train | 16/16 | Loss:0.5146 | MainLoss:0.0861 | SPLoss:4.2200 | CLSLoss:0.6478 | top1:96.8800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6137 | MainLoss:0.1985 | SPLoss:4.0870 | CLSLoss:0.6455 | top1:92.7308 | AUROC:0.9819\n",
      "Test | 129/16 | Loss:2.0671 | MainLoss:1.6519 | SPLoss:4.0871 | CLSLoss:0.6455 | top1:58.1745 | AUROC:0.8114\n",
      "\n",
      "Epoch: [199 | 1000] LR: 0.036647\n",
      "Train | 16/16 | Loss:0.4927 | MainLoss:0.0917 | SPLoss:3.9459 | CLSLoss:0.6459 | top1:96.6400 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6028 | MainLoss:0.2162 | SPLoss:3.8012 | CLSLoss:0.6486 | top1:92.2436 | AUROC:0.9813\n",
      "Test | 129/16 | Loss:1.8315 | MainLoss:1.4449 | SPLoss:3.8012 | CLSLoss:0.6486 | top1:61.2710 | AUROC:0.8230\n",
      "\n",
      "Epoch: [200 | 1000] LR: 0.036612\n",
      "Train | 16/16 | Loss:0.4562 | MainLoss:0.0794 | SPLoss:3.7028 | CLSLoss:0.6513 | top1:97.0933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.5661 | MainLoss:0.1981 | SPLoss:3.6143 | CLSLoss:0.6516 | top1:93.1667 | AUROC:0.9809\n",
      "Test | 129/16 | Loss:2.1373 | MainLoss:1.7694 | SPLoss:3.6143 | CLSLoss:0.6516 | top1:57.9470 | AUROC:0.8100\n",
      "\n",
      "Epoch: [201 | 1000] LR: 0.036577\n",
      "Train | 16/16 | Loss:0.4434 | MainLoss:0.0851 | SPLoss:3.5186 | CLSLoss:0.6518 | top1:96.9600 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.5364 | MainLoss:0.1898 | SPLoss:3.4013 | CLSLoss:0.6497 | top1:93.1538 | AUROC:0.9810\n",
      "Test | 129/16 | Loss:2.1729 | MainLoss:1.8263 | SPLoss:3.4013 | CLSLoss:0.6497 | top1:56.4517 | AUROC:0.8197\n",
      "\n",
      "Epoch: [202 | 1000] LR: 0.036542\n",
      "Train | 16/16 | Loss:0.4214 | MainLoss:0.0844 | SPLoss:3.3047 | CLSLoss:0.6491 | top1:97.1467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.5141 | MainLoss:0.1884 | SPLoss:3.1919 | CLSLoss:0.6514 | top1:93.3462 | AUROC:0.9817\n",
      "Test | 129/16 | Loss:2.1927 | MainLoss:1.8670 | SPLoss:3.1919 | CLSLoss:0.6514 | top1:56.0748 | AUROC:0.8290\n",
      "\n",
      "Epoch: [203 | 1000] LR: 0.036506\n",
      "Train | 16/16 | Loss:0.3946 | MainLoss:0.0774 | SPLoss:3.1072 | CLSLoss:0.6520 | top1:97.6000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.4988 | MainLoss:0.1914 | SPLoss:3.0090 | CLSLoss:0.6511 | top1:93.3846 | AUROC:0.9822\n",
      "Test | 129/16 | Loss:1.9744 | MainLoss:1.6670 | SPLoss:3.0090 | CLSLoss:0.6511 | top1:58.9065 | AUROC:0.8421\n",
      "\n",
      "Epoch: [204 | 1000] LR: 0.036471\n",
      "Train | 16/16 | Loss:0.3875 | MainLoss:0.0867 | SPLoss:2.9433 | CLSLoss:0.6488 | top1:96.9067 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.5042 | MainLoss:0.2136 | SPLoss:2.8412 | CLSLoss:0.6499 | top1:92.4615 | AUROC:0.9812\n",
      "Test | 129/16 | Loss:2.3426 | MainLoss:2.0520 | SPLoss:2.8412 | CLSLoss:0.6499 | top1:54.4143 | AUROC:0.8421\n",
      "\n",
      "Epoch: [205 | 1000] LR: 0.036435\n",
      "Train | 16/16 | Loss:0.3638 | MainLoss:0.0754 | SPLoss:2.8194 | CLSLoss:0.6516 | top1:97.2000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.4985 | MainLoss:0.2109 | SPLoss:2.8104 | CLSLoss:0.6554 | top1:92.7051 | AUROC:0.9810\n",
      "Test | 129/16 | Loss:1.9067 | MainLoss:1.6191 | SPLoss:2.8104 | CLSLoss:0.6554 | top1:60.4050 | AUROC:0.8341\n",
      "\n",
      "Epoch: [206 | 1000] LR: 0.036399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 16/16 | Loss:0.4561 | MainLoss:0.0946 | SPLoss:3.5490 | CLSLoss:0.6539 | top1:96.7733 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6619 | MainLoss:0.2245 | SPLoss:4.3086 | CLSLoss:0.6530 | top1:92.0256 | AUROC:0.9761\n",
      "Test | 129/16 | Loss:1.8753 | MainLoss:1.4379 | SPLoss:4.3086 | CLSLoss:0.6530 | top1:61.3489 | AUROC:0.8716\n",
      "\n",
      "Epoch: [207 | 1000] LR: 0.036363\n",
      "Train | 16/16 | Loss:0.5646 | MainLoss:0.1392 | SPLoss:4.1893 | CLSLoss:0.6500 | top1:94.2933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.5885 | MainLoss:0.1762 | SPLoss:4.0583 | CLSLoss:0.6421 | top1:93.0641 | AUROC:0.9812\n",
      "Test | 129/16 | Loss:1.8546 | MainLoss:1.4423 | SPLoss:4.0583 | CLSLoss:0.6421 | top1:57.4424 | AUROC:0.8257\n",
      "\n",
      "Epoch: [208 | 1000] LR: 0.036327\n",
      "Train | 16/16 | Loss:0.4960 | MainLoss:0.0966 | SPLoss:3.9288 | CLSLoss:0.6478 | top1:96.6933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.5710 | MainLoss:0.1830 | SPLoss:3.8152 | CLSLoss:0.6470 | top1:93.2308 | AUROC:0.9819\n",
      "Test | 129/16 | Loss:2.0762 | MainLoss:1.6882 | SPLoss:3.8152 | CLSLoss:0.6470 | top1:57.2025 | AUROC:0.8188\n",
      "\n",
      "Epoch: [209 | 1000] LR: 0.036290\n",
      "Train | 16/16 | Loss:0.4655 | MainLoss:0.0888 | SPLoss:3.7014 | CLSLoss:0.6486 | top1:96.8533 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.5616 | MainLoss:0.1991 | SPLoss:3.5596 | CLSLoss:0.6519 | top1:93.1282 | AUROC:0.9816\n",
      "Test | 129/16 | Loss:2.0274 | MainLoss:1.6649 | SPLoss:3.5596 | CLSLoss:0.6519 | top1:58.9595 | AUROC:0.8295\n",
      "\n",
      "Epoch: [210 | 1000] LR: 0.036254\n",
      "Train | 16/16 | Loss:0.4471 | MainLoss:0.0837 | SPLoss:3.5696 | CLSLoss:0.6529 | top1:96.5867 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.5530 | MainLoss:0.1899 | SPLoss:3.5659 | CLSLoss:0.6515 | top1:93.2949 | AUROC:0.9833\n",
      "Test | 129/16 | Loss:1.9092 | MainLoss:1.5461 | SPLoss:3.5659 | CLSLoss:0.6515 | top1:60.0530 | AUROC:0.8275\n",
      "\n",
      "Epoch: [211 | 1000] LR: 0.036217\n",
      "Train | 16/16 | Loss:0.4432 | MainLoss:0.0913 | SPLoss:3.4539 | CLSLoss:0.6511 | top1:96.7733 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.5222 | MainLoss:0.1836 | SPLoss:3.3208 | CLSLoss:0.6508 | top1:93.4615 | AUROC:0.9825\n",
      "Test | 129/16 | Loss:2.0329 | MainLoss:1.6943 | SPLoss:3.3208 | CLSLoss:0.6508 | top1:58.2928 | AUROC:0.8373\n",
      "\n",
      "Epoch: [212 | 1000] LR: 0.036180\n",
      "Train | 16/16 | Loss:0.4328 | MainLoss:0.1029 | SPLoss:3.2335 | CLSLoss:0.6483 | top1:96.2133 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.4960 | MainLoss:0.1768 | SPLoss:3.1265 | CLSLoss:0.6466 | top1:93.4359 | AUROC:0.9826\n",
      "Test | 129/16 | Loss:1.8921 | MainLoss:1.5729 | SPLoss:3.1266 | CLSLoss:0.6466 | top1:58.5171 | AUROC:0.8282\n",
      "\n",
      "Epoch: [213 | 1000] LR: 0.036143\n",
      "Train | 16/16 | Loss:0.4008 | MainLoss:0.0896 | SPLoss:3.0468 | CLSLoss:0.6505 | top1:96.6400 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.4792 | MainLoss:0.1745 | SPLoss:2.9815 | CLSLoss:0.6494 | top1:93.5385 | AUROC:0.9829\n",
      "Test | 129/16 | Loss:2.2258 | MainLoss:1.9212 | SPLoss:2.9816 | CLSLoss:0.6494 | top1:54.7165 | AUROC:0.8078\n",
      "\n",
      "Epoch: [214 | 1000] LR: 0.036106\n",
      "Train | 16/16 | Loss:0.3888 | MainLoss:0.0923 | SPLoss:2.9006 | CLSLoss:0.6496 | top1:96.7733 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.4936 | MainLoss:0.2053 | SPLoss:2.8181 | CLSLoss:0.6527 | top1:92.7821 | AUROC:0.9833\n",
      "Test | 129/16 | Loss:1.7836 | MainLoss:1.4952 | SPLoss:2.8181 | CLSLoss:0.6527 | top1:61.0249 | AUROC:0.8290\n",
      "\n",
      "Epoch: [215 | 1000] LR: 0.036069\n",
      "Train | 16/16 | Loss:0.3810 | MainLoss:0.0989 | SPLoss:2.7559 | CLSLoss:0.6501 | top1:96.4800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.4499 | MainLoss:0.1744 | SPLoss:2.6905 | CLSLoss:0.6484 | top1:93.5385 | AUROC:0.9830\n",
      "Test | 129/16 | Loss:2.0578 | MainLoss:1.7822 | SPLoss:2.6905 | CLSLoss:0.6484 | top1:56.3115 | AUROC:0.8003\n",
      "\n",
      "Epoch: [216 | 1000] LR: 0.036031\n",
      "Train | 16/16 | Loss:0.3569 | MainLoss:0.0868 | SPLoss:2.6360 | CLSLoss:0.6513 | top1:96.6933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.4490 | MainLoss:0.1841 | SPLoss:2.5847 | CLSLoss:0.6509 | top1:93.5641 | AUROC:0.9828\n",
      "Test | 129/16 | Loss:1.9564 | MainLoss:1.6914 | SPLoss:2.5847 | CLSLoss:0.6509 | top1:57.8131 | AUROC:0.8061\n",
      "\n",
      "Epoch: [217 | 1000] LR: 0.035994\n",
      "Train | 16/16 | Loss:0.3488 | MainLoss:0.0885 | SPLoss:2.5387 | CLSLoss:0.6513 | top1:96.9333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.4523 | MainLoss:0.1988 | SPLoss:2.4700 | CLSLoss:0.6530 | top1:92.8462 | AUROC:0.9825\n",
      "Test | 129/16 | Loss:1.8152 | MainLoss:1.5617 | SPLoss:2.4700 | CLSLoss:0.6530 | top1:59.9907 | AUROC:0.8307\n",
      "\n",
      "Epoch: [218 | 1000] LR: 0.035956\n",
      "Train | 16/16 | Loss:0.3173 | MainLoss:0.0689 | SPLoss:2.4185 | CLSLoss:0.6557 | top1:97.4400 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.4488 | MainLoss:0.2061 | SPLoss:2.3612 | CLSLoss:0.6583 | top1:92.7051 | AUROC:0.9805\n",
      "Test | 129/16 | Loss:2.2412 | MainLoss:1.9985 | SPLoss:2.3612 | CLSLoss:0.6583 | top1:55.7445 | AUROC:0.7922\n",
      "\n",
      "Epoch: [219 | 1000] LR: 0.035918\n",
      "Train | 16/16 | Loss:0.3463 | MainLoss:0.1057 | SPLoss:2.3410 | CLSLoss:0.6528 | top1:96.4000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.4184 | MainLoss:0.1821 | SPLoss:2.2981 | CLSLoss:0.6503 | top1:93.1410 | AUROC:0.9814\n",
      "Test | 129/16 | Loss:1.9977 | MainLoss:1.7614 | SPLoss:2.2981 | CLSLoss:0.6503 | top1:56.4860 | AUROC:0.8008\n",
      "\n",
      "Epoch: [220 | 1000] LR: 0.035880\n",
      "Train | 16/16 | Loss:0.3941 | MainLoss:0.0884 | SPLoss:2.9918 | CLSLoss:0.6532 | top1:96.6400 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6476 | MainLoss:0.2247 | SPLoss:4.1645 | CLSLoss:0.6523 | top1:91.7436 | AUROC:0.9748\n",
      "Test | 129/16 | Loss:1.8890 | MainLoss:1.4660 | SPLoss:4.1645 | CLSLoss:0.6523 | top1:60.4237 | AUROC:0.8565\n",
      "\n",
      "Epoch: [221 | 1000] LR: 0.035842\n",
      "Train | 16/16 | Loss:0.5403 | MainLoss:0.1262 | SPLoss:4.0756 | CLSLoss:0.6499 | top1:95.3333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.5967 | MainLoss:0.1930 | SPLoss:3.9713 | CLSLoss:0.6479 | top1:92.8846 | AUROC:0.9813\n",
      "Test | 129/16 | Loss:1.8260 | MainLoss:1.4224 | SPLoss:3.9713 | CLSLoss:0.6479 | top1:60.0280 | AUROC:0.8318\n",
      "\n",
      "Epoch: [222 | 1000] LR: 0.035803\n",
      "Train | 16/16 | Loss:0.4895 | MainLoss:0.0979 | SPLoss:3.8506 | CLSLoss:0.6492 | top1:96.3200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.5657 | MainLoss:0.1861 | SPLoss:3.7308 | CLSLoss:0.6493 | top1:93.2949 | AUROC:0.9816\n",
      "Test | 129/16 | Loss:2.1293 | MainLoss:1.7497 | SPLoss:3.7308 | CLSLoss:0.6493 | top1:56.7414 | AUROC:0.8221\n",
      "\n",
      "Epoch: [223 | 1000] LR: 0.035765\n",
      "Train | 16/16 | Loss:0.4584 | MainLoss:0.0897 | SPLoss:3.6231 | CLSLoss:0.6488 | top1:96.6933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.5631 | MainLoss:0.2020 | SPLoss:3.5452 | CLSLoss:0.6516 | top1:92.7564 | AUROC:0.9807\n",
      "Test | 129/16 | Loss:1.8385 | MainLoss:1.4774 | SPLoss:3.5452 | CLSLoss:0.6516 | top1:61.1090 | AUROC:0.8669\n",
      "\n",
      "Epoch: [224 | 1000] LR: 0.035726\n",
      "Train | 16/16 | Loss:0.4476 | MainLoss:0.0940 | SPLoss:3.4710 | CLSLoss:0.6507 | top1:96.4800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.5291 | MainLoss:0.1845 | SPLoss:3.3808 | CLSLoss:0.6503 | top1:93.1923 | AUROC:0.9822\n",
      "Test | 129/16 | Loss:1.9453 | MainLoss:1.6007 | SPLoss:3.3808 | CLSLoss:0.6503 | top1:59.1371 | AUROC:0.8463\n",
      "\n",
      "Epoch: [225 | 1000] LR: 0.035687\n",
      "Train | 16/16 | Loss:0.4480 | MainLoss:0.1002 | SPLoss:3.4134 | CLSLoss:0.6492 | top1:96.5867 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.5468 | MainLoss:0.1841 | SPLoss:3.5623 | CLSLoss:0.6471 | top1:92.9359 | AUROC:0.9822\n",
      "Test | 129/16 | Loss:1.8845 | MainLoss:1.5218 | SPLoss:3.5623 | CLSLoss:0.6471 | top1:59.2118 | AUROC:0.8267\n",
      "\n",
      "Epoch: [226 | 1000] LR: 0.035648\n",
      "Train | 16/16 | Loss:0.5389 | MainLoss:0.0950 | SPLoss:4.3747 | CLSLoss:0.6486 | top1:96.2933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.7268 | MainLoss:0.1878 | SPLoss:5.3255 | CLSLoss:0.6469 | top1:92.7821 | AUROC:0.9805\n",
      "Test | 129/16 | Loss:2.1005 | MainLoss:1.5615 | SPLoss:5.3255 | CLSLoss:0.6469 | top1:58.8006 | AUROC:0.8283\n",
      "\n",
      "Epoch: [227 | 1000] LR: 0.035609\n",
      "Train | 16/16 | Loss:0.6083 | MainLoss:0.0874 | SPLoss:5.1443 | CLSLoss:0.6496 | top1:96.7200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6963 | MainLoss:0.1960 | SPLoss:4.9378 | CLSLoss:0.6510 | top1:93.1410 | AUROC:0.9819\n",
      "Test | 129/16 | Loss:2.0991 | MainLoss:1.5988 | SPLoss:4.9378 | CLSLoss:0.6510 | top1:59.4984 | AUROC:0.8502\n",
      "\n",
      "Epoch: [228 | 1000] LR: 0.035569\n",
      "Train | 16/16 | Loss:0.5828 | MainLoss:0.0997 | SPLoss:4.7660 | CLSLoss:0.6482 | top1:96.6667 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6502 | MainLoss:0.1860 | SPLoss:4.5770 | CLSLoss:0.6460 | top1:92.9615 | AUROC:0.9811\n",
      "Test | 129/16 | Loss:2.0432 | MainLoss:1.5790 | SPLoss:4.5771 | CLSLoss:0.6460 | top1:58.5857 | AUROC:0.8565\n",
      "\n",
      "Epoch: [229 | 1000] LR: 0.035530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 16/16 | Loss:0.5357 | MainLoss:0.0856 | SPLoss:4.4359 | CLSLoss:0.6486 | top1:96.8533 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6230 | MainLoss:0.1893 | SPLoss:4.2722 | CLSLoss:0.6511 | top1:93.3077 | AUROC:0.9816\n",
      "Test | 129/16 | Loss:2.1605 | MainLoss:1.7268 | SPLoss:4.2722 | CLSLoss:0.6511 | top1:57.5234 | AUROC:0.8236\n",
      "\n",
      "Epoch: [230 | 1000] LR: 0.035490\n",
      "Train | 16/16 | Loss:0.4901 | MainLoss:0.0709 | SPLoss:4.1268 | CLSLoss:0.6536 | top1:97.5200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6133 | MainLoss:0.2115 | SPLoss:3.9522 | CLSLoss:0.6566 | top1:92.7692 | AUROC:0.9808\n",
      "Test | 129/16 | Loss:1.9042 | MainLoss:1.5024 | SPLoss:3.9522 | CLSLoss:0.6566 | top1:61.6386 | AUROC:0.8570\n",
      "\n",
      "Epoch: [231 | 1000] LR: 0.035450\n",
      "Train | 16/16 | Loss:0.4799 | MainLoss:0.0895 | SPLoss:3.8385 | CLSLoss:0.6550 | top1:96.8267 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.5705 | MainLoss:0.1925 | SPLoss:3.7149 | CLSLoss:0.6529 | top1:92.8974 | AUROC:0.9809\n",
      "Test | 129/16 | Loss:2.0121 | MainLoss:1.6341 | SPLoss:3.7149 | CLSLoss:0.6529 | top1:58.4829 | AUROC:0.8266\n",
      "\n",
      "Epoch: [232 | 1000] LR: 0.035410\n",
      "Train | 16/16 | Loss:0.4676 | MainLoss:0.1014 | SPLoss:3.5963 | CLSLoss:0.6535 | top1:96.8267 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.5448 | MainLoss:0.1897 | SPLoss:3.4863 | CLSLoss:0.6445 | top1:92.4359 | AUROC:0.9810\n",
      "Test | 129/16 | Loss:2.1064 | MainLoss:1.7514 | SPLoss:3.4863 | CLSLoss:0.6445 | top1:56.1682 | AUROC:0.8623\n",
      "\n",
      "Epoch: [233 | 1000] LR: 0.035370\n",
      "Train | 16/16 | Loss:0.4338 | MainLoss:0.0871 | SPLoss:3.4030 | CLSLoss:0.6478 | top1:96.9333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.5478 | MainLoss:0.2106 | SPLoss:3.3072 | CLSLoss:0.6496 | top1:92.3077 | AUROC:0.9786\n",
      "Test | 129/16 | Loss:2.0044 | MainLoss:1.6672 | SPLoss:3.3072 | CLSLoss:0.6496 | top1:58.2804 | AUROC:0.8754\n",
      "\n",
      "Epoch: [234 | 1000] LR: 0.035330\n",
      "Train | 16/16 | Loss:0.4462 | MainLoss:0.1177 | SPLoss:3.2205 | CLSLoss:0.6469 | top1:95.9733 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.5236 | MainLoss:0.2032 | SPLoss:3.1403 | CLSLoss:0.6416 | top1:92.2436 | AUROC:0.9808\n",
      "Test | 129/16 | Loss:2.0064 | MainLoss:1.6860 | SPLoss:3.1403 | CLSLoss:0.6416 | top1:56.1931 | AUROC:0.8630\n",
      "\n",
      "Epoch: [235 | 1000] LR: 0.035289\n",
      "Train | 16/16 | Loss:0.4087 | MainLoss:0.0946 | SPLoss:3.0763 | CLSLoss:0.6435 | top1:96.6933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.4984 | MainLoss:0.1926 | SPLoss:2.9927 | CLSLoss:0.6477 | top1:92.7821 | AUROC:0.9819\n",
      "Test | 129/16 | Loss:1.7796 | MainLoss:1.4739 | SPLoss:2.9927 | CLSLoss:0.6477 | top1:60.2928 | AUROC:0.8494\n",
      "\n",
      "Epoch: [236 | 1000] LR: 0.035249\n",
      "Train | 16/16 | Loss:0.3697 | MainLoss:0.0712 | SPLoss:2.9197 | CLSLoss:0.6512 | top1:97.7067 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.5008 | MainLoss:0.2069 | SPLoss:2.8745 | CLSLoss:0.6510 | top1:92.8590 | AUROC:0.9803\n",
      "Test | 129/16 | Loss:2.0300 | MainLoss:1.7361 | SPLoss:2.8745 | CLSLoss:0.6510 | top1:58.8941 | AUROC:0.8531\n",
      "\n",
      "Epoch: [237 | 1000] LR: 0.035208\n",
      "Train | 16/16 | Loss:0.3855 | MainLoss:0.0980 | SPLoss:2.8101 | CLSLoss:0.6468 | top1:96.5333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.4858 | MainLoss:0.2042 | SPLoss:2.7517 | CLSLoss:0.6445 | top1:92.8205 | AUROC:0.9800\n",
      "Test | 129/16 | Loss:1.7588 | MainLoss:1.4772 | SPLoss:2.7517 | CLSLoss:0.6445 | top1:60.7539 | AUROC:0.8560\n",
      "\n",
      "Epoch: [238 | 1000] LR: 0.035167\n",
      "Train | 16/16 | Loss:0.3633 | MainLoss:0.0883 | SPLoss:2.6855 | CLSLoss:0.6451 | top1:96.6400 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.4704 | MainLoss:0.2016 | SPLoss:2.6225 | CLSLoss:0.6479 | top1:92.8590 | AUROC:0.9808\n",
      "Test | 129/16 | Loss:1.8091 | MainLoss:1.5404 | SPLoss:2.6226 | CLSLoss:0.6479 | top1:60.3240 | AUROC:0.8676\n",
      "\n",
      "Epoch: [239 | 1000] LR: 0.035126\n",
      "Train | 16/16 | Loss:0.3361 | MainLoss:0.0729 | SPLoss:2.5665 | CLSLoss:0.6487 | top1:97.3867 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.4703 | MainLoss:0.2124 | SPLoss:2.5139 | CLSLoss:0.6522 | top1:92.7308 | AUROC:0.9797\n",
      "Test | 129/16 | Loss:1.8834 | MainLoss:1.6255 | SPLoss:2.5139 | CLSLoss:0.6522 | top1:59.7944 | AUROC:0.8643\n",
      "\n",
      "Epoch: [240 | 1000] LR: 0.035085\n",
      "Train | 16/16 | Loss:0.3534 | MainLoss:0.0946 | SPLoss:2.5224 | CLSLoss:0.6496 | top1:96.5600 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.4542 | MainLoss:0.1982 | SPLoss:2.4954 | CLSLoss:0.6495 | top1:92.9231 | AUROC:0.9804\n",
      "Test | 129/16 | Loss:1.9610 | MainLoss:1.7050 | SPLoss:2.4954 | CLSLoss:0.6495 | top1:57.9907 | AUROC:0.8729\n",
      "\n",
      "Epoch: [241 | 1000] LR: 0.035044\n",
      "Train | 16/16 | Loss:0.3629 | MainLoss:0.0925 | SPLoss:2.6388 | CLSLoss:0.6484 | top1:96.5333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.4651 | MainLoss:0.1957 | SPLoss:2.6289 | CLSLoss:0.6476 | top1:92.8590 | AUROC:0.9806\n",
      "Test | 129/16 | Loss:1.9234 | MainLoss:1.6540 | SPLoss:2.6289 | CLSLoss:0.6476 | top1:58.6106 | AUROC:0.8772\n",
      "\n",
      "Epoch: [242 | 1000] LR: 0.035002\n",
      "Train | 16/16 | Loss:0.3494 | MainLoss:0.0843 | SPLoss:2.5866 | CLSLoss:0.6483 | top1:96.9867 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.4613 | MainLoss:0.1961 | SPLoss:2.5873 | CLSLoss:0.6485 | top1:92.7564 | AUROC:0.9806\n",
      "Test | 129/16 | Loss:1.9041 | MainLoss:1.6389 | SPLoss:2.5873 | CLSLoss:0.6485 | top1:58.5607 | AUROC:0.8517\n",
      "\n",
      "Epoch: [243 | 1000] LR: 0.034961\n",
      "Train | 16/16 | Loss:0.3623 | MainLoss:0.0969 | SPLoss:2.5885 | CLSLoss:0.6478 | top1:96.3733 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.4814 | MainLoss:0.2191 | SPLoss:2.5580 | CLSLoss:0.6484 | top1:91.9615 | AUROC:0.9797\n",
      "Test | 129/16 | Loss:1.5250 | MainLoss:1.2627 | SPLoss:2.5580 | CLSLoss:0.6484 | top1:63.9128 | AUROC:0.8647\n",
      "\n",
      "Epoch: [244 | 1000] LR: 0.034919\n",
      "Train | 16/16 | Loss:0.3396 | MainLoss:0.0820 | SPLoss:2.5106 | CLSLoss:0.6506 | top1:96.9067 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.4471 | MainLoss:0.1948 | SPLoss:2.4580 | CLSLoss:0.6504 | top1:92.9103 | AUROC:0.9801\n",
      "Test | 129/16 | Loss:1.7730 | MainLoss:1.5207 | SPLoss:2.4580 | CLSLoss:0.6504 | top1:59.7819 | AUROC:0.8658\n",
      "\n",
      "Epoch: [245 | 1000] LR: 0.034877\n",
      "Train | 16/16 | Loss:0.3257 | MainLoss:0.0775 | SPLoss:2.4165 | CLSLoss:0.6531 | top1:97.2267 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.4482 | MainLoss:0.2044 | SPLoss:2.3734 | CLSLoss:0.6536 | top1:92.8077 | AUROC:0.9794\n",
      "Test | 129/16 | Loss:1.9305 | MainLoss:1.6867 | SPLoss:2.3734 | CLSLoss:0.6536 | top1:58.0623 | AUROC:0.8437\n",
      "\n",
      "Epoch: [246 | 1000] LR: 0.034835\n",
      "Train | 16/16 | Loss:9.3146 | MainLoss:0.1054 | SPLoss:92.0270 | CLSLoss:0.6485 | top1:96.0533 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:35.2997 | MainLoss:0.1948 | SPLoss:350.9839 | CLSLoss:0.6511 | top1:92.8590 | AUROC:0.9812\n",
      "Test | 129/16 | Loss:36.5451 | MainLoss:1.4402 | SPLoss:350.9840 | CLSLoss:0.6511 | top1:61.5514 | AUROC:0.8748\n",
      "\n",
      "Epoch: [247 | 1000] LR: 0.034793\n",
      "Train | 16/16 | Loss:36.9464 | MainLoss:0.1722 | SPLoss:367.6779 | CLSLoss:0.6400 | top1:93.2533 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:36.1022 | MainLoss:0.2060 | SPLoss:358.8973 | CLSLoss:0.6400 | top1:91.9487 | AUROC:0.9761\n",
      "Test | 129/16 | Loss:36.9853 | MainLoss:1.0892 | SPLoss:358.8972 | CLSLoss:0.6400 | top1:65.6075 | AUROC:0.8745\n",
      "\n",
      "Epoch: [248 | 1000] LR: 0.034750\n",
      "Train | 16/16 | Loss:34.1323 | MainLoss:0.0987 | SPLoss:340.2722 | CLSLoss:0.6428 | top1:96.1067 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:32.2046 | MainLoss:0.2204 | SPLoss:319.7769 | CLSLoss:0.6474 | top1:92.0513 | AUROC:0.9797\n",
      "Test | 129/16 | Loss:33.1170 | MainLoss:1.1329 | SPLoss:319.7764 | CLSLoss:0.6474 | top1:67.0343 | AUROC:0.8696\n",
      "\n",
      "Epoch: [249 | 1000] LR: 0.034708\n",
      "Train | 16/16 | Loss:30.4291 | MainLoss:0.1010 | SPLoss:303.2167 | CLSLoss:0.6467 | top1:96.3467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:28.6887 | MainLoss:0.1844 | SPLoss:284.9790 | CLSLoss:0.6435 | top1:93.1538 | AUROC:0.9811\n",
      "Test | 129/16 | Loss:29.9443 | MainLoss:1.4400 | SPLoss:284.9786 | CLSLoss:0.6435 | top1:60.3551 | AUROC:0.8293\n",
      "\n",
      "Epoch: [250 | 1000] LR: 0.034665\n",
      "Train | 16/16 | Loss:27.1309 | MainLoss:0.1016 | SPLoss:270.2295 | CLSLoss:0.6436 | top1:96.3200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:25.6046 | MainLoss:0.1984 | SPLoss:253.9975 | CLSLoss:0.6412 | top1:92.5513 | AUROC:0.9818\n",
      "Test | 129/16 | Loss:26.6082 | MainLoss:1.2021 | SPLoss:253.9979 | CLSLoss:0.6412 | top1:64.0280 | AUROC:0.8494\n",
      "\n",
      "Epoch: [251 | 1000] LR: 0.034622\n",
      "Train | 16/16 | Loss:24.1749 | MainLoss:0.0824 | SPLoss:240.8610 | CLSLoss:0.6450 | top1:96.9867 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:22.8632 | MainLoss:0.2136 | SPLoss:226.4305 | CLSLoss:0.6465 | top1:92.4487 | AUROC:0.9813\n",
      "Test | 129/16 | Loss:23.9191 | MainLoss:1.2696 | SPLoss:226.4305 | CLSLoss:0.6465 | top1:64.4174 | AUROC:0.8483\n",
      "\n",
      "Epoch: [252 | 1000] LR: 0.003458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 16/16 | Loss:22.6096 | MainLoss:0.0810 | SPLoss:225.2221 | CLSLoss:0.6464 | top1:97.3067 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:22.5899 | MainLoss:0.1988 | SPLoss:223.8460 | CLSLoss:0.6465 | top1:92.9103 | AUROC:0.9818\n",
      "Test | 129/16 | Loss:23.7295 | MainLoss:1.3384 | SPLoss:223.8460 | CLSLoss:0.6465 | top1:63.2991 | AUROC:0.8471\n",
      "\n",
      "Epoch: [253 | 1000] LR: 0.003454\n",
      "Train | 16/16 | Loss:22.3556 | MainLoss:0.0836 | SPLoss:222.6554 | CLSLoss:0.6466 | top1:96.9867 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:22.3295 | MainLoss:0.1930 | SPLoss:221.3004 | CLSLoss:0.6467 | top1:93.1667 | AUROC:0.9820\n",
      "Test | 129/16 | Loss:23.5383 | MainLoss:1.4018 | SPLoss:221.3001 | CLSLoss:0.6467 | top1:62.2741 | AUROC:0.8454\n",
      "\n",
      "Epoch: [254 | 1000] LR: 0.003449\n",
      "Train | 16/16 | Loss:22.0883 | MainLoss:0.0695 | SPLoss:220.1233 | CLSLoss:0.6468 | top1:97.6267 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:22.0772 | MainLoss:0.1926 | SPLoss:218.7816 | CLSLoss:0.6473 | top1:93.1538 | AUROC:0.9820\n",
      "Test | 129/16 | Loss:23.2954 | MainLoss:1.4107 | SPLoss:218.7819 | CLSLoss:0.6473 | top1:62.3271 | AUROC:0.8466\n",
      "\n",
      "Epoch: [255 | 1000] LR: 0.003445\n",
      "Train | 16/16 | Loss:21.8552 | MainLoss:0.0865 | SPLoss:217.6220 | CLSLoss:0.6472 | top1:96.8000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:21.8268 | MainLoss:0.1904 | SPLoss:216.2995 | CLSLoss:0.6470 | top1:93.2436 | AUROC:0.9820\n",
      "Test | 129/16 | Loss:23.0527 | MainLoss:1.4163 | SPLoss:216.2996 | CLSLoss:0.6470 | top1:62.0717 | AUROC:0.8459\n",
      "\n",
      "Epoch: [256 | 1000] LR: 0.003441\n",
      "Train | 16/16 | Loss:21.6013 | MainLoss:0.0795 | SPLoss:215.1531 | CLSLoss:0.6468 | top1:97.3600 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:21.5851 | MainLoss:0.1939 | SPLoss:213.8480 | CLSLoss:0.6471 | top1:93.2179 | AUROC:0.9824\n",
      "Test | 129/16 | Loss:22.7609 | MainLoss:1.3696 | SPLoss:213.8480 | CLSLoss:0.6471 | top1:62.9034 | AUROC:0.8465\n",
      "\n",
      "Epoch: [257 | 1000] LR: 0.003436\n",
      "Train | 16/16 | Loss:21.3438 | MainLoss:0.0658 | SPLoss:212.7156 | CLSLoss:0.6475 | top1:97.9467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:21.3439 | MainLoss:0.1949 | SPLoss:211.4260 | CLSLoss:0.6478 | top1:93.2179 | AUROC:0.9823\n",
      "Test | 129/16 | Loss:22.5319 | MainLoss:1.3828 | SPLoss:211.4260 | CLSLoss:0.6478 | top1:62.8598 | AUROC:0.8483\n",
      "\n",
      "Epoch: [258 | 1000] LR: 0.003432\n",
      "Train | 16/16 | Loss:21.1266 | MainLoss:0.0894 | SPLoss:210.3075 | CLSLoss:0.6475 | top1:97.1467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:21.1032 | MainLoss:0.1932 | SPLoss:209.0353 | CLSLoss:0.6474 | top1:93.2692 | AUROC:0.9822\n",
      "Test | 129/16 | Loss:22.2780 | MainLoss:1.3680 | SPLoss:209.0355 | CLSLoss:0.6474 | top1:63.0654 | AUROC:0.8498\n",
      "\n",
      "Epoch: [259 | 1000] LR: 0.003427\n",
      "Train | 16/16 | Loss:20.8887 | MainLoss:0.0891 | SPLoss:207.9310 | CLSLoss:0.6472 | top1:96.6933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:20.8657 | MainLoss:0.1917 | SPLoss:206.6749 | CLSLoss:0.6470 | top1:93.4231 | AUROC:0.9827\n",
      "Test | 129/16 | Loss:22.0111 | MainLoss:1.3371 | SPLoss:206.6746 | CLSLoss:0.6470 | top1:63.4548 | AUROC:0.8537\n",
      "\n",
      "Epoch: [260 | 1000] LR: 0.003423\n",
      "Train | 16/16 | Loss:20.6404 | MainLoss:0.0755 | SPLoss:205.5839 | CLSLoss:0.6473 | top1:97.3867 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:20.6850 | MainLoss:0.1892 | SPLoss:204.8929 | CLSLoss:0.6474 | top1:93.5256 | AUROC:0.9823\n",
      "Test | 129/16 | Loss:21.8483 | MainLoss:1.3526 | SPLoss:204.8926 | CLSLoss:0.6474 | top1:63.3053 | AUROC:0.8559\n",
      "\n",
      "Epoch: [261 | 1000] LR: 0.003419\n",
      "Train | 16/16 | Loss:20.4791 | MainLoss:0.0768 | SPLoss:203.9586 | CLSLoss:0.6477 | top1:97.5467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:20.4848 | MainLoss:0.2027 | SPLoss:202.7564 | CLSLoss:0.6478 | top1:92.7179 | AUROC:0.9804\n",
      "Test | 129/16 | Loss:21.6326 | MainLoss:1.3505 | SPLoss:202.7561 | CLSLoss:0.6478 | top1:63.3146 | AUROC:0.8486\n",
      "\n",
      "Epoch: [262 | 1000] LR: 0.003414\n",
      "Train | 16/16 | Loss:20.2455 | MainLoss:0.0700 | SPLoss:201.6903 | CLSLoss:0.6482 | top1:97.7333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:20.2521 | MainLoss:0.1979 | SPLoss:200.4769 | CLSLoss:0.6487 | top1:93.0128 | AUROC:0.9807\n",
      "Test | 129/16 | Loss:21.4905 | MainLoss:1.4363 | SPLoss:200.4766 | CLSLoss:0.6487 | top1:62.1558 | AUROC:0.8460\n",
      "\n",
      "Epoch: [263 | 1000] LR: 0.003410\n",
      "Train | 16/16 | Loss:20.0428 | MainLoss:0.0938 | SPLoss:199.4256 | CLSLoss:0.6484 | top1:96.4800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:20.0277 | MainLoss:0.1984 | SPLoss:198.2280 | CLSLoss:0.6483 | top1:92.8590 | AUROC:0.9806\n",
      "Test | 129/16 | Loss:21.2303 | MainLoss:1.4010 | SPLoss:198.2280 | CLSLoss:0.6483 | top1:62.5389 | AUROC:0.8473\n",
      "\n",
      "Epoch: [264 | 1000] LR: 0.003405\n",
      "Train | 16/16 | Loss:19.8168 | MainLoss:0.0913 | SPLoss:197.1898 | CLSLoss:0.6481 | top1:96.7200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:19.8063 | MainLoss:0.1992 | SPLoss:196.0058 | CLSLoss:0.6480 | top1:92.9231 | AUROC:0.9808\n",
      "Test | 129/16 | Loss:20.9696 | MainLoss:1.3625 | SPLoss:196.0060 | CLSLoss:0.6480 | top1:62.9657 | AUROC:0.8517\n",
      "\n",
      "Epoch: [265 | 1000] LR: 0.003401\n",
      "Train | 16/16 | Loss:19.5810 | MainLoss:0.0764 | SPLoss:194.9805 | CLSLoss:0.6483 | top1:97.0400 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:19.5910 | MainLoss:0.2030 | SPLoss:193.8148 | CLSLoss:0.6486 | top1:92.9103 | AUROC:0.9803\n",
      "Test | 129/16 | Loss:20.7277 | MainLoss:1.3397 | SPLoss:193.8147 | CLSLoss:0.6486 | top1:63.4673 | AUROC:0.8526\n",
      "\n",
      "Epoch: [266 | 1000] LR: 0.003396\n",
      "Train | 16/16 | Loss:19.3594 | MainLoss:0.0726 | SPLoss:192.8030 | CLSLoss:0.6488 | top1:97.7067 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:19.3731 | MainLoss:0.2016 | SPLoss:191.6501 | CLSLoss:0.6490 | top1:92.9487 | AUROC:0.9804\n",
      "Test | 129/16 | Loss:20.5427 | MainLoss:1.3712 | SPLoss:191.6501 | CLSLoss:0.6490 | top1:63.0841 | AUROC:0.8544\n",
      "\n",
      "Epoch: [267 | 1000] LR: 0.003392\n",
      "Train | 16/16 | Loss:19.1521 | MainLoss:0.0806 | SPLoss:190.6502 | CLSLoss:0.6493 | top1:97.2533 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:19.1564 | MainLoss:0.1986 | SPLoss:189.5130 | CLSLoss:0.6491 | top1:93.1282 | AUROC:0.9804\n",
      "Test | 129/16 | Loss:20.3577 | MainLoss:1.3999 | SPLoss:189.5133 | CLSLoss:0.6491 | top1:62.6386 | AUROC:0.8528\n",
      "\n",
      "Epoch: [268 | 1000] LR: 0.003387\n",
      "Train | 16/16 | Loss:18.9363 | MainLoss:0.0774 | SPLoss:188.5250 | CLSLoss:0.6493 | top1:97.3067 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:18.9496 | MainLoss:0.2030 | SPLoss:187.4015 | CLSLoss:0.6494 | top1:92.9359 | AUROC:0.9806\n",
      "Test | 129/16 | Loss:20.0721 | MainLoss:1.3254 | SPLoss:187.4018 | CLSLoss:0.6494 | top1:63.8692 | AUROC:0.8565\n",
      "\n",
      "Epoch: [269 | 1000] LR: 0.003383\n",
      "Train | 16/16 | Loss:18.7238 | MainLoss:0.0747 | SPLoss:186.4258 | CLSLoss:0.6495 | top1:97.3600 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:18.7395 | MainLoss:0.2013 | SPLoss:185.3165 | CLSLoss:0.6497 | top1:93.1026 | AUROC:0.9807\n",
      "Test | 129/16 | Loss:19.8902 | MainLoss:1.3521 | SPLoss:185.3162 | CLSLoss:0.6497 | top1:63.4953 | AUROC:0.8553\n",
      "\n",
      "Epoch: [270 | 1000] LR: 0.003378\n",
      "Train | 16/16 | Loss:18.5175 | MainLoss:0.0756 | SPLoss:184.3542 | CLSLoss:0.6497 | top1:97.4133 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:18.5318 | MainLoss:0.1996 | SPLoss:183.2569 | CLSLoss:0.6499 | top1:93.1538 | AUROC:0.9808\n",
      "Test | 129/16 | Loss:19.7125 | MainLoss:1.3803 | SPLoss:183.2567 | CLSLoss:0.6499 | top1:63.1090 | AUROC:0.8556\n",
      "\n",
      "Epoch: [271 | 1000] LR: 0.003374\n",
      "Train | 16/16 | Loss:18.3190 | MainLoss:0.0818 | SPLoss:182.3076 | CLSLoss:0.6497 | top1:97.1200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:18.3267 | MainLoss:0.1977 | SPLoss:181.2248 | CLSLoss:0.6499 | top1:93.1538 | AUROC:0.9810\n",
      "Test | 129/16 | Loss:19.5070 | MainLoss:1.3780 | SPLoss:181.2247 | CLSLoss:0.6499 | top1:63.1059 | AUROC:0.8554\n",
      "\n",
      "Epoch: [272 | 1000] LR: 0.003369\n",
      "Train | 16/16 | Loss:18.1085 | MainLoss:0.0735 | SPLoss:180.2853 | CLSLoss:0.6499 | top1:97.7867 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:18.1268 | MainLoss:0.1988 | SPLoss:179.2158 | CLSLoss:0.6501 | top1:93.1154 | AUROC:0.9807\n",
      "Test | 129/16 | Loss:19.3331 | MainLoss:1.4050 | SPLoss:179.2160 | CLSLoss:0.6501 | top1:62.7913 | AUROC:0.8522\n",
      "\n",
      "Epoch: [273 | 1000] LR: 0.003365\n",
      "Train | 16/16 | Loss:17.9096 | MainLoss:0.0741 | SPLoss:178.2902 | CLSLoss:0.6502 | top1:97.4400 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:17.9378 | MainLoss:0.2078 | SPLoss:177.2350 | CLSLoss:0.6503 | top1:93.0256 | AUROC:0.9799\n",
      "Test | 129/16 | Loss:19.1145 | MainLoss:1.3845 | SPLoss:177.2347 | CLSLoss:0.6503 | top1:63.2804 | AUROC:0.8482\n",
      "\n",
      "Epoch: [274 | 1000] LR: 0.003360\n",
      "Train | 16/16 | Loss:17.7158 | MainLoss:0.0772 | SPLoss:176.3201 | CLSLoss:0.6503 | top1:97.1733 | AUROC:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 32/16 | Loss:17.7387 | MainLoss:0.2046 | SPLoss:175.2765 | CLSLoss:0.6502 | top1:93.0769 | AUROC:0.9805\n",
      "Test | 129/16 | Loss:18.9288 | MainLoss:1.3946 | SPLoss:175.2766 | CLSLoss:0.6502 | top1:63.0997 | AUROC:0.8489\n",
      "\n",
      "Epoch: [275 | 1000] LR: 0.003355\n",
      "Train | 16/16 | Loss:17.5163 | MainLoss:0.0726 | SPLoss:174.3717 | CLSLoss:0.6503 | top1:97.4667 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:17.5469 | MainLoss:0.2060 | SPLoss:173.3437 | CLSLoss:0.6506 | top1:93.0641 | AUROC:0.9800\n",
      "Test | 129/16 | Loss:18.7236 | MainLoss:1.3827 | SPLoss:173.3439 | CLSLoss:0.6506 | top1:63.3458 | AUROC:0.8503\n",
      "\n",
      "Epoch: [276 | 1000] LR: 0.003351\n",
      "Train | 16/16 | Loss:17.3325 | MainLoss:0.0810 | SPLoss:172.4500 | CLSLoss:0.6505 | top1:97.3600 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:17.3585 | MainLoss:0.2088 | SPLoss:171.4322 | CLSLoss:0.6504 | top1:92.9872 | AUROC:0.9803\n",
      "Test | 129/16 | Loss:18.4997 | MainLoss:1.3499 | SPLoss:171.4321 | CLSLoss:0.6504 | top1:63.8100 | AUROC:0.8535\n",
      "\n",
      "Epoch: [277 | 1000] LR: 0.003346\n",
      "Train | 16/16 | Loss:17.1439 | MainLoss:0.0822 | SPLoss:170.5518 | CLSLoss:0.6505 | top1:96.9333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:17.1683 | MainLoss:0.2070 | SPLoss:169.5475 | CLSLoss:0.6503 | top1:93.0385 | AUROC:0.9804\n",
      "Test | 129/16 | Loss:18.3327 | MainLoss:1.3714 | SPLoss:169.5478 | CLSLoss:0.6503 | top1:63.3583 | AUROC:0.8515\n",
      "\n",
      "Epoch: [278 | 1000] LR: 0.003341\n",
      "Train | 16/16 | Loss:16.9444 | MainLoss:0.0702 | SPLoss:168.6771 | CLSLoss:0.6505 | top1:97.8133 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:16.9827 | MainLoss:0.2077 | SPLoss:167.6855 | CLSLoss:0.6507 | top1:93.0128 | AUROC:0.9800\n",
      "Test | 129/16 | Loss:18.1460 | MainLoss:1.3709 | SPLoss:167.6858 | CLSLoss:0.6507 | top1:63.5545 | AUROC:0.8554\n",
      "\n",
      "Epoch: [279 | 1000] LR: 0.003337\n",
      "Train | 16/16 | Loss:16.7525 | MainLoss:0.0635 | SPLoss:166.8253 | CLSLoss:0.6510 | top1:97.8400 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:16.7959 | MainLoss:0.2048 | SPLoss:165.8458 | CLSLoss:0.6513 | top1:93.0513 | AUROC:0.9802\n",
      "Test | 129/16 | Loss:17.9934 | MainLoss:1.4023 | SPLoss:165.8460 | CLSLoss:0.6513 | top1:63.1682 | AUROC:0.8553\n",
      "\n",
      "Epoch: [280 | 1000] LR: 0.003332\n",
      "Train | 16/16 | Loss:16.5961 | MainLoss:0.0898 | SPLoss:164.9975 | CLSLoss:0.6511 | top1:96.8000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:16.6138 | MainLoss:0.2042 | SPLoss:164.0309 | CLSLoss:0.6506 | top1:93.0513 | AUROC:0.9804\n",
      "Test | 129/16 | Loss:17.7809 | MainLoss:1.3713 | SPLoss:164.0308 | CLSLoss:0.6506 | top1:63.4517 | AUROC:0.8547\n",
      "\n",
      "Epoch: [281 | 1000] LR: 0.003327\n",
      "Train | 16/16 | Loss:16.3906 | MainLoss:0.0650 | SPLoss:163.1916 | CLSLoss:0.6507 | top1:98.0800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:16.4344 | MainLoss:0.2043 | SPLoss:162.2357 | CLSLoss:0.6511 | top1:93.1410 | AUROC:0.9805\n",
      "Test | 129/16 | Loss:17.6213 | MainLoss:1.3912 | SPLoss:162.2358 | CLSLoss:0.6511 | top1:63.2648 | AUROC:0.8538\n",
      "\n",
      "Epoch: [282 | 1000] LR: 0.003323\n",
      "Train | 16/16 | Loss:16.2199 | MainLoss:0.0727 | SPLoss:161.4071 | CLSLoss:0.6512 | top1:97.4400 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:16.2547 | MainLoss:0.2018 | SPLoss:160.4635 | CLSLoss:0.6513 | top1:93.1667 | AUROC:0.9803\n",
      "Test | 129/16 | Loss:17.4594 | MainLoss:1.4066 | SPLoss:160.4638 | CLSLoss:0.6513 | top1:63.1059 | AUROC:0.8545\n",
      "\n",
      "Epoch: [283 | 1000] LR: 0.003318\n",
      "Train | 16/16 | Loss:16.0514 | MainLoss:0.0805 | SPLoss:159.6448 | CLSLoss:0.6511 | top1:97.0933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:16.0803 | MainLoss:0.2025 | SPLoss:158.7128 | CLSLoss:0.6510 | top1:93.2179 | AUROC:0.9807\n",
      "Test | 129/16 | Loss:17.2326 | MainLoss:1.3548 | SPLoss:158.7128 | CLSLoss:0.6510 | top1:63.9284 | AUROC:0.8600\n",
      "\n",
      "Epoch: [284 | 1000] LR: 0.003313\n",
      "Train | 16/16 | Loss:15.8593 | MainLoss:0.0623 | SPLoss:157.9055 | CLSLoss:0.6512 | top1:97.9467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:15.9072 | MainLoss:0.2021 | SPLoss:156.9860 | CLSLoss:0.6518 | top1:93.1667 | AUROC:0.9808\n",
      "Test | 129/16 | Loss:17.0855 | MainLoss:1.3804 | SPLoss:156.9860 | CLSLoss:0.6518 | top1:63.5670 | AUROC:0.8566\n",
      "\n",
      "Epoch: [285 | 1000] LR: 0.003308\n",
      "Train | 16/16 | Loss:15.6907 | MainLoss:0.0655 | SPLoss:156.1871 | CLSLoss:0.6520 | top1:97.7333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:15.7342 | MainLoss:0.1998 | SPLoss:155.2795 | CLSLoss:0.6522 | top1:93.2436 | AUROC:0.9807\n",
      "Test | 129/16 | Loss:16.9205 | MainLoss:1.3861 | SPLoss:155.2794 | CLSLoss:0.6522 | top1:63.5358 | AUROC:0.8619\n",
      "\n",
      "Epoch: [286 | 1000] LR: 0.003304\n",
      "Train | 16/16 | Loss:15.5214 | MainLoss:0.0658 | SPLoss:154.4909 | CLSLoss:0.6524 | top1:97.5467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:15.5694 | MainLoss:0.2036 | SPLoss:153.5928 | CLSLoss:0.6527 | top1:93.2949 | AUROC:0.9807\n",
      "Test | 129/16 | Loss:16.7126 | MainLoss:1.3468 | SPLoss:153.5928 | CLSLoss:0.6527 | top1:64.3458 | AUROC:0.8635\n",
      "\n",
      "Epoch: [287 | 1000] LR: 0.003299\n",
      "Train | 16/16 | Loss:15.3481 | MainLoss:0.0601 | SPLoss:152.8142 | CLSLoss:0.6529 | top1:98.1067 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:15.4028 | MainLoss:0.2035 | SPLoss:151.9280 | CLSLoss:0.6533 | top1:93.2179 | AUROC:0.9811\n",
      "Test | 129/16 | Loss:16.5768 | MainLoss:1.3775 | SPLoss:151.9280 | CLSLoss:0.6533 | top1:64.0499 | AUROC:0.8613\n",
      "\n",
      "Epoch: [288 | 1000] LR: 0.003294\n",
      "Train | 16/16 | Loss:15.1885 | MainLoss:0.0660 | SPLoss:151.1594 | CLSLoss:0.6535 | top1:97.8400 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:15.2407 | MainLoss:0.2057 | SPLoss:150.2853 | CLSLoss:0.6537 | top1:93.1538 | AUROC:0.9809\n",
      "Test | 129/16 | Loss:16.4076 | MainLoss:1.3725 | SPLoss:150.2853 | CLSLoss:0.6537 | top1:64.1713 | AUROC:0.8634\n",
      "\n",
      "Epoch: [289 | 1000] LR: 0.003289\n",
      "Train | 16/16 | Loss:15.0205 | MainLoss:0.0614 | SPLoss:149.5250 | CLSLoss:0.6540 | top1:97.8667 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:15.0787 | MainLoss:0.2062 | SPLoss:148.6593 | CLSLoss:0.6542 | top1:93.1026 | AUROC:0.9805\n",
      "Test | 129/16 | Loss:16.2222 | MainLoss:1.3497 | SPLoss:148.6593 | CLSLoss:0.6542 | top1:64.7072 | AUROC:0.8627\n",
      "\n",
      "Epoch: [290 | 1000] LR: 0.003285\n",
      "Train | 16/16 | Loss:14.8727 | MainLoss:0.0749 | SPLoss:147.9126 | CLSLoss:0.6541 | top1:97.2000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:14.9254 | MainLoss:0.2130 | SPLoss:147.0590 | CLSLoss:0.6542 | top1:93.0128 | AUROC:0.9804\n",
      "Test | 129/16 | Loss:16.0090 | MainLoss:1.2965 | SPLoss:147.0589 | CLSLoss:0.6542 | top1:65.4798 | AUROC:0.8636\n",
      "\n",
      "Epoch: [291 | 1000] LR: 0.003280\n",
      "Train | 16/16 | Loss:14.7150 | MainLoss:0.0765 | SPLoss:146.3198 | CLSLoss:0.6543 | top1:97.2267 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:14.7590 | MainLoss:0.2048 | SPLoss:145.4767 | CLSLoss:0.6541 | top1:93.1026 | AUROC:0.9812\n",
      "Test | 129/16 | Loss:15.9116 | MainLoss:1.3574 | SPLoss:145.4767 | CLSLoss:0.6541 | top1:64.4424 | AUROC:0.8613\n",
      "\n",
      "Epoch: [292 | 1000] LR: 0.003275\n",
      "Train | 16/16 | Loss:14.5482 | MainLoss:0.0672 | SPLoss:144.7445 | CLSLoss:0.6539 | top1:97.4667 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:14.6065 | MainLoss:0.2090 | SPLoss:143.9101 | CLSLoss:0.6539 | top1:92.9103 | AUROC:0.9806\n",
      "Test | 129/16 | Loss:15.7120 | MainLoss:1.3145 | SPLoss:143.9100 | CLSLoss:0.6539 | top1:65.0717 | AUROC:0.8630\n",
      "\n",
      "Epoch: [293 | 1000] LR: 0.003270\n",
      "Train | 16/16 | Loss:14.4020 | MainLoss:0.0767 | SPLoss:143.1875 | CLSLoss:0.6539 | top1:97.2000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:14.4454 | MainLoss:0.2022 | SPLoss:142.3666 | CLSLoss:0.6538 | top1:93.1923 | AUROC:0.9811\n",
      "Test | 129/16 | Loss:15.5984 | MainLoss:1.3552 | SPLoss:142.3667 | CLSLoss:0.6538 | top1:64.3614 | AUROC:0.8620\n",
      "\n",
      "Epoch: [294 | 1000] LR: 0.003265\n",
      "Train | 16/16 | Loss:14.2400 | MainLoss:0.0681 | SPLoss:141.6527 | CLSLoss:0.6537 | top1:97.7867 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:14.2933 | MainLoss:0.2027 | SPLoss:140.8402 | CLSLoss:0.6540 | top1:93.1667 | AUROC:0.9809\n",
      "Test | 129/16 | Loss:15.4446 | MainLoss:1.3540 | SPLoss:140.8401 | CLSLoss:0.6540 | top1:64.4424 | AUROC:0.8641\n",
      "\n",
      "Epoch: [295 | 1000] LR: 0.003260\n",
      "Train | 16/16 | Loss:14.0959 | MainLoss:0.0758 | SPLoss:140.1356 | CLSLoss:0.6539 | top1:97.5200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:14.1426 | MainLoss:0.2027 | SPLoss:139.3337 | CLSLoss:0.6539 | top1:93.0897 | AUROC:0.9806\n",
      "Test | 129/16 | Loss:15.3091 | MainLoss:1.3692 | SPLoss:139.3338 | CLSLoss:0.6539 | top1:64.1620 | AUROC:0.8631\n",
      "\n",
      "Epoch: [296 | 1000] LR: 0.003255\n",
      "Train | 16/16 | Loss:13.9430 | MainLoss:0.0727 | SPLoss:138.6373 | CLSLoss:0.6539 | top1:97.4133 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:13.9951 | MainLoss:0.2040 | SPLoss:137.8460 | CLSLoss:0.6538 | top1:92.9359 | AUROC:0.9809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 129/16 | Loss:15.1513 | MainLoss:1.3601 | SPLoss:137.8460 | CLSLoss:0.6538 | top1:64.3894 | AUROC:0.8633\n",
      "\n",
      "Epoch: [297 | 1000] LR: 0.003250\n",
      "Train | 16/16 | Loss:13.7838 | MainLoss:0.0614 | SPLoss:137.1577 | CLSLoss:0.6541 | top1:98.0267 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:13.8460 | MainLoss:0.2020 | SPLoss:136.3743 | CLSLoss:0.6542 | top1:93.1667 | AUROC:0.9811\n",
      "Test | 129/16 | Loss:15.0313 | MainLoss:1.3874 | SPLoss:136.3741 | CLSLoss:0.6542 | top1:64.0436 | AUROC:0.8643\n",
      "\n",
      "Epoch: [298 | 1000] LR: 0.003246\n",
      "Train | 16/16 | Loss:13.6437 | MainLoss:0.0677 | SPLoss:135.6939 | CLSLoss:0.6544 | top1:97.6267 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:13.6988 | MainLoss:0.2002 | SPLoss:134.9206 | CLSLoss:0.6544 | top1:93.3718 | AUROC:0.9810\n",
      "Test | 129/16 | Loss:14.9332 | MainLoss:1.4346 | SPLoss:134.9207 | CLSLoss:0.6544 | top1:63.4299 | AUROC:0.8632\n",
      "\n",
      "Epoch: [299 | 1000] LR: 0.003241\n",
      "Train | 16/16 | Loss:13.4987 | MainLoss:0.0671 | SPLoss:134.2507 | CLSLoss:0.6544 | top1:97.8933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:13.5563 | MainLoss:0.2010 | SPLoss:133.4868 | CLSLoss:0.6546 | top1:93.3077 | AUROC:0.9811\n",
      "Test | 129/16 | Loss:14.7723 | MainLoss:1.4170 | SPLoss:133.4869 | CLSLoss:0.6545 | top1:63.6231 | AUROC:0.8622\n",
      "\n",
      "Epoch: [300 | 1000] LR: 0.003236\n",
      "Train | 16/16 | Loss:13.3464 | MainLoss:0.0574 | SPLoss:132.8244 | CLSLoss:0.6547 | top1:98.2933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:13.4194 | MainLoss:0.2060 | SPLoss:132.0680 | CLSLoss:0.6550 | top1:93.1410 | AUROC:0.9808\n",
      "Test | 129/16 | Loss:14.5647 | MainLoss:1.3514 | SPLoss:132.0680 | CLSLoss:0.6550 | top1:64.7383 | AUROC:0.8652\n",
      "\n",
      "Epoch: [301 | 1000] LR: 0.003231\n",
      "Train | 16/16 | Loss:13.1998 | MainLoss:0.0520 | SPLoss:131.4126 | CLSLoss:0.6554 | top1:98.3467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:13.2741 | MainLoss:0.2010 | SPLoss:130.6647 | CLSLoss:0.6557 | top1:93.3462 | AUROC:0.9807\n",
      "Test | 129/16 | Loss:14.4975 | MainLoss:1.4245 | SPLoss:130.6649 | CLSLoss:0.6557 | top1:63.7632 | AUROC:0.8650\n",
      "\n",
      "Epoch: [302 | 1000] LR: 0.003226\n",
      "Train | 16/16 | Loss:13.0716 | MainLoss:0.0631 | SPLoss:130.0196 | CLSLoss:0.6558 | top1:97.8933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:13.1450 | MainLoss:0.2101 | SPLoss:129.2840 | CLSLoss:0.6560 | top1:93.0641 | AUROC:0.9807\n",
      "Test | 129/16 | Loss:14.2882 | MainLoss:1.3532 | SPLoss:129.2840 | CLSLoss:0.6560 | top1:64.9907 | AUROC:0.8668\n",
      "\n",
      "Epoch: [303 | 1000] LR: 0.003221\n",
      "Train | 16/16 | Loss:12.9222 | MainLoss:0.0512 | SPLoss:128.6445 | CLSLoss:0.6563 | top1:98.4000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:13.0052 | MainLoss:0.2071 | SPLoss:127.9154 | CLSLoss:0.6566 | top1:93.2436 | AUROC:0.9805\n",
      "Test | 129/16 | Loss:14.2050 | MainLoss:1.4069 | SPLoss:127.9152 | CLSLoss:0.6566 | top1:64.1807 | AUROC:0.8653\n",
      "\n",
      "Epoch: [304 | 1000] LR: 0.003216\n",
      "Train | 16/16 | Loss:12.8094 | MainLoss:0.0743 | SPLoss:127.2848 | CLSLoss:0.6564 | top1:97.5200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:12.8757 | MainLoss:0.2123 | SPLoss:126.5685 | CLSLoss:0.6561 | top1:93.0256 | AUROC:0.9804\n",
      "Test | 129/16 | Loss:14.0266 | MainLoss:1.3632 | SPLoss:126.5683 | CLSLoss:0.6561 | top1:64.7632 | AUROC:0.8638\n",
      "\n",
      "Epoch: [305 | 1000] LR: 0.003211\n",
      "Train | 16/16 | Loss:12.6690 | MainLoss:0.0680 | SPLoss:125.9438 | CLSLoss:0.6562 | top1:97.8133 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:12.7386 | MainLoss:0.2085 | SPLoss:125.2352 | CLSLoss:0.6562 | top1:93.0897 | AUROC:0.9800\n",
      "Test | 129/16 | Loss:13.9995 | MainLoss:1.4694 | SPLoss:125.2351 | CLSLoss:0.6562 | top1:62.9938 | AUROC:0.8608\n",
      "\n",
      "Epoch: [306 | 1000] LR: 0.003206\n",
      "Train | 16/16 | Loss:12.5403 | MainLoss:0.0718 | SPLoss:124.6189 | CLSLoss:0.6560 | top1:97.4667 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:12.6135 | MainLoss:0.2152 | SPLoss:123.9178 | CLSLoss:0.6559 | top1:92.8718 | AUROC:0.9801\n",
      "Test | 129/16 | Loss:13.7693 | MainLoss:1.3710 | SPLoss:123.9179 | CLSLoss:0.6559 | top1:64.4081 | AUROC:0.8665\n",
      "\n",
      "Epoch: [307 | 1000] LR: 0.003201\n",
      "Train | 16/16 | Loss:12.4063 | MainLoss:0.0689 | SPLoss:123.3089 | CLSLoss:0.6558 | top1:97.5200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:12.4809 | MainLoss:0.2128 | SPLoss:122.6155 | CLSLoss:0.6559 | top1:92.8846 | AUROC:0.9798\n",
      "Test | 129/16 | Loss:13.6358 | MainLoss:1.3677 | SPLoss:122.6153 | CLSLoss:0.6559 | top1:64.3988 | AUROC:0.8674\n",
      "\n",
      "Epoch: [308 | 1000] LR: 0.003196\n",
      "Train | 16/16 | Loss:12.2729 | MainLoss:0.0649 | SPLoss:122.0141 | CLSLoss:0.6561 | top1:97.9733 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:12.3501 | MainLoss:0.2105 | SPLoss:121.3299 | CLSLoss:0.6561 | top1:93.0641 | AUROC:0.9799\n",
      "Test | 129/16 | Loss:13.5438 | MainLoss:1.4043 | SPLoss:121.3300 | CLSLoss:0.6561 | top1:63.8629 | AUROC:0.8651\n",
      "\n",
      "Epoch: [309 | 1000] LR: 0.003191\n",
      "Train | 16/16 | Loss:12.1505 | MainLoss:0.0702 | SPLoss:120.7378 | CLSLoss:0.6561 | top1:97.7600 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:12.2233 | MainLoss:0.2104 | SPLoss:120.0636 | CLSLoss:0.6560 | top1:92.9615 | AUROC:0.9798\n",
      "Test | 129/16 | Loss:13.4163 | MainLoss:1.4033 | SPLoss:120.0637 | CLSLoss:0.6560 | top1:63.9065 | AUROC:0.8667\n",
      "\n",
      "Epoch: [310 | 1000] LR: 0.003186\n",
      "Train | 16/16 | Loss:12.0213 | MainLoss:0.0669 | SPLoss:119.4787 | CLSLoss:0.6559 | top1:97.8933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:12.1016 | MainLoss:0.2140 | SPLoss:118.8103 | CLSLoss:0.6561 | top1:92.9487 | AUROC:0.9803\n",
      "Test | 129/16 | Loss:13.2316 | MainLoss:1.3440 | SPLoss:118.8102 | CLSLoss:0.6561 | top1:64.7446 | AUROC:0.8679\n",
      "\n",
      "Epoch: [311 | 1000] LR: 0.003181\n",
      "Train | 16/16 | Loss:11.8890 | MainLoss:0.0594 | SPLoss:118.2309 | CLSLoss:0.6562 | top1:97.9467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:11.9778 | MainLoss:0.2141 | SPLoss:117.5719 | CLSLoss:0.6565 | top1:92.9103 | AUROC:0.9800\n",
      "Test | 129/16 | Loss:13.1351 | MainLoss:1.3714 | SPLoss:117.5720 | CLSLoss:0.6565 | top1:64.3364 | AUROC:0.8666\n",
      "\n",
      "Epoch: [312 | 1000] LR: 0.003176\n",
      "Train | 16/16 | Loss:11.7768 | MainLoss:0.0702 | SPLoss:116.9998 | CLSLoss:0.6566 | top1:97.6800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:11.8610 | MainLoss:0.2194 | SPLoss:116.3497 | CLSLoss:0.6565 | top1:92.8462 | AUROC:0.9799\n",
      "Test | 129/16 | Loss:12.9446 | MainLoss:1.3031 | SPLoss:116.3498 | CLSLoss:0.6565 | top1:65.3645 | AUROC:0.8672\n",
      "\n",
      "Epoch: [313 | 1000] LR: 0.003170\n",
      "Train | 16/16 | Loss:11.6581 | MainLoss:0.0730 | SPLoss:115.7848 | CLSLoss:0.6563 | top1:97.5467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:11.7371 | MainLoss:0.2164 | SPLoss:115.1415 | CLSLoss:0.6563 | top1:92.9359 | AUROC:0.9800\n",
      "Test | 129/16 | Loss:12.8463 | MainLoss:1.3255 | SPLoss:115.1417 | CLSLoss:0.6563 | top1:64.9502 | AUROC:0.8645\n",
      "\n",
      "Epoch: [314 | 1000] LR: 0.003165\n",
      "Train | 16/16 | Loss:11.5231 | MainLoss:0.0582 | SPLoss:114.5839 | CLSLoss:0.6567 | top1:98.2667 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:11.6219 | MainLoss:0.2205 | SPLoss:113.9487 | CLSLoss:0.6569 | top1:92.8462 | AUROC:0.9801\n",
      "Test | 129/16 | Loss:12.7295 | MainLoss:1.3281 | SPLoss:113.9488 | CLSLoss:0.6569 | top1:65.0966 | AUROC:0.8669\n",
      "\n",
      "Epoch: [315 | 1000] LR: 0.003160\n",
      "Train | 16/16 | Loss:11.4160 | MainLoss:0.0697 | SPLoss:113.3971 | CLSLoss:0.6568 | top1:97.6267 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:11.5001 | MainLoss:0.2166 | SPLoss:112.7699 | CLSLoss:0.6568 | top1:93.0897 | AUROC:0.9801\n",
      "Test | 129/16 | Loss:12.6387 | MainLoss:1.3552 | SPLoss:112.7700 | CLSLoss:0.6568 | top1:64.6542 | AUROC:0.8647\n",
      "\n",
      "Epoch: [316 | 1000] LR: 0.003155\n",
      "Train | 16/16 | Loss:11.3022 | MainLoss:0.0733 | SPLoss:112.2234 | CLSLoss:0.6567 | top1:97.3067 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:11.3787 | MainLoss:0.2119 | SPLoss:111.6027 | CLSLoss:0.6566 | top1:93.0769 | AUROC:0.9801\n",
      "Test | 129/16 | Loss:12.5455 | MainLoss:1.3787 | SPLoss:111.6028 | CLSLoss:0.6566 | top1:64.3084 | AUROC:0.8676\n",
      "\n",
      "Epoch: [317 | 1000] LR: 0.003150\n",
      "Train | 16/16 | Loss:11.1758 | MainLoss:0.0628 | SPLoss:111.0647 | CLSLoss:0.6567 | top1:97.8933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:11.2608 | MainLoss:0.2090 | SPLoss:110.4520 | CLSLoss:0.6568 | top1:93.1795 | AUROC:0.9803\n",
      "Test | 129/16 | Loss:12.5109 | MainLoss:1.4591 | SPLoss:110.4520 | CLSLoss:0.6568 | top1:63.1308 | AUROC:0.8628\n",
      "\n",
      "Epoch: [318 | 1000] LR: 0.003145\n",
      "Train | 16/16 | Loss:11.0676 | MainLoss:0.0690 | SPLoss:109.9197 | CLSLoss:0.6569 | top1:97.6800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:11.1500 | MainLoss:0.2121 | SPLoss:109.3135 | CLSLoss:0.6567 | top1:93.0513 | AUROC:0.9798\n",
      "Test | 129/16 | Loss:12.3442 | MainLoss:1.4062 | SPLoss:109.3137 | CLSLoss:0.6567 | top1:63.9284 | AUROC:0.8663\n",
      "\n",
      "Epoch: [319 | 1000] LR: 0.003140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 16/16 | Loss:10.9491 | MainLoss:0.0638 | SPLoss:108.7874 | CLSLoss:0.6566 | top1:97.8400 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:11.0381 | MainLoss:0.2127 | SPLoss:108.1880 | CLSLoss:0.6568 | top1:93.0897 | AUROC:0.9796\n",
      "Test | 129/16 | Loss:12.2306 | MainLoss:1.4053 | SPLoss:108.1880 | CLSLoss:0.6568 | top1:63.9595 | AUROC:0.8668\n",
      "\n",
      "Epoch: [320 | 1000] LR: 0.003135\n",
      "Train | 16/16 | Loss:10.8562 | MainLoss:0.0826 | SPLoss:107.6696 | CLSLoss:0.6564 | top1:96.9867 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:10.9257 | MainLoss:0.2112 | SPLoss:107.0793 | CLSLoss:0.6563 | top1:93.1026 | AUROC:0.9800\n",
      "Test | 129/16 | Loss:12.1045 | MainLoss:1.3900 | SPLoss:107.0793 | CLSLoss:0.6563 | top1:63.8660 | AUROC:0.8648\n",
      "\n",
      "Epoch: [321 | 1000] LR: 0.003129\n",
      "Train | 16/16 | Loss:10.7208 | MainLoss:0.0577 | SPLoss:106.5657 | CLSLoss:0.6566 | top1:98.1333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:10.8183 | MainLoss:0.2137 | SPLoss:105.9803 | CLSLoss:0.6569 | top1:93.0000 | AUROC:0.9796\n",
      "Test | 129/16 | Loss:11.9876 | MainLoss:1.3830 | SPLoss:105.9803 | CLSLoss:0.6569 | top1:64.2461 | AUROC:0.8675\n",
      "\n",
      "Epoch: [322 | 1000] LR: 0.003124\n",
      "Train | 16/16 | Loss:10.6267 | MainLoss:0.0729 | SPLoss:105.4725 | CLSLoss:0.6566 | top1:97.6800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:10.7070 | MainLoss:0.2107 | SPLoss:104.8966 | CLSLoss:0.6566 | top1:93.0000 | AUROC:0.9799\n",
      "Test | 129/16 | Loss:11.9037 | MainLoss:1.4074 | SPLoss:104.8967 | CLSLoss:0.6566 | top1:63.7508 | AUROC:0.8657\n",
      "\n",
      "Epoch: [323 | 1000] LR: 0.003119\n",
      "Train | 16/16 | Loss:10.4979 | MainLoss:0.0517 | SPLoss:104.3965 | CLSLoss:0.6570 | top1:98.2400 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:10.6028 | MainLoss:0.2137 | SPLoss:103.8252 | CLSLoss:0.6573 | top1:92.9231 | AUROC:0.9798\n",
      "Test | 129/16 | Loss:11.7892 | MainLoss:1.4001 | SPLoss:103.8251 | CLSLoss:0.6573 | top1:64.1153 | AUROC:0.8662\n",
      "\n",
      "Epoch: [324 | 1000] LR: 0.003114\n",
      "Train | 16/16 | Loss:10.4084 | MainLoss:0.0686 | SPLoss:103.3321 | CLSLoss:0.6574 | top1:97.7867 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:10.4926 | MainLoss:0.2091 | SPLoss:102.7692 | CLSLoss:0.6572 | top1:93.2308 | AUROC:0.9799\n",
      "Test | 129/16 | Loss:11.7693 | MainLoss:1.4858 | SPLoss:102.7691 | CLSLoss:0.6572 | top1:62.7352 | AUROC:0.8646\n",
      "\n",
      "Epoch: [325 | 1000] LR: 0.003109\n",
      "Train | 16/16 | Loss:10.2968 | MainLoss:0.0621 | SPLoss:102.2813 | CLSLoss:0.6573 | top1:97.7867 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:10.3900 | MainLoss:0.2108 | SPLoss:101.7255 | CLSLoss:0.6574 | top1:93.0641 | AUROC:0.9799\n",
      "Test | 129/16 | Loss:11.6184 | MainLoss:1.4393 | SPLoss:101.7253 | CLSLoss:0.6574 | top1:63.3333 | AUROC:0.8636\n",
      "\n",
      "Epoch: [326 | 1000] LR: 0.003103\n",
      "Train | 16/16 | Loss:10.1919 | MainLoss:0.0611 | SPLoss:101.2424 | CLSLoss:0.6572 | top1:98.1067 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:10.2881 | MainLoss:0.2123 | SPLoss:100.6915 | CLSLoss:0.6575 | top1:93.0256 | AUROC:0.9800\n",
      "Test | 129/16 | Loss:11.5196 | MainLoss:1.4438 | SPLoss:100.6913 | CLSLoss:0.6575 | top1:63.3551 | AUROC:0.8654\n",
      "\n",
      "Epoch: [327 | 1000] LR: 0.003098\n",
      "Train | 16/16 | Loss:10.1031 | MainLoss:0.0750 | SPLoss:100.2151 | CLSLoss:0.6575 | top1:97.2267 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:10.1868 | MainLoss:0.2130 | SPLoss:99.6726 | CLSLoss:0.6573 | top1:93.0128 | AUROC:0.9803\n",
      "Test | 129/16 | Loss:11.3865 | MainLoss:1.4127 | SPLoss:99.6727 | CLSLoss:0.6573 | top1:63.7103 | AUROC:0.8699\n",
      "\n",
      "Epoch: [328 | 1000] LR: 0.003093\n",
      "Train | 16/16 | Loss:9.9894 | MainLoss:0.0627 | SPLoss:99.2013 | CLSLoss:0.6574 | top1:97.9200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:10.0851 | MainLoss:0.2121 | SPLoss:98.6646 | CLSLoss:0.6575 | top1:93.0385 | AUROC:0.9800\n",
      "Test | 129/16 | Loss:11.3113 | MainLoss:1.4382 | SPLoss:98.6647 | CLSLoss:0.6575 | top1:63.3302 | AUROC:0.8668\n",
      "\n",
      "Epoch: [329 | 1000] LR: 0.003088\n",
      "Train | 16/16 | Loss:9.8842 | MainLoss:0.0578 | SPLoss:98.1990 | CLSLoss:0.6578 | top1:98.1867 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:9.9845 | MainLoss:0.2111 | SPLoss:97.6685 | CLSLoss:0.6578 | top1:93.1026 | AUROC:0.9798\n",
      "Test | 129/16 | Loss:11.2297 | MainLoss:1.4563 | SPLoss:97.6683 | CLSLoss:0.6578 | top1:63.1620 | AUROC:0.8664\n",
      "\n",
      "Epoch: [330 | 1000] LR: 0.003082\n",
      "Train | 16/16 | Loss:9.8097 | MainLoss:0.0821 | SPLoss:97.2105 | CLSLoss:0.6577 | top1:97.3333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:9.8915 | MainLoss:0.2160 | SPLoss:96.6890 | CLSLoss:0.6573 | top1:92.8205 | AUROC:0.9800\n",
      "Test | 129/16 | Loss:11.0762 | MainLoss:1.4007 | SPLoss:96.6890 | CLSLoss:0.6573 | top1:64.0156 | AUROC:0.8660\n",
      "\n",
      "Epoch: [331 | 1000] LR: 0.003077\n",
      "Train | 16/16 | Loss:9.7116 | MainLoss:0.0816 | SPLoss:96.2343 | CLSLoss:0.6571 | top1:97.4400 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:9.7868 | MainLoss:0.2085 | SPLoss:95.7175 | CLSLoss:0.6567 | top1:93.2051 | AUROC:0.9797\n",
      "Test | 129/16 | Loss:11.0195 | MainLoss:1.4412 | SPLoss:95.7177 | CLSLoss:0.6567 | top1:63.1464 | AUROC:0.8629\n",
      "\n",
      "Epoch: [332 | 1000] LR: 0.003072\n",
      "Train | 16/16 | Loss:9.6009 | MainLoss:0.0676 | SPLoss:95.2679 | CLSLoss:0.6566 | top1:97.6800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:9.6928 | MainLoss:0.2105 | SPLoss:94.7565 | CLSLoss:0.6566 | top1:93.0385 | AUROC:0.9798\n",
      "Test | 129/16 | Loss:10.9056 | MainLoss:1.4234 | SPLoss:94.7563 | CLSLoss:0.6566 | top1:63.4143 | AUROC:0.8591\n",
      "\n",
      "Epoch: [333 | 1000] LR: 0.003066\n",
      "Train | 16/16 | Loss:9.5132 | MainLoss:0.0754 | SPLoss:94.3131 | CLSLoss:0.6565 | top1:97.5467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:9.6004 | MainLoss:0.2129 | SPLoss:93.8089 | CLSLoss:0.6563 | top1:92.9103 | AUROC:0.9798\n",
      "Test | 129/16 | Loss:10.8105 | MainLoss:1.4231 | SPLoss:93.8090 | CLSLoss:0.6563 | top1:63.3988 | AUROC:0.8637\n",
      "\n",
      "Epoch: [334 | 1000] LR: 0.003061\n",
      "Train | 16/16 | Loss:9.4103 | MainLoss:0.0666 | SPLoss:93.3707 | CLSLoss:0.6564 | top1:97.8400 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:9.5078 | MainLoss:0.2142 | SPLoss:92.8704 | CLSLoss:0.6563 | top1:92.9231 | AUROC:0.9801\n",
      "Test | 129/16 | Loss:10.7045 | MainLoss:1.4109 | SPLoss:92.8703 | CLSLoss:0.6563 | top1:63.5732 | AUROC:0.8625\n",
      "\n",
      "Epoch: [335 | 1000] LR: 0.003056\n",
      "Train | 16/16 | Loss:9.3198 | MainLoss:0.0696 | SPLoss:92.4357 | CLSLoss:0.6562 | top1:97.6267 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:9.4146 | MainLoss:0.2138 | SPLoss:91.9424 | CLSLoss:0.6563 | top1:92.9872 | AUROC:0.9799\n",
      "Test | 129/16 | Loss:10.6143 | MainLoss:1.4135 | SPLoss:91.9423 | CLSLoss:0.6563 | top1:63.5981 | AUROC:0.8655\n",
      "\n",
      "Epoch: [336 | 1000] LR: 0.003050\n",
      "Train | 16/16 | Loss:9.2181 | MainLoss:0.0603 | SPLoss:91.5128 | CLSLoss:0.6566 | top1:98.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:9.3250 | MainLoss:0.2160 | SPLoss:91.0245 | CLSLoss:0.6567 | top1:92.8974 | AUROC:0.9796\n",
      "Test | 129/16 | Loss:10.5107 | MainLoss:1.4017 | SPLoss:91.0246 | CLSLoss:0.6567 | top1:63.8411 | AUROC:0.8644\n",
      "\n",
      "Epoch: [337 | 1000] LR: 0.003045\n",
      "Train | 16/16 | Loss:9.1338 | MainLoss:0.0670 | SPLoss:90.6017 | CLSLoss:0.6568 | top1:97.8133 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:9.2325 | MainLoss:0.2139 | SPLoss:90.1204 | CLSLoss:0.6568 | top1:92.9744 | AUROC:0.9796\n",
      "Test | 129/16 | Loss:10.4483 | MainLoss:1.4297 | SPLoss:90.1203 | CLSLoss:0.6568 | top1:63.3146 | AUROC:0.8633\n",
      "\n",
      "Epoch: [338 | 1000] LR: 0.003040\n",
      "Train | 16/16 | Loss:9.0544 | MainLoss:0.0776 | SPLoss:89.7026 | CLSLoss:0.6569 | top1:97.3867 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:9.1387 | MainLoss:0.2094 | SPLoss:89.2268 | CLSLoss:0.6564 | top1:93.1154 | AUROC:0.9799\n",
      "Test | 129/16 | Loss:10.4135 | MainLoss:1.4842 | SPLoss:89.2269 | CLSLoss:0.6564 | top1:62.4299 | AUROC:0.8591\n",
      "\n",
      "Epoch: [339 | 1000] LR: 0.003034\n",
      "Train | 16/16 | Loss:8.9538 | MainLoss:0.0659 | SPLoss:88.8139 | CLSLoss:0.6566 | top1:97.8667 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:9.0525 | MainLoss:0.2117 | SPLoss:88.3423 | CLSLoss:0.6566 | top1:92.9744 | AUROC:0.9798\n",
      "Test | 129/16 | Loss:10.2949 | MainLoss:1.4542 | SPLoss:88.3423 | CLSLoss:0.6566 | top1:62.8069 | AUROC:0.8615\n",
      "\n",
      "Epoch: [340 | 1000] LR: 0.003029\n",
      "Train | 16/16 | Loss:8.8572 | MainLoss:0.0572 | SPLoss:87.9342 | CLSLoss:0.6567 | top1:98.1333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:8.9726 | MainLoss:0.2191 | SPLoss:87.4693 | CLSLoss:0.6569 | top1:92.8590 | AUROC:0.9796\n",
      "Test | 129/16 | Loss:10.1313 | MainLoss:1.3778 | SPLoss:87.4693 | CLSLoss:0.6569 | top1:64.0779 | AUROC:0.8644\n",
      "\n",
      "Epoch: [341 | 1000] LR: 0.003023\n",
      "Train | 16/16 | Loss:8.7721 | MainLoss:0.0590 | SPLoss:87.0660 | CLSLoss:0.6568 | top1:98.1867 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:8.8853 | MainLoss:0.2183 | SPLoss:86.6042 | CLSLoss:0.6572 | top1:92.9872 | AUROC:0.9794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 129/16 | Loss:10.0708 | MainLoss:1.4038 | SPLoss:86.6041 | CLSLoss:0.6572 | top1:63.8162 | AUROC:0.8637\n",
      "\n",
      "Epoch: [342 | 1000] LR: 0.003018\n",
      "Train | 16/16 | Loss:8.6948 | MainLoss:0.0678 | SPLoss:86.2052 | CLSLoss:0.6573 | top1:97.6800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:8.7961 | MainLoss:0.2146 | SPLoss:85.7495 | CLSLoss:0.6573 | top1:92.9744 | AUROC:0.9789\n",
      "Test | 129/16 | Loss:10.0417 | MainLoss:1.4601 | SPLoss:85.7496 | CLSLoss:0.6573 | top1:63.1558 | AUROC:0.8627\n",
      "\n",
      "Epoch: [343 | 1000] LR: 0.003013\n",
      "Train | 16/16 | Loss:8.6032 | MainLoss:0.0610 | SPLoss:85.3565 | CLSLoss:0.6574 | top1:97.9200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:8.7184 | MainLoss:0.2211 | SPLoss:84.9080 | CLSLoss:0.6577 | top1:92.8974 | AUROC:0.9794\n",
      "Test | 129/16 | Loss:9.8937 | MainLoss:1.3964 | SPLoss:84.9080 | CLSLoss:0.6577 | top1:64.1776 | AUROC:0.8675\n",
      "\n",
      "Epoch: [344 | 1000] LR: 0.003007\n",
      "Train | 16/16 | Loss:8.5125 | MainLoss:0.0542 | SPLoss:84.5174 | CLSLoss:0.6579 | top1:98.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:8.6308 | MainLoss:0.2170 | SPLoss:84.0722 | CLSLoss:0.6582 | top1:92.9103 | AUROC:0.9794\n",
      "Test | 129/16 | Loss:9.8336 | MainLoss:1.4198 | SPLoss:84.0721 | CLSLoss:0.6582 | top1:63.8847 | AUROC:0.8684\n",
      "\n",
      "Epoch: [345 | 1000] LR: 0.003002\n",
      "Train | 16/16 | Loss:8.4354 | MainLoss:0.0601 | SPLoss:83.6870 | CLSLoss:0.6583 | top1:98.0800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:8.5513 | MainLoss:0.2199 | SPLoss:83.2490 | CLSLoss:0.6582 | top1:92.7949 | AUROC:0.9794\n",
      "Test | 129/16 | Loss:9.6918 | MainLoss:1.3603 | SPLoss:83.2490 | CLSLoss:0.6582 | top1:64.7632 | AUROC:0.8706\n",
      "\n",
      "Epoch: [346 | 1000] LR: 0.002996\n",
      "Train | 16/16 | Loss:8.3632 | MainLoss:0.0698 | SPLoss:82.8686 | CLSLoss:0.6582 | top1:97.5733 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:8.4698 | MainLoss:0.2195 | SPLoss:82.4373 | CLSLoss:0.6582 | top1:92.8718 | AUROC:0.9796\n",
      "Test | 129/16 | Loss:9.5991 | MainLoss:1.3488 | SPLoss:82.4373 | CLSLoss:0.6582 | top1:64.9907 | AUROC:0.8725\n",
      "\n",
      "Epoch: [347 | 1000] LR: 0.002991\n",
      "Train | 16/16 | Loss:8.2776 | MainLoss:0.0649 | SPLoss:82.0613 | CLSLoss:0.6581 | top1:97.8667 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:8.3822 | MainLoss:0.2124 | SPLoss:81.6321 | CLSLoss:0.6582 | top1:93.1026 | AUROC:0.9796\n",
      "Test | 129/16 | Loss:9.6063 | MainLoss:1.4365 | SPLoss:81.6320 | CLSLoss:0.6582 | top1:63.5763 | AUROC:0.8694\n",
      "\n",
      "Epoch: [348 | 1000] LR: 0.002985\n",
      "Train | 16/16 | Loss:8.2025 | MainLoss:0.0698 | SPLoss:81.2616 | CLSLoss:0.6579 | top1:97.6000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:8.3053 | MainLoss:0.2149 | SPLoss:80.8387 | CLSLoss:0.6580 | top1:93.0256 | AUROC:0.9795\n",
      "Test | 129/16 | Loss:9.4701 | MainLoss:1.3797 | SPLoss:80.8387 | CLSLoss:0.6580 | top1:64.3427 | AUROC:0.8716\n",
      "\n",
      "Epoch: [349 | 1000] LR: 0.002980\n",
      "Train | 16/16 | Loss:8.1223 | MainLoss:0.0684 | SPLoss:80.4734 | CLSLoss:0.6583 | top1:97.8667 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:8.2283 | MainLoss:0.2160 | SPLoss:80.0576 | CLSLoss:0.6579 | top1:92.9872 | AUROC:0.9799\n",
      "Test | 129/16 | Loss:9.3885 | MainLoss:1.3762 | SPLoss:80.0577 | CLSLoss:0.6579 | top1:64.2430 | AUROC:0.8665\n",
      "\n",
      "Epoch: [350 | 1000] LR: 0.002975\n",
      "Train | 16/16 | Loss:8.0317 | MainLoss:0.0557 | SPLoss:79.6944 | CLSLoss:0.6582 | top1:98.2933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:8.1483 | MainLoss:0.2136 | SPLoss:79.2812 | CLSLoss:0.6584 | top1:93.0769 | AUROC:0.9798\n",
      "Test | 129/16 | Loss:9.3586 | MainLoss:1.4239 | SPLoss:79.2811 | CLSLoss:0.6584 | top1:63.4579 | AUROC:0.8628\n",
      "\n",
      "Epoch: [351 | 1000] LR: 0.002969\n",
      "Train | 16/16 | Loss:7.9539 | MainLoss:0.0551 | SPLoss:78.9223 | CLSLoss:0.6586 | top1:98.1600 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:8.0740 | MainLoss:0.2163 | SPLoss:78.5119 | CLSLoss:0.6588 | top1:93.1410 | AUROC:0.9798\n",
      "Test | 129/16 | Loss:9.2634 | MainLoss:1.4056 | SPLoss:78.5120 | CLSLoss:0.6588 | top1:63.9315 | AUROC:0.8628\n",
      "\n",
      "Epoch: [352 | 1000] LR: 0.002964\n",
      "Train | 16/16 | Loss:7.8950 | MainLoss:0.0726 | SPLoss:78.1578 | CLSLoss:0.6587 | top1:97.6533 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:7.9981 | MainLoss:0.2161 | SPLoss:77.7545 | CLSLoss:0.6584 | top1:93.0641 | AUROC:0.9797\n",
      "Test | 129/16 | Loss:9.1917 | MainLoss:1.4096 | SPLoss:77.7546 | CLSLoss:0.6584 | top1:63.8411 | AUROC:0.8628\n",
      "\n",
      "Epoch: [353 | 1000] LR: 0.002958\n",
      "Train | 16/16 | Loss:7.8139 | MainLoss:0.0668 | SPLoss:77.4048 | CLSLoss:0.6585 | top1:97.7333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:7.9192 | MainLoss:0.2119 | SPLoss:77.0067 | CLSLoss:0.6585 | top1:93.0128 | AUROC:0.9798\n",
      "Test | 129/16 | Loss:9.1655 | MainLoss:1.4582 | SPLoss:77.0067 | CLSLoss:0.6585 | top1:63.1153 | AUROC:0.8611\n",
      "\n",
      "Epoch: [354 | 1000] LR: 0.002952\n",
      "Train | 16/16 | Loss:7.7261 | MainLoss:0.0537 | SPLoss:76.6586 | CLSLoss:0.6588 | top1:98.2667 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:7.8445 | MainLoss:0.2116 | SPLoss:76.2628 | CLSLoss:0.6589 | top1:93.0897 | AUROC:0.9794\n",
      "Test | 129/16 | Loss:9.0970 | MainLoss:1.4641 | SPLoss:76.2629 | CLSLoss:0.6589 | top1:63.0841 | AUROC:0.8633\n",
      "\n",
      "Epoch: [355 | 1000] LR: 0.002947\n",
      "Train | 16/16 | Loss:7.6703 | MainLoss:0.0717 | SPLoss:75.9200 | CLSLoss:0.6589 | top1:97.7867 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:7.7716 | MainLoss:0.2120 | SPLoss:75.5296 | CLSLoss:0.6585 | top1:93.0641 | AUROC:0.9797\n",
      "Test | 129/16 | Loss:8.9908 | MainLoss:1.4312 | SPLoss:75.5296 | CLSLoss:0.6585 | top1:63.5265 | AUROC:0.8683\n",
      "\n",
      "Epoch: [356 | 1000] LR: 0.002941\n",
      "Train | 16/16 | Loss:7.5982 | MainLoss:0.0725 | SPLoss:75.1916 | CLSLoss:0.6582 | top1:97.6533 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:7.6985 | MainLoss:0.2113 | SPLoss:74.8064 | CLSLoss:0.6583 | top1:93.0897 | AUROC:0.9800\n",
      "Test | 129/16 | Loss:8.9096 | MainLoss:1.4224 | SPLoss:74.8064 | CLSLoss:0.6583 | top1:63.6636 | AUROC:0.8683\n",
      "\n",
      "Epoch: [357 | 1000] LR: 0.002936\n",
      "Train | 16/16 | Loss:7.5142 | MainLoss:0.0604 | SPLoss:74.4724 | CLSLoss:0.6583 | top1:97.9200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:7.6323 | MainLoss:0.2166 | SPLoss:74.0917 | CLSLoss:0.6585 | top1:92.8846 | AUROC:0.9796\n",
      "Test | 129/16 | Loss:8.8091 | MainLoss:1.3933 | SPLoss:74.0917 | CLSLoss:0.6585 | top1:64.1745 | AUROC:0.8689\n",
      "\n",
      "Epoch: [358 | 1000] LR: 0.002930\n",
      "Train | 16/16 | Loss:7.4618 | MainLoss:0.0792 | SPLoss:73.7601 | CLSLoss:0.6582 | top1:97.3867 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:7.5572 | MainLoss:0.2122 | SPLoss:73.3843 | CLSLoss:0.6579 | top1:93.0897 | AUROC:0.9793\n",
      "Test | 129/16 | Loss:8.7350 | MainLoss:1.3900 | SPLoss:73.3844 | CLSLoss:0.6579 | top1:64.0623 | AUROC:0.8691\n",
      "\n",
      "Epoch: [359 | 1000] LR: 0.002925\n",
      "Train | 16/16 | Loss:7.3763 | MainLoss:0.0639 | SPLoss:73.0581 | CLSLoss:0.6580 | top1:97.7600 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:7.4895 | MainLoss:0.2142 | SPLoss:72.6873 | CLSLoss:0.6581 | top1:93.0897 | AUROC:0.9798\n",
      "Test | 129/16 | Loss:8.6698 | MainLoss:1.3945 | SPLoss:72.6874 | CLSLoss:0.6581 | top1:64.0561 | AUROC:0.8679\n",
      "\n",
      "Epoch: [360 | 1000] LR: 0.002919\n",
      "Train | 16/16 | Loss:7.3135 | MainLoss:0.0704 | SPLoss:72.3651 | CLSLoss:0.6581 | top1:97.4400 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:7.4176 | MainLoss:0.2112 | SPLoss:71.9982 | CLSLoss:0.6580 | top1:93.0897 | AUROC:0.9795\n",
      "Test | 129/16 | Loss:8.6222 | MainLoss:1.4158 | SPLoss:71.9981 | CLSLoss:0.6580 | top1:63.5888 | AUROC:0.8678\n",
      "\n",
      "Epoch: [361 | 1000] LR: 0.002914\n",
      "Train | 16/16 | Loss:7.2545 | MainLoss:0.0800 | SPLoss:71.6791 | CLSLoss:0.6577 | top1:97.3333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:7.3496 | MainLoss:0.2114 | SPLoss:71.3159 | CLSLoss:0.6574 | top1:93.0128 | AUROC:0.9798\n",
      "Test | 129/16 | Loss:8.5091 | MainLoss:1.3709 | SPLoss:71.3160 | CLSLoss:0.6574 | top1:64.2679 | AUROC:0.8683\n",
      "\n",
      "Epoch: [362 | 1000] LR: 0.002908\n",
      "Train | 16/16 | Loss:7.1692 | MainLoss:0.0625 | SPLoss:71.0010 | CLSLoss:0.6575 | top1:98.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:7.2837 | MainLoss:0.2130 | SPLoss:70.6409 | CLSLoss:0.6577 | top1:93.0256 | AUROC:0.9798\n",
      "Test | 129/16 | Loss:8.4521 | MainLoss:1.3814 | SPLoss:70.6410 | CLSLoss:0.6577 | top1:64.2243 | AUROC:0.8680\n",
      "\n",
      "Epoch: [363 | 1000] LR: 0.002902\n",
      "Train | 16/16 | Loss:7.1138 | MainLoss:0.0744 | SPLoss:70.3288 | CLSLoss:0.6576 | top1:97.4933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:7.2171 | MainLoss:0.2131 | SPLoss:69.9745 | CLSLoss:0.6577 | top1:92.9872 | AUROC:0.9794\n",
      "Test | 129/16 | Loss:8.3553 | MainLoss:1.3513 | SPLoss:69.9745 | CLSLoss:0.6577 | top1:64.8349 | AUROC:0.8782\n",
      "\n",
      "Epoch: [364 | 1000] LR: 0.002897\n",
      "Train | 16/16 | Loss:7.0268 | MainLoss:0.0535 | SPLoss:69.6666 | CLSLoss:0.6580 | top1:98.2667 | AUROC:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 32/16 | Loss:7.1550 | MainLoss:0.2169 | SPLoss:69.3152 | CLSLoss:0.6584 | top1:92.7949 | AUROC:0.9788\n",
      "Test | 129/16 | Loss:8.2690 | MainLoss:1.3309 | SPLoss:69.3151 | CLSLoss:0.6584 | top1:65.3427 | AUROC:0.8770\n",
      "\n",
      "Epoch: [365 | 1000] LR: 0.002891\n",
      "Train | 16/16 | Loss:6.9649 | MainLoss:0.0572 | SPLoss:69.0109 | CLSLoss:0.6587 | top1:98.1867 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:7.0909 | MainLoss:0.2180 | SPLoss:68.6631 | CLSLoss:0.6589 | top1:92.8462 | AUROC:0.9791\n",
      "Test | 129/16 | Loss:8.2065 | MainLoss:1.3336 | SPLoss:68.6630 | CLSLoss:0.6589 | top1:65.3676 | AUROC:0.8769\n",
      "\n",
      "Epoch: [366 | 1000] LR: 0.002886\n",
      "Train | 16/16 | Loss:6.9045 | MainLoss:0.0617 | SPLoss:68.3617 | CLSLoss:0.6590 | top1:97.7867 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:7.0274 | MainLoss:0.2188 | SPLoss:68.0202 | CLSLoss:0.6591 | top1:92.8462 | AUROC:0.9792\n",
      "Test | 129/16 | Loss:8.1434 | MainLoss:1.3348 | SPLoss:68.0201 | CLSLoss:0.6591 | top1:65.4548 | AUROC:0.8769\n",
      "\n",
      "Epoch: [367 | 1000] LR: 0.002880\n",
      "Train | 16/16 | Loss:6.8546 | MainLoss:0.0756 | SPLoss:67.7237 | CLSLoss:0.6590 | top1:97.3600 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:6.9619 | MainLoss:0.2167 | SPLoss:67.3862 | CLSLoss:0.6589 | top1:92.9615 | AUROC:0.9797\n",
      "Test | 129/16 | Loss:8.1020 | MainLoss:1.3568 | SPLoss:67.3861 | CLSLoss:0.6589 | top1:64.9875 | AUROC:0.8727\n",
      "\n",
      "Epoch: [368 | 1000] LR: 0.002874\n",
      "Train | 16/16 | Loss:6.7879 | MainLoss:0.0720 | SPLoss:67.0931 | CLSLoss:0.6587 | top1:97.4400 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:6.8966 | MainLoss:0.2141 | SPLoss:66.7585 | CLSLoss:0.6587 | top1:92.9872 | AUROC:0.9797\n",
      "Test | 129/16 | Loss:8.0662 | MainLoss:1.3837 | SPLoss:66.7585 | CLSLoss:0.6587 | top1:64.4424 | AUROC:0.8693\n",
      "\n",
      "Epoch: [369 | 1000] LR: 0.002869\n",
      "Train | 16/16 | Loss:6.7011 | MainLoss:0.0477 | SPLoss:66.4671 | CLSLoss:0.6592 | top1:98.6400 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:6.8354 | MainLoss:0.2153 | SPLoss:66.1351 | CLSLoss:0.6595 | top1:92.9744 | AUROC:0.9797\n",
      "Test | 129/16 | Loss:8.0164 | MainLoss:1.3963 | SPLoss:66.1351 | CLSLoss:0.6595 | top1:64.4891 | AUROC:0.8720\n",
      "\n",
      "Epoch: [370 | 1000] LR: 0.002863\n",
      "Train | 16/16 | Loss:6.6808 | MainLoss:0.0893 | SPLoss:65.8495 | CLSLoss:0.6592 | top1:96.8533 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:6.7727 | MainLoss:0.2137 | SPLoss:65.5234 | CLSLoss:0.6587 | top1:93.0128 | AUROC:0.9797\n",
      "Test | 129/16 | Loss:7.9317 | MainLoss:1.3728 | SPLoss:65.5235 | CLSLoss:0.6587 | top1:64.7477 | AUROC:0.8733\n",
      "\n",
      "Epoch: [371 | 1000] LR: 0.002857\n",
      "Train | 16/16 | Loss:6.5957 | MainLoss:0.0651 | SPLoss:65.2394 | CLSLoss:0.6588 | top1:97.8133 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:6.7102 | MainLoss:0.2121 | SPLoss:64.9156 | CLSLoss:0.6588 | top1:93.0897 | AUROC:0.9798\n",
      "Test | 129/16 | Loss:7.9058 | MainLoss:1.4076 | SPLoss:64.9155 | CLSLoss:0.6588 | top1:64.2492 | AUROC:0.8733\n",
      "\n",
      "Epoch: [372 | 1000] LR: 0.002852\n",
      "Train | 16/16 | Loss:6.5434 | MainLoss:0.0734 | SPLoss:64.6337 | CLSLoss:0.6588 | top1:97.4667 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:6.6558 | MainLoss:0.2178 | SPLoss:64.3140 | CLSLoss:0.6586 | top1:92.8974 | AUROC:0.9795\n",
      "Test | 129/16 | Loss:7.7775 | MainLoss:1.3395 | SPLoss:64.3140 | CLSLoss:0.6586 | top1:65.2305 | AUROC:0.8748\n",
      "\n",
      "Epoch: [373 | 1000] LR: 0.002846\n",
      "Train | 16/16 | Loss:6.4749 | MainLoss:0.0646 | SPLoss:64.0366 | CLSLoss:0.6588 | top1:98.0533 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:6.5983 | MainLoss:0.2197 | SPLoss:63.7202 | CLSLoss:0.6589 | top1:92.9359 | AUROC:0.9789\n",
      "Test | 129/16 | Loss:7.7587 | MainLoss:1.3801 | SPLoss:63.7201 | CLSLoss:0.6589 | top1:64.6386 | AUROC:0.8729\n",
      "\n",
      "Epoch: [374 | 1000] LR: 0.002840\n",
      "Train | 16/16 | Loss:6.4211 | MainLoss:0.0699 | SPLoss:63.4465 | CLSLoss:0.6588 | top1:97.4933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:6.5361 | MainLoss:0.2161 | SPLoss:63.1348 | CLSLoss:0.6589 | top1:92.9231 | AUROC:0.9789\n",
      "Test | 129/16 | Loss:7.7397 | MainLoss:1.4197 | SPLoss:63.1349 | CLSLoss:0.6589 | top1:64.0187 | AUROC:0.8713\n",
      "\n",
      "Epoch: [375 | 1000] LR: 0.002834\n",
      "Train | 16/16 | Loss:6.3606 | MainLoss:0.0675 | SPLoss:62.8648 | CLSLoss:0.6587 | top1:97.7867 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:6.4771 | MainLoss:0.2149 | SPLoss:62.5560 | CLSLoss:0.6588 | top1:92.9744 | AUROC:0.9794\n",
      "Test | 129/16 | Loss:7.6805 | MainLoss:1.4183 | SPLoss:62.5560 | CLSLoss:0.6588 | top1:64.0343 | AUROC:0.8683\n",
      "\n",
      "Epoch: [376 | 1000] LR: 0.002829\n",
      "Train | 16/16 | Loss:6.2995 | MainLoss:0.0640 | SPLoss:62.2895 | CLSLoss:0.6590 | top1:97.7600 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:6.4211 | MainLoss:0.2161 | SPLoss:61.9840 | CLSLoss:0.6591 | top1:92.9231 | AUROC:0.9789\n",
      "Test | 129/16 | Loss:7.6148 | MainLoss:1.4098 | SPLoss:61.9840 | CLSLoss:0.6591 | top1:64.2430 | AUROC:0.8710\n",
      "\n",
      "Epoch: [377 | 1000] LR: 0.002823\n",
      "Train | 16/16 | Loss:6.2360 | MainLoss:0.0575 | SPLoss:61.7188 | CLSLoss:0.6593 | top1:98.3200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:6.3667 | MainLoss:0.2184 | SPLoss:61.4170 | CLSLoss:0.6595 | top1:92.9615 | AUROC:0.9792\n",
      "Test | 129/16 | Loss:7.5161 | MainLoss:1.3678 | SPLoss:61.4170 | CLSLoss:0.6595 | top1:64.8879 | AUROC:0.8737\n",
      "\n",
      "Epoch: [378 | 1000] LR: 0.002817\n",
      "Train | 16/16 | Loss:6.1838 | MainLoss:0.0617 | SPLoss:61.1551 | CLSLoss:0.6596 | top1:98.1333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:6.3104 | MainLoss:0.2181 | SPLoss:60.8574 | CLSLoss:0.6598 | top1:93.0000 | AUROC:0.9794\n",
      "Test | 129/16 | Loss:7.4845 | MainLoss:1.3921 | SPLoss:60.8575 | CLSLoss:0.6598 | top1:64.5950 | AUROC:0.8718\n",
      "\n",
      "Epoch: [379 | 1000] LR: 0.002812\n",
      "Train | 16/16 | Loss:6.1236 | MainLoss:0.0572 | SPLoss:60.5979 | CLSLoss:0.6601 | top1:98.1867 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:6.2633 | MainLoss:0.2263 | SPLoss:60.3035 | CLSLoss:0.6602 | top1:92.6154 | AUROC:0.9793\n",
      "Test | 129/16 | Loss:7.3496 | MainLoss:1.3126 | SPLoss:60.3035 | CLSLoss:0.6602 | top1:65.9626 | AUROC:0.8798\n",
      "\n",
      "Epoch: [380 | 1000] LR: 0.002806\n",
      "Train | 16/16 | Loss:6.0723 | MainLoss:0.0611 | SPLoss:60.0461 | CLSLoss:0.6602 | top1:98.1333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:6.2053 | MainLoss:0.2232 | SPLoss:59.7545 | CLSLoss:0.6604 | top1:92.8590 | AUROC:0.9787\n",
      "Test | 129/16 | Loss:7.3674 | MainLoss:1.3853 | SPLoss:59.7545 | CLSLoss:0.6604 | top1:65.0748 | AUROC:0.8694\n",
      "\n",
      "Epoch: [381 | 1000] LR: 0.002800\n",
      "Train | 16/16 | Loss:6.0226 | MainLoss:0.0659 | SPLoss:59.5005 | CLSLoss:0.6604 | top1:97.9200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:6.1458 | MainLoss:0.2182 | SPLoss:59.2106 | CLSLoss:0.6601 | top1:92.7436 | AUROC:0.9791\n",
      "Test | 129/16 | Loss:7.3263 | MainLoss:1.3986 | SPLoss:59.2106 | CLSLoss:0.6601 | top1:64.5981 | AUROC:0.8740\n",
      "\n",
      "Epoch: [382 | 1000] LR: 0.002794\n",
      "Train | 16/16 | Loss:5.9755 | MainLoss:0.0728 | SPLoss:58.9616 | CLSLoss:0.6601 | top1:97.6267 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:6.0897 | MainLoss:0.2155 | SPLoss:58.6762 | CLSLoss:0.6599 | top1:92.8846 | AUROC:0.9791\n",
      "Test | 129/16 | Loss:7.3486 | MainLoss:1.4744 | SPLoss:58.6761 | CLSLoss:0.6599 | top1:63.1900 | AUROC:0.8379\n",
      "\n",
      "Epoch: [383 | 1000] LR: 0.002789\n",
      "Train | 16/16 | Loss:5.9360 | MainLoss:0.0864 | SPLoss:58.4304 | CLSLoss:0.6596 | top1:97.0933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:6.0404 | MainLoss:0.2188 | SPLoss:58.1500 | CLSLoss:0.6592 | top1:92.7179 | AUROC:0.9790\n",
      "Test | 129/16 | Loss:7.2552 | MainLoss:1.4336 | SPLoss:58.1500 | CLSLoss:0.6592 | top1:63.6355 | AUROC:0.8319\n",
      "\n",
      "Epoch: [384 | 1000] LR: 0.002783\n",
      "Train | 16/16 | Loss:5.8487 | MainLoss:0.0516 | SPLoss:57.9048 | CLSLoss:0.6594 | top1:98.4267 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:5.9838 | MainLoss:0.2147 | SPLoss:57.6251 | CLSLoss:0.6599 | top1:92.9744 | AUROC:0.9791\n",
      "Test | 129/16 | Loss:7.2575 | MainLoss:1.4883 | SPLoss:57.6250 | CLSLoss:0.6599 | top1:62.9284 | AUROC:0.8280\n",
      "\n",
      "Epoch: [385 | 1000] LR: 0.002777\n",
      "Train | 16/16 | Loss:5.8332 | MainLoss:0.0882 | SPLoss:57.3840 | CLSLoss:0.6594 | top1:97.2267 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:5.9318 | MainLoss:0.2144 | SPLoss:57.1084 | CLSLoss:0.6590 | top1:92.8205 | AUROC:0.9800\n",
      "Test | 129/16 | Loss:7.1492 | MainLoss:1.4317 | SPLoss:57.1085 | CLSLoss:0.6590 | top1:63.6698 | AUROC:0.8316\n",
      "\n",
      "Epoch: [386 | 1000] LR: 0.002771\n",
      "Train | 16/16 | Loss:5.7542 | MainLoss:0.0607 | SPLoss:56.8686 | CLSLoss:0.6591 | top1:98.1333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:5.8816 | MainLoss:0.2154 | SPLoss:56.5967 | CLSLoss:0.6593 | top1:92.8590 | AUROC:0.9796\n",
      "Test | 129/16 | Loss:7.0993 | MainLoss:1.4330 | SPLoss:56.5966 | CLSLoss:0.6593 | top1:63.6604 | AUROC:0.8300\n",
      "\n",
      "Epoch: [387 | 1000] LR: 0.002765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 16/16 | Loss:5.7285 | MainLoss:0.0857 | SPLoss:56.3612 | CLSLoss:0.6592 | top1:97.3333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:5.8399 | MainLoss:0.2240 | SPLoss:56.0935 | CLSLoss:0.6587 | top1:92.6923 | AUROC:0.9800\n",
      "Test | 129/16 | Loss:6.9675 | MainLoss:1.3515 | SPLoss:56.0935 | CLSLoss:0.6587 | top1:64.7290 | AUROC:0.8314\n",
      "\n",
      "Epoch: [388 | 1000] LR: 0.002760\n",
      "Train | 16/16 | Loss:5.6612 | MainLoss:0.0687 | SPLoss:55.8587 | CLSLoss:0.6585 | top1:97.5733 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:5.7788 | MainLoss:0.2130 | SPLoss:55.5919 | CLSLoss:0.6585 | top1:92.8718 | AUROC:0.9804\n",
      "Test | 129/16 | Loss:6.9854 | MainLoss:1.4196 | SPLoss:55.5919 | CLSLoss:0.6585 | top1:63.7757 | AUROC:0.8281\n",
      "\n",
      "Epoch: [389 | 1000] LR: 0.002754\n",
      "Train | 16/16 | Loss:5.5944 | MainLoss:0.0519 | SPLoss:55.3583 | CLSLoss:0.6588 | top1:98.2667 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:5.7290 | MainLoss:0.2129 | SPLoss:55.0947 | CLSLoss:0.6591 | top1:92.9231 | AUROC:0.9799\n",
      "Test | 129/16 | Loss:6.9643 | MainLoss:1.4482 | SPLoss:55.0946 | CLSLoss:0.6591 | top1:63.4393 | AUROC:0.8304\n",
      "\n",
      "Epoch: [390 | 1000] LR: 0.002748\n",
      "Train | 16/16 | Loss:5.5636 | MainLoss:0.0705 | SPLoss:54.8657 | CLSLoss:0.6591 | top1:97.5200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:5.6811 | MainLoss:0.2140 | SPLoss:54.6049 | CLSLoss:0.6589 | top1:93.0000 | AUROC:0.9798\n",
      "Test | 129/16 | Loss:6.8999 | MainLoss:1.4328 | SPLoss:54.6050 | CLSLoss:0.6589 | top1:63.6106 | AUROC:0.8290\n",
      "\n",
      "Epoch: [391 | 1000] LR: 0.002742\n",
      "Train | 16/16 | Loss:5.5196 | MainLoss:0.0751 | SPLoss:54.3784 | CLSLoss:0.6589 | top1:97.1200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:5.6319 | MainLoss:0.2132 | SPLoss:54.1209 | CLSLoss:0.6587 | top1:92.8590 | AUROC:0.9797\n",
      "Test | 129/16 | Loss:6.8332 | MainLoss:1.4145 | SPLoss:54.1210 | CLSLoss:0.6587 | top1:63.6822 | AUROC:0.8298\n",
      "\n",
      "Epoch: [392 | 1000] LR: 0.002736\n",
      "Train | 16/16 | Loss:5.4699 | MainLoss:0.0736 | SPLoss:53.8975 | CLSLoss:0.6586 | top1:97.5467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:5.5803 | MainLoss:0.2095 | SPLoss:53.6424 | CLSLoss:0.6587 | top1:93.0385 | AUROC:0.9798\n",
      "Test | 129/16 | Loss:6.8348 | MainLoss:1.4640 | SPLoss:53.6424 | CLSLoss:0.6587 | top1:62.9221 | AUROC:0.8277\n",
      "\n",
      "Epoch: [393 | 1000] LR: 0.002730\n",
      "Train | 16/16 | Loss:5.4218 | MainLoss:0.0730 | SPLoss:53.4216 | CLSLoss:0.6587 | top1:97.5733 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:5.5335 | MainLoss:0.2100 | SPLoss:53.1692 | CLSLoss:0.6587 | top1:93.0385 | AUROC:0.9799\n",
      "Test | 129/16 | Loss:6.7631 | MainLoss:1.4396 | SPLoss:53.1691 | CLSLoss:0.6587 | top1:63.4486 | AUROC:0.8328\n",
      "\n",
      "Epoch: [394 | 1000] LR: 0.002725\n",
      "Train | 16/16 | Loss:5.3915 | MainLoss:0.0897 | SPLoss:52.9517 | CLSLoss:0.6583 | top1:96.8800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:5.4853 | MainLoss:0.2084 | SPLoss:52.7031 | CLSLoss:0.6580 | top1:93.0513 | AUROC:0.9799\n",
      "Test | 129/16 | Loss:6.6867 | MainLoss:1.4099 | SPLoss:52.7031 | CLSLoss:0.6580 | top1:63.7539 | AUROC:0.8361\n",
      "\n",
      "Epoch: [395 | 1000] LR: 0.002719\n",
      "Train | 16/16 | Loss:5.3154 | MainLoss:0.0602 | SPLoss:52.4860 | CLSLoss:0.6582 | top1:98.0800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:5.4382 | MainLoss:0.2078 | SPLoss:52.2382 | CLSLoss:0.6582 | top1:93.0256 | AUROC:0.9802\n",
      "Test | 129/16 | Loss:6.6781 | MainLoss:1.4477 | SPLoss:52.2382 | CLSLoss:0.6582 | top1:63.1963 | AUROC:0.8332\n",
      "\n",
      "Epoch: [396 | 1000] LR: 0.002713\n",
      "Train | 16/16 | Loss:5.2807 | MainLoss:0.0718 | SPLoss:52.0240 | CLSLoss:0.6583 | top1:97.7600 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:5.3965 | MainLoss:0.2120 | SPLoss:51.7795 | CLSLoss:0.6580 | top1:93.0385 | AUROC:0.9796\n",
      "Test | 129/16 | Loss:6.5778 | MainLoss:1.3932 | SPLoss:51.7795 | CLSLoss:0.6580 | top1:64.0561 | AUROC:0.8387\n",
      "\n",
      "Epoch: [397 | 1000] LR: 0.002707\n",
      "Train | 16/16 | Loss:5.2361 | MainLoss:0.0726 | SPLoss:51.5690 | CLSLoss:0.6579 | top1:97.3333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:5.3482 | MainLoss:0.2088 | SPLoss:51.3278 | CLSLoss:0.6580 | top1:93.0513 | AUROC:0.9798\n",
      "Test | 129/16 | Loss:6.5859 | MainLoss:1.4466 | SPLoss:51.3279 | CLSLoss:0.6580 | top1:63.1277 | AUROC:0.8336\n",
      "\n",
      "Epoch: [398 | 1000] LR: 0.002701\n",
      "Train | 16/16 | Loss:5.1880 | MainLoss:0.0693 | SPLoss:51.1210 | CLSLoss:0.6581 | top1:97.6533 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:5.3030 | MainLoss:0.2081 | SPLoss:50.8835 | CLSLoss:0.6582 | top1:93.0256 | AUROC:0.9797\n",
      "Test | 129/16 | Loss:6.5370 | MainLoss:1.4421 | SPLoss:50.8835 | CLSLoss:0.6582 | top1:63.2555 | AUROC:0.8345\n",
      "\n",
      "Epoch: [399 | 1000] LR: 0.002695\n",
      "Train | 16/16 | Loss:5.1550 | MainLoss:0.0806 | SPLoss:50.6784 | CLSLoss:0.6579 | top1:97.4400 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:5.2618 | MainLoss:0.2109 | SPLoss:50.4434 | CLSLoss:0.6578 | top1:92.9615 | AUROC:0.9802\n",
      "Test | 129/16 | Loss:6.4331 | MainLoss:1.3822 | SPLoss:50.4435 | CLSLoss:0.6578 | top1:64.1184 | AUROC:0.8399\n",
      "\n",
      "Epoch: [400 | 1000] LR: 0.002689\n",
      "Train | 16/16 | Loss:5.1018 | MainLoss:0.0713 | SPLoss:50.2386 | CLSLoss:0.6578 | top1:97.7600 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:5.2137 | MainLoss:0.2066 | SPLoss:50.0055 | CLSLoss:0.6578 | top1:93.0385 | AUROC:0.9800\n",
      "Test | 129/16 | Loss:6.4549 | MainLoss:1.4477 | SPLoss:50.0055 | CLSLoss:0.6578 | top1:63.2056 | AUROC:0.8388\n",
      "\n",
      "Epoch: [401 | 1000] LR: 0.002683\n",
      "Train | 16/16 | Loss:5.0502 | MainLoss:0.0632 | SPLoss:49.8040 | CLSLoss:0.6579 | top1:97.8933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:5.1775 | MainLoss:0.2135 | SPLoss:49.5741 | CLSLoss:0.6581 | top1:92.8077 | AUROC:0.9803\n",
      "Test | 129/16 | Loss:6.3338 | MainLoss:1.3698 | SPLoss:49.5740 | CLSLoss:0.6581 | top1:64.4361 | AUROC:0.8423\n",
      "\n",
      "Epoch: [402 | 1000] LR: 0.002677\n",
      "Train | 16/16 | Loss:5.0099 | MainLoss:0.0661 | SPLoss:49.3725 | CLSLoss:0.6581 | top1:97.8400 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:5.1332 | MainLoss:0.2122 | SPLoss:49.1442 | CLSLoss:0.6581 | top1:92.9744 | AUROC:0.9801\n",
      "Test | 129/16 | Loss:6.3226 | MainLoss:1.4016 | SPLoss:49.1441 | CLSLoss:0.6581 | top1:63.8847 | AUROC:0.8374\n",
      "\n",
      "Epoch: [403 | 1000] LR: 0.002672\n",
      "Train | 16/16 | Loss:4.9656 | MainLoss:0.0646 | SPLoss:48.9445 | CLSLoss:0.6580 | top1:98.0267 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:5.0915 | MainLoss:0.2130 | SPLoss:48.7186 | CLSLoss:0.6581 | top1:92.9744 | AUROC:0.9798\n",
      "Test | 129/16 | Loss:6.2756 | MainLoss:1.3972 | SPLoss:48.7185 | CLSLoss:0.6581 | top1:63.9408 | AUROC:0.8375\n",
      "\n",
      "Epoch: [404 | 1000] LR: 0.002666\n",
      "Train | 16/16 | Loss:4.9323 | MainLoss:0.0734 | SPLoss:48.5229 | CLSLoss:0.6580 | top1:97.5200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:5.0446 | MainLoss:0.2081 | SPLoss:48.2994 | CLSLoss:0.6581 | top1:93.0641 | AUROC:0.9806\n",
      "Test | 129/16 | Loss:6.2705 | MainLoss:1.4339 | SPLoss:48.2994 | CLSLoss:0.6581 | top1:63.4112 | AUROC:0.8366\n",
      "\n",
      "Epoch: [405 | 1000] LR: 0.002660\n",
      "Train | 16/16 | Loss:4.8753 | MainLoss:0.0580 | SPLoss:48.1063 | CLSLoss:0.6582 | top1:98.2933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:5.0129 | MainLoss:0.2177 | SPLoss:47.8858 | CLSLoss:0.6584 | top1:92.7949 | AUROC:0.9800\n",
      "Test | 129/16 | Loss:6.1552 | MainLoss:1.3600 | SPLoss:47.8858 | CLSLoss:0.6584 | top1:64.7414 | AUROC:0.8398\n",
      "\n",
      "Epoch: [406 | 1000] LR: 0.002654\n",
      "Train | 16/16 | Loss:4.8604 | MainLoss:0.0843 | SPLoss:47.6945 | CLSLoss:0.6578 | top1:97.2533 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:4.9685 | MainLoss:0.2144 | SPLoss:47.4754 | CLSLoss:0.6577 | top1:92.9872 | AUROC:0.9797\n",
      "Test | 129/16 | Loss:6.1308 | MainLoss:1.3767 | SPLoss:47.4755 | CLSLoss:0.6577 | top1:64.2118 | AUROC:0.8387\n",
      "\n",
      "Epoch: [407 | 1000] LR: 0.002648\n",
      "Train | 16/16 | Loss:4.7923 | MainLoss:0.0571 | SPLoss:47.2865 | CLSLoss:0.6579 | top1:98.2400 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:4.9245 | MainLoss:0.2110 | SPLoss:47.0692 | CLSLoss:0.6581 | top1:93.0385 | AUROC:0.9797\n",
      "Test | 129/16 | Loss:6.1683 | MainLoss:1.4548 | SPLoss:47.0691 | CLSLoss:0.6581 | top1:63.1433 | AUROC:0.8361\n",
      "\n",
      "Epoch: [408 | 1000] LR: 0.002642\n",
      "Train | 16/16 | Loss:4.7480 | MainLoss:0.0532 | SPLoss:46.8819 | CLSLoss:0.6583 | top1:98.4800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:4.8884 | MainLoss:0.2149 | SPLoss:46.6682 | CLSLoss:0.6586 | top1:93.0128 | AUROC:0.9798\n",
      "Test | 129/16 | Loss:6.0984 | MainLoss:1.4249 | SPLoss:46.6682 | CLSLoss:0.6586 | top1:63.7664 | AUROC:0.8392\n",
      "\n",
      "Epoch: [409 | 1000] LR: 0.002636\n",
      "Train | 16/16 | Loss:4.7188 | MainLoss:0.0638 | SPLoss:46.4842 | CLSLoss:0.6586 | top1:98.0533 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:4.8493 | MainLoss:0.2153 | SPLoss:46.2737 | CLSLoss:0.6585 | top1:92.9359 | AUROC:0.9798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 129/16 | Loss:6.0891 | MainLoss:1.4552 | SPLoss:46.2737 | CLSLoss:0.6585 | top1:63.3427 | AUROC:0.8360\n",
      "\n",
      "Epoch: [410 | 1000] LR: 0.002630\n",
      "Train | 16/16 | Loss:4.6840 | MainLoss:0.0684 | SPLoss:46.0910 | CLSLoss:0.6583 | top1:97.8667 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:4.8112 | MainLoss:0.2162 | SPLoss:45.8842 | CLSLoss:0.6583 | top1:92.8974 | AUROC:0.9801\n",
      "Test | 129/16 | Loss:6.0543 | MainLoss:1.4593 | SPLoss:45.8842 | CLSLoss:0.6583 | top1:63.2586 | AUROC:0.8327\n",
      "\n",
      "Epoch: [411 | 1000] LR: 0.002624\n",
      "Train | 16/16 | Loss:4.6467 | MainLoss:0.0699 | SPLoss:45.7024 | CLSLoss:0.6583 | top1:97.7333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:4.7683 | MainLoss:0.2122 | SPLoss:45.4951 | CLSLoss:0.6583 | top1:92.9359 | AUROC:0.9798\n",
      "Test | 129/16 | Loss:6.0756 | MainLoss:1.5195 | SPLoss:45.4950 | CLSLoss:0.6583 | top1:62.4050 | AUROC:0.8315\n",
      "\n",
      "Epoch: [412 | 1000] LR: 0.002618\n",
      "Train | 16/16 | Loss:4.6062 | MainLoss:0.0680 | SPLoss:45.3162 | CLSLoss:0.6581 | top1:97.7600 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:4.7335 | MainLoss:0.2158 | SPLoss:45.1117 | CLSLoss:0.6582 | top1:92.9615 | AUROC:0.9797\n",
      "Test | 129/16 | Loss:5.9476 | MainLoss:1.4299 | SPLoss:45.1116 | CLSLoss:0.6582 | top1:63.6199 | AUROC:0.8360\n",
      "\n",
      "Epoch: [413 | 1000] LR: 0.002612\n",
      "Train | 16/16 | Loss:4.5745 | MainLoss:0.0745 | SPLoss:44.9341 | CLSLoss:0.6580 | top1:97.6533 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:4.6887 | MainLoss:0.2088 | SPLoss:44.7326 | CLSLoss:0.6578 | top1:93.0897 | AUROC:0.9802\n",
      "Test | 129/16 | Loss:5.9247 | MainLoss:1.4448 | SPLoss:44.7325 | CLSLoss:0.6578 | top1:63.3645 | AUROC:0.8376\n",
      "\n",
      "Epoch: [414 | 1000] LR: 0.002606\n",
      "Train | 16/16 | Loss:4.5176 | MainLoss:0.0553 | SPLoss:44.5571 | CLSLoss:0.6580 | top1:98.2400 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:4.6537 | MainLoss:0.2115 | SPLoss:44.3561 | CLSLoss:0.6580 | top1:92.9359 | AUROC:0.9799\n",
      "Test | 129/16 | Loss:5.8682 | MainLoss:1.4260 | SPLoss:44.3561 | CLSLoss:0.6580 | top1:63.7103 | AUROC:0.8376\n",
      "\n",
      "Epoch: [415 | 1000] LR: 0.002600\n",
      "Train | 16/16 | Loss:4.4930 | MainLoss:0.0681 | SPLoss:44.1829 | CLSLoss:0.6580 | top1:97.8667 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:4.6170 | MainLoss:0.2117 | SPLoss:43.9865 | CLSLoss:0.6579 | top1:92.9744 | AUROC:0.9797\n",
      "Test | 129/16 | Loss:5.8383 | MainLoss:1.4331 | SPLoss:43.9865 | CLSLoss:0.6579 | top1:63.4891 | AUROC:0.8330\n",
      "\n",
      "Epoch: [416 | 1000] LR: 0.002594\n",
      "Train | 16/16 | Loss:4.4423 | MainLoss:0.0543 | SPLoss:43.8147 | CLSLoss:0.6581 | top1:98.1867 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:4.5825 | MainLoss:0.2141 | SPLoss:43.6178 | CLSLoss:0.6583 | top1:92.8846 | AUROC:0.9799\n",
      "Test | 129/16 | Loss:5.8093 | MainLoss:1.4410 | SPLoss:43.6178 | CLSLoss:0.6583 | top1:63.4704 | AUROC:0.8299\n",
      "\n",
      "Epoch: [417 | 1000] LR: 0.002588\n",
      "Train | 16/16 | Loss:4.4196 | MainLoss:0.0683 | SPLoss:43.4472 | CLSLoss:0.6583 | top1:97.9200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:4.5419 | MainLoss:0.2100 | SPLoss:43.2532 | CLSLoss:0.6582 | top1:92.9744 | AUROC:0.9797\n",
      "Test | 129/16 | Loss:5.8202 | MainLoss:1.4883 | SPLoss:43.2532 | CLSLoss:0.6582 | top1:62.6449 | AUROC:0.8257\n",
      "\n",
      "Epoch: [418 | 1000] LR: 0.002582\n",
      "Train | 16/16 | Loss:4.3777 | MainLoss:0.0625 | SPLoss:43.0861 | CLSLoss:0.6581 | top1:97.9733 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:4.5111 | MainLoss:0.2151 | SPLoss:42.8947 | CLSLoss:0.6583 | top1:92.8590 | AUROC:0.9792\n",
      "Test | 129/16 | Loss:5.7074 | MainLoss:1.4113 | SPLoss:42.8947 | CLSLoss:0.6583 | top1:63.9751 | AUROC:0.8317\n",
      "\n",
      "Epoch: [419 | 1000] LR: 0.002576\n",
      "Train | 16/16 | Loss:4.3444 | MainLoss:0.0650 | SPLoss:42.7280 | CLSLoss:0.6583 | top1:97.7867 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:4.4751 | MainLoss:0.2147 | SPLoss:42.5384 | CLSLoss:0.6584 | top1:92.9103 | AUROC:0.9794\n",
      "Test | 129/16 | Loss:5.6890 | MainLoss:1.4286 | SPLoss:42.5385 | CLSLoss:0.6584 | top1:63.8287 | AUROC:0.8352\n",
      "\n",
      "Epoch: [420 | 1000] LR: 0.002570\n",
      "Train | 16/16 | Loss:4.3212 | MainLoss:0.0772 | SPLoss:42.3741 | CLSLoss:0.6583 | top1:97.6267 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:4.4435 | MainLoss:0.2183 | SPLoss:42.1865 | CLSLoss:0.6581 | top1:92.8077 | AUROC:0.9796\n",
      "Test | 129/16 | Loss:5.5898 | MainLoss:1.3646 | SPLoss:42.1865 | CLSLoss:0.6581 | top1:64.7850 | AUROC:0.8404\n",
      "\n",
      "Epoch: [421 | 1000] LR: 0.002564\n",
      "Train | 16/16 | Loss:4.2727 | MainLoss:0.0638 | SPLoss:42.0233 | CLSLoss:0.6581 | top1:98.0533 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:4.4097 | MainLoss:0.2192 | SPLoss:41.8390 | CLSLoss:0.6582 | top1:92.7692 | AUROC:0.9800\n",
      "Test | 129/16 | Loss:5.5616 | MainLoss:1.3711 | SPLoss:41.8390 | CLSLoss:0.6582 | top1:64.7601 | AUROC:0.8426\n",
      "\n",
      "Epoch: [422 | 1000] LR: 0.002558\n",
      "Train | 16/16 | Loss:4.2382 | MainLoss:0.0638 | SPLoss:41.6789 | CLSLoss:0.6583 | top1:97.8933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:4.3721 | MainLoss:0.2159 | SPLoss:41.4961 | CLSLoss:0.6584 | top1:93.0000 | AUROC:0.9798\n",
      "Test | 129/16 | Loss:5.5658 | MainLoss:1.4096 | SPLoss:41.4960 | CLSLoss:0.6584 | top1:64.1277 | AUROC:0.8397\n",
      "\n",
      "Epoch: [423 | 1000] LR: 0.002552\n",
      "Train | 16/16 | Loss:4.2014 | MainLoss:0.0611 | SPLoss:41.3373 | CLSLoss:0.6585 | top1:97.8667 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:4.3364 | MainLoss:0.2140 | SPLoss:41.1574 | CLSLoss:0.6586 | top1:92.9615 | AUROC:0.9800\n",
      "Test | 129/16 | Loss:5.5889 | MainLoss:1.4665 | SPLoss:41.1573 | CLSLoss:0.6586 | top1:63.1433 | AUROC:0.8349\n",
      "\n",
      "Epoch: [424 | 1000] LR: 0.002546\n",
      "Train | 16/16 | Loss:4.1662 | MainLoss:0.0595 | SPLoss:41.0006 | CLSLoss:0.6587 | top1:98.1333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:4.3091 | MainLoss:0.2204 | SPLoss:40.8216 | CLSLoss:0.6588 | top1:92.7308 | AUROC:0.9798\n",
      "Test | 129/16 | Loss:5.4728 | MainLoss:1.3840 | SPLoss:40.8215 | CLSLoss:0.6588 | top1:64.5545 | AUROC:0.8407\n",
      "\n",
      "Epoch: [425 | 1000] LR: 0.002540\n",
      "Train | 16/16 | Loss:4.1413 | MainLoss:0.0682 | SPLoss:40.6658 | CLSLoss:0.6589 | top1:97.6800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:4.2704 | MainLoss:0.2148 | SPLoss:40.4895 | CLSLoss:0.6587 | top1:93.0385 | AUROC:0.9799\n",
      "Test | 129/16 | Loss:5.4766 | MainLoss:1.4211 | SPLoss:40.4895 | CLSLoss:0.6587 | top1:63.8567 | AUROC:0.8374\n",
      "\n",
      "Epoch: [426 | 1000] LR: 0.002534\n",
      "Train | 16/16 | Loss:4.1047 | MainLoss:0.0645 | SPLoss:40.3356 | CLSLoss:0.6588 | top1:97.7867 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:4.2395 | MainLoss:0.2168 | SPLoss:40.1612 | CLSLoss:0.6588 | top1:92.8590 | AUROC:0.9799\n",
      "Test | 129/16 | Loss:5.4342 | MainLoss:1.4115 | SPLoss:40.1612 | CLSLoss:0.6588 | top1:63.9284 | AUROC:0.8375\n",
      "\n",
      "Epoch: [427 | 1000] LR: 0.002528\n",
      "Train | 16/16 | Loss:4.0827 | MainLoss:0.0752 | SPLoss:40.0093 | CLSLoss:0.6585 | top1:97.4400 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:4.2023 | MainLoss:0.2122 | SPLoss:39.8353 | CLSLoss:0.6585 | top1:92.9872 | AUROC:0.9796\n",
      "Test | 129/16 | Loss:5.4559 | MainLoss:1.4658 | SPLoss:39.8353 | CLSLoss:0.6585 | top1:63.1745 | AUROC:0.8335\n",
      "\n",
      "Epoch: [428 | 1000] LR: 0.002522\n",
      "Train | 16/16 | Loss:4.0329 | MainLoss:0.0578 | SPLoss:39.6847 | CLSLoss:0.6586 | top1:98.2933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:4.1819 | MainLoss:0.2240 | SPLoss:39.5135 | CLSLoss:0.6587 | top1:92.6667 | AUROC:0.9800\n",
      "Test | 129/16 | Loss:5.3085 | MainLoss:1.3506 | SPLoss:39.5135 | CLSLoss:0.6587 | top1:64.9751 | AUROC:0.8395\n",
      "\n",
      "Epoch: [429 | 1000] LR: 0.002516\n",
      "Train | 16/16 | Loss:4.0136 | MainLoss:0.0706 | SPLoss:39.3648 | CLSLoss:0.6586 | top1:97.5733 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:4.1389 | MainLoss:0.2128 | SPLoss:39.1950 | CLSLoss:0.6586 | top1:92.9487 | AUROC:0.9796\n",
      "Test | 129/16 | Loss:5.3850 | MainLoss:1.4589 | SPLoss:39.1950 | CLSLoss:0.6586 | top1:63.3427 | AUROC:0.8344\n",
      "\n",
      "Epoch: [430 | 1000] LR: 0.002510\n",
      "Train | 16/16 | Loss:3.9753 | MainLoss:0.0639 | SPLoss:39.0480 | CLSLoss:0.6587 | top1:97.7600 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:4.1092 | MainLoss:0.2144 | SPLoss:38.8819 | CLSLoss:0.6587 | top1:92.9359 | AUROC:0.9797\n",
      "Test | 129/16 | Loss:5.3476 | MainLoss:1.4528 | SPLoss:38.8820 | CLSLoss:0.6587 | top1:63.4673 | AUROC:0.8338\n",
      "\n",
      "Epoch: [431 | 1000] LR: 0.002503\n",
      "Train | 16/16 | Loss:3.9517 | MainLoss:0.0715 | SPLoss:38.7368 | CLSLoss:0.6587 | top1:97.9733 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:4.0875 | MainLoss:0.2238 | SPLoss:38.5712 | CLSLoss:0.6585 | top1:92.6026 | AUROC:0.9798\n",
      "Test | 129/16 | Loss:5.2333 | MainLoss:1.3696 | SPLoss:38.5712 | CLSLoss:0.6585 | top1:64.6168 | AUROC:0.8321\n",
      "\n",
      "Epoch: [432 | 1000] LR: 0.002497\n",
      "Train | 16/16 | Loss:3.9147 | MainLoss:0.0655 | SPLoss:38.4269 | CLSLoss:0.6585 | top1:97.6267 | AUROC:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 32/16 | Loss:4.0492 | MainLoss:0.2162 | SPLoss:38.2641 | CLSLoss:0.6586 | top1:92.8974 | AUROC:0.9799\n",
      "Test | 129/16 | Loss:5.2637 | MainLoss:1.4307 | SPLoss:38.2640 | CLSLoss:0.6586 | top1:63.5670 | AUROC:0.8263\n",
      "\n",
      "Epoch: [433 | 1000] LR: 0.002491\n",
      "Train | 16/16 | Loss:3.8803 | MainLoss:0.0614 | SPLoss:38.1226 | CLSLoss:0.6587 | top1:97.8933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:4.0201 | MainLoss:0.2174 | SPLoss:37.9610 | CLSLoss:0.6588 | top1:92.8205 | AUROC:0.9801\n",
      "Test | 129/16 | Loss:5.2106 | MainLoss:1.4079 | SPLoss:37.9610 | CLSLoss:0.6588 | top1:64.0312 | AUROC:0.8299\n",
      "\n",
      "Epoch: [434 | 1000] LR: 0.002485\n",
      "Train | 16/16 | Loss:3.8625 | MainLoss:0.0740 | SPLoss:37.8193 | CLSLoss:0.6589 | top1:97.5733 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:3.9908 | MainLoss:0.2182 | SPLoss:37.6605 | CLSLoss:0.6586 | top1:92.7051 | AUROC:0.9800\n",
      "Test | 129/16 | Loss:5.1796 | MainLoss:1.4069 | SPLoss:37.6605 | CLSLoss:0.6586 | top1:63.8660 | AUROC:0.8285\n",
      "\n",
      "Epoch: [435 | 1000] LR: 0.002479\n",
      "Train | 16/16 | Loss:3.8224 | MainLoss:0.0639 | SPLoss:37.5191 | CLSLoss:0.6586 | top1:98.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:3.9560 | MainLoss:0.2135 | SPLoss:37.3589 | CLSLoss:0.6587 | top1:92.9103 | AUROC:0.9801\n",
      "Test | 129/16 | Loss:5.1753 | MainLoss:1.4328 | SPLoss:37.3590 | CLSLoss:0.6587 | top1:63.5452 | AUROC:0.8344\n",
      "\n",
      "Epoch: [436 | 1000] LR: 0.002473\n",
      "Train | 16/16 | Loss:3.8037 | MainLoss:0.0752 | SPLoss:37.2195 | CLSLoss:0.6585 | top1:97.7333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:3.9235 | MainLoss:0.2108 | SPLoss:37.0614 | CLSLoss:0.6583 | top1:93.0769 | AUROC:0.9804\n",
      "Test | 129/16 | Loss:5.1429 | MainLoss:1.4302 | SPLoss:37.0614 | CLSLoss:0.6583 | top1:63.5296 | AUROC:0.8346\n",
      "\n",
      "Epoch: [437 | 1000] LR: 0.002467\n",
      "Train | 16/16 | Loss:3.7760 | MainLoss:0.0769 | SPLoss:36.9251 | CLSLoss:0.6582 | top1:97.3067 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:3.8981 | MainLoss:0.2145 | SPLoss:36.7704 | CLSLoss:0.6580 | top1:92.8462 | AUROC:0.9802\n",
      "Test | 129/16 | Loss:5.0807 | MainLoss:1.3970 | SPLoss:36.7705 | CLSLoss:0.6580 | top1:63.9688 | AUROC:0.8364\n",
      "\n",
      "Epoch: [438 | 1000] LR: 0.002461\n",
      "Train | 16/16 | Loss:3.7298 | MainLoss:0.0598 | SPLoss:36.6350 | CLSLoss:0.6581 | top1:97.9200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:3.8652 | MainLoss:0.2106 | SPLoss:36.4802 | CLSLoss:0.6583 | top1:93.0128 | AUROC:0.9800\n",
      "Test | 129/16 | Loss:5.1398 | MainLoss:1.4852 | SPLoss:36.4802 | CLSLoss:0.6583 | top1:62.6386 | AUROC:0.8310\n",
      "\n",
      "Epoch: [439 | 1000] LR: 0.002455\n",
      "Train | 16/16 | Loss:3.7015 | MainLoss:0.0600 | SPLoss:36.3487 | CLSLoss:0.6584 | top1:98.0800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:3.8442 | MainLoss:0.2178 | SPLoss:36.1980 | CLSLoss:0.6586 | top1:92.8590 | AUROC:0.9801\n",
      "Test | 129/16 | Loss:5.0511 | MainLoss:1.4247 | SPLoss:36.1980 | CLSLoss:0.6586 | top1:63.6604 | AUROC:0.8336\n",
      "\n",
      "Epoch: [440 | 1000] LR: 0.002449\n",
      "Train | 16/16 | Loss:3.6755 | MainLoss:0.0624 | SPLoss:36.0657 | CLSLoss:0.6586 | top1:97.6533 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:3.8139 | MainLoss:0.2159 | SPLoss:35.9144 | CLSLoss:0.6587 | top1:93.0128 | AUROC:0.9797\n",
      "Test | 129/16 | Loss:5.0196 | MainLoss:1.4215 | SPLoss:35.9143 | CLSLoss:0.6587 | top1:63.7695 | AUROC:0.8366\n",
      "\n",
      "Epoch: [441 | 1000] LR: 0.002442\n",
      "Train | 16/16 | Loss:3.6516 | MainLoss:0.0666 | SPLoss:35.7842 | CLSLoss:0.6587 | top1:97.8667 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:3.7876 | MainLoss:0.2175 | SPLoss:35.6352 | CLSLoss:0.6588 | top1:92.9103 | AUROC:0.9796\n",
      "Test | 129/16 | Loss:4.9955 | MainLoss:1.4254 | SPLoss:35.6352 | CLSLoss:0.6588 | top1:63.7601 | AUROC:0.8367\n",
      "\n",
      "Epoch: [442 | 1000] LR: 0.002436\n",
      "Train | 16/16 | Loss:3.6275 | MainLoss:0.0703 | SPLoss:35.5064 | CLSLoss:0.6587 | top1:97.6000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:3.7589 | MainLoss:0.2165 | SPLoss:35.3582 | CLSLoss:0.6585 | top1:92.8846 | AUROC:0.9799\n",
      "Test | 129/16 | Loss:4.9683 | MainLoss:1.4259 | SPLoss:35.3582 | CLSLoss:0.6585 | top1:63.6885 | AUROC:0.8380\n",
      "\n",
      "Epoch: [443 | 1000] LR: 0.002430\n",
      "Train | 16/16 | Loss:3.5992 | MainLoss:0.0697 | SPLoss:35.2296 | CLSLoss:0.6585 | top1:97.7600 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:3.7321 | MainLoss:0.2172 | SPLoss:35.0825 | CLSLoss:0.6584 | top1:92.8590 | AUROC:0.9801\n",
      "Test | 129/16 | Loss:4.9031 | MainLoss:1.3883 | SPLoss:35.0825 | CLSLoss:0.6584 | top1:64.2741 | AUROC:0.8396\n",
      "\n",
      "Epoch: [444 | 1000] LR: 0.002424\n",
      "Train | 16/16 | Loss:3.5802 | MainLoss:0.0780 | SPLoss:34.9561 | CLSLoss:0.6583 | top1:97.4667 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:3.7044 | MainLoss:0.2164 | SPLoss:34.8134 | CLSLoss:0.6582 | top1:92.8590 | AUROC:0.9798\n",
      "Test | 129/16 | Loss:4.9227 | MainLoss:1.4348 | SPLoss:34.8134 | CLSLoss:0.6582 | top1:63.4891 | AUROC:0.8365\n",
      "\n",
      "Epoch: [445 | 1000] LR: 0.002418\n",
      "Train | 16/16 | Loss:3.5256 | MainLoss:0.0503 | SPLoss:34.6865 | CLSLoss:0.6585 | top1:98.4267 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:3.6820 | MainLoss:0.2211 | SPLoss:34.5433 | CLSLoss:0.6587 | top1:92.7949 | AUROC:0.9797\n",
      "Test | 129/16 | Loss:4.8471 | MainLoss:1.3862 | SPLoss:34.5433 | CLSLoss:0.6587 | top1:64.4891 | AUROC:0.8408\n",
      "\n",
      "Epoch: [446 | 1000] LR: 0.002412\n",
      "Train | 16/16 | Loss:3.5294 | MainLoss:0.0809 | SPLoss:34.4189 | CLSLoss:0.6586 | top1:97.0933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:3.6484 | MainLoss:0.2140 | SPLoss:34.2787 | CLSLoss:0.6583 | top1:92.9231 | AUROC:0.9800\n",
      "Test | 129/16 | Loss:4.8405 | MainLoss:1.4061 | SPLoss:34.2787 | CLSLoss:0.6583 | top1:64.0561 | AUROC:0.8407\n",
      "\n",
      "Epoch: [447 | 1000] LR: 0.002406\n",
      "Train | 16/16 | Loss:3.4755 | MainLoss:0.0534 | SPLoss:34.1551 | CLSLoss:0.6585 | top1:98.3467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:3.6214 | MainLoss:0.2133 | SPLoss:34.0149 | CLSLoss:0.6587 | top1:92.9615 | AUROC:0.9799\n",
      "Test | 129/16 | Loss:4.8548 | MainLoss:1.4467 | SPLoss:34.0149 | CLSLoss:0.6587 | top1:63.6386 | AUROC:0.8389\n",
      "\n",
      "Epoch: [448 | 1000] LR: 0.002399\n",
      "Train | 16/16 | Loss:3.4553 | MainLoss:0.0593 | SPLoss:33.8939 | CLSLoss:0.6587 | top1:97.9733 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:3.6046 | MainLoss:0.2223 | SPLoss:33.7564 | CLSLoss:0.6589 | top1:92.6795 | AUROC:0.9804\n",
      "Test | 129/16 | Loss:4.7354 | MainLoss:1.3532 | SPLoss:33.7565 | CLSLoss:0.6589 | top1:65.0935 | AUROC:0.8421\n",
      "\n",
      "Epoch: [449 | 1000] LR: 0.002393\n",
      "Train | 16/16 | Loss:3.4263 | MainLoss:0.0563 | SPLoss:33.6338 | CLSLoss:0.6591 | top1:98.2933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:3.5727 | MainLoss:0.2165 | SPLoss:33.4962 | CLSLoss:0.6591 | top1:92.6795 | AUROC:0.9796\n",
      "Test | 129/16 | Loss:4.7899 | MainLoss:1.4337 | SPLoss:33.4962 | CLSLoss:0.6591 | top1:63.9688 | AUROC:0.8413\n",
      "\n",
      "Epoch: [450 | 1000] LR: 0.002387\n",
      "Train | 16/16 | Loss:3.4134 | MainLoss:0.0689 | SPLoss:33.3784 | CLSLoss:0.6588 | top1:97.7867 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:3.5481 | MainLoss:0.2173 | SPLoss:33.2427 | CLSLoss:0.6588 | top1:92.7179 | AUROC:0.9794\n",
      "Test | 129/16 | Loss:4.7782 | MainLoss:1.4474 | SPLoss:33.2427 | CLSLoss:0.6588 | top1:63.5607 | AUROC:0.8342\n",
      "\n",
      "Epoch: [451 | 1000] LR: 0.002381\n",
      "Train | 16/16 | Loss:3.3936 | MainLoss:0.0745 | SPLoss:33.1245 | CLSLoss:0.6588 | top1:97.3867 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:3.5235 | MainLoss:0.2179 | SPLoss:32.9902 | CLSLoss:0.6584 | top1:92.7564 | AUROC:0.9797\n",
      "Test | 129/16 | Loss:4.6856 | MainLoss:1.3800 | SPLoss:32.9902 | CLSLoss:0.6584 | top1:64.6012 | AUROC:0.8409\n",
      "\n",
      "Epoch: [452 | 1000] LR: 0.002375\n",
      "Train | 16/16 | Loss:3.3714 | MainLoss:0.0774 | SPLoss:32.8744 | CLSLoss:0.6582 | top1:97.5733 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:3.4974 | MainLoss:0.2166 | SPLoss:32.7419 | CLSLoss:0.6579 | top1:92.7436 | AUROC:0.9801\n",
      "Test | 129/16 | Loss:4.6744 | MainLoss:1.3936 | SPLoss:32.7419 | CLSLoss:0.6579 | top1:64.1776 | AUROC:0.8391\n",
      "\n",
      "Epoch: [453 | 1000] LR: 0.002369\n",
      "Train | 16/16 | Loss:3.3463 | MainLoss:0.0769 | SPLoss:32.6281 | CLSLoss:0.6579 | top1:97.3333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:3.4755 | MainLoss:0.2191 | SPLoss:32.4982 | CLSLoss:0.6577 | top1:92.6410 | AUROC:0.9794\n",
      "Test | 129/16 | Loss:4.6429 | MainLoss:1.3865 | SPLoss:32.4982 | CLSLoss:0.6577 | top1:64.2586 | AUROC:0.8357\n",
      "\n",
      "Epoch: [454 | 1000] LR: 0.002362\n",
      "Train | 16/16 | Loss:3.3155 | MainLoss:0.0705 | SPLoss:32.3846 | CLSLoss:0.6576 | top1:97.6000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:3.4523 | MainLoss:0.2202 | SPLoss:32.2553 | CLSLoss:0.6575 | top1:92.5385 | AUROC:0.9797\n",
      "Test | 129/16 | Loss:4.5991 | MainLoss:1.3670 | SPLoss:32.2553 | CLSLoss:0.6575 | top1:64.4953 | AUROC:0.8357\n",
      "\n",
      "Epoch: [455 | 1000] LR: 0.002356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 16/16 | Loss:3.2955 | MainLoss:0.0747 | SPLoss:32.1425 | CLSLoss:0.6574 | top1:97.5467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:3.4240 | MainLoss:0.2160 | SPLoss:32.0142 | CLSLoss:0.6575 | top1:92.6795 | AUROC:0.9798\n",
      "Test | 129/16 | Loss:4.5892 | MainLoss:1.3812 | SPLoss:32.0142 | CLSLoss:0.6575 | top1:64.3084 | AUROC:0.8378\n",
      "\n",
      "Epoch: [456 | 1000] LR: 0.002350\n",
      "Train | 16/16 | Loss:3.2574 | MainLoss:0.0608 | SPLoss:31.9012 | CLSLoss:0.6576 | top1:98.0533 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:3.3985 | MainLoss:0.2145 | SPLoss:31.7737 | CLSLoss:0.6577 | top1:92.7051 | AUROC:0.9795\n",
      "Test | 129/16 | Loss:4.5956 | MainLoss:1.4117 | SPLoss:31.7737 | CLSLoss:0.6577 | top1:63.7819 | AUROC:0.8364\n",
      "\n",
      "Epoch: [457 | 1000] LR: 0.002344\n",
      "Train | 16/16 | Loss:3.2501 | MainLoss:0.0771 | SPLoss:31.6636 | CLSLoss:0.6576 | top1:97.4400 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:3.3701 | MainLoss:0.2099 | SPLoss:31.5366 | CLSLoss:0.6573 | top1:92.8462 | AUROC:0.9795\n",
      "Test | 129/16 | Loss:4.6503 | MainLoss:1.4901 | SPLoss:31.5366 | CLSLoss:0.6573 | top1:62.5140 | AUROC:0.8336\n",
      "\n",
      "Epoch: [458 | 1000] LR: 0.002338\n",
      "Train | 16/16 | Loss:3.2200 | MainLoss:0.0706 | SPLoss:31.4290 | CLSLoss:0.6572 | top1:97.4933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:3.3531 | MainLoss:0.2161 | SPLoss:31.3041 | CLSLoss:0.6574 | top1:92.6410 | AUROC:0.9796\n",
      "Test | 129/16 | Loss:4.4789 | MainLoss:1.3420 | SPLoss:31.3042 | CLSLoss:0.6574 | top1:64.7819 | AUROC:0.8418\n",
      "\n",
      "Epoch: [459 | 1000] LR: 0.002331\n",
      "Train | 16/16 | Loss:3.1929 | MainLoss:0.0668 | SPLoss:31.1953 | CLSLoss:0.6575 | top1:97.6800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:3.3269 | MainLoss:0.2131 | SPLoss:31.0718 | CLSLoss:0.6576 | top1:92.7821 | AUROC:0.9798\n",
      "Test | 129/16 | Loss:4.5001 | MainLoss:1.3863 | SPLoss:31.0718 | CLSLoss:0.6576 | top1:64.1526 | AUROC:0.8434\n",
      "\n",
      "Epoch: [460 | 1000] LR: 0.002325\n",
      "Train | 16/16 | Loss:3.1696 | MainLoss:0.0666 | SPLoss:30.9644 | CLSLoss:0.6576 | top1:97.7067 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:3.3030 | MainLoss:0.2121 | SPLoss:30.8429 | CLSLoss:0.6577 | top1:92.8846 | AUROC:0.9797\n",
      "Test | 129/16 | Loss:4.5210 | MainLoss:1.4302 | SPLoss:30.8429 | CLSLoss:0.6577 | top1:63.4735 | AUROC:0.8413\n",
      "\n",
      "Epoch: [461 | 1000] LR: 0.002319\n",
      "Train | 16/16 | Loss:3.1513 | MainLoss:0.0709 | SPLoss:30.7373 | CLSLoss:0.6577 | top1:97.7600 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:3.2857 | MainLoss:0.2175 | SPLoss:30.6165 | CLSLoss:0.6577 | top1:92.7179 | AUROC:0.9798\n",
      "Test | 129/16 | Loss:4.4374 | MainLoss:1.3692 | SPLoss:30.6165 | CLSLoss:0.6577 | top1:64.4237 | AUROC:0.8450\n",
      "\n",
      "Epoch: [462 | 1000] LR: 0.002313\n",
      "Train | 16/16 | Loss:3.1168 | MainLoss:0.0591 | SPLoss:30.5106 | CLSLoss:0.6578 | top1:98.2133 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:3.2632 | MainLoss:0.2176 | SPLoss:30.3902 | CLSLoss:0.6579 | top1:92.7821 | AUROC:0.9797\n",
      "Test | 129/16 | Loss:4.4339 | MainLoss:1.3883 | SPLoss:30.3902 | CLSLoss:0.6579 | top1:64.2555 | AUROC:0.8435\n",
      "\n",
      "Epoch: [463 | 1000] LR: 0.002307\n",
      "Train | 16/16 | Loss:3.1184 | MainLoss:0.0832 | SPLoss:30.2854 | CLSLoss:0.6577 | top1:97.1733 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:3.2401 | MainLoss:0.2169 | SPLoss:30.1665 | CLSLoss:0.6574 | top1:92.8077 | AUROC:0.9799\n",
      "Test | 129/16 | Loss:4.3719 | MainLoss:1.3486 | SPLoss:30.1665 | CLSLoss:0.6574 | top1:64.7196 | AUROC:0.8459\n",
      "\n",
      "Epoch: [464 | 1000] LR: 0.002300\n",
      "Train | 16/16 | Loss:3.0759 | MainLoss:0.0630 | SPLoss:30.0633 | CLSLoss:0.6574 | top1:97.8933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:3.2139 | MainLoss:0.2127 | SPLoss:29.9460 | CLSLoss:0.6577 | top1:92.7308 | AUROC:0.9791\n",
      "Test | 129/16 | Loss:4.4711 | MainLoss:1.4699 | SPLoss:29.9460 | CLSLoss:0.6577 | top1:62.8910 | AUROC:0.8386\n",
      "\n",
      "Epoch: [465 | 1000] LR: 0.002294\n",
      "Train | 16/16 | Loss:3.0487 | MainLoss:0.0576 | SPLoss:29.8446 | CLSLoss:0.6578 | top1:98.1333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:3.2014 | MainLoss:0.2219 | SPLoss:29.7289 | CLSLoss:0.6581 | top1:92.5385 | AUROC:0.9794\n",
      "Test | 129/16 | Loss:4.3107 | MainLoss:1.3313 | SPLoss:29.7289 | CLSLoss:0.6581 | top1:65.2181 | AUROC:0.8444\n",
      "\n",
      "Epoch: [466 | 1000] LR: 0.002288\n",
      "Train | 16/16 | Loss:3.0443 | MainLoss:0.0748 | SPLoss:29.6292 | CLSLoss:0.6580 | top1:97.4667 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:3.1746 | MainLoss:0.2165 | SPLoss:29.5157 | CLSLoss:0.6580 | top1:92.7564 | AUROC:0.9800\n",
      "Test | 129/16 | Loss:4.3304 | MainLoss:1.3723 | SPLoss:29.5157 | CLSLoss:0.6580 | top1:64.4891 | AUROC:0.8434\n",
      "\n",
      "Epoch: [467 | 1000] LR: 0.002282\n",
      "Train | 16/16 | Loss:3.0212 | MainLoss:0.0731 | SPLoss:29.4149 | CLSLoss:0.6580 | top1:97.6267 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:3.1489 | MainLoss:0.2122 | SPLoss:29.3008 | CLSLoss:0.6579 | top1:92.8462 | AUROC:0.9797\n",
      "Test | 129/16 | Loss:4.3270 | MainLoss:1.3903 | SPLoss:29.3008 | CLSLoss:0.6579 | top1:64.2430 | AUROC:0.8480\n",
      "\n",
      "Epoch: [468 | 1000] LR: 0.002276\n",
      "Train | 16/16 | Loss:2.9819 | MainLoss:0.0549 | SPLoss:29.2036 | CLSLoss:0.6581 | top1:97.9467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:3.1316 | MainLoss:0.2159 | SPLoss:29.0913 | CLSLoss:0.6584 | top1:92.7949 | AUROC:0.9799\n",
      "Test | 129/16 | Loss:4.3166 | MainLoss:1.4009 | SPLoss:29.0913 | CLSLoss:0.6584 | top1:64.2523 | AUROC:0.8452\n",
      "\n",
      "Epoch: [469 | 1000] LR: 0.002269\n",
      "Train | 16/16 | Loss:2.9681 | MainLoss:0.0621 | SPLoss:28.9937 | CLSLoss:0.6584 | top1:98.0267 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:3.1144 | MainLoss:0.2196 | SPLoss:28.8825 | CLSLoss:0.6584 | top1:92.7051 | AUROC:0.9794\n",
      "Test | 129/16 | Loss:4.2259 | MainLoss:1.3310 | SPLoss:28.8825 | CLSLoss:0.6584 | top1:65.5545 | AUROC:0.8542\n",
      "\n",
      "Epoch: [470 | 1000] LR: 0.002263\n",
      "Train | 16/16 | Loss:2.9445 | MainLoss:0.0593 | SPLoss:28.7861 | CLSLoss:0.6584 | top1:98.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:3.0938 | MainLoss:0.2195 | SPLoss:28.6765 | CLSLoss:0.6587 | top1:92.7564 | AUROC:0.9793\n",
      "Test | 129/16 | Loss:4.2714 | MainLoss:1.3972 | SPLoss:28.6765 | CLSLoss:0.6587 | top1:64.4455 | AUROC:0.8428\n",
      "\n",
      "Epoch: [471 | 1000] LR: 0.002257\n",
      "Train | 16/16 | Loss:2.9271 | MainLoss:0.0623 | SPLoss:28.5819 | CLSLoss:0.6588 | top1:97.9733 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:3.0738 | MainLoss:0.2199 | SPLoss:28.4735 | CLSLoss:0.6588 | top1:92.7692 | AUROC:0.9791\n",
      "Test | 129/16 | Loss:4.2598 | MainLoss:1.4059 | SPLoss:28.4735 | CLSLoss:0.6588 | top1:64.3832 | AUROC:0.8424\n",
      "\n",
      "Epoch: [472 | 1000] LR: 0.002251\n",
      "Train | 16/16 | Loss:2.9034 | MainLoss:0.0589 | SPLoss:28.3791 | CLSLoss:0.6589 | top1:98.2133 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:3.0562 | MainLoss:0.2224 | SPLoss:28.2716 | CLSLoss:0.6590 | top1:92.6538 | AUROC:0.9786\n",
      "Test | 129/16 | Loss:4.2731 | MainLoss:1.4393 | SPLoss:28.2716 | CLSLoss:0.6590 | top1:63.8255 | AUROC:0.8367\n",
      "\n",
      "Epoch: [473 | 1000] LR: 0.002244\n",
      "Train | 16/16 | Loss:2.8914 | MainLoss:0.0671 | SPLoss:28.1770 | CLSLoss:0.6590 | top1:97.6533 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:3.0384 | MainLoss:0.2248 | SPLoss:28.0702 | CLSLoss:0.6590 | top1:92.5769 | AUROC:0.9788\n",
      "Test | 129/16 | Loss:4.2001 | MainLoss:1.3865 | SPLoss:28.0702 | CLSLoss:0.6590 | top1:64.5016 | AUROC:0.8373\n",
      "\n",
      "Epoch: [474 | 1000] LR: 0.002238\n",
      "Train | 16/16 | Loss:2.8591 | MainLoss:0.0547 | SPLoss:27.9777 | CLSLoss:0.6591 | top1:98.1333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:3.0154 | MainLoss:0.2217 | SPLoss:27.8715 | CLSLoss:0.6594 | top1:92.7308 | AUROC:0.9790\n",
      "Test | 129/16 | Loss:4.2117 | MainLoss:1.4179 | SPLoss:27.8715 | CLSLoss:0.6594 | top1:64.2025 | AUROC:0.8392\n",
      "\n",
      "Epoch: [475 | 1000] LR: 0.002232\n",
      "Train | 16/16 | Loss:2.8462 | MainLoss:0.0616 | SPLoss:27.7800 | CLSLoss:0.6594 | top1:97.8933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:2.9975 | MainLoss:0.2234 | SPLoss:27.6752 | CLSLoss:0.6595 | top1:92.7436 | AUROC:0.9792\n",
      "Test | 129/16 | Loss:4.1913 | MainLoss:1.4172 | SPLoss:27.6752 | CLSLoss:0.6595 | top1:64.1495 | AUROC:0.8381\n",
      "\n",
      "Epoch: [476 | 1000] LR: 0.002226\n",
      "Train | 16/16 | Loss:2.8290 | MainLoss:0.0640 | SPLoss:27.5842 | CLSLoss:0.6595 | top1:98.0533 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:2.9831 | MainLoss:0.2283 | SPLoss:27.4817 | CLSLoss:0.6593 | top1:92.4359 | AUROC:0.9792\n",
      "Test | 129/16 | Loss:4.1227 | MainLoss:1.3679 | SPLoss:27.4817 | CLSLoss:0.6593 | top1:64.9439 | AUROC:0.8390\n",
      "\n",
      "Epoch: [477 | 1000] LR: 0.002219\n",
      "Train | 16/16 | Loss:2.7996 | MainLoss:0.0539 | SPLoss:27.3910 | CLSLoss:0.6595 | top1:98.3200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:2.9632 | MainLoss:0.2279 | SPLoss:27.2872 | CLSLoss:0.6596 | top1:92.5256 | AUROC:0.9793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 129/16 | Loss:4.1103 | MainLoss:1.3750 | SPLoss:27.2872 | CLSLoss:0.6596 | top1:64.9315 | AUROC:0.8400\n",
      "\n",
      "Epoch: [478 | 1000] LR: 0.002213\n",
      "Train | 16/16 | Loss:2.7995 | MainLoss:0.0732 | SPLoss:27.1973 | CLSLoss:0.6594 | top1:97.4933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:2.9400 | MainLoss:0.2237 | SPLoss:27.0967 | CLSLoss:0.6593 | top1:92.6667 | AUROC:0.9791\n",
      "Test | 129/16 | Loss:4.1164 | MainLoss:1.4001 | SPLoss:27.0967 | CLSLoss:0.6593 | top1:64.3863 | AUROC:0.8410\n",
      "\n",
      "Epoch: [479 | 1000] LR: 0.002207\n",
      "Train | 16/16 | Loss:2.7740 | MainLoss:0.0664 | SPLoss:27.0099 | CLSLoss:0.6594 | top1:97.7067 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:2.9187 | MainLoss:0.2212 | SPLoss:26.9094 | CLSLoss:0.6593 | top1:92.7436 | AUROC:0.9796\n",
      "Test | 129/16 | Loss:4.1338 | MainLoss:1.4362 | SPLoss:26.9095 | CLSLoss:0.6593 | top1:63.7944 | AUROC:0.8377\n",
      "\n",
      "Epoch: [480 | 1000] LR: 0.002201\n",
      "Train | 16/16 | Loss:2.7414 | MainLoss:0.0526 | SPLoss:26.8225 | CLSLoss:0.6594 | top1:98.2667 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:2.8998 | MainLoss:0.2209 | SPLoss:26.7235 | CLSLoss:0.6596 | top1:92.7179 | AUROC:0.9790\n",
      "Test | 129/16 | Loss:4.1250 | MainLoss:1.4461 | SPLoss:26.7235 | CLSLoss:0.6596 | top1:63.5794 | AUROC:0.8332\n",
      "\n",
      "Epoch: [481 | 1000] LR: 0.002194\n",
      "Train | 16/16 | Loss:2.7443 | MainLoss:0.0740 | SPLoss:26.6370 | CLSLoss:0.6595 | top1:97.5733 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:2.8815 | MainLoss:0.2211 | SPLoss:26.5388 | CLSLoss:0.6593 | top1:92.6795 | AUROC:0.9794\n",
      "Test | 129/16 | Loss:4.0505 | MainLoss:1.3900 | SPLoss:26.5388 | CLSLoss:0.6593 | top1:64.3707 | AUROC:0.8364\n",
      "\n",
      "Epoch: [482 | 1000] LR: 0.002188\n",
      "Train | 16/16 | Loss:2.7206 | MainLoss:0.0686 | SPLoss:26.4539 | CLSLoss:0.6593 | top1:97.6000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:2.8611 | MainLoss:0.2187 | SPLoss:26.3585 | CLSLoss:0.6593 | top1:92.6667 | AUROC:0.9794\n",
      "Test | 129/16 | Loss:4.0766 | MainLoss:1.4341 | SPLoss:26.3585 | CLSLoss:0.6593 | top1:63.6947 | AUROC:0.8330\n",
      "\n",
      "Epoch: [483 | 1000] LR: 0.002182\n",
      "Train | 16/16 | Loss:2.6887 | MainLoss:0.0546 | SPLoss:26.2746 | CLSLoss:0.6594 | top1:98.3467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:2.8409 | MainLoss:0.2165 | SPLoss:26.1780 | CLSLoss:0.6596 | top1:92.7436 | AUROC:0.9800\n",
      "Test | 129/16 | Loss:4.0800 | MainLoss:1.4557 | SPLoss:26.1780 | CLSLoss:0.6596 | top1:63.4579 | AUROC:0.8346\n",
      "\n",
      "Epoch: [484 | 1000] LR: 0.002176\n",
      "Train | 16/16 | Loss:2.6925 | MainLoss:0.0764 | SPLoss:26.0947 | CLSLoss:0.6593 | top1:97.5733 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:2.8259 | MainLoss:0.2194 | SPLoss:25.9995 | CLSLoss:0.6592 | top1:92.7692 | AUROC:0.9802\n",
      "Test | 129/16 | Loss:3.9855 | MainLoss:1.3790 | SPLoss:25.9995 | CLSLoss:0.6592 | top1:64.5576 | AUROC:0.8396\n",
      "\n",
      "Epoch: [485 | 1000] LR: 0.002169\n",
      "Train | 16/16 | Loss:2.6495 | MainLoss:0.0513 | SPLoss:25.9158 | CLSLoss:0.6595 | top1:98.1600 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:2.8086 | MainLoss:0.2199 | SPLoss:25.8213 | CLSLoss:0.6596 | top1:92.7949 | AUROC:0.9799\n",
      "Test | 129/16 | Loss:3.9802 | MainLoss:1.3915 | SPLoss:25.8213 | CLSLoss:0.6596 | top1:64.5296 | AUROC:0.8424\n",
      "\n",
      "Epoch: [486 | 1000] LR: 0.002163\n",
      "Train | 16/16 | Loss:2.6483 | MainLoss:0.0676 | SPLoss:25.7410 | CLSLoss:0.6594 | top1:97.9200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:2.7853 | MainLoss:0.2140 | SPLoss:25.6472 | CLSLoss:0.6595 | top1:92.9359 | AUROC:0.9802\n",
      "Test | 129/16 | Loss:4.0489 | MainLoss:1.4776 | SPLoss:25.6472 | CLSLoss:0.6595 | top1:63.1277 | AUROC:0.8369\n",
      "\n",
      "Epoch: [487 | 1000] LR: 0.002157\n",
      "Train | 16/16 | Loss:2.6216 | MainLoss:0.0584 | SPLoss:25.5664 | CLSLoss:0.6595 | top1:98.4533 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:2.7709 | MainLoss:0.2170 | SPLoss:25.4733 | CLSLoss:0.6596 | top1:92.9103 | AUROC:0.9803\n",
      "Test | 129/16 | Loss:4.0082 | MainLoss:1.4542 | SPLoss:25.4733 | CLSLoss:0.6596 | top1:63.5234 | AUROC:0.8348\n",
      "\n",
      "Epoch: [488 | 1000] LR: 0.002151\n",
      "Train | 16/16 | Loss:2.6067 | MainLoss:0.0608 | SPLoss:25.3931 | CLSLoss:0.6597 | top1:98.2133 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:2.7576 | MainLoss:0.2209 | SPLoss:25.3010 | CLSLoss:0.6597 | top1:92.8205 | AUROC:0.9799\n",
      "Test | 129/16 | Loss:3.9614 | MainLoss:1.4247 | SPLoss:25.3010 | CLSLoss:0.6597 | top1:63.9907 | AUROC:0.8360\n",
      "\n",
      "Epoch: [489 | 1000] LR: 0.002144\n",
      "Train | 16/16 | Loss:2.6017 | MainLoss:0.0730 | SPLoss:25.2211 | CLSLoss:0.6597 | top1:97.3867 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:2.7334 | MainLoss:0.2138 | SPLoss:25.1304 | CLSLoss:0.6594 | top1:92.8333 | AUROC:0.9795\n",
      "Test | 129/16 | Loss:4.0207 | MainLoss:1.5011 | SPLoss:25.1304 | CLSLoss:0.6594 | top1:62.6667 | AUROC:0.8297\n",
      "\n",
      "Epoch: [490 | 1000] LR: 0.002138\n",
      "Train | 16/16 | Loss:2.5756 | MainLoss:0.0639 | SPLoss:25.0516 | CLSLoss:0.6594 | top1:98.0267 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:2.7189 | MainLoss:0.2162 | SPLoss:24.9609 | CLSLoss:0.6596 | top1:92.8590 | AUROC:0.9800\n",
      "Test | 129/16 | Loss:3.9494 | MainLoss:1.4467 | SPLoss:24.9609 | CLSLoss:0.6596 | top1:63.4393 | AUROC:0.8314\n",
      "\n",
      "Epoch: [491 | 1000] LR: 0.002132\n",
      "Train | 16/16 | Loss:2.5665 | MainLoss:0.0716 | SPLoss:24.8831 | CLSLoss:0.6595 | top1:97.5467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:2.7016 | MainLoss:0.2156 | SPLoss:24.7939 | CLSLoss:0.6593 | top1:92.9359 | AUROC:0.9803\n",
      "Test | 129/16 | Loss:3.9275 | MainLoss:1.4415 | SPLoss:24.7939 | CLSLoss:0.6593 | top1:63.5514 | AUROC:0.8306\n",
      "\n",
      "Epoch: [492 | 1000] LR: 0.002126\n",
      "Train | 16/16 | Loss:2.5462 | MainLoss:0.0678 | SPLoss:24.7175 | CLSLoss:0.6592 | top1:97.7067 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:2.6829 | MainLoss:0.2134 | SPLoss:24.6290 | CLSLoss:0.6592 | top1:93.0000 | AUROC:0.9796\n",
      "Test | 129/16 | Loss:3.9770 | MainLoss:1.5075 | SPLoss:24.6290 | CLSLoss:0.6592 | top1:62.5234 | AUROC:0.8265\n",
      "\n",
      "Epoch: [493 | 1000] LR: 0.002119\n",
      "Train | 16/16 | Loss:2.5247 | MainLoss:0.0628 | SPLoss:24.5530 | CLSLoss:0.6593 | top1:97.8667 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:2.6679 | MainLoss:0.2148 | SPLoss:24.4650 | CLSLoss:0.6593 | top1:92.8333 | AUROC:0.9799\n",
      "Test | 129/16 | Loss:3.9304 | MainLoss:1.4773 | SPLoss:24.4650 | CLSLoss:0.6593 | top1:62.9875 | AUROC:0.8308\n",
      "\n",
      "Epoch: [494 | 1000] LR: 0.002113\n",
      "Train | 16/16 | Loss:2.5033 | MainLoss:0.0578 | SPLoss:24.3892 | CLSLoss:0.6593 | top1:98.1333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:2.6564 | MainLoss:0.2197 | SPLoss:24.3013 | CLSLoss:0.6594 | top1:92.6538 | AUROC:0.9798\n",
      "Test | 129/16 | Loss:3.8456 | MainLoss:1.4088 | SPLoss:24.3013 | CLSLoss:0.6594 | top1:63.9751 | AUROC:0.8349\n",
      "\n",
      "Epoch: [495 | 1000] LR: 0.002107\n",
      "Train | 16/16 | Loss:2.4745 | MainLoss:0.0453 | SPLoss:24.2256 | CLSLoss:0.6598 | top1:98.6400 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:2.6411 | MainLoss:0.2205 | SPLoss:24.1398 | CLSLoss:0.6601 | top1:92.6667 | AUROC:0.9794\n",
      "Test | 129/16 | Loss:3.8860 | MainLoss:1.4654 | SPLoss:24.1398 | CLSLoss:0.6601 | top1:63.3645 | AUROC:0.8334\n",
      "\n",
      "Epoch: [496 | 1000] LR: 0.002100\n",
      "Train | 16/16 | Loss:2.4858 | MainLoss:0.0725 | SPLoss:24.0675 | CLSLoss:0.6598 | top1:97.5733 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:2.6227 | MainLoss:0.2178 | SPLoss:23.9832 | CLSLoss:0.6598 | top1:92.7308 | AUROC:0.9795\n",
      "Test | 129/16 | Loss:3.8880 | MainLoss:1.4831 | SPLoss:23.9832 | CLSLoss:0.6598 | top1:62.9938 | AUROC:0.8274\n",
      "\n",
      "Epoch: [497 | 1000] LR: 0.002094\n",
      "Train | 16/16 | Loss:2.4495 | MainLoss:0.0519 | SPLoss:23.9100 | CLSLoss:0.6600 | top1:98.2667 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:2.6093 | MainLoss:0.2202 | SPLoss:23.8257 | CLSLoss:0.6603 | top1:92.6795 | AUROC:0.9798\n",
      "Test | 129/16 | Loss:3.8687 | MainLoss:1.4795 | SPLoss:23.8257 | CLSLoss:0.6603 | top1:63.1371 | AUROC:0.8286\n",
      "\n",
      "Epoch: [498 | 1000] LR: 0.002088\n",
      "Train | 16/16 | Loss:2.4396 | MainLoss:0.0578 | SPLoss:23.7517 | CLSLoss:0.6605 | top1:98.0800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:2.5931 | MainLoss:0.2197 | SPLoss:23.6687 | CLSLoss:0.6604 | top1:92.7051 | AUROC:0.9792\n",
      "Test | 129/16 | Loss:3.8593 | MainLoss:1.4858 | SPLoss:23.6687 | CLSLoss:0.6604 | top1:63.1308 | AUROC:0.8330\n",
      "\n",
      "Epoch: [499 | 1000] LR: 0.002082\n",
      "Train | 16/16 | Loss:2.4375 | MainLoss:0.0712 | SPLoss:23.5969 | CLSLoss:0.6603 | top1:97.5200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:2.5769 | MainLoss:0.2190 | SPLoss:23.5136 | CLSLoss:0.6602 | top1:92.6795 | AUROC:0.9796\n",
      "Test | 129/16 | Loss:3.8181 | MainLoss:1.4601 | SPLoss:23.5136 | CLSLoss:0.6602 | top1:63.5140 | AUROC:0.8380\n",
      "\n",
      "Epoch: [500 | 1000] LR: 0.002075\n",
      "Train | 16/16 | Loss:2.4116 | MainLoss:0.0608 | SPLoss:23.4421 | CLSLoss:0.6604 | top1:97.8933 | AUROC:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 32/16 | Loss:2.5653 | MainLoss:0.2225 | SPLoss:23.3616 | CLSLoss:0.6604 | top1:92.6667 | AUROC:0.9796\n",
      "Test | 129/16 | Loss:3.7769 | MainLoss:1.4342 | SPLoss:23.3616 | CLSLoss:0.6604 | top1:64.0156 | AUROC:0.8354\n",
      "\n",
      "Epoch: [501 | 1000] LR: 0.002069\n",
      "Train | 16/16 | Loss:2.4075 | MainLoss:0.0718 | SPLoss:23.2913 | CLSLoss:0.6604 | top1:97.7067 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:2.5512 | MainLoss:0.2235 | SPLoss:23.2106 | CLSLoss:0.6602 | top1:92.6923 | AUROC:0.9798\n",
      "Test | 129/16 | Loss:3.7590 | MainLoss:1.4314 | SPLoss:23.2106 | CLSLoss:0.6602 | top1:64.0374 | AUROC:0.8349\n",
      "\n",
      "Epoch: [502 | 1000] LR: 0.000206\n",
      "Train | 16/16 | Loss:2.3772 | MainLoss:0.0502 | SPLoss:23.2034 | CLSLoss:0.6602 | top1:98.4533 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:2.5483 | MainLoss:0.2221 | SPLoss:23.1951 | CLSLoss:0.6602 | top1:92.6923 | AUROC:0.9792\n",
      "Test | 129/16 | Loss:3.7701 | MainLoss:1.4440 | SPLoss:23.1952 | CLSLoss:0.6602 | top1:63.8318 | AUROC:0.8350\n",
      "\n",
      "Epoch: [503 | 1000] LR: 0.000206\n",
      "Train | 16/16 | Loss:2.4039 | MainLoss:0.0785 | SPLoss:23.1881 | CLSLoss:0.6602 | top1:97.3333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:2.5467 | MainLoss:0.2221 | SPLoss:23.1803 | CLSLoss:0.6602 | top1:92.7051 | AUROC:0.9793\n",
      "Test | 129/16 | Loss:3.7666 | MainLoss:1.4420 | SPLoss:23.1803 | CLSLoss:0.6602 | top1:63.8380 | AUROC:0.8353\n",
      "\n",
      "Epoch: [504 | 1000] LR: 0.000205\n",
      "Train | 16/16 | Loss:2.3846 | MainLoss:0.0607 | SPLoss:23.1733 | CLSLoss:0.6601 | top1:98.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:2.5446 | MainLoss:0.2215 | SPLoss:23.1653 | CLSLoss:0.6602 | top1:92.7179 | AUROC:0.9796\n",
      "Test | 129/16 | Loss:3.7684 | MainLoss:1.4453 | SPLoss:23.1653 | CLSLoss:0.6602 | top1:63.7757 | AUROC:0.8339\n",
      "\n",
      "Epoch: [505 | 1000] LR: 0.000204\n",
      "Train | 16/16 | Loss:2.4080 | MainLoss:0.0855 | SPLoss:23.1583 | CLSLoss:0.6601 | top1:97.0667 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:2.5412 | MainLoss:0.2196 | SPLoss:23.1504 | CLSLoss:0.6601 | top1:92.7179 | AUROC:0.9794\n",
      "Test | 129/16 | Loss:3.7825 | MainLoss:1.4609 | SPLoss:23.1503 | CLSLoss:0.6601 | top1:63.5016 | AUROC:0.8333\n",
      "\n",
      "Epoch: [506 | 1000] LR: 0.000204\n",
      "Train | 16/16 | Loss:2.3831 | MainLoss:0.0622 | SPLoss:23.1436 | CLSLoss:0.6601 | top1:98.0533 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:2.5401 | MainLoss:0.2199 | SPLoss:23.1357 | CLSLoss:0.6601 | top1:92.7051 | AUROC:0.9798\n",
      "Test | 129/16 | Loss:3.7788 | MainLoss:1.4586 | SPLoss:23.1357 | CLSLoss:0.6601 | top1:63.5483 | AUROC:0.8341\n",
      "\n",
      "Epoch: [507 | 1000] LR: 0.000203\n",
      "Train | 16/16 | Loss:2.4014 | MainLoss:0.0819 | SPLoss:23.1288 | CLSLoss:0.6601 | top1:97.1733 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:2.5389 | MainLoss:0.2202 | SPLoss:23.1212 | CLSLoss:0.6600 | top1:92.7179 | AUROC:0.9797\n",
      "Test | 129/16 | Loss:3.7712 | MainLoss:1.4525 | SPLoss:23.1212 | CLSLoss:0.6600 | top1:63.6075 | AUROC:0.8338\n",
      "\n",
      "Epoch: [508 | 1000] LR: 0.000203\n",
      "Train | 16/16 | Loss:2.3847 | MainLoss:0.0667 | SPLoss:23.1143 | CLSLoss:0.6600 | top1:97.9467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:2.5373 | MainLoss:0.2200 | SPLoss:23.1064 | CLSLoss:0.6600 | top1:92.7308 | AUROC:0.9796\n",
      "Test | 129/16 | Loss:3.7692 | MainLoss:1.4520 | SPLoss:23.1063 | CLSLoss:0.6600 | top1:63.6044 | AUROC:0.8338\n",
      "\n",
      "Epoch: [509 | 1000] LR: 0.000202\n",
      "Train | 16/16 | Loss:2.3791 | MainLoss:0.0626 | SPLoss:23.0994 | CLSLoss:0.6600 | top1:97.8400 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:2.5353 | MainLoss:0.2196 | SPLoss:23.0916 | CLSLoss:0.6600 | top1:92.6795 | AUROC:0.9797\n",
      "Test | 129/16 | Loss:3.7703 | MainLoss:1.4546 | SPLoss:23.0916 | CLSLoss:0.6600 | top1:63.5888 | AUROC:0.8337\n",
      "\n",
      "Epoch: [510 | 1000] LR: 0.000201\n",
      "Train | 16/16 | Loss:2.3699 | MainLoss:0.0548 | SPLoss:23.0848 | CLSLoss:0.6601 | top1:98.3200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:2.5336 | MainLoss:0.2193 | SPLoss:23.0770 | CLSLoss:0.6601 | top1:92.6923 | AUROC:0.9795\n",
      "Test | 129/16 | Loss:3.7719 | MainLoss:1.4576 | SPLoss:23.0770 | CLSLoss:0.6601 | top1:63.5607 | AUROC:0.8343\n",
      "\n",
      "Epoch: [511 | 1000] LR: 0.000201\n",
      "Train | 16/16 | Loss:2.3915 | MainLoss:0.0779 | SPLoss:23.0702 | CLSLoss:0.6600 | top1:97.5733 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:2.5315 | MainLoss:0.2187 | SPLoss:23.0624 | CLSLoss:0.6600 | top1:92.6538 | AUROC:0.9795\n",
      "Test | 129/16 | Loss:3.7748 | MainLoss:1.4619 | SPLoss:23.0624 | CLSLoss:0.6600 | top1:63.4611 | AUROC:0.8338\n",
      "\n",
      "Epoch: [512 | 1000] LR: 0.000200\n",
      "Train | 16/16 | Loss:2.3766 | MainLoss:0.0644 | SPLoss:23.0556 | CLSLoss:0.6600 | top1:97.8667 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:2.5296 | MainLoss:0.2183 | SPLoss:23.0478 | CLSLoss:0.6600 | top1:92.6923 | AUROC:0.9797\n",
      "Test | 129/16 | Loss:3.7778 | MainLoss:1.4664 | SPLoss:23.0478 | CLSLoss:0.6600 | top1:63.3801 | AUROC:0.8336\n",
      "\n",
      "Epoch: [513 | 1000] LR: 0.000199\n",
      "Train | 16/16 | Loss:2.3650 | MainLoss:0.0543 | SPLoss:23.0410 | CLSLoss:0.6600 | top1:98.4000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:2.5284 | MainLoss:0.2184 | SPLoss:23.0333 | CLSLoss:0.6600 | top1:92.6538 | AUROC:0.9797\n",
      "Test | 129/16 | Loss:3.7745 | MainLoss:1.4646 | SPLoss:23.0333 | CLSLoss:0.6600 | top1:63.4112 | AUROC:0.8342\n",
      "\n",
      "Epoch: [514 | 1000] LR: 0.000199\n",
      "Train | 16/16 | Loss:2.3651 | MainLoss:0.0558 | SPLoss:23.0266 | CLSLoss:0.6600 | top1:98.2933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:2.5274 | MainLoss:0.2189 | SPLoss:23.0190 | CLSLoss:0.6601 | top1:92.6923 | AUROC:0.9801\n",
      "Test | 129/16 | Loss:3.7679 | MainLoss:1.4594 | SPLoss:23.0190 | CLSLoss:0.6601 | top1:63.5109 | AUROC:0.8340\n",
      "\n",
      "Epoch: [515 | 1000] LR: 0.000198\n",
      "Train | 16/16 | Loss:2.3709 | MainLoss:0.0630 | SPLoss:23.0123 | CLSLoss:0.6601 | top1:98.0800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:2.5258 | MainLoss:0.2187 | SPLoss:23.0048 | CLSLoss:0.6601 | top1:92.6923 | AUROC:0.9794\n",
      "Test | 129/16 | Loss:3.7714 | MainLoss:1.4643 | SPLoss:23.0048 | CLSLoss:0.6601 | top1:63.4019 | AUROC:0.8333\n",
      "\n",
      "Epoch: [516 | 1000] LR: 0.000197\n",
      "Train | 16/16 | Loss:2.3761 | MainLoss:0.0697 | SPLoss:22.9981 | CLSLoss:0.6601 | top1:97.8133 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:2.5243 | MainLoss:0.2187 | SPLoss:22.9904 | CLSLoss:0.6600 | top1:92.6667 | AUROC:0.9797\n",
      "Test | 129/16 | Loss:3.7679 | MainLoss:1.4622 | SPLoss:22.9905 | CLSLoss:0.6600 | top1:63.4517 | AUROC:0.8335\n",
      "\n",
      "Epoch: [517 | 1000] LR: 0.000197\n",
      "Train | 16/16 | Loss:2.3811 | MainLoss:0.0761 | SPLoss:22.9838 | CLSLoss:0.6600 | top1:97.4667 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:2.5224 | MainLoss:0.2182 | SPLoss:22.9762 | CLSLoss:0.6600 | top1:92.6667 | AUROC:0.9798\n",
      "Test | 129/16 | Loss:3.7710 | MainLoss:1.4668 | SPLoss:22.9762 | CLSLoss:0.6600 | top1:63.3676 | AUROC:0.8334\n",
      "\n",
      "Epoch: [518 | 1000] LR: 0.000196\n",
      "Train | 16/16 | Loss:2.3727 | MainLoss:0.0691 | SPLoss:22.9696 | CLSLoss:0.6600 | top1:97.5467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:2.5209 | MainLoss:0.2181 | SPLoss:22.9621 | CLSLoss:0.6600 | top1:92.6667 | AUROC:0.9797\n",
      "Test | 129/16 | Loss:3.7673 | MainLoss:1.4645 | SPLoss:22.9622 | CLSLoss:0.6600 | top1:63.3988 | AUROC:0.8337\n",
      "\n",
      "Epoch: [519 | 1000] LR: 0.000196\n",
      "Train | 16/16 | Loss:2.3502 | MainLoss:0.0480 | SPLoss:22.9556 | CLSLoss:0.6600 | top1:98.3200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:2.5197 | MainLoss:0.2183 | SPLoss:22.9480 | CLSLoss:0.6600 | top1:92.6795 | AUROC:0.9792\n",
      "Test | 129/16 | Loss:3.7654 | MainLoss:1.4640 | SPLoss:22.9480 | CLSLoss:0.6600 | top1:63.4330 | AUROC:0.8329\n",
      "\n",
      "Epoch: [520 | 1000] LR: 0.000195\n",
      "Train | 16/16 | Loss:2.3591 | MainLoss:0.0584 | SPLoss:22.9415 | CLSLoss:0.6600 | top1:98.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:2.5187 | MainLoss:0.2187 | SPLoss:22.9341 | CLSLoss:0.6600 | top1:92.6923 | AUROC:0.9796\n",
      "Test | 129/16 | Loss:3.7594 | MainLoss:1.4594 | SPLoss:22.9341 | CLSLoss:0.6600 | top1:63.4829 | AUROC:0.8328\n",
      "\n",
      "Epoch: [521 | 1000] LR: 0.000194\n",
      "Train | 16/16 | Loss:2.3617 | MainLoss:0.0624 | SPLoss:22.9277 | CLSLoss:0.6600 | top1:97.8400 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:2.5183 | MainLoss:0.2197 | SPLoss:22.9203 | CLSLoss:0.6600 | top1:92.7821 | AUROC:0.9799\n",
      "Test | 129/16 | Loss:3.7448 | MainLoss:1.4462 | SPLoss:22.9203 | CLSLoss:0.6600 | top1:63.7134 | AUROC:0.8338\n",
      "\n",
      "Epoch: [522 | 1000] LR: 0.000194\n",
      "Train | 16/16 | Loss:2.3468 | MainLoss:0.0488 | SPLoss:22.9136 | CLSLoss:0.6601 | top1:98.6133 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:2.5159 | MainLoss:0.2187 | SPLoss:22.9060 | CLSLoss:0.6601 | top1:92.7308 | AUROC:0.9797\n",
      "Test | 129/16 | Loss:3.7551 | MainLoss:1.4579 | SPLoss:22.9060 | CLSLoss:0.6601 | top1:63.5421 | AUROC:0.8339\n",
      "\n",
      "Epoch: [523 | 1000] LR: 0.000193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 16/16 | Loss:2.3632 | MainLoss:0.0667 | SPLoss:22.8995 | CLSLoss:0.6601 | top1:97.8667 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:2.5148 | MainLoss:0.2190 | SPLoss:22.8920 | CLSLoss:0.6601 | top1:92.7436 | AUROC:0.9798\n",
      "Test | 129/16 | Loss:3.7460 | MainLoss:1.4502 | SPLoss:22.8920 | CLSLoss:0.6601 | top1:63.6729 | AUROC:0.8340\n",
      "\n",
      "Epoch: [524 | 1000] LR: 0.000192\n",
      "Train | 16/16 | Loss:2.3522 | MainLoss:0.0571 | SPLoss:22.8856 | CLSLoss:0.6601 | top1:98.2133 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:2.5133 | MainLoss:0.2189 | SPLoss:22.8781 | CLSLoss:0.6601 | top1:92.7692 | AUROC:0.9794\n",
      "Test | 129/16 | Loss:3.7459 | MainLoss:1.4515 | SPLoss:22.8781 | CLSLoss:0.6601 | top1:63.6636 | AUROC:0.8341\n",
      "\n",
      "Epoch: [525 | 1000] LR: 0.000192\n",
      "Train | 16/16 | Loss:2.3424 | MainLoss:0.0486 | SPLoss:22.8717 | CLSLoss:0.6601 | top1:98.4267 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:2.5125 | MainLoss:0.2194 | SPLoss:22.8643 | CLSLoss:0.6601 | top1:92.7821 | AUROC:0.9797\n",
      "Test | 129/16 | Loss:3.7425 | MainLoss:1.4495 | SPLoss:22.8643 | CLSLoss:0.6601 | top1:63.7259 | AUROC:0.8346\n",
      "\n",
      "Epoch: [526 | 1000] LR: 0.000191\n",
      "Train | 16/16 | Loss:2.3580 | MainLoss:0.0656 | SPLoss:22.8579 | CLSLoss:0.6601 | top1:97.7067 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:2.5104 | MainLoss:0.2188 | SPLoss:22.8505 | CLSLoss:0.6601 | top1:92.7692 | AUROC:0.9795\n",
      "Test | 129/16 | Loss:3.7456 | MainLoss:1.4539 | SPLoss:22.8505 | CLSLoss:0.6601 | top1:63.6449 | AUROC:0.8345\n",
      "\n",
      "Epoch: [527 | 1000] LR: 0.000191\n",
      "Train | 16/16 | Loss:2.3536 | MainLoss:0.0626 | SPLoss:22.8442 | CLSLoss:0.6601 | top1:97.8667 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:2.5091 | MainLoss:0.2188 | SPLoss:22.8369 | CLSLoss:0.6601 | top1:92.7436 | AUROC:0.9799\n",
      "Test | 129/16 | Loss:3.7450 | MainLoss:1.4547 | SPLoss:22.8369 | CLSLoss:0.6601 | top1:63.6386 | AUROC:0.8346\n",
      "\n",
      "Epoch: [528 | 1000] LR: 0.000190\n",
      "Train | 16/16 | Loss:2.3368 | MainLoss:0.0471 | SPLoss:22.8306 | CLSLoss:0.6602 | top1:98.4533 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:2.5084 | MainLoss:0.2195 | SPLoss:22.8233 | CLSLoss:0.6602 | top1:92.7692 | AUROC:0.9797\n",
      "Test | 129/16 | Loss:3.7382 | MainLoss:1.4492 | SPLoss:22.8233 | CLSLoss:0.6602 | top1:63.7352 | AUROC:0.8346\n",
      "\n",
      "Epoch: [529 | 1000] LR: 0.000189\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-b6b4742642ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nEpoch: [%d | %d] LR: %f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_auroc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudent_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_auroc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_target_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudent_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0msource_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_auroc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_source_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudent_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-6e1a78ca2a25>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, model, criterion, optimizer, epoch, use_cuda)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mloss_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mloss_sp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mloss_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreg_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0mloss_sp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreg_l2sp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mloss_main\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msp_alpha\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mloss_sp\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msp_beta\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mloss_cls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-0014dd33d595>\u001b[0m in \u001b[0;36mreg_cls\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mreg_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0ml2_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfc_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0ml2_cls\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(start_epoch, epochs):\n",
    "    state['lr'] = optimizer.state_dict()['param_groups'][0]['lr']\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "    print('\\nEpoch: [%d | %d] LR: %f' % (epoch + 1, epochs, state['lr']))\n",
    "    \n",
    "    train_loss, train_acc, train_auroc = train(train_loader, student_model, criterion, optimizer, epoch, use_cuda)\n",
    "    test_loss, test_acc, test_auroc = test(val_target_loader, student_model, criterion, epoch, use_cuda)\n",
    "    source_loss, source_acc, source_auroc = test(val_source_loader, student_model, criterion, epoch, use_cuda)\n",
    "\n",
    "\n",
    "    logger.append([state['lr'], train_loss, test_loss,  source_loss, train_acc, test_acc,source_acc, train_auroc, test_auroc, source_auroc])\n",
    "    is_best = test_acc > best_acc\n",
    "    best_acc = max(test_acc, best_acc)\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'state_dict' : student_model.state_dict(),\n",
    "        'acc': test_acc,\n",
    "        'best_acc': best_acc,\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    }, is_best, checkpoint=checkpoint)\n",
    "    scheduler_warmup.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
