{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import collections\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "\n",
    "from model_pytorch import EfficientNet\n",
    "from utils import Bar,Logger, AverageMeter, accuracy, mkdir_p, savefig\n",
    "from warmup_scheduler import GradualWarmupScheduler\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "import cv2\n",
    "\n",
    "from PIL import ImageFile, ImageOps\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU device 2: True\n"
     ]
    }
   ],
   "source": [
    "# GPU Device\n",
    "gpu_id = 2\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(\"GPU device %d:\" %(gpu_id), use_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = '/media/data2/dataset/GAN_ImageData/PGGAN_128/'\n",
    "target_dir = '/media/data2/dataset/GAN_ImageData/StyleGAN2_256/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained = './log/pggan/128/b0/aug/checkpoint.pth.tar'\n",
    "resume = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model_name = 'efficientnet-b0' # b0-b7 scale\n",
    "\n",
    "# Optimization\n",
    "num_classes = 2\n",
    "epochs = 1000\n",
    "start_epoch = 0\n",
    "train_batch = 250\n",
    "test_batch = 250\n",
    "lr = 0.1\n",
    "momentum = 0.1\n",
    "gamma = 0.1 # LR is multiplied by gamma on schedule\n",
    "\n",
    "# CheckPoint\n",
    "checkpoint = './log/pggan/128/b0/to_style2/2000shot/self2' # dir\n",
    "if not os.path.isdir(checkpoint):\n",
    "    os.makedirs(checkpoint)\n",
    "num_workers = 8\n",
    "\n",
    "# Seed\n",
    "manual_seed = 7\n",
    "random.seed(manual_seed)\n",
    "torch.cuda.manual_seed_all(manual_seed)\n",
    "\n",
    "# Image\n",
    "size = (128, 128)\n",
    "\n",
    "# cutmix\n",
    "cm_prob = 0.5\n",
    "cm_beta = 1.0\n",
    "\n",
    "# augmentation\n",
    "blur_prob = 0.5\n",
    "blog_sig = 0.5\n",
    "jpg_prob = 0.5\n",
    "\n",
    "best_acc = 0\n",
    "\n",
    "# sp\n",
    "sp_alpha = 0.1\n",
    "sp_beta = 0.1\n",
    "fc_name = '_fc.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {}\n",
    "state['num_classes'] = num_classes\n",
    "state['epochs'] = epochs\n",
    "state['start_epoch'] = start_epoch\n",
    "state['train_batch'] = train_batch\n",
    "state['test_batch'] = test_batch\n",
    "state['lr'] = lr\n",
    "state['momentum'] = momentum\n",
    "state['gamma'] = gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_augment(img):\n",
    "    img = np.array(img)\n",
    "\n",
    "    if random.random() < blur_prob:\n",
    "        sig = np.random.uniform(0.0, 3.0)\n",
    "        gaussian_blur(img, sig)\n",
    "\n",
    "    if random.random() < jpg_prob:\n",
    "        qual = np.random.uniform(30.0, 100.0)\n",
    "        img = cv2_jpg(img, qual)\n",
    "\n",
    "    return Image.fromarray(img)\n",
    "\n",
    "\n",
    "def gaussian_blur(img, sigma):\n",
    "    gaussian_filter(img[:,:,0], output=img[:,:,0], sigma=sigma)\n",
    "    gaussian_filter(img[:,:,1], output=img[:,:,1], sigma=sigma)\n",
    "    gaussian_filter(img[:,:,2], output=img[:,:,2], sigma=sigma)\n",
    "\n",
    "\n",
    "def cv2_jpg(img, compress_val):\n",
    "    img_cv2 = img[:,:,::-1]\n",
    "    encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), compress_val]\n",
    "    result, encimg = cv2.imencode('.jpg', img_cv2, encode_param)\n",
    "    decimg = cv2.imdecode(encimg, 1)\n",
    "    return decimg[:,:,::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_bbox(size, lam):\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = np.int(W * cut_rat)\n",
    "    cut_h = np.int(H * cut_rat)\n",
    "\n",
    "    # uniform\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join(source_dir, 'style2/2000_shot')\n",
    "val_target_dir = os.path.join(target_dir, 'validation')\n",
    "val_source_dir = os.path.join(source_dir, 'validation')\n",
    "\n",
    "train_aug = transforms.Compose([\n",
    "    transforms.Lambda(lambda img: data_augment(img)),\n",
    "    transforms.Resize(size),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "val_aug = transforms.Compose([\n",
    "    transforms.Resize(size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# pin_memory : cuda pin memeory use\n",
    "train_loader = DataLoader(datasets.ImageFolder(train_dir, transform=train_aug),\n",
    "                          batch_size=train_batch, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "val_target_loader = DataLoader(datasets.ImageFolder(val_target_dir, val_aug),\n",
    "                       batch_size=test_batch, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "val_source_loader = DataLoader(datasets.ImageFolder(val_source_dir, val_aug),\n",
    "                       batch_size=test_batch, shuffle=True, num_workers=num_workers, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> using pre-trained model './log/pggan/128/b0/aug/checkpoint.pth.tar'\n"
     ]
    }
   ],
   "source": [
    "teacher_model = EfficientNet.from_name(model_name, num_classes=num_classes,\n",
    "                              override_params={'dropout_rate':0.2, 'drop_connect_rate':0.2})\n",
    "student_model = EfficientNet.from_name(model_name, num_classes=num_classes,\n",
    "                              override_params={'dropout_rate':0.2, 'drop_connect_rate':0.2})\n",
    "\n",
    "# Pre-trained\n",
    "if pretrained:\n",
    "    print(\"=> using pre-trained model '{}'\".format(pretrained))\n",
    "    teacher_model.load_state_dict(torch.load(pretrained)['state_dict'])\n",
    "    student_model.load_state_dict(torch.load(pretrained)['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Total params: 4.01M\n"
     ]
    }
   ],
   "source": [
    "teacher_model.to('cuda')\n",
    "student_model.to('cuda')\n",
    "cudnn.benchmark = True\n",
    "print('    Total params: %.2fM' % (sum(p.numel() for p in teacher_model.parameters())/1000000.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = optim.SGD(student_model.parameters(), lr=lr, momentum=momentum)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, 200, gamma=0.1, last_epoch=-1)\n",
    "scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)\n",
    "scheduler_warmup = GradualWarmupScheduler(optimizer, multiplier=2, total_epoch=50, after_scheduler=scheduler_cosine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resume\n",
    "if resume:\n",
    "    print('==> Resuming from checkpoint..')\n",
    "    checkpoint = os.path.dirname(resume)\n",
    "    resume = torch.load(resume)\n",
    "    best_acc = resume['best_acc']\n",
    "    start_epoch = resume['epoch']\n",
    "    student_model.load_state_dict(resume['state_dict'])\n",
    "    optimizer.load_state_dict(resume['optimizer'])\n",
    "    logger = Logger(os.path.join(checkpoint, 'log.txt'), resume=True)\n",
    "else:\n",
    "    logger = Logger(os.path.join(checkpoint, 'log.txt'))\n",
    "    logger.set_names(['Learning Rate', 'Train Loss', 'Valid Loss', 'Source Loss', 'Train AUROC', 'Valid AUROC', 'Source AUROC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EfficientNet(\n",
       "  (_conv_stem): Conv2dStaticSamePadding(\n",
       "    3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
       "    (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "  )\n",
       "  (_gn0): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "  (_blocks): ModuleList(\n",
       "    (0): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        32, 32, kernel_size=(3, 3), stride=[1, 1], groups=32, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        32, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        8, 32, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 16, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (1): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 96, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        96, 96, kernel_size=(3, 3), stride=[2, 2], groups=96, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 96, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        96, 4, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        4, 96, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 24, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (2): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 144, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 144, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 24, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (3): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 144, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        144, 144, kernel_size=(5, 5), stride=[2, 2], groups=144, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 144, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 40, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (4): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 240, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        240, 240, kernel_size=(5, 5), stride=(1, 1), groups=240, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 240, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 40, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (5): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 240, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        240, 240, kernel_size=(3, 3), stride=[2, 2], groups=240, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 240, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 80, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (6): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 480, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 480, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 80, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (7): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 480, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 480, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 80, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (8): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 480, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        480, 480, kernel_size=(5, 5), stride=[1, 1], groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 480, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 112, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (9): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 672, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 672, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 112, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (10): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 672, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 672, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 112, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (11): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 672, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5), stride=[2, 2], groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 672, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 192, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (12): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 1152, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 1152, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 192, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (13): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 1152, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 1152, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 192, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (14): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 1152, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 1152, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 192, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (15): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 1152, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(3, 3), stride=[1, 1], groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 1152, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 320, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "  )\n",
       "  (_conv_head): Conv2dStaticSamePadding(\n",
       "    320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "    (static_padding): Identity()\n",
       "  )\n",
       "  (_gn1): GroupNorm(8, 1280, eps=1e-05, affine=True)\n",
       "  (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n",
       "  (_dropout): Dropout(p=0.2, inplace=False)\n",
       "  (_fc): Linear(in_features=1280, out_features=2, bias=True)\n",
       "  (_swish): MemoryEfficientSwish()\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for param in teacher_model.parameters():\n",
    "    param.requires_grad = False\n",
    "teacher_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_model_weights = {}\n",
    "for name, param in teacher_model.named_parameters():\n",
    "    teacher_model_weights[name] = param.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_cls(model):\n",
    "    l2_cls = torch.tensor(0.).cuda()\n",
    "    for name, param in model.named_parameters():\n",
    "        if name.startswith(fc_name):\n",
    "            l2_cls += 0.5 * torch.norm(param) ** 2\n",
    "    return l2_cls\n",
    "\n",
    "def reg_l2sp(model):\n",
    "    sp_loss = torch.tensor(0.).cuda()\n",
    "    for name, param in model.named_parameters():\n",
    "        if not name.startswith(fc_name):\n",
    "            sp_loss += 0.5 * torch.norm(param - teacher_model_weights[name]) ** 2\n",
    "    return sp_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, teacher_model, student_model, criterion, optimizer, epoch, use_cuda):\n",
    "    teacher_model.eval()\n",
    "    student_model.train()\n",
    "    \n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    arc = AverageMeter()\n",
    "    end = time.time()\n",
    "    cls_losses = AverageMeter()\n",
    "    sp_losses = AverageMeter()\n",
    "    main_losses = AverageMeter()\n",
    "    alpha = AverageMeter()\n",
    "    \n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        batch_size = inputs.size(0)\n",
    "        if batch_size < train_batch:\n",
    "            continue\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            \n",
    "        r = np.random.rand(1)\n",
    "        if cm_beta > 0 and r < cm_prob:\n",
    "            \n",
    "            rand_index = torch.randperm(inputs.size()[0]).cuda()\n",
    "            tt= targets[rand_index]\n",
    "            boolean = targets==tt\n",
    "            rand_index = rand_index[boolean]\n",
    "            lam = np.random.beta(cm_beta, cm_beta)\n",
    "            bbx1, bby1, bbx2, bby2 = rand_bbox(inputs.size(), lam)\n",
    "            inputs[boolean, :, bbx1:bbx2, bby1:bby2] = inputs[rand_index, :, bbx1:bbx2, bby1:bby2]\n",
    "\n",
    "        # compute output\n",
    "        with torch.no_grad():\n",
    "            teacher_outputs = teacher_model(inputs)\n",
    "            teacher_loss = criterion(teacher_outputs, targets)\n",
    "            sp_alpha = 0\n",
    "            sigmoid = nn.Sigmoid()\n",
    "            sp_alpha += sigmoid(-teacher_loss)\n",
    "        \n",
    "        outputs = student_model(inputs)\n",
    "        loss_main = criterion(outputs, targets)\n",
    "        loss_cls = 0\n",
    "        loss_sp = 0\n",
    "        loss_cls = reg_cls(student_model)\n",
    "        loss_sp = reg_l2sp(student_model)\n",
    "        loss =  loss_main + 0.1*loss_sp + 0.1*loss_cls\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        losses.update(loss.data.tolist(), inputs.size(0))\n",
    "        cls_losses.update(loss_cls, inputs.size(0))\n",
    "        sp_losses.update(loss_sp, inputs.size(0))\n",
    "        main_losses.update(loss_main.tolist(), inputs.size(0))\n",
    "        alpha.update(sp_alpha, inputs.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        \n",
    "    print('Train | {batch}/{size} | Loss:{loss:.4f} | MainLoss:{main:.4f} | Alpha:{alp:.4f} | SPLoss:{sp:.4f} | CLSLoss:{cls:.4f} | AUROC:{ac:.4f}'.format(\n",
    "                     batch=batch_idx+1, size=len(train_loader), loss=losses.avg, main=main_losses.avg, alp=alpha.avg, sp=sp_losses.avg, cls=cls_losses.avg, ac=arc.avg))\n",
    "    return (losses.avg, arc.avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(val_loader, model, criterion, epoch, use_cuda):\n",
    "    global best_acc\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    arc = AverageMeter()\n",
    "    cls_losses = AverageMeter()\n",
    "    sp_losses = AverageMeter()\n",
    "    main_losses = AverageMeter()\n",
    "\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(val_loader):\n",
    "            # measure data loading time\n",
    "            data_time.update(time.time() - end)\n",
    "\n",
    "            if use_cuda:\n",
    "                inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "            # compute output\n",
    "            outputs = model(inputs)\n",
    "            loss_main = criterion(outputs, targets)\n",
    "            loss_cls = 0\n",
    "            loss_sp = 0\n",
    "            loss_cls = reg_cls(model)\n",
    "            loss_sp = reg_l2sp(model)\n",
    "            loss = loss_main + 0*loss_sp + 0*loss_cls\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            auroc = roc_auc_score(targets.cpu().detach().numpy(), outputs.cpu().detach().numpy()[:,1])\n",
    "            losses.update(loss.data.tolist(), inputs.size(0))\n",
    "            arc.update(auroc, inputs.size(0))\n",
    "            cls_losses.update(loss_cls, inputs.size(0))\n",
    "            sp_losses.update(loss_sp, inputs.size(0))\n",
    "            main_losses.update(loss_main.tolist(), inputs.size(0))\n",
    "\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "    print('Test | {batch}/{size} | Loss:{loss:.4f} | MainLoss:{main:.4f} | SPLoss:{sp:.4f} | CLSLoss:{cls:.4f} | AUROC:{ac:.4f}'.format(\n",
    "                     batch=batch_idx+1, size=len(train_loader), loss=losses.avg, main=main_losses.avg, sp=sp_losses.avg, cls=cls_losses.avg, ac=arc.avg))\n",
    "    return (losses.avg, arc.avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, checkpoint='checkpoint', filename='checkpoint.pth.tar'):\n",
    "    filepath = os.path.join(checkpoint, filename)\n",
    "    torch.save(state, filepath)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filepath, os.path.join(checkpoint, 'model_best.pth.tar'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [1 | 1000] LR: 0.100000\n",
      "Train | 16/16 | Loss:1.1415 | MainLoss:0.9020 | Alpha:0.0256 | SPLoss:1.0929 | CLSLoss:1.3017 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6923 | MainLoss:0.6923 | SPLoss:0.9854 | CLSLoss:1.0441 | AUROC:0.5695\n",
      "Test | 128/16 | Loss:0.6206 | MainLoss:0.6206 | SPLoss:0.9854 | CLSLoss:1.0441 | AUROC:1.0000\n",
      "\n",
      "Epoch: [2 | 1000] LR: 0.102000\n",
      "Train | 16/16 | Loss:0.8577 | MainLoss:0.6865 | Alpha:0.0253 | SPLoss:0.8241 | CLSLoss:0.8880 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6888 | MainLoss:0.6888 | SPLoss:0.6586 | CLSLoss:0.7335 | AUROC:0.5699\n",
      "Test | 128/16 | Loss:0.5028 | MainLoss:0.5028 | SPLoss:0.6586 | CLSLoss:0.7335 | AUROC:1.0000\n",
      "\n",
      "Epoch: [3 | 1000] LR: 0.104000\n",
      "Train | 16/16 | Loss:0.7926 | MainLoss:0.6757 | Alpha:0.0237 | SPLoss:0.5404 | CLSLoss:0.6283 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6836 | MainLoss:0.6836 | SPLoss:0.4317 | CLSLoss:0.5215 | AUROC:0.5840\n",
      "Test | 128/16 | Loss:0.2797 | MainLoss:0.2797 | SPLoss:0.4317 | CLSLoss:0.5215 | AUROC:1.0000\n",
      "\n",
      "Epoch: [4 | 1000] LR: 0.106000\n",
      "Train | 16/16 | Loss:0.7363 | MainLoss:0.6547 | Alpha:0.0270 | SPLoss:0.3659 | CLSLoss:0.4492 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6785 | MainLoss:0.6785 | SPLoss:0.3098 | CLSLoss:0.3779 | AUROC:0.6207\n",
      "Test | 128/16 | Loss:0.0901 | MainLoss:0.0901 | SPLoss:0.3098 | CLSLoss:0.3779 | AUROC:1.0000\n",
      "\n",
      "Epoch: [5 | 1000] LR: 0.108000\n",
      "Train | 16/16 | Loss:0.6992 | MainLoss:0.6369 | Alpha:0.0260 | SPLoss:0.2998 | CLSLoss:0.3237 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6482 | MainLoss:0.6482 | SPLoss:0.2989 | CLSLoss:0.2691 | AUROC:0.6741\n",
      "Test | 128/16 | Loss:0.1042 | MainLoss:0.1042 | SPLoss:0.2989 | CLSLoss:0.2691 | AUROC:1.0000\n",
      "\n",
      "Epoch: [6 | 1000] LR: 0.110000\n",
      "Train | 16/16 | Loss:0.6539 | MainLoss:0.5972 | Alpha:0.0258 | SPLoss:0.3283 | CLSLoss:0.2380 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6076 | MainLoss:0.6076 | SPLoss:0.3829 | CLSLoss:0.2070 | AUROC:0.7398\n",
      "Test | 128/16 | Loss:0.0612 | MainLoss:0.0612 | SPLoss:0.3829 | CLSLoss:0.2070 | AUROC:1.0000\n",
      "\n",
      "Epoch: [7 | 1000] LR: 0.112000\n",
      "Train | 16/16 | Loss:0.6193 | MainLoss:0.5501 | Alpha:0.0266 | SPLoss:0.5044 | CLSLoss:0.1873 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.5603 | MainLoss:0.5603 | SPLoss:0.6843 | CLSLoss:0.1542 | AUROC:0.8072\n",
      "Test | 128/16 | Loss:0.1390 | MainLoss:0.1390 | SPLoss:0.6843 | CLSLoss:0.1542 | AUROC:1.0000\n",
      "\n",
      "Epoch: [8 | 1000] LR: 0.114000\n",
      "Train | 16/16 | Loss:1.3744 | MainLoss:0.5116 | Alpha:0.0252 | SPLoss:8.4801 | CLSLoss:0.1471 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.4579 | MainLoss:0.4579 | SPLoss:9.4788 | CLSLoss:0.1542 | AUROC:0.8681\n",
      "Test | 128/16 | Loss:0.1454 | MainLoss:0.1454 | SPLoss:9.4788 | CLSLoss:0.1542 | AUROC:0.9986\n",
      "\n",
      "Epoch: [9 | 1000] LR: 0.116000\n",
      "Train | 16/16 | Loss:4.5901 | MainLoss:0.4735 | Alpha:0.0240 | SPLoss:41.0307 | CLSLoss:0.1348 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.4344 | MainLoss:0.4344 | SPLoss:41.2675 | CLSLoss:0.1563 | AUROC:0.8829\n",
      "Test | 128/16 | Loss:0.1991 | MainLoss:0.1991 | SPLoss:41.2675 | CLSLoss:0.1563 | AUROC:0.9978\n",
      "\n",
      "Epoch: [10 | 1000] LR: 0.118000\n",
      "Train | 16/16 | Loss:3.8536 | MainLoss:0.3975 | Alpha:0.0256 | SPLoss:34.4093 | CLSLoss:0.1520 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.4177 | MainLoss:0.4177 | SPLoss:27.6518 | CLSLoss:0.1561 | AUROC:0.9167\n",
      "Test | 128/16 | Loss:0.1563 | MainLoss:0.1563 | SPLoss:27.6518 | CLSLoss:0.1561 | AUROC:0.9962\n",
      "\n",
      "Epoch: [11 | 1000] LR: 0.120000\n",
      "Train | 16/16 | Loss:2.7067 | MainLoss:0.3771 | Alpha:0.0256 | SPLoss:23.1364 | CLSLoss:0.1586 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3568 | MainLoss:0.3568 | SPLoss:18.7818 | CLSLoss:0.1431 | AUROC:0.9367\n",
      "Test | 128/16 | Loss:0.2000 | MainLoss:0.2000 | SPLoss:18.7818 | CLSLoss:0.1431 | AUROC:0.9949\n",
      "\n",
      "Epoch: [12 | 1000] LR: 0.122000\n",
      "Train | 16/16 | Loss:1.9381 | MainLoss:0.3320 | Alpha:0.0261 | SPLoss:15.8978 | CLSLoss:0.1632 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2959 | MainLoss:0.2959 | SPLoss:13.0785 | CLSLoss:0.1639 | AUROC:0.9491\n",
      "Test | 128/16 | Loss:0.3155 | MainLoss:0.3155 | SPLoss:13.0785 | CLSLoss:0.1639 | AUROC:0.9904\n",
      "\n",
      "Epoch: [13 | 1000] LR: 0.124000\n",
      "Train | 16/16 | Loss:1.4226 | MainLoss:0.2972 | Alpha:0.0252 | SPLoss:11.0790 | CLSLoss:0.1752 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3661 | MainLoss:0.3661 | SPLoss:9.1439 | CLSLoss:0.1730 | AUROC:0.9559\n",
      "Test | 128/16 | Loss:0.1835 | MainLoss:0.1835 | SPLoss:9.1439 | CLSLoss:0.1730 | AUROC:0.9911\n",
      "\n",
      "Epoch: [14 | 1000] LR: 0.126000\n",
      "Train | 16/16 | Loss:1.0898 | MainLoss:0.2878 | Alpha:0.0253 | SPLoss:7.8430 | CLSLoss:0.1772 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2713 | MainLoss:0.2713 | SPLoss:6.5728 | CLSLoss:0.1840 | AUROC:0.9564\n",
      "Test | 128/16 | Loss:0.4520 | MainLoss:0.4520 | SPLoss:6.5728 | CLSLoss:0.1840 | AUROC:0.9777\n",
      "\n",
      "Epoch: [15 | 1000] LR: 0.128000\n",
      "Train | 16/16 | Loss:0.8726 | MainLoss:0.2594 | Alpha:0.0251 | SPLoss:5.9424 | CLSLoss:0.1892 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2890 | MainLoss:0.2890 | SPLoss:5.2795 | CLSLoss:0.1752 | AUROC:0.9559\n",
      "Test | 128/16 | Loss:0.3266 | MainLoss:0.3266 | SPLoss:5.2795 | CLSLoss:0.1752 | AUROC:0.9847\n",
      "\n",
      "Epoch: [16 | 1000] LR: 0.130000\n",
      "Train | 16/16 | Loss:0.7452 | MainLoss:0.2580 | Alpha:0.0267 | SPLoss:4.6905 | CLSLoss:0.1817 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2504 | MainLoss:0.2504 | SPLoss:4.1040 | CLSLoss:0.1961 | AUROC:0.9627\n",
      "Test | 128/16 | Loss:0.3485 | MainLoss:0.3485 | SPLoss:4.1040 | CLSLoss:0.1961 | AUROC:0.9870\n",
      "\n",
      "Epoch: [17 | 1000] LR: 0.132000\n",
      "Train | 16/16 | Loss:0.6598 | MainLoss:0.2637 | Alpha:0.0253 | SPLoss:3.7765 | CLSLoss:0.1847 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2409 | MainLoss:0.2409 | SPLoss:3.4159 | CLSLoss:0.1943 | AUROC:0.9679\n",
      "Test | 128/16 | Loss:0.3539 | MainLoss:0.3539 | SPLoss:3.4159 | CLSLoss:0.1943 | AUROC:0.9836\n",
      "\n",
      "Epoch: [18 | 1000] LR: 0.134000\n",
      "Train | 16/16 | Loss:0.5719 | MainLoss:0.2336 | Alpha:0.0269 | SPLoss:3.1968 | CLSLoss:0.1854 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3549 | MainLoss:0.3549 | SPLoss:2.9444 | CLSLoss:0.1897 | AUROC:0.9650\n",
      "Test | 128/16 | Loss:0.1735 | MainLoss:0.1735 | SPLoss:2.9444 | CLSLoss:0.1897 | AUROC:0.9906\n",
      "\n",
      "Epoch: [19 | 1000] LR: 0.136000\n",
      "Train | 16/16 | Loss:0.6653 | MainLoss:0.2742 | Alpha:0.0247 | SPLoss:3.7310 | CLSLoss:0.1799 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3596 | MainLoss:0.3596 | SPLoss:4.2116 | CLSLoss:0.1372 | AUROC:0.9732\n",
      "Test | 128/16 | Loss:0.2925 | MainLoss:0.2925 | SPLoss:4.2116 | CLSLoss:0.1372 | AUROC:0.9838\n",
      "\n",
      "Epoch: [20 | 1000] LR: 0.138000\n",
      "Train | 16/16 | Loss:0.6351 | MainLoss:0.2421 | Alpha:0.0277 | SPLoss:3.7533 | CLSLoss:0.1776 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2231 | MainLoss:0.2231 | SPLoss:3.3530 | CLSLoss:0.2023 | AUROC:0.9703\n",
      "Test | 128/16 | Loss:0.4178 | MainLoss:0.4178 | SPLoss:3.3530 | CLSLoss:0.2023 | AUROC:0.9850\n",
      "\n",
      "Epoch: [21 | 1000] LR: 0.140000\n",
      "Train | 16/16 | Loss:2.5181 | MainLoss:0.2760 | Alpha:0.0246 | SPLoss:22.2386 | CLSLoss:0.1823 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2494 | MainLoss:0.2494 | SPLoss:37.6679 | CLSLoss:0.1804 | AUROC:0.9637\n",
      "Test | 128/16 | Loss:0.3868 | MainLoss:0.3868 | SPLoss:37.6680 | CLSLoss:0.1804 | AUROC:0.9872\n",
      "\n",
      "Epoch: [22 | 1000] LR: 0.142000\n",
      "Train | 16/16 | Loss:3.3427 | MainLoss:0.2745 | Alpha:0.0263 | SPLoss:30.5105 | CLSLoss:0.1711 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2219 | MainLoss:0.2219 | SPLoss:23.5941 | CLSLoss:0.1823 | AUROC:0.9731\n",
      "Test | 128/16 | Loss:0.3166 | MainLoss:0.3166 | SPLoss:23.5941 | CLSLoss:0.1823 | AUROC:0.9856\n",
      "\n",
      "Epoch: [23 | 1000] LR: 0.144000\n",
      "Train | 16/16 | Loss:2.3454 | MainLoss:0.1994 | Alpha:0.0242 | SPLoss:21.2622 | CLSLoss:0.1973 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2399 | MainLoss:0.2399 | SPLoss:18.5970 | CLSLoss:0.2047 | AUROC:0.9658\n",
      "Test | 128/16 | Loss:0.3369 | MainLoss:0.3369 | SPLoss:18.5970 | CLSLoss:0.2047 | AUROC:0.9894\n",
      "\n",
      "Epoch: [24 | 1000] LR: 0.146000\n",
      "Train | 16/16 | Loss:1.8482 | MainLoss:0.2868 | Alpha:0.0253 | SPLoss:15.4309 | CLSLoss:0.1833 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2398 | MainLoss:0.2398 | SPLoss:12.4078 | CLSLoss:0.1960 | AUROC:0.9710\n",
      "Test | 128/16 | Loss:0.3022 | MainLoss:0.3022 | SPLoss:12.4078 | CLSLoss:0.1960 | AUROC:0.9868\n",
      "\n",
      "Epoch: [25 | 1000] LR: 0.148000\n",
      "Train | 16/16 | Loss:4.7951 | MainLoss:0.3215 | Alpha:0.0254 | SPLoss:44.5613 | CLSLoss:0.1750 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3019 | MainLoss:0.3019 | SPLoss:90.4553 | CLSLoss:0.1612 | AUROC:0.9480\n",
      "Test | 128/16 | Loss:0.4453 | MainLoss:0.4453 | SPLoss:90.4553 | CLSLoss:0.1612 | AUROC:0.9640\n",
      "\n",
      "Epoch: [26 | 1000] LR: 0.150000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 16/16 | Loss:7.5076 | MainLoss:0.3334 | Alpha:0.0240 | SPLoss:71.5865 | CLSLoss:0.1556 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2784 | MainLoss:0.2784 | SPLoss:53.6209 | CLSLoss:0.1743 | AUROC:0.9561\n",
      "Test | 128/16 | Loss:0.5341 | MainLoss:0.5341 | SPLoss:53.6210 | CLSLoss:0.1743 | AUROC:0.9783\n",
      "\n",
      "Epoch: [27 | 1000] LR: 0.152000\n",
      "Train | 16/16 | Loss:5.0454 | MainLoss:0.2930 | Alpha:0.0240 | SPLoss:47.3544 | CLSLoss:0.1696 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3733 | MainLoss:0.3733 | SPLoss:36.0319 | CLSLoss:0.1651 | AUROC:0.9593\n",
      "Test | 128/16 | Loss:0.3027 | MainLoss:0.3027 | SPLoss:36.0320 | CLSLoss:0.1651 | AUROC:0.9595\n",
      "\n",
      "Epoch: [28 | 1000] LR: 0.154000\n",
      "Train | 16/16 | Loss:3.1797 | MainLoss:0.2885 | Alpha:0.0250 | SPLoss:28.7387 | CLSLoss:0.1730 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2673 | MainLoss:0.2673 | SPLoss:22.6017 | CLSLoss:0.1843 | AUROC:0.9652\n",
      "Test | 128/16 | Loss:0.3841 | MainLoss:0.3841 | SPLoss:22.6017 | CLSLoss:0.1843 | AUROC:0.9748\n",
      "\n",
      "Epoch: [29 | 1000] LR: 0.156000\n",
      "Train | 16/16 | Loss:4.8366 | MainLoss:0.3019 | Alpha:0.0248 | SPLoss:45.1777 | CLSLoss:0.1694 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2708 | MainLoss:0.2708 | SPLoss:44.6204 | CLSLoss:0.1789 | AUROC:0.9595\n",
      "Test | 128/16 | Loss:0.3859 | MainLoss:0.3859 | SPLoss:44.6204 | CLSLoss:0.1789 | AUROC:0.9607\n",
      "\n",
      "Epoch: [30 | 1000] LR: 0.158000\n",
      "Train | 16/16 | Loss:3.8075 | MainLoss:0.2708 | Alpha:0.0250 | SPLoss:35.1883 | CLSLoss:0.1783 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3007 | MainLoss:0.3007 | SPLoss:26.2597 | CLSLoss:0.1909 | AUROC:0.9564\n",
      "Test | 128/16 | Loss:0.7761 | MainLoss:0.7761 | SPLoss:26.2597 | CLSLoss:0.1909 | AUROC:0.9422\n",
      "\n",
      "Epoch: [31 | 1000] LR: 0.160000\n",
      "Train | 16/16 | Loss:2.3747 | MainLoss:0.2689 | Alpha:0.0247 | SPLoss:20.8795 | CLSLoss:0.1787 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2586 | MainLoss:0.2586 | SPLoss:15.7861 | CLSLoss:0.1822 | AUROC:0.9599\n",
      "Test | 128/16 | Loss:0.5990 | MainLoss:0.5990 | SPLoss:15.7861 | CLSLoss:0.1822 | AUROC:0.9473\n",
      "\n",
      "Epoch: [32 | 1000] LR: 0.162000\n",
      "Train | 16/16 | Loss:1.5420 | MainLoss:0.2485 | Alpha:0.0255 | SPLoss:12.7538 | CLSLoss:0.1805 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.4413 | MainLoss:0.4413 | SPLoss:10.0894 | CLSLoss:0.1693 | AUROC:0.9502\n",
      "Test | 128/16 | Loss:0.9421 | MainLoss:0.9421 | SPLoss:10.0894 | CLSLoss:0.1693 | AUROC:0.9457\n",
      "\n",
      "Epoch: [33 | 1000] LR: 0.164000\n",
      "Train | 16/16 | Loss:1.1489 | MainLoss:0.2844 | Alpha:0.0257 | SPLoss:8.4807 | CLSLoss:0.1643 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.5634 | MainLoss:0.5634 | SPLoss:12.5038 | CLSLoss:0.1667 | AUROC:0.9586\n",
      "Test | 128/16 | Loss:0.3665 | MainLoss:0.3665 | SPLoss:12.5038 | CLSLoss:0.1667 | AUROC:0.9186\n",
      "\n",
      "Epoch: [34 | 1000] LR: 0.166000\n",
      "Train | 16/16 | Loss:18.3765 | MainLoss:0.2853 | Alpha:0.0278 | SPLoss:180.7427 | CLSLoss:0.1693 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3097 | MainLoss:0.3097 | SPLoss:146.4433 | CLSLoss:0.1730 | AUROC:0.9620\n",
      "Test | 128/16 | Loss:0.3351 | MainLoss:0.3351 | SPLoss:146.4433 | CLSLoss:0.1730 | AUROC:0.9819\n",
      "\n",
      "Epoch: [35 | 1000] LR: 0.168000\n",
      "Train | 16/16 | Loss:11.6422 | MainLoss:0.2951 | Alpha:0.0251 | SPLoss:113.3022 | CLSLoss:0.1694 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2668 | MainLoss:0.2668 | SPLoss:82.5645 | CLSLoss:0.1714 | AUROC:0.9604\n",
      "Test | 128/16 | Loss:0.5823 | MainLoss:0.5823 | SPLoss:82.5644 | CLSLoss:0.1714 | AUROC:0.9710\n",
      "\n",
      "Epoch: [36 | 1000] LR: 0.170000\n",
      "Train | 16/16 | Loss:6.6232 | MainLoss:0.2557 | Alpha:0.0263 | SPLoss:63.4968 | CLSLoss:0.1787 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2838 | MainLoss:0.2838 | SPLoss:45.8371 | CLSLoss:0.1587 | AUROC:0.9624\n",
      "Test | 128/16 | Loss:0.6037 | MainLoss:0.6037 | SPLoss:45.8370 | CLSLoss:0.1587 | AUROC:0.9658\n",
      "\n",
      "Epoch: [37 | 1000] LR: 0.172000\n",
      "Train | 16/16 | Loss:7.3530 | MainLoss:0.3670 | Alpha:0.0256 | SPLoss:69.7180 | CLSLoss:0.1428 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2745 | MainLoss:0.2745 | SPLoss:76.6537 | CLSLoss:0.1743 | AUROC:0.9588\n",
      "Test | 128/16 | Loss:0.3826 | MainLoss:0.3826 | SPLoss:76.6536 | CLSLoss:0.1743 | AUROC:0.9916\n",
      "\n",
      "Epoch: [38 | 1000] LR: 0.174000\n",
      "Train | 16/16 | Loss:6.4187 | MainLoss:0.2827 | Alpha:0.0258 | SPLoss:61.1835 | CLSLoss:0.1771 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2626 | MainLoss:0.2626 | SPLoss:48.0162 | CLSLoss:0.1934 | AUROC:0.9646\n",
      "Test | 128/16 | Loss:0.3553 | MainLoss:0.3553 | SPLoss:48.0162 | CLSLoss:0.1934 | AUROC:0.9817\n",
      "\n",
      "Epoch: [39 | 1000] LR: 0.176000\n",
      "Train | 16/16 | Loss:4.0137 | MainLoss:0.3080 | Alpha:0.0254 | SPLoss:36.8865 | CLSLoss:0.1703 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2606 | MainLoss:0.2606 | SPLoss:26.6129 | CLSLoss:0.1889 | AUROC:0.9668\n",
      "Test | 128/16 | Loss:0.4698 | MainLoss:0.4698 | SPLoss:26.6129 | CLSLoss:0.1889 | AUROC:0.9716\n",
      "\n",
      "Epoch: [40 | 1000] LR: 0.178000\n",
      "Train | 16/16 | Loss:2.6059 | MainLoss:0.3054 | Alpha:0.0265 | SPLoss:22.8323 | CLSLoss:0.1722 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3237 | MainLoss:0.3237 | SPLoss:25.9888 | CLSLoss:0.1845 | AUROC:0.9566\n",
      "Test | 128/16 | Loss:0.3092 | MainLoss:0.3092 | SPLoss:25.9888 | CLSLoss:0.1845 | AUROC:0.9845\n",
      "\n",
      "Epoch: [41 | 1000] LR: 0.180000\n",
      "Train | 16/16 | Loss:3.1445 | MainLoss:0.3368 | Alpha:0.0260 | SPLoss:27.9110 | CLSLoss:0.1653 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3312 | MainLoss:0.3312 | SPLoss:154.1874 | CLSLoss:0.1206 | AUROC:0.9570\n",
      "Test | 128/16 | Loss:0.4555 | MainLoss:0.4555 | SPLoss:154.1873 | CLSLoss:0.1206 | AUROC:0.9676\n",
      "\n",
      "Epoch: [42 | 1000] LR: 0.182000\n",
      "Train | 16/16 | Loss:12.1150 | MainLoss:0.2912 | Alpha:0.0263 | SPLoss:118.0688 | CLSLoss:0.1691 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2875 | MainLoss:0.2875 | SPLoss:82.8607 | CLSLoss:0.1710 | AUROC:0.9631\n",
      "Test | 128/16 | Loss:0.3727 | MainLoss:0.3727 | SPLoss:82.8607 | CLSLoss:0.1710 | AUROC:0.9739\n",
      "\n",
      "Epoch: [43 | 1000] LR: 0.184000\n",
      "Train | 16/16 | Loss:6.5459 | MainLoss:0.2843 | Alpha:0.0254 | SPLoss:62.4389 | CLSLoss:0.1774 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2598 | MainLoss:0.2598 | SPLoss:43.9598 | CLSLoss:0.1758 | AUROC:0.9605\n",
      "Test | 128/16 | Loss:0.5220 | MainLoss:0.5220 | SPLoss:43.9598 | CLSLoss:0.1758 | AUROC:0.9629\n",
      "\n",
      "Epoch: [44 | 1000] LR: 0.186000\n",
      "Train | 16/16 | Loss:3.9267 | MainLoss:0.2847 | Alpha:0.0268 | SPLoss:36.2436 | CLSLoss:0.1761 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3203 | MainLoss:0.3203 | SPLoss:43.1239 | CLSLoss:0.1460 | AUROC:0.9448\n",
      "Test | 128/16 | Loss:0.5116 | MainLoss:0.5116 | SPLoss:43.1240 | CLSLoss:0.1460 | AUROC:0.9733\n",
      "\n",
      "Epoch: [45 | 1000] LR: 0.188000\n",
      "Train | 16/16 | Loss:3.7205 | MainLoss:0.3067 | Alpha:0.0265 | SPLoss:33.9731 | CLSLoss:0.1646 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2490 | MainLoss:0.2490 | SPLoss:24.0930 | CLSLoss:0.1676 | AUROC:0.9644\n",
      "Test | 128/16 | Loss:0.4175 | MainLoss:0.4175 | SPLoss:24.0930 | CLSLoss:0.1676 | AUROC:0.9850\n",
      "\n",
      "Epoch: [46 | 1000] LR: 0.190000\n",
      "Train | 16/16 | Loss:2.8143 | MainLoss:0.2648 | Alpha:0.0252 | SPLoss:25.3174 | CLSLoss:0.1783 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3501 | MainLoss:0.3501 | SPLoss:106.6490 | CLSLoss:0.1655 | AUROC:0.9660\n",
      "Test | 128/16 | Loss:0.2513 | MainLoss:0.2513 | SPLoss:106.6490 | CLSLoss:0.1655 | AUROC:0.9898\n",
      "\n",
      "Epoch: [47 | 1000] LR: 0.192000\n",
      "Train | 16/16 | Loss:10.8965 | MainLoss:0.2969 | Alpha:0.0241 | SPLoss:105.8273 | CLSLoss:0.1691 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3314 | MainLoss:0.3314 | SPLoss:131.1093 | CLSLoss:0.1604 | AUROC:0.9433\n",
      "Test | 128/16 | Loss:0.8294 | MainLoss:0.8294 | SPLoss:131.1092 | CLSLoss:0.1604 | AUROC:0.9085\n",
      "\n",
      "Epoch: [48 | 1000] LR: 0.194000\n",
      "Train | 16/16 | Loss:10.0188 | MainLoss:0.2942 | Alpha:0.0259 | SPLoss:97.0871 | CLSLoss:0.1588 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2533 | MainLoss:0.2533 | SPLoss:66.3477 | CLSLoss:0.1739 | AUROC:0.9625\n",
      "Test | 128/16 | Loss:0.7208 | MainLoss:0.7208 | SPLoss:66.3476 | CLSLoss:0.1739 | AUROC:0.9397\n",
      "\n",
      "Epoch: [49 | 1000] LR: 0.196000\n",
      "Train | 16/16 | Loss:5.4290 | MainLoss:0.2884 | Alpha:0.0249 | SPLoss:51.2437 | CLSLoss:0.1617 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2610 | MainLoss:0.2610 | SPLoss:51.8541 | CLSLoss:0.1695 | AUROC:0.9686\n",
      "Test | 128/16 | Loss:0.4881 | MainLoss:0.4881 | SPLoss:51.8540 | CLSLoss:0.1695 | AUROC:0.9555\n",
      "\n",
      "Epoch: [50 | 1000] LR: 0.198000\n",
      "Train | 16/16 | Loss:4.1816 | MainLoss:0.2643 | Alpha:0.0260 | SPLoss:39.0038 | CLSLoss:0.1687 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2519 | MainLoss:0.2519 | SPLoss:27.8936 | CLSLoss:0.1520 | AUROC:0.9662\n",
      "Test | 128/16 | Loss:0.5783 | MainLoss:0.5783 | SPLoss:27.8935 | CLSLoss:0.1520 | AUROC:0.9528\n",
      "\n",
      "Epoch: [51 | 1000] LR: 0.200000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 16/16 | Loss:2.3949 | MainLoss:0.2797 | Alpha:0.0256 | SPLoss:20.9894 | CLSLoss:0.1626 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2608 | MainLoss:0.2608 | SPLoss:14.7331 | CLSLoss:0.1773 | AUROC:0.9633\n",
      "Test | 128/16 | Loss:0.8627 | MainLoss:0.8627 | SPLoss:14.7331 | CLSLoss:0.1773 | AUROC:0.9292\n",
      "\n",
      "Epoch: [52 | 1000] LR: 0.200000\n",
      "Train | 16/16 | Loss:19.3284 | MainLoss:0.3203 | Alpha:0.0253 | SPLoss:189.9150 | CLSLoss:0.1658 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6245 | MainLoss:0.6245 | SPLoss:765.6499 | CLSLoss:0.0715 | AUROC:0.8843\n",
      "Test | 128/16 | Loss:0.7110 | MainLoss:0.7110 | SPLoss:765.6487 | CLSLoss:0.0715 | AUROC:0.6025\n",
      "\n",
      "Epoch: [53 | 1000] LR: 0.200000\n",
      "Train | 16/16 | Loss:56.7560 | MainLoss:0.4192 | Alpha:0.0249 | SPLoss:563.2334 | CLSLoss:0.1338 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2859 | MainLoss:0.2859 | SPLoss:377.3233 | CLSLoss:0.1746 | AUROC:0.9557\n",
      "Test | 128/16 | Loss:0.5679 | MainLoss:0.5679 | SPLoss:377.3237 | CLSLoss:0.1746 | AUROC:0.9361\n",
      "\n",
      "Epoch: [54 | 1000] LR: 0.199998\n",
      "Train | 16/16 | Loss:28.3928 | MainLoss:0.4249 | Alpha:0.0287 | SPLoss:279.5301 | CLSLoss:0.1488 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3474 | MainLoss:0.3474 | SPLoss:194.4135 | CLSLoss:0.1358 | AUROC:0.9345\n",
      "Test | 128/16 | Loss:0.6090 | MainLoss:0.6090 | SPLoss:194.4138 | CLSLoss:0.1358 | AUROC:0.9401\n",
      "\n",
      "Epoch: [55 | 1000] LR: 0.199996\n",
      "Train | 16/16 | Loss:14.6231 | MainLoss:0.3384 | Alpha:0.0273 | SPLoss:142.6872 | CLSLoss:0.1594 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2781 | MainLoss:0.2781 | SPLoss:97.5777 | CLSLoss:0.1789 | AUROC:0.9629\n",
      "Test | 128/16 | Loss:0.9976 | MainLoss:0.9976 | SPLoss:97.5777 | CLSLoss:0.1789 | AUROC:0.8810\n",
      "\n",
      "Epoch: [56 | 1000] LR: 0.199992\n",
      "Train | 16/16 | Loss:7.5321 | MainLoss:0.3130 | Alpha:0.0255 | SPLoss:72.0282 | CLSLoss:0.1626 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2982 | MainLoss:0.2982 | SPLoss:49.6516 | CLSLoss:0.1516 | AUROC:0.9747\n",
      "Test | 128/16 | Loss:0.5130 | MainLoss:0.5130 | SPLoss:49.6515 | CLSLoss:0.1516 | AUROC:0.9288\n",
      "\n",
      "Epoch: [57 | 1000] LR: 0.199988\n",
      "Train | 16/16 | Loss:5.5203 | MainLoss:0.2892 | Alpha:0.0241 | SPLoss:52.1465 | CLSLoss:0.1642 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2467 | MainLoss:0.2467 | SPLoss:40.1640 | CLSLoss:0.1740 | AUROC:0.9710\n",
      "Test | 128/16 | Loss:0.6659 | MainLoss:0.6659 | SPLoss:40.1640 | CLSLoss:0.1740 | AUROC:0.9380\n",
      "\n",
      "Epoch: [58 | 1000] LR: 0.199982\n",
      "Train | 16/16 | Loss:16.6668 | MainLoss:0.3301 | Alpha:0.0253 | SPLoss:163.2094 | CLSLoss:0.1577 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2432 | MainLoss:0.2432 | SPLoss:234.0029 | CLSLoss:0.1687 | AUROC:0.9662\n",
      "Test | 128/16 | Loss:0.8002 | MainLoss:0.8002 | SPLoss:234.0025 | CLSLoss:0.1687 | AUROC:0.8982\n",
      "\n",
      "Epoch: [59 | 1000] LR: 0.199976\n",
      "Train | 16/16 | Loss:17.5040 | MainLoss:0.3386 | Alpha:0.0263 | SPLoss:171.4960 | CLSLoss:0.1580 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3458 | MainLoss:0.3458 | SPLoss:115.5995 | CLSLoss:0.1109 | AUROC:0.9688\n",
      "Test | 128/16 | Loss:0.6479 | MainLoss:0.6479 | SPLoss:115.5997 | CLSLoss:0.1109 | AUROC:0.7184\n",
      "\n",
      "Epoch: [60 | 1000] LR: 0.199968\n",
      "Train | 16/16 | Loss:9.2634 | MainLoss:0.3075 | Alpha:0.0257 | SPLoss:89.3935 | CLSLoss:0.1655 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2594 | MainLoss:0.2594 | SPLoss:64.4656 | CLSLoss:0.1580 | AUROC:0.9733\n",
      "Test | 128/16 | Loss:0.6453 | MainLoss:0.6453 | SPLoss:64.4655 | CLSLoss:0.1580 | AUROC:0.8949\n",
      "\n",
      "Epoch: [61 | 1000] LR: 0.199960\n",
      "Train | 16/16 | Loss:5.4481 | MainLoss:0.2632 | Alpha:0.0247 | SPLoss:51.6711 | CLSLoss:0.1779 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2149 | MainLoss:0.2149 | SPLoss:40.8605 | CLSLoss:0.1798 | AUROC:0.9739\n",
      "Test | 128/16 | Loss:0.7633 | MainLoss:0.7633 | SPLoss:40.8605 | CLSLoss:0.1798 | AUROC:0.9265\n",
      "\n",
      "Epoch: [62 | 1000] LR: 0.199951\n",
      "Train | 16/16 | Loss:3.6611 | MainLoss:0.2668 | Alpha:0.0231 | SPLoss:33.7692 | CLSLoss:0.1737 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2544 | MainLoss:0.2544 | SPLoss:23.8520 | CLSLoss:0.1847 | AUROC:0.9636\n",
      "Test | 128/16 | Loss:0.7898 | MainLoss:0.7898 | SPLoss:23.8520 | CLSLoss:0.1847 | AUROC:0.9487\n",
      "\n",
      "Epoch: [63 | 1000] LR: 0.199940\n",
      "Train | 16/16 | Loss:7.1175 | MainLoss:0.4033 | Alpha:0.0256 | SPLoss:66.9986 | CLSLoss:0.1435 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2909 | MainLoss:0.2909 | SPLoss:52.5284 | CLSLoss:0.1677 | AUROC:0.9626\n",
      "Test | 128/16 | Loss:0.5179 | MainLoss:0.5179 | SPLoss:52.5285 | CLSLoss:0.1677 | AUROC:0.9567\n",
      "\n",
      "Epoch: [64 | 1000] LR: 0.199929\n",
      "Train | 16/16 | Loss:4.3457 | MainLoss:0.2997 | Alpha:0.0251 | SPLoss:40.2954 | CLSLoss:0.1651 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2225 | MainLoss:0.2225 | SPLoss:33.7966 | CLSLoss:0.1616 | AUROC:0.9745\n",
      "Test | 128/16 | Loss:0.9427 | MainLoss:0.9427 | SPLoss:33.7966 | CLSLoss:0.1616 | AUROC:0.8957\n",
      "\n",
      "Epoch: [65 | 1000] LR: 0.199917\n",
      "Train | 16/16 | Loss:47.9429 | MainLoss:0.5115 | Alpha:0.0268 | SPLoss:474.2085 | CLSLoss:0.1057 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.4326 | MainLoss:0.4326 | SPLoss:386.1011 | CLSLoss:0.1136 | AUROC:0.9002\n",
      "Test | 128/16 | Loss:0.6226 | MainLoss:0.6226 | SPLoss:386.1010 | CLSLoss:0.1136 | AUROC:0.7659\n",
      "\n",
      "Epoch: [66 | 1000] LR: 0.199903\n",
      "Train | 16/16 | Loss:28.5657 | MainLoss:0.3536 | Alpha:0.0254 | SPLoss:281.9586 | CLSLoss:0.1623 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2699 | MainLoss:0.2699 | SPLoss:188.9655 | CLSLoss:0.1760 | AUROC:0.9700\n",
      "Test | 128/16 | Loss:0.6179 | MainLoss:0.6179 | SPLoss:188.9655 | CLSLoss:0.1761 | AUROC:0.9112\n",
      "\n",
      "Epoch: [67 | 1000] LR: 0.199889\n",
      "Train | 16/16 | Loss:16.5189 | MainLoss:0.3377 | Alpha:0.0249 | SPLoss:161.6475 | CLSLoss:0.1641 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2494 | MainLoss:0.2494 | SPLoss:117.0193 | CLSLoss:0.1810 | AUROC:0.9655\n",
      "Test | 128/16 | Loss:0.9810 | MainLoss:0.9810 | SPLoss:117.0192 | CLSLoss:0.1810 | AUROC:0.8559\n",
      "\n",
      "Epoch: [68 | 1000] LR: 0.199874\n",
      "Train | 16/16 | Loss:8.9326 | MainLoss:0.3049 | Alpha:0.0254 | SPLoss:86.1039 | CLSLoss:0.1732 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2353 | MainLoss:0.2353 | SPLoss:63.5392 | CLSLoss:0.1630 | AUROC:0.9711\n",
      "Test | 128/16 | Loss:0.6410 | MainLoss:0.6410 | SPLoss:63.5391 | CLSLoss:0.1630 | AUROC:0.8900\n",
      "\n",
      "Epoch: [69 | 1000] LR: 0.199857\n",
      "Train | 16/16 | Loss:5.1511 | MainLoss:0.3027 | Alpha:0.0270 | SPLoss:48.3140 | CLSLoss:0.1699 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6094 | MainLoss:0.6094 | SPLoss:33.6629 | CLSLoss:0.1174 | AUROC:0.9586\n",
      "Test | 128/16 | Loss:0.6026 | MainLoss:0.6026 | SPLoss:33.6630 | CLSLoss:0.1174 | AUROC:0.7812\n",
      "\n",
      "Epoch: [70 | 1000] LR: 0.199840\n",
      "Train | 16/16 | Loss:2.8310 | MainLoss:0.3088 | Alpha:0.0257 | SPLoss:25.0595 | CLSLoss:0.1624 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2587 | MainLoss:0.2587 | SPLoss:17.3760 | CLSLoss:0.1810 | AUROC:0.9649\n",
      "Test | 128/16 | Loss:0.8791 | MainLoss:0.8791 | SPLoss:17.3760 | CLSLoss:0.1810 | AUROC:0.8657\n",
      "\n",
      "Epoch: [71 | 1000] LR: 0.199822\n",
      "Train | 16/16 | Loss:5.2508 | MainLoss:0.2850 | Alpha:0.0246 | SPLoss:49.4826 | CLSLoss:0.1755 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3270 | MainLoss:0.3270 | SPLoss:40.6064 | CLSLoss:0.1543 | AUROC:0.9651\n",
      "Test | 128/16 | Loss:0.7951 | MainLoss:0.7951 | SPLoss:40.6064 | CLSLoss:0.1543 | AUROC:0.9119\n",
      "\n",
      "Epoch: [72 | 1000] LR: 0.199803\n",
      "Train | 16/16 | Loss:4.4296 | MainLoss:0.3041 | Alpha:0.0260 | SPLoss:41.0902 | CLSLoss:0.1649 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2403 | MainLoss:0.2403 | SPLoss:34.7291 | CLSLoss:0.1705 | AUROC:0.9759\n",
      "Test | 128/16 | Loss:0.5315 | MainLoss:0.5315 | SPLoss:34.7292 | CLSLoss:0.1705 | AUROC:0.9338\n",
      "\n",
      "Epoch: [73 | 1000] LR: 0.199782\n",
      "Train | 16/16 | Loss:2.9687 | MainLoss:0.2679 | Alpha:0.0248 | SPLoss:26.8340 | CLSLoss:0.1741 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2138 | MainLoss:0.2138 | SPLoss:19.5703 | CLSLoss:0.1771 | AUROC:0.9766\n",
      "Test | 128/16 | Loss:0.6329 | MainLoss:0.6329 | SPLoss:19.5703 | CLSLoss:0.1771 | AUROC:0.9272\n",
      "\n",
      "Epoch: [74 | 1000] LR: 0.199761\n",
      "Train | 16/16 | Loss:1.9807 | MainLoss:0.2679 | Alpha:0.0258 | SPLoss:16.9460 | CLSLoss:0.1814 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6029 | MainLoss:0.6029 | SPLoss:78.7993 | CLSLoss:0.1442 | AUROC:0.9552\n",
      "Test | 128/16 | Loss:0.4046 | MainLoss:0.4046 | SPLoss:78.7993 | CLSLoss:0.1442 | AUROC:0.9086\n",
      "\n",
      "Epoch: [75 | 1000] LR: 0.199739\n",
      "Train | 16/16 | Loss:7.1808 | MainLoss:0.3038 | Alpha:0.0275 | SPLoss:68.6063 | CLSLoss:0.1640 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2182 | MainLoss:0.2182 | SPLoss:49.0127 | CLSLoss:0.1753 | AUROC:0.9730\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 128/16 | Loss:0.5707 | MainLoss:0.5707 | SPLoss:49.0126 | CLSLoss:0.1753 | AUROC:0.9478\n",
      "\n",
      "Epoch: [76 | 1000] LR: 0.199716\n",
      "Train | 16/16 | Loss:4.1075 | MainLoss:0.2796 | Alpha:0.0261 | SPLoss:38.1068 | CLSLoss:0.1715 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2570 | MainLoss:0.2570 | SPLoss:29.3644 | CLSLoss:0.1387 | AUROC:0.9713\n",
      "Test | 128/16 | Loss:0.8624 | MainLoss:0.8624 | SPLoss:29.3643 | CLSLoss:0.1387 | AUROC:0.8887\n",
      "\n",
      "Epoch: [77 | 1000] LR: 0.199692\n",
      "Train | 16/16 | Loss:2.6397 | MainLoss:0.2895 | Alpha:0.0271 | SPLoss:23.3448 | CLSLoss:0.1566 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2169 | MainLoss:0.2169 | SPLoss:17.7361 | CLSLoss:0.1659 | AUROC:0.9733\n",
      "Test | 128/16 | Loss:0.6600 | MainLoss:0.6600 | SPLoss:17.7361 | CLSLoss:0.1659 | AUROC:0.9294\n",
      "\n",
      "Epoch: [78 | 1000] LR: 0.199667\n",
      "Train | 16/16 | Loss:15.7095 | MainLoss:0.3914 | Alpha:0.0251 | SPLoss:153.0348 | CLSLoss:0.1454 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3263 | MainLoss:0.3263 | SPLoss:154.4740 | CLSLoss:0.1277 | AUROC:0.9465\n",
      "Test | 128/16 | Loss:0.6199 | MainLoss:0.6199 | SPLoss:154.4740 | CLSLoss:0.1277 | AUROC:0.8193\n",
      "\n",
      "Epoch: [79 | 1000] LR: 0.199640\n",
      "Train | 16/16 | Loss:12.5745 | MainLoss:0.3360 | Alpha:0.0245 | SPLoss:122.2332 | CLSLoss:0.1524 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3070 | MainLoss:0.3070 | SPLoss:84.5825 | CLSLoss:0.1271 | AUROC:0.9637\n",
      "Test | 128/16 | Loss:0.5592 | MainLoss:0.5592 | SPLoss:84.5826 | CLSLoss:0.1271 | AUROC:0.8648\n",
      "\n",
      "Epoch: [80 | 1000] LR: 0.199613\n",
      "Train | 16/16 | Loss:6.7028 | MainLoss:0.3025 | Alpha:0.0241 | SPLoss:63.8411 | CLSLoss:0.1620 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2686 | MainLoss:0.2686 | SPLoss:47.6759 | CLSLoss:0.1512 | AUROC:0.9611\n",
      "Test | 128/16 | Loss:0.6852 | MainLoss:0.6852 | SPLoss:47.6759 | CLSLoss:0.1512 | AUROC:0.9310\n",
      "\n",
      "Epoch: [81 | 1000] LR: 0.199585\n",
      "Train | 16/16 | Loss:3.8682 | MainLoss:0.2960 | Alpha:0.0256 | SPLoss:35.5631 | CLSLoss:0.1587 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2952 | MainLoss:0.2952 | SPLoss:24.4920 | CLSLoss:0.1746 | AUROC:0.9662\n",
      "Test | 128/16 | Loss:0.5717 | MainLoss:0.5717 | SPLoss:24.4920 | CLSLoss:0.1746 | AUROC:0.9278\n",
      "\n",
      "Epoch: [82 | 1000] LR: 0.199556\n",
      "Train | 16/16 | Loss:2.1363 | MainLoss:0.2721 | Alpha:0.0255 | SPLoss:18.4726 | CLSLoss:0.1694 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.5152 | MainLoss:0.5152 | SPLoss:13.1298 | CLSLoss:0.1573 | AUROC:0.9624\n",
      "Test | 128/16 | Loss:0.3039 | MainLoss:0.3039 | SPLoss:13.1298 | CLSLoss:0.1573 | AUROC:0.9578\n",
      "\n",
      "Epoch: [83 | 1000] LR: 0.199526\n",
      "Train | 16/16 | Loss:2.0775 | MainLoss:0.3028 | Alpha:0.0263 | SPLoss:17.5818 | CLSLoss:0.1645 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2596 | MainLoss:0.2596 | SPLoss:39.4409 | CLSLoss:0.1584 | AUROC:0.9605\n",
      "Test | 128/16 | Loss:0.8883 | MainLoss:0.8883 | SPLoss:39.4409 | CLSLoss:0.1584 | AUROC:0.7748\n",
      "\n",
      "Epoch: [84 | 1000] LR: 0.199495\n",
      "Train | 16/16 | Loss:3.2524 | MainLoss:0.3041 | Alpha:0.0253 | SPLoss:29.3202 | CLSLoss:0.1629 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.4234 | MainLoss:0.4234 | SPLoss:20.4166 | CLSLoss:0.1411 | AUROC:0.9671\n",
      "Test | 128/16 | Loss:0.4565 | MainLoss:0.4565 | SPLoss:20.4166 | CLSLoss:0.1411 | AUROC:0.8880\n",
      "\n",
      "Epoch: [85 | 1000] LR: 0.199463\n",
      "Train | 16/16 | Loss:2.6219 | MainLoss:0.2844 | Alpha:0.0252 | SPLoss:23.2128 | CLSLoss:0.1622 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3351 | MainLoss:0.3351 | SPLoss:22.7397 | CLSLoss:0.1825 | AUROC:0.9585\n",
      "Test | 128/16 | Loss:1.0500 | MainLoss:1.0500 | SPLoss:22.7397 | CLSLoss:0.1825 | AUROC:0.8996\n",
      "\n",
      "Epoch: [86 | 1000] LR: 0.199430\n",
      "Train | 16/16 | Loss:2.0685 | MainLoss:0.3129 | Alpha:0.0260 | SPLoss:17.3930 | CLSLoss:0.1623 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3571 | MainLoss:0.3571 | SPLoss:12.5564 | CLSLoss:0.1641 | AUROC:0.9712\n",
      "Test | 128/16 | Loss:0.4046 | MainLoss:0.4046 | SPLoss:12.5564 | CLSLoss:0.1641 | AUROC:0.9358\n",
      "\n",
      "Epoch: [87 | 1000] LR: 0.199396\n",
      "Train | 16/16 | Loss:1.2860 | MainLoss:0.2796 | Alpha:0.0284 | SPLoss:9.8923 | CLSLoss:0.1709 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3175 | MainLoss:0.3175 | SPLoss:7.6433 | CLSLoss:0.1649 | AUROC:0.9644\n",
      "Test | 128/16 | Loss:1.0659 | MainLoss:1.0659 | SPLoss:7.6433 | CLSLoss:0.1649 | AUROC:0.8730\n",
      "\n",
      "Epoch: [88 | 1000] LR: 0.199361\n",
      "Train | 16/16 | Loss:13.1618 | MainLoss:0.3345 | Alpha:0.0258 | SPLoss:128.1225 | CLSLoss:0.1505 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2821 | MainLoss:0.2821 | SPLoss:105.1430 | CLSLoss:0.1628 | AUROC:0.9631\n",
      "Test | 128/16 | Loss:0.6335 | MainLoss:0.6335 | SPLoss:105.1430 | CLSLoss:0.1628 | AUROC:0.8809\n",
      "\n",
      "Epoch: [89 | 1000] LR: 0.199325\n",
      "Train | 16/16 | Loss:8.0535 | MainLoss:0.2955 | Alpha:0.0245 | SPLoss:77.4194 | CLSLoss:0.1605 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2554 | MainLoss:0.2554 | SPLoss:53.1844 | CLSLoss:0.1409 | AUROC:0.9673\n",
      "Test | 128/16 | Loss:0.7219 | MainLoss:0.7219 | SPLoss:53.1844 | CLSLoss:0.1409 | AUROC:0.8329\n",
      "\n",
      "Epoch: [90 | 1000] LR: 0.199288\n",
      "Train | 16/16 | Loss:4.2546 | MainLoss:0.2759 | Alpha:0.0260 | SPLoss:39.6199 | CLSLoss:0.1662 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2249 | MainLoss:0.2249 | SPLoss:27.4384 | CLSLoss:0.1767 | AUROC:0.9718\n",
      "Test | 128/16 | Loss:0.6772 | MainLoss:0.6772 | SPLoss:27.4383 | CLSLoss:0.1767 | AUROC:0.9128\n",
      "\n",
      "Epoch: [91 | 1000] LR: 0.199250\n",
      "Train | 16/16 | Loss:2.8535 | MainLoss:0.3530 | Alpha:0.0284 | SPLoss:24.8479 | CLSLoss:0.1572 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.5060 | MainLoss:0.5060 | SPLoss:47.7681 | CLSLoss:0.1154 | AUROC:0.9327\n",
      "Test | 128/16 | Loss:0.9409 | MainLoss:0.9409 | SPLoss:47.7681 | CLSLoss:0.1154 | AUROC:0.7128\n",
      "\n",
      "Epoch: [92 | 1000] LR: 0.199211\n",
      "Train | 16/16 | Loss:4.2974 | MainLoss:0.3358 | Alpha:0.0263 | SPLoss:39.4703 | CLSLoss:0.1451 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.4587 | MainLoss:0.4587 | SPLoss:27.5151 | CLSLoss:0.1593 | AUROC:0.9656\n",
      "Test | 128/16 | Loss:0.4621 | MainLoss:0.4621 | SPLoss:27.5151 | CLSLoss:0.1593 | AUROC:0.8958\n",
      "\n",
      "Epoch: [93 | 1000] LR: 0.199172\n",
      "Train | 16/16 | Loss:3.1286 | MainLoss:0.3565 | Alpha:0.0272 | SPLoss:27.5754 | CLSLoss:0.1452 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2663 | MainLoss:0.2663 | SPLoss:22.0292 | CLSLoss:0.1539 | AUROC:0.9595\n",
      "Test | 128/16 | Loss:0.7039 | MainLoss:0.7039 | SPLoss:22.0292 | CLSLoss:0.1539 | AUROC:0.8629\n",
      "\n",
      "Epoch: [94 | 1000] LR: 0.199131\n",
      "Train | 16/16 | Loss:2.0698 | MainLoss:0.3016 | Alpha:0.0261 | SPLoss:17.5208 | CLSLoss:0.1619 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3966 | MainLoss:0.3966 | SPLoss:26.7399 | CLSLoss:0.1507 | AUROC:0.9533\n",
      "Test | 128/16 | Loss:0.7743 | MainLoss:0.7743 | SPLoss:26.7400 | CLSLoss:0.1507 | AUROC:0.9416\n",
      "\n",
      "Epoch: [95 | 1000] LR: 0.199089\n",
      "Train | 16/16 | Loss:2.7404 | MainLoss:0.3118 | Alpha:0.0257 | SPLoss:24.1311 | CLSLoss:0.1550 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2413 | MainLoss:0.2413 | SPLoss:27.6935 | CLSLoss:0.1529 | AUROC:0.9686\n",
      "Test | 128/16 | Loss:0.6148 | MainLoss:0.6148 | SPLoss:27.6935 | CLSLoss:0.1529 | AUROC:0.8907\n",
      "\n",
      "Epoch: [96 | 1000] LR: 0.199046\n",
      "Train | 16/16 | Loss:8.0445 | MainLoss:0.2792 | Alpha:0.0253 | SPLoss:77.4910 | CLSLoss:0.1614 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3874 | MainLoss:0.3874 | SPLoss:80.1068 | CLSLoss:0.1608 | AUROC:0.9660\n",
      "Test | 128/16 | Loss:0.2930 | MainLoss:0.2930 | SPLoss:80.1069 | CLSLoss:0.1608 | AUROC:0.9633\n",
      "\n",
      "Epoch: [97 | 1000] LR: 0.199002\n",
      "Train | 16/16 | Loss:6.4889 | MainLoss:0.3783 | Alpha:0.0260 | SPLoss:60.9641 | CLSLoss:0.1417 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.4434 | MainLoss:0.4434 | SPLoss:46.6835 | CLSLoss:0.0878 | AUROC:0.9257\n",
      "Test | 128/16 | Loss:0.5353 | MainLoss:0.5353 | SPLoss:46.6835 | CLSLoss:0.0878 | AUROC:0.9036\n",
      "\n",
      "Epoch: [98 | 1000] LR: 0.198958\n",
      "Train | 16/16 | Loss:4.1869 | MainLoss:0.3753 | Alpha:0.0267 | SPLoss:37.9667 | CLSLoss:0.1496 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.4507 | MainLoss:0.4507 | SPLoss:574.4460 | CLSLoss:0.1526 | AUROC:0.9530\n",
      "Test | 128/16 | Loss:0.5419 | MainLoss:0.5419 | SPLoss:574.4470 | CLSLoss:0.1526 | AUROC:0.8208\n",
      "\n",
      "Epoch: [99 | 1000] LR: 0.198912\n",
      "Train | 16/16 | Loss:54.2912 | MainLoss:0.3368 | Alpha:0.0266 | SPLoss:539.3843 | CLSLoss:0.1590 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2980 | MainLoss:0.2980 | SPLoss:370.1759 | CLSLoss:0.1737 | AUROC:0.9639\n",
      "Test | 128/16 | Loss:0.6924 | MainLoss:0.6924 | SPLoss:370.1759 | CLSLoss:0.1737 | AUROC:0.8173\n",
      "\n",
      "Epoch: [100 | 1000] LR: 0.198865\n",
      "Train | 16/16 | Loss:27.7211 | MainLoss:0.3375 | Alpha:0.0261 | SPLoss:273.6793 | CLSLoss:0.1567 | AUROC:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 32/16 | Loss:0.2570 | MainLoss:0.2570 | SPLoss:189.5985 | CLSLoss:0.1531 | AUROC:0.9645\n",
      "Test | 128/16 | Loss:0.8735 | MainLoss:0.8735 | SPLoss:189.5985 | CLSLoss:0.1531 | AUROC:0.7464\n",
      "\n",
      "Epoch: [101 | 1000] LR: 0.198817\n",
      "Train | 16/16 | Loss:0.4812 | MainLoss:0.2915 | Alpha:0.4349 | SPLoss:1.7409 | CLSLoss:0.1565 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2100 | MainLoss:0.2100 | SPLoss:2.0563 | CLSLoss:0.1668 | AUROC:0.9768\n",
      "Test | 128/16 | Loss:0.9472 | MainLoss:0.9472 | SPLoss:2.0563 | CLSLoss:0.1668 | AUROC:0.7438\n",
      "\n",
      "Epoch: [102 | 1000] LR: 0.198769\n",
      "Train | 16/16 | Loss:0.4199 | MainLoss:0.2333 | Alpha:0.4352 | SPLoss:1.6967 | CLSLoss:0.1698 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2031 | MainLoss:0.2031 | SPLoss:1.3900 | CLSLoss:0.1659 | AUROC:0.9803\n",
      "Test | 128/16 | Loss:1.1294 | MainLoss:1.1294 | SPLoss:1.3900 | CLSLoss:0.1659 | AUROC:0.6997\n",
      "\n",
      "Epoch: [103 | 1000] LR: 0.198719\n",
      "Train | 16/16 | Loss:0.3601 | MainLoss:0.2187 | Alpha:0.4339 | SPLoss:1.2495 | CLSLoss:0.1643 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1805 | MainLoss:0.1805 | SPLoss:1.1179 | CLSLoss:0.1754 | AUROC:0.9817\n",
      "Test | 128/16 | Loss:1.2305 | MainLoss:1.2305 | SPLoss:1.1179 | CLSLoss:0.1754 | AUROC:0.7894\n",
      "\n",
      "Epoch: [104 | 1000] LR: 0.198669\n",
      "Train | 16/16 | Loss:0.3475 | MainLoss:0.2227 | Alpha:0.4352 | SPLoss:1.0861 | CLSLoss:0.1618 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1861 | MainLoss:0.1861 | SPLoss:1.0007 | CLSLoss:0.1849 | AUROC:0.9820\n",
      "Test | 128/16 | Loss:1.1094 | MainLoss:1.1094 | SPLoss:1.0007 | CLSLoss:0.1849 | AUROC:0.7918\n",
      "\n",
      "Epoch: [105 | 1000] LR: 0.198617\n",
      "Train | 16/16 | Loss:0.3190 | MainLoss:0.2016 | Alpha:0.4341 | SPLoss:1.0001 | CLSLoss:0.1742 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2114 | MainLoss:0.2114 | SPLoss:0.9706 | CLSLoss:0.1521 | AUROC:0.9821\n",
      "Test | 128/16 | Loss:1.2681 | MainLoss:1.2681 | SPLoss:0.9706 | CLSLoss:0.1521 | AUROC:0.7369\n",
      "\n",
      "Epoch: [106 | 1000] LR: 0.198564\n",
      "Train | 16/16 | Loss:0.3117 | MainLoss:0.1961 | Alpha:0.4383 | SPLoss:0.9903 | CLSLoss:0.1655 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2117 | MainLoss:0.2117 | SPLoss:0.9780 | CLSLoss:0.1714 | AUROC:0.9794\n",
      "Test | 128/16 | Loss:1.0202 | MainLoss:1.0202 | SPLoss:0.9780 | CLSLoss:0.1714 | AUROC:0.7787\n",
      "\n",
      "Epoch: [107 | 1000] LR: 0.198511\n",
      "Train | 16/16 | Loss:0.3202 | MainLoss:0.2061 | Alpha:0.4361 | SPLoss:0.9765 | CLSLoss:0.1639 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1952 | MainLoss:0.1952 | SPLoss:0.9521 | CLSLoss:0.1616 | AUROC:0.9815\n",
      "Test | 128/16 | Loss:0.9435 | MainLoss:0.9435 | SPLoss:0.9521 | CLSLoss:0.1616 | AUROC:0.7764\n",
      "\n",
      "Epoch: [108 | 1000] LR: 0.198456\n",
      "Train | 16/16 | Loss:0.2983 | MainLoss:0.1920 | Alpha:0.4369 | SPLoss:0.9019 | CLSLoss:0.1607 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1655 | MainLoss:0.1655 | SPLoss:0.8858 | CLSLoss:0.1576 | AUROC:0.9838\n",
      "Test | 128/16 | Loss:1.1632 | MainLoss:1.1632 | SPLoss:0.8858 | CLSLoss:0.1576 | AUROC:0.7619\n",
      "\n",
      "Epoch: [109 | 1000] LR: 0.198401\n",
      "Train | 16/16 | Loss:0.2974 | MainLoss:0.1902 | Alpha:0.4376 | SPLoss:0.9120 | CLSLoss:0.1599 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1753 | MainLoss:0.1753 | SPLoss:1.0016 | CLSLoss:0.1725 | AUROC:0.9827\n",
      "Test | 128/16 | Loss:1.1975 | MainLoss:1.1975 | SPLoss:1.0016 | CLSLoss:0.1725 | AUROC:0.7654\n",
      "\n",
      "Epoch: [110 | 1000] LR: 0.198345\n",
      "Train | 16/16 | Loss:0.3267 | MainLoss:0.2092 | Alpha:0.4354 | SPLoss:1.0169 | CLSLoss:0.1587 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1942 | MainLoss:0.1942 | SPLoss:0.9722 | CLSLoss:0.1456 | AUROC:0.9836\n",
      "Test | 128/16 | Loss:0.8989 | MainLoss:0.8989 | SPLoss:0.9722 | CLSLoss:0.1456 | AUROC:0.7817\n",
      "\n",
      "Epoch: [111 | 1000] LR: 0.198287\n",
      "Train | 16/16 | Loss:0.3132 | MainLoss:0.1993 | Alpha:0.4338 | SPLoss:0.9789 | CLSLoss:0.1603 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1927 | MainLoss:0.1927 | SPLoss:1.0180 | CLSLoss:0.1640 | AUROC:0.9821\n",
      "Test | 128/16 | Loss:1.2290 | MainLoss:1.2290 | SPLoss:1.0180 | CLSLoss:0.1640 | AUROC:0.7887\n",
      "\n",
      "Epoch: [112 | 1000] LR: 0.198229\n",
      "Train | 16/16 | Loss:0.5500 | MainLoss:0.2267 | Alpha:0.4352 | SPLoss:3.0785 | CLSLoss:0.1539 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1732 | MainLoss:0.1732 | SPLoss:4.2220 | CLSLoss:0.1548 | AUROC:0.9832\n",
      "Test | 128/16 | Loss:1.1157 | MainLoss:1.1157 | SPLoss:4.2220 | CLSLoss:0.1548 | AUROC:0.7346\n",
      "\n",
      "Epoch: [113 | 1000] LR: 0.198169\n",
      "Train | 16/16 | Loss:0.5673 | MainLoss:0.2168 | Alpha:0.4337 | SPLoss:3.3472 | CLSLoss:0.1571 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2477 | MainLoss:0.2477 | SPLoss:2.6050 | CLSLoss:0.1495 | AUROC:0.9842\n",
      "Test | 128/16 | Loss:0.8256 | MainLoss:0.8256 | SPLoss:2.6050 | CLSLoss:0.1495 | AUROC:0.7610\n",
      "\n",
      "Epoch: [114 | 1000] LR: 0.198109\n",
      "Train | 16/16 | Loss:0.4445 | MainLoss:0.2111 | Alpha:0.4349 | SPLoss:2.1765 | CLSLoss:0.1575 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1653 | MainLoss:0.1653 | SPLoss:1.8281 | CLSLoss:0.1606 | AUROC:0.9844\n",
      "Test | 128/16 | Loss:1.2949 | MainLoss:1.2949 | SPLoss:1.8281 | CLSLoss:0.1606 | AUROC:0.7081\n",
      "\n",
      "Epoch: [115 | 1000] LR: 0.198048\n",
      "Train | 16/16 | Loss:0.3753 | MainLoss:0.1997 | Alpha:0.4355 | SPLoss:1.5936 | CLSLoss:0.1622 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1863 | MainLoss:0.1863 | SPLoss:1.4102 | CLSLoss:0.1306 | AUROC:0.9834\n",
      "Test | 128/16 | Loss:0.9994 | MainLoss:0.9994 | SPLoss:1.4102 | CLSLoss:0.1306 | AUROC:0.7032\n",
      "\n",
      "Epoch: [116 | 1000] LR: 0.197986\n",
      "Train | 16/16 | Loss:0.4516 | MainLoss:0.2069 | Alpha:0.4368 | SPLoss:2.2938 | CLSLoss:0.1532 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3111 | MainLoss:0.3111 | SPLoss:4.5840 | CLSLoss:0.1461 | AUROC:0.9800\n",
      "Test | 128/16 | Loss:0.7648 | MainLoss:0.7648 | SPLoss:4.5840 | CLSLoss:0.1461 | AUROC:0.7586\n",
      "\n",
      "Epoch: [117 | 1000] LR: 0.197922\n",
      "Train | 16/16 | Loss:0.6497 | MainLoss:0.2364 | Alpha:0.4341 | SPLoss:3.9891 | CLSLoss:0.1446 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1888 | MainLoss:0.1888 | SPLoss:4.2349 | CLSLoss:0.1537 | AUROC:0.9836\n",
      "Test | 128/16 | Loss:1.0057 | MainLoss:1.0057 | SPLoss:4.2349 | CLSLoss:0.1537 | AUROC:0.7693\n",
      "\n",
      "Epoch: [118 | 1000] LR: 0.197858\n",
      "Train | 16/16 | Loss:0.5597 | MainLoss:0.2037 | Alpha:0.4333 | SPLoss:3.4003 | CLSLoss:0.1599 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2751 | MainLoss:0.2751 | SPLoss:2.6200 | CLSLoss:0.1482 | AUROC:0.9830\n",
      "Test | 128/16 | Loss:0.7121 | MainLoss:0.7121 | SPLoss:2.6200 | CLSLoss:0.1482 | AUROC:0.7618\n",
      "\n",
      "Epoch: [119 | 1000] LR: 0.197793\n",
      "Train | 16/16 | Loss:0.4370 | MainLoss:0.2039 | Alpha:0.4336 | SPLoss:2.1693 | CLSLoss:0.1615 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2819 | MainLoss:0.2819 | SPLoss:1.7805 | CLSLoss:0.1515 | AUROC:0.9853\n",
      "Test | 128/16 | Loss:0.7436 | MainLoss:0.7436 | SPLoss:1.7805 | CLSLoss:0.1515 | AUROC:0.8160\n",
      "\n",
      "Epoch: [120 | 1000] LR: 0.197727\n",
      "Train | 16/16 | Loss:0.4016 | MainLoss:0.2245 | Alpha:0.4339 | SPLoss:1.6205 | CLSLoss:0.1498 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1721 | MainLoss:0.1721 | SPLoss:1.4000 | CLSLoss:0.1513 | AUROC:0.9829\n",
      "Test | 128/16 | Loss:1.1293 | MainLoss:1.1293 | SPLoss:1.4000 | CLSLoss:0.1513 | AUROC:0.7415\n",
      "\n",
      "Epoch: [121 | 1000] LR: 0.197660\n",
      "Train | 16/16 | Loss:0.6160 | MainLoss:0.2235 | Alpha:0.4347 | SPLoss:3.7737 | CLSLoss:0.1514 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1896 | MainLoss:0.1896 | SPLoss:3.5734 | CLSLoss:0.1402 | AUROC:0.9824\n",
      "Test | 128/16 | Loss:1.0660 | MainLoss:1.0660 | SPLoss:3.5734 | CLSLoss:0.1402 | AUROC:0.7372\n",
      "\n",
      "Epoch: [122 | 1000] LR: 0.197592\n",
      "Train | 16/16 | Loss:0.5148 | MainLoss:0.2118 | Alpha:0.4343 | SPLoss:2.8708 | CLSLoss:0.1592 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1911 | MainLoss:0.1911 | SPLoss:2.2879 | CLSLoss:0.1394 | AUROC:0.9830\n",
      "Test | 128/16 | Loss:0.9021 | MainLoss:0.9021 | SPLoss:2.2879 | CLSLoss:0.1394 | AUROC:0.8080\n",
      "\n",
      "Epoch: [123 | 1000] LR: 0.197523\n",
      "Train | 16/16 | Loss:0.4177 | MainLoss:0.2077 | Alpha:0.4358 | SPLoss:1.9468 | CLSLoss:0.1529 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1799 | MainLoss:0.1799 | SPLoss:1.6347 | CLSLoss:0.1526 | AUROC:0.9824\n",
      "Test | 128/16 | Loss:1.1040 | MainLoss:1.1040 | SPLoss:1.6347 | CLSLoss:0.1526 | AUROC:0.7377\n",
      "\n",
      "Epoch: [124 | 1000] LR: 0.197453\n",
      "Train | 16/16 | Loss:0.3623 | MainLoss:0.1972 | Alpha:0.4358 | SPLoss:1.4931 | CLSLoss:0.1581 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2148 | MainLoss:0.2148 | SPLoss:1.3739 | CLSLoss:0.1652 | AUROC:0.9838\n",
      "Test | 128/16 | Loss:1.0147 | MainLoss:1.0147 | SPLoss:1.3739 | CLSLoss:0.1652 | AUROC:0.7570\n",
      "\n",
      "Epoch: [125 | 1000] LR: 0.197382\n",
      "Train | 16/16 | Loss:1.1575 | MainLoss:0.1987 | Alpha:0.4356 | SPLoss:9.4280 | CLSLoss:0.1600 | AUROC:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 32/16 | Loss:0.1750 | MainLoss:0.1750 | SPLoss:17.2132 | CLSLoss:0.1553 | AUROC:0.9845\n",
      "Test | 128/16 | Loss:1.0047 | MainLoss:1.0047 | SPLoss:17.2132 | CLSLoss:0.1553 | AUROC:0.8074\n",
      "\n",
      "Epoch: [126 | 1000] LR: 0.197310\n",
      "Train | 16/16 | Loss:1.5326 | MainLoss:0.2245 | Alpha:0.4356 | SPLoss:12.9256 | CLSLoss:0.1549 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1748 | MainLoss:0.1748 | SPLoss:8.9885 | CLSLoss:0.1614 | AUROC:0.9830\n",
      "Test | 128/16 | Loss:1.2167 | MainLoss:1.2167 | SPLoss:8.9885 | CLSLoss:0.1614 | AUROC:0.7294\n",
      "\n",
      "Epoch: [127 | 1000] LR: 0.197237\n",
      "Train | 16/16 | Loss:0.9463 | MainLoss:0.2060 | Alpha:0.4351 | SPLoss:7.2388 | CLSLoss:0.1637 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1722 | MainLoss:0.1722 | SPLoss:5.4600 | CLSLoss:0.1532 | AUROC:0.9834\n",
      "Test | 128/16 | Loss:1.1229 | MainLoss:1.1229 | SPLoss:5.4600 | CLSLoss:0.1532 | AUROC:0.7061\n",
      "\n",
      "Epoch: [128 | 1000] LR: 0.197163\n",
      "Train | 16/16 | Loss:0.6340 | MainLoss:0.1912 | Alpha:0.4363 | SPLoss:4.2669 | CLSLoss:0.1611 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1639 | MainLoss:0.1639 | SPLoss:3.1822 | CLSLoss:0.1607 | AUROC:0.9840\n",
      "Test | 128/16 | Loss:1.1758 | MainLoss:1.1758 | SPLoss:3.1822 | CLSLoss:0.1607 | AUROC:0.7684\n",
      "\n",
      "Epoch: [129 | 1000] LR: 0.197088\n",
      "Train | 16/16 | Loss:0.4818 | MainLoss:0.2043 | Alpha:0.4354 | SPLoss:2.6186 | CLSLoss:0.1561 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1786 | MainLoss:0.1786 | SPLoss:2.1209 | CLSLoss:0.1576 | AUROC:0.9836\n",
      "Test | 128/16 | Loss:0.9993 | MainLoss:0.9993 | SPLoss:2.1209 | CLSLoss:0.1576 | AUROC:0.7532\n",
      "\n",
      "Epoch: [130 | 1000] LR: 0.197013\n",
      "Train | 16/16 | Loss:0.3946 | MainLoss:0.1903 | Alpha:0.4369 | SPLoss:1.8785 | CLSLoss:0.1649 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1952 | MainLoss:0.1952 | SPLoss:2.0254 | CLSLoss:0.1548 | AUROC:0.9850\n",
      "Test | 128/16 | Loss:0.9115 | MainLoss:0.9115 | SPLoss:2.0254 | CLSLoss:0.1548 | AUROC:0.7813\n",
      "\n",
      "Epoch: [131 | 1000] LR: 0.196936\n",
      "Train | 16/16 | Loss:0.4057 | MainLoss:0.2115 | Alpha:0.4342 | SPLoss:1.7847 | CLSLoss:0.1581 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2044 | MainLoss:0.2044 | SPLoss:1.5979 | CLSLoss:0.1537 | AUROC:0.9829\n",
      "Test | 128/16 | Loss:1.0141 | MainLoss:1.0141 | SPLoss:1.5979 | CLSLoss:0.1537 | AUROC:0.7468\n",
      "\n",
      "Epoch: [132 | 1000] LR: 0.196858\n",
      "Train | 16/16 | Loss:0.3530 | MainLoss:0.1966 | Alpha:0.4354 | SPLoss:1.4065 | CLSLoss:0.1583 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1817 | MainLoss:0.1817 | SPLoss:1.2313 | CLSLoss:0.1595 | AUROC:0.9831\n",
      "Test | 128/16 | Loss:1.1692 | MainLoss:1.1692 | SPLoss:1.2313 | CLSLoss:0.1595 | AUROC:0.7035\n",
      "\n",
      "Epoch: [133 | 1000] LR: 0.196780\n",
      "Train | 16/16 | Loss:0.4777 | MainLoss:0.1940 | Alpha:0.4352 | SPLoss:2.6796 | CLSLoss:0.1578 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1793 | MainLoss:0.1793 | SPLoss:3.4898 | CLSLoss:0.1406 | AUROC:0.9831\n",
      "Test | 128/16 | Loss:1.0172 | MainLoss:1.0172 | SPLoss:3.4898 | CLSLoss:0.1406 | AUROC:0.7758\n",
      "\n",
      "Epoch: [134 | 1000] LR: 0.196700\n",
      "Train | 16/16 | Loss:0.5003 | MainLoss:0.2041 | Alpha:0.4351 | SPLoss:2.8083 | CLSLoss:0.1535 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3154 | MainLoss:0.3154 | SPLoss:2.2188 | CLSLoss:0.1442 | AUROC:0.9866\n",
      "Test | 128/16 | Loss:0.6373 | MainLoss:0.6373 | SPLoss:2.2188 | CLSLoss:0.1442 | AUROC:0.7979\n",
      "\n",
      "Epoch: [135 | 1000] LR: 0.196620\n",
      "Train | 16/16 | Loss:0.4897 | MainLoss:0.1911 | Alpha:0.4335 | SPLoss:2.8287 | CLSLoss:0.1575 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1997 | MainLoss:0.1997 | SPLoss:4.1823 | CLSLoss:0.1728 | AUROC:0.9829\n",
      "Test | 128/16 | Loss:1.1594 | MainLoss:1.1594 | SPLoss:4.1823 | CLSLoss:0.1728 | AUROC:0.7386\n",
      "\n",
      "Epoch: [136 | 1000] LR: 0.196538\n",
      "Train | 16/16 | Loss:0.5423 | MainLoss:0.1923 | Alpha:0.4368 | SPLoss:3.3363 | CLSLoss:0.1628 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1828 | MainLoss:0.1828 | SPLoss:2.5817 | CLSLoss:0.1566 | AUROC:0.9847\n",
      "Test | 128/16 | Loss:0.9380 | MainLoss:0.9380 | SPLoss:2.5817 | CLSLoss:0.1566 | AUROC:0.7928\n",
      "\n",
      "Epoch: [137 | 1000] LR: 0.196456\n",
      "Train | 16/16 | Loss:0.4560 | MainLoss:0.2252 | Alpha:0.4325 | SPLoss:2.1524 | CLSLoss:0.1553 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1856 | MainLoss:0.1856 | SPLoss:1.7376 | CLSLoss:0.1591 | AUROC:0.9851\n",
      "Test | 128/16 | Loss:0.9967 | MainLoss:0.9967 | SPLoss:1.7376 | CLSLoss:0.1591 | AUROC:0.7425\n",
      "\n",
      "Epoch: [138 | 1000] LR: 0.196372\n",
      "Train | 16/16 | Loss:0.3885 | MainLoss:0.1859 | Alpha:0.4365 | SPLoss:1.8645 | CLSLoss:0.1617 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2296 | MainLoss:0.2296 | SPLoss:6.9236 | CLSLoss:0.1675 | AUROC:0.9803\n",
      "Test | 128/16 | Loss:0.9858 | MainLoss:0.9858 | SPLoss:6.9236 | CLSLoss:0.1675 | AUROC:0.7628\n",
      "\n",
      "Epoch: [139 | 1000] LR: 0.196288\n",
      "Train | 16/16 | Loss:0.7605 | MainLoss:0.2003 | Alpha:0.4367 | SPLoss:5.4417 | CLSLoss:0.1605 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1971 | MainLoss:0.1971 | SPLoss:3.9623 | CLSLoss:0.1706 | AUROC:0.9814\n",
      "Test | 128/16 | Loss:1.1236 | MainLoss:1.1236 | SPLoss:3.9623 | CLSLoss:0.1706 | AUROC:0.7527\n",
      "\n",
      "Epoch: [140 | 1000] LR: 0.196203\n",
      "Train | 16/16 | Loss:0.5408 | MainLoss:0.2055 | Alpha:0.4324 | SPLoss:3.1923 | CLSLoss:0.1601 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2265 | MainLoss:0.2265 | SPLoss:2.5070 | CLSLoss:0.1364 | AUROC:0.9811\n",
      "Test | 128/16 | Loss:1.2485 | MainLoss:1.2485 | SPLoss:2.5070 | CLSLoss:0.1364 | AUROC:0.7646\n",
      "\n",
      "Epoch: [141 | 1000] LR: 0.196117\n",
      "Train | 16/16 | Loss:0.4228 | MainLoss:0.2010 | Alpha:0.4354 | SPLoss:2.0622 | CLSLoss:0.1555 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1918 | MainLoss:0.1918 | SPLoss:1.6896 | CLSLoss:0.1624 | AUROC:0.9848\n",
      "Test | 128/16 | Loss:0.9352 | MainLoss:0.9352 | SPLoss:1.6896 | CLSLoss:0.1624 | AUROC:0.8123\n",
      "\n",
      "Epoch: [142 | 1000] LR: 0.196029\n",
      "Train | 16/16 | Loss:0.3510 | MainLoss:0.1836 | Alpha:0.4341 | SPLoss:1.5105 | CLSLoss:0.1633 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1734 | MainLoss:0.1734 | SPLoss:1.3672 | CLSLoss:0.1473 | AUROC:0.9830\n",
      "Test | 128/16 | Loss:1.0141 | MainLoss:1.0141 | SPLoss:1.3672 | CLSLoss:0.1473 | AUROC:0.8006\n",
      "\n",
      "Epoch: [143 | 1000] LR: 0.195941\n",
      "Train | 16/16 | Loss:0.3708 | MainLoss:0.2080 | Alpha:0.4361 | SPLoss:1.4753 | CLSLoss:0.1534 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1656 | MainLoss:0.1656 | SPLoss:2.3737 | CLSLoss:0.1660 | AUROC:0.9847\n",
      "Test | 128/16 | Loss:1.1771 | MainLoss:1.1771 | SPLoss:2.3737 | CLSLoss:0.1660 | AUROC:0.7590\n",
      "\n",
      "Epoch: [144 | 1000] LR: 0.195852\n",
      "Train | 16/16 | Loss:0.5638 | MainLoss:0.1905 | Alpha:0.4339 | SPLoss:3.5658 | CLSLoss:0.1675 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1940 | MainLoss:0.1940 | SPLoss:4.2427 | CLSLoss:0.1630 | AUROC:0.9827\n",
      "Test | 128/16 | Loss:1.0072 | MainLoss:1.0072 | SPLoss:4.2427 | CLSLoss:0.1630 | AUROC:0.7742\n",
      "\n",
      "Epoch: [145 | 1000] LR: 0.195762\n",
      "Train | 16/16 | Loss:0.5509 | MainLoss:0.1914 | Alpha:0.4352 | SPLoss:3.4276 | CLSLoss:0.1673 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1603 | MainLoss:0.1603 | SPLoss:2.7577 | CLSLoss:0.1582 | AUROC:0.9851\n",
      "Test | 128/16 | Loss:1.1366 | MainLoss:1.1366 | SPLoss:2.7577 | CLSLoss:0.1582 | AUROC:0.8058\n",
      "\n",
      "Epoch: [146 | 1000] LR: 0.195671\n",
      "Train | 16/16 | Loss:0.4402 | MainLoss:0.1965 | Alpha:0.4366 | SPLoss:2.2746 | CLSLoss:0.1622 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1708 | MainLoss:0.1708 | SPLoss:1.8684 | CLSLoss:0.1525 | AUROC:0.9842\n",
      "Test | 128/16 | Loss:1.0374 | MainLoss:1.0374 | SPLoss:1.8684 | CLSLoss:0.1525 | AUROC:0.8122\n",
      "\n",
      "Epoch: [147 | 1000] LR: 0.195579\n",
      "Train | 16/16 | Loss:0.3547 | MainLoss:0.1794 | Alpha:0.4365 | SPLoss:1.5866 | CLSLoss:0.1664 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1987 | MainLoss:0.1987 | SPLoss:1.3449 | CLSLoss:0.1580 | AUROC:0.9858\n",
      "Test | 128/16 | Loss:0.9805 | MainLoss:0.9805 | SPLoss:1.3449 | CLSLoss:0.1580 | AUROC:0.7642\n",
      "\n",
      "Epoch: [148 | 1000] LR: 0.195486\n",
      "Train | 16/16 | Loss:0.3426 | MainLoss:0.2004 | Alpha:0.4358 | SPLoss:1.2637 | CLSLoss:0.1583 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1930 | MainLoss:0.1930 | SPLoss:1.2512 | CLSLoss:0.1265 | AUROC:0.9807\n",
      "Test | 128/16 | Loss:1.0474 | MainLoss:1.0474 | SPLoss:1.2512 | CLSLoss:0.1265 | AUROC:0.7428\n",
      "\n",
      "Epoch: [149 | 1000] LR: 0.195393\n",
      "Train | 16/16 | Loss:0.3190 | MainLoss:0.1825 | Alpha:0.4352 | SPLoss:1.2107 | CLSLoss:0.1545 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1762 | MainLoss:0.1762 | SPLoss:1.0417 | CLSLoss:0.1683 | AUROC:0.9828\n",
      "Test | 128/16 | Loss:1.2191 | MainLoss:1.2191 | SPLoss:1.0417 | CLSLoss:0.1683 | AUROC:0.7818\n",
      "\n",
      "Epoch: [150 | 1000] LR: 0.195298\n",
      "Train | 16/16 | Loss:0.3234 | MainLoss:0.2047 | Alpha:0.4336 | SPLoss:1.0290 | CLSLoss:0.1583 | AUROC:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 32/16 | Loss:0.1720 | MainLoss:0.1720 | SPLoss:1.0052 | CLSLoss:0.1589 | AUROC:0.9844\n",
      "Test | 128/16 | Loss:1.0897 | MainLoss:1.0897 | SPLoss:1.0052 | CLSLoss:0.1589 | AUROC:0.7757\n",
      "\n",
      "Epoch: [151 | 1000] LR: 0.195202\n",
      "Train | 16/16 | Loss:0.3999 | MainLoss:0.1902 | Alpha:0.4354 | SPLoss:1.9360 | CLSLoss:0.1603 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1612 | MainLoss:0.1612 | SPLoss:1.9498 | CLSLoss:0.1635 | AUROC:0.9858\n",
      "Test | 128/16 | Loss:1.1945 | MainLoss:1.1945 | SPLoss:1.9498 | CLSLoss:0.1635 | AUROC:0.7944\n",
      "\n",
      "Epoch: [152 | 1000] LR: 0.195106\n",
      "Train | 16/16 | Loss:0.4337 | MainLoss:0.2169 | Alpha:0.4317 | SPLoss:2.0152 | CLSLoss:0.1520 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1824 | MainLoss:0.1824 | SPLoss:2.6170 | CLSLoss:0.1607 | AUROC:0.9857\n",
      "Test | 128/16 | Loss:1.0244 | MainLoss:1.0244 | SPLoss:2.6170 | CLSLoss:0.1607 | AUROC:0.7862\n",
      "\n",
      "Epoch: [153 | 1000] LR: 0.195008\n",
      "Train | 16/16 | Loss:0.4158 | MainLoss:0.1837 | Alpha:0.4355 | SPLoss:2.1606 | CLSLoss:0.1611 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2094 | MainLoss:0.2094 | SPLoss:1.7265 | CLSLoss:0.1606 | AUROC:0.9822\n",
      "Test | 128/16 | Loss:0.9520 | MainLoss:0.9520 | SPLoss:1.7265 | CLSLoss:0.1606 | AUROC:0.8267\n",
      "\n",
      "Epoch: [154 | 1000] LR: 0.194910\n",
      "Train | 16/16 | Loss:0.3718 | MainLoss:0.2006 | Alpha:0.4340 | SPLoss:1.5535 | CLSLoss:0.1582 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1815 | MainLoss:0.1815 | SPLoss:1.4745 | CLSLoss:0.1555 | AUROC:0.9813\n",
      "Test | 128/16 | Loss:0.9616 | MainLoss:0.9616 | SPLoss:1.4745 | CLSLoss:0.1555 | AUROC:0.8472\n",
      "\n",
      "Epoch: [155 | 1000] LR: 0.194810\n",
      "Train | 16/16 | Loss:0.4254 | MainLoss:0.2026 | Alpha:0.4359 | SPLoss:2.0678 | CLSLoss:0.1604 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1661 | MainLoss:0.1661 | SPLoss:2.0114 | CLSLoss:0.1605 | AUROC:0.9841\n",
      "Test | 128/16 | Loss:1.1061 | MainLoss:1.1061 | SPLoss:2.0114 | CLSLoss:0.1605 | AUROC:0.7826\n",
      "\n",
      "Epoch: [156 | 1000] LR: 0.194710\n",
      "Train | 16/16 | Loss:0.3782 | MainLoss:0.1882 | Alpha:0.4349 | SPLoss:1.7348 | CLSLoss:0.1650 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2956 | MainLoss:0.2956 | SPLoss:1.4879 | CLSLoss:0.1688 | AUROC:0.9827\n",
      "Test | 128/16 | Loss:0.7408 | MainLoss:0.7408 | SPLoss:1.4879 | CLSLoss:0.1688 | AUROC:0.8414\n",
      "\n",
      "Epoch: [157 | 1000] LR: 0.194609\n",
      "Train | 16/16 | Loss:0.3513 | MainLoss:0.1956 | Alpha:0.4340 | SPLoss:1.3918 | CLSLoss:0.1646 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1758 | MainLoss:0.1758 | SPLoss:1.3775 | CLSLoss:0.1543 | AUROC:0.9852\n",
      "Test | 128/16 | Loss:0.9148 | MainLoss:0.9148 | SPLoss:1.3775 | CLSLoss:0.1543 | AUROC:0.8376\n",
      "\n",
      "Epoch: [158 | 1000] LR: 0.194506\n",
      "Train | 16/16 | Loss:0.3590 | MainLoss:0.1868 | Alpha:0.4352 | SPLoss:1.5618 | CLSLoss:0.1609 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1738 | MainLoss:0.1738 | SPLoss:1.5703 | CLSLoss:0.1560 | AUROC:0.9844\n",
      "Test | 128/16 | Loss:1.0166 | MainLoss:1.0166 | SPLoss:1.5703 | CLSLoss:0.1560 | AUROC:0.8081\n",
      "\n",
      "Epoch: [159 | 1000] LR: 0.194403\n",
      "Train | 16/16 | Loss:0.3764 | MainLoss:0.1941 | Alpha:0.4350 | SPLoss:1.6658 | CLSLoss:0.1571 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1631 | MainLoss:0.1631 | SPLoss:1.5843 | CLSLoss:0.1611 | AUROC:0.9848\n",
      "Test | 128/16 | Loss:1.2177 | MainLoss:1.2177 | SPLoss:1.5843 | CLSLoss:0.1611 | AUROC:0.7694\n",
      "\n",
      "Epoch: [160 | 1000] LR: 0.194299\n",
      "Train | 16/16 | Loss:0.6495 | MainLoss:0.2022 | Alpha:0.4352 | SPLoss:4.3188 | CLSLoss:0.1541 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2031 | MainLoss:0.2031 | SPLoss:4.6250 | CLSLoss:0.1632 | AUROC:0.9858\n",
      "Test | 128/16 | Loss:0.9489 | MainLoss:0.9489 | SPLoss:4.6250 | CLSLoss:0.1632 | AUROC:0.7719\n",
      "\n",
      "Epoch: [161 | 1000] LR: 0.194194\n",
      "Train | 16/16 | Loss:0.7479 | MainLoss:0.2264 | Alpha:0.4336 | SPLoss:5.0636 | CLSLoss:0.1518 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2183 | MainLoss:0.2183 | SPLoss:5.5216 | CLSLoss:0.1443 | AUROC:0.9847\n",
      "Test | 128/16 | Loss:0.8739 | MainLoss:0.8739 | SPLoss:5.5216 | CLSLoss:0.1443 | AUROC:0.7464\n",
      "\n",
      "Epoch: [162 | 1000] LR: 0.194088\n",
      "Train | 16/16 | Loss:0.6229 | MainLoss:0.1758 | Alpha:0.4370 | SPLoss:4.3080 | CLSLoss:0.1634 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2145 | MainLoss:0.2145 | SPLoss:3.4595 | CLSLoss:0.1652 | AUROC:0.9845\n",
      "Test | 128/16 | Loss:1.0348 | MainLoss:1.0348 | SPLoss:3.4595 | CLSLoss:0.1652 | AUROC:0.7672\n",
      "\n",
      "Epoch: [163 | 1000] LR: 0.193981\n",
      "Train | 16/16 | Loss:0.4928 | MainLoss:0.1984 | Alpha:0.4372 | SPLoss:2.7890 | CLSLoss:0.1552 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1780 | MainLoss:0.1780 | SPLoss:2.1626 | CLSLoss:0.1658 | AUROC:0.9821\n",
      "Test | 128/16 | Loss:1.2217 | MainLoss:1.2217 | SPLoss:2.1626 | CLSLoss:0.1658 | AUROC:0.7704\n",
      "\n",
      "Epoch: [164 | 1000] LR: 0.193873\n",
      "Train | 16/16 | Loss:0.3864 | MainLoss:0.1811 | Alpha:0.4361 | SPLoss:1.8901 | CLSLoss:0.1632 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1745 | MainLoss:0.1745 | SPLoss:1.6527 | CLSLoss:0.1652 | AUROC:0.9835\n",
      "Test | 128/16 | Loss:1.1010 | MainLoss:1.1010 | SPLoss:1.6527 | CLSLoss:0.1652 | AUROC:0.7555\n",
      "\n",
      "Epoch: [165 | 1000] LR: 0.193765\n",
      "Train | 16/16 | Loss:0.3694 | MainLoss:0.2065 | Alpha:0.4334 | SPLoss:1.4734 | CLSLoss:0.1556 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2562 | MainLoss:0.2562 | SPLoss:1.3042 | CLSLoss:0.1488 | AUROC:0.9853\n",
      "Test | 128/16 | Loss:0.8463 | MainLoss:0.8463 | SPLoss:1.3042 | CLSLoss:0.1488 | AUROC:0.7479\n",
      "\n",
      "Epoch: [166 | 1000] LR: 0.193655\n",
      "Train | 16/16 | Loss:0.3321 | MainLoss:0.1949 | Alpha:0.4329 | SPLoss:1.2142 | CLSLoss:0.1577 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1974 | MainLoss:0.1974 | SPLoss:8.0480 | CLSLoss:0.1702 | AUROC:0.9834\n",
      "Test | 128/16 | Loss:1.0096 | MainLoss:1.0096 | SPLoss:8.0480 | CLSLoss:0.1702 | AUROC:0.7871\n",
      "\n",
      "Epoch: [167 | 1000] LR: 0.193544\n",
      "Train | 16/16 | Loss:0.9441 | MainLoss:0.1953 | Alpha:0.4359 | SPLoss:7.3276 | CLSLoss:0.1604 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2131 | MainLoss:0.2131 | SPLoss:5.3136 | CLSLoss:0.1692 | AUROC:0.9845\n",
      "Test | 128/16 | Loss:0.9799 | MainLoss:0.9799 | SPLoss:5.3136 | CLSLoss:0.1692 | AUROC:0.7411\n",
      "\n",
      "Epoch: [168 | 1000] LR: 0.193433\n",
      "Train | 16/16 | Loss:0.6269 | MainLoss:0.1950 | Alpha:0.4364 | SPLoss:4.1555 | CLSLoss:0.1635 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1661 | MainLoss:0.1661 | SPLoss:3.0918 | CLSLoss:0.1437 | AUROC:0.9851\n",
      "Test | 128/16 | Loss:1.1319 | MainLoss:1.1319 | SPLoss:3.0918 | CLSLoss:0.1437 | AUROC:0.7312\n",
      "\n",
      "Epoch: [169 | 1000] LR: 0.193320\n",
      "Train | 16/16 | Loss:0.4774 | MainLoss:0.1991 | Alpha:0.4340 | SPLoss:2.6261 | CLSLoss:0.1563 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3201 | MainLoss:0.3201 | SPLoss:2.8456 | CLSLoss:0.1575 | AUROC:0.9848\n",
      "Test | 128/16 | Loss:0.7422 | MainLoss:0.7422 | SPLoss:2.8456 | CLSLoss:0.1575 | AUROC:0.7756\n",
      "\n",
      "Epoch: [170 | 1000] LR: 0.193207\n",
      "Train | 16/16 | Loss:0.5797 | MainLoss:0.1993 | Alpha:0.4353 | SPLoss:3.6412 | CLSLoss:0.1621 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1757 | MainLoss:0.1757 | SPLoss:3.3454 | CLSLoss:0.1635 | AUROC:0.9849\n",
      "Test | 128/16 | Loss:1.0469 | MainLoss:1.0469 | SPLoss:3.3454 | CLSLoss:0.1635 | AUROC:0.7900\n",
      "\n",
      "Epoch: [171 | 1000] LR: 0.193093\n",
      "Train | 16/16 | Loss:0.4882 | MainLoss:0.1937 | Alpha:0.4355 | SPLoss:2.7850 | CLSLoss:0.1607 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1686 | MainLoss:0.1686 | SPLoss:2.4237 | CLSLoss:0.1619 | AUROC:0.9838\n",
      "Test | 128/16 | Loss:1.1286 | MainLoss:1.1286 | SPLoss:2.4237 | CLSLoss:0.1619 | AUROC:0.7686\n",
      "\n",
      "Epoch: [172 | 1000] LR: 0.192978\n",
      "Train | 16/16 | Loss:0.4203 | MainLoss:0.1988 | Alpha:0.4369 | SPLoss:2.0540 | CLSLoss:0.1608 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1634 | MainLoss:0.1634 | SPLoss:1.7459 | CLSLoss:0.1601 | AUROC:0.9863\n",
      "Test | 128/16 | Loss:1.0726 | MainLoss:1.0726 | SPLoss:1.7459 | CLSLoss:0.1601 | AUROC:0.8237\n",
      "\n",
      "Epoch: [173 | 1000] LR: 0.192862\n",
      "Train | 16/16 | Loss:0.3826 | MainLoss:0.1996 | Alpha:0.4352 | SPLoss:1.6709 | CLSLoss:0.1593 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1801 | MainLoss:0.1801 | SPLoss:1.9530 | CLSLoss:0.1676 | AUROC:0.9816\n",
      "Test | 128/16 | Loss:1.2026 | MainLoss:1.2026 | SPLoss:1.9530 | CLSLoss:0.1676 | AUROC:0.7801\n",
      "\n",
      "Epoch: [174 | 1000] LR: 0.192745\n",
      "Train | 16/16 | Loss:0.3887 | MainLoss:0.1876 | Alpha:0.4348 | SPLoss:1.8462 | CLSLoss:0.1651 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1948 | MainLoss:0.1948 | SPLoss:1.6248 | CLSLoss:0.1511 | AUROC:0.9831\n",
      "Test | 128/16 | Loss:0.9240 | MainLoss:0.9240 | SPLoss:1.6248 | CLSLoss:0.1511 | AUROC:0.7967\n",
      "\n",
      "Epoch: [175 | 1000] LR: 0.192627\n",
      "Train | 16/16 | Loss:2.4365 | MainLoss:0.1937 | Alpha:0.4392 | SPLoss:22.2686 | CLSLoss:0.1600 | AUROC:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 32/16 | Loss:0.2280 | MainLoss:0.2280 | SPLoss:50.7514 | CLSLoss:0.1560 | AUROC:0.9821\n",
      "Test | 128/16 | Loss:0.8283 | MainLoss:0.8283 | SPLoss:50.7515 | CLSLoss:0.1560 | AUROC:0.8697\n",
      "\n",
      "Epoch: [176 | 1000] LR: 0.192508\n",
      "Train | 16/16 | Loss:4.0760 | MainLoss:0.1883 | Alpha:0.4341 | SPLoss:38.7141 | CLSLoss:0.1624 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2215 | MainLoss:0.2215 | SPLoss:29.7621 | CLSLoss:0.1526 | AUROC:0.9825\n",
      "Test | 128/16 | Loss:0.8431 | MainLoss:0.8431 | SPLoss:29.7622 | CLSLoss:0.1526 | AUROC:0.8116\n",
      "\n",
      "Epoch: [177 | 1000] LR: 0.192388\n",
      "Train | 16/16 | Loss:2.4287 | MainLoss:0.1877 | Alpha:0.4338 | SPLoss:22.2512 | CLSLoss:0.1591 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2041 | MainLoss:0.2041 | SPLoss:16.1236 | CLSLoss:0.1512 | AUROC:0.9816\n",
      "Test | 128/16 | Loss:0.9633 | MainLoss:0.9633 | SPLoss:16.1236 | CLSLoss:0.1512 | AUROC:0.7938\n",
      "\n",
      "Epoch: [178 | 1000] LR: 0.192267\n",
      "Train | 16/16 | Loss:1.4472 | MainLoss:0.1934 | Alpha:0.4352 | SPLoss:12.3814 | CLSLoss:0.1570 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2346 | MainLoss:0.2346 | SPLoss:10.6983 | CLSLoss:0.1469 | AUROC:0.9828\n",
      "Test | 128/16 | Loss:0.7926 | MainLoss:0.7926 | SPLoss:10.6983 | CLSLoss:0.1469 | AUROC:0.8065\n",
      "\n",
      "Epoch: [179 | 1000] LR: 0.192146\n",
      "Train | 16/16 | Loss:1.0285 | MainLoss:0.1963 | Alpha:0.4324 | SPLoss:8.1672 | CLSLoss:0.1551 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1634 | MainLoss:0.1634 | SPLoss:5.8427 | CLSLoss:0.1508 | AUROC:0.9851\n",
      "Test | 128/16 | Loss:1.0400 | MainLoss:1.0400 | SPLoss:5.8427 | CLSLoss:0.1508 | AUROC:0.7690\n",
      "\n",
      "Epoch: [180 | 1000] LR: 0.192023\n",
      "Train | 16/16 | Loss:0.6727 | MainLoss:0.2025 | Alpha:0.4334 | SPLoss:4.5441 | CLSLoss:0.1578 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1885 | MainLoss:0.1885 | SPLoss:3.3620 | CLSLoss:0.1645 | AUROC:0.9840\n",
      "Test | 128/16 | Loss:0.9450 | MainLoss:0.9450 | SPLoss:3.3620 | CLSLoss:0.1645 | AUROC:0.8245\n",
      "\n",
      "Epoch: [181 | 1000] LR: 0.191900\n",
      "Train | 16/16 | Loss:2.3275 | MainLoss:0.1994 | Alpha:0.4350 | SPLoss:21.1199 | CLSLoss:0.1612 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1802 | MainLoss:0.1802 | SPLoss:67.9698 | CLSLoss:0.1515 | AUROC:0.9837\n",
      "Test | 128/16 | Loss:1.0194 | MainLoss:1.0194 | SPLoss:67.9699 | CLSLoss:0.1515 | AUROC:0.7907\n",
      "\n",
      "Epoch: [182 | 1000] LR: 0.191775\n",
      "Train | 16/16 | Loss:5.2332 | MainLoss:0.1787 | Alpha:0.4350 | SPLoss:50.3853 | CLSLoss:0.1603 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1772 | MainLoss:0.1772 | SPLoss:34.5316 | CLSLoss:0.1657 | AUROC:0.9828\n",
      "Test | 128/16 | Loss:1.0611 | MainLoss:1.0611 | SPLoss:34.5316 | CLSLoss:0.1657 | AUROC:0.7816\n",
      "\n",
      "Epoch: [183 | 1000] LR: 0.191650\n",
      "Train | 16/16 | Loss:2.7813 | MainLoss:0.1895 | Alpha:0.4336 | SPLoss:25.7523 | CLSLoss:0.1654 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2051 | MainLoss:0.2051 | SPLoss:17.7966 | CLSLoss:0.1532 | AUROC:0.9799\n",
      "Test | 128/16 | Loss:0.9999 | MainLoss:0.9999 | SPLoss:17.7966 | CLSLoss:0.1532 | AUROC:0.7832\n",
      "\n",
      "Epoch: [184 | 1000] LR: 0.191524\n",
      "Train | 16/16 | Loss:1.5707 | MainLoss:0.2144 | Alpha:0.4328 | SPLoss:13.4102 | CLSLoss:0.1527 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1823 | MainLoss:0.1823 | SPLoss:9.5046 | CLSLoss:0.1539 | AUROC:0.9823\n",
      "Test | 128/16 | Loss:1.0850 | MainLoss:1.0850 | SPLoss:9.5046 | CLSLoss:0.1539 | AUROC:0.7528\n",
      "\n",
      "Epoch: [185 | 1000] LR: 0.191397\n",
      "Train | 16/16 | Loss:0.9328 | MainLoss:0.1927 | Alpha:0.4339 | SPLoss:7.2408 | CLSLoss:0.1602 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1912 | MainLoss:0.1912 | SPLoss:5.2679 | CLSLoss:0.1563 | AUROC:0.9829\n",
      "Test | 128/16 | Loss:1.4268 | MainLoss:1.4268 | SPLoss:5.2679 | CLSLoss:0.1563 | AUROC:0.7454\n",
      "\n",
      "Epoch: [186 | 1000] LR: 0.191269\n",
      "Train | 16/16 | Loss:0.6369 | MainLoss:0.2090 | Alpha:0.4330 | SPLoss:4.1237 | CLSLoss:0.1561 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1922 | MainLoss:0.1922 | SPLoss:3.4662 | CLSLoss:0.1585 | AUROC:0.9829\n",
      "Test | 128/16 | Loss:1.0482 | MainLoss:1.0482 | SPLoss:3.4662 | CLSLoss:0.1585 | AUROC:0.7774\n",
      "\n",
      "Epoch: [187 | 1000] LR: 0.191140\n",
      "Train | 16/16 | Loss:0.4867 | MainLoss:0.1911 | Alpha:0.4356 | SPLoss:2.7957 | CLSLoss:0.1606 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1760 | MainLoss:0.1760 | SPLoss:2.1869 | CLSLoss:0.1560 | AUROC:0.9836\n",
      "Test | 128/16 | Loss:1.0125 | MainLoss:1.0125 | SPLoss:2.1869 | CLSLoss:0.1560 | AUROC:0.7720\n",
      "\n",
      "Epoch: [188 | 1000] LR: 0.191011\n",
      "Train | 16/16 | Loss:0.3771 | MainLoss:0.1778 | Alpha:0.4353 | SPLoss:1.8265 | CLSLoss:0.1666 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1661 | MainLoss:0.1661 | SPLoss:1.4894 | CLSLoss:0.1679 | AUROC:0.9851\n",
      "Test | 128/16 | Loss:1.0683 | MainLoss:1.0683 | SPLoss:1.4894 | CLSLoss:0.1679 | AUROC:0.8222\n",
      "\n",
      "Epoch: [189 | 1000] LR: 0.190880\n",
      "Train | 16/16 | Loss:1.1216 | MainLoss:0.2744 | Alpha:0.4356 | SPLoss:8.3300 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1753 | MainLoss:0.1753 | SPLoss:10.2081 | CLSLoss:0.1686 | AUROC:0.9830\n",
      "Test | 128/16 | Loss:1.2475 | MainLoss:1.2475 | SPLoss:10.2080 | CLSLoss:0.1686 | AUROC:0.7056\n",
      "\n",
      "Epoch: [190 | 1000] LR: 0.190748\n",
      "Train | 16/16 | Loss:1.6766 | MainLoss:0.1925 | Alpha:0.4372 | SPLoss:14.6698 | CLSLoss:0.1706 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1836 | MainLoss:0.1836 | SPLoss:15.6488 | CLSLoss:0.1736 | AUROC:0.9821\n",
      "Test | 128/16 | Loss:1.3792 | MainLoss:1.3792 | SPLoss:15.6489 | CLSLoss:0.1736 | AUROC:0.7343\n",
      "\n",
      "Epoch: [191 | 1000] LR: 0.190616\n",
      "Train | 16/16 | Loss:1.3823 | MainLoss:0.1855 | Alpha:0.4391 | SPLoss:11.7955 | CLSLoss:0.1718 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1613 | MainLoss:0.1613 | SPLoss:8.3077 | CLSLoss:0.1758 | AUROC:0.9853\n",
      "Test | 128/16 | Loss:1.3018 | MainLoss:1.3018 | SPLoss:8.3077 | CLSLoss:0.1758 | AUROC:0.7468\n",
      "\n",
      "Epoch: [192 | 1000] LR: 0.190483\n",
      "Train | 16/16 | Loss:0.8435 | MainLoss:0.1789 | Alpha:0.4353 | SPLoss:6.4745 | CLSLoss:0.1716 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1719 | MainLoss:0.1719 | SPLoss:4.8125 | CLSLoss:0.1764 | AUROC:0.9828\n",
      "Test | 128/16 | Loss:1.3068 | MainLoss:1.3068 | SPLoss:4.8125 | CLSLoss:0.1764 | AUROC:0.7545\n",
      "\n",
      "Epoch: [193 | 1000] LR: 0.190348\n",
      "Train | 16/16 | Loss:0.5848 | MainLoss:0.1890 | Alpha:0.4358 | SPLoss:3.7960 | CLSLoss:0.1615 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1684 | MainLoss:0.1684 | SPLoss:2.8766 | CLSLoss:0.1572 | AUROC:0.9835\n",
      "Test | 128/16 | Loss:1.0810 | MainLoss:1.0810 | SPLoss:2.8766 | CLSLoss:0.1572 | AUROC:0.8323\n",
      "\n",
      "Epoch: [194 | 1000] LR: 0.190213\n",
      "Train | 16/16 | Loss:0.6206 | MainLoss:0.2116 | Alpha:0.4375 | SPLoss:3.9337 | CLSLoss:0.1562 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2098 | MainLoss:0.2098 | SPLoss:28.6491 | CLSLoss:0.1345 | AUROC:0.9769\n",
      "Test | 128/16 | Loss:0.9733 | MainLoss:0.9733 | SPLoss:28.6491 | CLSLoss:0.1345 | AUROC:0.7295\n",
      "\n",
      "Epoch: [195 | 1000] LR: 0.190077\n",
      "Train | 16/16 | Loss:2.7103 | MainLoss:0.2207 | Alpha:0.4361 | SPLoss:24.7469 | CLSLoss:0.1488 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1771 | MainLoss:0.1771 | SPLoss:20.7482 | CLSLoss:0.1596 | AUROC:0.9848\n",
      "Test | 128/16 | Loss:1.0505 | MainLoss:1.0505 | SPLoss:20.7482 | CLSLoss:0.1596 | AUROC:0.7675\n",
      "\n",
      "Epoch: [196 | 1000] LR: 0.189941\n",
      "Train | 16/16 | Loss:1.7717 | MainLoss:0.1948 | Alpha:0.4359 | SPLoss:15.6071 | CLSLoss:0.1615 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1599 | MainLoss:0.1599 | SPLoss:10.9220 | CLSLoss:0.1699 | AUROC:0.9862\n",
      "Test | 128/16 | Loss:1.0976 | MainLoss:1.0976 | SPLoss:10.9220 | CLSLoss:0.1699 | AUROC:0.7944\n",
      "\n",
      "Epoch: [197 | 1000] LR: 0.189803\n",
      "Train | 16/16 | Loss:1.0654 | MainLoss:0.2057 | Alpha:0.4363 | SPLoss:8.4342 | CLSLoss:0.1624 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3247 | MainLoss:0.3247 | SPLoss:6.2695 | CLSLoss:0.1466 | AUROC:0.9827\n",
      "Test | 128/16 | Loss:0.6638 | MainLoss:0.6638 | SPLoss:6.2695 | CLSLoss:0.1466 | AUROC:0.8139\n",
      "\n",
      "Epoch: [198 | 1000] LR: 0.189664\n",
      "Train | 16/16 | Loss:0.7218 | MainLoss:0.2086 | Alpha:0.4340 | SPLoss:4.9741 | CLSLoss:0.1580 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2093 | MainLoss:0.2093 | SPLoss:3.7538 | CLSLoss:0.1593 | AUROC:0.9838\n",
      "Test | 128/16 | Loss:0.8414 | MainLoss:0.8414 | SPLoss:3.7538 | CLSLoss:0.1593 | AUROC:0.8195\n",
      "\n",
      "Epoch: [199 | 1000] LR: 0.189525\n",
      "Train | 16/16 | Loss:0.6309 | MainLoss:0.2016 | Alpha:0.4350 | SPLoss:4.1313 | CLSLoss:0.1615 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1722 | MainLoss:0.1722 | SPLoss:3.2003 | CLSLoss:0.1632 | AUROC:0.9831\n",
      "Test | 128/16 | Loss:1.0282 | MainLoss:1.0282 | SPLoss:3.2003 | CLSLoss:0.1632 | AUROC:0.7749\n",
      "\n",
      "Epoch: [200 | 1000] LR: 0.189384\n",
      "Train | 16/16 | Loss:0.4751 | MainLoss:0.1975 | Alpha:0.4337 | SPLoss:2.6147 | CLSLoss:0.1613 | AUROC:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 32/16 | Loss:0.2002 | MainLoss:0.2002 | SPLoss:2.1561 | CLSLoss:0.1521 | AUROC:0.9794\n",
      "Test | 128/16 | Loss:1.1299 | MainLoss:1.1299 | SPLoss:2.1561 | CLSLoss:0.1521 | AUROC:0.7626\n",
      "\n",
      "Epoch: [201 | 1000] LR: 0.018924\n",
      "Train | 16/16 | Loss:0.1959 | MainLoss:0.1797 | Alpha:0.4472 | SPLoss:0.0045 | CLSLoss:0.1574 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1807 | MainLoss:0.1807 | SPLoss:0.0096 | CLSLoss:0.1629 | AUROC:0.9836\n",
      "Test | 128/16 | Loss:1.0446 | MainLoss:1.0446 | SPLoss:0.0096 | CLSLoss:0.1629 | AUROC:0.7755\n",
      "\n",
      "Epoch: [202 | 1000] LR: 0.018910\n",
      "Train | 16/16 | Loss:0.1735 | MainLoss:0.1555 | Alpha:0.4471 | SPLoss:0.0139 | CLSLoss:0.1665 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1720 | MainLoss:0.1720 | SPLoss:0.0184 | CLSLoss:0.1702 | AUROC:0.9850\n",
      "Test | 128/16 | Loss:1.1263 | MainLoss:1.1263 | SPLoss:0.0184 | CLSLoss:0.1702 | AUROC:0.7731\n",
      "\n",
      "Epoch: [203 | 1000] LR: 0.018896\n",
      "Train | 16/16 | Loss:0.1711 | MainLoss:0.1517 | Alpha:0.4478 | SPLoss:0.0234 | CLSLoss:0.1703 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1658 | MainLoss:0.1658 | SPLoss:0.0270 | CLSLoss:0.1708 | AUROC:0.9860\n",
      "Test | 128/16 | Loss:1.1290 | MainLoss:1.1290 | SPLoss:0.0270 | CLSLoss:0.1708 | AUROC:0.7778\n",
      "\n",
      "Epoch: [204 | 1000] LR: 0.018881\n",
      "Train | 16/16 | Loss:0.1653 | MainLoss:0.1448 | Alpha:0.4473 | SPLoss:0.0325 | CLSLoss:0.1724 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1652 | MainLoss:0.1652 | SPLoss:0.0394 | CLSLoss:0.1726 | AUROC:0.9869\n",
      "Test | 128/16 | Loss:1.1209 | MainLoss:1.1209 | SPLoss:0.0394 | CLSLoss:0.1726 | AUROC:0.7847\n",
      "\n",
      "Epoch: [205 | 1000] LR: 0.018867\n",
      "Train | 16/16 | Loss:0.1626 | MainLoss:0.1407 | Alpha:0.4463 | SPLoss:0.0450 | CLSLoss:0.1738 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1591 | MainLoss:0.1591 | SPLoss:0.0486 | CLSLoss:0.1722 | AUROC:0.9868\n",
      "Test | 128/16 | Loss:1.1489 | MainLoss:1.1489 | SPLoss:0.0486 | CLSLoss:0.1722 | AUROC:0.7865\n",
      "\n",
      "Epoch: [206 | 1000] LR: 0.018852\n",
      "Train | 16/16 | Loss:0.1695 | MainLoss:0.1471 | Alpha:0.4452 | SPLoss:0.0531 | CLSLoss:0.1711 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1605 | MainLoss:0.1605 | SPLoss:0.0592 | CLSLoss:0.1724 | AUROC:0.9877\n",
      "Test | 128/16 | Loss:1.1022 | MainLoss:1.1022 | SPLoss:0.0592 | CLSLoss:0.1724 | AUROC:0.7952\n",
      "\n",
      "Epoch: [207 | 1000] LR: 0.018838\n",
      "Train | 16/16 | Loss:0.1546 | MainLoss:0.1309 | Alpha:0.4489 | SPLoss:0.0629 | CLSLoss:0.1737 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1546 | MainLoss:0.1546 | SPLoss:0.0676 | CLSLoss:0.1743 | AUROC:0.9878\n",
      "Test | 128/16 | Loss:1.1464 | MainLoss:1.1464 | SPLoss:0.0676 | CLSLoss:0.1743 | AUROC:0.7968\n",
      "\n",
      "Epoch: [208 | 1000] LR: 0.018823\n",
      "Train | 16/16 | Loss:0.1543 | MainLoss:0.1296 | Alpha:0.4470 | SPLoss:0.0724 | CLSLoss:0.1743 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1572 | MainLoss:0.1572 | SPLoss:0.0766 | CLSLoss:0.1752 | AUROC:0.9879\n",
      "Test | 128/16 | Loss:1.1501 | MainLoss:1.1501 | SPLoss:0.0766 | CLSLoss:0.1752 | AUROC:0.8017\n",
      "\n",
      "Epoch: [209 | 1000] LR: 0.018808\n",
      "Train | 16/16 | Loss:0.1581 | MainLoss:0.1325 | Alpha:0.4455 | SPLoss:0.0809 | CLSLoss:0.1751 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1643 | MainLoss:0.1643 | SPLoss:0.0868 | CLSLoss:0.1731 | AUROC:0.9880\n",
      "Test | 128/16 | Loss:1.0869 | MainLoss:1.0869 | SPLoss:0.0868 | CLSLoss:0.1731 | AUROC:0.8089\n",
      "\n",
      "Epoch: [210 | 1000] LR: 0.018793\n",
      "Train | 16/16 | Loss:0.1671 | MainLoss:0.1408 | Alpha:0.4438 | SPLoss:0.0905 | CLSLoss:0.1720 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1532 | MainLoss:0.1532 | SPLoss:0.0943 | CLSLoss:0.1696 | AUROC:0.9881\n",
      "Test | 128/16 | Loss:1.1027 | MainLoss:1.1027 | SPLoss:0.0943 | CLSLoss:0.1696 | AUROC:0.8079\n",
      "\n",
      "Epoch: [211 | 1000] LR: 0.018778\n",
      "Train | 16/16 | Loss:0.1522 | MainLoss:0.1253 | Alpha:0.4473 | SPLoss:0.0988 | CLSLoss:0.1705 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1519 | MainLoss:0.1519 | SPLoss:0.1025 | CLSLoss:0.1718 | AUROC:0.9883\n",
      "Test | 128/16 | Loss:1.1440 | MainLoss:1.1440 | SPLoss:0.1025 | CLSLoss:0.1718 | AUROC:0.8106\n",
      "\n",
      "Epoch: [212 | 1000] LR: 0.018763\n",
      "Train | 16/16 | Loss:0.1563 | MainLoss:0.1284 | Alpha:0.4438 | SPLoss:0.1073 | CLSLoss:0.1717 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1551 | MainLoss:0.1551 | SPLoss:0.1121 | CLSLoss:0.1714 | AUROC:0.9886\n",
      "Test | 128/16 | Loss:1.1277 | MainLoss:1.1277 | SPLoss:0.1121 | CLSLoss:0.1714 | AUROC:0.8105\n",
      "\n",
      "Epoch: [213 | 1000] LR: 0.018748\n",
      "Train | 16/16 | Loss:0.1568 | MainLoss:0.1281 | Alpha:0.4458 | SPLoss:0.1157 | CLSLoss:0.1710 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1586 | MainLoss:0.1586 | SPLoss:0.1202 | CLSLoss:0.1700 | AUROC:0.9883\n",
      "Test | 128/16 | Loss:1.0989 | MainLoss:1.0989 | SPLoss:0.1202 | CLSLoss:0.1700 | AUROC:0.8095\n",
      "\n",
      "Epoch: [214 | 1000] LR: 0.018733\n",
      "Train | 16/16 | Loss:0.1452 | MainLoss:0.1156 | Alpha:0.4486 | SPLoss:0.1239 | CLSLoss:0.1715 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1480 | MainLoss:0.1480 | SPLoss:0.1281 | CLSLoss:0.1726 | AUROC:0.9888\n",
      "Test | 128/16 | Loss:1.1680 | MainLoss:1.1680 | SPLoss:0.1281 | CLSLoss:0.1726 | AUROC:0.8057\n",
      "\n",
      "Epoch: [215 | 1000] LR: 0.018717\n",
      "Train | 16/16 | Loss:0.1316 | MainLoss:0.1010 | Alpha:0.4496 | SPLoss:0.1324 | CLSLoss:0.1737 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1623 | MainLoss:0.1623 | SPLoss:0.1358 | CLSLoss:0.1752 | AUROC:0.9883\n",
      "Test | 128/16 | Loss:1.1254 | MainLoss:1.1254 | SPLoss:0.1358 | CLSLoss:0.1752 | AUROC:0.8136\n",
      "\n",
      "Epoch: [216 | 1000] LR: 0.018702\n",
      "Train | 16/16 | Loss:0.1511 | MainLoss:0.1198 | Alpha:0.4466 | SPLoss:0.1385 | CLSLoss:0.1747 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1531 | MainLoss:0.1531 | SPLoss:0.1425 | CLSLoss:0.1727 | AUROC:0.9886\n",
      "Test | 128/16 | Loss:1.1388 | MainLoss:1.1388 | SPLoss:0.1425 | CLSLoss:0.1727 | AUROC:0.8117\n",
      "\n",
      "Epoch: [217 | 1000] LR: 0.018686\n",
      "Train | 16/16 | Loss:0.1510 | MainLoss:0.1193 | Alpha:0.4457 | SPLoss:0.1441 | CLSLoss:0.1728 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1512 | MainLoss:0.1512 | SPLoss:0.1467 | CLSLoss:0.1724 | AUROC:0.9887\n",
      "Test | 128/16 | Loss:1.1428 | MainLoss:1.1428 | SPLoss:0.1467 | CLSLoss:0.1724 | AUROC:0.8130\n",
      "\n",
      "Epoch: [218 | 1000] LR: 0.018671\n",
      "Train | 16/16 | Loss:0.1442 | MainLoss:0.1120 | Alpha:0.4477 | SPLoss:0.1494 | CLSLoss:0.1728 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1564 | MainLoss:0.1564 | SPLoss:0.1531 | CLSLoss:0.1729 | AUROC:0.9885\n",
      "Test | 128/16 | Loss:1.1163 | MainLoss:1.1163 | SPLoss:0.1531 | CLSLoss:0.1729 | AUROC:0.8174\n",
      "\n",
      "Epoch: [219 | 1000] LR: 0.018655\n",
      "Train | 16/16 | Loss:0.1437 | MainLoss:0.1107 | Alpha:0.4455 | SPLoss:0.1566 | CLSLoss:0.1730 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1545 | MainLoss:0.1545 | SPLoss:0.1587 | CLSLoss:0.1723 | AUROC:0.9886\n",
      "Test | 128/16 | Loss:1.1543 | MainLoss:1.1543 | SPLoss:0.1587 | CLSLoss:0.1723 | AUROC:0.8151\n",
      "\n",
      "Epoch: [220 | 1000] LR: 0.018639\n",
      "Train | 16/16 | Loss:0.1505 | MainLoss:0.1171 | Alpha:0.4432 | SPLoss:0.1633 | CLSLoss:0.1713 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1573 | MainLoss:0.1573 | SPLoss:0.1661 | CLSLoss:0.1717 | AUROC:0.9885\n",
      "Test | 128/16 | Loss:1.1118 | MainLoss:1.1118 | SPLoss:0.1661 | CLSLoss:0.1717 | AUROC:0.8241\n",
      "\n",
      "Epoch: [221 | 1000] LR: 0.018623\n",
      "Train | 16/16 | Loss:0.1435 | MainLoss:0.1094 | Alpha:0.4461 | SPLoss:0.1685 | CLSLoss:0.1720 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1590 | MainLoss:0.1590 | SPLoss:0.1726 | CLSLoss:0.1733 | AUROC:0.9881\n",
      "Test | 128/16 | Loss:1.1414 | MainLoss:1.1414 | SPLoss:0.1726 | CLSLoss:0.1733 | AUROC:0.8193\n",
      "\n",
      "Epoch: [222 | 1000] LR: 0.018607\n",
      "Train | 16/16 | Loss:0.1478 | MainLoss:0.1129 | Alpha:0.4440 | SPLoss:0.1766 | CLSLoss:0.1722 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1571 | MainLoss:0.1571 | SPLoss:0.1804 | CLSLoss:0.1736 | AUROC:0.9884\n",
      "Test | 128/16 | Loss:1.1369 | MainLoss:1.1369 | SPLoss:0.1804 | CLSLoss:0.1736 | AUROC:0.8251\n",
      "\n",
      "Epoch: [223 | 1000] LR: 0.018591\n",
      "Train | 16/16 | Loss:0.1367 | MainLoss:0.1011 | Alpha:0.4474 | SPLoss:0.1816 | CLSLoss:0.1738 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1655 | MainLoss:0.1655 | SPLoss:0.1836 | CLSLoss:0.1736 | AUROC:0.9882\n",
      "Test | 128/16 | Loss:1.1113 | MainLoss:1.1113 | SPLoss:0.1836 | CLSLoss:0.1736 | AUROC:0.8265\n",
      "\n",
      "Epoch: [224 | 1000] LR: 0.018575\n",
      "Train | 16/16 | Loss:0.1337 | MainLoss:0.0976 | Alpha:0.4445 | SPLoss:0.1865 | CLSLoss:0.1748 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1559 | MainLoss:0.1559 | SPLoss:0.1905 | CLSLoss:0.1750 | AUROC:0.9883\n",
      "Test | 128/16 | Loss:1.1750 | MainLoss:1.1750 | SPLoss:0.1905 | CLSLoss:0.1750 | AUROC:0.8255\n",
      "\n",
      "Epoch: [225 | 1000] LR: 0.018559\n",
      "Train | 16/16 | Loss:0.1506 | MainLoss:0.1140 | Alpha:0.4456 | SPLoss:0.1928 | CLSLoss:0.1730 | AUROC:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 32/16 | Loss:0.1636 | MainLoss:0.1636 | SPLoss:0.1960 | CLSLoss:0.1723 | AUROC:0.9880\n",
      "Test | 128/16 | Loss:1.1232 | MainLoss:1.1232 | SPLoss:0.1960 | CLSLoss:0.1723 | AUROC:0.8301\n",
      "\n",
      "Epoch: [226 | 1000] LR: 0.018543\n",
      "Train | 16/16 | Loss:0.1436 | MainLoss:0.1067 | Alpha:0.4476 | SPLoss:0.1977 | CLSLoss:0.1716 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1540 | MainLoss:0.1540 | SPLoss:0.1999 | CLSLoss:0.1718 | AUROC:0.9884\n",
      "Test | 128/16 | Loss:1.1244 | MainLoss:1.1244 | SPLoss:0.1999 | CLSLoss:0.1718 | AUROC:0.8314\n",
      "\n",
      "Epoch: [227 | 1000] LR: 0.018526\n",
      "Train | 16/16 | Loss:0.1387 | MainLoss:0.1013 | Alpha:0.4466 | SPLoss:0.2023 | CLSLoss:0.1723 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1627 | MainLoss:0.1627 | SPLoss:0.2057 | CLSLoss:0.1727 | AUROC:0.9888\n",
      "Test | 128/16 | Loss:1.0865 | MainLoss:1.0865 | SPLoss:0.2057 | CLSLoss:0.1727 | AUROC:0.8365\n",
      "\n",
      "Epoch: [228 | 1000] LR: 0.018510\n",
      "Train | 16/16 | Loss:0.1379 | MainLoss:0.0999 | Alpha:0.4480 | SPLoss:0.2070 | CLSLoss:0.1734 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1592 | MainLoss:0.1592 | SPLoss:0.2105 | CLSLoss:0.1720 | AUROC:0.9889\n",
      "Test | 128/16 | Loss:1.0989 | MainLoss:1.0989 | SPLoss:0.2105 | CLSLoss:0.1720 | AUROC:0.8353\n",
      "\n",
      "Epoch: [229 | 1000] LR: 0.018493\n",
      "Train | 16/16 | Loss:0.1343 | MainLoss:0.0957 | Alpha:0.4471 | SPLoss:0.2133 | CLSLoss:0.1728 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1618 | MainLoss:0.1618 | SPLoss:0.2143 | CLSLoss:0.1738 | AUROC:0.9885\n",
      "Test | 128/16 | Loss:1.1319 | MainLoss:1.1319 | SPLoss:0.2143 | CLSLoss:0.1738 | AUROC:0.8333\n",
      "\n",
      "Epoch: [230 | 1000] LR: 0.018477\n",
      "Train | 16/16 | Loss:0.1331 | MainLoss:0.0941 | Alpha:0.4472 | SPLoss:0.2162 | CLSLoss:0.1737 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1677 | MainLoss:0.1677 | SPLoss:0.2184 | CLSLoss:0.1744 | AUROC:0.9888\n",
      "Test | 128/16 | Loss:1.1272 | MainLoss:1.1272 | SPLoss:0.2184 | CLSLoss:0.1744 | AUROC:0.8315\n",
      "\n",
      "Epoch: [231 | 1000] LR: 0.018460\n",
      "Train | 16/16 | Loss:0.1412 | MainLoss:0.1018 | Alpha:0.4451 | SPLoss:0.2210 | CLSLoss:0.1735 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1691 | MainLoss:0.1691 | SPLoss:0.2245 | CLSLoss:0.1722 | AUROC:0.9888\n",
      "Test | 128/16 | Loss:1.1037 | MainLoss:1.1037 | SPLoss:0.2245 | CLSLoss:0.1722 | AUROC:0.8356\n",
      "\n",
      "Epoch: [232 | 1000] LR: 0.018443\n",
      "Train | 16/16 | Loss:0.1323 | MainLoss:0.0928 | Alpha:0.4485 | SPLoss:0.2233 | CLSLoss:0.1719 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1690 | MainLoss:0.1690 | SPLoss:0.2262 | CLSLoss:0.1720 | AUROC:0.9886\n",
      "Test | 128/16 | Loss:1.1143 | MainLoss:1.1143 | SPLoss:0.2262 | CLSLoss:0.1720 | AUROC:0.8348\n",
      "\n",
      "Epoch: [233 | 1000] LR: 0.018426\n",
      "Train | 16/16 | Loss:0.1315 | MainLoss:0.0916 | Alpha:0.4489 | SPLoss:0.2267 | CLSLoss:0.1716 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1560 | MainLoss:0.1560 | SPLoss:0.2289 | CLSLoss:0.1731 | AUROC:0.9884\n",
      "Test | 128/16 | Loss:1.1877 | MainLoss:1.1877 | SPLoss:0.2289 | CLSLoss:0.1731 | AUROC:0.8354\n",
      "\n",
      "Epoch: [234 | 1000] LR: 0.018409\n",
      "Train | 16/16 | Loss:0.1445 | MainLoss:0.1041 | Alpha:0.4438 | SPLoss:0.2324 | CLSLoss:0.1719 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1636 | MainLoss:0.1636 | SPLoss:0.2359 | CLSLoss:0.1709 | AUROC:0.9890\n",
      "Test | 128/16 | Loss:1.1308 | MainLoss:1.1308 | SPLoss:0.2359 | CLSLoss:0.1709 | AUROC:0.8339\n",
      "\n",
      "Epoch: [235 | 1000] LR: 0.018392\n",
      "Train | 16/16 | Loss:0.1344 | MainLoss:0.0939 | Alpha:0.4494 | SPLoss:0.2342 | CLSLoss:0.1709 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1673 | MainLoss:0.1673 | SPLoss:0.2344 | CLSLoss:0.1699 | AUROC:0.9887\n",
      "Test | 128/16 | Loss:1.0996 | MainLoss:1.0996 | SPLoss:0.2344 | CLSLoss:0.1699 | AUROC:0.8383\n",
      "\n",
      "Epoch: [236 | 1000] LR: 0.018375\n",
      "Train | 16/16 | Loss:0.1402 | MainLoss:0.0996 | Alpha:0.4456 | SPLoss:0.2363 | CLSLoss:0.1702 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1615 | MainLoss:0.1615 | SPLoss:0.2385 | CLSLoss:0.1699 | AUROC:0.9885\n",
      "Test | 128/16 | Loss:1.1199 | MainLoss:1.1199 | SPLoss:0.2385 | CLSLoss:0.1699 | AUROC:0.8417\n",
      "\n",
      "Epoch: [237 | 1000] LR: 0.018358\n",
      "Train | 16/16 | Loss:0.1307 | MainLoss:0.0896 | Alpha:0.4488 | SPLoss:0.2405 | CLSLoss:0.1706 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1614 | MainLoss:0.1614 | SPLoss:0.2411 | CLSLoss:0.1716 | AUROC:0.9887\n",
      "Test | 128/16 | Loss:1.1556 | MainLoss:1.1556 | SPLoss:0.2411 | CLSLoss:0.1716 | AUROC:0.8389\n",
      "\n",
      "Epoch: [238 | 1000] LR: 0.018341\n",
      "Train | 16/16 | Loss:0.1406 | MainLoss:0.0992 | Alpha:0.4468 | SPLoss:0.2427 | CLSLoss:0.1709 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1593 | MainLoss:0.1593 | SPLoss:0.2446 | CLSLoss:0.1703 | AUROC:0.9887\n",
      "Test | 128/16 | Loss:1.1645 | MainLoss:1.1645 | SPLoss:0.2446 | CLSLoss:0.1703 | AUROC:0.8392\n",
      "\n",
      "Epoch: [239 | 1000] LR: 0.018323\n",
      "Train | 16/16 | Loss:0.1556 | MainLoss:0.1142 | Alpha:0.4458 | SPLoss:0.2455 | CLSLoss:0.1686 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1588 | MainLoss:0.1588 | SPLoss:0.2471 | CLSLoss:0.1654 | AUROC:0.9887\n",
      "Test | 128/16 | Loss:1.0741 | MainLoss:1.0741 | SPLoss:0.2471 | CLSLoss:0.1654 | AUROC:0.8441\n",
      "\n",
      "Epoch: [240 | 1000] LR: 0.018306\n",
      "Train | 16/16 | Loss:0.1391 | MainLoss:0.0977 | Alpha:0.4461 | SPLoss:0.2474 | CLSLoss:0.1661 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1583 | MainLoss:0.1583 | SPLoss:0.2483 | CLSLoss:0.1667 | AUROC:0.9888\n",
      "Test | 128/16 | Loss:1.1277 | MainLoss:1.1277 | SPLoss:0.2483 | CLSLoss:0.1667 | AUROC:0.8369\n",
      "\n",
      "Epoch: [241 | 1000] LR: 0.018288\n",
      "Train | 16/16 | Loss:0.1377 | MainLoss:0.0961 | Alpha:0.4467 | SPLoss:0.2495 | CLSLoss:0.1672 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1603 | MainLoss:0.1603 | SPLoss:0.2527 | CLSLoss:0.1665 | AUROC:0.9893\n",
      "Test | 128/16 | Loss:1.0743 | MainLoss:1.0743 | SPLoss:0.2527 | CLSLoss:0.1665 | AUROC:0.8464\n",
      "\n",
      "Epoch: [242 | 1000] LR: 0.018271\n",
      "Train | 16/16 | Loss:0.1357 | MainLoss:0.0936 | Alpha:0.4476 | SPLoss:0.2528 | CLSLoss:0.1677 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1589 | MainLoss:0.1589 | SPLoss:0.2555 | CLSLoss:0.1677 | AUROC:0.9896\n",
      "Test | 128/16 | Loss:1.1133 | MainLoss:1.1133 | SPLoss:0.2555 | CLSLoss:0.1677 | AUROC:0.8375\n",
      "\n",
      "Epoch: [243 | 1000] LR: 0.018253\n",
      "Train | 16/16 | Loss:0.1405 | MainLoss:0.0981 | Alpha:0.4468 | SPLoss:0.2562 | CLSLoss:0.1676 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1497 | MainLoss:0.1497 | SPLoss:0.2574 | CLSLoss:0.1678 | AUROC:0.9894\n",
      "Test | 128/16 | Loss:1.1740 | MainLoss:1.1740 | SPLoss:0.2574 | CLSLoss:0.1678 | AUROC:0.8356\n",
      "\n",
      "Epoch: [244 | 1000] LR: 0.018235\n",
      "Train | 16/16 | Loss:0.1413 | MainLoss:0.0988 | Alpha:0.4459 | SPLoss:0.2580 | CLSLoss:0.1676 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1546 | MainLoss:0.1546 | SPLoss:0.2584 | CLSLoss:0.1668 | AUROC:0.9898\n",
      "Test | 128/16 | Loss:1.1408 | MainLoss:1.1408 | SPLoss:0.2584 | CLSLoss:0.1668 | AUROC:0.8366\n",
      "\n",
      "Epoch: [245 | 1000] LR: 0.018217\n",
      "Train | 16/16 | Loss:0.1446 | MainLoss:0.1020 | Alpha:0.4470 | SPLoss:0.2604 | CLSLoss:0.1663 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1461 | MainLoss:0.1461 | SPLoss:0.2595 | CLSLoss:0.1645 | AUROC:0.9897\n",
      "Test | 128/16 | Loss:1.1638 | MainLoss:1.1638 | SPLoss:0.2595 | CLSLoss:0.1645 | AUROC:0.8356\n",
      "\n",
      "Epoch: [246 | 1000] LR: 0.018200\n",
      "Train | 16/16 | Loss:0.1336 | MainLoss:0.0907 | Alpha:0.4472 | SPLoss:0.2628 | CLSLoss:0.1659 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1504 | MainLoss:0.1504 | SPLoss:0.2626 | CLSLoss:0.1669 | AUROC:0.9892\n",
      "Test | 128/16 | Loss:1.1901 | MainLoss:1.1901 | SPLoss:0.2626 | CLSLoss:0.1669 | AUROC:0.8309\n",
      "\n",
      "Epoch: [247 | 1000] LR: 0.018181\n",
      "Train | 16/16 | Loss:0.1447 | MainLoss:0.1019 | Alpha:0.4466 | SPLoss:0.2625 | CLSLoss:0.1658 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1636 | MainLoss:0.1636 | SPLoss:0.2627 | CLSLoss:0.1654 | AUROC:0.9893\n",
      "Test | 128/16 | Loss:1.0994 | MainLoss:1.0994 | SPLoss:0.2627 | CLSLoss:0.1654 | AUROC:0.8348\n",
      "\n",
      "Epoch: [248 | 1000] LR: 0.018163\n",
      "Train | 16/16 | Loss:0.1351 | MainLoss:0.0921 | Alpha:0.4498 | SPLoss:0.2635 | CLSLoss:0.1659 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1515 | MainLoss:0.1515 | SPLoss:0.2626 | CLSLoss:0.1659 | AUROC:0.9893\n",
      "Test | 128/16 | Loss:1.1625 | MainLoss:1.1625 | SPLoss:0.2626 | CLSLoss:0.1659 | AUROC:0.8393\n",
      "\n",
      "Epoch: [249 | 1000] LR: 0.018145\n",
      "Train | 16/16 | Loss:0.1346 | MainLoss:0.0915 | Alpha:0.4480 | SPLoss:0.2644 | CLSLoss:0.1661 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1574 | MainLoss:0.1574 | SPLoss:0.2645 | CLSLoss:0.1672 | AUROC:0.9890\n",
      "Test | 128/16 | Loss:1.1441 | MainLoss:1.1441 | SPLoss:0.2645 | CLSLoss:0.1672 | AUROC:0.8438\n",
      "\n",
      "Epoch: [250 | 1000] LR: 0.018127\n",
      "Train | 16/16 | Loss:0.1391 | MainLoss:0.0957 | Alpha:0.4465 | SPLoss:0.2668 | CLSLoss:0.1669 | AUROC:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 32/16 | Loss:0.1588 | MainLoss:0.1588 | SPLoss:0.2692 | CLSLoss:0.1665 | AUROC:0.9888\n",
      "Test | 128/16 | Loss:1.1410 | MainLoss:1.1410 | SPLoss:0.2692 | CLSLoss:0.1665 | AUROC:0.8421\n",
      "\n",
      "Epoch: [251 | 1000] LR: 0.018109\n",
      "Train | 16/16 | Loss:0.1333 | MainLoss:0.0895 | Alpha:0.4481 | SPLoss:0.2712 | CLSLoss:0.1672 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:0.2731 | CLSLoss:0.1672 | AUROC:0.9887\n",
      "Test | 128/16 | Loss:1.1168 | MainLoss:1.1168 | SPLoss:0.2731 | CLSLoss:0.1672 | AUROC:0.8475\n",
      "\n",
      "Epoch: [252 | 1000] LR: 0.018090\n",
      "Train | 16/16 | Loss:0.1448 | MainLoss:0.1009 | Alpha:0.4456 | SPLoss:0.2731 | CLSLoss:0.1666 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1543 | MainLoss:0.1543 | SPLoss:0.2723 | CLSLoss:0.1665 | AUROC:0.9892\n",
      "Test | 128/16 | Loss:1.1338 | MainLoss:1.1338 | SPLoss:0.2723 | CLSLoss:0.1665 | AUROC:0.8453\n",
      "\n",
      "Epoch: [253 | 1000] LR: 0.018072\n",
      "Train | 16/16 | Loss:0.1429 | MainLoss:0.0988 | Alpha:0.4453 | SPLoss:0.2738 | CLSLoss:0.1669 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1507 | MainLoss:0.1507 | SPLoss:0.2745 | CLSLoss:0.1664 | AUROC:0.9891\n",
      "Test | 128/16 | Loss:1.1738 | MainLoss:1.1738 | SPLoss:0.2745 | CLSLoss:0.1664 | AUROC:0.8372\n",
      "\n",
      "Epoch: [254 | 1000] LR: 0.018053\n",
      "Train | 16/16 | Loss:0.1249 | MainLoss:0.0805 | Alpha:0.4482 | SPLoss:0.2754 | CLSLoss:0.1684 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1630 | MainLoss:0.1630 | SPLoss:0.2756 | CLSLoss:0.1700 | AUROC:0.9890\n",
      "Test | 128/16 | Loss:1.1503 | MainLoss:1.1503 | SPLoss:0.2756 | CLSLoss:0.1700 | AUROC:0.8417\n",
      "\n",
      "Epoch: [255 | 1000] LR: 0.018034\n",
      "Train | 16/16 | Loss:0.1317 | MainLoss:0.0870 | Alpha:0.4471 | SPLoss:0.2762 | CLSLoss:0.1701 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1717 | MainLoss:0.1717 | SPLoss:0.2767 | CLSLoss:0.1701 | AUROC:0.9883\n",
      "Test | 128/16 | Loss:1.1168 | MainLoss:1.1168 | SPLoss:0.2767 | CLSLoss:0.1701 | AUROC:0.8470\n",
      "\n",
      "Epoch: [256 | 1000] LR: 0.018016\n",
      "Train | 16/16 | Loss:0.1496 | MainLoss:0.1051 | Alpha:0.4468 | SPLoss:0.2769 | CLSLoss:0.1683 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1580 | MainLoss:0.1580 | SPLoss:0.2760 | CLSLoss:0.1659 | AUROC:0.9883\n",
      "Test | 128/16 | Loss:1.1467 | MainLoss:1.1467 | SPLoss:0.2760 | CLSLoss:0.1659 | AUROC:0.8470\n",
      "\n",
      "Epoch: [257 | 1000] LR: 0.017997\n",
      "Train | 16/16 | Loss:0.1420 | MainLoss:0.0976 | Alpha:0.4459 | SPLoss:0.2782 | CLSLoss:0.1656 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1558 | MainLoss:0.1558 | SPLoss:0.2780 | CLSLoss:0.1649 | AUROC:0.9886\n",
      "Test | 128/16 | Loss:1.1197 | MainLoss:1.1197 | SPLoss:0.2780 | CLSLoss:0.1649 | AUROC:0.8527\n",
      "\n",
      "Epoch: [258 | 1000] LR: 0.017978\n",
      "Train | 16/16 | Loss:0.1366 | MainLoss:0.0922 | Alpha:0.4476 | SPLoss:0.2787 | CLSLoss:0.1653 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1668 | MainLoss:0.1668 | SPLoss:0.2814 | CLSLoss:0.1656 | AUROC:0.9884\n",
      "Test | 128/16 | Loss:1.0829 | MainLoss:1.0829 | SPLoss:0.2814 | CLSLoss:0.1656 | AUROC:0.8505\n",
      "\n",
      "Epoch: [259 | 1000] LR: 0.017959\n",
      "Train | 16/16 | Loss:0.1379 | MainLoss:0.0930 | Alpha:0.4465 | SPLoss:0.2831 | CLSLoss:0.1656 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1560 | MainLoss:0.1560 | SPLoss:0.2845 | CLSLoss:0.1660 | AUROC:0.9888\n",
      "Test | 128/16 | Loss:1.1697 | MainLoss:1.1697 | SPLoss:0.2845 | CLSLoss:0.1660 | AUROC:0.8427\n",
      "\n",
      "Epoch: [260 | 1000] LR: 0.017940\n",
      "Train | 16/16 | Loss:0.1329 | MainLoss:0.0876 | Alpha:0.4472 | SPLoss:0.2860 | CLSLoss:0.1663 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1548 | MainLoss:0.1548 | SPLoss:0.2853 | CLSLoss:0.1662 | AUROC:0.9886\n",
      "Test | 128/16 | Loss:1.1782 | MainLoss:1.1782 | SPLoss:0.2853 | CLSLoss:0.1662 | AUROC:0.8428\n",
      "\n",
      "Epoch: [261 | 1000] LR: 0.017921\n",
      "Train | 16/16 | Loss:0.1309 | MainLoss:0.0856 | Alpha:0.4461 | SPLoss:0.2859 | CLSLoss:0.1667 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1610 | MainLoss:0.1610 | SPLoss:0.2857 | CLSLoss:0.1674 | AUROC:0.9888\n",
      "Test | 128/16 | Loss:1.1720 | MainLoss:1.1720 | SPLoss:0.2857 | CLSLoss:0.1674 | AUROC:0.8434\n",
      "\n",
      "Epoch: [262 | 1000] LR: 0.017902\n",
      "Train | 16/16 | Loss:0.1374 | MainLoss:0.0922 | Alpha:0.4474 | SPLoss:0.2855 | CLSLoss:0.1669 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1607 | MainLoss:0.1607 | SPLoss:0.2863 | CLSLoss:0.1656 | AUROC:0.9883\n",
      "Test | 128/16 | Loss:1.1786 | MainLoss:1.1786 | SPLoss:0.2863 | CLSLoss:0.1656 | AUROC:0.8431\n",
      "\n",
      "Epoch: [263 | 1000] LR: 0.017882\n",
      "Train | 16/16 | Loss:0.1276 | MainLoss:0.0823 | Alpha:0.4488 | SPLoss:0.2866 | CLSLoss:0.1656 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1592 | MainLoss:0.1592 | SPLoss:0.2858 | CLSLoss:0.1661 | AUROC:0.9886\n",
      "Test | 128/16 | Loss:1.1999 | MainLoss:1.1999 | SPLoss:0.2858 | CLSLoss:0.1661 | AUROC:0.8422\n",
      "\n",
      "Epoch: [264 | 1000] LR: 0.017863\n",
      "Train | 16/16 | Loss:0.1339 | MainLoss:0.0885 | Alpha:0.4484 | SPLoss:0.2878 | CLSLoss:0.1665 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1496 | MainLoss:0.1496 | SPLoss:0.2885 | CLSLoss:0.1654 | AUROC:0.9888\n",
      "Test | 128/16 | Loss:1.2515 | MainLoss:1.2515 | SPLoss:0.2885 | CLSLoss:0.1654 | AUROC:0.8378\n",
      "\n",
      "Epoch: [265 | 1000] LR: 0.017843\n",
      "Train | 16/16 | Loss:0.1379 | MainLoss:0.0922 | Alpha:0.4464 | SPLoss:0.2915 | CLSLoss:0.1651 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1597 | MainLoss:0.1597 | SPLoss:0.2918 | CLSLoss:0.1656 | AUROC:0.9887\n",
      "Test | 128/16 | Loss:1.1881 | MainLoss:1.1881 | SPLoss:0.2918 | CLSLoss:0.1656 | AUROC:0.8379\n",
      "\n",
      "Epoch: [266 | 1000] LR: 0.017824\n",
      "Train | 16/16 | Loss:0.1437 | MainLoss:0.0980 | Alpha:0.4465 | SPLoss:0.2920 | CLSLoss:0.1647 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1536 | MainLoss:0.1536 | SPLoss:0.2938 | CLSLoss:0.1636 | AUROC:0.9891\n",
      "Test | 128/16 | Loss:1.1914 | MainLoss:1.1914 | SPLoss:0.2938 | CLSLoss:0.1636 | AUROC:0.8393\n",
      "\n",
      "Epoch: [267 | 1000] LR: 0.017804\n",
      "Train | 16/16 | Loss:0.1486 | MainLoss:0.1031 | Alpha:0.4467 | SPLoss:0.2936 | CLSLoss:0.1618 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1528 | MainLoss:0.1528 | SPLoss:0.2944 | CLSLoss:0.1608 | AUROC:0.9892\n",
      "Test | 128/16 | Loss:1.1433 | MainLoss:1.1433 | SPLoss:0.2944 | CLSLoss:0.1608 | AUROC:0.8443\n",
      "\n",
      "Epoch: [268 | 1000] LR: 0.017785\n",
      "Train | 16/16 | Loss:0.1319 | MainLoss:0.0862 | Alpha:0.4482 | SPLoss:0.2952 | CLSLoss:0.1623 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1612 | MainLoss:0.1612 | SPLoss:0.2949 | CLSLoss:0.1618 | AUROC:0.9887\n",
      "Test | 128/16 | Loss:1.1148 | MainLoss:1.1148 | SPLoss:0.2949 | CLSLoss:0.1618 | AUROC:0.8501\n",
      "\n",
      "Epoch: [269 | 1000] LR: 0.017765\n",
      "Train | 16/16 | Loss:0.1361 | MainLoss:0.0902 | Alpha:0.4473 | SPLoss:0.2966 | CLSLoss:0.1623 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1629 | MainLoss:0.1629 | SPLoss:0.2973 | CLSLoss:0.1619 | AUROC:0.9887\n",
      "Test | 128/16 | Loss:1.1104 | MainLoss:1.1104 | SPLoss:0.2973 | CLSLoss:0.1619 | AUROC:0.8525\n",
      "\n",
      "Epoch: [270 | 1000] LR: 0.017745\n",
      "Train | 16/16 | Loss:0.1381 | MainLoss:0.0921 | Alpha:0.4463 | SPLoss:0.2982 | CLSLoss:0.1621 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1590 | MainLoss:0.1590 | SPLoss:0.2994 | CLSLoss:0.1623 | AUROC:0.9887\n",
      "Test | 128/16 | Loss:1.1173 | MainLoss:1.1173 | SPLoss:0.2994 | CLSLoss:0.1623 | AUROC:0.8568\n",
      "\n",
      "Epoch: [271 | 1000] LR: 0.017725\n",
      "Train | 16/16 | Loss:0.1387 | MainLoss:0.0926 | Alpha:0.4467 | SPLoss:0.2993 | CLSLoss:0.1617 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1575 | MainLoss:0.1575 | SPLoss:0.2993 | CLSLoss:0.1630 | AUROC:0.9886\n",
      "Test | 128/16 | Loss:1.1270 | MainLoss:1.1270 | SPLoss:0.2993 | CLSLoss:0.1630 | AUROC:0.8556\n",
      "\n",
      "Epoch: [272 | 1000] LR: 0.017705\n",
      "Train | 16/16 | Loss:0.1333 | MainLoss:0.0871 | Alpha:0.4483 | SPLoss:0.2988 | CLSLoss:0.1629 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1592 | MainLoss:0.1592 | SPLoss:0.2998 | CLSLoss:0.1645 | AUROC:0.9886\n",
      "Test | 128/16 | Loss:1.1751 | MainLoss:1.1751 | SPLoss:0.2998 | CLSLoss:0.1645 | AUROC:0.8472\n",
      "\n",
      "Epoch: [273 | 1000] LR: 0.017685\n",
      "Train | 16/16 | Loss:0.1315 | MainLoss:0.0848 | Alpha:0.4466 | SPLoss:0.3018 | CLSLoss:0.1656 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1641 | MainLoss:0.1641 | SPLoss:0.3039 | CLSLoss:0.1652 | AUROC:0.9880\n",
      "Test | 128/16 | Loss:1.1131 | MainLoss:1.1131 | SPLoss:0.3039 | CLSLoss:0.1652 | AUROC:0.8592\n",
      "\n",
      "Epoch: [274 | 1000] LR: 0.017665\n",
      "Train | 16/16 | Loss:0.1420 | MainLoss:0.0952 | Alpha:0.4469 | SPLoss:0.3035 | CLSLoss:0.1644 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1630 | MainLoss:0.1630 | SPLoss:0.3034 | CLSLoss:0.1634 | AUROC:0.9885\n",
      "Test | 128/16 | Loss:1.1301 | MainLoss:1.1301 | SPLoss:0.3034 | CLSLoss:0.1634 | AUROC:0.8505\n",
      "\n",
      "Epoch: [275 | 1000] LR: 0.017645\n",
      "Train | 16/16 | Loss:0.1392 | MainLoss:0.0923 | Alpha:0.4436 | SPLoss:0.3048 | CLSLoss:0.1639 | AUROC:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 32/16 | Loss:0.1584 | MainLoss:0.1584 | SPLoss:0.3047 | CLSLoss:0.1630 | AUROC:0.9884\n",
      "Test | 128/16 | Loss:1.1668 | MainLoss:1.1668 | SPLoss:0.3047 | CLSLoss:0.1630 | AUROC:0.8469\n",
      "\n",
      "Epoch: [276 | 1000] LR: 0.017624\n",
      "Train | 16/16 | Loss:0.1359 | MainLoss:0.0890 | Alpha:0.4476 | SPLoss:0.3048 | CLSLoss:0.1636 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1578 | MainLoss:0.1578 | SPLoss:0.3061 | CLSLoss:0.1633 | AUROC:0.9884\n",
      "Test | 128/16 | Loss:1.1770 | MainLoss:1.1770 | SPLoss:0.3061 | CLSLoss:0.1633 | AUROC:0.8395\n",
      "\n",
      "Epoch: [277 | 1000] LR: 0.017604\n",
      "Train | 16/16 | Loss:0.1420 | MainLoss:0.0952 | Alpha:0.4473 | SPLoss:0.3047 | CLSLoss:0.1627 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1612 | MainLoss:0.1612 | SPLoss:0.3032 | CLSLoss:0.1621 | AUROC:0.9886\n",
      "Test | 128/16 | Loss:1.1307 | MainLoss:1.1307 | SPLoss:0.3032 | CLSLoss:0.1621 | AUROC:0.8396\n",
      "\n",
      "Epoch: [278 | 1000] LR: 0.017584\n",
      "Train | 16/16 | Loss:0.1379 | MainLoss:0.0913 | Alpha:0.4464 | SPLoss:0.3043 | CLSLoss:0.1625 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1507 | MainLoss:0.1507 | SPLoss:0.3046 | CLSLoss:0.1628 | AUROC:0.9887\n",
      "Test | 128/16 | Loss:1.1721 | MainLoss:1.1721 | SPLoss:0.3046 | CLSLoss:0.1628 | AUROC:0.8410\n",
      "\n",
      "Epoch: [279 | 1000] LR: 0.017563\n",
      "Train | 16/16 | Loss:0.1330 | MainLoss:0.0860 | Alpha:0.4480 | SPLoss:0.3062 | CLSLoss:0.1636 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1632 | MainLoss:0.1632 | SPLoss:0.3075 | CLSLoss:0.1628 | AUROC:0.9884\n",
      "Test | 128/16 | Loss:1.1105 | MainLoss:1.1105 | SPLoss:0.3075 | CLSLoss:0.1628 | AUROC:0.8472\n",
      "\n",
      "Epoch: [280 | 1000] LR: 0.017543\n",
      "Train | 16/16 | Loss:0.1345 | MainLoss:0.0875 | Alpha:0.4466 | SPLoss:0.3064 | CLSLoss:0.1632 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1650 | MainLoss:0.1650 | SPLoss:0.3063 | CLSLoss:0.1648 | AUROC:0.9886\n",
      "Test | 128/16 | Loss:1.1133 | MainLoss:1.1133 | SPLoss:0.3063 | CLSLoss:0.1648 | AUROC:0.8502\n",
      "\n",
      "Epoch: [281 | 1000] LR: 0.017522\n",
      "Train | 16/16 | Loss:0.1411 | MainLoss:0.0944 | Alpha:0.4489 | SPLoss:0.3037 | CLSLoss:0.1639 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1584 | MainLoss:0.1584 | SPLoss:0.3047 | CLSLoss:0.1631 | AUROC:0.9888\n",
      "Test | 128/16 | Loss:1.1117 | MainLoss:1.1117 | SPLoss:0.3047 | CLSLoss:0.1631 | AUROC:0.8458\n",
      "\n",
      "Epoch: [282 | 1000] LR: 0.017501\n",
      "Train | 16/16 | Loss:0.1442 | MainLoss:0.0973 | Alpha:0.4454 | SPLoss:0.3057 | CLSLoss:0.1632 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1548 | MainLoss:0.1548 | SPLoss:0.3052 | CLSLoss:0.1629 | AUROC:0.9889\n",
      "Test | 128/16 | Loss:1.1297 | MainLoss:1.1297 | SPLoss:0.3052 | CLSLoss:0.1629 | AUROC:0.8441\n",
      "\n",
      "Epoch: [283 | 1000] LR: 0.017480\n",
      "Train | 16/16 | Loss:0.1352 | MainLoss:0.0882 | Alpha:0.4462 | SPLoss:0.3062 | CLSLoss:0.1641 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1677 | MainLoss:0.1677 | SPLoss:0.3079 | CLSLoss:0.1649 | AUROC:0.9887\n",
      "Test | 128/16 | Loss:1.1229 | MainLoss:1.1229 | SPLoss:0.3079 | CLSLoss:0.1649 | AUROC:0.8433\n",
      "\n",
      "Epoch: [284 | 1000] LR: 0.017459\n",
      "Train | 16/16 | Loss:0.1443 | MainLoss:0.0970 | Alpha:0.4453 | SPLoss:0.3083 | CLSLoss:0.1644 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1586 | MainLoss:0.1586 | SPLoss:0.3080 | CLSLoss:0.1637 | AUROC:0.9892\n",
      "Test | 128/16 | Loss:1.1306 | MainLoss:1.1306 | SPLoss:0.3080 | CLSLoss:0.1637 | AUROC:0.8448\n",
      "\n",
      "Epoch: [285 | 1000] LR: 0.017438\n",
      "Train | 16/16 | Loss:0.1431 | MainLoss:0.0962 | Alpha:0.4451 | SPLoss:0.3063 | CLSLoss:0.1632 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1660 | MainLoss:0.1660 | SPLoss:0.3057 | CLSLoss:0.1622 | AUROC:0.9893\n",
      "Test | 128/16 | Loss:1.1047 | MainLoss:1.1047 | SPLoss:0.3057 | CLSLoss:0.1622 | AUROC:0.8451\n",
      "\n",
      "Epoch: [286 | 1000] LR: 0.017417\n",
      "Train | 16/16 | Loss:0.1471 | MainLoss:0.1002 | Alpha:0.4431 | SPLoss:0.3069 | CLSLoss:0.1619 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1650 | MainLoss:0.1650 | SPLoss:0.3078 | CLSLoss:0.1614 | AUROC:0.9887\n",
      "Test | 128/16 | Loss:1.1117 | MainLoss:1.1117 | SPLoss:0.3078 | CLSLoss:0.1614 | AUROC:0.8524\n",
      "\n",
      "Epoch: [287 | 1000] LR: 0.017396\n",
      "Train | 16/16 | Loss:0.1364 | MainLoss:0.0895 | Alpha:0.4471 | SPLoss:0.3073 | CLSLoss:0.1617 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1572 | MainLoss:0.1572 | SPLoss:0.3067 | CLSLoss:0.1615 | AUROC:0.9881\n",
      "Test | 128/16 | Loss:1.1445 | MainLoss:1.1445 | SPLoss:0.3067 | CLSLoss:0.1615 | AUROC:0.8520\n",
      "\n",
      "Epoch: [288 | 1000] LR: 0.017375\n",
      "Train | 16/16 | Loss:0.1324 | MainLoss:0.0853 | Alpha:0.4463 | SPLoss:0.3082 | CLSLoss:0.1630 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1638 | MainLoss:0.1638 | SPLoss:0.3113 | CLSLoss:0.1632 | AUROC:0.9884\n",
      "Test | 128/16 | Loss:1.1034 | MainLoss:1.1034 | SPLoss:0.3113 | CLSLoss:0.1632 | AUROC:0.8542\n",
      "\n",
      "Epoch: [289 | 1000] LR: 0.017354\n",
      "Train | 16/16 | Loss:0.1509 | MainLoss:0.1037 | Alpha:0.4471 | SPLoss:0.3102 | CLSLoss:0.1619 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1560 | MainLoss:0.1560 | SPLoss:0.3104 | CLSLoss:0.1605 | AUROC:0.9884\n",
      "Test | 128/16 | Loss:1.1352 | MainLoss:1.1352 | SPLoss:0.3104 | CLSLoss:0.1605 | AUROC:0.8517\n",
      "\n",
      "Epoch: [290 | 1000] LR: 0.017333\n",
      "Train | 16/16 | Loss:0.1369 | MainLoss:0.0896 | Alpha:0.4468 | SPLoss:0.3120 | CLSLoss:0.1611 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1640 | MainLoss:0.1640 | SPLoss:0.3139 | CLSLoss:0.1615 | AUROC:0.9886\n",
      "Test | 128/16 | Loss:1.0979 | MainLoss:1.0979 | SPLoss:0.3139 | CLSLoss:0.1615 | AUROC:0.8514\n",
      "\n",
      "Epoch: [291 | 1000] LR: 0.017311\n",
      "Train | 16/16 | Loss:0.1327 | MainLoss:0.0852 | Alpha:0.4462 | SPLoss:0.3130 | CLSLoss:0.1623 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1657 | MainLoss:0.1657 | SPLoss:0.3129 | CLSLoss:0.1630 | AUROC:0.9885\n",
      "Test | 128/16 | Loss:1.0866 | MainLoss:1.0866 | SPLoss:0.3129 | CLSLoss:0.1630 | AUROC:0.8608\n",
      "\n",
      "Epoch: [292 | 1000] LR: 0.017290\n",
      "Train | 16/16 | Loss:0.1416 | MainLoss:0.0941 | Alpha:0.4466 | SPLoss:0.3131 | CLSLoss:0.1625 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1559 | MainLoss:0.1559 | SPLoss:0.3122 | CLSLoss:0.1634 | AUROC:0.9886\n",
      "Test | 128/16 | Loss:1.1635 | MainLoss:1.1635 | SPLoss:0.3122 | CLSLoss:0.1634 | AUROC:0.8518\n",
      "\n",
      "Epoch: [293 | 1000] LR: 0.017268\n",
      "Train | 16/16 | Loss:0.1481 | MainLoss:0.1007 | Alpha:0.4465 | SPLoss:0.3111 | CLSLoss:0.1625 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1583 | MainLoss:0.1583 | SPLoss:0.3118 | CLSLoss:0.1607 | AUROC:0.9886\n",
      "Test | 128/16 | Loss:1.1297 | MainLoss:1.1297 | SPLoss:0.3118 | CLSLoss:0.1607 | AUROC:0.8511\n",
      "\n",
      "Epoch: [294 | 1000] LR: 0.017247\n",
      "Train | 16/16 | Loss:0.1386 | MainLoss:0.0913 | Alpha:0.4461 | SPLoss:0.3128 | CLSLoss:0.1610 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1638 | MainLoss:0.1638 | SPLoss:0.3129 | CLSLoss:0.1622 | AUROC:0.9889\n",
      "Test | 128/16 | Loss:1.1028 | MainLoss:1.1028 | SPLoss:0.3129 | CLSLoss:0.1622 | AUROC:0.8502\n",
      "\n",
      "Epoch: [295 | 1000] LR: 0.017225\n",
      "Train | 16/16 | Loss:0.1336 | MainLoss:0.0863 | Alpha:0.4486 | SPLoss:0.3116 | CLSLoss:0.1616 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1491 | MainLoss:0.1491 | SPLoss:0.3099 | CLSLoss:0.1626 | AUROC:0.9888\n",
      "Test | 128/16 | Loss:1.1980 | MainLoss:1.1980 | SPLoss:0.3099 | CLSLoss:0.1626 | AUROC:0.8442\n",
      "\n",
      "Epoch: [296 | 1000] LR: 0.017203\n",
      "Train | 16/16 | Loss:0.1459 | MainLoss:0.0989 | Alpha:0.4480 | SPLoss:0.3089 | CLSLoss:0.1609 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1528 | MainLoss:0.1528 | SPLoss:0.3087 | CLSLoss:0.1597 | AUROC:0.9887\n",
      "Test | 128/16 | Loss:1.1285 | MainLoss:1.1285 | SPLoss:0.3087 | CLSLoss:0.1597 | AUROC:0.8510\n",
      "\n",
      "Epoch: [297 | 1000] LR: 0.017181\n",
      "Train | 16/16 | Loss:0.1318 | MainLoss:0.0848 | Alpha:0.4470 | SPLoss:0.3098 | CLSLoss:0.1603 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1680 | MainLoss:0.1680 | SPLoss:0.3124 | CLSLoss:0.1619 | AUROC:0.9886\n",
      "Test | 128/16 | Loss:1.0692 | MainLoss:1.0692 | SPLoss:0.3124 | CLSLoss:0.1619 | AUROC:0.8523\n",
      "\n",
      "Epoch: [298 | 1000] LR: 0.017159\n",
      "Train | 16/16 | Loss:0.1386 | MainLoss:0.0912 | Alpha:0.4460 | SPLoss:0.3111 | CLSLoss:0.1622 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1563 | MainLoss:0.1563 | SPLoss:0.3102 | CLSLoss:0.1614 | AUROC:0.9888\n",
      "Test | 128/16 | Loss:1.1344 | MainLoss:1.1344 | SPLoss:0.3102 | CLSLoss:0.1614 | AUROC:0.8459\n",
      "\n",
      "Epoch: [299 | 1000] LR: 0.017137\n",
      "Train | 16/16 | Loss:0.1293 | MainLoss:0.0820 | Alpha:0.4476 | SPLoss:0.3106 | CLSLoss:0.1628 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1621 | MainLoss:0.1621 | SPLoss:0.3103 | CLSLoss:0.1629 | AUROC:0.9889\n",
      "Test | 128/16 | Loss:1.1335 | MainLoss:1.1335 | SPLoss:0.3103 | CLSLoss:0.1629 | AUROC:0.8481\n",
      "\n",
      "Epoch: [300 | 1000] LR: 0.017115\n",
      "Train | 16/16 | Loss:0.1384 | MainLoss:0.0912 | Alpha:0.4467 | SPLoss:0.3110 | CLSLoss:0.1615 | AUROC:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 32/16 | Loss:0.1569 | MainLoss:0.1569 | SPLoss:0.3108 | CLSLoss:0.1608 | AUROC:0.9891\n",
      "Test | 128/16 | Loss:1.1080 | MainLoss:1.1080 | SPLoss:0.3108 | CLSLoss:0.1608 | AUROC:0.8552\n",
      "\n",
      "Epoch: [301 | 1000] LR: 0.017093\n",
      "Train | 16/16 | Loss:0.0932 | MainLoss:0.0768 | Alpha:0.4826 | SPLoss:0.0020 | CLSLoss:0.1622 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1532 | MainLoss:0.1532 | SPLoss:0.0041 | CLSLoss:0.1637 | AUROC:0.9893\n",
      "Test | 128/16 | Loss:1.1701 | MainLoss:1.1701 | SPLoss:0.0041 | CLSLoss:0.1637 | AUROC:0.8503\n",
      "\n",
      "Epoch: [302 | 1000] LR: 0.017071\n",
      "Train | 16/16 | Loss:0.0974 | MainLoss:0.0804 | Alpha:0.4811 | SPLoss:0.0061 | CLSLoss:0.1640 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1808 | MainLoss:0.1808 | SPLoss:0.0088 | CLSLoss:0.1638 | AUROC:0.9887\n",
      "Test | 128/16 | Loss:1.1014 | MainLoss:1.1014 | SPLoss:0.0088 | CLSLoss:0.1638 | AUROC:0.8507\n",
      "\n",
      "Epoch: [303 | 1000] LR: 0.017049\n",
      "Train | 16/16 | Loss:0.1082 | MainLoss:0.0908 | Alpha:0.4794 | SPLoss:0.0113 | CLSLoss:0.1623 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1651 | MainLoss:0.1651 | SPLoss:0.0133 | CLSLoss:0.1612 | AUROC:0.9889\n",
      "Test | 128/16 | Loss:1.1105 | MainLoss:1.1105 | SPLoss:0.0133 | CLSLoss:0.1612 | AUROC:0.8565\n",
      "\n",
      "Epoch: [304 | 1000] LR: 0.017026\n",
      "Train | 16/16 | Loss:0.1002 | MainLoss:0.0826 | Alpha:0.4804 | SPLoss:0.0153 | CLSLoss:0.1610 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1637 | MainLoss:0.1637 | SPLoss:0.0179 | CLSLoss:0.1608 | AUROC:0.9884\n",
      "Test | 128/16 | Loss:1.1320 | MainLoss:1.1320 | SPLoss:0.0179 | CLSLoss:0.1608 | AUROC:0.8589\n",
      "\n",
      "Epoch: [305 | 1000] LR: 0.017004\n",
      "Train | 16/16 | Loss:0.1050 | MainLoss:0.0870 | Alpha:0.4805 | SPLoss:0.0196 | CLSLoss:0.1603 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1590 | MainLoss:0.1590 | SPLoss:0.0215 | CLSLoss:0.1584 | AUROC:0.9889\n",
      "Test | 128/16 | Loss:1.1217 | MainLoss:1.1217 | SPLoss:0.0215 | CLSLoss:0.1584 | AUROC:0.8588\n",
      "\n",
      "Epoch: [306 | 1000] LR: 0.016982\n",
      "Train | 16/16 | Loss:0.0988 | MainLoss:0.0806 | Alpha:0.4807 | SPLoss:0.0230 | CLSLoss:0.1585 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1508 | MainLoss:0.1508 | SPLoss:0.0250 | CLSLoss:0.1592 | AUROC:0.9891\n",
      "Test | 128/16 | Loss:1.1581 | MainLoss:1.1581 | SPLoss:0.0250 | CLSLoss:0.1592 | AUROC:0.8616\n",
      "\n",
      "Epoch: [307 | 1000] LR: 0.016959\n",
      "Train | 16/16 | Loss:0.0920 | MainLoss:0.0734 | Alpha:0.4823 | SPLoss:0.0267 | CLSLoss:0.1592 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1607 | MainLoss:0.1607 | SPLoss:0.0280 | CLSLoss:0.1603 | AUROC:0.9892\n",
      "Test | 128/16 | Loss:1.1135 | MainLoss:1.1135 | SPLoss:0.0280 | CLSLoss:0.1603 | AUROC:0.8690\n",
      "\n",
      "Epoch: [308 | 1000] LR: 0.016937\n",
      "Train | 16/16 | Loss:0.1028 | MainLoss:0.0838 | Alpha:0.4786 | SPLoss:0.0300 | CLSLoss:0.1600 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1540 | MainLoss:0.1540 | SPLoss:0.0323 | CLSLoss:0.1593 | AUROC:0.9888\n",
      "Test | 128/16 | Loss:1.1730 | MainLoss:1.1730 | SPLoss:0.0323 | CLSLoss:0.1593 | AUROC:0.8689\n",
      "\n",
      "Epoch: [309 | 1000] LR: 0.016914\n",
      "Train | 16/16 | Loss:0.0968 | MainLoss:0.0776 | Alpha:0.4815 | SPLoss:0.0340 | CLSLoss:0.1584 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1648 | MainLoss:0.1648 | SPLoss:0.0353 | CLSLoss:0.1593 | AUROC:0.9891\n",
      "Test | 128/16 | Loss:1.1045 | MainLoss:1.1045 | SPLoss:0.0353 | CLSLoss:0.1593 | AUROC:0.8732\n",
      "\n",
      "Epoch: [310 | 1000] LR: 0.016891\n",
      "Train | 16/16 | Loss:0.1079 | MainLoss:0.0883 | Alpha:0.4781 | SPLoss:0.0375 | CLSLoss:0.1580 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1584 | MainLoss:0.1584 | SPLoss:0.0399 | CLSLoss:0.1560 | AUROC:0.9889\n",
      "Test | 128/16 | Loss:1.1173 | MainLoss:1.1173 | SPLoss:0.0399 | CLSLoss:0.1560 | AUROC:0.8677\n",
      "\n",
      "Epoch: [311 | 1000] LR: 0.016868\n",
      "Train | 16/16 | Loss:0.1013 | MainLoss:0.0815 | Alpha:0.4797 | SPLoss:0.0413 | CLSLoss:0.1563 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1708 | MainLoss:0.1708 | SPLoss:0.0437 | CLSLoss:0.1560 | AUROC:0.9891\n",
      "Test | 128/16 | Loss:1.0436 | MainLoss:1.0436 | SPLoss:0.0437 | CLSLoss:0.1560 | AUROC:0.8712\n",
      "\n",
      "Epoch: [312 | 1000] LR: 0.016845\n",
      "Train | 16/16 | Loss:0.1100 | MainLoss:0.0899 | Alpha:0.4777 | SPLoss:0.0457 | CLSLoss:0.1553 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1618 | MainLoss:0.1618 | SPLoss:0.0476 | CLSLoss:0.1547 | AUROC:0.9891\n",
      "Test | 128/16 | Loss:1.1081 | MainLoss:1.1081 | SPLoss:0.0476 | CLSLoss:0.1547 | AUROC:0.8654\n",
      "\n",
      "Epoch: [313 | 1000] LR: 0.016823\n",
      "Train | 16/16 | Loss:0.0890 | MainLoss:0.0686 | Alpha:0.4819 | SPLoss:0.0483 | CLSLoss:0.1555 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1627 | MainLoss:0.1627 | SPLoss:0.0495 | CLSLoss:0.1569 | AUROC:0.9894\n",
      "Test | 128/16 | Loss:1.1092 | MainLoss:1.1092 | SPLoss:0.0495 | CLSLoss:0.1569 | AUROC:0.8688\n",
      "\n",
      "Epoch: [314 | 1000] LR: 0.016800\n",
      "Train | 16/16 | Loss:0.1014 | MainLoss:0.0807 | Alpha:0.4792 | SPLoss:0.0513 | CLSLoss:0.1557 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1622 | MainLoss:0.1622 | SPLoss:0.0528 | CLSLoss:0.1565 | AUROC:0.9894\n",
      "Test | 128/16 | Loss:1.1201 | MainLoss:1.1201 | SPLoss:0.0528 | CLSLoss:0.1565 | AUROC:0.8688\n",
      "\n",
      "Epoch: [315 | 1000] LR: 0.016776\n",
      "Train | 16/16 | Loss:0.1075 | MainLoss:0.0864 | Alpha:0.4779 | SPLoss:0.0549 | CLSLoss:0.1559 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1501 | MainLoss:0.1501 | SPLoss:0.0577 | CLSLoss:0.1547 | AUROC:0.9896\n",
      "Test | 128/16 | Loss:1.1376 | MainLoss:1.1376 | SPLoss:0.0577 | CLSLoss:0.1547 | AUROC:0.8737\n",
      "\n",
      "Epoch: [316 | 1000] LR: 0.016753\n",
      "Train | 16/16 | Loss:0.0903 | MainLoss:0.0688 | Alpha:0.4819 | SPLoss:0.0584 | CLSLoss:0.1564 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1528 | MainLoss:0.1528 | SPLoss:0.0591 | CLSLoss:0.1558 | AUROC:0.9895\n",
      "Test | 128/16 | Loss:1.1393 | MainLoss:1.1393 | SPLoss:0.0591 | CLSLoss:0.1558 | AUROC:0.8709\n",
      "\n",
      "Epoch: [317 | 1000] LR: 0.016730\n",
      "Train | 16/16 | Loss:0.0978 | MainLoss:0.0762 | Alpha:0.4796 | SPLoss:0.0606 | CLSLoss:0.1554 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1564 | MainLoss:0.1564 | SPLoss:0.0615 | CLSLoss:0.1551 | AUROC:0.9896\n",
      "Test | 128/16 | Loss:1.1342 | MainLoss:1.1342 | SPLoss:0.0615 | CLSLoss:0.1551 | AUROC:0.8702\n",
      "\n",
      "Epoch: [318 | 1000] LR: 0.016707\n",
      "Train | 16/16 | Loss:0.0941 | MainLoss:0.0724 | Alpha:0.4822 | SPLoss:0.0618 | CLSLoss:0.1551 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1590 | MainLoss:0.1590 | SPLoss:0.0625 | CLSLoss:0.1550 | AUROC:0.9897\n",
      "Test | 128/16 | Loss:1.1360 | MainLoss:1.1360 | SPLoss:0.0625 | CLSLoss:0.1550 | AUROC:0.8659\n",
      "\n",
      "Epoch: [319 | 1000] LR: 0.016684\n",
      "Train | 16/16 | Loss:0.0873 | MainLoss:0.0654 | Alpha:0.4829 | SPLoss:0.0632 | CLSLoss:0.1557 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1607 | MainLoss:0.1607 | SPLoss:0.0644 | CLSLoss:0.1555 | AUROC:0.9898\n",
      "Test | 128/16 | Loss:1.1623 | MainLoss:1.1623 | SPLoss:0.0644 | CLSLoss:0.1555 | AUROC:0.8632\n",
      "\n",
      "Epoch: [320 | 1000] LR: 0.016660\n",
      "Train | 16/16 | Loss:0.0924 | MainLoss:0.0703 | Alpha:0.4804 | SPLoss:0.0658 | CLSLoss:0.1553 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1521 | MainLoss:0.1521 | SPLoss:0.0673 | CLSLoss:0.1550 | AUROC:0.9901\n",
      "Test | 128/16 | Loss:1.1989 | MainLoss:1.1989 | SPLoss:0.0673 | CLSLoss:0.1550 | AUROC:0.8627\n",
      "\n",
      "Epoch: [321 | 1000] LR: 0.016637\n",
      "Train | 16/16 | Loss:0.0949 | MainLoss:0.0725 | Alpha:0.4824 | SPLoss:0.0685 | CLSLoss:0.1546 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1627 | MainLoss:0.1627 | SPLoss:0.0699 | CLSLoss:0.1540 | AUROC:0.9900\n",
      "Test | 128/16 | Loss:1.1406 | MainLoss:1.1406 | SPLoss:0.0699 | CLSLoss:0.1540 | AUROC:0.8635\n",
      "\n",
      "Epoch: [322 | 1000] LR: 0.016613\n",
      "Train | 16/16 | Loss:0.1055 | MainLoss:0.0833 | Alpha:0.4787 | SPLoss:0.0706 | CLSLoss:0.1515 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1586 | MainLoss:0.1586 | SPLoss:0.0716 | CLSLoss:0.1523 | AUROC:0.9898\n",
      "Test | 128/16 | Loss:1.1331 | MainLoss:1.1331 | SPLoss:0.0716 | CLSLoss:0.1523 | AUROC:0.8644\n",
      "\n",
      "Epoch: [323 | 1000] LR: 0.016590\n",
      "Train | 16/16 | Loss:0.1028 | MainLoss:0.0804 | Alpha:0.4790 | SPLoss:0.0727 | CLSLoss:0.1512 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1440 | MainLoss:0.1440 | SPLoss:0.0733 | CLSLoss:0.1514 | AUROC:0.9902\n",
      "Test | 128/16 | Loss:1.1994 | MainLoss:1.1994 | SPLoss:0.0733 | CLSLoss:0.1514 | AUROC:0.8621\n",
      "\n",
      "Epoch: [324 | 1000] LR: 0.016566\n",
      "Train | 16/16 | Loss:0.0985 | MainLoss:0.0758 | Alpha:0.4793 | SPLoss:0.0752 | CLSLoss:0.1522 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1510 | MainLoss:0.1510 | SPLoss:0.0772 | CLSLoss:0.1519 | AUROC:0.9897\n",
      "Test | 128/16 | Loss:1.1620 | MainLoss:1.1620 | SPLoss:0.0772 | CLSLoss:0.1519 | AUROC:0.8719\n",
      "\n",
      "Epoch: [325 | 1000] LR: 0.016542\n",
      "Train | 16/16 | Loss:0.1016 | MainLoss:0.0786 | Alpha:0.4777 | SPLoss:0.0789 | CLSLoss:0.1511 | AUROC:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 32/16 | Loss:0.1647 | MainLoss:0.1647 | SPLoss:0.0807 | CLSLoss:0.1518 | AUROC:0.9901\n",
      "Test | 128/16 | Loss:1.0963 | MainLoss:1.0963 | SPLoss:0.0807 | CLSLoss:0.1518 | AUROC:0.8725\n",
      "\n",
      "Epoch: [326 | 1000] LR: 0.016518\n",
      "Train | 16/16 | Loss:0.0992 | MainLoss:0.0759 | Alpha:0.4787 | SPLoss:0.0812 | CLSLoss:0.1517 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1468 | MainLoss:0.1468 | SPLoss:0.0821 | CLSLoss:0.1507 | AUROC:0.9899\n",
      "Test | 128/16 | Loss:1.2429 | MainLoss:1.2429 | SPLoss:0.0821 | CLSLoss:0.1507 | AUROC:0.8598\n",
      "\n",
      "Epoch: [327 | 1000] LR: 0.016494\n",
      "Train | 16/16 | Loss:0.0881 | MainLoss:0.0646 | Alpha:0.4816 | SPLoss:0.0835 | CLSLoss:0.1515 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1578 | MainLoss:0.1578 | SPLoss:0.0845 | CLSLoss:0.1531 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1942 | MainLoss:1.1942 | SPLoss:0.0845 | CLSLoss:0.1531 | AUROC:0.8616\n",
      "\n",
      "Epoch: [328 | 1000] LR: 0.016471\n",
      "Train | 16/16 | Loss:0.0941 | MainLoss:0.0703 | Alpha:0.4811 | SPLoss:0.0854 | CLSLoss:0.1530 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1505 | MainLoss:0.1505 | SPLoss:0.0861 | CLSLoss:0.1524 | AUROC:0.9901\n",
      "Test | 128/16 | Loss:1.2332 | MainLoss:1.2332 | SPLoss:0.0861 | CLSLoss:0.1524 | AUROC:0.8598\n",
      "\n",
      "Epoch: [329 | 1000] LR: 0.016447\n",
      "Train | 16/16 | Loss:0.1055 | MainLoss:0.0816 | Alpha:0.4779 | SPLoss:0.0871 | CLSLoss:0.1518 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1461 | MainLoss:0.1461 | SPLoss:0.0881 | CLSLoss:0.1508 | AUROC:0.9904\n",
      "Test | 128/16 | Loss:1.2128 | MainLoss:1.2128 | SPLoss:0.0881 | CLSLoss:0.1508 | AUROC:0.8619\n",
      "\n",
      "Epoch: [330 | 1000] LR: 0.016423\n",
      "Train | 16/16 | Loss:0.0944 | MainLoss:0.0703 | Alpha:0.4799 | SPLoss:0.0896 | CLSLoss:0.1516 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1427 | MainLoss:0.1427 | SPLoss:0.0907 | CLSLoss:0.1515 | AUROC:0.9903\n",
      "Test | 128/16 | Loss:1.2472 | MainLoss:1.2472 | SPLoss:0.0907 | CLSLoss:0.1515 | AUROC:0.8639\n",
      "\n",
      "Epoch: [331 | 1000] LR: 0.016398\n",
      "Train | 16/16 | Loss:0.0936 | MainLoss:0.0693 | Alpha:0.4803 | SPLoss:0.0914 | CLSLoss:0.1515 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1505 | MainLoss:0.1505 | SPLoss:0.0927 | CLSLoss:0.1521 | AUROC:0.9899\n",
      "Test | 128/16 | Loss:1.1937 | MainLoss:1.1937 | SPLoss:0.0927 | CLSLoss:0.1521 | AUROC:0.8729\n",
      "\n",
      "Epoch: [332 | 1000] LR: 0.016374\n",
      "Train | 16/16 | Loss:0.1063 | MainLoss:0.0818 | Alpha:0.4787 | SPLoss:0.0936 | CLSLoss:0.1516 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1472 | MainLoss:0.1472 | SPLoss:0.0947 | CLSLoss:0.1503 | AUROC:0.9902\n",
      "Test | 128/16 | Loss:1.2190 | MainLoss:1.2190 | SPLoss:0.0947 | CLSLoss:0.1503 | AUROC:0.8665\n",
      "\n",
      "Epoch: [333 | 1000] LR: 0.016350\n",
      "Train | 16/16 | Loss:0.0979 | MainLoss:0.0734 | Alpha:0.4788 | SPLoss:0.0953 | CLSLoss:0.1494 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1554 | MainLoss:0.1554 | SPLoss:0.0970 | CLSLoss:0.1496 | AUROC:0.9901\n",
      "Test | 128/16 | Loss:1.1459 | MainLoss:1.1459 | SPLoss:0.0970 | CLSLoss:0.1496 | AUROC:0.8751\n",
      "\n",
      "Epoch: [334 | 1000] LR: 0.016326\n",
      "Train | 16/16 | Loss:0.1069 | MainLoss:0.0822 | Alpha:0.4771 | SPLoss:0.0981 | CLSLoss:0.1492 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1461 | MainLoss:0.1461 | SPLoss:0.0990 | CLSLoss:0.1476 | AUROC:0.9902\n",
      "Test | 128/16 | Loss:1.1274 | MainLoss:1.1274 | SPLoss:0.0990 | CLSLoss:0.1476 | AUROC:0.8801\n",
      "\n",
      "Epoch: [335 | 1000] LR: 0.016301\n",
      "Train | 16/16 | Loss:0.0936 | MainLoss:0.0688 | Alpha:0.4806 | SPLoss:0.0998 | CLSLoss:0.1487 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1620 | MainLoss:0.1620 | SPLoss:0.1005 | CLSLoss:0.1497 | AUROC:0.9902\n",
      "Test | 128/16 | Loss:1.1031 | MainLoss:1.1031 | SPLoss:0.1005 | CLSLoss:0.1497 | AUROC:0.8803\n",
      "\n",
      "Epoch: [336 | 1000] LR: 0.016277\n",
      "Train | 16/16 | Loss:0.0990 | MainLoss:0.0739 | Alpha:0.4797 | SPLoss:0.1006 | CLSLoss:0.1499 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1541 | MainLoss:0.1541 | SPLoss:0.1010 | CLSLoss:0.1482 | AUROC:0.9901\n",
      "Test | 128/16 | Loss:1.1142 | MainLoss:1.1142 | SPLoss:0.1010 | CLSLoss:0.1482 | AUROC:0.8812\n",
      "\n",
      "Epoch: [337 | 1000] LR: 0.016252\n",
      "Train | 16/16 | Loss:0.0990 | MainLoss:0.0741 | Alpha:0.4799 | SPLoss:0.1020 | CLSLoss:0.1474 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1500 | MainLoss:0.1500 | SPLoss:0.1031 | CLSLoss:0.1482 | AUROC:0.9898\n",
      "Test | 128/16 | Loss:1.1418 | MainLoss:1.1418 | SPLoss:0.1031 | CLSLoss:0.1482 | AUROC:0.8783\n",
      "\n",
      "Epoch: [338 | 1000] LR: 0.016228\n",
      "Train | 16/16 | Loss:0.0990 | MainLoss:0.0738 | Alpha:0.4785 | SPLoss:0.1046 | CLSLoss:0.1483 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1598 | MainLoss:0.1598 | SPLoss:0.1055 | CLSLoss:0.1488 | AUROC:0.9900\n",
      "Test | 128/16 | Loss:1.0894 | MainLoss:1.0894 | SPLoss:0.1055 | CLSLoss:0.1488 | AUROC:0.8800\n",
      "\n",
      "Epoch: [339 | 1000] LR: 0.016203\n",
      "Train | 16/16 | Loss:0.1018 | MainLoss:0.0763 | Alpha:0.4791 | SPLoss:0.1058 | CLSLoss:0.1495 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1549 | MainLoss:0.1549 | SPLoss:0.1070 | CLSLoss:0.1479 | AUROC:0.9898\n",
      "Test | 128/16 | Loss:1.1494 | MainLoss:1.1494 | SPLoss:0.1070 | CLSLoss:0.1479 | AUROC:0.8709\n",
      "\n",
      "Epoch: [340 | 1000] LR: 0.016179\n",
      "Train | 16/16 | Loss:0.0958 | MainLoss:0.0701 | Alpha:0.4792 | SPLoss:0.1081 | CLSLoss:0.1487 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1572 | MainLoss:0.1572 | SPLoss:0.1090 | CLSLoss:0.1485 | AUROC:0.9896\n",
      "Test | 128/16 | Loss:1.1410 | MainLoss:1.1410 | SPLoss:0.1090 | CLSLoss:0.1485 | AUROC:0.8731\n",
      "\n",
      "Epoch: [341 | 1000] LR: 0.016154\n",
      "Train | 16/16 | Loss:0.0947 | MainLoss:0.0688 | Alpha:0.4796 | SPLoss:0.1102 | CLSLoss:0.1495 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1599 | MainLoss:0.1599 | SPLoss:0.1112 | CLSLoss:0.1494 | AUROC:0.9896\n",
      "Test | 128/16 | Loss:1.1273 | MainLoss:1.1273 | SPLoss:0.1112 | CLSLoss:0.1494 | AUROC:0.8759\n",
      "\n",
      "Epoch: [342 | 1000] LR: 0.016129\n",
      "Train | 16/16 | Loss:0.1041 | MainLoss:0.0778 | Alpha:0.4758 | SPLoss:0.1141 | CLSLoss:0.1490 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1525 | MainLoss:0.1525 | SPLoss:0.1173 | CLSLoss:0.1491 | AUROC:0.9894\n",
      "Test | 128/16 | Loss:1.1510 | MainLoss:1.1510 | SPLoss:0.1173 | CLSLoss:0.1491 | AUROC:0.8748\n",
      "\n",
      "Epoch: [343 | 1000] LR: 0.016104\n",
      "Train | 16/16 | Loss:0.1011 | MainLoss:0.0744 | Alpha:0.4795 | SPLoss:0.1171 | CLSLoss:0.1494 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1528 | MainLoss:0.1528 | SPLoss:0.1177 | CLSLoss:0.1488 | AUROC:0.9899\n",
      "Test | 128/16 | Loss:1.1554 | MainLoss:1.1554 | SPLoss:0.1177 | CLSLoss:0.1488 | AUROC:0.8720\n",
      "\n",
      "Epoch: [344 | 1000] LR: 0.016079\n",
      "Train | 16/16 | Loss:0.1017 | MainLoss:0.0751 | Alpha:0.4796 | SPLoss:0.1175 | CLSLoss:0.1487 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1488 | MainLoss:0.1488 | SPLoss:0.1169 | CLSLoss:0.1478 | AUROC:0.9901\n",
      "Test | 128/16 | Loss:1.1472 | MainLoss:1.1472 | SPLoss:0.1169 | CLSLoss:0.1478 | AUROC:0.8767\n",
      "\n",
      "Epoch: [345 | 1000] LR: 0.016054\n",
      "Train | 16/16 | Loss:0.0827 | MainLoss:0.0560 | Alpha:0.4828 | SPLoss:0.1170 | CLSLoss:0.1497 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1587 | MainLoss:0.1587 | SPLoss:0.1169 | CLSLoss:0.1507 | AUROC:0.9899\n",
      "Test | 128/16 | Loss:1.1533 | MainLoss:1.1533 | SPLoss:0.1169 | CLSLoss:0.1507 | AUROC:0.8739\n",
      "\n",
      "Epoch: [346 | 1000] LR: 0.016029\n",
      "Train | 16/16 | Loss:0.0929 | MainLoss:0.0662 | Alpha:0.4800 | SPLoss:0.1169 | CLSLoss:0.1496 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1542 | MainLoss:0.1542 | SPLoss:0.1172 | CLSLoss:0.1503 | AUROC:0.9899\n",
      "Test | 128/16 | Loss:1.1999 | MainLoss:1.1999 | SPLoss:0.1172 | CLSLoss:0.1503 | AUROC:0.8699\n",
      "\n",
      "Epoch: [347 | 1000] LR: 0.016004\n",
      "Train | 16/16 | Loss:0.0955 | MainLoss:0.0687 | Alpha:0.4789 | SPLoss:0.1181 | CLSLoss:0.1500 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1648 | MainLoss:0.1648 | SPLoss:0.1201 | CLSLoss:0.1496 | AUROC:0.9898\n",
      "Test | 128/16 | Loss:1.1332 | MainLoss:1.1332 | SPLoss:0.1201 | CLSLoss:0.1496 | AUROC:0.8731\n",
      "\n",
      "Epoch: [348 | 1000] LR: 0.015979\n",
      "Train | 16/16 | Loss:0.0923 | MainLoss:0.0653 | Alpha:0.4804 | SPLoss:0.1200 | CLSLoss:0.1497 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1565 | MainLoss:0.1565 | SPLoss:0.1204 | CLSLoss:0.1495 | AUROC:0.9897\n",
      "Test | 128/16 | Loss:1.1870 | MainLoss:1.1870 | SPLoss:0.1204 | CLSLoss:0.1495 | AUROC:0.8708\n",
      "\n",
      "Epoch: [349 | 1000] LR: 0.015954\n",
      "Train | 16/16 | Loss:0.0872 | MainLoss:0.0602 | Alpha:0.4813 | SPLoss:0.1202 | CLSLoss:0.1499 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1686 | MainLoss:0.1686 | SPLoss:0.1202 | CLSLoss:0.1501 | AUROC:0.9902\n",
      "Test | 128/16 | Loss:1.1433 | MainLoss:1.1433 | SPLoss:0.1202 | CLSLoss:0.1501 | AUROC:0.8753\n",
      "\n",
      "Epoch: [350 | 1000] LR: 0.015929\n",
      "Train | 16/16 | Loss:0.0830 | MainLoss:0.0559 | Alpha:0.4828 | SPLoss:0.1207 | CLSLoss:0.1501 | AUROC:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 32/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:0.1211 | CLSLoss:0.1505 | AUROC:0.9902\n",
      "Test | 128/16 | Loss:1.1616 | MainLoss:1.1616 | SPLoss:0.1211 | CLSLoss:0.1505 | AUROC:0.8740\n",
      "\n",
      "Epoch: [351 | 1000] LR: 0.015903\n",
      "Train | 16/16 | Loss:0.0923 | MainLoss:0.0650 | Alpha:0.4800 | SPLoss:0.1225 | CLSLoss:0.1508 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1717 | MainLoss:0.1717 | SPLoss:0.1237 | CLSLoss:0.1499 | AUROC:0.9904\n",
      "Test | 128/16 | Loss:1.1150 | MainLoss:1.1150 | SPLoss:0.1237 | CLSLoss:0.1499 | AUROC:0.8725\n",
      "\n",
      "Epoch: [352 | 1000] LR: 0.015878\n",
      "Train | 16/16 | Loss:0.0901 | MainLoss:0.0629 | Alpha:0.4814 | SPLoss:0.1230 | CLSLoss:0.1494 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:0.1228 | CLSLoss:0.1497 | AUROC:0.9900\n",
      "Test | 128/16 | Loss:1.1450 | MainLoss:1.1450 | SPLoss:0.1228 | CLSLoss:0.1497 | AUROC:0.8690\n",
      "\n",
      "Epoch: [353 | 1000] LR: 0.015852\n",
      "Train | 16/16 | Loss:0.0945 | MainLoss:0.0673 | Alpha:0.4814 | SPLoss:0.1238 | CLSLoss:0.1487 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1524 | MainLoss:0.1524 | SPLoss:0.1232 | CLSLoss:0.1491 | AUROC:0.9900\n",
      "Test | 128/16 | Loss:1.2010 | MainLoss:1.2010 | SPLoss:0.1232 | CLSLoss:0.1491 | AUROC:0.8637\n",
      "\n",
      "Epoch: [354 | 1000] LR: 0.015827\n",
      "Train | 16/16 | Loss:0.0969 | MainLoss:0.0697 | Alpha:0.4797 | SPLoss:0.1237 | CLSLoss:0.1484 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1597 | MainLoss:0.1597 | SPLoss:0.1244 | CLSLoss:0.1479 | AUROC:0.9899\n",
      "Test | 128/16 | Loss:1.1673 | MainLoss:1.1673 | SPLoss:0.1244 | CLSLoss:0.1479 | AUROC:0.8684\n",
      "\n",
      "Epoch: [355 | 1000] LR: 0.015801\n",
      "Train | 16/16 | Loss:0.0932 | MainLoss:0.0660 | Alpha:0.4792 | SPLoss:0.1245 | CLSLoss:0.1478 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1842 | MainLoss:0.1842 | SPLoss:0.1254 | CLSLoss:0.1479 | AUROC:0.9898\n",
      "Test | 128/16 | Loss:1.0545 | MainLoss:1.0545 | SPLoss:0.1254 | CLSLoss:0.1479 | AUROC:0.8748\n",
      "\n",
      "Epoch: [356 | 1000] LR: 0.015776\n",
      "Train | 16/16 | Loss:0.0994 | MainLoss:0.0721 | Alpha:0.4796 | SPLoss:0.1258 | CLSLoss:0.1471 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1762 | MainLoss:0.1762 | SPLoss:0.1261 | CLSLoss:0.1460 | AUROC:0.9900\n",
      "Test | 128/16 | Loss:1.0664 | MainLoss:1.0664 | SPLoss:0.1261 | CLSLoss:0.1460 | AUROC:0.8785\n",
      "\n",
      "Epoch: [357 | 1000] LR: 0.015750\n",
      "Train | 16/16 | Loss:0.0901 | MainLoss:0.0628 | Alpha:0.4808 | SPLoss:0.1263 | CLSLoss:0.1465 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1611 | MainLoss:0.1611 | SPLoss:0.1274 | CLSLoss:0.1463 | AUROC:0.9898\n",
      "Test | 128/16 | Loss:1.1771 | MainLoss:1.1771 | SPLoss:0.1274 | CLSLoss:0.1463 | AUROC:0.8715\n",
      "\n",
      "Epoch: [358 | 1000] LR: 0.015724\n",
      "Train | 16/16 | Loss:0.0805 | MainLoss:0.0529 | Alpha:0.4825 | SPLoss:0.1273 | CLSLoss:0.1479 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1579 | MainLoss:0.1579 | SPLoss:0.1267 | CLSLoss:0.1485 | AUROC:0.9897\n",
      "Test | 128/16 | Loss:1.2522 | MainLoss:1.2522 | SPLoss:0.1267 | CLSLoss:0.1485 | AUROC:0.8692\n",
      "\n",
      "Epoch: [359 | 1000] LR: 0.015699\n",
      "Train | 16/16 | Loss:0.0882 | MainLoss:0.0606 | Alpha:0.4809 | SPLoss:0.1276 | CLSLoss:0.1485 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1693 | MainLoss:0.1693 | SPLoss:0.1286 | CLSLoss:0.1476 | AUROC:0.9899\n",
      "Test | 128/16 | Loss:1.1696 | MainLoss:1.1696 | SPLoss:0.1286 | CLSLoss:0.1477 | AUROC:0.8726\n",
      "\n",
      "Epoch: [360 | 1000] LR: 0.015673\n",
      "Train | 16/16 | Loss:0.0928 | MainLoss:0.0652 | Alpha:0.4807 | SPLoss:0.1289 | CLSLoss:0.1474 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1670 | MainLoss:0.1670 | SPLoss:0.1287 | CLSLoss:0.1471 | AUROC:0.9902\n",
      "Test | 128/16 | Loss:1.1568 | MainLoss:1.1568 | SPLoss:0.1287 | CLSLoss:0.1471 | AUROC:0.8717\n",
      "\n",
      "Epoch: [361 | 1000] LR: 0.015647\n",
      "Train | 16/16 | Loss:0.1082 | MainLoss:0.0807 | Alpha:0.4766 | SPLoss:0.1295 | CLSLoss:0.1454 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1640 | MainLoss:0.1640 | SPLoss:0.1304 | CLSLoss:0.1442 | AUROC:0.9897\n",
      "Test | 128/16 | Loss:1.1181 | MainLoss:1.1181 | SPLoss:0.1304 | CLSLoss:0.1442 | AUROC:0.8747\n",
      "\n",
      "Epoch: [362 | 1000] LR: 0.015621\n",
      "Train | 16/16 | Loss:0.1019 | MainLoss:0.0745 | Alpha:0.4797 | SPLoss:0.1305 | CLSLoss:0.1437 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1508 | MainLoss:0.1508 | SPLoss:0.1303 | CLSLoss:0.1439 | AUROC:0.9900\n",
      "Test | 128/16 | Loss:1.2139 | MainLoss:1.2139 | SPLoss:0.1303 | CLSLoss:0.1439 | AUROC:0.8652\n",
      "\n",
      "Epoch: [363 | 1000] LR: 0.015595\n",
      "Train | 16/16 | Loss:0.0782 | MainLoss:0.0506 | Alpha:0.4830 | SPLoss:0.1302 | CLSLoss:0.1460 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1647 | MainLoss:0.1647 | SPLoss:0.1296 | CLSLoss:0.1464 | AUROC:0.9893\n",
      "Test | 128/16 | Loss:1.1631 | MainLoss:1.1631 | SPLoss:0.1296 | CLSLoss:0.1464 | AUROC:0.8740\n",
      "\n",
      "Epoch: [364 | 1000] LR: 0.015569\n",
      "Train | 16/16 | Loss:0.1035 | MainLoss:0.0760 | Alpha:0.4787 | SPLoss:0.1294 | CLSLoss:0.1447 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1533 | MainLoss:0.1533 | SPLoss:0.1297 | CLSLoss:0.1448 | AUROC:0.9898\n",
      "Test | 128/16 | Loss:1.2184 | MainLoss:1.2184 | SPLoss:0.1297 | CLSLoss:0.1448 | AUROC:0.8705\n",
      "\n",
      "Epoch: [365 | 1000] LR: 0.015543\n",
      "Train | 16/16 | Loss:0.0964 | MainLoss:0.0689 | Alpha:0.4796 | SPLoss:0.1304 | CLSLoss:0.1451 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1724 | MainLoss:0.1724 | SPLoss:0.1305 | CLSLoss:0.1444 | AUROC:0.9894\n",
      "Test | 128/16 | Loss:1.0608 | MainLoss:1.0608 | SPLoss:0.1305 | CLSLoss:0.1444 | AUROC:0.8875\n",
      "\n",
      "Epoch: [366 | 1000] LR: 0.015516\n",
      "Train | 16/16 | Loss:0.0805 | MainLoss:0.0527 | Alpha:0.4823 | SPLoss:0.1315 | CLSLoss:0.1462 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1621 | MainLoss:0.1621 | SPLoss:0.1310 | CLSLoss:0.1475 | AUROC:0.9895\n",
      "Test | 128/16 | Loss:1.1627 | MainLoss:1.1627 | SPLoss:0.1310 | CLSLoss:0.1475 | AUROC:0.8812\n",
      "\n",
      "Epoch: [367 | 1000] LR: 0.015490\n",
      "Train | 16/16 | Loss:0.0848 | MainLoss:0.0569 | Alpha:0.4810 | SPLoss:0.1315 | CLSLoss:0.1475 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1536 | MainLoss:0.1536 | SPLoss:0.1317 | CLSLoss:0.1480 | AUROC:0.9897\n",
      "Test | 128/16 | Loss:1.2711 | MainLoss:1.2711 | SPLoss:0.1317 | CLSLoss:0.1480 | AUROC:0.8687\n",
      "\n",
      "Epoch: [368 | 1000] LR: 0.015464\n",
      "Train | 16/16 | Loss:0.0975 | MainLoss:0.0697 | Alpha:0.4791 | SPLoss:0.1317 | CLSLoss:0.1470 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1476 | MainLoss:0.1476 | SPLoss:0.1318 | CLSLoss:0.1463 | AUROC:0.9898\n",
      "Test | 128/16 | Loss:1.2827 | MainLoss:1.2827 | SPLoss:0.1318 | CLSLoss:0.1463 | AUROC:0.8673\n",
      "\n",
      "Epoch: [369 | 1000] LR: 0.015438\n",
      "Train | 16/16 | Loss:0.0998 | MainLoss:0.0721 | Alpha:0.4790 | SPLoss:0.1318 | CLSLoss:0.1448 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1608 | MainLoss:0.1608 | SPLoss:0.1316 | CLSLoss:0.1447 | AUROC:0.9901\n",
      "Test | 128/16 | Loss:1.1316 | MainLoss:1.1316 | SPLoss:0.1316 | CLSLoss:0.1447 | AUROC:0.8781\n",
      "\n",
      "Epoch: [370 | 1000] LR: 0.015411\n",
      "Train | 16/16 | Loss:0.1128 | MainLoss:0.0853 | Alpha:0.4764 | SPLoss:0.1316 | CLSLoss:0.1435 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1564 | MainLoss:0.1564 | SPLoss:0.1320 | CLSLoss:0.1409 | AUROC:0.9903\n",
      "Test | 128/16 | Loss:1.1350 | MainLoss:1.1350 | SPLoss:0.1320 | CLSLoss:0.1409 | AUROC:0.8757\n",
      "\n",
      "Epoch: [371 | 1000] LR: 0.015385\n",
      "Train | 16/16 | Loss:0.1067 | MainLoss:0.0794 | Alpha:0.4772 | SPLoss:0.1323 | CLSLoss:0.1406 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1749 | MainLoss:0.1749 | SPLoss:0.1326 | CLSLoss:0.1400 | AUROC:0.9901\n",
      "Test | 128/16 | Loss:1.0374 | MainLoss:1.0374 | SPLoss:0.1326 | CLSLoss:0.1400 | AUROC:0.8827\n",
      "\n",
      "Epoch: [372 | 1000] LR: 0.015358\n",
      "Train | 16/16 | Loss:0.0882 | MainLoss:0.0608 | Alpha:0.4819 | SPLoss:0.1324 | CLSLoss:0.1414 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1655 | MainLoss:0.1655 | SPLoss:0.1322 | CLSLoss:0.1425 | AUROC:0.9899\n",
      "Test | 128/16 | Loss:1.1128 | MainLoss:1.1128 | SPLoss:0.1322 | CLSLoss:0.1425 | AUROC:0.8737\n",
      "\n",
      "Epoch: [373 | 1000] LR: 0.015332\n",
      "Train | 16/16 | Loss:0.0957 | MainLoss:0.0681 | Alpha:0.4785 | SPLoss:0.1332 | CLSLoss:0.1429 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1655 | MainLoss:0.1655 | SPLoss:0.1333 | CLSLoss:0.1440 | AUROC:0.9900\n",
      "Test | 128/16 | Loss:1.1375 | MainLoss:1.1375 | SPLoss:0.1333 | CLSLoss:0.1440 | AUROC:0.8700\n",
      "\n",
      "Epoch: [374 | 1000] LR: 0.015305\n",
      "Train | 16/16 | Loss:0.0917 | MainLoss:0.0639 | Alpha:0.4801 | SPLoss:0.1337 | CLSLoss:0.1447 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1596 | MainLoss:0.1596 | SPLoss:0.1338 | CLSLoss:0.1453 | AUROC:0.9898\n",
      "Test | 128/16 | Loss:1.2137 | MainLoss:1.2137 | SPLoss:0.1338 | CLSLoss:0.1453 | AUROC:0.8664\n",
      "\n",
      "Epoch: [375 | 1000] LR: 0.015278\n",
      "Train | 16/16 | Loss:0.0873 | MainLoss:0.0594 | Alpha:0.4825 | SPLoss:0.1340 | CLSLoss:0.1457 | AUROC:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 32/16 | Loss:0.1655 | MainLoss:0.1655 | SPLoss:0.1339 | CLSLoss:0.1451 | AUROC:0.9902\n",
      "Test | 128/16 | Loss:1.1778 | MainLoss:1.1778 | SPLoss:0.1339 | CLSLoss:0.1451 | AUROC:0.8689\n",
      "\n",
      "Epoch: [376 | 1000] LR: 0.015252\n",
      "Train | 16/16 | Loss:0.0885 | MainLoss:0.0605 | Alpha:0.4813 | SPLoss:0.1340 | CLSLoss:0.1454 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1648 | MainLoss:0.1648 | SPLoss:0.1343 | CLSLoss:0.1454 | AUROC:0.9899\n",
      "Test | 128/16 | Loss:1.1636 | MainLoss:1.1636 | SPLoss:0.1343 | CLSLoss:0.1454 | AUROC:0.8709\n",
      "\n",
      "Epoch: [377 | 1000] LR: 0.015225\n",
      "Train | 16/16 | Loss:0.0890 | MainLoss:0.0609 | Alpha:0.4806 | SPLoss:0.1346 | CLSLoss:0.1461 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1596 | MainLoss:0.1596 | SPLoss:0.1356 | CLSLoss:0.1457 | AUROC:0.9900\n",
      "Test | 128/16 | Loss:1.1607 | MainLoss:1.1607 | SPLoss:0.1356 | CLSLoss:0.1457 | AUROC:0.8785\n",
      "\n",
      "Epoch: [378 | 1000] LR: 0.015198\n",
      "Train | 16/16 | Loss:0.0818 | MainLoss:0.0537 | Alpha:0.4829 | SPLoss:0.1351 | CLSLoss:0.1464 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1611 | MainLoss:0.1611 | SPLoss:0.1345 | CLSLoss:0.1472 | AUROC:0.9902\n",
      "Test | 128/16 | Loss:1.1791 | MainLoss:1.1791 | SPLoss:0.1345 | CLSLoss:0.1472 | AUROC:0.8766\n",
      "\n",
      "Epoch: [379 | 1000] LR: 0.015171\n",
      "Train | 16/16 | Loss:0.0859 | MainLoss:0.0577 | Alpha:0.4821 | SPLoss:0.1344 | CLSLoss:0.1475 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1689 | MainLoss:0.1689 | SPLoss:0.1357 | CLSLoss:0.1480 | AUROC:0.9896\n",
      "Test | 128/16 | Loss:1.1513 | MainLoss:1.1513 | SPLoss:0.1357 | CLSLoss:0.1480 | AUROC:0.8795\n",
      "\n",
      "Epoch: [380 | 1000] LR: 0.015144\n",
      "Train | 16/16 | Loss:0.0869 | MainLoss:0.0585 | Alpha:0.4818 | SPLoss:0.1359 | CLSLoss:0.1480 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1552 | MainLoss:0.1552 | SPLoss:0.1362 | CLSLoss:0.1478 | AUROC:0.9900\n",
      "Test | 128/16 | Loss:1.2310 | MainLoss:1.2310 | SPLoss:0.1362 | CLSLoss:0.1478 | AUROC:0.8752\n",
      "\n",
      "Epoch: [381 | 1000] LR: 0.015117\n",
      "Train | 16/16 | Loss:0.0879 | MainLoss:0.0595 | Alpha:0.4814 | SPLoss:0.1359 | CLSLoss:0.1476 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1587 | MainLoss:0.1587 | SPLoss:0.1363 | CLSLoss:0.1470 | AUROC:0.9901\n",
      "Test | 128/16 | Loss:1.1777 | MainLoss:1.1777 | SPLoss:0.1363 | CLSLoss:0.1470 | AUROC:0.8803\n",
      "\n",
      "Epoch: [382 | 1000] LR: 0.015090\n",
      "Train | 16/16 | Loss:0.0954 | MainLoss:0.0670 | Alpha:0.4800 | SPLoss:0.1370 | CLSLoss:0.1466 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1715 | MainLoss:0.1715 | SPLoss:0.1370 | CLSLoss:0.1458 | AUROC:0.9902\n",
      "Test | 128/16 | Loss:1.0738 | MainLoss:1.0738 | SPLoss:0.1370 | CLSLoss:0.1458 | AUROC:0.8826\n",
      "\n",
      "Epoch: [383 | 1000] LR: 0.015063\n",
      "Train | 16/16 | Loss:0.0852 | MainLoss:0.0570 | Alpha:0.4811 | SPLoss:0.1365 | CLSLoss:0.1461 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1699 | MainLoss:0.1699 | SPLoss:0.1368 | CLSLoss:0.1469 | AUROC:0.9900\n",
      "Test | 128/16 | Loss:1.0964 | MainLoss:1.0964 | SPLoss:0.1368 | CLSLoss:0.1469 | AUROC:0.8805\n",
      "\n",
      "Epoch: [384 | 1000] LR: 0.015036\n",
      "Train | 16/16 | Loss:0.0952 | MainLoss:0.0669 | Alpha:0.4791 | SPLoss:0.1372 | CLSLoss:0.1464 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1508 | MainLoss:0.1508 | SPLoss:0.1379 | CLSLoss:0.1461 | AUROC:0.9900\n",
      "Test | 128/16 | Loss:1.2047 | MainLoss:1.2047 | SPLoss:0.1379 | CLSLoss:0.1461 | AUROC:0.8767\n",
      "\n",
      "Epoch: [385 | 1000] LR: 0.015009\n",
      "Train | 16/16 | Loss:0.0914 | MainLoss:0.0631 | Alpha:0.4795 | SPLoss:0.1370 | CLSLoss:0.1460 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1716 | MainLoss:0.1716 | SPLoss:0.1377 | CLSLoss:0.1462 | AUROC:0.9904\n",
      "Test | 128/16 | Loss:1.1040 | MainLoss:1.1040 | SPLoss:0.1377 | CLSLoss:0.1462 | AUROC:0.8782\n",
      "\n",
      "Epoch: [386 | 1000] LR: 0.014982\n",
      "Train | 16/16 | Loss:0.1033 | MainLoss:0.0750 | Alpha:0.4797 | SPLoss:0.1371 | CLSLoss:0.1457 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1657 | MainLoss:0.1657 | SPLoss:0.1376 | CLSLoss:0.1435 | AUROC:0.9901\n",
      "Test | 128/16 | Loss:1.0940 | MainLoss:1.0940 | SPLoss:0.1376 | CLSLoss:0.1435 | AUROC:0.8787\n",
      "\n",
      "Epoch: [387 | 1000] LR: 0.014955\n",
      "Train | 16/16 | Loss:0.0978 | MainLoss:0.0696 | Alpha:0.4789 | SPLoss:0.1384 | CLSLoss:0.1429 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1518 | MainLoss:0.1518 | SPLoss:0.1384 | CLSLoss:0.1434 | AUROC:0.9900\n",
      "Test | 128/16 | Loss:1.1507 | MainLoss:1.1507 | SPLoss:0.1384 | CLSLoss:0.1434 | AUROC:0.8787\n",
      "\n",
      "Epoch: [388 | 1000] LR: 0.014927\n",
      "Train | 16/16 | Loss:0.0972 | MainLoss:0.0690 | Alpha:0.4791 | SPLoss:0.1386 | CLSLoss:0.1434 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1573 | MainLoss:0.1573 | SPLoss:0.1384 | CLSLoss:0.1435 | AUROC:0.9900\n",
      "Test | 128/16 | Loss:1.1197 | MainLoss:1.1197 | SPLoss:0.1384 | CLSLoss:0.1435 | AUROC:0.8859\n",
      "\n",
      "Epoch: [389 | 1000] LR: 0.014900\n",
      "Train | 16/16 | Loss:0.0894 | MainLoss:0.0612 | Alpha:0.4804 | SPLoss:0.1385 | CLSLoss:0.1442 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1608 | MainLoss:0.1608 | SPLoss:0.1387 | CLSLoss:0.1452 | AUROC:0.9902\n",
      "Test | 128/16 | Loss:1.1132 | MainLoss:1.1132 | SPLoss:0.1387 | CLSLoss:0.1452 | AUROC:0.8850\n",
      "\n",
      "Epoch: [390 | 1000] LR: 0.014873\n",
      "Train | 16/16 | Loss:0.0950 | MainLoss:0.0665 | Alpha:0.4796 | SPLoss:0.1397 | CLSLoss:0.1449 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1605 | MainLoss:0.1605 | SPLoss:0.1406 | CLSLoss:0.1456 | AUROC:0.9899\n",
      "Test | 128/16 | Loss:1.1325 | MainLoss:1.1325 | SPLoss:0.1406 | CLSLoss:0.1456 | AUROC:0.8783\n",
      "\n",
      "Epoch: [391 | 1000] LR: 0.014845\n",
      "Train | 16/16 | Loss:0.0960 | MainLoss:0.0674 | Alpha:0.4804 | SPLoss:0.1404 | CLSLoss:0.1451 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1493 | MainLoss:0.1493 | SPLoss:0.1400 | CLSLoss:0.1457 | AUROC:0.9900\n",
      "Test | 128/16 | Loss:1.1989 | MainLoss:1.1989 | SPLoss:0.1400 | CLSLoss:0.1457 | AUROC:0.8756\n",
      "\n",
      "Epoch: [392 | 1000] LR: 0.014818\n",
      "Train | 16/16 | Loss:0.0760 | MainLoss:0.0473 | Alpha:0.4837 | SPLoss:0.1404 | CLSLoss:0.1474 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1613 | MainLoss:0.1613 | SPLoss:0.1406 | CLSLoss:0.1490 | AUROC:0.9900\n",
      "Test | 128/16 | Loss:1.1851 | MainLoss:1.1851 | SPLoss:0.1406 | CLSLoss:0.1490 | AUROC:0.8768\n",
      "\n",
      "Epoch: [393 | 1000] LR: 0.014790\n",
      "Train | 16/16 | Loss:0.0914 | MainLoss:0.0625 | Alpha:0.4806 | SPLoss:0.1406 | CLSLoss:0.1487 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1656 | MainLoss:0.1656 | SPLoss:0.1403 | CLSLoss:0.1488 | AUROC:0.9901\n",
      "Test | 128/16 | Loss:1.1579 | MainLoss:1.1579 | SPLoss:0.1403 | CLSLoss:0.1488 | AUROC:0.8808\n",
      "\n",
      "Epoch: [394 | 1000] LR: 0.014762\n",
      "Train | 16/16 | Loss:0.1035 | MainLoss:0.0746 | Alpha:0.4776 | SPLoss:0.1411 | CLSLoss:0.1472 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1656 | MainLoss:0.1656 | SPLoss:0.1425 | CLSLoss:0.1467 | AUROC:0.9900\n",
      "Test | 128/16 | Loss:1.1034 | MainLoss:1.1034 | SPLoss:0.1425 | CLSLoss:0.1467 | AUROC:0.8860\n",
      "\n",
      "Epoch: [395 | 1000] LR: 0.014735\n",
      "Train | 16/16 | Loss:0.0967 | MainLoss:0.0678 | Alpha:0.4786 | SPLoss:0.1424 | CLSLoss:0.1471 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1613 | MainLoss:0.1613 | SPLoss:0.1427 | CLSLoss:0.1465 | AUROC:0.9901\n",
      "Test | 128/16 | Loss:1.1316 | MainLoss:1.1316 | SPLoss:0.1427 | CLSLoss:0.1465 | AUROC:0.8837\n",
      "\n",
      "Epoch: [396 | 1000] LR: 0.014707\n",
      "Train | 16/16 | Loss:0.1014 | MainLoss:0.0726 | Alpha:0.4785 | SPLoss:0.1421 | CLSLoss:0.1456 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1530 | MainLoss:0.1530 | SPLoss:0.1418 | CLSLoss:0.1448 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1527 | MainLoss:1.1527 | SPLoss:0.1418 | CLSLoss:0.1448 | AUROC:0.8786\n",
      "\n",
      "Epoch: [397 | 1000] LR: 0.014679\n",
      "Train | 16/16 | Loss:0.0890 | MainLoss:0.0603 | Alpha:0.4823 | SPLoss:0.1414 | CLSLoss:0.1456 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1655 | MainLoss:0.1655 | SPLoss:0.1407 | CLSLoss:0.1459 | AUROC:0.9902\n",
      "Test | 128/16 | Loss:1.1149 | MainLoss:1.1149 | SPLoss:0.1407 | CLSLoss:0.1459 | AUROC:0.8786\n",
      "\n",
      "Epoch: [398 | 1000] LR: 0.014652\n",
      "Train | 16/16 | Loss:0.0975 | MainLoss:0.0689 | Alpha:0.4799 | SPLoss:0.1404 | CLSLoss:0.1460 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1544 | MainLoss:0.1544 | SPLoss:0.1404 | CLSLoss:0.1454 | AUROC:0.9899\n",
      "Test | 128/16 | Loss:1.1684 | MainLoss:1.1684 | SPLoss:0.1404 | CLSLoss:0.1454 | AUROC:0.8767\n",
      "\n",
      "Epoch: [399 | 1000] LR: 0.014624\n",
      "Train | 16/16 | Loss:0.0858 | MainLoss:0.0571 | Alpha:0.4825 | SPLoss:0.1404 | CLSLoss:0.1465 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1665 | MainLoss:0.1665 | SPLoss:0.1399 | CLSLoss:0.1465 | AUROC:0.9899\n",
      "Test | 128/16 | Loss:1.1156 | MainLoss:1.1156 | SPLoss:0.1399 | CLSLoss:0.1465 | AUROC:0.8800\n",
      "\n",
      "Epoch: [400 | 1000] LR: 0.014596\n",
      "Train | 16/16 | Loss:0.0861 | MainLoss:0.0575 | Alpha:0.4822 | SPLoss:0.1390 | CLSLoss:0.1470 | AUROC:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 32/16 | Loss:0.1589 | MainLoss:0.1589 | SPLoss:0.1387 | CLSLoss:0.1475 | AUROC:0.9901\n",
      "Test | 128/16 | Loss:1.2071 | MainLoss:1.2071 | SPLoss:0.1387 | CLSLoss:0.1475 | AUROC:0.8744\n",
      "\n",
      "Epoch: [401 | 1000] LR: 0.001457\n",
      "Train | 16/16 | Loss:0.0757 | MainLoss:0.0610 | Alpha:0.4861 | SPLoss:0.0000 | CLSLoss:0.1474 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1591 | MainLoss:0.1591 | SPLoss:0.0000 | CLSLoss:0.1474 | AUROC:0.9900\n",
      "Test | 128/16 | Loss:1.2035 | MainLoss:1.2035 | SPLoss:0.0000 | CLSLoss:0.1474 | AUROC:0.8752\n",
      "\n",
      "Epoch: [402 | 1000] LR: 0.001454\n",
      "Train | 16/16 | Loss:0.0705 | MainLoss:0.0557 | Alpha:0.4875 | SPLoss:0.0001 | CLSLoss:0.1475 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1595 | MainLoss:0.1595 | SPLoss:0.0001 | CLSLoss:0.1475 | AUROC:0.9903\n",
      "Test | 128/16 | Loss:1.2026 | MainLoss:1.2026 | SPLoss:0.0001 | CLSLoss:0.1475 | AUROC:0.8755\n",
      "\n",
      "Epoch: [403 | 1000] LR: 0.001451\n",
      "Train | 16/16 | Loss:0.0886 | MainLoss:0.0738 | Alpha:0.4835 | SPLoss:0.0001 | CLSLoss:0.1473 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1607 | MainLoss:0.1607 | SPLoss:0.0001 | CLSLoss:0.1471 | AUROC:0.9902\n",
      "Test | 128/16 | Loss:1.1897 | MainLoss:1.1897 | SPLoss:0.0001 | CLSLoss:0.1471 | AUROC:0.8762\n",
      "\n",
      "Epoch: [404 | 1000] LR: 0.001448\n",
      "Train | 16/16 | Loss:0.0805 | MainLoss:0.0658 | Alpha:0.4847 | SPLoss:0.0001 | CLSLoss:0.1471 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1628 | MainLoss:0.1628 | SPLoss:0.0002 | CLSLoss:0.1469 | AUROC:0.9903\n",
      "Test | 128/16 | Loss:1.1769 | MainLoss:1.1769 | SPLoss:0.0002 | CLSLoss:0.1469 | AUROC:0.8764\n",
      "\n",
      "Epoch: [405 | 1000] LR: 0.001446\n",
      "Train | 16/16 | Loss:0.0818 | MainLoss:0.0671 | Alpha:0.4842 | SPLoss:0.0002 | CLSLoss:0.1469 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1640 | MainLoss:0.1640 | SPLoss:0.0002 | CLSLoss:0.1467 | AUROC:0.9903\n",
      "Test | 128/16 | Loss:1.1625 | MainLoss:1.1625 | SPLoss:0.0002 | CLSLoss:0.1467 | AUROC:0.8777\n",
      "\n",
      "Epoch: [406 | 1000] LR: 0.001443\n",
      "Train | 16/16 | Loss:0.0758 | MainLoss:0.0611 | Alpha:0.4863 | SPLoss:0.0003 | CLSLoss:0.1467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1605 | MainLoss:0.1605 | SPLoss:0.0003 | CLSLoss:0.1467 | AUROC:0.9903\n",
      "Test | 128/16 | Loss:1.1793 | MainLoss:1.1793 | SPLoss:0.0003 | CLSLoss:0.1467 | AUROC:0.8769\n",
      "\n",
      "Epoch: [407 | 1000] LR: 0.001440\n",
      "Train | 16/16 | Loss:0.0714 | MainLoss:0.0567 | Alpha:0.4870 | SPLoss:0.0003 | CLSLoss:0.1467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1603 | MainLoss:0.1603 | SPLoss:0.0003 | CLSLoss:0.1467 | AUROC:0.9902\n",
      "Test | 128/16 | Loss:1.1819 | MainLoss:1.1819 | SPLoss:0.0003 | CLSLoss:0.1467 | AUROC:0.8772\n",
      "\n",
      "Epoch: [408 | 1000] LR: 0.001437\n",
      "Train | 16/16 | Loss:0.0847 | MainLoss:0.0700 | Alpha:0.4842 | SPLoss:0.0003 | CLSLoss:0.1466 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1604 | MainLoss:0.1604 | SPLoss:0.0004 | CLSLoss:0.1465 | AUROC:0.9901\n",
      "Test | 128/16 | Loss:1.1718 | MainLoss:1.1718 | SPLoss:0.0004 | CLSLoss:0.1465 | AUROC:0.8783\n",
      "\n",
      "Epoch: [409 | 1000] LR: 0.001434\n",
      "Train | 16/16 | Loss:0.0745 | MainLoss:0.0598 | Alpha:0.4864 | SPLoss:0.0004 | CLSLoss:0.1465 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1615 | MainLoss:0.1615 | SPLoss:0.0004 | CLSLoss:0.1464 | AUROC:0.9903\n",
      "Test | 128/16 | Loss:1.1628 | MainLoss:1.1628 | SPLoss:0.0004 | CLSLoss:0.1464 | AUROC:0.8797\n",
      "\n",
      "Epoch: [410 | 1000] LR: 0.001431\n",
      "Train | 16/16 | Loss:0.0855 | MainLoss:0.0708 | Alpha:0.4837 | SPLoss:0.0005 | CLSLoss:0.1464 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1553 | MainLoss:0.1553 | SPLoss:0.0005 | CLSLoss:0.1462 | AUROC:0.9903\n",
      "Test | 128/16 | Loss:1.1896 | MainLoss:1.1896 | SPLoss:0.0005 | CLSLoss:0.1462 | AUROC:0.8791\n",
      "\n",
      "Epoch: [411 | 1000] LR: 0.001429\n",
      "Train | 16/16 | Loss:0.0912 | MainLoss:0.0765 | Alpha:0.4831 | SPLoss:0.0005 | CLSLoss:0.1461 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1564 | MainLoss:0.1564 | SPLoss:0.0005 | CLSLoss:0.1459 | AUROC:0.9902\n",
      "Test | 128/16 | Loss:1.1795 | MainLoss:1.1795 | SPLoss:0.0005 | CLSLoss:0.1459 | AUROC:0.8793\n",
      "\n",
      "Epoch: [412 | 1000] LR: 0.001426\n",
      "Train | 16/16 | Loss:0.0785 | MainLoss:0.0639 | Alpha:0.4865 | SPLoss:0.0006 | CLSLoss:0.1459 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1575 | MainLoss:0.1575 | SPLoss:0.0006 | CLSLoss:0.1458 | AUROC:0.9900\n",
      "Test | 128/16 | Loss:1.1743 | MainLoss:1.1743 | SPLoss:0.0006 | CLSLoss:0.1458 | AUROC:0.8792\n",
      "\n",
      "Epoch: [413 | 1000] LR: 0.001423\n",
      "Train | 16/16 | Loss:0.0750 | MainLoss:0.0604 | Alpha:0.4864 | SPLoss:0.0006 | CLSLoss:0.1459 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1604 | MainLoss:0.1604 | SPLoss:0.0006 | CLSLoss:0.1459 | AUROC:0.9903\n",
      "Test | 128/16 | Loss:1.1618 | MainLoss:1.1618 | SPLoss:0.0006 | CLSLoss:0.1459 | AUROC:0.8795\n",
      "\n",
      "Epoch: [414 | 1000] LR: 0.001420\n",
      "Train | 16/16 | Loss:0.0881 | MainLoss:0.0734 | Alpha:0.4832 | SPLoss:0.0007 | CLSLoss:0.1458 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1588 | MainLoss:0.1588 | SPLoss:0.0007 | CLSLoss:0.1456 | AUROC:0.9903\n",
      "Test | 128/16 | Loss:1.1680 | MainLoss:1.1680 | SPLoss:0.0007 | CLSLoss:0.1456 | AUROC:0.8795\n",
      "\n",
      "Epoch: [415 | 1000] LR: 0.001417\n",
      "Train | 16/16 | Loss:0.0845 | MainLoss:0.0698 | Alpha:0.4836 | SPLoss:0.0007 | CLSLoss:0.1456 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0008 | CLSLoss:0.1454 | AUROC:0.9901\n",
      "Test | 128/16 | Loss:1.1715 | MainLoss:1.1715 | SPLoss:0.0008 | CLSLoss:0.1454 | AUROC:0.8781\n",
      "\n",
      "Epoch: [416 | 1000] LR: 0.001414\n",
      "Train | 16/16 | Loss:0.0983 | MainLoss:0.0837 | Alpha:0.4812 | SPLoss:0.0008 | CLSLoss:0.1452 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1584 | MainLoss:0.1584 | SPLoss:0.0008 | CLSLoss:0.1450 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1642 | MainLoss:1.1642 | SPLoss:0.0008 | CLSLoss:0.1450 | AUROC:0.8788\n",
      "\n",
      "Epoch: [417 | 1000] LR: 0.001412\n",
      "Train | 16/16 | Loss:0.0881 | MainLoss:0.0735 | Alpha:0.4830 | SPLoss:0.0009 | CLSLoss:0.1450 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1566 | MainLoss:0.1566 | SPLoss:0.0009 | CLSLoss:0.1448 | AUROC:0.9901\n",
      "Test | 128/16 | Loss:1.1678 | MainLoss:1.1678 | SPLoss:0.0009 | CLSLoss:0.1448 | AUROC:0.8788\n",
      "\n",
      "Epoch: [418 | 1000] LR: 0.001409\n",
      "Train | 16/16 | Loss:0.0833 | MainLoss:0.0687 | Alpha:0.4840 | SPLoss:0.0009 | CLSLoss:0.1447 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1560 | MainLoss:0.1560 | SPLoss:0.0010 | CLSLoss:0.1446 | AUROC:0.9903\n",
      "Test | 128/16 | Loss:1.1663 | MainLoss:1.1663 | SPLoss:0.0010 | CLSLoss:0.1446 | AUROC:0.8793\n",
      "\n",
      "Epoch: [419 | 1000] LR: 0.001406\n",
      "Train | 16/16 | Loss:0.0729 | MainLoss:0.0584 | Alpha:0.4870 | SPLoss:0.0010 | CLSLoss:0.1447 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1564 | MainLoss:0.1564 | SPLoss:0.0010 | CLSLoss:0.1448 | AUROC:0.9904\n",
      "Test | 128/16 | Loss:1.1679 | MainLoss:1.1679 | SPLoss:0.0010 | CLSLoss:0.1448 | AUROC:0.8791\n",
      "\n",
      "Epoch: [420 | 1000] LR: 0.001403\n",
      "Train | 16/16 | Loss:0.0786 | MainLoss:0.0640 | Alpha:0.4850 | SPLoss:0.0011 | CLSLoss:0.1447 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1575 | MainLoss:0.1575 | SPLoss:0.0011 | CLSLoss:0.1448 | AUROC:0.9901\n",
      "Test | 128/16 | Loss:1.1628 | MainLoss:1.1628 | SPLoss:0.0011 | CLSLoss:0.1448 | AUROC:0.8786\n",
      "\n",
      "Epoch: [421 | 1000] LR: 0.001400\n",
      "Train | 16/16 | Loss:0.0718 | MainLoss:0.0572 | Alpha:0.4874 | SPLoss:0.0011 | CLSLoss:0.1448 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1579 | MainLoss:0.1579 | SPLoss:0.0011 | CLSLoss:0.1448 | AUROC:0.9904\n",
      "Test | 128/16 | Loss:1.1623 | MainLoss:1.1623 | SPLoss:0.0011 | CLSLoss:0.1448 | AUROC:0.8790\n",
      "\n",
      "Epoch: [422 | 1000] LR: 0.001397\n",
      "Train | 16/16 | Loss:0.0631 | MainLoss:0.0485 | Alpha:0.4897 | SPLoss:0.0012 | CLSLoss:0.1450 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1580 | MainLoss:0.1580 | SPLoss:0.0012 | CLSLoss:0.1451 | AUROC:0.9902\n",
      "Test | 128/16 | Loss:1.1687 | MainLoss:1.1687 | SPLoss:0.0012 | CLSLoss:0.1451 | AUROC:0.8789\n",
      "\n",
      "Epoch: [423 | 1000] LR: 0.001394\n",
      "Train | 16/16 | Loss:0.0877 | MainLoss:0.0730 | Alpha:0.4824 | SPLoss:0.0012 | CLSLoss:0.1449 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1582 | MainLoss:0.1582 | SPLoss:0.0013 | CLSLoss:0.1448 | AUROC:0.9903\n",
      "Test | 128/16 | Loss:1.1575 | MainLoss:1.1575 | SPLoss:0.0013 | CLSLoss:0.1448 | AUROC:0.8800\n",
      "\n",
      "Epoch: [424 | 1000] LR: 0.001391\n",
      "Train | 16/16 | Loss:0.0740 | MainLoss:0.0594 | Alpha:0.4858 | SPLoss:0.0013 | CLSLoss:0.1448 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1575 | MainLoss:0.1575 | SPLoss:0.0013 | CLSLoss:0.1449 | AUROC:0.9903\n",
      "Test | 128/16 | Loss:1.1631 | MainLoss:1.1631 | SPLoss:0.0013 | CLSLoss:0.1449 | AUROC:0.8798\n",
      "\n",
      "Epoch: [425 | 1000] LR: 0.001388\n",
      "Train | 16/16 | Loss:0.0734 | MainLoss:0.0587 | Alpha:0.4875 | SPLoss:0.0013 | CLSLoss:0.1448 | AUROC:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 32/16 | Loss:0.1584 | MainLoss:0.1584 | SPLoss:0.0014 | CLSLoss:0.1449 | AUROC:0.9902\n",
      "Test | 128/16 | Loss:1.1613 | MainLoss:1.1613 | SPLoss:0.0014 | CLSLoss:0.1449 | AUROC:0.8802\n",
      "\n",
      "Epoch: [426 | 1000] LR: 0.001386\n",
      "Train | 16/16 | Loss:0.0724 | MainLoss:0.0577 | Alpha:0.4878 | SPLoss:0.0014 | CLSLoss:0.1450 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1571 | MainLoss:0.1571 | SPLoss:0.0014 | CLSLoss:0.1450 | AUROC:0.9901\n",
      "Test | 128/16 | Loss:1.1706 | MainLoss:1.1706 | SPLoss:0.0014 | CLSLoss:0.1450 | AUROC:0.8799\n",
      "\n",
      "Epoch: [427 | 1000] LR: 0.001383\n",
      "Train | 16/16 | Loss:0.0634 | MainLoss:0.0487 | Alpha:0.4890 | SPLoss:0.0015 | CLSLoss:0.1452 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1586 | MainLoss:0.1586 | SPLoss:0.0015 | CLSLoss:0.1454 | AUROC:0.9903\n",
      "Test | 128/16 | Loss:1.1671 | MainLoss:1.1671 | SPLoss:0.0015 | CLSLoss:0.1454 | AUROC:0.8801\n",
      "\n",
      "Epoch: [428 | 1000] LR: 0.001380\n",
      "Train | 16/16 | Loss:0.0862 | MainLoss:0.0715 | Alpha:0.4842 | SPLoss:0.0015 | CLSLoss:0.1453 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1583 | MainLoss:0.1583 | SPLoss:0.0016 | CLSLoss:0.1452 | AUROC:0.9903\n",
      "Test | 128/16 | Loss:1.1671 | MainLoss:1.1671 | SPLoss:0.0016 | CLSLoss:0.1452 | AUROC:0.8805\n",
      "\n",
      "Epoch: [429 | 1000] LR: 0.001377\n",
      "Train | 16/16 | Loss:0.0722 | MainLoss:0.0575 | Alpha:0.4864 | SPLoss:0.0016 | CLSLoss:0.1452 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1589 | MainLoss:0.1589 | SPLoss:0.0016 | CLSLoss:0.1452 | AUROC:0.9902\n",
      "Test | 128/16 | Loss:1.1644 | MainLoss:1.1644 | SPLoss:0.0016 | CLSLoss:0.1452 | AUROC:0.8800\n",
      "\n",
      "Epoch: [430 | 1000] LR: 0.001374\n",
      "Train | 16/16 | Loss:0.0749 | MainLoss:0.0602 | Alpha:0.4864 | SPLoss:0.0017 | CLSLoss:0.1453 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1599 | MainLoss:0.1599 | SPLoss:0.0017 | CLSLoss:0.1453 | AUROC:0.9900\n",
      "Test | 128/16 | Loss:1.1602 | MainLoss:1.1602 | SPLoss:0.0017 | CLSLoss:0.1453 | AUROC:0.8802\n",
      "\n",
      "Epoch: [431 | 1000] LR: 0.001371\n",
      "Train | 16/16 | Loss:0.0685 | MainLoss:0.0538 | Alpha:0.4886 | SPLoss:0.0017 | CLSLoss:0.1453 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1599 | MainLoss:0.1599 | SPLoss:0.0018 | CLSLoss:0.1454 | AUROC:0.9901\n",
      "Test | 128/16 | Loss:1.1666 | MainLoss:1.1666 | SPLoss:0.0018 | CLSLoss:0.1454 | AUROC:0.8796\n",
      "\n",
      "Epoch: [432 | 1000] LR: 0.001368\n",
      "Train | 16/16 | Loss:0.0731 | MainLoss:0.0584 | Alpha:0.4865 | SPLoss:0.0018 | CLSLoss:0.1454 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1610 | MainLoss:0.1610 | SPLoss:0.0019 | CLSLoss:0.1454 | AUROC:0.9904\n",
      "Test | 128/16 | Loss:1.1646 | MainLoss:1.1646 | SPLoss:0.0019 | CLSLoss:0.1454 | AUROC:0.8787\n",
      "\n",
      "Epoch: [433 | 1000] LR: 0.001365\n",
      "Train | 16/16 | Loss:0.0700 | MainLoss:0.0553 | Alpha:0.4876 | SPLoss:0.0019 | CLSLoss:0.1454 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1620 | MainLoss:0.1620 | SPLoss:0.0019 | CLSLoss:0.1455 | AUROC:0.9904\n",
      "Test | 128/16 | Loss:1.1601 | MainLoss:1.1601 | SPLoss:0.0019 | CLSLoss:0.1455 | AUROC:0.8799\n",
      "\n",
      "Epoch: [434 | 1000] LR: 0.001362\n",
      "Train | 16/16 | Loss:0.0789 | MainLoss:0.0642 | Alpha:0.4854 | SPLoss:0.0020 | CLSLoss:0.1454 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1589 | MainLoss:0.1589 | SPLoss:0.0020 | CLSLoss:0.1454 | AUROC:0.9903\n",
      "Test | 128/16 | Loss:1.1771 | MainLoss:1.1771 | SPLoss:0.0020 | CLSLoss:0.1454 | AUROC:0.8782\n",
      "\n",
      "Epoch: [435 | 1000] LR: 0.001359\n",
      "Train | 16/16 | Loss:0.0731 | MainLoss:0.0584 | Alpha:0.4864 | SPLoss:0.0020 | CLSLoss:0.1453 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1592 | MainLoss:0.1592 | SPLoss:0.0021 | CLSLoss:0.1454 | AUROC:0.9903\n",
      "Test | 128/16 | Loss:1.1754 | MainLoss:1.1754 | SPLoss:0.0021 | CLSLoss:0.1454 | AUROC:0.8783\n",
      "\n",
      "Epoch: [436 | 1000] LR: 0.001356\n",
      "Train | 16/16 | Loss:0.0620 | MainLoss:0.0473 | Alpha:0.4890 | SPLoss:0.0021 | CLSLoss:0.1455 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1591 | MainLoss:0.1591 | SPLoss:0.0022 | CLSLoss:0.1456 | AUROC:0.9904\n",
      "Test | 128/16 | Loss:1.1794 | MainLoss:1.1794 | SPLoss:0.0022 | CLSLoss:0.1456 | AUROC:0.8785\n",
      "\n",
      "Epoch: [437 | 1000] LR: 0.001353\n",
      "Train | 16/16 | Loss:0.0699 | MainLoss:0.0551 | Alpha:0.4876 | SPLoss:0.0022 | CLSLoss:0.1457 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1592 | MainLoss:0.1592 | SPLoss:0.0022 | CLSLoss:0.1457 | AUROC:0.9904\n",
      "Test | 128/16 | Loss:1.1831 | MainLoss:1.1831 | SPLoss:0.0022 | CLSLoss:0.1457 | AUROC:0.8780\n",
      "\n",
      "Epoch: [438 | 1000] LR: 0.001351\n",
      "Train | 16/16 | Loss:0.0882 | MainLoss:0.0735 | Alpha:0.4827 | SPLoss:0.0023 | CLSLoss:0.1456 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1604 | MainLoss:0.1604 | SPLoss:0.0024 | CLSLoss:0.1454 | AUROC:0.9902\n",
      "Test | 128/16 | Loss:1.1735 | MainLoss:1.1735 | SPLoss:0.0024 | CLSLoss:0.1454 | AUROC:0.8781\n",
      "\n",
      "Epoch: [439 | 1000] LR: 0.001348\n",
      "Train | 16/16 | Loss:0.0809 | MainLoss:0.0661 | Alpha:0.4855 | SPLoss:0.0024 | CLSLoss:0.1454 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1594 | MainLoss:0.1594 | SPLoss:0.0024 | CLSLoss:0.1453 | AUROC:0.9901\n",
      "Test | 128/16 | Loss:1.1785 | MainLoss:1.1785 | SPLoss:0.0024 | CLSLoss:0.1453 | AUROC:0.8779\n",
      "\n",
      "Epoch: [440 | 1000] LR: 0.001345\n",
      "Train | 16/16 | Loss:0.0750 | MainLoss:0.0602 | Alpha:0.4851 | SPLoss:0.0025 | CLSLoss:0.1453 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1625 | MainLoss:0.1625 | SPLoss:0.0025 | CLSLoss:0.1453 | AUROC:0.9899\n",
      "Test | 128/16 | Loss:1.1618 | MainLoss:1.1618 | SPLoss:0.0025 | CLSLoss:0.1453 | AUROC:0.8793\n",
      "\n",
      "Epoch: [441 | 1000] LR: 0.001342\n",
      "Train | 16/16 | Loss:0.0771 | MainLoss:0.0623 | Alpha:0.4852 | SPLoss:0.0026 | CLSLoss:0.1452 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1633 | MainLoss:0.1633 | SPLoss:0.0026 | CLSLoss:0.1452 | AUROC:0.9902\n",
      "Test | 128/16 | Loss:1.1574 | MainLoss:1.1574 | SPLoss:0.0026 | CLSLoss:0.1452 | AUROC:0.8796\n",
      "\n",
      "Epoch: [442 | 1000] LR: 0.001339\n",
      "Train | 16/16 | Loss:0.0740 | MainLoss:0.0593 | Alpha:0.4859 | SPLoss:0.0026 | CLSLoss:0.1452 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1610 | MainLoss:0.1610 | SPLoss:0.0026 | CLSLoss:0.1452 | AUROC:0.9902\n",
      "Test | 128/16 | Loss:1.1712 | MainLoss:1.1712 | SPLoss:0.0026 | CLSLoss:0.1452 | AUROC:0.8785\n",
      "\n",
      "Epoch: [443 | 1000] LR: 0.001336\n",
      "Train | 16/16 | Loss:0.0829 | MainLoss:0.0681 | Alpha:0.4849 | SPLoss:0.0027 | CLSLoss:0.1451 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1607 | MainLoss:0.1607 | SPLoss:0.0027 | CLSLoss:0.1450 | AUROC:0.9902\n",
      "Test | 128/16 | Loss:1.1692 | MainLoss:1.1692 | SPLoss:0.0027 | CLSLoss:0.1450 | AUROC:0.8787\n",
      "\n",
      "Epoch: [444 | 1000] LR: 0.001333\n",
      "Train | 16/16 | Loss:0.0753 | MainLoss:0.0605 | Alpha:0.4857 | SPLoss:0.0028 | CLSLoss:0.1450 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1598 | MainLoss:0.1598 | SPLoss:0.0028 | CLSLoss:0.1450 | AUROC:0.9901\n",
      "Test | 128/16 | Loss:1.1751 | MainLoss:1.1751 | SPLoss:0.0028 | CLSLoss:0.1450 | AUROC:0.8784\n",
      "\n",
      "Epoch: [445 | 1000] LR: 0.001330\n",
      "Train | 16/16 | Loss:0.0660 | MainLoss:0.0512 | Alpha:0.4888 | SPLoss:0.0028 | CLSLoss:0.1451 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1593 | MainLoss:0.1593 | SPLoss:0.0029 | CLSLoss:0.1452 | AUROC:0.9901\n",
      "Test | 128/16 | Loss:1.1811 | MainLoss:1.1811 | SPLoss:0.0029 | CLSLoss:0.1452 | AUROC:0.8784\n",
      "\n",
      "Epoch: [446 | 1000] LR: 0.001327\n",
      "Train | 16/16 | Loss:0.0727 | MainLoss:0.0579 | Alpha:0.4862 | SPLoss:0.0029 | CLSLoss:0.1451 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1599 | MainLoss:0.1599 | SPLoss:0.0030 | CLSLoss:0.1452 | AUROC:0.9900\n",
      "Test | 128/16 | Loss:1.1773 | MainLoss:1.1773 | SPLoss:0.0030 | CLSLoss:0.1452 | AUROC:0.8793\n",
      "\n",
      "Epoch: [447 | 1000] LR: 0.001324\n",
      "Train | 16/16 | Loss:0.0637 | MainLoss:0.0488 | Alpha:0.4884 | SPLoss:0.0030 | CLSLoss:0.1452 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1593 | MainLoss:0.1593 | SPLoss:0.0030 | CLSLoss:0.1454 | AUROC:0.9901\n",
      "Test | 128/16 | Loss:1.1834 | MainLoss:1.1834 | SPLoss:0.0030 | CLSLoss:0.1454 | AUROC:0.8790\n",
      "\n",
      "Epoch: [448 | 1000] LR: 0.001321\n",
      "Train | 16/16 | Loss:0.0761 | MainLoss:0.0613 | Alpha:0.4861 | SPLoss:0.0031 | CLSLoss:0.1453 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1581 | MainLoss:0.1581 | SPLoss:0.0031 | CLSLoss:0.1454 | AUROC:0.9901\n",
      "Test | 128/16 | Loss:1.1879 | MainLoss:1.1879 | SPLoss:0.0031 | CLSLoss:0.1454 | AUROC:0.8794\n",
      "\n",
      "Epoch: [449 | 1000] LR: 0.001318\n",
      "Train | 16/16 | Loss:0.0678 | MainLoss:0.0530 | Alpha:0.4882 | SPLoss:0.0031 | CLSLoss:0.1454 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1578 | MainLoss:0.1578 | SPLoss:0.0032 | CLSLoss:0.1454 | AUROC:0.9901\n",
      "Test | 128/16 | Loss:1.1923 | MainLoss:1.1923 | SPLoss:0.0032 | CLSLoss:0.1454 | AUROC:0.8791\n",
      "\n",
      "Epoch: [450 | 1000] LR: 0.001315\n",
      "Train | 16/16 | Loss:0.0754 | MainLoss:0.0606 | Alpha:0.4860 | SPLoss:0.0032 | CLSLoss:0.1454 | AUROC:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 32/16 | Loss:0.1590 | MainLoss:0.1590 | SPLoss:0.0032 | CLSLoss:0.1454 | AUROC:0.9901\n",
      "Test | 128/16 | Loss:1.1825 | MainLoss:1.1825 | SPLoss:0.0032 | CLSLoss:0.1454 | AUROC:0.8799\n",
      "\n",
      "Epoch: [451 | 1000] LR: 0.001312\n",
      "Train | 16/16 | Loss:0.0757 | MainLoss:0.0608 | Alpha:0.4859 | SPLoss:0.0033 | CLSLoss:0.1453 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1596 | MainLoss:0.1596 | SPLoss:0.0033 | CLSLoss:0.1453 | AUROC:0.9902\n",
      "Test | 128/16 | Loss:1.1773 | MainLoss:1.1773 | SPLoss:0.0033 | CLSLoss:0.1453 | AUROC:0.8807\n",
      "\n",
      "Epoch: [452 | 1000] LR: 0.001309\n",
      "Train | 16/16 | Loss:0.0704 | MainLoss:0.0556 | Alpha:0.4873 | SPLoss:0.0034 | CLSLoss:0.1453 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1617 | MainLoss:0.1617 | SPLoss:0.0034 | CLSLoss:0.1453 | AUROC:0.9903\n",
      "Test | 128/16 | Loss:1.1669 | MainLoss:1.1669 | SPLoss:0.0034 | CLSLoss:0.1453 | AUROC:0.8813\n",
      "\n",
      "Epoch: [453 | 1000] LR: 0.001306\n",
      "Train | 16/16 | Loss:0.0774 | MainLoss:0.0626 | Alpha:0.4841 | SPLoss:0.0035 | CLSLoss:0.1453 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1605 | MainLoss:0.1605 | SPLoss:0.0035 | CLSLoss:0.1453 | AUROC:0.9900\n",
      "Test | 128/16 | Loss:1.1688 | MainLoss:1.1688 | SPLoss:0.0035 | CLSLoss:0.1453 | AUROC:0.8813\n",
      "\n",
      "Epoch: [454 | 1000] LR: 0.001303\n",
      "Train | 16/16 | Loss:0.0708 | MainLoss:0.0559 | Alpha:0.4875 | SPLoss:0.0036 | CLSLoss:0.1453 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1581 | MainLoss:0.1581 | SPLoss:0.0036 | CLSLoss:0.1453 | AUROC:0.9900\n",
      "Test | 128/16 | Loss:1.1839 | MainLoss:1.1839 | SPLoss:0.0036 | CLSLoss:0.1453 | AUROC:0.8808\n",
      "\n",
      "Epoch: [455 | 1000] LR: 0.001300\n",
      "Train | 16/16 | Loss:0.0770 | MainLoss:0.0621 | Alpha:0.4860 | SPLoss:0.0037 | CLSLoss:0.1453 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1570 | MainLoss:0.1570 | SPLoss:0.0037 | CLSLoss:0.1452 | AUROC:0.9902\n",
      "Test | 128/16 | Loss:1.1880 | MainLoss:1.1880 | SPLoss:0.0037 | CLSLoss:0.1452 | AUROC:0.8809\n",
      "\n",
      "Epoch: [456 | 1000] LR: 0.001297\n",
      "Train | 16/16 | Loss:0.0653 | MainLoss:0.0504 | Alpha:0.4889 | SPLoss:0.0037 | CLSLoss:0.1454 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1583 | MainLoss:0.1583 | SPLoss:0.0038 | CLSLoss:0.1454 | AUROC:0.9902\n",
      "Test | 128/16 | Loss:1.1837 | MainLoss:1.1837 | SPLoss:0.0038 | CLSLoss:0.1454 | AUROC:0.8816\n",
      "\n",
      "Epoch: [457 | 1000] LR: 0.001294\n",
      "Train | 16/16 | Loss:0.0760 | MainLoss:0.0611 | Alpha:0.4858 | SPLoss:0.0038 | CLSLoss:0.1454 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1540 | MainLoss:0.1540 | SPLoss:0.0039 | CLSLoss:0.1454 | AUROC:0.9901\n",
      "Test | 128/16 | Loss:1.2078 | MainLoss:1.2078 | SPLoss:0.0039 | CLSLoss:0.1454 | AUROC:0.8798\n",
      "\n",
      "Epoch: [458 | 1000] LR: 0.001291\n",
      "Train | 16/16 | Loss:0.0766 | MainLoss:0.0617 | Alpha:0.4857 | SPLoss:0.0039 | CLSLoss:0.1453 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1547 | MainLoss:0.1547 | SPLoss:0.0039 | CLSLoss:0.1452 | AUROC:0.9903\n",
      "Test | 128/16 | Loss:1.2001 | MainLoss:1.2001 | SPLoss:0.0039 | CLSLoss:0.1452 | AUROC:0.8806\n",
      "\n",
      "Epoch: [459 | 1000] LR: 0.001288\n",
      "Train | 16/16 | Loss:0.0710 | MainLoss:0.0560 | Alpha:0.4871 | SPLoss:0.0040 | CLSLoss:0.1453 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1598 | MainLoss:0.1598 | SPLoss:0.0040 | CLSLoss:0.1453 | AUROC:0.9901\n",
      "Test | 128/16 | Loss:1.1736 | MainLoss:1.1736 | SPLoss:0.0040 | CLSLoss:0.1453 | AUROC:0.8825\n",
      "\n",
      "Epoch: [460 | 1000] LR: 0.001285\n",
      "Train | 16/16 | Loss:0.0789 | MainLoss:0.0640 | Alpha:0.4859 | SPLoss:0.0040 | CLSLoss:0.1453 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1583 | MainLoss:0.1583 | SPLoss:0.0041 | CLSLoss:0.1452 | AUROC:0.9902\n",
      "Test | 128/16 | Loss:1.1814 | MainLoss:1.1814 | SPLoss:0.0041 | CLSLoss:0.1452 | AUROC:0.8818\n",
      "\n",
      "Epoch: [461 | 1000] LR: 0.001282\n",
      "Train | 16/16 | Loss:0.0705 | MainLoss:0.0556 | Alpha:0.4867 | SPLoss:0.0041 | CLSLoss:0.1452 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1609 | MainLoss:0.1609 | SPLoss:0.0041 | CLSLoss:0.1452 | AUROC:0.9901\n",
      "Test | 128/16 | Loss:1.1688 | MainLoss:1.1688 | SPLoss:0.0041 | CLSLoss:0.1452 | AUROC:0.8820\n",
      "\n",
      "Epoch: [462 | 1000] LR: 0.001279\n",
      "Train | 16/16 | Loss:0.0782 | MainLoss:0.0633 | Alpha:0.4842 | SPLoss:0.0042 | CLSLoss:0.1452 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1592 | MainLoss:0.1592 | SPLoss:0.0042 | CLSLoss:0.1451 | AUROC:0.9904\n",
      "Test | 128/16 | Loss:1.1756 | MainLoss:1.1756 | SPLoss:0.0042 | CLSLoss:0.1451 | AUROC:0.8823\n",
      "\n",
      "Epoch: [463 | 1000] LR: 0.001276\n",
      "Train | 16/16 | Loss:0.0711 | MainLoss:0.0562 | Alpha:0.4874 | SPLoss:0.0043 | CLSLoss:0.1451 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1604 | MainLoss:0.1604 | SPLoss:0.0043 | CLSLoss:0.1451 | AUROC:0.9902\n",
      "Test | 128/16 | Loss:1.1711 | MainLoss:1.1711 | SPLoss:0.0043 | CLSLoss:0.1451 | AUROC:0.8817\n",
      "\n",
      "Epoch: [464 | 1000] LR: 0.001273\n",
      "Train | 16/16 | Loss:0.0730 | MainLoss:0.0581 | Alpha:0.4860 | SPLoss:0.0043 | CLSLoss:0.1451 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1605 | MainLoss:0.1605 | SPLoss:0.0044 | CLSLoss:0.1451 | AUROC:0.9902\n",
      "Test | 128/16 | Loss:1.1694 | MainLoss:1.1694 | SPLoss:0.0044 | CLSLoss:0.1451 | AUROC:0.8815\n",
      "\n",
      "Epoch: [465 | 1000] LR: 0.001270\n",
      "Train | 16/16 | Loss:0.0591 | MainLoss:0.0441 | Alpha:0.4898 | SPLoss:0.0044 | CLSLoss:0.1452 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1617 | MainLoss:0.1617 | SPLoss:0.0045 | CLSLoss:0.1453 | AUROC:0.9902\n",
      "Test | 128/16 | Loss:1.1686 | MainLoss:1.1686 | SPLoss:0.0045 | CLSLoss:0.1453 | AUROC:0.8821\n",
      "\n",
      "Epoch: [466 | 1000] LR: 0.001267\n",
      "Train | 16/16 | Loss:0.0766 | MainLoss:0.0616 | Alpha:0.4852 | SPLoss:0.0045 | CLSLoss:0.1453 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1601 | MainLoss:0.1601 | SPLoss:0.0046 | CLSLoss:0.1452 | AUROC:0.9900\n",
      "Test | 128/16 | Loss:1.1733 | MainLoss:1.1733 | SPLoss:0.0046 | CLSLoss:0.1452 | AUROC:0.8819\n",
      "\n",
      "Epoch: [467 | 1000] LR: 0.001264\n",
      "Train | 16/16 | Loss:0.0731 | MainLoss:0.0582 | Alpha:0.4869 | SPLoss:0.0046 | CLSLoss:0.1452 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1599 | MainLoss:0.1599 | SPLoss:0.0046 | CLSLoss:0.1452 | AUROC:0.9900\n",
      "Test | 128/16 | Loss:1.1753 | MainLoss:1.1753 | SPLoss:0.0046 | CLSLoss:0.1452 | AUROC:0.8818\n",
      "\n",
      "Epoch: [468 | 1000] LR: 0.001261\n",
      "Train | 16/16 | Loss:0.0755 | MainLoss:0.0605 | Alpha:0.4848 | SPLoss:0.0047 | CLSLoss:0.1451 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1598 | MainLoss:0.1598 | SPLoss:0.0047 | CLSLoss:0.1451 | AUROC:0.9901\n",
      "Test | 128/16 | Loss:1.1735 | MainLoss:1.1735 | SPLoss:0.0047 | CLSLoss:0.1451 | AUROC:0.8823\n",
      "\n",
      "Epoch: [469 | 1000] LR: 0.001258\n",
      "Train | 16/16 | Loss:0.0873 | MainLoss:0.0723 | Alpha:0.4826 | SPLoss:0.0048 | CLSLoss:0.1449 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1598 | MainLoss:0.1598 | SPLoss:0.0048 | CLSLoss:0.1448 | AUROC:0.9901\n",
      "Test | 128/16 | Loss:1.1692 | MainLoss:1.1692 | SPLoss:0.0048 | CLSLoss:0.1448 | AUROC:0.8821\n",
      "\n",
      "Epoch: [470 | 1000] LR: 0.001255\n",
      "Train | 16/16 | Loss:0.0611 | MainLoss:0.0461 | Alpha:0.4897 | SPLoss:0.0049 | CLSLoss:0.1449 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1597 | MainLoss:0.1597 | SPLoss:0.0049 | CLSLoss:0.1450 | AUROC:0.9904\n",
      "Test | 128/16 | Loss:1.1725 | MainLoss:1.1725 | SPLoss:0.0049 | CLSLoss:0.1450 | AUROC:0.8821\n",
      "\n",
      "Epoch: [471 | 1000] LR: 0.001252\n",
      "Train | 16/16 | Loss:0.0782 | MainLoss:0.0632 | Alpha:0.4861 | SPLoss:0.0050 | CLSLoss:0.1450 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1594 | MainLoss:0.1594 | SPLoss:0.0050 | CLSLoss:0.1449 | AUROC:0.9902\n",
      "Test | 128/16 | Loss:1.1713 | MainLoss:1.1713 | SPLoss:0.0050 | CLSLoss:0.1449 | AUROC:0.8822\n",
      "\n",
      "Epoch: [472 | 1000] LR: 0.001249\n",
      "Train | 16/16 | Loss:0.0713 | MainLoss:0.0563 | Alpha:0.4863 | SPLoss:0.0050 | CLSLoss:0.1449 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1611 | MainLoss:0.1611 | SPLoss:0.0051 | CLSLoss:0.1449 | AUROC:0.9904\n",
      "Test | 128/16 | Loss:1.1615 | MainLoss:1.1615 | SPLoss:0.0051 | CLSLoss:0.1449 | AUROC:0.8823\n",
      "\n",
      "Epoch: [473 | 1000] LR: 0.001246\n",
      "Train | 16/16 | Loss:0.0724 | MainLoss:0.0574 | Alpha:0.4864 | SPLoss:0.0051 | CLSLoss:0.1449 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1596 | MainLoss:0.1596 | SPLoss:0.0052 | CLSLoss:0.1449 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1711 | MainLoss:1.1711 | SPLoss:0.0052 | CLSLoss:0.1449 | AUROC:0.8820\n",
      "\n",
      "Epoch: [474 | 1000] LR: 0.001243\n",
      "Train | 16/16 | Loss:0.0703 | MainLoss:0.0552 | Alpha:0.4870 | SPLoss:0.0052 | CLSLoss:0.1449 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1568 | MainLoss:0.1568 | SPLoss:0.0053 | CLSLoss:0.1449 | AUROC:0.9902\n",
      "Test | 128/16 | Loss:1.1863 | MainLoss:1.1863 | SPLoss:0.0053 | CLSLoss:0.1449 | AUROC:0.8814\n",
      "\n",
      "Epoch: [475 | 1000] LR: 0.001240\n",
      "Train | 16/16 | Loss:0.0679 | MainLoss:0.0529 | Alpha:0.4879 | SPLoss:0.0053 | CLSLoss:0.1450 | AUROC:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 32/16 | Loss:0.1570 | MainLoss:0.1570 | SPLoss:0.0054 | CLSLoss:0.1450 | AUROC:0.9901\n",
      "Test | 128/16 | Loss:1.1841 | MainLoss:1.1841 | SPLoss:0.0054 | CLSLoss:0.1450 | AUROC:0.8821\n",
      "\n",
      "Epoch: [476 | 1000] LR: 0.001236\n",
      "Train | 16/16 | Loss:0.0699 | MainLoss:0.0549 | Alpha:0.4869 | SPLoss:0.0054 | CLSLoss:0.1450 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1598 | MainLoss:0.1598 | SPLoss:0.0054 | CLSLoss:0.1450 | AUROC:0.9903\n",
      "Test | 128/16 | Loss:1.1716 | MainLoss:1.1716 | SPLoss:0.0054 | CLSLoss:0.1450 | AUROC:0.8822\n",
      "\n",
      "Epoch: [477 | 1000] LR: 0.001233\n",
      "Train | 16/16 | Loss:0.0735 | MainLoss:0.0585 | Alpha:0.4849 | SPLoss:0.0055 | CLSLoss:0.1450 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1605 | MainLoss:0.1605 | SPLoss:0.0055 | CLSLoss:0.1450 | AUROC:0.9899\n",
      "Test | 128/16 | Loss:1.1668 | MainLoss:1.1668 | SPLoss:0.0055 | CLSLoss:0.1450 | AUROC:0.8823\n",
      "\n",
      "Epoch: [478 | 1000] LR: 0.001230\n",
      "Train | 16/16 | Loss:0.0576 | MainLoss:0.0425 | Alpha:0.4899 | SPLoss:0.0056 | CLSLoss:0.1451 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1614 | MainLoss:0.1614 | SPLoss:0.0056 | CLSLoss:0.1452 | AUROC:0.9903\n",
      "Test | 128/16 | Loss:1.1692 | MainLoss:1.1692 | SPLoss:0.0056 | CLSLoss:0.1452 | AUROC:0.8827\n",
      "\n",
      "Epoch: [479 | 1000] LR: 0.001227\n",
      "Train | 16/16 | Loss:0.0747 | MainLoss:0.0596 | Alpha:0.4861 | SPLoss:0.0056 | CLSLoss:0.1452 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1591 | MainLoss:0.1591 | SPLoss:0.0057 | CLSLoss:0.1451 | AUROC:0.9902\n",
      "Test | 128/16 | Loss:1.1781 | MainLoss:1.1781 | SPLoss:0.0057 | CLSLoss:0.1451 | AUROC:0.8823\n",
      "\n",
      "Epoch: [480 | 1000] LR: 0.001224\n",
      "Train | 16/16 | Loss:0.0821 | MainLoss:0.0671 | Alpha:0.4844 | SPLoss:0.0057 | CLSLoss:0.1450 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1568 | MainLoss:0.1568 | SPLoss:0.0058 | CLSLoss:0.1450 | AUROC:0.9902\n",
      "Test | 128/16 | Loss:1.1879 | MainLoss:1.1879 | SPLoss:0.0058 | CLSLoss:0.1450 | AUROC:0.8823\n",
      "\n",
      "Epoch: [481 | 1000] LR: 0.001221\n",
      "Train | 16/16 | Loss:0.0723 | MainLoss:0.0572 | Alpha:0.4861 | SPLoss:0.0058 | CLSLoss:0.1450 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1566 | MainLoss:0.1566 | SPLoss:0.0059 | CLSLoss:0.1450 | AUROC:0.9903\n",
      "Test | 128/16 | Loss:1.1896 | MainLoss:1.1896 | SPLoss:0.0059 | CLSLoss:0.1450 | AUROC:0.8817\n",
      "\n",
      "Epoch: [482 | 1000] LR: 0.001218\n",
      "Train | 16/16 | Loss:0.0752 | MainLoss:0.0601 | Alpha:0.4856 | SPLoss:0.0059 | CLSLoss:0.1450 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1565 | MainLoss:0.1565 | SPLoss:0.0060 | CLSLoss:0.1450 | AUROC:0.9904\n",
      "Test | 128/16 | Loss:1.1895 | MainLoss:1.1895 | SPLoss:0.0060 | CLSLoss:0.1450 | AUROC:0.8819\n",
      "\n",
      "Epoch: [483 | 1000] LR: 0.001215\n",
      "Train | 16/16 | Loss:0.0753 | MainLoss:0.0602 | Alpha:0.4854 | SPLoss:0.0060 | CLSLoss:0.1449 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1577 | MainLoss:0.1577 | SPLoss:0.0061 | CLSLoss:0.1449 | AUROC:0.9902\n",
      "Test | 128/16 | Loss:1.1814 | MainLoss:1.1814 | SPLoss:0.0061 | CLSLoss:0.1449 | AUROC:0.8824\n",
      "\n",
      "Epoch: [484 | 1000] LR: 0.001212\n",
      "Train | 16/16 | Loss:0.0702 | MainLoss:0.0552 | Alpha:0.4863 | SPLoss:0.0061 | CLSLoss:0.1448 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1600 | MainLoss:0.1600 | SPLoss:0.0062 | CLSLoss:0.1449 | AUROC:0.9902\n",
      "Test | 128/16 | Loss:1.1693 | MainLoss:1.1693 | SPLoss:0.0062 | CLSLoss:0.1449 | AUROC:0.8832\n",
      "\n",
      "Epoch: [485 | 1000] LR: 0.001209\n",
      "Train | 16/16 | Loss:0.0655 | MainLoss:0.0504 | Alpha:0.4885 | SPLoss:0.0062 | CLSLoss:0.1449 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1600 | MainLoss:0.1600 | SPLoss:0.0062 | CLSLoss:0.1449 | AUROC:0.9902\n",
      "Test | 128/16 | Loss:1.1722 | MainLoss:1.1722 | SPLoss:0.0062 | CLSLoss:0.1449 | AUROC:0.8831\n",
      "\n",
      "Epoch: [486 | 1000] LR: 0.001206\n",
      "Train | 16/16 | Loss:0.0679 | MainLoss:0.0527 | Alpha:0.4866 | SPLoss:0.0062 | CLSLoss:0.1449 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1600 | MainLoss:0.1600 | SPLoss:0.0063 | CLSLoss:0.1450 | AUROC:0.9904\n",
      "Test | 128/16 | Loss:1.1757 | MainLoss:1.1757 | SPLoss:0.0063 | CLSLoss:0.1450 | AUROC:0.8826\n",
      "\n",
      "Epoch: [487 | 1000] LR: 0.001203\n",
      "Train | 16/16 | Loss:0.0741 | MainLoss:0.0590 | Alpha:0.4860 | SPLoss:0.0063 | CLSLoss:0.1450 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1624 | MainLoss:0.1624 | SPLoss:0.0064 | CLSLoss:0.1450 | AUROC:0.9902\n",
      "Test | 128/16 | Loss:1.1631 | MainLoss:1.1631 | SPLoss:0.0064 | CLSLoss:0.1450 | AUROC:0.8841\n",
      "\n",
      "Epoch: [488 | 1000] LR: 0.001200\n",
      "Train | 16/16 | Loss:0.0729 | MainLoss:0.0577 | Alpha:0.4862 | SPLoss:0.0064 | CLSLoss:0.1450 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1611 | MainLoss:0.1611 | SPLoss:0.0065 | CLSLoss:0.1449 | AUROC:0.9903\n",
      "Test | 128/16 | Loss:1.1709 | MainLoss:1.1709 | SPLoss:0.0065 | CLSLoss:0.1449 | AUROC:0.8831\n",
      "\n",
      "Epoch: [489 | 1000] LR: 0.001197\n",
      "Train | 16/16 | Loss:0.0775 | MainLoss:0.0623 | Alpha:0.4843 | SPLoss:0.0065 | CLSLoss:0.1449 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1589 | MainLoss:0.1589 | SPLoss:0.0065 | CLSLoss:0.1448 | AUROC:0.9902\n",
      "Test | 128/16 | Loss:1.1854 | MainLoss:1.1854 | SPLoss:0.0065 | CLSLoss:0.1448 | AUROC:0.8825\n",
      "\n",
      "Epoch: [490 | 1000] LR: 0.001194\n",
      "Train | 16/16 | Loss:0.0690 | MainLoss:0.0538 | Alpha:0.4874 | SPLoss:0.0065 | CLSLoss:0.1448 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1592 | MainLoss:0.1592 | SPLoss:0.0066 | CLSLoss:0.1449 | AUROC:0.9902\n",
      "Test | 128/16 | Loss:1.1841 | MainLoss:1.1841 | SPLoss:0.0066 | CLSLoss:0.1449 | AUROC:0.8824\n",
      "\n",
      "Epoch: [491 | 1000] LR: 0.001190\n",
      "Train | 16/16 | Loss:0.0711 | MainLoss:0.0559 | Alpha:0.4871 | SPLoss:0.0066 | CLSLoss:0.1449 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1601 | MainLoss:0.1601 | SPLoss:0.0067 | CLSLoss:0.1449 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1776 | MainLoss:1.1776 | SPLoss:0.0067 | CLSLoss:0.1449 | AUROC:0.8837\n",
      "\n",
      "Epoch: [492 | 1000] LR: 0.001187\n",
      "Train | 16/16 | Loss:0.0814 | MainLoss:0.0663 | Alpha:0.4838 | SPLoss:0.0067 | CLSLoss:0.1448 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1592 | MainLoss:0.1592 | SPLoss:0.0068 | CLSLoss:0.1447 | AUROC:0.9902\n",
      "Test | 128/16 | Loss:1.1799 | MainLoss:1.1799 | SPLoss:0.0068 | CLSLoss:0.1447 | AUROC:0.8835\n",
      "\n",
      "Epoch: [493 | 1000] LR: 0.001184\n",
      "Train | 16/16 | Loss:0.0699 | MainLoss:0.0548 | Alpha:0.4864 | SPLoss:0.0068 | CLSLoss:0.1446 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1614 | MainLoss:0.1614 | SPLoss:0.0069 | CLSLoss:0.1447 | AUROC:0.9902\n",
      "Test | 128/16 | Loss:1.1724 | MainLoss:1.1724 | SPLoss:0.0069 | CLSLoss:0.1447 | AUROC:0.8833\n",
      "\n",
      "Epoch: [494 | 1000] LR: 0.001181\n",
      "Train | 16/16 | Loss:0.0703 | MainLoss:0.0551 | Alpha:0.4874 | SPLoss:0.0069 | CLSLoss:0.1448 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1601 | MainLoss:0.1601 | SPLoss:0.0070 | CLSLoss:0.1448 | AUROC:0.9902\n",
      "Test | 128/16 | Loss:1.1806 | MainLoss:1.1806 | SPLoss:0.0070 | CLSLoss:0.1448 | AUROC:0.8828\n",
      "\n",
      "Epoch: [495 | 1000] LR: 0.001178\n",
      "Train | 16/16 | Loss:0.0798 | MainLoss:0.0647 | Alpha:0.4839 | SPLoss:0.0070 | CLSLoss:0.1447 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1613 | MainLoss:0.1613 | SPLoss:0.0071 | CLSLoss:0.1447 | AUROC:0.9901\n",
      "Test | 128/16 | Loss:1.1715 | MainLoss:1.1715 | SPLoss:0.0071 | CLSLoss:0.1447 | AUROC:0.8832\n",
      "\n",
      "Epoch: [496 | 1000] LR: 0.001175\n",
      "Train | 16/16 | Loss:0.0931 | MainLoss:0.0779 | Alpha:0.4808 | SPLoss:0.0071 | CLSLoss:0.1445 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1576 | MainLoss:0.1576 | SPLoss:0.0072 | CLSLoss:0.1443 | AUROC:0.9902\n",
      "Test | 128/16 | Loss:1.1844 | MainLoss:1.1844 | SPLoss:0.0072 | CLSLoss:0.1443 | AUROC:0.8827\n",
      "\n",
      "Epoch: [497 | 1000] LR: 0.001172\n",
      "Train | 16/16 | Loss:0.0697 | MainLoss:0.0546 | Alpha:0.4872 | SPLoss:0.0072 | CLSLoss:0.1443 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1590 | MainLoss:0.1590 | SPLoss:0.0073 | CLSLoss:0.1443 | AUROC:0.9903\n",
      "Test | 128/16 | Loss:1.1787 | MainLoss:1.1787 | SPLoss:0.0073 | CLSLoss:0.1443 | AUROC:0.8831\n",
      "\n",
      "Epoch: [498 | 1000] LR: 0.001169\n",
      "Train | 16/16 | Loss:0.0776 | MainLoss:0.0624 | Alpha:0.4844 | SPLoss:0.0073 | CLSLoss:0.1443 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1597 | MainLoss:0.1597 | SPLoss:0.0074 | CLSLoss:0.1442 | AUROC:0.9903\n",
      "Test | 128/16 | Loss:1.1745 | MainLoss:1.1745 | SPLoss:0.0074 | CLSLoss:0.1442 | AUROC:0.8829\n",
      "\n",
      "Epoch: [499 | 1000] LR: 0.001166\n",
      "Train | 16/16 | Loss:0.0816 | MainLoss:0.0664 | Alpha:0.4831 | SPLoss:0.0074 | CLSLoss:0.1442 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1615 | MainLoss:0.1615 | SPLoss:0.0075 | CLSLoss:0.1441 | AUROC:0.9904\n",
      "Test | 128/16 | Loss:1.1642 | MainLoss:1.1642 | SPLoss:0.0075 | CLSLoss:0.1441 | AUROC:0.8837\n",
      "\n",
      "Epoch: [500 | 1000] LR: 0.001163\n",
      "Train | 16/16 | Loss:0.0703 | MainLoss:0.0551 | Alpha:0.4864 | SPLoss:0.0075 | CLSLoss:0.1442 | AUROC:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 32/16 | Loss:0.1627 | MainLoss:0.1627 | SPLoss:0.0076 | CLSLoss:0.1442 | AUROC:0.9901\n",
      "Test | 128/16 | Loss:1.1583 | MainLoss:1.1583 | SPLoss:0.0076 | CLSLoss:0.1442 | AUROC:0.8842\n",
      "\n",
      "Epoch: [501 | 1000] LR: 0.001160\n",
      "Train | 16/16 | Loss:0.0672 | MainLoss:0.0527 | Alpha:0.4887 | SPLoss:0.0000 | CLSLoss:0.1442 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1631 | MainLoss:0.1631 | SPLoss:0.0000 | CLSLoss:0.1443 | AUROC:0.9903\n",
      "Test | 128/16 | Loss:1.1582 | MainLoss:1.1582 | SPLoss:0.0000 | CLSLoss:0.1443 | AUROC:0.8841\n",
      "\n",
      "Epoch: [502 | 1000] LR: 0.001156\n",
      "Train | 16/16 | Loss:0.0684 | MainLoss:0.0540 | Alpha:0.4886 | SPLoss:0.0000 | CLSLoss:0.1443 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1619 | MainLoss:0.1619 | SPLoss:0.0000 | CLSLoss:0.1443 | AUROC:0.9903\n",
      "Test | 128/16 | Loss:1.1642 | MainLoss:1.1642 | SPLoss:0.0000 | CLSLoss:0.1443 | AUROC:0.8841\n",
      "\n",
      "Epoch: [503 | 1000] LR: 0.001153\n",
      "Train | 16/16 | Loss:0.0716 | MainLoss:0.0572 | Alpha:0.4879 | SPLoss:0.0000 | CLSLoss:0.1443 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1606 | MainLoss:0.1606 | SPLoss:0.0001 | CLSLoss:0.1443 | AUROC:0.9900\n",
      "Test | 128/16 | Loss:1.1713 | MainLoss:1.1713 | SPLoss:0.0001 | CLSLoss:0.1443 | AUROC:0.8839\n",
      "\n",
      "Epoch: [504 | 1000] LR: 0.001150\n",
      "Train | 16/16 | Loss:0.0694 | MainLoss:0.0550 | Alpha:0.4882 | SPLoss:0.0001 | CLSLoss:0.1443 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1632 | MainLoss:0.1632 | SPLoss:0.0001 | CLSLoss:0.1443 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1615 | MainLoss:1.1615 | SPLoss:0.0001 | CLSLoss:0.1443 | AUROC:0.8840\n",
      "\n",
      "Epoch: [505 | 1000] LR: 0.001147\n",
      "Train | 16/16 | Loss:0.0858 | MainLoss:0.0714 | Alpha:0.4843 | SPLoss:0.0001 | CLSLoss:0.1442 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1628 | MainLoss:0.1628 | SPLoss:0.0001 | CLSLoss:0.1441 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1589 | MainLoss:1.1589 | SPLoss:0.0001 | CLSLoss:0.1441 | AUROC:0.8839\n",
      "\n",
      "Epoch: [506 | 1000] LR: 0.001144\n",
      "Train | 16/16 | Loss:0.0642 | MainLoss:0.0498 | Alpha:0.4889 | SPLoss:0.0001 | CLSLoss:0.1442 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1584 | MainLoss:0.1584 | SPLoss:0.0001 | CLSLoss:0.1442 | AUROC:0.9903\n",
      "Test | 128/16 | Loss:1.1859 | MainLoss:1.1859 | SPLoss:0.0001 | CLSLoss:0.1442 | AUROC:0.8824\n",
      "\n",
      "Epoch: [507 | 1000] LR: 0.001141\n",
      "Train | 16/16 | Loss:0.0610 | MainLoss:0.0466 | Alpha:0.4896 | SPLoss:0.0002 | CLSLoss:0.1442 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1570 | MainLoss:0.1570 | SPLoss:0.0002 | CLSLoss:0.1443 | AUROC:0.9903\n",
      "Test | 128/16 | Loss:1.1993 | MainLoss:1.1993 | SPLoss:0.0002 | CLSLoss:0.1443 | AUROC:0.8814\n",
      "\n",
      "Epoch: [508 | 1000] LR: 0.001138\n",
      "Train | 16/16 | Loss:0.0688 | MainLoss:0.0544 | Alpha:0.4886 | SPLoss:0.0002 | CLSLoss:0.1443 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1561 | MainLoss:0.1561 | SPLoss:0.0002 | CLSLoss:0.1443 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.2047 | MainLoss:1.2047 | SPLoss:0.0002 | CLSLoss:0.1443 | AUROC:0.8814\n",
      "\n",
      "Epoch: [509 | 1000] LR: 0.001135\n",
      "Train | 16/16 | Loss:0.0751 | MainLoss:0.0606 | Alpha:0.4862 | SPLoss:0.0002 | CLSLoss:0.1443 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1552 | MainLoss:0.1552 | SPLoss:0.0002 | CLSLoss:0.1443 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.2082 | MainLoss:1.2082 | SPLoss:0.0002 | CLSLoss:0.1443 | AUROC:0.8814\n",
      "\n",
      "Epoch: [510 | 1000] LR: 0.001132\n",
      "Train | 16/16 | Loss:0.0690 | MainLoss:0.0546 | Alpha:0.4886 | SPLoss:0.0002 | CLSLoss:0.1442 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1563 | MainLoss:0.1563 | SPLoss:0.0002 | CLSLoss:0.1442 | AUROC:0.9904\n",
      "Test | 128/16 | Loss:1.2011 | MainLoss:1.2011 | SPLoss:0.0002 | CLSLoss:0.1442 | AUROC:0.8823\n",
      "\n",
      "Epoch: [511 | 1000] LR: 0.001128\n",
      "Train | 16/16 | Loss:0.0793 | MainLoss:0.0649 | Alpha:0.4861 | SPLoss:0.0002 | CLSLoss:0.1442 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1593 | MainLoss:0.1593 | SPLoss:0.0003 | CLSLoss:0.1441 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1816 | MainLoss:1.1816 | SPLoss:0.0003 | CLSLoss:0.1441 | AUROC:0.8837\n",
      "\n",
      "Epoch: [512 | 1000] LR: 0.001125\n",
      "Train | 16/16 | Loss:0.0817 | MainLoss:0.0672 | Alpha:0.4854 | SPLoss:0.0003 | CLSLoss:0.1440 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1597 | MainLoss:0.1597 | SPLoss:0.0003 | CLSLoss:0.1439 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1789 | MainLoss:1.1789 | SPLoss:0.0003 | CLSLoss:0.1439 | AUROC:0.8836\n",
      "\n",
      "Epoch: [513 | 1000] LR: 0.001122\n",
      "Train | 16/16 | Loss:0.0653 | MainLoss:0.0508 | Alpha:0.4888 | SPLoss:0.0003 | CLSLoss:0.1439 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1590 | MainLoss:0.1590 | SPLoss:0.0003 | CLSLoss:0.1439 | AUROC:0.9904\n",
      "Test | 128/16 | Loss:1.1849 | MainLoss:1.1849 | SPLoss:0.0003 | CLSLoss:0.1439 | AUROC:0.8832\n",
      "\n",
      "Epoch: [514 | 1000] LR: 0.001119\n",
      "Train | 16/16 | Loss:0.0688 | MainLoss:0.0544 | Alpha:0.4880 | SPLoss:0.0003 | CLSLoss:0.1439 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1591 | MainLoss:0.1591 | SPLoss:0.0003 | CLSLoss:0.1440 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1837 | MainLoss:1.1837 | SPLoss:0.0003 | CLSLoss:0.1440 | AUROC:0.8834\n",
      "\n",
      "Epoch: [515 | 1000] LR: 0.001116\n",
      "Train | 16/16 | Loss:0.0746 | MainLoss:0.0602 | Alpha:0.4872 | SPLoss:0.0004 | CLSLoss:0.1439 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1592 | MainLoss:0.1592 | SPLoss:0.0004 | CLSLoss:0.1439 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1807 | MainLoss:1.1807 | SPLoss:0.0004 | CLSLoss:0.1439 | AUROC:0.8833\n",
      "\n",
      "Epoch: [516 | 1000] LR: 0.001113\n",
      "Train | 16/16 | Loss:0.0659 | MainLoss:0.0514 | Alpha:0.4889 | SPLoss:0.0004 | CLSLoss:0.1439 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1582 | MainLoss:0.1582 | SPLoss:0.0004 | CLSLoss:0.1440 | AUROC:0.9903\n",
      "Test | 128/16 | Loss:1.1862 | MainLoss:1.1862 | SPLoss:0.0004 | CLSLoss:0.1440 | AUROC:0.8833\n",
      "\n",
      "Epoch: [517 | 1000] LR: 0.001110\n",
      "Train | 16/16 | Loss:0.0762 | MainLoss:0.0618 | Alpha:0.4866 | SPLoss:0.0004 | CLSLoss:0.1439 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1567 | MainLoss:0.1567 | SPLoss:0.0005 | CLSLoss:0.1438 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1914 | MainLoss:1.1914 | SPLoss:0.0005 | CLSLoss:0.1438 | AUROC:0.8833\n",
      "\n",
      "Epoch: [518 | 1000] LR: 0.001107\n",
      "Train | 16/16 | Loss:0.0781 | MainLoss:0.0636 | Alpha:0.4852 | SPLoss:0.0005 | CLSLoss:0.1438 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1575 | MainLoss:0.1575 | SPLoss:0.0005 | CLSLoss:0.1437 | AUROC:0.9904\n",
      "Test | 128/16 | Loss:1.1869 | MainLoss:1.1869 | SPLoss:0.0005 | CLSLoss:0.1437 | AUROC:0.8829\n",
      "\n",
      "Epoch: [519 | 1000] LR: 0.001103\n",
      "Train | 16/16 | Loss:0.0757 | MainLoss:0.0613 | Alpha:0.4862 | SPLoss:0.0005 | CLSLoss:0.1437 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1576 | MainLoss:0.1576 | SPLoss:0.0005 | CLSLoss:0.1436 | AUROC:0.9903\n",
      "Test | 128/16 | Loss:1.1834 | MainLoss:1.1834 | SPLoss:0.0005 | CLSLoss:0.1436 | AUROC:0.8837\n",
      "\n",
      "Epoch: [520 | 1000] LR: 0.001100\n",
      "Train | 16/16 | Loss:0.0714 | MainLoss:0.0570 | Alpha:0.4872 | SPLoss:0.0005 | CLSLoss:0.1436 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1586 | MainLoss:0.1586 | SPLoss:0.0006 | CLSLoss:0.1436 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1773 | MainLoss:1.1773 | SPLoss:0.0006 | CLSLoss:0.1436 | AUROC:0.8838\n",
      "\n",
      "Epoch: [521 | 1000] LR: 0.001097\n",
      "Train | 16/16 | Loss:0.0722 | MainLoss:0.0578 | Alpha:0.4872 | SPLoss:0.0006 | CLSLoss:0.1436 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1589 | MainLoss:0.1589 | SPLoss:0.0006 | CLSLoss:0.1436 | AUROC:0.9904\n",
      "Test | 128/16 | Loss:1.1748 | MainLoss:1.1748 | SPLoss:0.0006 | CLSLoss:0.1436 | AUROC:0.8848\n",
      "\n",
      "Epoch: [522 | 1000] LR: 0.001094\n",
      "Train | 16/16 | Loss:0.0685 | MainLoss:0.0541 | Alpha:0.4875 | SPLoss:0.0006 | CLSLoss:0.1436 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1605 | MainLoss:0.1605 | SPLoss:0.0006 | CLSLoss:0.1436 | AUROC:0.9908\n",
      "Test | 128/16 | Loss:1.1650 | MainLoss:1.1650 | SPLoss:0.0006 | CLSLoss:0.1436 | AUROC:0.8853\n",
      "\n",
      "Epoch: [523 | 1000] LR: 0.001091\n",
      "Train | 16/16 | Loss:0.0781 | MainLoss:0.0637 | Alpha:0.4855 | SPLoss:0.0006 | CLSLoss:0.1435 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1605 | MainLoss:0.1605 | SPLoss:0.0007 | CLSLoss:0.1434 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1633 | MainLoss:1.1633 | SPLoss:0.0007 | CLSLoss:0.1434 | AUROC:0.8851\n",
      "\n",
      "Epoch: [524 | 1000] LR: 0.001088\n",
      "Train | 16/16 | Loss:0.0613 | MainLoss:0.0468 | Alpha:0.4898 | SPLoss:0.0007 | CLSLoss:0.1435 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1598 | MainLoss:0.1598 | SPLoss:0.0007 | CLSLoss:0.1435 | AUROC:0.9903\n",
      "Test | 128/16 | Loss:1.1690 | MainLoss:1.1690 | SPLoss:0.0007 | CLSLoss:0.1435 | AUROC:0.8846\n",
      "\n",
      "Epoch: [525 | 1000] LR: 0.001085\n",
      "Train | 16/16 | Loss:0.0719 | MainLoss:0.0574 | Alpha:0.4869 | SPLoss:0.0007 | CLSLoss:0.1435 | AUROC:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 32/16 | Loss:0.1597 | MainLoss:0.1597 | SPLoss:0.0007 | CLSLoss:0.1435 | AUROC:0.9904\n",
      "Test | 128/16 | Loss:1.1692 | MainLoss:1.1692 | SPLoss:0.0007 | CLSLoss:0.1435 | AUROC:0.8854\n",
      "\n",
      "Epoch: [526 | 1000] LR: 0.001082\n",
      "Train | 16/16 | Loss:0.0704 | MainLoss:0.0560 | Alpha:0.4870 | SPLoss:0.0007 | CLSLoss:0.1435 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1562 | MainLoss:0.1562 | SPLoss:0.0008 | CLSLoss:0.1435 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1882 | MainLoss:1.1882 | SPLoss:0.0008 | CLSLoss:0.1435 | AUROC:0.8844\n",
      "\n",
      "Epoch: [527 | 1000] LR: 0.001078\n",
      "Train | 16/16 | Loss:0.0699 | MainLoss:0.0554 | Alpha:0.4875 | SPLoss:0.0008 | CLSLoss:0.1435 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1591 | MainLoss:0.1591 | SPLoss:0.0008 | CLSLoss:0.1435 | AUROC:0.9904\n",
      "Test | 128/16 | Loss:1.1719 | MainLoss:1.1719 | SPLoss:0.0008 | CLSLoss:0.1435 | AUROC:0.8851\n",
      "\n",
      "Epoch: [528 | 1000] LR: 0.001075\n",
      "Train | 16/16 | Loss:0.0651 | MainLoss:0.0506 | Alpha:0.4885 | SPLoss:0.0008 | CLSLoss:0.1435 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1613 | MainLoss:0.1613 | SPLoss:0.0008 | CLSLoss:0.1436 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1627 | MainLoss:1.1627 | SPLoss:0.0008 | CLSLoss:0.1436 | AUROC:0.8859\n",
      "\n",
      "Epoch: [529 | 1000] LR: 0.001072\n",
      "Train | 16/16 | Loss:0.0776 | MainLoss:0.0631 | Alpha:0.4859 | SPLoss:0.0009 | CLSLoss:0.1434 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1588 | MainLoss:0.1588 | SPLoss:0.0009 | CLSLoss:0.1434 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1730 | MainLoss:1.1730 | SPLoss:0.0009 | CLSLoss:0.1434 | AUROC:0.8853\n",
      "\n",
      "Epoch: [530 | 1000] LR: 0.001069\n",
      "Train | 16/16 | Loss:0.0796 | MainLoss:0.0651 | Alpha:0.4855 | SPLoss:0.0009 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1589 | MainLoss:0.1589 | SPLoss:0.0009 | CLSLoss:0.1433 | AUROC:0.9904\n",
      "Test | 128/16 | Loss:1.1710 | MainLoss:1.1710 | SPLoss:0.0009 | CLSLoss:0.1433 | AUROC:0.8850\n",
      "\n",
      "Epoch: [531 | 1000] LR: 0.001066\n",
      "Train | 16/16 | Loss:0.0704 | MainLoss:0.0560 | Alpha:0.4876 | SPLoss:0.0009 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1572 | MainLoss:0.1572 | SPLoss:0.0009 | CLSLoss:0.1433 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1872 | MainLoss:1.1872 | SPLoss:0.0009 | CLSLoss:0.1433 | AUROC:0.8843\n",
      "\n",
      "Epoch: [532 | 1000] LR: 0.001063\n",
      "Train | 16/16 | Loss:0.0664 | MainLoss:0.0519 | Alpha:0.4884 | SPLoss:0.0009 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1570 | MainLoss:0.1570 | SPLoss:0.0010 | CLSLoss:0.1433 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1899 | MainLoss:1.1899 | SPLoss:0.0010 | CLSLoss:0.1433 | AUROC:0.8836\n",
      "\n",
      "Epoch: [533 | 1000] LR: 0.001060\n",
      "Train | 16/16 | Loss:0.0807 | MainLoss:0.0663 | Alpha:0.4850 | SPLoss:0.0010 | CLSLoss:0.1431 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1568 | MainLoss:0.1568 | SPLoss:0.0010 | CLSLoss:0.1431 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1886 | MainLoss:1.1886 | SPLoss:0.0010 | CLSLoss:0.1431 | AUROC:0.8837\n",
      "\n",
      "Epoch: [534 | 1000] LR: 0.001057\n",
      "Train | 16/16 | Loss:0.0673 | MainLoss:0.0529 | Alpha:0.4887 | SPLoss:0.0010 | CLSLoss:0.1431 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1568 | MainLoss:0.1568 | SPLoss:0.0010 | CLSLoss:0.1431 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1886 | MainLoss:1.1886 | SPLoss:0.0010 | CLSLoss:0.1431 | AUROC:0.8836\n",
      "\n",
      "Epoch: [535 | 1000] LR: 0.001053\n",
      "Train | 16/16 | Loss:0.0769 | MainLoss:0.0625 | Alpha:0.4857 | SPLoss:0.0010 | CLSLoss:0.1430 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1576 | MainLoss:0.1576 | SPLoss:0.0010 | CLSLoss:0.1430 | AUROC:0.9904\n",
      "Test | 128/16 | Loss:1.1833 | MainLoss:1.1833 | SPLoss:0.0010 | CLSLoss:0.1430 | AUROC:0.8834\n",
      "\n",
      "Epoch: [536 | 1000] LR: 0.001050\n",
      "Train | 16/16 | Loss:0.0629 | MainLoss:0.0485 | Alpha:0.4890 | SPLoss:0.0011 | CLSLoss:0.1430 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1570 | MainLoss:0.1570 | SPLoss:0.0011 | CLSLoss:0.1431 | AUROC:0.9904\n",
      "Test | 128/16 | Loss:1.1898 | MainLoss:1.1898 | SPLoss:0.0011 | CLSLoss:0.1431 | AUROC:0.8828\n",
      "\n",
      "Epoch: [537 | 1000] LR: 0.001047\n",
      "Train | 16/16 | Loss:0.0699 | MainLoss:0.0555 | Alpha:0.4875 | SPLoss:0.0011 | CLSLoss:0.1431 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1590 | MainLoss:0.1590 | SPLoss:0.0011 | CLSLoss:0.1431 | AUROC:0.9904\n",
      "Test | 128/16 | Loss:1.1799 | MainLoss:1.1799 | SPLoss:0.0011 | CLSLoss:0.1431 | AUROC:0.8832\n",
      "\n",
      "Epoch: [538 | 1000] LR: 0.001044\n",
      "Train | 16/16 | Loss:0.0756 | MainLoss:0.0612 | Alpha:0.4861 | SPLoss:0.0011 | CLSLoss:0.1430 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0011 | CLSLoss:0.1430 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1824 | MainLoss:1.1824 | SPLoss:0.0011 | CLSLoss:0.1430 | AUROC:0.8834\n",
      "\n",
      "Epoch: [539 | 1000] LR: 0.001041\n",
      "Train | 16/16 | Loss:0.0802 | MainLoss:0.0658 | Alpha:0.4856 | SPLoss:0.0012 | CLSLoss:0.1429 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1589 | MainLoss:0.1589 | SPLoss:0.0012 | CLSLoss:0.1428 | AUROC:0.9904\n",
      "Test | 128/16 | Loss:1.1771 | MainLoss:1.1771 | SPLoss:0.0012 | CLSLoss:0.1428 | AUROC:0.8835\n",
      "\n",
      "Epoch: [540 | 1000] LR: 0.001038\n",
      "Train | 16/16 | Loss:0.0783 | MainLoss:0.0639 | Alpha:0.4858 | SPLoss:0.0012 | CLSLoss:0.1428 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0012 | CLSLoss:0.1426 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1774 | MainLoss:1.1774 | SPLoss:0.0012 | CLSLoss:0.1426 | AUROC:0.8833\n",
      "\n",
      "Epoch: [541 | 1000] LR: 0.001035\n",
      "Train | 16/16 | Loss:0.0610 | MainLoss:0.0466 | Alpha:0.4896 | SPLoss:0.0012 | CLSLoss:0.1427 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1604 | MainLoss:0.1604 | SPLoss:0.0012 | CLSLoss:0.1428 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1703 | MainLoss:1.1703 | SPLoss:0.0012 | CLSLoss:0.1428 | AUROC:0.8837\n",
      "\n",
      "Epoch: [542 | 1000] LR: 0.001031\n",
      "Train | 16/16 | Loss:0.0710 | MainLoss:0.0566 | Alpha:0.4869 | SPLoss:0.0012 | CLSLoss:0.1428 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1586 | MainLoss:0.1586 | SPLoss:0.0013 | CLSLoss:0.1428 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1794 | MainLoss:1.1794 | SPLoss:0.0013 | CLSLoss:0.1428 | AUROC:0.8838\n",
      "\n",
      "Epoch: [543 | 1000] LR: 0.001028\n",
      "Train | 16/16 | Loss:0.0623 | MainLoss:0.0478 | Alpha:0.4894 | SPLoss:0.0013 | CLSLoss:0.1428 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1571 | MainLoss:0.1571 | SPLoss:0.0013 | CLSLoss:0.1429 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1917 | MainLoss:1.1917 | SPLoss:0.0013 | CLSLoss:0.1429 | AUROC:0.8831\n",
      "\n",
      "Epoch: [544 | 1000] LR: 0.001025\n",
      "Train | 16/16 | Loss:0.0610 | MainLoss:0.0466 | Alpha:0.4901 | SPLoss:0.0013 | CLSLoss:0.1429 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1570 | MainLoss:0.1570 | SPLoss:0.0014 | CLSLoss:0.1430 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1942 | MainLoss:1.1942 | SPLoss:0.0014 | CLSLoss:0.1430 | AUROC:0.8832\n",
      "\n",
      "Epoch: [545 | 1000] LR: 0.001022\n",
      "Train | 16/16 | Loss:0.0772 | MainLoss:0.0628 | Alpha:0.4860 | SPLoss:0.0014 | CLSLoss:0.1429 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1567 | MainLoss:0.1567 | SPLoss:0.0014 | CLSLoss:0.1429 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1908 | MainLoss:1.1908 | SPLoss:0.0014 | CLSLoss:0.1429 | AUROC:0.8836\n",
      "\n",
      "Epoch: [546 | 1000] LR: 0.001019\n",
      "Train | 16/16 | Loss:0.0732 | MainLoss:0.0588 | Alpha:0.4867 | SPLoss:0.0014 | CLSLoss:0.1428 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1552 | MainLoss:0.1552 | SPLoss:0.0014 | CLSLoss:0.1428 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1980 | MainLoss:1.1980 | SPLoss:0.0014 | CLSLoss:0.1428 | AUROC:0.8837\n",
      "\n",
      "Epoch: [547 | 1000] LR: 0.001016\n",
      "Train | 16/16 | Loss:0.0669 | MainLoss:0.0525 | Alpha:0.4877 | SPLoss:0.0014 | CLSLoss:0.1427 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1567 | MainLoss:0.1567 | SPLoss:0.0015 | CLSLoss:0.1428 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1907 | MainLoss:1.1907 | SPLoss:0.0015 | CLSLoss:0.1428 | AUROC:0.8842\n",
      "\n",
      "Epoch: [548 | 1000] LR: 0.001013\n",
      "Train | 16/16 | Loss:0.0716 | MainLoss:0.0572 | Alpha:0.4871 | SPLoss:0.0015 | CLSLoss:0.1427 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1587 | MainLoss:0.1587 | SPLoss:0.0015 | CLSLoss:0.1427 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1777 | MainLoss:1.1777 | SPLoss:0.0015 | CLSLoss:0.1427 | AUROC:0.8845\n",
      "\n",
      "Epoch: [549 | 1000] LR: 0.001009\n",
      "Train | 16/16 | Loss:0.0790 | MainLoss:0.0646 | Alpha:0.4852 | SPLoss:0.0015 | CLSLoss:0.1427 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1583 | MainLoss:0.1583 | SPLoss:0.0016 | CLSLoss:0.1427 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1769 | MainLoss:1.1769 | SPLoss:0.0016 | CLSLoss:0.1427 | AUROC:0.8851\n",
      "\n",
      "Epoch: [550 | 1000] LR: 0.001006\n",
      "Train | 16/16 | Loss:0.0642 | MainLoss:0.0498 | Alpha:0.4893 | SPLoss:0.0016 | CLSLoss:0.1427 | AUROC:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 32/16 | Loss:0.1591 | MainLoss:0.1591 | SPLoss:0.0016 | CLSLoss:0.1428 | AUROC:0.9903\n",
      "Test | 128/16 | Loss:1.1750 | MainLoss:1.1750 | SPLoss:0.0016 | CLSLoss:0.1428 | AUROC:0.8853\n",
      "\n",
      "Epoch: [551 | 1000] LR: 0.001003\n",
      "Train | 16/16 | Loss:0.0823 | MainLoss:0.0679 | Alpha:0.4838 | SPLoss:0.0016 | CLSLoss:0.1427 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1586 | MainLoss:0.1586 | SPLoss:0.0016 | CLSLoss:0.1426 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1763 | MainLoss:1.1763 | SPLoss:0.0016 | CLSLoss:0.1426 | AUROC:0.8854\n",
      "\n",
      "Epoch: [552 | 1000] LR: 0.001000\n",
      "Train | 16/16 | Loss:0.0721 | MainLoss:0.0576 | Alpha:0.4878 | SPLoss:0.0017 | CLSLoss:0.1426 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1576 | MainLoss:0.1576 | SPLoss:0.0017 | CLSLoss:0.1426 | AUROC:0.9910\n",
      "Test | 128/16 | Loss:1.1818 | MainLoss:1.1818 | SPLoss:0.0017 | CLSLoss:0.1426 | AUROC:0.8851\n",
      "\n",
      "Epoch: [553 | 1000] LR: 0.000997\n",
      "Train | 16/16 | Loss:0.0778 | MainLoss:0.0634 | Alpha:0.4853 | SPLoss:0.0017 | CLSLoss:0.1424 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1582 | MainLoss:0.1582 | SPLoss:0.0017 | CLSLoss:0.1424 | AUROC:0.9908\n",
      "Test | 128/16 | Loss:1.1743 | MainLoss:1.1743 | SPLoss:0.0017 | CLSLoss:0.1424 | AUROC:0.8857\n",
      "\n",
      "Epoch: [554 | 1000] LR: 0.000994\n",
      "Train | 16/16 | Loss:0.0734 | MainLoss:0.0590 | Alpha:0.4865 | SPLoss:0.0017 | CLSLoss:0.1424 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1594 | MainLoss:0.1594 | SPLoss:0.0018 | CLSLoss:0.1423 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1675 | MainLoss:1.1675 | SPLoss:0.0018 | CLSLoss:0.1423 | AUROC:0.8864\n",
      "\n",
      "Epoch: [555 | 1000] LR: 0.000991\n",
      "Train | 16/16 | Loss:0.0720 | MainLoss:0.0576 | Alpha:0.4865 | SPLoss:0.0018 | CLSLoss:0.1424 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1587 | MainLoss:0.1587 | SPLoss:0.0018 | CLSLoss:0.1423 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1708 | MainLoss:1.1708 | SPLoss:0.0018 | CLSLoss:0.1423 | AUROC:0.8859\n",
      "\n",
      "Epoch: [556 | 1000] LR: 0.000987\n",
      "Train | 16/16 | Loss:0.0612 | MainLoss:0.0468 | Alpha:0.4890 | SPLoss:0.0018 | CLSLoss:0.1424 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0018 | CLSLoss:0.1425 | AUROC:0.9908\n",
      "Test | 128/16 | Loss:1.1766 | MainLoss:1.1766 | SPLoss:0.0018 | CLSLoss:0.1425 | AUROC:0.8850\n",
      "\n",
      "Epoch: [557 | 1000] LR: 0.000984\n",
      "Train | 16/16 | Loss:0.0715 | MainLoss:0.0570 | Alpha:0.4876 | SPLoss:0.0019 | CLSLoss:0.1424 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1570 | MainLoss:0.1570 | SPLoss:0.0019 | CLSLoss:0.1425 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1870 | MainLoss:1.1870 | SPLoss:0.0019 | CLSLoss:0.1425 | AUROC:0.8839\n",
      "\n",
      "Epoch: [558 | 1000] LR: 0.000981\n",
      "Train | 16/16 | Loss:0.0726 | MainLoss:0.0582 | Alpha:0.4871 | SPLoss:0.0019 | CLSLoss:0.1425 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1581 | MainLoss:0.1581 | SPLoss:0.0019 | CLSLoss:0.1424 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1805 | MainLoss:1.1805 | SPLoss:0.0019 | CLSLoss:0.1424 | AUROC:0.8847\n",
      "\n",
      "Epoch: [559 | 1000] LR: 0.000978\n",
      "Train | 16/16 | Loss:0.0802 | MainLoss:0.0658 | Alpha:0.4855 | SPLoss:0.0019 | CLSLoss:0.1424 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1565 | MainLoss:0.1565 | SPLoss:0.0020 | CLSLoss:0.1423 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1850 | MainLoss:1.1850 | SPLoss:0.0020 | CLSLoss:0.1423 | AUROC:0.8848\n",
      "\n",
      "Epoch: [560 | 1000] LR: 0.000975\n",
      "Train | 16/16 | Loss:0.0623 | MainLoss:0.0478 | Alpha:0.4894 | SPLoss:0.0020 | CLSLoss:0.1424 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1568 | MainLoss:0.1568 | SPLoss:0.0020 | CLSLoss:0.1424 | AUROC:0.9908\n",
      "Test | 128/16 | Loss:1.1854 | MainLoss:1.1854 | SPLoss:0.0020 | CLSLoss:0.1424 | AUROC:0.8847\n",
      "\n",
      "Epoch: [561 | 1000] LR: 0.000972\n",
      "Train | 16/16 | Loss:0.0772 | MainLoss:0.0627 | Alpha:0.4850 | SPLoss:0.0020 | CLSLoss:0.1424 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1573 | MainLoss:0.1573 | SPLoss:0.0021 | CLSLoss:0.1424 | AUROC:0.9909\n",
      "Test | 128/16 | Loss:1.1839 | MainLoss:1.1839 | SPLoss:0.0021 | CLSLoss:0.1424 | AUROC:0.8843\n",
      "\n",
      "Epoch: [562 | 1000] LR: 0.000969\n",
      "Train | 16/16 | Loss:0.0754 | MainLoss:0.0609 | Alpha:0.4861 | SPLoss:0.0021 | CLSLoss:0.1423 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1572 | MainLoss:0.1572 | SPLoss:0.0021 | CLSLoss:0.1423 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1846 | MainLoss:1.1846 | SPLoss:0.0021 | CLSLoss:0.1423 | AUROC:0.8840\n",
      "\n",
      "Epoch: [563 | 1000] LR: 0.000965\n",
      "Train | 16/16 | Loss:0.0673 | MainLoss:0.0529 | Alpha:0.4882 | SPLoss:0.0021 | CLSLoss:0.1423 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1570 | MainLoss:0.1570 | SPLoss:0.0021 | CLSLoss:0.1423 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1858 | MainLoss:1.1858 | SPLoss:0.0021 | CLSLoss:0.1423 | AUROC:0.8836\n",
      "\n",
      "Epoch: [564 | 1000] LR: 0.000962\n",
      "Train | 16/16 | Loss:0.0822 | MainLoss:0.0678 | Alpha:0.4845 | SPLoss:0.0022 | CLSLoss:0.1422 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1583 | MainLoss:0.1583 | SPLoss:0.0022 | CLSLoss:0.1421 | AUROC:0.9908\n",
      "Test | 128/16 | Loss:1.1728 | MainLoss:1.1728 | SPLoss:0.0022 | CLSLoss:0.1421 | AUROC:0.8847\n",
      "\n",
      "Epoch: [565 | 1000] LR: 0.000959\n",
      "Train | 16/16 | Loss:0.0695 | MainLoss:0.0551 | Alpha:0.4878 | SPLoss:0.0022 | CLSLoss:0.1421 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1599 | MainLoss:0.1599 | SPLoss:0.0022 | CLSLoss:0.1421 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1660 | MainLoss:1.1660 | SPLoss:0.0022 | CLSLoss:0.1421 | AUROC:0.8852\n",
      "\n",
      "Epoch: [566 | 1000] LR: 0.000956\n",
      "Train | 16/16 | Loss:0.0787 | MainLoss:0.0643 | Alpha:0.4854 | SPLoss:0.0023 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1597 | MainLoss:0.1597 | SPLoss:0.0023 | CLSLoss:0.1420 | AUROC:0.9908\n",
      "Test | 128/16 | Loss:1.1648 | MainLoss:1.1648 | SPLoss:0.0023 | CLSLoss:0.1420 | AUROC:0.8852\n",
      "\n",
      "Epoch: [567 | 1000] LR: 0.000953\n",
      "Train | 16/16 | Loss:0.0752 | MainLoss:0.0607 | Alpha:0.4853 | SPLoss:0.0023 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1600 | MainLoss:0.1600 | SPLoss:0.0023 | CLSLoss:0.1420 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1673 | MainLoss:1.1673 | SPLoss:0.0023 | CLSLoss:0.1420 | AUROC:0.8848\n",
      "\n",
      "Epoch: [568 | 1000] LR: 0.000950\n",
      "Train | 16/16 | Loss:0.0748 | MainLoss:0.0604 | Alpha:0.4872 | SPLoss:0.0023 | CLSLoss:0.1419 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1594 | MainLoss:0.1594 | SPLoss:0.0024 | CLSLoss:0.1419 | AUROC:0.9908\n",
      "Test | 128/16 | Loss:1.1702 | MainLoss:1.1702 | SPLoss:0.0024 | CLSLoss:0.1419 | AUROC:0.8849\n",
      "\n",
      "Epoch: [569 | 1000] LR: 0.000947\n",
      "Train | 16/16 | Loss:0.0746 | MainLoss:0.0602 | Alpha:0.4861 | SPLoss:0.0024 | CLSLoss:0.1419 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1606 | MainLoss:0.1606 | SPLoss:0.0024 | CLSLoss:0.1419 | AUROC:0.9909\n",
      "Test | 128/16 | Loss:1.1629 | MainLoss:1.1629 | SPLoss:0.0024 | CLSLoss:0.1419 | AUROC:0.8848\n",
      "\n",
      "Epoch: [570 | 1000] LR: 0.000943\n",
      "Train | 16/16 | Loss:0.0845 | MainLoss:0.0701 | Alpha:0.4838 | SPLoss:0.0024 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1589 | MainLoss:0.1589 | SPLoss:0.0025 | CLSLoss:0.1417 | AUROC:0.9908\n",
      "Test | 128/16 | Loss:1.1689 | MainLoss:1.1689 | SPLoss:0.0025 | CLSLoss:0.1417 | AUROC:0.8846\n",
      "\n",
      "Epoch: [571 | 1000] LR: 0.000940\n",
      "Train | 16/16 | Loss:0.0650 | MainLoss:0.0505 | Alpha:0.4887 | SPLoss:0.0025 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1580 | MainLoss:0.1580 | SPLoss:0.0025 | CLSLoss:0.1417 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1763 | MainLoss:1.1763 | SPLoss:0.0025 | CLSLoss:0.1417 | AUROC:0.8846\n",
      "\n",
      "Epoch: [572 | 1000] LR: 0.000937\n",
      "Train | 16/16 | Loss:0.0815 | MainLoss:0.0671 | Alpha:0.4854 | SPLoss:0.0025 | CLSLoss:0.1417 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1567 | MainLoss:0.1567 | SPLoss:0.0026 | CLSLoss:0.1416 | AUROC:0.9904\n",
      "Test | 128/16 | Loss:1.1820 | MainLoss:1.1820 | SPLoss:0.0026 | CLSLoss:0.1416 | AUROC:0.8837\n",
      "\n",
      "Epoch: [573 | 1000] LR: 0.000934\n",
      "Train | 16/16 | Loss:0.0656 | MainLoss:0.0511 | Alpha:0.4890 | SPLoss:0.0026 | CLSLoss:0.1416 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1573 | MainLoss:0.1573 | SPLoss:0.0026 | CLSLoss:0.1417 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1792 | MainLoss:1.1792 | SPLoss:0.0026 | CLSLoss:0.1417 | AUROC:0.8844\n",
      "\n",
      "Epoch: [574 | 1000] LR: 0.000931\n",
      "Train | 16/16 | Loss:0.0621 | MainLoss:0.0477 | Alpha:0.4895 | SPLoss:0.0026 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1567 | MainLoss:0.1567 | SPLoss:0.0027 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1868 | MainLoss:1.1868 | SPLoss:0.0027 | CLSLoss:0.1418 | AUROC:0.8838\n",
      "\n",
      "Epoch: [575 | 1000] LR: 0.000928\n",
      "Train | 16/16 | Loss:0.0679 | MainLoss:0.0535 | Alpha:0.4881 | SPLoss:0.0027 | CLSLoss:0.1418 | AUROC:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 32/16 | Loss:0.1574 | MainLoss:0.1574 | SPLoss:0.0027 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1837 | MainLoss:1.1837 | SPLoss:0.0027 | CLSLoss:0.1418 | AUROC:0.8839\n",
      "\n",
      "Epoch: [576 | 1000] LR: 0.000925\n",
      "Train | 16/16 | Loss:0.0725 | MainLoss:0.0581 | Alpha:0.4869 | SPLoss:0.0027 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1570 | MainLoss:0.1570 | SPLoss:0.0027 | CLSLoss:0.1418 | AUROC:0.9909\n",
      "Test | 128/16 | Loss:1.1864 | MainLoss:1.1864 | SPLoss:0.0027 | CLSLoss:0.1418 | AUROC:0.8835\n",
      "\n",
      "Epoch: [577 | 1000] LR: 0.000922\n",
      "Train | 16/16 | Loss:0.0612 | MainLoss:0.0467 | Alpha:0.4899 | SPLoss:0.0027 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1572 | MainLoss:0.1572 | SPLoss:0.0028 | CLSLoss:0.1419 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1878 | MainLoss:1.1878 | SPLoss:0.0028 | CLSLoss:0.1419 | AUROC:0.8838\n",
      "\n",
      "Epoch: [578 | 1000] LR: 0.000918\n",
      "Train | 16/16 | Loss:0.0735 | MainLoss:0.0590 | Alpha:0.4863 | SPLoss:0.0028 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1588 | MainLoss:0.1588 | SPLoss:0.0028 | CLSLoss:0.1419 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1816 | MainLoss:1.1816 | SPLoss:0.0028 | CLSLoss:0.1419 | AUROC:0.8832\n",
      "\n",
      "Epoch: [579 | 1000] LR: 0.000915\n",
      "Train | 16/16 | Loss:0.0645 | MainLoss:0.0500 | Alpha:0.4887 | SPLoss:0.0028 | CLSLoss:0.1419 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1601 | MainLoss:0.1601 | SPLoss:0.0028 | CLSLoss:0.1420 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1763 | MainLoss:1.1763 | SPLoss:0.0028 | CLSLoss:0.1420 | AUROC:0.8837\n",
      "\n",
      "Epoch: [580 | 1000] LR: 0.000912\n",
      "Train | 16/16 | Loss:0.0683 | MainLoss:0.0539 | Alpha:0.4882 | SPLoss:0.0029 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1600 | MainLoss:0.1600 | SPLoss:0.0029 | CLSLoss:0.1420 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1783 | MainLoss:1.1783 | SPLoss:0.0029 | CLSLoss:0.1420 | AUROC:0.8834\n",
      "\n",
      "Epoch: [581 | 1000] LR: 0.000909\n",
      "Train | 16/16 | Loss:0.0681 | MainLoss:0.0537 | Alpha:0.4873 | SPLoss:0.0029 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1607 | MainLoss:0.1607 | SPLoss:0.0029 | CLSLoss:0.1420 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1766 | MainLoss:1.1766 | SPLoss:0.0029 | CLSLoss:0.1420 | AUROC:0.8833\n",
      "\n",
      "Epoch: [582 | 1000] LR: 0.000906\n",
      "Train | 16/16 | Loss:0.0769 | MainLoss:0.0624 | Alpha:0.4853 | SPLoss:0.0029 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0030 | CLSLoss:0.1420 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1897 | MainLoss:1.1897 | SPLoss:0.0030 | CLSLoss:0.1420 | AUROC:0.8828\n",
      "\n",
      "Epoch: [583 | 1000] LR: 0.000903\n",
      "Train | 16/16 | Loss:0.0597 | MainLoss:0.0452 | Alpha:0.4897 | SPLoss:0.0030 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1580 | MainLoss:0.1580 | SPLoss:0.0030 | CLSLoss:0.1421 | AUROC:0.9908\n",
      "Test | 128/16 | Loss:1.1935 | MainLoss:1.1935 | SPLoss:0.0030 | CLSLoss:0.1421 | AUROC:0.8827\n",
      "\n",
      "Epoch: [584 | 1000] LR: 0.000900\n",
      "Train | 16/16 | Loss:0.0635 | MainLoss:0.0490 | Alpha:0.4889 | SPLoss:0.0030 | CLSLoss:0.1421 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1590 | MainLoss:0.1590 | SPLoss:0.0031 | CLSLoss:0.1422 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1912 | MainLoss:1.1912 | SPLoss:0.0031 | CLSLoss:0.1422 | AUROC:0.8827\n",
      "\n",
      "Epoch: [585 | 1000] LR: 0.000897\n",
      "Train | 16/16 | Loss:0.0760 | MainLoss:0.0614 | Alpha:0.4857 | SPLoss:0.0031 | CLSLoss:0.1421 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0031 | CLSLoss:0.1421 | AUROC:0.9909\n",
      "Test | 128/16 | Loss:1.1926 | MainLoss:1.1926 | SPLoss:0.0031 | CLSLoss:0.1421 | AUROC:0.8828\n",
      "\n",
      "Epoch: [586 | 1000] LR: 0.000893\n",
      "Train | 16/16 | Loss:0.0717 | MainLoss:0.0572 | Alpha:0.4872 | SPLoss:0.0031 | CLSLoss:0.1421 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1597 | MainLoss:0.1597 | SPLoss:0.0031 | CLSLoss:0.1421 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1841 | MainLoss:1.1841 | SPLoss:0.0031 | CLSLoss:0.1421 | AUROC:0.8836\n",
      "\n",
      "Epoch: [587 | 1000] LR: 0.000890\n",
      "Train | 16/16 | Loss:0.0745 | MainLoss:0.0600 | Alpha:0.4863 | SPLoss:0.0032 | CLSLoss:0.1421 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1595 | MainLoss:0.1595 | SPLoss:0.0032 | CLSLoss:0.1420 | AUROC:0.9908\n",
      "Test | 128/16 | Loss:1.1854 | MainLoss:1.1854 | SPLoss:0.0032 | CLSLoss:0.1420 | AUROC:0.8838\n",
      "\n",
      "Epoch: [588 | 1000] LR: 0.000887\n",
      "Train | 16/16 | Loss:0.0694 | MainLoss:0.0548 | Alpha:0.4887 | SPLoss:0.0032 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1605 | MainLoss:0.1605 | SPLoss:0.0032 | CLSLoss:0.1420 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1784 | MainLoss:1.1784 | SPLoss:0.0032 | CLSLoss:0.1420 | AUROC:0.8838\n",
      "\n",
      "Epoch: [589 | 1000] LR: 0.000884\n",
      "Train | 16/16 | Loss:0.0731 | MainLoss:0.0585 | Alpha:0.4863 | SPLoss:0.0032 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1593 | MainLoss:0.1593 | SPLoss:0.0033 | CLSLoss:0.1420 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1844 | MainLoss:1.1844 | SPLoss:0.0033 | CLSLoss:0.1420 | AUROC:0.8838\n",
      "\n",
      "Epoch: [590 | 1000] LR: 0.000881\n",
      "Train | 16/16 | Loss:0.0758 | MainLoss:0.0613 | Alpha:0.4867 | SPLoss:0.0033 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1579 | MainLoss:0.1579 | SPLoss:0.0033 | CLSLoss:0.1419 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1908 | MainLoss:1.1908 | SPLoss:0.0033 | CLSLoss:0.1419 | AUROC:0.8837\n",
      "\n",
      "Epoch: [591 | 1000] LR: 0.000878\n",
      "Train | 16/16 | Loss:0.0608 | MainLoss:0.0462 | Alpha:0.4897 | SPLoss:0.0033 | CLSLoss:0.1419 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1594 | MainLoss:0.1594 | SPLoss:0.0033 | CLSLoss:0.1420 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1848 | MainLoss:1.1848 | SPLoss:0.0033 | CLSLoss:0.1420 | AUROC:0.8846\n",
      "\n",
      "Epoch: [592 | 1000] LR: 0.000875\n",
      "Train | 16/16 | Loss:0.0669 | MainLoss:0.0524 | Alpha:0.4883 | SPLoss:0.0034 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1591 | MainLoss:0.1591 | SPLoss:0.0034 | CLSLoss:0.1420 | AUROC:0.9908\n",
      "Test | 128/16 | Loss:1.1870 | MainLoss:1.1870 | SPLoss:0.0034 | CLSLoss:0.1420 | AUROC:0.8844\n",
      "\n",
      "Epoch: [593 | 1000] LR: 0.000872\n",
      "Train | 16/16 | Loss:0.0660 | MainLoss:0.0515 | Alpha:0.4882 | SPLoss:0.0034 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1588 | MainLoss:0.1588 | SPLoss:0.0034 | CLSLoss:0.1420 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1906 | MainLoss:1.1906 | SPLoss:0.0034 | CLSLoss:0.1420 | AUROC:0.8847\n",
      "\n",
      "Epoch: [594 | 1000] LR: 0.000868\n",
      "Train | 16/16 | Loss:0.0627 | MainLoss:0.0482 | Alpha:0.4886 | SPLoss:0.0034 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1601 | MainLoss:0.1601 | SPLoss:0.0034 | CLSLoss:0.1420 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1834 | MainLoss:1.1834 | SPLoss:0.0034 | CLSLoss:0.1420 | AUROC:0.8850\n",
      "\n",
      "Epoch: [595 | 1000] LR: 0.000865\n",
      "Train | 16/16 | Loss:0.0666 | MainLoss:0.0520 | Alpha:0.4883 | SPLoss:0.0035 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1595 | MainLoss:0.1595 | SPLoss:0.0035 | CLSLoss:0.1420 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1856 | MainLoss:1.1856 | SPLoss:0.0035 | CLSLoss:0.1420 | AUROC:0.8851\n",
      "\n",
      "Epoch: [596 | 1000] LR: 0.000862\n",
      "Train | 16/16 | Loss:0.0780 | MainLoss:0.0634 | Alpha:0.4856 | SPLoss:0.0035 | CLSLoss:0.1419 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1581 | MainLoss:0.1581 | SPLoss:0.0035 | CLSLoss:0.1419 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1907 | MainLoss:1.1907 | SPLoss:0.0035 | CLSLoss:0.1419 | AUROC:0.8852\n",
      "\n",
      "Epoch: [597 | 1000] LR: 0.000859\n",
      "Train | 16/16 | Loss:0.0757 | MainLoss:0.0612 | Alpha:0.4859 | SPLoss:0.0035 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1579 | MainLoss:0.1579 | SPLoss:0.0036 | CLSLoss:0.1418 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1890 | MainLoss:1.1890 | SPLoss:0.0036 | CLSLoss:0.1418 | AUROC:0.8852\n",
      "\n",
      "Epoch: [598 | 1000] LR: 0.000856\n",
      "Train | 16/16 | Loss:0.0658 | MainLoss:0.0513 | Alpha:0.4895 | SPLoss:0.0036 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1581 | MainLoss:0.1581 | SPLoss:0.0036 | CLSLoss:0.1418 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1898 | MainLoss:1.1898 | SPLoss:0.0036 | CLSLoss:0.1418 | AUROC:0.8850\n",
      "\n",
      "Epoch: [599 | 1000] LR: 0.000853\n",
      "Train | 16/16 | Loss:0.0634 | MainLoss:0.0489 | Alpha:0.4892 | SPLoss:0.0036 | CLSLoss:0.1419 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1594 | MainLoss:0.1594 | SPLoss:0.0036 | CLSLoss:0.1419 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1849 | MainLoss:1.1849 | SPLoss:0.0036 | CLSLoss:0.1419 | AUROC:0.8855\n",
      "\n",
      "Epoch: [600 | 1000] LR: 0.000850\n",
      "Train | 16/16 | Loss:0.0767 | MainLoss:0.0622 | Alpha:0.4860 | SPLoss:0.0036 | CLSLoss:0.1419 | AUROC:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 32/16 | Loss:0.1589 | MainLoss:0.1589 | SPLoss:0.0037 | CLSLoss:0.1418 | AUROC:0.9904\n",
      "Test | 128/16 | Loss:1.1851 | MainLoss:1.1851 | SPLoss:0.0037 | CLSLoss:0.1418 | AUROC:0.8853\n",
      "\n",
      "Epoch: [601 | 1000] LR: 0.000085\n",
      "Train | 16/16 | Loss:0.0622 | MainLoss:0.0480 | Alpha:0.4892 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1592 | MainLoss:0.1592 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1839 | MainLoss:1.1839 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8854\n",
      "\n",
      "Epoch: [602 | 1000] LR: 0.000084\n",
      "Train | 16/16 | Loss:0.0637 | MainLoss:0.0495 | Alpha:0.4892 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1590 | MainLoss:0.1590 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1851 | MainLoss:1.1851 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8855\n",
      "\n",
      "Epoch: [603 | 1000] LR: 0.000084\n",
      "Train | 16/16 | Loss:0.0758 | MainLoss:0.0616 | Alpha:0.4866 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1591 | MainLoss:0.1591 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1845 | MainLoss:1.1845 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8857\n",
      "\n",
      "Epoch: [604 | 1000] LR: 0.000084\n",
      "Train | 16/16 | Loss:0.0685 | MainLoss:0.0543 | Alpha:0.4880 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1591 | MainLoss:0.1591 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1848 | MainLoss:1.1848 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8853\n",
      "\n",
      "Epoch: [605 | 1000] LR: 0.000083\n",
      "Train | 16/16 | Loss:0.0621 | MainLoss:0.0480 | Alpha:0.4900 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1591 | MainLoss:0.1591 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1850 | MainLoss:1.1850 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8855\n",
      "\n",
      "Epoch: [606 | 1000] LR: 0.000083\n",
      "Train | 16/16 | Loss:0.0661 | MainLoss:0.0519 | Alpha:0.4885 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1592 | MainLoss:0.1592 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1844 | MainLoss:1.1844 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8859\n",
      "\n",
      "Epoch: [607 | 1000] LR: 0.000083\n",
      "Train | 16/16 | Loss:0.0760 | MainLoss:0.0619 | Alpha:0.4863 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1590 | MainLoss:0.1590 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1851 | MainLoss:1.1851 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8858\n",
      "\n",
      "Epoch: [608 | 1000] LR: 0.000082\n",
      "Train | 16/16 | Loss:0.0622 | MainLoss:0.0480 | Alpha:0.4898 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1590 | MainLoss:0.1590 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1855 | MainLoss:1.1855 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8856\n",
      "\n",
      "Epoch: [609 | 1000] LR: 0.000082\n",
      "Train | 16/16 | Loss:0.0686 | MainLoss:0.0544 | Alpha:0.4891 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1592 | MainLoss:0.1592 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1844 | MainLoss:1.1844 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8854\n",
      "\n",
      "Epoch: [610 | 1000] LR: 0.000082\n",
      "Train | 16/16 | Loss:0.0558 | MainLoss:0.0416 | Alpha:0.4908 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1592 | MainLoss:0.1592 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1847 | MainLoss:1.1847 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8856\n",
      "\n",
      "Epoch: [611 | 1000] LR: 0.000082\n",
      "Train | 16/16 | Loss:0.0631 | MainLoss:0.0490 | Alpha:0.4891 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1590 | MainLoss:0.1590 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9904\n",
      "Test | 128/16 | Loss:1.1861 | MainLoss:1.1861 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8850\n",
      "\n",
      "Epoch: [612 | 1000] LR: 0.000081\n",
      "Train | 16/16 | Loss:0.0720 | MainLoss:0.0578 | Alpha:0.4873 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1593 | MainLoss:0.1593 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1844 | MainLoss:1.1844 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8854\n",
      "\n",
      "Epoch: [613 | 1000] LR: 0.000081\n",
      "Train | 16/16 | Loss:0.0591 | MainLoss:0.0449 | Alpha:0.4908 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1592 | MainLoss:0.1592 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1848 | MainLoss:1.1848 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8856\n",
      "\n",
      "Epoch: [614 | 1000] LR: 0.000081\n",
      "Train | 16/16 | Loss:0.0680 | MainLoss:0.0538 | Alpha:0.4879 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1592 | MainLoss:0.1592 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1847 | MainLoss:1.1847 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8854\n",
      "\n",
      "Epoch: [615 | 1000] LR: 0.000080\n",
      "Train | 16/16 | Loss:0.0779 | MainLoss:0.0637 | Alpha:0.4859 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1593 | MainLoss:0.1593 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1838 | MainLoss:1.1838 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8854\n",
      "\n",
      "Epoch: [616 | 1000] LR: 0.000080\n",
      "Train | 16/16 | Loss:0.0696 | MainLoss:0.0554 | Alpha:0.4881 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1593 | MainLoss:0.1593 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9904\n",
      "Test | 128/16 | Loss:1.1835 | MainLoss:1.1835 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8858\n",
      "\n",
      "Epoch: [617 | 1000] LR: 0.000080\n",
      "Train | 16/16 | Loss:0.0617 | MainLoss:0.0475 | Alpha:0.4898 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1592 | MainLoss:0.1592 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9904\n",
      "Test | 128/16 | Loss:1.1843 | MainLoss:1.1843 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8856\n",
      "\n",
      "Epoch: [618 | 1000] LR: 0.000079\n",
      "Train | 16/16 | Loss:0.0711 | MainLoss:0.0569 | Alpha:0.4872 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1593 | MainLoss:0.1593 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1839 | MainLoss:1.1839 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8854\n",
      "\n",
      "Epoch: [619 | 1000] LR: 0.000079\n",
      "Train | 16/16 | Loss:0.0708 | MainLoss:0.0566 | Alpha:0.4884 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1592 | MainLoss:0.1592 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9904\n",
      "Test | 128/16 | Loss:1.1843 | MainLoss:1.1843 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8855\n",
      "\n",
      "Epoch: [620 | 1000] LR: 0.000079\n",
      "Train | 16/16 | Loss:0.0631 | MainLoss:0.0489 | Alpha:0.4890 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1592 | MainLoss:0.1592 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1841 | MainLoss:1.1841 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8855\n",
      "\n",
      "Epoch: [621 | 1000] LR: 0.000078\n",
      "Train | 16/16 | Loss:0.0699 | MainLoss:0.0558 | Alpha:0.4880 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1593 | MainLoss:0.1593 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1839 | MainLoss:1.1839 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8855\n",
      "\n",
      "Epoch: [622 | 1000] LR: 0.000078\n",
      "Train | 16/16 | Loss:0.0775 | MainLoss:0.0633 | Alpha:0.4877 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1592 | MainLoss:0.1592 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1841 | MainLoss:1.1841 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8854\n",
      "\n",
      "Epoch: [623 | 1000] LR: 0.000078\n",
      "Train | 16/16 | Loss:0.0702 | MainLoss:0.0560 | Alpha:0.4880 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1591 | MainLoss:0.1591 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1851 | MainLoss:1.1851 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8857\n",
      "\n",
      "Epoch: [624 | 1000] LR: 0.000078\n",
      "Train | 16/16 | Loss:0.0599 | MainLoss:0.0457 | Alpha:0.4905 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1591 | MainLoss:0.1591 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1854 | MainLoss:1.1854 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8855\n",
      "\n",
      "Epoch: [625 | 1000] LR: 0.000077\n",
      "Train | 16/16 | Loss:0.0576 | MainLoss:0.0434 | Alpha:0.4908 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 32/16 | Loss:0.1590 | MainLoss:0.1590 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1861 | MainLoss:1.1861 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8855\n",
      "\n",
      "Epoch: [626 | 1000] LR: 0.000077\n",
      "Train | 16/16 | Loss:0.0687 | MainLoss:0.0545 | Alpha:0.4879 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1587 | MainLoss:0.1587 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9909\n",
      "Test | 128/16 | Loss:1.1882 | MainLoss:1.1882 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8855\n",
      "\n",
      "Epoch: [627 | 1000] LR: 0.000077\n",
      "Train | 16/16 | Loss:0.0748 | MainLoss:0.0606 | Alpha:0.4865 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1586 | MainLoss:0.1586 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1888 | MainLoss:1.1888 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8852\n",
      "\n",
      "Epoch: [628 | 1000] LR: 0.000076\n",
      "Train | 16/16 | Loss:0.0617 | MainLoss:0.0476 | Alpha:0.4899 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9904\n",
      "Test | 128/16 | Loss:1.1891 | MainLoss:1.1891 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8855\n",
      "\n",
      "Epoch: [629 | 1000] LR: 0.000076\n",
      "Train | 16/16 | Loss:0.0695 | MainLoss:0.0553 | Alpha:0.4876 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9904\n",
      "Test | 128/16 | Loss:1.1894 | MainLoss:1.1894 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8857\n",
      "\n",
      "Epoch: [630 | 1000] LR: 0.000076\n",
      "Train | 16/16 | Loss:0.0706 | MainLoss:0.0564 | Alpha:0.4884 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1583 | MainLoss:0.1583 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9904\n",
      "Test | 128/16 | Loss:1.1905 | MainLoss:1.1905 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8853\n",
      "\n",
      "Epoch: [631 | 1000] LR: 0.000075\n",
      "Train | 16/16 | Loss:0.0719 | MainLoss:0.0577 | Alpha:0.4872 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1895 | MainLoss:1.1895 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8852\n",
      "\n",
      "Epoch: [632 | 1000] LR: 0.000075\n",
      "Train | 16/16 | Loss:0.0724 | MainLoss:0.0582 | Alpha:0.4876 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1893 | MainLoss:1.1893 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8854\n",
      "\n",
      "Epoch: [633 | 1000] LR: 0.000075\n",
      "Train | 16/16 | Loss:0.0748 | MainLoss:0.0606 | Alpha:0.4862 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1586 | MainLoss:0.1586 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1890 | MainLoss:1.1890 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8853\n",
      "\n",
      "Epoch: [634 | 1000] LR: 0.000075\n",
      "Train | 16/16 | Loss:0.0696 | MainLoss:0.0554 | Alpha:0.4881 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1588 | MainLoss:0.1588 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1877 | MainLoss:1.1877 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8858\n",
      "\n",
      "Epoch: [635 | 1000] LR: 0.000074\n",
      "Train | 16/16 | Loss:0.0663 | MainLoss:0.0521 | Alpha:0.4889 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1588 | MainLoss:0.1588 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9904\n",
      "Test | 128/16 | Loss:1.1877 | MainLoss:1.1877 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8855\n",
      "\n",
      "Epoch: [636 | 1000] LR: 0.000074\n",
      "Train | 16/16 | Loss:0.0652 | MainLoss:0.0511 | Alpha:0.4892 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1588 | MainLoss:0.1588 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1875 | MainLoss:1.1875 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8855\n",
      "\n",
      "Epoch: [637 | 1000] LR: 0.000074\n",
      "Train | 16/16 | Loss:0.0776 | MainLoss:0.0634 | Alpha:0.4865 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1588 | MainLoss:0.1588 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1874 | MainLoss:1.1874 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8860\n",
      "\n",
      "Epoch: [638 | 1000] LR: 0.000073\n",
      "Train | 16/16 | Loss:0.0657 | MainLoss:0.0515 | Alpha:0.4884 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1587 | MainLoss:0.1587 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1882 | MainLoss:1.1882 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8855\n",
      "\n",
      "Epoch: [639 | 1000] LR: 0.000073\n",
      "Train | 16/16 | Loss:0.0622 | MainLoss:0.0480 | Alpha:0.4890 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1586 | MainLoss:0.1586 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1891 | MainLoss:1.1891 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8853\n",
      "\n",
      "Epoch: [640 | 1000] LR: 0.000073\n",
      "Train | 16/16 | Loss:0.0780 | MainLoss:0.0638 | Alpha:0.4871 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1895 | MainLoss:1.1895 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8859\n",
      "\n",
      "Epoch: [641 | 1000] LR: 0.000072\n",
      "Train | 16/16 | Loss:0.0626 | MainLoss:0.0485 | Alpha:0.4892 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1898 | MainLoss:1.1898 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8854\n",
      "\n",
      "Epoch: [642 | 1000] LR: 0.000072\n",
      "Train | 16/16 | Loss:0.0731 | MainLoss:0.0589 | Alpha:0.4867 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1586 | MainLoss:0.1586 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9908\n",
      "Test | 128/16 | Loss:1.1887 | MainLoss:1.1887 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8855\n",
      "\n",
      "Epoch: [643 | 1000] LR: 0.000072\n",
      "Train | 16/16 | Loss:0.0728 | MainLoss:0.0586 | Alpha:0.4881 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1586 | MainLoss:0.1586 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1887 | MainLoss:1.1887 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8856\n",
      "\n",
      "Epoch: [644 | 1000] LR: 0.000071\n",
      "Train | 16/16 | Loss:0.0714 | MainLoss:0.0572 | Alpha:0.4871 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1586 | MainLoss:0.1586 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1888 | MainLoss:1.1888 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8855\n",
      "\n",
      "Epoch: [645 | 1000] LR: 0.000071\n",
      "Train | 16/16 | Loss:0.0597 | MainLoss:0.0456 | Alpha:0.4900 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9904\n",
      "Test | 128/16 | Loss:1.1891 | MainLoss:1.1891 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8858\n",
      "\n",
      "Epoch: [646 | 1000] LR: 0.000071\n",
      "Train | 16/16 | Loss:0.0719 | MainLoss:0.0578 | Alpha:0.4871 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9904\n",
      "Test | 128/16 | Loss:1.1890 | MainLoss:1.1890 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8857\n",
      "\n",
      "Epoch: [647 | 1000] LR: 0.000071\n",
      "Train | 16/16 | Loss:0.0659 | MainLoss:0.0517 | Alpha:0.4889 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1584 | MainLoss:0.1584 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1898 | MainLoss:1.1898 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8858\n",
      "\n",
      "Epoch: [648 | 1000] LR: 0.000070\n",
      "Train | 16/16 | Loss:0.0774 | MainLoss:0.0632 | Alpha:0.4866 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1888 | MainLoss:1.1888 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8858\n",
      "\n",
      "Epoch: [649 | 1000] LR: 0.000070\n",
      "Train | 16/16 | Loss:0.0636 | MainLoss:0.0494 | Alpha:0.4897 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1586 | MainLoss:0.1586 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9904\n",
      "Test | 128/16 | Loss:1.1885 | MainLoss:1.1885 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8856\n",
      "\n",
      "Epoch: [650 | 1000] LR: 0.000070\n",
      "Train | 16/16 | Loss:0.0761 | MainLoss:0.0619 | Alpha:0.4866 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 32/16 | Loss:0.1587 | MainLoss:0.1587 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1878 | MainLoss:1.1878 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8857\n",
      "\n",
      "Epoch: [651 | 1000] LR: 0.000069\n",
      "Train | 16/16 | Loss:0.0721 | MainLoss:0.0579 | Alpha:0.4877 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1588 | MainLoss:0.1588 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1870 | MainLoss:1.1870 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8856\n",
      "\n",
      "Epoch: [652 | 1000] LR: 0.000069\n",
      "Train | 16/16 | Loss:0.0637 | MainLoss:0.0495 | Alpha:0.4896 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1589 | MainLoss:0.1589 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1867 | MainLoss:1.1867 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8858\n",
      "\n",
      "Epoch: [653 | 1000] LR: 0.000069\n",
      "Train | 16/16 | Loss:0.0645 | MainLoss:0.0503 | Alpha:0.4883 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1589 | MainLoss:0.1589 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1869 | MainLoss:1.1869 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8852\n",
      "\n",
      "Epoch: [654 | 1000] LR: 0.000069\n",
      "Train | 16/16 | Loss:0.0704 | MainLoss:0.0562 | Alpha:0.4872 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1590 | MainLoss:0.1590 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1865 | MainLoss:1.1865 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8857\n",
      "\n",
      "Epoch: [655 | 1000] LR: 0.000068\n",
      "Train | 16/16 | Loss:0.0606 | MainLoss:0.0464 | Alpha:0.4899 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1591 | MainLoss:0.1591 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1857 | MainLoss:1.1857 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8858\n",
      "\n",
      "Epoch: [656 | 1000] LR: 0.000068\n",
      "Train | 16/16 | Loss:0.0630 | MainLoss:0.0488 | Alpha:0.4898 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1590 | MainLoss:0.1590 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1865 | MainLoss:1.1865 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8857\n",
      "\n",
      "Epoch: [657 | 1000] LR: 0.000068\n",
      "Train | 16/16 | Loss:0.0607 | MainLoss:0.0465 | Alpha:0.4905 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1589 | MainLoss:0.1589 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1873 | MainLoss:1.1873 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8856\n",
      "\n",
      "Epoch: [658 | 1000] LR: 0.000067\n",
      "Train | 16/16 | Loss:0.0625 | MainLoss:0.0483 | Alpha:0.4895 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1589 | MainLoss:0.1589 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1875 | MainLoss:1.1875 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8857\n",
      "\n",
      "Epoch: [659 | 1000] LR: 0.000067\n",
      "Train | 16/16 | Loss:0.0753 | MainLoss:0.0611 | Alpha:0.4860 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1590 | MainLoss:0.1590 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1869 | MainLoss:1.1869 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8856\n",
      "\n",
      "Epoch: [660 | 1000] LR: 0.000067\n",
      "Train | 16/16 | Loss:0.0555 | MainLoss:0.0414 | Alpha:0.4919 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1591 | MainLoss:0.1591 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1867 | MainLoss:1.1867 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8857\n",
      "\n",
      "Epoch: [661 | 1000] LR: 0.000066\n",
      "Train | 16/16 | Loss:0.0614 | MainLoss:0.0473 | Alpha:0.4902 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1590 | MainLoss:0.1590 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1871 | MainLoss:1.1871 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8856\n",
      "\n",
      "Epoch: [662 | 1000] LR: 0.000066\n",
      "Train | 16/16 | Loss:0.0629 | MainLoss:0.0487 | Alpha:0.4898 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1591 | MainLoss:0.1591 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1869 | MainLoss:1.1869 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8858\n",
      "\n",
      "Epoch: [663 | 1000] LR: 0.000066\n",
      "Train | 16/16 | Loss:0.0915 | MainLoss:0.0773 | Alpha:0.4824 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1589 | MainLoss:0.1589 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1876 | MainLoss:1.1876 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8859\n",
      "\n",
      "Epoch: [664 | 1000] LR: 0.000066\n",
      "Train | 16/16 | Loss:0.0735 | MainLoss:0.0594 | Alpha:0.4872 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1588 | MainLoss:0.1588 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1883 | MainLoss:1.1883 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8857\n",
      "\n",
      "Epoch: [665 | 1000] LR: 0.000065\n",
      "Train | 16/16 | Loss:0.0736 | MainLoss:0.0594 | Alpha:0.4871 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1587 | MainLoss:0.1587 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9903\n",
      "Test | 128/16 | Loss:1.1887 | MainLoss:1.1887 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8855\n",
      "\n",
      "Epoch: [666 | 1000] LR: 0.000065\n",
      "Train | 16/16 | Loss:0.0612 | MainLoss:0.0470 | Alpha:0.4904 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1589 | MainLoss:0.1589 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1880 | MainLoss:1.1880 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8859\n",
      "\n",
      "Epoch: [667 | 1000] LR: 0.000065\n",
      "Train | 16/16 | Loss:0.0800 | MainLoss:0.0659 | Alpha:0.4859 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1587 | MainLoss:0.1587 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1885 | MainLoss:1.1885 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8854\n",
      "\n",
      "Epoch: [668 | 1000] LR: 0.000064\n",
      "Train | 16/16 | Loss:0.0730 | MainLoss:0.0588 | Alpha:0.4873 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1586 | MainLoss:0.1586 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1894 | MainLoss:1.1894 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8857\n",
      "\n",
      "Epoch: [669 | 1000] LR: 0.000064\n",
      "Train | 16/16 | Loss:0.0790 | MainLoss:0.0648 | Alpha:0.4856 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9903\n",
      "Test | 128/16 | Loss:1.1896 | MainLoss:1.1896 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8851\n",
      "\n",
      "Epoch: [670 | 1000] LR: 0.000064\n",
      "Train | 16/16 | Loss:0.0759 | MainLoss:0.0617 | Alpha:0.4869 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1586 | MainLoss:0.1586 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1890 | MainLoss:1.1890 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8854\n",
      "\n",
      "Epoch: [671 | 1000] LR: 0.000063\n",
      "Train | 16/16 | Loss:0.0642 | MainLoss:0.0501 | Alpha:0.4892 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1586 | MainLoss:0.1586 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1890 | MainLoss:1.1890 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8855\n",
      "\n",
      "Epoch: [672 | 1000] LR: 0.000063\n",
      "Train | 16/16 | Loss:0.0623 | MainLoss:0.0481 | Alpha:0.4896 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1587 | MainLoss:0.1587 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1886 | MainLoss:1.1886 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8852\n",
      "\n",
      "Epoch: [673 | 1000] LR: 0.000063\n",
      "Train | 16/16 | Loss:0.0647 | MainLoss:0.0505 | Alpha:0.4892 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1587 | MainLoss:0.1587 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1885 | MainLoss:1.1885 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8857\n",
      "\n",
      "Epoch: [674 | 1000] LR: 0.000063\n",
      "Train | 16/16 | Loss:0.0658 | MainLoss:0.0516 | Alpha:0.4884 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1587 | MainLoss:0.1587 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1887 | MainLoss:1.1887 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8856\n",
      "\n",
      "Epoch: [675 | 1000] LR: 0.000062\n",
      "Train | 16/16 | Loss:0.0705 | MainLoss:0.0563 | Alpha:0.4870 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 32/16 | Loss:0.1586 | MainLoss:0.1586 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9908\n",
      "Test | 128/16 | Loss:1.1890 | MainLoss:1.1890 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8854\n",
      "\n",
      "Epoch: [676 | 1000] LR: 0.000062\n",
      "Train | 16/16 | Loss:0.0728 | MainLoss:0.0586 | Alpha:0.4870 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1899 | MainLoss:1.1899 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8853\n",
      "\n",
      "Epoch: [677 | 1000] LR: 0.000062\n",
      "Train | 16/16 | Loss:0.0729 | MainLoss:0.0588 | Alpha:0.4871 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1899 | MainLoss:1.1899 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8854\n",
      "\n",
      "Epoch: [678 | 1000] LR: 0.000061\n",
      "Train | 16/16 | Loss:0.0670 | MainLoss:0.0528 | Alpha:0.4890 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1586 | MainLoss:0.1586 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1896 | MainLoss:1.1896 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8856\n",
      "\n",
      "Epoch: [679 | 1000] LR: 0.000061\n",
      "Train | 16/16 | Loss:0.0689 | MainLoss:0.0547 | Alpha:0.4885 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1896 | MainLoss:1.1896 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8858\n",
      "\n",
      "Epoch: [680 | 1000] LR: 0.000061\n",
      "Train | 16/16 | Loss:0.0709 | MainLoss:0.0567 | Alpha:0.4874 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1586 | MainLoss:0.1586 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9908\n",
      "Test | 128/16 | Loss:1.1895 | MainLoss:1.1895 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8856\n",
      "\n",
      "Epoch: [681 | 1000] LR: 0.000061\n",
      "Train | 16/16 | Loss:0.0525 | MainLoss:0.0383 | Alpha:0.4919 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1586 | MainLoss:0.1586 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1895 | MainLoss:1.1895 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8855\n",
      "\n",
      "Epoch: [682 | 1000] LR: 0.000060\n",
      "Train | 16/16 | Loss:0.0721 | MainLoss:0.0579 | Alpha:0.4877 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1587 | MainLoss:0.1587 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1890 | MainLoss:1.1890 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8855\n",
      "\n",
      "Epoch: [683 | 1000] LR: 0.000060\n",
      "Train | 16/16 | Loss:0.0556 | MainLoss:0.0414 | Alpha:0.4918 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1587 | MainLoss:0.1587 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1891 | MainLoss:1.1891 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8859\n",
      "\n",
      "Epoch: [684 | 1000] LR: 0.000060\n",
      "Train | 16/16 | Loss:0.0600 | MainLoss:0.0458 | Alpha:0.4894 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1586 | MainLoss:0.1586 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1900 | MainLoss:1.1900 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8858\n",
      "\n",
      "Epoch: [685 | 1000] LR: 0.000059\n",
      "Train | 16/16 | Loss:0.0672 | MainLoss:0.0530 | Alpha:0.4886 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1586 | MainLoss:0.1586 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1898 | MainLoss:1.1898 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8853\n",
      "\n",
      "Epoch: [686 | 1000] LR: 0.000059\n",
      "Train | 16/16 | Loss:0.0771 | MainLoss:0.0629 | Alpha:0.4863 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1586 | MainLoss:0.1586 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1899 | MainLoss:1.1899 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8852\n",
      "\n",
      "Epoch: [687 | 1000] LR: 0.000059\n",
      "Train | 16/16 | Loss:0.0700 | MainLoss:0.0558 | Alpha:0.4878 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1904 | MainLoss:1.1904 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8855\n",
      "\n",
      "Epoch: [688 | 1000] LR: 0.000059\n",
      "Train | 16/16 | Loss:0.0659 | MainLoss:0.0518 | Alpha:0.4890 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1903 | MainLoss:1.1903 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8855\n",
      "\n",
      "Epoch: [689 | 1000] LR: 0.000058\n",
      "Train | 16/16 | Loss:0.0788 | MainLoss:0.0647 | Alpha:0.4856 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1584 | MainLoss:0.1584 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1911 | MainLoss:1.1911 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8856\n",
      "\n",
      "Epoch: [690 | 1000] LR: 0.000058\n",
      "Train | 16/16 | Loss:0.0742 | MainLoss:0.0600 | Alpha:0.4870 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1584 | MainLoss:0.1584 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1909 | MainLoss:1.1909 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8858\n",
      "\n",
      "Epoch: [691 | 1000] LR: 0.000058\n",
      "Train | 16/16 | Loss:0.0570 | MainLoss:0.0429 | Alpha:0.4908 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1584 | MainLoss:0.1584 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1910 | MainLoss:1.1910 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8854\n",
      "\n",
      "Epoch: [692 | 1000] LR: 0.000057\n",
      "Train | 16/16 | Loss:0.0670 | MainLoss:0.0528 | Alpha:0.4876 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1586 | MainLoss:0.1586 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9904\n",
      "Test | 128/16 | Loss:1.1900 | MainLoss:1.1900 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8858\n",
      "\n",
      "Epoch: [693 | 1000] LR: 0.000057\n",
      "Train | 16/16 | Loss:0.0649 | MainLoss:0.0507 | Alpha:0.4891 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1903 | MainLoss:1.1903 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8856\n",
      "\n",
      "Epoch: [694 | 1000] LR: 0.000057\n",
      "Train | 16/16 | Loss:0.0598 | MainLoss:0.0457 | Alpha:0.4907 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1586 | MainLoss:0.1586 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1905 | MainLoss:1.1905 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8856\n",
      "\n",
      "Epoch: [695 | 1000] LR: 0.000057\n",
      "Train | 16/16 | Loss:0.0683 | MainLoss:0.0541 | Alpha:0.4888 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1586 | MainLoss:0.1586 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1903 | MainLoss:1.1903 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8856\n",
      "\n",
      "Epoch: [696 | 1000] LR: 0.000056\n",
      "Train | 16/16 | Loss:0.0718 | MainLoss:0.0576 | Alpha:0.4870 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1586 | MainLoss:0.1586 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1902 | MainLoss:1.1902 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8857\n",
      "\n",
      "Epoch: [697 | 1000] LR: 0.000056\n",
      "Train | 16/16 | Loss:0.0611 | MainLoss:0.0469 | Alpha:0.4897 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9908\n",
      "Test | 128/16 | Loss:1.1908 | MainLoss:1.1908 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8855\n",
      "\n",
      "Epoch: [698 | 1000] LR: 0.000056\n",
      "Train | 16/16 | Loss:0.0697 | MainLoss:0.0556 | Alpha:0.4877 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1908 | MainLoss:1.1908 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8856\n",
      "\n",
      "Epoch: [699 | 1000] LR: 0.000055\n",
      "Train | 16/16 | Loss:0.0674 | MainLoss:0.0532 | Alpha:0.4885 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1584 | MainLoss:0.1584 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1914 | MainLoss:1.1914 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8857\n",
      "\n",
      "Epoch: [700 | 1000] LR: 0.000055\n",
      "Train | 16/16 | Loss:0.0681 | MainLoss:0.0540 | Alpha:0.4889 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 32/16 | Loss:0.1583 | MainLoss:0.1583 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1920 | MainLoss:1.1920 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8858\n",
      "\n",
      "Epoch: [701 | 1000] LR: 0.000055\n",
      "Train | 16/16 | Loss:0.0746 | MainLoss:0.0605 | Alpha:0.4866 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1582 | MainLoss:0.1582 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1923 | MainLoss:1.1923 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8853\n",
      "\n",
      "Epoch: [702 | 1000] LR: 0.000055\n",
      "Train | 16/16 | Loss:0.0623 | MainLoss:0.0482 | Alpha:0.4899 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1584 | MainLoss:0.1584 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1917 | MainLoss:1.1917 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8857\n",
      "\n",
      "Epoch: [703 | 1000] LR: 0.000054\n",
      "Train | 16/16 | Loss:0.0691 | MainLoss:0.0549 | Alpha:0.4881 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1583 | MainLoss:0.1583 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9904\n",
      "Test | 128/16 | Loss:1.1921 | MainLoss:1.1921 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8856\n",
      "\n",
      "Epoch: [704 | 1000] LR: 0.000054\n",
      "Train | 16/16 | Loss:0.0742 | MainLoss:0.0600 | Alpha:0.4883 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1582 | MainLoss:0.1582 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1925 | MainLoss:1.1925 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8852\n",
      "\n",
      "Epoch: [705 | 1000] LR: 0.000054\n",
      "Train | 16/16 | Loss:0.0602 | MainLoss:0.0460 | Alpha:0.4899 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1582 | MainLoss:0.1582 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9904\n",
      "Test | 128/16 | Loss:1.1927 | MainLoss:1.1927 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8857\n",
      "\n",
      "Epoch: [706 | 1000] LR: 0.000053\n",
      "Train | 16/16 | Loss:0.0655 | MainLoss:0.0513 | Alpha:0.4896 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1582 | MainLoss:0.1582 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8855\n",
      "\n",
      "Epoch: [707 | 1000] LR: 0.000053\n",
      "Train | 16/16 | Loss:0.0653 | MainLoss:0.0512 | Alpha:0.4890 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1582 | MainLoss:0.1582 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1929 | MainLoss:1.1929 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8857\n",
      "\n",
      "Epoch: [708 | 1000] LR: 0.000053\n",
      "Train | 16/16 | Loss:0.0677 | MainLoss:0.0535 | Alpha:0.4884 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1582 | MainLoss:0.1582 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1930 | MainLoss:1.1930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8860\n",
      "\n",
      "Epoch: [709 | 1000] LR: 0.000053\n",
      "Train | 16/16 | Loss:0.0676 | MainLoss:0.0534 | Alpha:0.4881 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1581 | MainLoss:0.1581 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1935 | MainLoss:1.1935 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8853\n",
      "\n",
      "Epoch: [710 | 1000] LR: 0.000052\n",
      "Train | 16/16 | Loss:0.0649 | MainLoss:0.0507 | Alpha:0.4896 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1581 | MainLoss:0.1581 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1941 | MainLoss:1.1941 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8853\n",
      "\n",
      "Epoch: [711 | 1000] LR: 0.000052\n",
      "Train | 16/16 | Loss:0.0705 | MainLoss:0.0563 | Alpha:0.4877 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1580 | MainLoss:0.1580 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1941 | MainLoss:1.1941 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8856\n",
      "\n",
      "Epoch: [712 | 1000] LR: 0.000052\n",
      "Train | 16/16 | Loss:0.0769 | MainLoss:0.0628 | Alpha:0.4860 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1580 | MainLoss:0.1580 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1941 | MainLoss:1.1941 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8858\n",
      "\n",
      "Epoch: [713 | 1000] LR: 0.000052\n",
      "Train | 16/16 | Loss:0.0662 | MainLoss:0.0521 | Alpha:0.4891 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1581 | MainLoss:0.1581 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1941 | MainLoss:1.1941 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8853\n",
      "\n",
      "Epoch: [714 | 1000] LR: 0.000051\n",
      "Train | 16/16 | Loss:0.0705 | MainLoss:0.0563 | Alpha:0.4876 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1581 | MainLoss:0.1581 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9904\n",
      "Test | 128/16 | Loss:1.1939 | MainLoss:1.1939 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8855\n",
      "\n",
      "Epoch: [715 | 1000] LR: 0.000051\n",
      "Train | 16/16 | Loss:0.0655 | MainLoss:0.0513 | Alpha:0.4883 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1582 | MainLoss:0.1582 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1935 | MainLoss:1.1935 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8857\n",
      "\n",
      "Epoch: [716 | 1000] LR: 0.000051\n",
      "Train | 16/16 | Loss:0.0808 | MainLoss:0.0666 | Alpha:0.4853 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1583 | MainLoss:0.1583 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1930 | MainLoss:1.1930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8855\n",
      "\n",
      "Epoch: [717 | 1000] LR: 0.000050\n",
      "Train | 16/16 | Loss:0.0753 | MainLoss:0.0611 | Alpha:0.4867 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1583 | MainLoss:0.1583 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1927 | MainLoss:1.1927 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8857\n",
      "\n",
      "Epoch: [718 | 1000] LR: 0.000050\n",
      "Train | 16/16 | Loss:0.0628 | MainLoss:0.0486 | Alpha:0.4889 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1583 | MainLoss:0.1583 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1929 | MainLoss:1.1929 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8857\n",
      "\n",
      "Epoch: [719 | 1000] LR: 0.000050\n",
      "Train | 16/16 | Loss:0.0633 | MainLoss:0.0491 | Alpha:0.4892 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1583 | MainLoss:0.1583 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1930 | MainLoss:1.1930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8857\n",
      "\n",
      "Epoch: [720 | 1000] LR: 0.000050\n",
      "Train | 16/16 | Loss:0.0654 | MainLoss:0.0513 | Alpha:0.4895 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1584 | MainLoss:0.1584 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1925 | MainLoss:1.1925 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8856\n",
      "\n",
      "Epoch: [721 | 1000] LR: 0.000049\n",
      "Train | 16/16 | Loss:0.0665 | MainLoss:0.0524 | Alpha:0.4888 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1584 | MainLoss:0.1584 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1927 | MainLoss:1.1927 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8857\n",
      "\n",
      "Epoch: [722 | 1000] LR: 0.000049\n",
      "Train | 16/16 | Loss:0.0787 | MainLoss:0.0645 | Alpha:0.4850 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1583 | MainLoss:0.1583 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1930 | MainLoss:1.1930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8852\n",
      "\n",
      "Epoch: [723 | 1000] LR: 0.000049\n",
      "Train | 16/16 | Loss:0.0666 | MainLoss:0.0524 | Alpha:0.4878 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1583 | MainLoss:0.1583 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8851\n",
      "\n",
      "Epoch: [724 | 1000] LR: 0.000049\n",
      "Train | 16/16 | Loss:0.0714 | MainLoss:0.0573 | Alpha:0.4880 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1583 | MainLoss:0.1583 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1929 | MainLoss:1.1929 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8854\n",
      "\n",
      "Epoch: [725 | 1000] LR: 0.000048\n",
      "Train | 16/16 | Loss:0.0626 | MainLoss:0.0484 | Alpha:0.4896 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 32/16 | Loss:0.1583 | MainLoss:0.1583 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9908\n",
      "Test | 128/16 | Loss:1.1933 | MainLoss:1.1933 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8855\n",
      "\n",
      "Epoch: [726 | 1000] LR: 0.000048\n",
      "Train | 16/16 | Loss:0.0590 | MainLoss:0.0448 | Alpha:0.4900 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1583 | MainLoss:0.1583 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1934 | MainLoss:1.1934 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8857\n",
      "\n",
      "Epoch: [727 | 1000] LR: 0.000048\n",
      "Train | 16/16 | Loss:0.0714 | MainLoss:0.0572 | Alpha:0.4879 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1582 | MainLoss:0.1582 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1943 | MainLoss:1.1943 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8851\n",
      "\n",
      "Epoch: [728 | 1000] LR: 0.000047\n",
      "Train | 16/16 | Loss:0.0616 | MainLoss:0.0474 | Alpha:0.4902 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1581 | MainLoss:0.1581 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1948 | MainLoss:1.1948 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8856\n",
      "\n",
      "Epoch: [729 | 1000] LR: 0.000047\n",
      "Train | 16/16 | Loss:0.0745 | MainLoss:0.0604 | Alpha:0.4862 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1582 | MainLoss:0.1582 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1943 | MainLoss:1.1943 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8855\n",
      "\n",
      "Epoch: [730 | 1000] LR: 0.000047\n",
      "Train | 16/16 | Loss:0.0759 | MainLoss:0.0617 | Alpha:0.4866 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1581 | MainLoss:0.1581 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9904\n",
      "Test | 128/16 | Loss:1.1945 | MainLoss:1.1945 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8852\n",
      "\n",
      "Epoch: [731 | 1000] LR: 0.000047\n",
      "Train | 16/16 | Loss:0.0654 | MainLoss:0.0513 | Alpha:0.4896 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1582 | MainLoss:0.1582 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1939 | MainLoss:1.1939 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8854\n",
      "\n",
      "Epoch: [732 | 1000] LR: 0.000046\n",
      "Train | 16/16 | Loss:0.0577 | MainLoss:0.0435 | Alpha:0.4906 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1582 | MainLoss:0.1582 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9904\n",
      "Test | 128/16 | Loss:1.1940 | MainLoss:1.1940 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8853\n",
      "\n",
      "Epoch: [733 | 1000] LR: 0.000046\n",
      "Train | 16/16 | Loss:0.0633 | MainLoss:0.0491 | Alpha:0.4889 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1582 | MainLoss:0.1582 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1940 | MainLoss:1.1940 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8857\n",
      "\n",
      "Epoch: [734 | 1000] LR: 0.000046\n",
      "Train | 16/16 | Loss:0.0664 | MainLoss:0.0523 | Alpha:0.4893 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1581 | MainLoss:0.1581 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9903\n",
      "Test | 128/16 | Loss:1.1944 | MainLoss:1.1944 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8854\n",
      "\n",
      "Epoch: [735 | 1000] LR: 0.000046\n",
      "Train | 16/16 | Loss:0.0691 | MainLoss:0.0550 | Alpha:0.4879 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1581 | MainLoss:0.1581 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1945 | MainLoss:1.1945 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8854\n",
      "\n",
      "Epoch: [736 | 1000] LR: 0.000045\n",
      "Train | 16/16 | Loss:0.0738 | MainLoss:0.0596 | Alpha:0.4871 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1582 | MainLoss:0.1582 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1941 | MainLoss:1.1941 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8854\n",
      "\n",
      "Epoch: [737 | 1000] LR: 0.000045\n",
      "Train | 16/16 | Loss:0.0692 | MainLoss:0.0550 | Alpha:0.4883 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1583 | MainLoss:0.1583 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9904\n",
      "Test | 128/16 | Loss:1.1937 | MainLoss:1.1937 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8856\n",
      "\n",
      "Epoch: [738 | 1000] LR: 0.000045\n",
      "Train | 16/16 | Loss:0.0667 | MainLoss:0.0525 | Alpha:0.4892 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1583 | MainLoss:0.1583 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1935 | MainLoss:1.1935 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8856\n",
      "\n",
      "Epoch: [739 | 1000] LR: 0.000045\n",
      "Train | 16/16 | Loss:0.0736 | MainLoss:0.0595 | Alpha:0.4862 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1583 | MainLoss:0.1583 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1936 | MainLoss:1.1936 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8857\n",
      "\n",
      "Epoch: [740 | 1000] LR: 0.000044\n",
      "Train | 16/16 | Loss:0.0751 | MainLoss:0.0610 | Alpha:0.4863 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1582 | MainLoss:0.1582 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1937 | MainLoss:1.1937 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8854\n",
      "\n",
      "Epoch: [741 | 1000] LR: 0.000044\n",
      "Train | 16/16 | Loss:0.0609 | MainLoss:0.0467 | Alpha:0.4897 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1583 | MainLoss:0.1583 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1933 | MainLoss:1.1933 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8857\n",
      "\n",
      "Epoch: [742 | 1000] LR: 0.000044\n",
      "Train | 16/16 | Loss:0.0649 | MainLoss:0.0507 | Alpha:0.4892 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1584 | MainLoss:0.1584 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8856\n",
      "\n",
      "Epoch: [743 | 1000] LR: 0.000044\n",
      "Train | 16/16 | Loss:0.0706 | MainLoss:0.0564 | Alpha:0.4880 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1584 | MainLoss:0.1584 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8856\n",
      "\n",
      "Epoch: [744 | 1000] LR: 0.000043\n",
      "Train | 16/16 | Loss:0.0629 | MainLoss:0.0488 | Alpha:0.4891 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1584 | MainLoss:0.1584 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1927 | MainLoss:1.1927 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8859\n",
      "\n",
      "Epoch: [745 | 1000] LR: 0.000043\n",
      "Train | 16/16 | Loss:0.0605 | MainLoss:0.0463 | Alpha:0.4891 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1584 | MainLoss:0.1584 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1927 | MainLoss:1.1927 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8859\n",
      "\n",
      "Epoch: [746 | 1000] LR: 0.000043\n",
      "Train | 16/16 | Loss:0.0726 | MainLoss:0.0584 | Alpha:0.4873 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1584 | MainLoss:0.1584 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1928 | MainLoss:1.1928 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8857\n",
      "\n",
      "Epoch: [747 | 1000] LR: 0.000042\n",
      "Train | 16/16 | Loss:0.0579 | MainLoss:0.0438 | Alpha:0.4897 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1927 | MainLoss:1.1927 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8854\n",
      "\n",
      "Epoch: [748 | 1000] LR: 0.000042\n",
      "Train | 16/16 | Loss:0.0618 | MainLoss:0.0476 | Alpha:0.4894 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1586 | MainLoss:0.1586 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1921 | MainLoss:1.1921 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8860\n",
      "\n",
      "Epoch: [749 | 1000] LR: 0.000042\n",
      "Train | 16/16 | Loss:0.0716 | MainLoss:0.0575 | Alpha:0.4870 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1927 | MainLoss:1.1927 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8853\n",
      "\n",
      "Epoch: [750 | 1000] LR: 0.000042\n",
      "Train | 16/16 | Loss:0.0648 | MainLoss:0.0506 | Alpha:0.4888 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9909\n",
      "Test | 128/16 | Loss:1.1925 | MainLoss:1.1925 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8858\n",
      "\n",
      "Epoch: [751 | 1000] LR: 0.000041\n",
      "Train | 16/16 | Loss:0.0665 | MainLoss:0.0524 | Alpha:0.4886 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1586 | MainLoss:0.1586 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1920 | MainLoss:1.1920 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8854\n",
      "\n",
      "Epoch: [752 | 1000] LR: 0.000041\n",
      "Train | 16/16 | Loss:0.0724 | MainLoss:0.0582 | Alpha:0.4883 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1586 | MainLoss:0.1586 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9904\n",
      "Test | 128/16 | Loss:1.1916 | MainLoss:1.1916 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8854\n",
      "\n",
      "Epoch: [753 | 1000] LR: 0.000041\n",
      "Train | 16/16 | Loss:0.0708 | MainLoss:0.0566 | Alpha:0.4882 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1586 | MainLoss:0.1586 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9909\n",
      "Test | 128/16 | Loss:1.1916 | MainLoss:1.1916 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8856\n",
      "\n",
      "Epoch: [754 | 1000] LR: 0.000041\n",
      "Train | 16/16 | Loss:0.0609 | MainLoss:0.0467 | Alpha:0.4896 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1587 | MainLoss:0.1587 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1918 | MainLoss:1.1918 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8858\n",
      "\n",
      "Epoch: [755 | 1000] LR: 0.000040\n",
      "Train | 16/16 | Loss:0.0586 | MainLoss:0.0444 | Alpha:0.4905 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1587 | MainLoss:0.1587 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1916 | MainLoss:1.1916 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8854\n",
      "\n",
      "Epoch: [756 | 1000] LR: 0.000040\n",
      "Train | 16/16 | Loss:0.0619 | MainLoss:0.0477 | Alpha:0.4895 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1587 | MainLoss:0.1587 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1920 | MainLoss:1.1920 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8854\n",
      "\n",
      "Epoch: [757 | 1000] LR: 0.000040\n",
      "Train | 16/16 | Loss:0.0615 | MainLoss:0.0473 | Alpha:0.4895 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1587 | MainLoss:0.1587 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1921 | MainLoss:1.1921 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8860\n",
      "\n",
      "Epoch: [758 | 1000] LR: 0.000040\n",
      "Train | 16/16 | Loss:0.0796 | MainLoss:0.0654 | Alpha:0.4860 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1587 | MainLoss:0.1587 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9904\n",
      "Test | 128/16 | Loss:1.1918 | MainLoss:1.1918 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8856\n",
      "\n",
      "Epoch: [759 | 1000] LR: 0.000039\n",
      "Train | 16/16 | Loss:0.0630 | MainLoss:0.0488 | Alpha:0.4900 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1587 | MainLoss:0.1587 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1918 | MainLoss:1.1918 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8855\n",
      "\n",
      "Epoch: [760 | 1000] LR: 0.000039\n",
      "Train | 16/16 | Loss:0.0689 | MainLoss:0.0548 | Alpha:0.4877 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1587 | MainLoss:0.1587 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1918 | MainLoss:1.1918 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8854\n",
      "\n",
      "Epoch: [761 | 1000] LR: 0.000039\n",
      "Train | 16/16 | Loss:0.0648 | MainLoss:0.0506 | Alpha:0.4890 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1587 | MainLoss:0.1587 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1920 | MainLoss:1.1920 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8853\n",
      "\n",
      "Epoch: [762 | 1000] LR: 0.000039\n",
      "Train | 16/16 | Loss:0.0580 | MainLoss:0.0438 | Alpha:0.4903 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1586 | MainLoss:0.1586 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1922 | MainLoss:1.1922 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8858\n",
      "\n",
      "Epoch: [763 | 1000] LR: 0.000038\n",
      "Train | 16/16 | Loss:0.0652 | MainLoss:0.0510 | Alpha:0.4891 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1586 | MainLoss:0.1586 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1922 | MainLoss:1.1922 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8855\n",
      "\n",
      "Epoch: [764 | 1000] LR: 0.000038\n",
      "Train | 16/16 | Loss:0.0637 | MainLoss:0.0496 | Alpha:0.4897 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1587 | MainLoss:0.1587 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1921 | MainLoss:1.1921 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8854\n",
      "\n",
      "Epoch: [765 | 1000] LR: 0.000038\n",
      "Train | 16/16 | Loss:0.0611 | MainLoss:0.0469 | Alpha:0.4900 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1588 | MainLoss:0.1588 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1916 | MainLoss:1.1916 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8860\n",
      "\n",
      "Epoch: [766 | 1000] LR: 0.000038\n",
      "Train | 16/16 | Loss:0.0705 | MainLoss:0.0564 | Alpha:0.4881 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1589 | MainLoss:0.1589 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1909 | MainLoss:1.1909 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8854\n",
      "\n",
      "Epoch: [767 | 1000] LR: 0.000037\n",
      "Train | 16/16 | Loss:0.0698 | MainLoss:0.0556 | Alpha:0.4875 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1590 | MainLoss:0.1590 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1901 | MainLoss:1.1901 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8859\n",
      "\n",
      "Epoch: [768 | 1000] LR: 0.000037\n",
      "Train | 16/16 | Loss:0.0760 | MainLoss:0.0618 | Alpha:0.4865 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1591 | MainLoss:0.1591 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1893 | MainLoss:1.1893 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8857\n",
      "\n",
      "Epoch: [769 | 1000] LR: 0.000037\n",
      "Train | 16/16 | Loss:0.0705 | MainLoss:0.0563 | Alpha:0.4881 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1591 | MainLoss:0.1591 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9908\n",
      "Test | 128/16 | Loss:1.1896 | MainLoss:1.1896 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8858\n",
      "\n",
      "Epoch: [770 | 1000] LR: 0.000037\n",
      "Train | 16/16 | Loss:0.0723 | MainLoss:0.0581 | Alpha:0.4876 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1590 | MainLoss:0.1590 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9904\n",
      "Test | 128/16 | Loss:1.1901 | MainLoss:1.1901 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8857\n",
      "\n",
      "Epoch: [771 | 1000] LR: 0.000036\n",
      "Train | 16/16 | Loss:0.0663 | MainLoss:0.0521 | Alpha:0.4890 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1590 | MainLoss:0.1590 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1901 | MainLoss:1.1901 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8858\n",
      "\n",
      "Epoch: [772 | 1000] LR: 0.000036\n",
      "Train | 16/16 | Loss:0.0735 | MainLoss:0.0594 | Alpha:0.4876 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1590 | MainLoss:0.1590 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1898 | MainLoss:1.1898 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8858\n",
      "\n",
      "Epoch: [773 | 1000] LR: 0.000036\n",
      "Train | 16/16 | Loss:0.0651 | MainLoss:0.0509 | Alpha:0.4895 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1590 | MainLoss:0.1590 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9904\n",
      "Test | 128/16 | Loss:1.1896 | MainLoss:1.1896 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8859\n",
      "\n",
      "Epoch: [774 | 1000] LR: 0.000036\n",
      "Train | 16/16 | Loss:0.0701 | MainLoss:0.0559 | Alpha:0.4878 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1590 | MainLoss:0.1590 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1899 | MainLoss:1.1899 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8856\n",
      "\n",
      "Epoch: [775 | 1000] LR: 0.000036\n",
      "Train | 16/16 | Loss:0.0664 | MainLoss:0.0522 | Alpha:0.4882 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 32/16 | Loss:0.1589 | MainLoss:0.1589 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1904 | MainLoss:1.1904 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8858\n",
      "\n",
      "Epoch: [776 | 1000] LR: 0.000035\n",
      "Train | 16/16 | Loss:0.0698 | MainLoss:0.0556 | Alpha:0.4878 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1589 | MainLoss:0.1589 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1906 | MainLoss:1.1906 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8860\n",
      "\n",
      "Epoch: [777 | 1000] LR: 0.000035\n",
      "Train | 16/16 | Loss:0.0656 | MainLoss:0.0514 | Alpha:0.4885 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1589 | MainLoss:0.1589 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1902 | MainLoss:1.1902 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8857\n",
      "\n",
      "Epoch: [778 | 1000] LR: 0.000035\n",
      "Train | 16/16 | Loss:0.0654 | MainLoss:0.0512 | Alpha:0.4884 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1588 | MainLoss:0.1588 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1906 | MainLoss:1.1906 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8856\n",
      "\n",
      "Epoch: [779 | 1000] LR: 0.000035\n",
      "Train | 16/16 | Loss:0.0660 | MainLoss:0.0518 | Alpha:0.4887 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1588 | MainLoss:0.1588 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1906 | MainLoss:1.1906 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8858\n",
      "\n",
      "Epoch: [780 | 1000] LR: 0.000034\n",
      "Train | 16/16 | Loss:0.0729 | MainLoss:0.0587 | Alpha:0.4875 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1588 | MainLoss:0.1588 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1906 | MainLoss:1.1906 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8854\n",
      "\n",
      "Epoch: [781 | 1000] LR: 0.000034\n",
      "Train | 16/16 | Loss:0.0700 | MainLoss:0.0558 | Alpha:0.4881 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1588 | MainLoss:0.1588 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1906 | MainLoss:1.1906 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8860\n",
      "\n",
      "Epoch: [782 | 1000] LR: 0.000034\n",
      "Train | 16/16 | Loss:0.0575 | MainLoss:0.0433 | Alpha:0.4908 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1588 | MainLoss:0.1588 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1909 | MainLoss:1.1909 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8858\n",
      "\n",
      "Epoch: [783 | 1000] LR: 0.000034\n",
      "Train | 16/16 | Loss:0.0638 | MainLoss:0.0496 | Alpha:0.4892 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1588 | MainLoss:0.1588 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1910 | MainLoss:1.1910 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8858\n",
      "\n",
      "Epoch: [784 | 1000] LR: 0.000033\n",
      "Train | 16/16 | Loss:0.0691 | MainLoss:0.0549 | Alpha:0.4876 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1588 | MainLoss:0.1588 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1910 | MainLoss:1.1910 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8858\n",
      "\n",
      "Epoch: [785 | 1000] LR: 0.000033\n",
      "Train | 16/16 | Loss:0.0730 | MainLoss:0.0588 | Alpha:0.4877 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1588 | MainLoss:0.1588 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1912 | MainLoss:1.1912 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8860\n",
      "\n",
      "Epoch: [786 | 1000] LR: 0.000033\n",
      "Train | 16/16 | Loss:0.0693 | MainLoss:0.0551 | Alpha:0.4873 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1588 | MainLoss:0.1588 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1912 | MainLoss:1.1912 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8860\n",
      "\n",
      "Epoch: [787 | 1000] LR: 0.000033\n",
      "Train | 16/16 | Loss:0.0697 | MainLoss:0.0555 | Alpha:0.4878 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1588 | MainLoss:0.1588 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1912 | MainLoss:1.1912 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8858\n",
      "\n",
      "Epoch: [788 | 1000] LR: 0.000032\n",
      "Train | 16/16 | Loss:0.0622 | MainLoss:0.0480 | Alpha:0.4901 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1588 | MainLoss:0.1588 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1911 | MainLoss:1.1911 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8859\n",
      "\n",
      "Epoch: [789 | 1000] LR: 0.000032\n",
      "Train | 16/16 | Loss:0.0680 | MainLoss:0.0538 | Alpha:0.4883 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1588 | MainLoss:0.1588 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1914 | MainLoss:1.1914 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8856\n",
      "\n",
      "Epoch: [790 | 1000] LR: 0.000032\n",
      "Train | 16/16 | Loss:0.0735 | MainLoss:0.0593 | Alpha:0.4869 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1588 | MainLoss:0.1588 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1910 | MainLoss:1.1910 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8859\n",
      "\n",
      "Epoch: [791 | 1000] LR: 0.000032\n",
      "Train | 16/16 | Loss:0.0625 | MainLoss:0.0483 | Alpha:0.4892 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1588 | MainLoss:0.1588 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1910 | MainLoss:1.1910 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8855\n",
      "\n",
      "Epoch: [792 | 1000] LR: 0.000032\n",
      "Train | 16/16 | Loss:0.0670 | MainLoss:0.0528 | Alpha:0.4885 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1588 | MainLoss:0.1588 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9904\n",
      "Test | 128/16 | Loss:1.1913 | MainLoss:1.1913 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8860\n",
      "\n",
      "Epoch: [793 | 1000] LR: 0.000031\n",
      "Train | 16/16 | Loss:0.0724 | MainLoss:0.0582 | Alpha:0.4881 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1588 | MainLoss:0.1588 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1913 | MainLoss:1.1913 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8862\n",
      "\n",
      "Epoch: [794 | 1000] LR: 0.000031\n",
      "Train | 16/16 | Loss:0.0638 | MainLoss:0.0497 | Alpha:0.4896 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1587 | MainLoss:0.1587 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1915 | MainLoss:1.1915 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8860\n",
      "\n",
      "Epoch: [795 | 1000] LR: 0.000031\n",
      "Train | 16/16 | Loss:0.0830 | MainLoss:0.0688 | Alpha:0.4844 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1587 | MainLoss:0.1587 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1918 | MainLoss:1.1918 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8854\n",
      "\n",
      "Epoch: [796 | 1000] LR: 0.000031\n",
      "Train | 16/16 | Loss:0.0762 | MainLoss:0.0620 | Alpha:0.4869 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1586 | MainLoss:0.1586 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9908\n",
      "Test | 128/16 | Loss:1.1923 | MainLoss:1.1923 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8857\n",
      "\n",
      "Epoch: [797 | 1000] LR: 0.000030\n",
      "Train | 16/16 | Loss:0.0732 | MainLoss:0.0590 | Alpha:0.4881 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1586 | MainLoss:0.1586 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1922 | MainLoss:1.1922 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8857\n",
      "\n",
      "Epoch: [798 | 1000] LR: 0.000030\n",
      "Train | 16/16 | Loss:0.0654 | MainLoss:0.0513 | Alpha:0.4891 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1586 | MainLoss:0.1586 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1926 | MainLoss:1.1926 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8859\n",
      "\n",
      "Epoch: [799 | 1000] LR: 0.000030\n",
      "Train | 16/16 | Loss:0.0572 | MainLoss:0.0430 | Alpha:0.4907 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1927 | MainLoss:1.1927 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8857\n",
      "\n",
      "Epoch: [800 | 1000] LR: 0.000030\n",
      "Train | 16/16 | Loss:0.0645 | MainLoss:0.0503 | Alpha:0.4891 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9908\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8859\n",
      "\n",
      "Epoch: [801 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.0571 | MainLoss:0.0429 | Alpha:0.4904 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8857\n",
      "\n",
      "Epoch: [802 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.0670 | MainLoss:0.0528 | Alpha:0.4872 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9908\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8856\n",
      "\n",
      "Epoch: [803 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.0674 | MainLoss:0.0532 | Alpha:0.4881 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8859\n",
      "\n",
      "Epoch: [804 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.0735 | MainLoss:0.0593 | Alpha:0.4863 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8856\n",
      "\n",
      "Epoch: [805 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.0549 | MainLoss:0.0408 | Alpha:0.4911 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8857\n",
      "\n",
      "Epoch: [806 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.0569 | MainLoss:0.0427 | Alpha:0.4904 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8855\n",
      "\n",
      "Epoch: [807 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.0653 | MainLoss:0.0512 | Alpha:0.4891 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8857\n",
      "\n",
      "Epoch: [808 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.0669 | MainLoss:0.0527 | Alpha:0.4880 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9909\n",
      "Test | 128/16 | Loss:1.1930 | MainLoss:1.1930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8858\n",
      "\n",
      "Epoch: [809 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.0689 | MainLoss:0.0547 | Alpha:0.4891 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8858\n",
      "\n",
      "Epoch: [810 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.0627 | MainLoss:0.0485 | Alpha:0.4892 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9908\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8855\n",
      "\n",
      "Epoch: [811 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.0696 | MainLoss:0.0555 | Alpha:0.4873 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9904\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8859\n",
      "\n",
      "Epoch: [812 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.0661 | MainLoss:0.0519 | Alpha:0.4892 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8857\n",
      "\n",
      "Epoch: [813 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.0682 | MainLoss:0.0540 | Alpha:0.4879 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1930 | MainLoss:1.1930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8862\n",
      "\n",
      "Epoch: [814 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.0773 | MainLoss:0.0631 | Alpha:0.4854 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1930 | MainLoss:1.1930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8857\n",
      "\n",
      "Epoch: [815 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.0667 | MainLoss:0.0525 | Alpha:0.4886 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1930 | MainLoss:1.1930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8858\n",
      "\n",
      "Epoch: [816 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.0585 | MainLoss:0.0444 | Alpha:0.4896 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1930 | MainLoss:1.1930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8857\n",
      "\n",
      "Epoch: [817 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.0727 | MainLoss:0.0585 | Alpha:0.4869 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1930 | MainLoss:1.1930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8859\n",
      "\n",
      "Epoch: [818 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.0777 | MainLoss:0.0635 | Alpha:0.4865 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1930 | MainLoss:1.1930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8857\n",
      "\n",
      "Epoch: [819 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.0583 | MainLoss:0.0441 | Alpha:0.4912 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9904\n",
      "Test | 128/16 | Loss:1.1930 | MainLoss:1.1930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8858\n",
      "\n",
      "Epoch: [820 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.0602 | MainLoss:0.0460 | Alpha:0.4899 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9904\n",
      "Test | 128/16 | Loss:1.1930 | MainLoss:1.1930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8856\n",
      "\n",
      "Epoch: [821 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.0628 | MainLoss:0.0486 | Alpha:0.4896 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1930 | MainLoss:1.1930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8858\n",
      "\n",
      "Epoch: [822 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0663 | MainLoss:0.0522 | Alpha:0.4882 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9902\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8860\n",
      "\n",
      "Epoch: [823 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0708 | MainLoss:0.0566 | Alpha:0.4875 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9903\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8863\n",
      "\n",
      "Epoch: [824 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0719 | MainLoss:0.0578 | Alpha:0.4877 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8859\n",
      "\n",
      "Epoch: [825 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0693 | MainLoss:0.0552 | Alpha:0.4889 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8856\n",
      "\n",
      "Epoch: [826 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0813 | MainLoss:0.0672 | Alpha:0.4858 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8852\n",
      "\n",
      "Epoch: [827 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0637 | MainLoss:0.0495 | Alpha:0.4895 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8861\n",
      "\n",
      "Epoch: [828 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0799 | MainLoss:0.0657 | Alpha:0.4865 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8857\n",
      "\n",
      "Epoch: [829 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0651 | MainLoss:0.0509 | Alpha:0.4889 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8859\n",
      "\n",
      "Epoch: [830 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0667 | MainLoss:0.0526 | Alpha:0.4888 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8857\n",
      "\n",
      "Epoch: [831 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0661 | MainLoss:0.0520 | Alpha:0.4879 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9904\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8861\n",
      "\n",
      "Epoch: [832 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0676 | MainLoss:0.0534 | Alpha:0.4882 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8858\n",
      "\n",
      "Epoch: [833 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0636 | MainLoss:0.0494 | Alpha:0.4894 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8861\n",
      "\n",
      "Epoch: [834 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0601 | MainLoss:0.0459 | Alpha:0.4901 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9903\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8858\n",
      "\n",
      "Epoch: [835 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0777 | MainLoss:0.0635 | Alpha:0.4869 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9904\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8857\n",
      "\n",
      "Epoch: [836 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0707 | MainLoss:0.0565 | Alpha:0.4876 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8858\n",
      "\n",
      "Epoch: [837 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0762 | MainLoss:0.0620 | Alpha:0.4861 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9903\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8857\n",
      "\n",
      "Epoch: [838 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0672 | MainLoss:0.0530 | Alpha:0.4885 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1930 | MainLoss:1.1930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8858\n",
      "\n",
      "Epoch: [839 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0728 | MainLoss:0.0586 | Alpha:0.4878 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1930 | MainLoss:1.1930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8858\n",
      "\n",
      "Epoch: [840 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0622 | MainLoss:0.0480 | Alpha:0.4903 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8858\n",
      "\n",
      "Epoch: [841 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0718 | MainLoss:0.0576 | Alpha:0.4874 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8853\n",
      "\n",
      "Epoch: [842 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0669 | MainLoss:0.0527 | Alpha:0.4879 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8860\n",
      "\n",
      "Epoch: [843 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0621 | MainLoss:0.0479 | Alpha:0.4893 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8861\n",
      "\n",
      "Epoch: [844 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0641 | MainLoss:0.0500 | Alpha:0.4895 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8854\n",
      "\n",
      "Epoch: [845 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0618 | MainLoss:0.0476 | Alpha:0.4897 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8857\n",
      "\n",
      "Epoch: [846 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0722 | MainLoss:0.0580 | Alpha:0.4878 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8861\n",
      "\n",
      "Epoch: [847 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0505 | MainLoss:0.0363 | Alpha:0.4920 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8858\n",
      "\n",
      "Epoch: [848 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0738 | MainLoss:0.0596 | Alpha:0.4870 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8856\n",
      "\n",
      "Epoch: [849 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0698 | MainLoss:0.0556 | Alpha:0.4885 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9904\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8855\n",
      "\n",
      "Epoch: [850 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0760 | MainLoss:0.0618 | Alpha:0.4868 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8857\n",
      "\n",
      "Epoch: [851 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0601 | MainLoss:0.0459 | Alpha:0.4901 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9904\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8856\n",
      "\n",
      "Epoch: [852 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0633 | MainLoss:0.0491 | Alpha:0.4904 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9904\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8857\n",
      "\n",
      "Epoch: [853 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0630 | MainLoss:0.0489 | Alpha:0.4885 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9902\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8857\n",
      "\n",
      "Epoch: [854 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0831 | MainLoss:0.0689 | Alpha:0.4841 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8858\n",
      "\n",
      "Epoch: [855 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0689 | MainLoss:0.0548 | Alpha:0.4879 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8855\n",
      "\n",
      "Epoch: [856 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0668 | MainLoss:0.0526 | Alpha:0.4895 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9903\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8858\n",
      "\n",
      "Epoch: [857 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0619 | MainLoss:0.0477 | Alpha:0.4892 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9908\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8858\n",
      "\n",
      "Epoch: [858 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0712 | MainLoss:0.0570 | Alpha:0.4879 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9903\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8860\n",
      "\n",
      "Epoch: [859 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0667 | MainLoss:0.0525 | Alpha:0.4883 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8859\n",
      "\n",
      "Epoch: [860 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0709 | MainLoss:0.0567 | Alpha:0.4877 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8858\n",
      "\n",
      "Epoch: [861 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0772 | MainLoss:0.0631 | Alpha:0.4857 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1584 | MainLoss:0.1584 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1932 | MainLoss:1.1932 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8858\n",
      "\n",
      "Epoch: [862 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0803 | MainLoss:0.0661 | Alpha:0.4855 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1584 | MainLoss:0.1584 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9908\n",
      "Test | 128/16 | Loss:1.1932 | MainLoss:1.1932 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8862\n",
      "\n",
      "Epoch: [863 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0736 | MainLoss:0.0594 | Alpha:0.4869 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1584 | MainLoss:0.1584 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8859\n",
      "\n",
      "Epoch: [864 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0617 | MainLoss:0.0476 | Alpha:0.4891 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8857\n",
      "\n",
      "Epoch: [865 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0747 | MainLoss:0.0605 | Alpha:0.4866 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1584 | MainLoss:0.1584 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9904\n",
      "Test | 128/16 | Loss:1.1932 | MainLoss:1.1932 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8860\n",
      "\n",
      "Epoch: [866 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0780 | MainLoss:0.0638 | Alpha:0.4862 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1584 | MainLoss:0.1584 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1932 | MainLoss:1.1932 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8856\n",
      "\n",
      "Epoch: [867 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0762 | MainLoss:0.0620 | Alpha:0.4864 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1584 | MainLoss:0.1584 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1932 | MainLoss:1.1932 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8858\n",
      "\n",
      "Epoch: [868 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0657 | MainLoss:0.0515 | Alpha:0.4889 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1584 | MainLoss:0.1584 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1932 | MainLoss:1.1932 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8855\n",
      "\n",
      "Epoch: [869 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0553 | MainLoss:0.0411 | Alpha:0.4912 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1584 | MainLoss:0.1584 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9904\n",
      "Test | 128/16 | Loss:1.1932 | MainLoss:1.1932 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8859\n",
      "\n",
      "Epoch: [870 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0688 | MainLoss:0.0546 | Alpha:0.4887 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1584 | MainLoss:0.1584 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1932 | MainLoss:1.1932 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8855\n",
      "\n",
      "Epoch: [871 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0628 | MainLoss:0.0486 | Alpha:0.4896 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1584 | MainLoss:0.1584 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9904\n",
      "Test | 128/16 | Loss:1.1932 | MainLoss:1.1932 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8859\n",
      "\n",
      "Epoch: [872 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0652 | MainLoss:0.0510 | Alpha:0.4885 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1584 | MainLoss:0.1584 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1932 | MainLoss:1.1932 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8860\n",
      "\n",
      "Epoch: [873 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0737 | MainLoss:0.0595 | Alpha:0.4875 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1584 | MainLoss:0.1584 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9908\n",
      "Test | 128/16 | Loss:1.1932 | MainLoss:1.1932 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8862\n",
      "\n",
      "Epoch: [874 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0732 | MainLoss:0.0590 | Alpha:0.4872 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1584 | MainLoss:0.1584 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9908\n",
      "Test | 128/16 | Loss:1.1932 | MainLoss:1.1932 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8858\n",
      "\n",
      "Epoch: [875 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0678 | MainLoss:0.0536 | Alpha:0.4882 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 32/16 | Loss:0.1584 | MainLoss:0.1584 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1932 | MainLoss:1.1932 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8857\n",
      "\n",
      "Epoch: [876 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0672 | MainLoss:0.0530 | Alpha:0.4885 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1584 | MainLoss:0.1584 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1932 | MainLoss:1.1932 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8857\n",
      "\n",
      "Epoch: [877 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0675 | MainLoss:0.0533 | Alpha:0.4890 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1584 | MainLoss:0.1584 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9904\n",
      "Test | 128/16 | Loss:1.1932 | MainLoss:1.1932 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8858\n",
      "\n",
      "Epoch: [878 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0619 | MainLoss:0.0477 | Alpha:0.4900 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1584 | MainLoss:0.1584 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9904\n",
      "Test | 128/16 | Loss:1.1932 | MainLoss:1.1932 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8858\n",
      "\n",
      "Epoch: [879 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0633 | MainLoss:0.0491 | Alpha:0.4901 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1584 | MainLoss:0.1584 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1932 | MainLoss:1.1932 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8860\n",
      "\n",
      "Epoch: [880 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0714 | MainLoss:0.0572 | Alpha:0.4869 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1584 | MainLoss:0.1584 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1932 | MainLoss:1.1932 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8860\n",
      "\n",
      "Epoch: [881 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0728 | MainLoss:0.0586 | Alpha:0.4877 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1584 | MainLoss:0.1584 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9903\n",
      "Test | 128/16 | Loss:1.1932 | MainLoss:1.1932 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8859\n",
      "\n",
      "Epoch: [882 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0777 | MainLoss:0.0636 | Alpha:0.4864 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1584 | MainLoss:0.1584 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9902\n",
      "Test | 128/16 | Loss:1.1932 | MainLoss:1.1932 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8860\n",
      "\n",
      "Epoch: [883 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0700 | MainLoss:0.0558 | Alpha:0.4882 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1584 | MainLoss:0.1584 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1932 | MainLoss:1.1932 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8860\n",
      "\n",
      "Epoch: [884 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0583 | MainLoss:0.0441 | Alpha:0.4905 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1584 | MainLoss:0.1584 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1932 | MainLoss:1.1932 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8859\n",
      "\n",
      "Epoch: [885 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0690 | MainLoss:0.0548 | Alpha:0.4883 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1584 | MainLoss:0.1584 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1932 | MainLoss:1.1932 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8861\n",
      "\n",
      "Epoch: [886 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0726 | MainLoss:0.0585 | Alpha:0.4871 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1584 | MainLoss:0.1584 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1932 | MainLoss:1.1932 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8858\n",
      "\n",
      "Epoch: [887 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0835 | MainLoss:0.0693 | Alpha:0.4846 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1584 | MainLoss:0.1584 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9903\n",
      "Test | 128/16 | Loss:1.1932 | MainLoss:1.1932 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8860\n",
      "\n",
      "Epoch: [888 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0692 | MainLoss:0.0550 | Alpha:0.4877 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1584 | MainLoss:0.1584 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1932 | MainLoss:1.1932 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8859\n",
      "\n",
      "Epoch: [889 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0752 | MainLoss:0.0610 | Alpha:0.4878 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1584 | MainLoss:0.1584 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1932 | MainLoss:1.1932 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8858\n",
      "\n",
      "Epoch: [890 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0525 | MainLoss:0.0383 | Alpha:0.4917 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1584 | MainLoss:0.1584 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1932 | MainLoss:1.1932 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8861\n",
      "\n",
      "Epoch: [891 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0701 | MainLoss:0.0560 | Alpha:0.4880 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1584 | MainLoss:0.1584 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1932 | MainLoss:1.1932 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8859\n",
      "\n",
      "Epoch: [892 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0628 | MainLoss:0.0486 | Alpha:0.4903 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1584 | MainLoss:0.1584 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1932 | MainLoss:1.1932 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8858\n",
      "\n",
      "Epoch: [893 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0687 | MainLoss:0.0545 | Alpha:0.4892 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1584 | MainLoss:0.1584 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9904\n",
      "Test | 128/16 | Loss:1.1932 | MainLoss:1.1932 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8859\n",
      "\n",
      "Epoch: [894 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0660 | MainLoss:0.0518 | Alpha:0.4885 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1584 | MainLoss:0.1584 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1932 | MainLoss:1.1932 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8860\n",
      "\n",
      "Epoch: [895 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0576 | MainLoss:0.0435 | Alpha:0.4912 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1584 | MainLoss:0.1584 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1932 | MainLoss:1.1932 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8856\n",
      "\n",
      "Epoch: [896 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0732 | MainLoss:0.0590 | Alpha:0.4869 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1584 | MainLoss:0.1584 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9909\n",
      "Test | 128/16 | Loss:1.1932 | MainLoss:1.1932 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8857\n",
      "\n",
      "Epoch: [897 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0720 | MainLoss:0.0578 | Alpha:0.4887 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1584 | MainLoss:0.1584 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1932 | MainLoss:1.1932 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8858\n",
      "\n",
      "Epoch: [898 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0738 | MainLoss:0.0596 | Alpha:0.4869 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1584 | MainLoss:0.1584 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1932 | MainLoss:1.1932 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8859\n",
      "\n",
      "Epoch: [899 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0747 | MainLoss:0.0605 | Alpha:0.4867 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1584 | MainLoss:0.1584 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1932 | MainLoss:1.1932 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8855\n",
      "\n",
      "Epoch: [900 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0674 | MainLoss:0.0532 | Alpha:0.4891 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 32/16 | Loss:0.1584 | MainLoss:0.1584 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1932 | MainLoss:1.1932 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8858\n",
      "\n",
      "Epoch: [901 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0695 | MainLoss:0.0553 | Alpha:0.4883 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1584 | MainLoss:0.1584 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1932 | MainLoss:1.1932 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8858\n",
      "\n",
      "Epoch: [902 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0717 | MainLoss:0.0575 | Alpha:0.4875 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1584 | MainLoss:0.1584 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9908\n",
      "Test | 128/16 | Loss:1.1932 | MainLoss:1.1932 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8856\n",
      "\n",
      "Epoch: [903 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0653 | MainLoss:0.0511 | Alpha:0.4887 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1584 | MainLoss:0.1584 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1932 | MainLoss:1.1932 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8857\n",
      "\n",
      "Epoch: [904 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0702 | MainLoss:0.0560 | Alpha:0.4876 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1584 | MainLoss:0.1584 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1932 | MainLoss:1.1932 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8861\n",
      "\n",
      "Epoch: [905 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0651 | MainLoss:0.0509 | Alpha:0.4896 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1584 | MainLoss:0.1584 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9904\n",
      "Test | 128/16 | Loss:1.1932 | MainLoss:1.1932 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8859\n",
      "\n",
      "Epoch: [906 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0756 | MainLoss:0.0614 | Alpha:0.4865 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1584 | MainLoss:0.1584 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1932 | MainLoss:1.1932 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8858\n",
      "\n",
      "Epoch: [907 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0730 | MainLoss:0.0588 | Alpha:0.4873 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1584 | MainLoss:0.1584 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9904\n",
      "Test | 128/16 | Loss:1.1932 | MainLoss:1.1932 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8862\n",
      "\n",
      "Epoch: [908 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0596 | MainLoss:0.0455 | Alpha:0.4904 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1584 | MainLoss:0.1584 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1932 | MainLoss:1.1932 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8856\n",
      "\n",
      "Epoch: [909 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0814 | MainLoss:0.0672 | Alpha:0.4862 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1584 | MainLoss:0.1584 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1932 | MainLoss:1.1932 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8859\n",
      "\n",
      "Epoch: [910 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0667 | MainLoss:0.0525 | Alpha:0.4891 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1584 | MainLoss:0.1584 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1932 | MainLoss:1.1932 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8857\n",
      "\n",
      "Epoch: [911 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0757 | MainLoss:0.0615 | Alpha:0.4869 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1584 | MainLoss:0.1584 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1932 | MainLoss:1.1932 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8857\n",
      "\n",
      "Epoch: [912 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0698 | MainLoss:0.0556 | Alpha:0.4872 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1584 | MainLoss:0.1584 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1932 | MainLoss:1.1932 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8854\n",
      "\n",
      "Epoch: [913 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0669 | MainLoss:0.0527 | Alpha:0.4878 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1584 | MainLoss:0.1584 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1932 | MainLoss:1.1932 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8855\n",
      "\n",
      "Epoch: [914 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0691 | MainLoss:0.0549 | Alpha:0.4877 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1584 | MainLoss:0.1584 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9910\n",
      "Test | 128/16 | Loss:1.1932 | MainLoss:1.1932 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8858\n",
      "\n",
      "Epoch: [915 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0783 | MainLoss:0.0641 | Alpha:0.4863 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1584 | MainLoss:0.1584 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9908\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8854\n",
      "\n",
      "Epoch: [916 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0690 | MainLoss:0.0548 | Alpha:0.4877 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1584 | MainLoss:0.1584 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8857\n",
      "\n",
      "Epoch: [917 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0588 | MainLoss:0.0447 | Alpha:0.4907 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1584 | MainLoss:0.1584 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8858\n",
      "\n",
      "Epoch: [918 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0596 | MainLoss:0.0454 | Alpha:0.4904 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8857\n",
      "\n",
      "Epoch: [919 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0730 | MainLoss:0.0588 | Alpha:0.4874 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1584 | MainLoss:0.1584 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1932 | MainLoss:1.1932 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8853\n",
      "\n",
      "Epoch: [920 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0527 | MainLoss:0.0385 | Alpha:0.4922 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1584 | MainLoss:0.1584 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9902\n",
      "Test | 128/16 | Loss:1.1932 | MainLoss:1.1932 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8860\n",
      "\n",
      "Epoch: [921 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0728 | MainLoss:0.0587 | Alpha:0.4870 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1584 | MainLoss:0.1584 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1932 | MainLoss:1.1932 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8856\n",
      "\n",
      "Epoch: [922 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0651 | MainLoss:0.0509 | Alpha:0.4889 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1584 | MainLoss:0.1584 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9903\n",
      "Test | 128/16 | Loss:1.1932 | MainLoss:1.1932 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8859\n",
      "\n",
      "Epoch: [923 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0689 | MainLoss:0.0548 | Alpha:0.4876 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1584 | MainLoss:0.1584 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9909\n",
      "Test | 128/16 | Loss:1.1932 | MainLoss:1.1932 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8860\n",
      "\n",
      "Epoch: [924 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0672 | MainLoss:0.0531 | Alpha:0.4887 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1584 | MainLoss:0.1584 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9904\n",
      "Test | 128/16 | Loss:1.1932 | MainLoss:1.1932 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8857\n",
      "\n",
      "Epoch: [925 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0546 | MainLoss:0.0404 | Alpha:0.4912 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 32/16 | Loss:0.1584 | MainLoss:0.1584 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1932 | MainLoss:1.1932 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8855\n",
      "\n",
      "Epoch: [926 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0551 | MainLoss:0.0410 | Alpha:0.4910 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9908\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8856\n",
      "\n",
      "Epoch: [927 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0714 | MainLoss:0.0572 | Alpha:0.4873 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1584 | MainLoss:0.1584 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9908\n",
      "Test | 128/16 | Loss:1.1932 | MainLoss:1.1932 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8857\n",
      "\n",
      "Epoch: [928 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0741 | MainLoss:0.0599 | Alpha:0.4867 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8857\n",
      "\n",
      "Epoch: [929 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0816 | MainLoss:0.0675 | Alpha:0.4849 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8855\n",
      "\n",
      "Epoch: [930 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0719 | MainLoss:0.0577 | Alpha:0.4878 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8858\n",
      "\n",
      "Epoch: [931 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0644 | MainLoss:0.0502 | Alpha:0.4891 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8856\n",
      "\n",
      "Epoch: [932 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0708 | MainLoss:0.0567 | Alpha:0.4883 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9908\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8855\n",
      "\n",
      "Epoch: [933 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0799 | MainLoss:0.0657 | Alpha:0.4858 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8863\n",
      "\n",
      "Epoch: [934 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0745 | MainLoss:0.0603 | Alpha:0.4871 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9908\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8858\n",
      "\n",
      "Epoch: [935 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0581 | MainLoss:0.0439 | Alpha:0.4902 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8857\n",
      "\n",
      "Epoch: [936 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0604 | MainLoss:0.0463 | Alpha:0.4906 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8860\n",
      "\n",
      "Epoch: [937 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0697 | MainLoss:0.0556 | Alpha:0.4880 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8859\n",
      "\n",
      "Epoch: [938 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0596 | MainLoss:0.0454 | Alpha:0.4904 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8856\n",
      "\n",
      "Epoch: [939 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0702 | MainLoss:0.0560 | Alpha:0.4869 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8859\n",
      "\n",
      "Epoch: [940 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0635 | MainLoss:0.0493 | Alpha:0.4891 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8860\n",
      "\n",
      "Epoch: [941 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0707 | MainLoss:0.0565 | Alpha:0.4880 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8858\n",
      "\n",
      "Epoch: [942 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0706 | MainLoss:0.0564 | Alpha:0.4874 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8856\n",
      "\n",
      "Epoch: [943 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0654 | MainLoss:0.0512 | Alpha:0.4888 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8856\n",
      "\n",
      "Epoch: [944 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0663 | MainLoss:0.0521 | Alpha:0.4887 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9904\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8860\n",
      "\n",
      "Epoch: [945 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0696 | MainLoss:0.0554 | Alpha:0.4880 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9903\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8859\n",
      "\n",
      "Epoch: [946 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0664 | MainLoss:0.0522 | Alpha:0.4890 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9904\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8861\n",
      "\n",
      "Epoch: [947 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0756 | MainLoss:0.0614 | Alpha:0.4864 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8858\n",
      "\n",
      "Epoch: [948 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0654 | MainLoss:0.0512 | Alpha:0.4887 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8856\n",
      "\n",
      "Epoch: [949 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0673 | MainLoss:0.0531 | Alpha:0.4896 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8860\n",
      "\n",
      "Epoch: [950 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0679 | MainLoss:0.0537 | Alpha:0.4886 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8856\n",
      "\n",
      "Epoch: [951 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0717 | MainLoss:0.0575 | Alpha:0.4876 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9908\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8856\n",
      "\n",
      "Epoch: [952 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0672 | MainLoss:0.0530 | Alpha:0.4880 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9904\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8856\n",
      "\n",
      "Epoch: [953 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0674 | MainLoss:0.0532 | Alpha:0.4882 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8860\n",
      "\n",
      "Epoch: [954 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0807 | MainLoss:0.0665 | Alpha:0.4857 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8857\n",
      "\n",
      "Epoch: [955 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0745 | MainLoss:0.0603 | Alpha:0.4860 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8859\n",
      "\n",
      "Epoch: [956 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0585 | MainLoss:0.0443 | Alpha:0.4911 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8856\n",
      "\n",
      "Epoch: [957 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0738 | MainLoss:0.0596 | Alpha:0.4869 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8857\n",
      "\n",
      "Epoch: [958 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0696 | MainLoss:0.0554 | Alpha:0.4877 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9904\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8857\n",
      "\n",
      "Epoch: [959 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0781 | MainLoss:0.0640 | Alpha:0.4868 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8855\n",
      "\n",
      "Epoch: [960 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0791 | MainLoss:0.0649 | Alpha:0.4850 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8856\n",
      "\n",
      "Epoch: [961 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0648 | MainLoss:0.0506 | Alpha:0.4884 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9904\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8857\n",
      "\n",
      "Epoch: [962 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0601 | MainLoss:0.0460 | Alpha:0.4901 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8857\n",
      "\n",
      "Epoch: [963 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0584 | MainLoss:0.0442 | Alpha:0.4904 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9908\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8857\n",
      "\n",
      "Epoch: [964 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0675 | MainLoss:0.0533 | Alpha:0.4886 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8857\n",
      "\n",
      "Epoch: [965 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0743 | MainLoss:0.0601 | Alpha:0.4877 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9904\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8857\n",
      "\n",
      "Epoch: [966 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0880 | MainLoss:0.0738 | Alpha:0.4845 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8859\n",
      "\n",
      "Epoch: [967 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0602 | MainLoss:0.0461 | Alpha:0.4907 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8860\n",
      "\n",
      "Epoch: [968 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0745 | MainLoss:0.0603 | Alpha:0.4869 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9908\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8853\n",
      "\n",
      "Epoch: [969 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0631 | MainLoss:0.0490 | Alpha:0.4897 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8856\n",
      "\n",
      "Epoch: [970 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0735 | MainLoss:0.0593 | Alpha:0.4871 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8857\n",
      "\n",
      "Epoch: [971 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0763 | MainLoss:0.0621 | Alpha:0.4867 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9903\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8857\n",
      "\n",
      "Epoch: [972 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0708 | MainLoss:0.0566 | Alpha:0.4877 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9903\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8856\n",
      "\n",
      "Epoch: [973 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0649 | MainLoss:0.0507 | Alpha:0.4889 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8855\n",
      "\n",
      "Epoch: [974 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0739 | MainLoss:0.0597 | Alpha:0.4876 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8860\n",
      "\n",
      "Epoch: [975 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0651 | MainLoss:0.0509 | Alpha:0.4894 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9904\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8858\n",
      "\n",
      "Epoch: [976 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0669 | MainLoss:0.0527 | Alpha:0.4887 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8859\n",
      "\n",
      "Epoch: [977 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0765 | MainLoss:0.0624 | Alpha:0.4865 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9904\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8860\n",
      "\n",
      "Epoch: [978 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0702 | MainLoss:0.0560 | Alpha:0.4877 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8857\n",
      "\n",
      "Epoch: [979 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0595 | MainLoss:0.0453 | Alpha:0.4905 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8856\n",
      "\n",
      "Epoch: [980 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0715 | MainLoss:0.0573 | Alpha:0.4870 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8856\n",
      "\n",
      "Epoch: [981 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0624 | MainLoss:0.0482 | Alpha:0.4899 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8858\n",
      "\n",
      "Epoch: [982 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0716 | MainLoss:0.0574 | Alpha:0.4880 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9904\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8857\n",
      "\n",
      "Epoch: [983 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0771 | MainLoss:0.0629 | Alpha:0.4862 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8857\n",
      "\n",
      "Epoch: [984 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0697 | MainLoss:0.0555 | Alpha:0.4883 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8860\n",
      "\n",
      "Epoch: [985 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0585 | MainLoss:0.0443 | Alpha:0.4903 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8855\n",
      "\n",
      "Epoch: [986 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0671 | MainLoss:0.0529 | Alpha:0.4884 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9908\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8858\n",
      "\n",
      "Epoch: [987 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0723 | MainLoss:0.0581 | Alpha:0.4879 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8855\n",
      "\n",
      "Epoch: [988 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0597 | MainLoss:0.0455 | Alpha:0.4901 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8858\n",
      "\n",
      "Epoch: [989 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0526 | MainLoss:0.0384 | Alpha:0.4925 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8857\n",
      "\n",
      "Epoch: [990 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0655 | MainLoss:0.0513 | Alpha:0.4886 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9908\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8858\n",
      "\n",
      "Epoch: [991 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0591 | MainLoss:0.0450 | Alpha:0.4898 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9903\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8863\n",
      "\n",
      "Epoch: [992 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0818 | MainLoss:0.0676 | Alpha:0.4847 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8859\n",
      "\n",
      "Epoch: [993 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0586 | MainLoss:0.0444 | Alpha:0.4901 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8857\n",
      "\n",
      "Epoch: [994 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0823 | MainLoss:0.0682 | Alpha:0.4853 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8856\n",
      "\n",
      "Epoch: [995 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0694 | MainLoss:0.0552 | Alpha:0.4886 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8858\n",
      "\n",
      "Epoch: [996 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0764 | MainLoss:0.0623 | Alpha:0.4868 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9902\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8859\n",
      "\n",
      "Epoch: [997 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0705 | MainLoss:0.0563 | Alpha:0.4880 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8856\n",
      "\n",
      "Epoch: [998 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0684 | MainLoss:0.0542 | Alpha:0.4880 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8857\n",
      "\n",
      "Epoch: [999 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0683 | MainLoss:0.0541 | Alpha:0.4876 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8856\n",
      "\n",
      "Epoch: [1000 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0739 | MainLoss:0.0597 | Alpha:0.4873 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 32/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:1.1931 | MainLoss:1.1931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.8859\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(start_epoch, epochs):\n",
    "    state['lr'] = optimizer.state_dict()['param_groups'][0]['lr']\n",
    "\n",
    "    print('\\nEpoch: [%d | %d] LR: %f' % (epoch + 1, epochs, state['lr']))\n",
    "    \n",
    "    train_loss, train_auroc = train(train_loader, teacher_model, student_model, criterion, optimizer, epoch, use_cuda)\n",
    "    test_loss, test_auroc = test(val_target_loader, student_model, criterion, epoch, use_cuda)\n",
    "    source_loss, source_auroc = test(val_source_loader, student_model, criterion, epoch, use_cuda)\n",
    "\n",
    "\n",
    "    logger.append([state['lr'], train_loss, test_loss,  source_loss, train_auroc, test_auroc, source_auroc])\n",
    "    is_best = test_auroc+source_auroc > best_acc\n",
    "    best_acc = max(test_auroc+source_auroc, best_acc)\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'state_dict' : student_model.state_dict(),\n",
    "        'best_acc': best_acc,\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    }, is_best, checkpoint=checkpoint)\n",
    "    scheduler_warmup.step()\n",
    "    scheduler.step()\n",
    "    \n",
    "    if (epoch+1)%100 == 0:\n",
    "        teacher_model.load_state_dict(student_model.state_dict())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
