{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import collections\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "\n",
    "from model_pytorch import EfficientNet\n",
    "from utils import Bar,Logger, AverageMeter, accuracy, mkdir_p, savefig\n",
    "from warmup_scheduler import GradualWarmupScheduler\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "import cv2\n",
    "\n",
    "from PIL import ImageFile, ImageOps\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU device 3: True\n"
     ]
    }
   ],
   "source": [
    "# GPU Device\n",
    "gpu_id = 3\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(\"GPU device %d:\" %(gpu_id), use_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = '/media/data2/dataset/GAN_ImageData/StyleGAN_256/'\n",
    "target_dir = '/media/data2/dataset/GAN_ImageData/StarGAN_128/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained = './log/style1/128/b0/aug/checkpoint.pth.tar'\n",
    "resume = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model_name = 'efficientnet-b0' # b0-b7 scale\n",
    "\n",
    "# Optimization\n",
    "num_classes = 2\n",
    "epochs = 1000\n",
    "start_epoch = 0\n",
    "train_batch = 200\n",
    "test_batch = 200\n",
    "lr = 0.01\n",
    "schedule = [50, 250, 500, 750]\n",
    "momentum = 0.1\n",
    "gamma = 0.1 # LR is multiplied by gamma on schedule\n",
    "\n",
    "# CheckPoint\n",
    "checkpoint = './log/style1/128/b0/to_star/2000shot/self' # dir\n",
    "if not os.path.isdir(checkpoint):\n",
    "    os.makedirs(checkpoint)\n",
    "num_workers = 8\n",
    "\n",
    "# Seed\n",
    "manual_seed = 7\n",
    "random.seed(manual_seed)\n",
    "torch.cuda.manual_seed_all(manual_seed)\n",
    "\n",
    "# Image\n",
    "size = (128, 128)\n",
    "\n",
    "# cutmix\n",
    "cm_prob = 0.2\n",
    "cm_beta = 1.0\n",
    "\n",
    "# augmentation\n",
    "blur_prob = 0.2\n",
    "blog_sig = 0.5\n",
    "jpg_prob = 0.2\n",
    "\n",
    "best_acc = 0\n",
    "\n",
    "# sp\n",
    "sp_alpha = 0.1\n",
    "sp_beta = 0.1\n",
    "fc_name = '_fc.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {}\n",
    "state['num_classes'] = num_classes\n",
    "state['epochs'] = epochs\n",
    "state['start_epoch'] = start_epoch\n",
    "state['train_batch'] = train_batch\n",
    "state['test_batch'] = test_batch\n",
    "state['lr'] = lr\n",
    "state['schedule'] = schedule\n",
    "state['momentum'] = momentum\n",
    "state['gamma'] = gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_augment(img):\n",
    "    img = np.array(img)\n",
    "\n",
    "    if random.random() < blur_prob:\n",
    "        sig = np.random.uniform(0.0, 3.0)\n",
    "        gaussian_blur(img, sig)\n",
    "\n",
    "    if random.random() < jpg_prob:\n",
    "        qual = np.random.uniform(30.0, 100.0)\n",
    "        img = cv2_jpg(img, qual)\n",
    "\n",
    "    return Image.fromarray(img)\n",
    "\n",
    "\n",
    "def gaussian_blur(img, sigma):\n",
    "    gaussian_filter(img[:,:,0], output=img[:,:,0], sigma=sigma)\n",
    "    gaussian_filter(img[:,:,1], output=img[:,:,1], sigma=sigma)\n",
    "    gaussian_filter(img[:,:,2], output=img[:,:,2], sigma=sigma)\n",
    "\n",
    "\n",
    "def cv2_jpg(img, compress_val):\n",
    "    img_cv2 = img[:,:,::-1]\n",
    "    encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), compress_val]\n",
    "    result, encimg = cv2.imencode('.jpg', img_cv2, encode_param)\n",
    "    decimg = cv2.imdecode(encimg, 1)\n",
    "    return decimg[:,:,::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_bbox(size, lam):\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = np.int(W * cut_rat)\n",
    "    cut_h = np.int(H * cut_rat)\n",
    "\n",
    "    # uniform\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join(source_dir, 'star/2000_shot_only')\n",
    "val_target_dir = os.path.join(target_dir, 'validation')\n",
    "val_source_dir = os.path.join(source_dir, 'validation')\n",
    "\n",
    "train_aug = transforms.Compose([\n",
    "    transforms.Lambda(lambda img: data_augment(img)),\n",
    "    transforms.Resize(size),\n",
    "#     transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "val_aug = transforms.Compose([\n",
    "    transforms.Resize(size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# pin_memory : cuda pin memeory use\n",
    "train_loader = DataLoader(datasets.ImageFolder(train_dir, transform=train_aug),\n",
    "                          batch_size=train_batch, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "val_target_loader = DataLoader(datasets.ImageFolder(val_target_dir, val_aug),\n",
    "                       batch_size=test_batch, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "val_source_loader = DataLoader(datasets.ImageFolder(val_source_dir, val_aug),\n",
    "                       batch_size=test_batch, shuffle=True, num_workers=num_workers, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> using pre-trained model './log/style1/128/b0/aug/checkpoint.pth.tar'\n"
     ]
    }
   ],
   "source": [
    "teacher_model = EfficientNet.from_name(model_name, num_classes=num_classes,\n",
    "                              override_params={'dropout_rate':0.2, 'drop_connect_rate':0.2})\n",
    "student_model = EfficientNet.from_name(model_name, num_classes=num_classes,\n",
    "                              override_params={'dropout_rate':0.2, 'drop_connect_rate':0.2})\n",
    "\n",
    "# Pre-trained\n",
    "if pretrained:\n",
    "    print(\"=> using pre-trained model '{}'\".format(pretrained))\n",
    "    teacher_model.load_state_dict(torch.load(pretrained)['state_dict'])\n",
    "    student_model.load_state_dict(torch.load(pretrained)['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Total params: 4.01M\n"
     ]
    }
   ],
   "source": [
    "teacher_model.to('cuda')\n",
    "student_model.to('cuda')\n",
    "cudnn.benchmark = True\n",
    "print('    Total params: %.2fM' % (sum(p.numel() for p in teacher_model.parameters())/1000000.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "# optimizer = optim.SGD(student_model.parameters(), lr=lr, momentum=momentum)\n",
    "optimizer = optim.Adam(student_model.parameters())\n",
    "scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)\n",
    "scheduler_warmup = GradualWarmupScheduler(optimizer, multiplier=4, total_epoch=10, after_scheduler=scheduler_cosine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resume\n",
    "if resume:\n",
    "    print('==> Resuming from checkpoint..')\n",
    "    checkpoint = os.path.dirname(resume)\n",
    "#     checkpoint = torch.load(resume)\n",
    "    resume = torch.load(resume)\n",
    "    best_acc = resume['best_acc']\n",
    "    start_epoch = resume['epoch']\n",
    "    student_model.load_state_dict(resume['state_dict'])\n",
    "    optimizer.load_state_dict(resume['optimizer'])\n",
    "    logger = Logger(os.path.join(checkpoint, 'log.txt'), resume=True)\n",
    "else:\n",
    "    logger = Logger(os.path.join(checkpoint, 'log.txt'))\n",
    "    logger.set_names(['Learning Rate', 'Train Loss', 'Valid Loss', 'Source Loss', 'Train Acc.', 'Valid Acc.', 'Source ACC.', 'Train AUROC', 'Valid AUROC', 'Source AUROC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EfficientNet(\n",
       "  (_conv_stem): Conv2dStaticSamePadding(\n",
       "    3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
       "    (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "  )\n",
       "  (_gn0): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "  (_blocks): ModuleList(\n",
       "    (0): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        32, 32, kernel_size=(3, 3), stride=[1, 1], groups=32, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        32, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        8, 32, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 16, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (1): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 96, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        96, 96, kernel_size=(3, 3), stride=[2, 2], groups=96, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 96, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        96, 4, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        4, 96, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 24, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (2): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 144, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 144, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 24, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (3): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 144, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        144, 144, kernel_size=(5, 5), stride=[2, 2], groups=144, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 144, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 40, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (4): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 240, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        240, 240, kernel_size=(5, 5), stride=(1, 1), groups=240, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 240, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 40, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (5): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 240, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        240, 240, kernel_size=(3, 3), stride=[2, 2], groups=240, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 240, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 80, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (6): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 480, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 480, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 80, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (7): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 480, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 480, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 80, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (8): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 480, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        480, 480, kernel_size=(5, 5), stride=[1, 1], groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 480, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 112, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (9): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 672, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 672, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 112, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (10): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 672, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 672, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 112, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (11): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 672, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5), stride=[2, 2], groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 672, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 192, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (12): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 1152, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 1152, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 192, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (13): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 1152, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 1152, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 192, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (14): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 1152, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 1152, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 192, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (15): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 1152, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(3, 3), stride=[1, 1], groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 1152, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 320, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "  )\n",
       "  (_conv_head): Conv2dStaticSamePadding(\n",
       "    320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "    (static_padding): Identity()\n",
       "  )\n",
       "  (_gn1): GroupNorm(8, 1280, eps=1e-05, affine=True)\n",
       "  (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n",
       "  (_dropout): Dropout(p=0.2, inplace=False)\n",
       "  (_fc): Linear(in_features=1280, out_features=2, bias=True)\n",
       "  (_swish): MemoryEfficientSwish()\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for param in teacher_model.parameters():\n",
    "    param.requires_grad = False\n",
    "teacher_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_model_weights = {}\n",
    "for name, param in teacher_model.named_parameters():\n",
    "    teacher_model_weights[name] = param.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_cls(model):\n",
    "    l2_cls = torch.tensor(0.).cuda()\n",
    "    for name, param in model.named_parameters():\n",
    "        if name.startswith(fc_name):\n",
    "            l2_cls += 0.5 * torch.norm(param) ** 2\n",
    "    return l2_cls\n",
    "\n",
    "def reg_l2sp(model):\n",
    "    sp_loss = torch.tensor(0.).cuda()\n",
    "    for name, param in model.named_parameters():\n",
    "        if not name.startswith(fc_name):\n",
    "            sp_loss += 0.5 * torch.norm(param - teacher_model_weights[name]) ** 2\n",
    "    return sp_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, teacher_model, student_model, criterion, optimizer, epoch, use_cuda):\n",
    "    teacher_model.eval()\n",
    "    student_model.train()\n",
    "    \n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    arc = AverageMeter()\n",
    "    end = time.time()\n",
    "    cls_losses = AverageMeter()\n",
    "    sp_losses = AverageMeter()\n",
    "    main_losses = AverageMeter()\n",
    "    alpha = AverageMeter()\n",
    "    \n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        batch_size = inputs.size(0)\n",
    "        if batch_size < train_batch:\n",
    "            continue\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            \n",
    "        r = np.random.rand(1)\n",
    "        if cm_beta > 0 and r < cm_prob:\n",
    "            \n",
    "            rand_index = torch.randperm(inputs.size()[0]).cuda()\n",
    "            tt= targets[rand_index]\n",
    "            boolean = targets==tt\n",
    "            rand_index = rand_index[boolean]\n",
    "            lam = np.random.beta(cm_beta, cm_beta)\n",
    "            bbx1, bby1, bbx2, bby2 = rand_bbox(inputs.size(), lam)\n",
    "            inputs[boolean, :, bbx1:bbx2, bby1:bby2] = inputs[rand_index, :, bbx1:bbx2, bby1:bby2]\n",
    "\n",
    "        # compute output\n",
    "        with torch.no_grad():\n",
    "            teacher_outputs = teacher_model(inputs)\n",
    "            teacher_loss = criterion(teacher_outputs, targets)\n",
    "            sp_alpha = 0\n",
    "            sigmoid = nn.Sigmoid()\n",
    "            sp_alpha += sigmoid(-teacher_loss)\n",
    "        \n",
    "        outputs = student_model(inputs)\n",
    "        loss_main = criterion(outputs, targets)\n",
    "        loss_cls = 0\n",
    "        loss_sp = 0\n",
    "        loss_cls = reg_cls(student_model)\n",
    "        loss_sp = reg_l2sp(student_model)\n",
    "        loss =  loss_main\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1 = accuracy(outputs.data, targets.data)\n",
    "        losses.update(loss.data.tolist(), inputs.size(0))\n",
    "        top1.update(prec1[0], inputs.size(0))\n",
    "        cls_losses.update(loss_cls, inputs.size(0))\n",
    "        sp_losses.update(loss_sp, inputs.size(0))\n",
    "        main_losses.update(loss_main.tolist(), inputs.size(0))\n",
    "        alpha.update(sp_alpha, inputs.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        \n",
    "#         if batch_idx % 100 == 0:\n",
    "#             print('{batch}/{size} | Loss:{loss:.4f} | MainLoss:{main:.4f} | SPLoss:{sp:.4f} | CLSLoss:{cls:.4f} | top1:{tp1:.4f} | AUROC:{ac:.4f}'.format(\n",
    "#                      batch=batch_idx+1, size=len(train_loader), loss=losses.avg, main=main_losses.avg, sp=sp_losses.avg, cls=cls_losses.avg, tp1=top1.avg, ac=arc.avg))\n",
    "    print('Train | {batch}/{size} | Loss:{loss:.4f} | MainLoss:{main:.4f} | Alpha:{alp:.4f} | SPLoss:{sp:.4f} | CLSLoss:{cls:.4f} | top1:{tp1:.4f} | AUROC:{ac:.4f}'.format(\n",
    "                     batch=batch_idx+1, size=len(train_loader), loss=losses.avg, main=main_losses.avg, alp=alpha.avg, sp=sp_losses.avg, cls=cls_losses.avg, tp1=top1.avg, ac=arc.avg))\n",
    "    return (losses.avg, top1.avg, arc.avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(val_loader, model, criterion, epoch, use_cuda):\n",
    "    global best_acc\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    arc = AverageMeter()\n",
    "    cls_losses = AverageMeter()\n",
    "    sp_losses = AverageMeter()\n",
    "    main_losses = AverageMeter()\n",
    "\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(val_loader):\n",
    "            # measure data loading time\n",
    "            data_time.update(time.time() - end)\n",
    "\n",
    "            if use_cuda:\n",
    "                inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "            # compute output\n",
    "            outputs = model(inputs)\n",
    "            loss_main = criterion(outputs, targets)\n",
    "            loss_cls = 0\n",
    "            loss_sp = 0\n",
    "            loss_cls = reg_cls(model)\n",
    "            loss_sp = reg_l2sp(model)\n",
    "            loss = loss_main + 0*loss_sp + 0*loss_cls\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            prec1 = accuracy(outputs.data, targets.data)\n",
    "            auroc = roc_auc_score(targets.cpu().detach().numpy(), outputs.cpu().detach().numpy()[:,1])\n",
    "            losses.update(loss.data.tolist(), inputs.size(0))\n",
    "            top1.update(prec1[0], inputs.size(0))\n",
    "            arc.update(auroc, inputs.size(0))\n",
    "            cls_losses.update(loss_cls, inputs.size(0))\n",
    "            sp_losses.update(loss_sp, inputs.size(0))\n",
    "            main_losses.update(loss_main.tolist(), inputs.size(0))\n",
    "\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "    print('Test | {batch}/{size} | Loss:{loss:.4f} | MainLoss:{main:.4f} | SPLoss:{sp:.4f} | CLSLoss:{cls:.4f} | top1:{tp1:.4f} | AUROC:{ac:.4f}'.format(\n",
    "                     batch=batch_idx+1, size=len(train_loader), loss=losses.avg, main=main_losses.avg, sp=sp_losses.avg, cls=cls_losses.avg, tp1=top1.avg, ac=arc.avg))\n",
    "    return (losses.avg, top1.avg, arc.avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, checkpoint='checkpoint', filename='checkpoint.pth.tar'):\n",
    "    filepath = os.path.join(checkpoint, filename)\n",
    "    torch.save(state, filepath)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filepath, os.path.join(checkpoint, 'model_best.pth.tar'))\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    global state\n",
    "    lr_set = [1, 1e-1, 1e-2, 1e-3, 1e-4, 1e-5]\n",
    "    lr_list = schedule.copy()\n",
    "    lr_list.append(epoch)\n",
    "    lr_list.sort()\n",
    "    idx = lr_list.index(epoch)\n",
    "    state['lr'] *= lr_set[idx]\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = state['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [1 | 1000] LR: 0.001000\n",
      "Train | 20/20 | Loss:1.0848 | MainLoss:1.0848 | Alpha:0.0253 | SPLoss:45.2560 | CLSLoss:4.7257 | top1:50.0750 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.6969 | MainLoss:0.6969 | SPLoss:97.0363 | CLSLoss:4.4243 | top1:50.1900 | AUROC:0.5083\n",
      "Test | 39/20 | Loss:0.5891 | MainLoss:0.5891 | SPLoss:97.0365 | CLSLoss:4.4242 | top1:63.5385 | AUROC:0.9705\n",
      "\n",
      "Epoch: [2 | 1000] LR: 0.001300\n",
      "Train | 20/20 | Loss:0.6986 | MainLoss:0.6986 | Alpha:0.3323 | SPLoss:3.1959 | CLSLoss:4.3171 | top1:50.7250 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.6972 | MainLoss:0.6972 | SPLoss:7.0607 | CLSLoss:4.2432 | top1:49.9902 | AUROC:0.5054\n",
      "Test | 39/20 | Loss:0.6670 | MainLoss:0.6670 | SPLoss:7.0607 | CLSLoss:4.2432 | top1:52.0897 | AUROC:0.9085\n",
      "\n",
      "Epoch: [3 | 1000] LR: 0.001600\n",
      "Train | 20/20 | Loss:0.6963 | MainLoss:0.6963 | Alpha:0.3327 | SPLoss:0.8740 | CLSLoss:4.2115 | top1:51.8250 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.6973 | MainLoss:0.6973 | SPLoss:2.3087 | CLSLoss:4.1954 | top1:50.1343 | AUROC:0.5178\n",
      "Test | 39/20 | Loss:0.6501 | MainLoss:0.6501 | SPLoss:2.3087 | CLSLoss:4.1954 | top1:50.7564 | AUROC:0.9811\n",
      "\n",
      "Epoch: [4 | 1000] LR: 0.001900\n",
      "Train | 20/20 | Loss:0.6966 | MainLoss:0.6966 | Alpha:0.3326 | SPLoss:0.5136 | CLSLoss:4.1542 | top1:51.1500 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.6957 | MainLoss:0.6957 | SPLoss:1.1533 | CLSLoss:4.1354 | top1:50.2261 | AUROC:0.5250\n",
      "Test | 39/20 | Loss:0.6452 | MainLoss:0.6452 | SPLoss:1.1533 | CLSLoss:4.1354 | top1:52.4872 | AUROC:0.9866\n",
      "\n",
      "Epoch: [5 | 1000] LR: 0.002200\n",
      "Train | 20/20 | Loss:0.6952 | MainLoss:0.6952 | Alpha:0.3333 | SPLoss:0.9039 | CLSLoss:4.0775 | top1:51.8250 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.6909 | MainLoss:0.6909 | SPLoss:2.6627 | CLSLoss:4.0404 | top1:52.7851 | AUROC:0.5404\n",
      "Test | 39/20 | Loss:0.5597 | MainLoss:0.5597 | SPLoss:2.6627 | CLSLoss:4.0404 | top1:78.6923 | AUROC:0.9889\n",
      "\n",
      "Epoch: [6 | 1000] LR: 0.002500\n",
      "Train | 20/20 | Loss:0.6871 | MainLoss:0.6871 | Alpha:0.3352 | SPLoss:1.9950 | CLSLoss:4.0302 | top1:55.0500 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.6906 | MainLoss:0.6906 | SPLoss:5.8079 | CLSLoss:4.0047 | top1:54.1874 | AUROC:0.5619\n",
      "Test | 39/20 | Loss:0.4783 | MainLoss:0.4783 | SPLoss:5.8079 | CLSLoss:4.0047 | top1:82.4487 | AUROC:0.9833\n",
      "\n",
      "Epoch: [7 | 1000] LR: 0.002800\n",
      "Train | 20/20 | Loss:0.6672 | MainLoss:0.6672 | Alpha:0.3384 | SPLoss:5.1022 | CLSLoss:4.0061 | top1:59.0750 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.6823 | MainLoss:0.6823 | SPLoss:17.3472 | CLSLoss:3.9857 | top1:56.6022 | AUROC:0.5947\n",
      "Test | 39/20 | Loss:0.4676 | MainLoss:0.4676 | SPLoss:17.3472 | CLSLoss:3.9858 | top1:79.1154 | AUROC:0.9690\n",
      "\n",
      "Epoch: [8 | 1000] LR: 0.003100\n",
      "Train | 20/20 | Loss:0.6411 | MainLoss:0.6411 | Alpha:0.3445 | SPLoss:11.3311 | CLSLoss:4.0089 | top1:62.3500 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.6622 | MainLoss:0.6622 | SPLoss:31.7523 | CLSLoss:4.0038 | top1:60.8060 | AUROC:0.6454\n",
      "Test | 39/20 | Loss:0.4924 | MainLoss:0.4924 | SPLoss:31.7523 | CLSLoss:4.0038 | top1:77.4487 | AUROC:0.9112\n",
      "\n",
      "Epoch: [9 | 1000] LR: 0.003400\n",
      "Train | 20/20 | Loss:0.6058 | MainLoss:0.6058 | Alpha:0.3525 | SPLoss:15.9664 | CLSLoss:4.0847 | top1:67.0000 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.6433 | MainLoss:0.6433 | SPLoss:41.3969 | CLSLoss:4.1345 | top1:63.4109 | AUROC:0.6926\n",
      "Test | 39/20 | Loss:0.4122 | MainLoss:0.4122 | SPLoss:41.3970 | CLSLoss:4.1345 | top1:82.0000 | AUROC:0.9343\n",
      "\n",
      "Epoch: [10 | 1000] LR: 0.003700\n",
      "Train | 20/20 | Loss:0.5646 | MainLoss:0.5646 | Alpha:0.3630 | SPLoss:18.7996 | CLSLoss:4.1973 | top1:71.0750 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.6184 | MainLoss:0.6184 | SPLoss:57.2311 | CLSLoss:4.1692 | top1:65.8683 | AUROC:0.7194\n",
      "Test | 39/20 | Loss:0.4989 | MainLoss:0.4989 | SPLoss:57.2310 | CLSLoss:4.1692 | top1:75.3590 | AUROC:0.8941\n",
      "\n",
      "Epoch: [11 | 1000] LR: 0.004000\n",
      "Train | 20/20 | Loss:0.5496 | MainLoss:0.5496 | Alpha:0.3682 | SPLoss:24.0726 | CLSLoss:4.2710 | top1:71.4250 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.6092 | MainLoss:0.6092 | SPLoss:59.1900 | CLSLoss:4.3585 | top1:67.6966 | AUROC:0.7403\n",
      "Test | 39/20 | Loss:0.4817 | MainLoss:0.4817 | SPLoss:59.1900 | CLSLoss:4.3585 | top1:76.7949 | AUROC:0.8860\n",
      "\n",
      "Epoch: [12 | 1000] LR: 0.004000\n",
      "Train | 20/20 | Loss:0.5009 | MainLoss:0.5009 | Alpha:0.3829 | SPLoss:18.4364 | CLSLoss:4.4655 | top1:75.8500 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.6001 | MainLoss:0.6001 | SPLoss:49.3693 | CLSLoss:4.4321 | top1:68.0865 | AUROC:0.7457\n",
      "Test | 39/20 | Loss:0.5037 | MainLoss:0.5037 | SPLoss:49.3693 | CLSLoss:4.4321 | top1:75.4487 | AUROC:0.8397\n",
      "\n",
      "Epoch: [13 | 1000] LR: 0.004000\n",
      "Train | 20/20 | Loss:0.4788 | MainLoss:0.4788 | Alpha:0.3865 | SPLoss:25.3409 | CLSLoss:4.5444 | top1:77.4500 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.6067 | MainLoss:0.6067 | SPLoss:66.4456 | CLSLoss:4.5732 | top1:69.0203 | AUROC:0.7580\n",
      "Test | 39/20 | Loss:0.5287 | MainLoss:0.5287 | SPLoss:66.4456 | CLSLoss:4.5732 | top1:73.7051 | AUROC:0.8440\n",
      "\n",
      "Epoch: [14 | 1000] LR: 0.004000\n",
      "Train | 20/20 | Loss:0.4627 | MainLoss:0.4627 | Alpha:0.3960 | SPLoss:19.0692 | CLSLoss:4.5822 | top1:77.7250 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.6280 | MainLoss:0.6280 | SPLoss:48.1708 | CLSLoss:4.4043 | top1:67.9686 | AUROC:0.7637\n",
      "Test | 39/20 | Loss:0.4742 | MainLoss:0.4742 | SPLoss:48.1709 | CLSLoss:4.4043 | top1:77.3333 | AUROC:0.8548\n",
      "\n",
      "Epoch: [15 | 1000] LR: 0.004000\n",
      "Train | 20/20 | Loss:0.4040 | MainLoss:0.4040 | Alpha:0.3911 | SPLoss:16.9357 | CLSLoss:4.5896 | top1:81.6750 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.6414 | MainLoss:0.6414 | SPLoss:41.0707 | CLSLoss:4.7620 | top1:69.5183 | AUROC:0.7664\n",
      "Test | 39/20 | Loss:0.6078 | MainLoss:0.6078 | SPLoss:41.0708 | CLSLoss:4.7620 | top1:72.3333 | AUROC:0.8027\n",
      "\n",
      "Epoch: [16 | 1000] LR: 0.004000\n",
      "Train | 20/20 | Loss:0.3810 | MainLoss:0.3810 | Alpha:0.4154 | SPLoss:12.7734 | CLSLoss:4.8907 | top1:82.1500 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.6536 | MainLoss:0.6536 | SPLoss:34.6094 | CLSLoss:4.9006 | top1:69.6265 | AUROC:0.7713\n",
      "Test | 39/20 | Loss:0.6051 | MainLoss:0.6051 | SPLoss:34.6094 | CLSLoss:4.9006 | top1:71.7692 | AUROC:0.7878\n",
      "\n",
      "Epoch: [17 | 1000] LR: 0.004000\n",
      "Train | 20/20 | Loss:0.3778 | MainLoss:0.3778 | Alpha:0.4049 | SPLoss:13.6921 | CLSLoss:5.0258 | top1:82.9250 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.6343 | MainLoss:0.6343 | SPLoss:36.3175 | CLSLoss:4.9390 | top1:69.8296 | AUROC:0.7703\n",
      "Test | 39/20 | Loss:0.7102 | MainLoss:0.7102 | SPLoss:36.3176 | CLSLoss:4.9390 | top1:66.3077 | AUROC:0.7205\n",
      "\n",
      "Epoch: [18 | 1000] LR: 0.004000\n",
      "Train | 20/20 | Loss:0.3425 | MainLoss:0.3425 | Alpha:0.4183 | SPLoss:11.7509 | CLSLoss:5.0676 | top1:84.4750 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.6578 | MainLoss:0.6578 | SPLoss:31.1872 | CLSLoss:5.2332 | top1:70.5537 | AUROC:0.7779\n",
      "Test | 39/20 | Loss:0.6401 | MainLoss:0.6401 | SPLoss:31.1872 | CLSLoss:5.2332 | top1:71.6026 | AUROC:0.7973\n",
      "\n",
      "Epoch: [19 | 1000] LR: 0.004000\n",
      "Train | 20/20 | Loss:0.3204 | MainLoss:0.3204 | Alpha:0.4272 | SPLoss:11.0358 | CLSLoss:5.4460 | top1:85.9000 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.6829 | MainLoss:0.6829 | SPLoss:28.7182 | CLSLoss:5.4681 | top1:69.9672 | AUROC:0.7757\n",
      "Test | 39/20 | Loss:0.7406 | MainLoss:0.7406 | SPLoss:28.7183 | CLSLoss:5.4681 | top1:68.2051 | AUROC:0.7546\n",
      "\n",
      "Epoch: [20 | 1000] LR: 0.003999\n",
      "Train | 20/20 | Loss:0.3192 | MainLoss:0.3192 | Alpha:0.4250 | SPLoss:11.5743 | CLSLoss:5.4532 | top1:85.6250 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.7063 | MainLoss:0.7063 | SPLoss:27.8195 | CLSLoss:5.5456 | top1:70.3080 | AUROC:0.7796\n",
      "Test | 39/20 | Loss:0.7798 | MainLoss:0.7798 | SPLoss:27.8195 | CLSLoss:5.5456 | top1:68.1154 | AUROC:0.7579\n",
      "\n",
      "Epoch: [21 | 1000] LR: 0.003999\n",
      "Train | 20/20 | Loss:0.2945 | MainLoss:0.2945 | Alpha:0.4305 | SPLoss:11.9731 | CLSLoss:5.5721 | top1:86.5500 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.7452 | MainLoss:0.7452 | SPLoss:29.0453 | CLSLoss:5.7080 | top1:71.0321 | AUROC:0.7877\n",
      "Test | 39/20 | Loss:0.8558 | MainLoss:0.8558 | SPLoss:29.0453 | CLSLoss:5.7080 | top1:67.8718 | AUROC:0.7463\n",
      "\n",
      "Epoch: [22 | 1000] LR: 0.003999\n",
      "Train | 20/20 | Loss:0.2825 | MainLoss:0.2825 | Alpha:0.4358 | SPLoss:10.4667 | CLSLoss:5.7585 | top1:87.6000 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.6903 | MainLoss:0.6903 | SPLoss:29.1747 | CLSLoss:5.7262 | top1:71.0452 | AUROC:0.7849\n",
      "Test | 39/20 | Loss:0.8414 | MainLoss:0.8414 | SPLoss:29.1746 | CLSLoss:5.7262 | top1:64.8974 | AUROC:0.7061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [23 | 1000] LR: 0.003999\n",
      "Train | 20/20 | Loss:0.2783 | MainLoss:0.2783 | Alpha:0.4340 | SPLoss:9.6295 | CLSLoss:5.7714 | top1:87.8000 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.7274 | MainLoss:0.7274 | SPLoss:25.1570 | CLSLoss:5.8731 | top1:71.5007 | AUROC:0.7918\n",
      "Test | 39/20 | Loss:0.9685 | MainLoss:0.9685 | SPLoss:25.1570 | CLSLoss:5.8731 | top1:62.9744 | AUROC:0.6812\n",
      "\n",
      "Epoch: [24 | 1000] LR: 0.003999\n",
      "Train | 20/20 | Loss:0.2516 | MainLoss:0.2516 | Alpha:0.4447 | SPLoss:7.1508 | CLSLoss:5.9875 | top1:89.3250 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.7493 | MainLoss:0.7493 | SPLoss:19.9539 | CLSLoss:5.9884 | top1:71.2942 | AUROC:0.7881\n",
      "Test | 39/20 | Loss:0.9567 | MainLoss:0.9567 | SPLoss:19.9539 | CLSLoss:5.9884 | top1:63.7308 | AUROC:0.6895\n",
      "\n",
      "Epoch: [25 | 1000] LR: 0.003998\n",
      "Train | 20/20 | Loss:0.2315 | MainLoss:0.2315 | Alpha:0.4488 | SPLoss:8.9180 | CLSLoss:6.1788 | top1:89.9750 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.7998 | MainLoss:0.7998 | SPLoss:23.5652 | CLSLoss:6.2697 | top1:71.3991 | AUROC:0.7869\n",
      "Test | 39/20 | Loss:0.9982 | MainLoss:0.9982 | SPLoss:23.5652 | CLSLoss:6.2697 | top1:65.4103 | AUROC:0.7077\n",
      "\n",
      "Epoch: [26 | 1000] LR: 0.003998\n",
      "Train | 20/20 | Loss:0.2544 | MainLoss:0.2544 | Alpha:0.4448 | SPLoss:14.2094 | CLSLoss:6.2271 | top1:89.1000 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.7512 | MainLoss:0.7512 | SPLoss:35.5123 | CLSLoss:6.0781 | top1:71.2287 | AUROC:0.7905\n",
      "Test | 39/20 | Loss:0.9534 | MainLoss:0.9534 | SPLoss:35.5123 | CLSLoss:6.0781 | top1:64.3205 | AUROC:0.7005\n",
      "\n",
      "Epoch: [27 | 1000] LR: 0.003998\n",
      "Train | 20/20 | Loss:0.2580 | MainLoss:0.2580 | Alpha:0.4425 | SPLoss:9.4989 | CLSLoss:6.1540 | top1:88.3000 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.7194 | MainLoss:0.7194 | SPLoss:25.2174 | CLSLoss:6.1052 | top1:71.9561 | AUROC:0.7931\n",
      "Test | 39/20 | Loss:1.0162 | MainLoss:1.0162 | SPLoss:25.2174 | CLSLoss:6.1052 | top1:61.5128 | AUROC:0.6576\n",
      "\n",
      "Epoch: [28 | 1000] LR: 0.003997\n",
      "Train | 20/20 | Loss:0.2607 | MainLoss:0.2607 | Alpha:0.4462 | SPLoss:10.5557 | CLSLoss:5.9719 | top1:88.2250 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.7223 | MainLoss:0.7223 | SPLoss:29.0815 | CLSLoss:5.8194 | top1:71.6448 | AUROC:0.7928\n",
      "Test | 39/20 | Loss:0.9608 | MainLoss:0.9608 | SPLoss:29.0815 | CLSLoss:5.8194 | top1:63.8205 | AUROC:0.6875\n",
      "\n",
      "Epoch: [29 | 1000] LR: 0.003997\n",
      "Train | 20/20 | Loss:0.2247 | MainLoss:0.2247 | Alpha:0.4502 | SPLoss:9.2354 | CLSLoss:5.9741 | top1:90.3500 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.7439 | MainLoss:0.7439 | SPLoss:22.9291 | CLSLoss:6.0128 | top1:72.0511 | AUROC:0.7960\n",
      "Test | 39/20 | Loss:1.0342 | MainLoss:1.0342 | SPLoss:22.9291 | CLSLoss:6.0128 | top1:62.0897 | AUROC:0.6679\n",
      "\n",
      "Epoch: [30 | 1000] LR: 0.003997\n",
      "Train | 20/20 | Loss:0.2281 | MainLoss:0.2281 | Alpha:0.4454 | SPLoss:7.4652 | CLSLoss:6.1301 | top1:89.9500 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.7699 | MainLoss:0.7699 | SPLoss:19.2250 | CLSLoss:6.1807 | top1:71.6940 | AUROC:0.7924\n",
      "Test | 39/20 | Loss:1.0827 | MainLoss:1.0827 | SPLoss:19.2250 | CLSLoss:6.1807 | top1:61.3718 | AUROC:0.6570\n",
      "\n",
      "Epoch: [31 | 1000] LR: 0.003996\n",
      "Train | 20/20 | Loss:0.2268 | MainLoss:0.2268 | Alpha:0.4495 | SPLoss:9.6783 | CLSLoss:6.1699 | top1:90.6250 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.7818 | MainLoss:0.7818 | SPLoss:24.0241 | CLSLoss:6.2798 | top1:72.1166 | AUROC:0.7969\n",
      "Test | 39/20 | Loss:1.0601 | MainLoss:1.0601 | SPLoss:24.0241 | CLSLoss:6.2798 | top1:64.2051 | AUROC:0.6858\n",
      "\n",
      "Epoch: [32 | 1000] LR: 0.003996\n",
      "Train | 20/20 | Loss:0.2251 | MainLoss:0.2251 | Alpha:0.4494 | SPLoss:9.0608 | CLSLoss:6.2136 | top1:90.1250 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8054 | MainLoss:0.8054 | SPLoss:22.3634 | CLSLoss:6.2663 | top1:71.8512 | AUROC:0.7945\n",
      "Test | 39/20 | Loss:1.0353 | MainLoss:1.0353 | SPLoss:22.3634 | CLSLoss:6.2663 | top1:64.9231 | AUROC:0.7021\n",
      "\n",
      "Epoch: [33 | 1000] LR: 0.003996\n",
      "Train | 20/20 | Loss:0.2135 | MainLoss:0.2135 | Alpha:0.4537 | SPLoss:6.9100 | CLSLoss:6.2700 | top1:90.9250 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8105 | MainLoss:0.8105 | SPLoss:16.8306 | CLSLoss:6.4169 | top1:72.0478 | AUROC:0.8001\n",
      "Test | 39/20 | Loss:1.1373 | MainLoss:1.1373 | SPLoss:16.8306 | CLSLoss:6.4169 | top1:62.6282 | AUROC:0.6698\n",
      "\n",
      "Epoch: [34 | 1000] LR: 0.003995\n",
      "Train | 20/20 | Loss:0.1896 | MainLoss:0.1896 | Alpha:0.4591 | SPLoss:8.0668 | CLSLoss:6.5814 | top1:91.4250 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.7734 | MainLoss:0.7734 | SPLoss:20.6570 | CLSLoss:6.6029 | top1:72.1953 | AUROC:0.7980\n",
      "Test | 39/20 | Loss:1.1188 | MainLoss:1.1188 | SPLoss:20.6570 | CLSLoss:6.6029 | top1:61.4744 | AUROC:0.6565\n",
      "\n",
      "Epoch: [35 | 1000] LR: 0.003995\n",
      "Train | 20/20 | Loss:0.1947 | MainLoss:0.1947 | Alpha:0.4538 | SPLoss:6.0979 | CLSLoss:6.6511 | top1:91.5250 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8237 | MainLoss:0.8237 | SPLoss:16.5028 | CLSLoss:6.6473 | top1:71.5138 | AUROC:0.7992\n",
      "Test | 39/20 | Loss:1.1757 | MainLoss:1.1757 | SPLoss:16.5028 | CLSLoss:6.6474 | top1:61.1667 | AUROC:0.6554\n",
      "\n",
      "Epoch: [36 | 1000] LR: 0.003994\n",
      "Train | 20/20 | Loss:0.2203 | MainLoss:0.2203 | Alpha:0.4523 | SPLoss:6.5325 | CLSLoss:6.5908 | top1:90.2750 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8472 | MainLoss:0.8472 | SPLoss:17.3544 | CLSLoss:6.5019 | top1:71.4941 | AUROC:0.7970\n",
      "Test | 39/20 | Loss:1.2221 | MainLoss:1.2221 | SPLoss:17.3543 | CLSLoss:6.5019 | top1:59.9487 | AUROC:0.6332\n",
      "\n",
      "Epoch: [37 | 1000] LR: 0.003994\n",
      "Train | 20/20 | Loss:0.1851 | MainLoss:0.1851 | Alpha:0.4561 | SPLoss:8.5016 | CLSLoss:6.4111 | top1:92.0000 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8241 | MainLoss:0.8241 | SPLoss:20.4294 | CLSLoss:6.4580 | top1:71.9430 | AUROC:0.7965\n",
      "Test | 39/20 | Loss:1.1537 | MainLoss:1.1537 | SPLoss:20.4294 | CLSLoss:6.4580 | top1:62.4103 | AUROC:0.6651\n",
      "\n",
      "Epoch: [38 | 1000] LR: 0.003993\n",
      "Train | 20/20 | Loss:0.1814 | MainLoss:0.1814 | Alpha:0.4595 | SPLoss:6.2004 | CLSLoss:6.5334 | top1:92.3250 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.9261 | MainLoss:0.9261 | SPLoss:16.4262 | CLSLoss:6.7102 | top1:71.7759 | AUROC:0.7920\n",
      "Test | 39/20 | Loss:1.3628 | MainLoss:1.3628 | SPLoss:16.4262 | CLSLoss:6.7102 | top1:60.6026 | AUROC:0.6481\n",
      "\n",
      "Epoch: [39 | 1000] LR: 0.003993\n",
      "Train | 20/20 | Loss:0.1946 | MainLoss:0.1946 | Alpha:0.4536 | SPLoss:6.9864 | CLSLoss:6.7465 | top1:91.1500 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8003 | MainLoss:0.8003 | SPLoss:18.8541 | CLSLoss:6.6393 | top1:71.9758 | AUROC:0.7985\n",
      "Test | 39/20 | Loss:1.0988 | MainLoss:1.0988 | SPLoss:18.8541 | CLSLoss:6.6393 | top1:63.0128 | AUROC:0.6744\n",
      "\n",
      "Epoch: [40 | 1000] LR: 0.003992\n",
      "Train | 20/20 | Loss:0.1794 | MainLoss:0.1794 | Alpha:0.4576 | SPLoss:5.9244 | CLSLoss:6.7179 | top1:92.3500 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8119 | MainLoss:0.8119 | SPLoss:14.2862 | CLSLoss:6.7765 | top1:72.2215 | AUROC:0.7987\n",
      "Test | 39/20 | Loss:1.2807 | MainLoss:1.2807 | SPLoss:14.2862 | CLSLoss:6.7765 | top1:58.7436 | AUROC:0.6233\n",
      "\n",
      "Epoch: [41 | 1000] LR: 0.003992\n",
      "Train | 20/20 | Loss:0.1746 | MainLoss:0.1746 | Alpha:0.4611 | SPLoss:6.9255 | CLSLoss:6.9508 | top1:92.2500 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.9121 | MainLoss:0.9121 | SPLoss:17.4107 | CLSLoss:7.0266 | top1:73.1225 | AUROC:0.8069\n",
      "Test | 39/20 | Loss:1.5064 | MainLoss:1.5064 | SPLoss:17.4107 | CLSLoss:7.0265 | top1:59.5128 | AUROC:0.6290\n",
      "\n",
      "Epoch: [42 | 1000] LR: 0.003991\n",
      "Train | 20/20 | Loss:0.1899 | MainLoss:0.1899 | Alpha:0.4596 | SPLoss:7.0676 | CLSLoss:6.9276 | top1:91.1000 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.7679 | MainLoss:0.7679 | SPLoss:20.6759 | CLSLoss:6.5707 | top1:72.6966 | AUROC:0.8006\n",
      "Test | 39/20 | Loss:1.1939 | MainLoss:1.1939 | SPLoss:20.6760 | CLSLoss:6.5707 | top1:60.5000 | AUROC:0.6406\n",
      "\n",
      "Epoch: [43 | 1000] LR: 0.003991\n",
      "Train | 20/20 | Loss:0.1843 | MainLoss:0.1843 | Alpha:0.4594 | SPLoss:8.4399 | CLSLoss:6.4677 | top1:92.1250 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8525 | MainLoss:0.8525 | SPLoss:19.5022 | CLSLoss:6.4977 | top1:72.1396 | AUROC:0.8011\n",
      "Test | 39/20 | Loss:1.1711 | MainLoss:1.1711 | SPLoss:19.5022 | CLSLoss:6.4977 | top1:63.6154 | AUROC:0.6819\n",
      "\n",
      "Epoch: [44 | 1000] LR: 0.003990\n",
      "Train | 20/20 | Loss:0.1972 | MainLoss:0.1972 | Alpha:0.4559 | SPLoss:6.5717 | CLSLoss:6.4945 | top1:91.7000 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.7931 | MainLoss:0.7931 | SPLoss:16.4914 | CLSLoss:6.5571 | top1:72.0184 | AUROC:0.7992\n",
      "Test | 39/20 | Loss:1.2291 | MainLoss:1.2291 | SPLoss:16.4913 | CLSLoss:6.5571 | top1:59.0897 | AUROC:0.6285\n",
      "\n",
      "Epoch: [45 | 1000] LR: 0.003989\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 20/20 | Loss:0.1641 | MainLoss:0.1641 | Alpha:0.4602 | SPLoss:5.4454 | CLSLoss:6.6778 | top1:92.8000 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8741 | MainLoss:0.8741 | SPLoss:14.5659 | CLSLoss:6.8238 | top1:72.7982 | AUROC:0.8019\n",
      "Test | 39/20 | Loss:1.3866 | MainLoss:1.3866 | SPLoss:14.5660 | CLSLoss:6.8238 | top1:59.8333 | AUROC:0.6376\n",
      "\n",
      "Epoch: [46 | 1000] LR: 0.003989\n",
      "Train | 20/20 | Loss:0.1760 | MainLoss:0.1760 | Alpha:0.4598 | SPLoss:4.7410 | CLSLoss:6.9016 | top1:92.0250 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8249 | MainLoss:0.8249 | SPLoss:12.7214 | CLSLoss:6.9593 | top1:73.5682 | AUROC:0.8127\n",
      "Test | 39/20 | Loss:1.2794 | MainLoss:1.2794 | SPLoss:12.7214 | CLSLoss:6.9593 | top1:61.5385 | AUROC:0.6597\n",
      "\n",
      "Epoch: [47 | 1000] LR: 0.003988\n",
      "Train | 20/20 | Loss:0.1702 | MainLoss:0.1702 | Alpha:0.4621 | SPLoss:4.8792 | CLSLoss:7.0024 | top1:92.6000 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8392 | MainLoss:0.8392 | SPLoss:13.0107 | CLSLoss:6.7781 | top1:72.5000 | AUROC:0.8013\n",
      "Test | 39/20 | Loss:1.2645 | MainLoss:1.2645 | SPLoss:13.0107 | CLSLoss:6.7782 | top1:61.2051 | AUROC:0.6516\n",
      "\n",
      "Epoch: [48 | 1000] LR: 0.003987\n",
      "Train | 20/20 | Loss:0.2001 | MainLoss:0.2001 | Alpha:0.4574 | SPLoss:5.4000 | CLSLoss:6.7128 | top1:90.8500 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8295 | MainLoss:0.8295 | SPLoss:14.0993 | CLSLoss:6.6854 | top1:73.5223 | AUROC:0.8139\n",
      "Test | 39/20 | Loss:1.4115 | MainLoss:1.4115 | SPLoss:14.0993 | CLSLoss:6.6854 | top1:59.2308 | AUROC:0.6426\n",
      "\n",
      "Epoch: [49 | 1000] LR: 0.003987\n",
      "Train | 20/20 | Loss:0.2000 | MainLoss:0.2000 | Alpha:0.4517 | SPLoss:7.2075 | CLSLoss:6.6206 | top1:91.3250 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.7389 | MainLoss:0.7389 | SPLoss:18.5163 | CLSLoss:6.4229 | top1:72.4115 | AUROC:0.8004\n",
      "Test | 39/20 | Loss:1.3217 | MainLoss:1.3217 | SPLoss:18.5163 | CLSLoss:6.4229 | top1:55.1282 | AUROC:0.5797\n",
      "\n",
      "Epoch: [50 | 1000] LR: 0.003986\n",
      "Train | 20/20 | Loss:0.1873 | MainLoss:0.1873 | Alpha:0.4563 | SPLoss:6.6580 | CLSLoss:6.5829 | top1:91.9000 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8047 | MainLoss:0.8047 | SPLoss:17.7317 | CLSLoss:6.6634 | top1:73.2831 | AUROC:0.8068\n",
      "Test | 39/20 | Loss:1.2850 | MainLoss:1.2850 | SPLoss:17.7316 | CLSLoss:6.6634 | top1:60.3205 | AUROC:0.6427\n",
      "\n",
      "Epoch: [51 | 1000] LR: 0.003985\n",
      "Train | 20/20 | Loss:0.1932 | MainLoss:0.1932 | Alpha:0.4585 | SPLoss:5.7542 | CLSLoss:6.5805 | top1:91.0750 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.7791 | MainLoss:0.7791 | SPLoss:15.1352 | CLSLoss:6.3704 | top1:72.4607 | AUROC:0.8034\n",
      "Test | 39/20 | Loss:1.2350 | MainLoss:1.2350 | SPLoss:15.1352 | CLSLoss:6.3704 | top1:59.5128 | AUROC:0.6355\n",
      "\n",
      "Epoch: [52 | 1000] LR: 0.000398\n",
      "Train | 20/20 | Loss:0.1688 | MainLoss:0.1688 | Alpha:0.4564 | SPLoss:0.1884 | CLSLoss:6.4053 | top1:92.5500 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.7927 | MainLoss:0.7927 | SPLoss:0.4472 | CLSLoss:6.4431 | top1:72.8965 | AUROC:0.8078\n",
      "Test | 39/20 | Loss:1.2081 | MainLoss:1.2081 | SPLoss:0.4472 | CLSLoss:6.4431 | top1:59.8333 | AUROC:0.6411\n",
      "\n",
      "Epoch: [53 | 1000] LR: 0.000398\n",
      "Train | 20/20 | Loss:0.1686 | MainLoss:0.1686 | Alpha:0.4592 | SPLoss:0.0857 | CLSLoss:6.4469 | top1:92.5250 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.7799 | MainLoss:0.7799 | SPLoss:0.2336 | CLSLoss:6.4616 | top1:73.1553 | AUROC:0.8110\n",
      "Test | 39/20 | Loss:1.2003 | MainLoss:1.2003 | SPLoss:0.2336 | CLSLoss:6.4616 | top1:60.2179 | AUROC:0.6479\n",
      "\n",
      "Epoch: [54 | 1000] LR: 0.000398\n",
      "Train | 20/20 | Loss:0.1454 | MainLoss:0.1454 | Alpha:0.4648 | SPLoss:0.0693 | CLSLoss:6.4966 | top1:93.9750 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.7912 | MainLoss:0.7912 | SPLoss:0.1907 | CLSLoss:6.5288 | top1:73.2569 | AUROC:0.8121\n",
      "Test | 39/20 | Loss:1.2290 | MainLoss:1.2290 | SPLoss:0.1907 | CLSLoss:6.5288 | top1:60.4487 | AUROC:0.6482\n",
      "\n",
      "Epoch: [55 | 1000] LR: 0.000398\n",
      "Train | 20/20 | Loss:0.1445 | MainLoss:0.1445 | Alpha:0.4669 | SPLoss:0.0524 | CLSLoss:6.5612 | top1:93.8000 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8054 | MainLoss:0.8054 | SPLoss:0.1550 | CLSLoss:6.6040 | top1:73.2929 | AUROC:0.8127\n",
      "Test | 39/20 | Loss:1.2653 | MainLoss:1.2653 | SPLoss:0.1550 | CLSLoss:6.6040 | top1:60.2436 | AUROC:0.6455\n",
      "\n",
      "Epoch: [56 | 1000] LR: 0.000398\n",
      "Train | 20/20 | Loss:0.1579 | MainLoss:0.1579 | Alpha:0.4625 | SPLoss:0.0483 | CLSLoss:6.6342 | top1:92.8500 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8059 | MainLoss:0.8059 | SPLoss:0.1197 | CLSLoss:6.6398 | top1:73.2110 | AUROC:0.8131\n",
      "Test | 39/20 | Loss:1.2581 | MainLoss:1.2581 | SPLoss:0.1197 | CLSLoss:6.6398 | top1:60.5256 | AUROC:0.6490\n",
      "\n",
      "Epoch: [57 | 1000] LR: 0.000398\n",
      "Train | 20/20 | Loss:0.1505 | MainLoss:0.1505 | Alpha:0.4645 | SPLoss:0.0685 | CLSLoss:6.6238 | top1:93.0000 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.7975 | MainLoss:0.7975 | SPLoss:0.1593 | CLSLoss:6.6387 | top1:73.3879 | AUROC:0.8143\n",
      "Test | 39/20 | Loss:1.2444 | MainLoss:1.2444 | SPLoss:0.1593 | CLSLoss:6.6387 | top1:60.7436 | AUROC:0.6512\n",
      "\n",
      "Epoch: [58 | 1000] LR: 0.000398\n",
      "Train | 20/20 | Loss:0.1469 | MainLoss:0.1469 | Alpha:0.4655 | SPLoss:0.0432 | CLSLoss:6.6678 | top1:93.6250 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8076 | MainLoss:0.8076 | SPLoss:0.1191 | CLSLoss:6.6879 | top1:73.5288 | AUROC:0.8139\n",
      "Test | 39/20 | Loss:1.2717 | MainLoss:1.2717 | SPLoss:0.1191 | CLSLoss:6.6879 | top1:60.9615 | AUROC:0.6503\n",
      "\n",
      "Epoch: [59 | 1000] LR: 0.000398\n",
      "Train | 20/20 | Loss:0.1425 | MainLoss:0.1425 | Alpha:0.4657 | SPLoss:0.0508 | CLSLoss:6.7064 | top1:93.7000 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8175 | MainLoss:0.8175 | SPLoss:0.1257 | CLSLoss:6.7199 | top1:73.4961 | AUROC:0.8139\n",
      "Test | 39/20 | Loss:1.2836 | MainLoss:1.2836 | SPLoss:0.1257 | CLSLoss:6.7199 | top1:60.7949 | AUROC:0.6525\n",
      "\n",
      "Epoch: [60 | 1000] LR: 0.000398\n",
      "Train | 20/20 | Loss:0.1510 | MainLoss:0.1510 | Alpha:0.4659 | SPLoss:0.0654 | CLSLoss:6.7466 | top1:93.8500 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8295 | MainLoss:0.8295 | SPLoss:0.1393 | CLSLoss:6.7543 | top1:73.4404 | AUROC:0.8145\n",
      "Test | 39/20 | Loss:1.2871 | MainLoss:1.2871 | SPLoss:0.1393 | CLSLoss:6.7543 | top1:60.8974 | AUROC:0.6524\n",
      "\n",
      "Epoch: [61 | 1000] LR: 0.000398\n",
      "Train | 20/20 | Loss:0.1418 | MainLoss:0.1418 | Alpha:0.4667 | SPLoss:0.0545 | CLSLoss:6.7563 | top1:93.3500 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8237 | MainLoss:0.8237 | SPLoss:0.1462 | CLSLoss:6.7717 | top1:73.3454 | AUROC:0.8137\n",
      "Test | 39/20 | Loss:1.2905 | MainLoss:1.2905 | SPLoss:0.1462 | CLSLoss:6.7717 | top1:60.7692 | AUROC:0.6495\n",
      "\n",
      "Epoch: [62 | 1000] LR: 0.000398\n",
      "Train | 20/20 | Loss:0.1497 | MainLoss:0.1497 | Alpha:0.4640 | SPLoss:0.0584 | CLSLoss:6.7891 | top1:93.7250 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8326 | MainLoss:0.8326 | SPLoss:0.1491 | CLSLoss:6.7933 | top1:73.4076 | AUROC:0.8129\n",
      "Test | 39/20 | Loss:1.3250 | MainLoss:1.3250 | SPLoss:0.1491 | CLSLoss:6.7933 | top1:60.4872 | AUROC:0.6484\n",
      "\n",
      "Epoch: [63 | 1000] LR: 0.000397\n",
      "Train | 20/20 | Loss:0.1445 | MainLoss:0.1445 | Alpha:0.4656 | SPLoss:0.0819 | CLSLoss:6.7799 | top1:93.6250 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8268 | MainLoss:0.8268 | SPLoss:0.2086 | CLSLoss:6.7809 | top1:73.1717 | AUROC:0.8125\n",
      "Test | 39/20 | Loss:1.2788 | MainLoss:1.2788 | SPLoss:0.2086 | CLSLoss:6.7809 | top1:61.1154 | AUROC:0.6521\n",
      "\n",
      "Epoch: [64 | 1000] LR: 0.000397\n",
      "Train | 20/20 | Loss:0.1344 | MainLoss:0.1344 | Alpha:0.4688 | SPLoss:0.0548 | CLSLoss:6.7980 | top1:94.0000 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8379 | MainLoss:0.8379 | SPLoss:0.1514 | CLSLoss:6.8260 | top1:73.3945 | AUROC:0.8131\n",
      "Test | 39/20 | Loss:1.3208 | MainLoss:1.3208 | SPLoss:0.1514 | CLSLoss:6.8260 | top1:60.7436 | AUROC:0.6505\n",
      "\n",
      "Epoch: [65 | 1000] LR: 0.000397\n",
      "Train | 20/20 | Loss:0.1315 | MainLoss:0.1315 | Alpha:0.4694 | SPLoss:0.0545 | CLSLoss:6.8475 | top1:94.1000 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8421 | MainLoss:0.8421 | SPLoss:0.1691 | CLSLoss:6.8617 | top1:73.5780 | AUROC:0.8123\n",
      "Test | 39/20 | Loss:1.3614 | MainLoss:1.3614 | SPLoss:0.1691 | CLSLoss:6.8617 | top1:60.3590 | AUROC:0.6460\n",
      "\n",
      "Epoch: [66 | 1000] LR: 0.000397\n",
      "Train | 20/20 | Loss:0.1452 | MainLoss:0.1452 | Alpha:0.4640 | SPLoss:0.0942 | CLSLoss:6.8822 | top1:93.8250 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8448 | MainLoss:0.8448 | SPLoss:0.2667 | CLSLoss:6.8864 | top1:73.1389 | AUROC:0.8126\n",
      "Test | 39/20 | Loss:1.3201 | MainLoss:1.3201 | SPLoss:0.2667 | CLSLoss:6.8864 | top1:59.9615 | AUROC:0.6411\n",
      "\n",
      "Epoch: [67 | 1000] LR: 0.000397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 20/20 | Loss:0.1345 | MainLoss:0.1345 | Alpha:0.4677 | SPLoss:0.0736 | CLSLoss:6.8657 | top1:94.0750 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8218 | MainLoss:0.8218 | SPLoss:0.1771 | CLSLoss:6.8703 | top1:73.5649 | AUROC:0.8131\n",
      "Test | 39/20 | Loss:1.3430 | MainLoss:1.3430 | SPLoss:0.1771 | CLSLoss:6.8703 | top1:59.8462 | AUROC:0.6381\n",
      "\n",
      "Epoch: [68 | 1000] LR: 0.000397\n",
      "Train | 20/20 | Loss:0.1233 | MainLoss:0.1233 | Alpha:0.4717 | SPLoss:0.0494 | CLSLoss:6.8888 | top1:94.2000 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8406 | MainLoss:0.8406 | SPLoss:0.1437 | CLSLoss:6.9139 | top1:73.6566 | AUROC:0.8144\n",
      "Test | 39/20 | Loss:1.3792 | MainLoss:1.3792 | SPLoss:0.1437 | CLSLoss:6.9139 | top1:60.2564 | AUROC:0.6409\n",
      "\n",
      "Epoch: [69 | 1000] LR: 0.000397\n",
      "Train | 20/20 | Loss:0.1317 | MainLoss:0.1317 | Alpha:0.4694 | SPLoss:0.0492 | CLSLoss:6.9353 | top1:94.0000 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8557 | MainLoss:0.8557 | SPLoss:0.1389 | CLSLoss:6.9537 | top1:73.6599 | AUROC:0.8154\n",
      "Test | 39/20 | Loss:1.3853 | MainLoss:1.3853 | SPLoss:0.1389 | CLSLoss:6.9537 | top1:60.2564 | AUROC:0.6406\n",
      "\n",
      "Epoch: [70 | 1000] LR: 0.000397\n",
      "Train | 20/20 | Loss:0.1434 | MainLoss:0.1434 | Alpha:0.4659 | SPLoss:0.0869 | CLSLoss:6.9353 | top1:93.5750 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8173 | MainLoss:0.8173 | SPLoss:0.2129 | CLSLoss:6.9269 | top1:73.8041 | AUROC:0.8165\n",
      "Test | 39/20 | Loss:1.3465 | MainLoss:1.3465 | SPLoss:0.2129 | CLSLoss:6.9269 | top1:60.0641 | AUROC:0.6380\n",
      "\n",
      "Epoch: [71 | 1000] LR: 0.000397\n",
      "Train | 20/20 | Loss:0.1585 | MainLoss:0.1585 | Alpha:0.4631 | SPLoss:0.0626 | CLSLoss:6.9242 | top1:92.7250 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8003 | MainLoss:0.8003 | SPLoss:0.1681 | CLSLoss:6.9214 | top1:73.7647 | AUROC:0.8160\n",
      "Test | 39/20 | Loss:1.3448 | MainLoss:1.3448 | SPLoss:0.1681 | CLSLoss:6.9214 | top1:59.5128 | AUROC:0.6319\n",
      "\n",
      "Epoch: [72 | 1000] LR: 0.000396\n",
      "Train | 20/20 | Loss:0.1320 | MainLoss:0.1320 | Alpha:0.4691 | SPLoss:0.0597 | CLSLoss:6.9246 | top1:94.5750 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8070 | MainLoss:0.8070 | SPLoss:0.1583 | CLSLoss:6.9380 | top1:73.8139 | AUROC:0.8153\n",
      "Test | 39/20 | Loss:1.3548 | MainLoss:1.3548 | SPLoss:0.1583 | CLSLoss:6.9380 | top1:59.3846 | AUROC:0.6341\n",
      "\n",
      "Epoch: [73 | 1000] LR: 0.000396\n",
      "Train | 20/20 | Loss:0.1453 | MainLoss:0.1453 | Alpha:0.4656 | SPLoss:0.0597 | CLSLoss:6.9580 | top1:93.8500 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8254 | MainLoss:0.8254 | SPLoss:0.1572 | CLSLoss:6.9722 | top1:73.4731 | AUROC:0.8160\n",
      "Test | 39/20 | Loss:1.3411 | MainLoss:1.3411 | SPLoss:0.1572 | CLSLoss:6.9722 | top1:60.0256 | AUROC:0.6368\n",
      "\n",
      "Epoch: [74 | 1000] LR: 0.000396\n",
      "Train | 20/20 | Loss:0.1251 | MainLoss:0.1251 | Alpha:0.4706 | SPLoss:0.0567 | CLSLoss:6.9944 | top1:94.1500 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8369 | MainLoss:0.8369 | SPLoss:0.1575 | CLSLoss:7.0209 | top1:73.5682 | AUROC:0.8172\n",
      "Test | 39/20 | Loss:1.3763 | MainLoss:1.3763 | SPLoss:0.1575 | CLSLoss:7.0209 | top1:59.9359 | AUROC:0.6337\n",
      "\n",
      "Epoch: [75 | 1000] LR: 0.000396\n",
      "Train | 20/20 | Loss:0.1560 | MainLoss:0.1560 | Alpha:0.4632 | SPLoss:0.0702 | CLSLoss:7.0035 | top1:93.3750 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8092 | MainLoss:0.8092 | SPLoss:0.1975 | CLSLoss:6.9789 | top1:73.7123 | AUROC:0.8172\n",
      "Test | 39/20 | Loss:1.3489 | MainLoss:1.3489 | SPLoss:0.1975 | CLSLoss:6.9789 | top1:59.6282 | AUROC:0.6340\n",
      "\n",
      "Epoch: [76 | 1000] LR: 0.000396\n",
      "Train | 20/20 | Loss:0.1424 | MainLoss:0.1424 | Alpha:0.4660 | SPLoss:0.0759 | CLSLoss:6.9780 | top1:93.8000 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.7963 | MainLoss:0.7963 | SPLoss:0.1848 | CLSLoss:6.9815 | top1:73.7287 | AUROC:0.8161\n",
      "Test | 39/20 | Loss:1.3343 | MainLoss:1.3343 | SPLoss:0.1848 | CLSLoss:6.9815 | top1:59.7179 | AUROC:0.6347\n",
      "\n",
      "Epoch: [77 | 1000] LR: 0.000396\n",
      "Train | 20/20 | Loss:0.1521 | MainLoss:0.1521 | Alpha:0.4643 | SPLoss:0.0710 | CLSLoss:6.9806 | top1:93.3250 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.7858 | MainLoss:0.7858 | SPLoss:0.1884 | CLSLoss:6.9813 | top1:73.5813 | AUROC:0.8162\n",
      "Test | 39/20 | Loss:1.2873 | MainLoss:1.2873 | SPLoss:0.1884 | CLSLoss:6.9813 | top1:59.9231 | AUROC:0.6369\n",
      "\n",
      "Epoch: [78 | 1000] LR: 0.000396\n",
      "Train | 20/20 | Loss:0.1252 | MainLoss:0.1252 | Alpha:0.4703 | SPLoss:0.1053 | CLSLoss:7.0046 | top1:94.4000 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8206 | MainLoss:0.8206 | SPLoss:0.2658 | CLSLoss:7.0423 | top1:73.8991 | AUROC:0.8164\n",
      "Test | 39/20 | Loss:1.3656 | MainLoss:1.3656 | SPLoss:0.2658 | CLSLoss:7.0423 | top1:59.9487 | AUROC:0.6414\n",
      "\n",
      "Epoch: [79 | 1000] LR: 0.000396\n",
      "Train | 20/20 | Loss:0.1180 | MainLoss:0.1180 | Alpha:0.4720 | SPLoss:0.0834 | CLSLoss:7.0712 | top1:94.2750 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8527 | MainLoss:0.8527 | SPLoss:0.2112 | CLSLoss:7.1079 | top1:73.6828 | AUROC:0.8159\n",
      "Test | 39/20 | Loss:1.3790 | MainLoss:1.3790 | SPLoss:0.2112 | CLSLoss:7.1079 | top1:60.5897 | AUROC:0.6476\n",
      "\n",
      "Epoch: [80 | 1000] LR: 0.000395\n",
      "Train | 20/20 | Loss:0.1397 | MainLoss:0.1397 | Alpha:0.4670 | SPLoss:0.0630 | CLSLoss:7.1304 | top1:93.6500 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8653 | MainLoss:0.8653 | SPLoss:0.1804 | CLSLoss:7.1299 | top1:73.4862 | AUROC:0.8153\n",
      "Test | 39/20 | Loss:1.3799 | MainLoss:1.3799 | SPLoss:0.1804 | CLSLoss:7.1299 | top1:60.4487 | AUROC:0.6468\n",
      "\n",
      "Epoch: [81 | 1000] LR: 0.000395\n",
      "Train | 20/20 | Loss:0.1474 | MainLoss:0.1474 | Alpha:0.4648 | SPLoss:0.0949 | CLSLoss:7.1024 | top1:93.1500 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8239 | MainLoss:0.8239 | SPLoss:0.2521 | CLSLoss:7.0831 | top1:73.5714 | AUROC:0.8152\n",
      "Test | 39/20 | Loss:1.3353 | MainLoss:1.3353 | SPLoss:0.2521 | CLSLoss:7.0831 | top1:60.3333 | AUROC:0.6456\n",
      "\n",
      "Epoch: [82 | 1000] LR: 0.000395\n",
      "Train | 20/20 | Loss:0.1348 | MainLoss:0.1348 | Alpha:0.4685 | SPLoss:0.0716 | CLSLoss:7.0889 | top1:94.2750 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8245 | MainLoss:0.8245 | SPLoss:0.2093 | CLSLoss:7.0962 | top1:73.5026 | AUROC:0.8157\n",
      "Test | 39/20 | Loss:1.3243 | MainLoss:1.3243 | SPLoss:0.2093 | CLSLoss:7.0962 | top1:60.3333 | AUROC:0.6456\n",
      "\n",
      "Epoch: [83 | 1000] LR: 0.000395\n",
      "Train | 20/20 | Loss:0.1336 | MainLoss:0.1336 | Alpha:0.4689 | SPLoss:0.0623 | CLSLoss:7.0880 | top1:93.7000 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8235 | MainLoss:0.8235 | SPLoss:0.1650 | CLSLoss:7.0918 | top1:73.6271 | AUROC:0.8150\n",
      "Test | 39/20 | Loss:1.3459 | MainLoss:1.3459 | SPLoss:0.1650 | CLSLoss:7.0918 | top1:60.1923 | AUROC:0.6448\n",
      "\n",
      "Epoch: [84 | 1000] LR: 0.000395\n",
      "Train | 20/20 | Loss:0.1228 | MainLoss:0.1228 | Alpha:0.4703 | SPLoss:0.0682 | CLSLoss:7.1231 | top1:94.2750 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8397 | MainLoss:0.8397 | SPLoss:0.1643 | CLSLoss:7.1336 | top1:73.6370 | AUROC:0.8154\n",
      "Test | 39/20 | Loss:1.3788 | MainLoss:1.3788 | SPLoss:0.1643 | CLSLoss:7.1336 | top1:60.1538 | AUROC:0.6416\n",
      "\n",
      "Epoch: [85 | 1000] LR: 0.000395\n",
      "Train | 20/20 | Loss:0.1229 | MainLoss:0.1229 | Alpha:0.4714 | SPLoss:0.0612 | CLSLoss:7.1438 | top1:94.3000 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8408 | MainLoss:0.8408 | SPLoss:0.1737 | CLSLoss:7.1655 | top1:73.6173 | AUROC:0.8151\n",
      "Test | 39/20 | Loss:1.3584 | MainLoss:1.3584 | SPLoss:0.1737 | CLSLoss:7.1655 | top1:60.3333 | AUROC:0.6447\n",
      "\n",
      "Epoch: [86 | 1000] LR: 0.000395\n",
      "Train | 20/20 | Loss:0.1345 | MainLoss:0.1345 | Alpha:0.4684 | SPLoss:0.0749 | CLSLoss:7.1703 | top1:94.1000 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8465 | MainLoss:0.8465 | SPLoss:0.2162 | CLSLoss:7.1777 | top1:73.5223 | AUROC:0.8151\n",
      "Test | 39/20 | Loss:1.3599 | MainLoss:1.3599 | SPLoss:0.2162 | CLSLoss:7.1777 | top1:60.2308 | AUROC:0.6436\n",
      "\n",
      "Epoch: [87 | 1000] LR: 0.000394\n",
      "Train | 20/20 | Loss:0.1301 | MainLoss:0.1301 | Alpha:0.4690 | SPLoss:0.0831 | CLSLoss:7.1784 | top1:94.3750 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8271 | MainLoss:0.8271 | SPLoss:0.2309 | CLSLoss:7.1866 | top1:73.5649 | AUROC:0.8159\n",
      "Test | 39/20 | Loss:1.3428 | MainLoss:1.3428 | SPLoss:0.2309 | CLSLoss:7.1866 | top1:60.0256 | AUROC:0.6422\n",
      "\n",
      "Epoch: [88 | 1000] LR: 0.000394\n",
      "Train | 20/20 | Loss:0.1198 | MainLoss:0.1198 | Alpha:0.4720 | SPLoss:0.0831 | CLSLoss:7.2259 | top1:94.8750 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8615 | MainLoss:0.8615 | SPLoss:0.2198 | CLSLoss:7.2589 | top1:73.6468 | AUROC:0.8163\n",
      "Test | 39/20 | Loss:1.3904 | MainLoss:1.3904 | SPLoss:0.2198 | CLSLoss:7.2589 | top1:60.3205 | AUROC:0.6454\n",
      "\n",
      "Epoch: [89 | 1000] LR: 0.000394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 20/20 | Loss:0.1236 | MainLoss:0.1236 | Alpha:0.4712 | SPLoss:0.0767 | CLSLoss:7.2691 | top1:94.6750 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8619 | MainLoss:0.8619 | SPLoss:0.2019 | CLSLoss:7.2730 | top1:73.7058 | AUROC:0.8160\n",
      "Test | 39/20 | Loss:1.4172 | MainLoss:1.4172 | SPLoss:0.2019 | CLSLoss:7.2730 | top1:60.3590 | AUROC:0.6462\n",
      "\n",
      "Epoch: [90 | 1000] LR: 0.000394\n",
      "Train | 20/20 | Loss:0.1359 | MainLoss:0.1359 | Alpha:0.4675 | SPLoss:0.1531 | CLSLoss:7.2503 | top1:94.2000 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8214 | MainLoss:0.8214 | SPLoss:0.3173 | CLSLoss:7.2061 | top1:73.7549 | AUROC:0.8153\n",
      "Test | 39/20 | Loss:1.3642 | MainLoss:1.3642 | SPLoss:0.3173 | CLSLoss:7.2061 | top1:60.1154 | AUROC:0.6441\n",
      "\n",
      "Epoch: [91 | 1000] LR: 0.000394\n",
      "Train | 20/20 | Loss:0.1270 | MainLoss:0.1270 | Alpha:0.4706 | SPLoss:0.0656 | CLSLoss:7.2308 | top1:94.5000 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8375 | MainLoss:0.8375 | SPLoss:0.1754 | CLSLoss:7.2305 | top1:73.7680 | AUROC:0.8162\n",
      "Test | 39/20 | Loss:1.3941 | MainLoss:1.3941 | SPLoss:0.1754 | CLSLoss:7.2305 | top1:59.9615 | AUROC:0.6421\n",
      "\n",
      "Epoch: [92 | 1000] LR: 0.000394\n",
      "Train | 20/20 | Loss:0.1164 | MainLoss:0.1164 | Alpha:0.4724 | SPLoss:0.0918 | CLSLoss:7.2368 | top1:94.8000 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8780 | MainLoss:0.8780 | SPLoss:0.2589 | CLSLoss:7.2589 | top1:73.6304 | AUROC:0.8164\n",
      "Test | 39/20 | Loss:1.4200 | MainLoss:1.4200 | SPLoss:0.2589 | CLSLoss:7.2589 | top1:59.9615 | AUROC:0.6410\n",
      "\n",
      "Epoch: [93 | 1000] LR: 0.000394\n",
      "Train | 20/20 | Loss:0.1445 | MainLoss:0.1445 | Alpha:0.4658 | SPLoss:0.0962 | CLSLoss:7.2465 | top1:93.9000 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8357 | MainLoss:0.8357 | SPLoss:0.2844 | CLSLoss:7.1962 | top1:73.7189 | AUROC:0.8159\n",
      "Test | 39/20 | Loss:1.3760 | MainLoss:1.3760 | SPLoss:0.2844 | CLSLoss:7.1962 | top1:60.0000 | AUROC:0.6419\n",
      "\n",
      "Epoch: [94 | 1000] LR: 0.000393\n",
      "Train | 20/20 | Loss:0.1431 | MainLoss:0.1431 | Alpha:0.4646 | SPLoss:0.1530 | CLSLoss:7.1743 | top1:93.5250 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8058 | MainLoss:0.8058 | SPLoss:0.3806 | CLSLoss:7.1700 | top1:73.4862 | AUROC:0.8158\n",
      "Test | 39/20 | Loss:1.2913 | MainLoss:1.2913 | SPLoss:0.3806 | CLSLoss:7.1700 | top1:60.3846 | AUROC:0.6429\n",
      "\n",
      "Epoch: [95 | 1000] LR: 0.000393\n",
      "Train | 20/20 | Loss:0.1275 | MainLoss:0.1275 | Alpha:0.4695 | SPLoss:0.0851 | CLSLoss:7.1821 | top1:94.5500 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8019 | MainLoss:0.8019 | SPLoss:0.2002 | CLSLoss:7.1903 | top1:73.7058 | AUROC:0.8162\n",
      "Test | 39/20 | Loss:1.3208 | MainLoss:1.3208 | SPLoss:0.2002 | CLSLoss:7.1903 | top1:59.8590 | AUROC:0.6394\n",
      "\n",
      "Epoch: [96 | 1000] LR: 0.000393\n",
      "Train | 20/20 | Loss:0.1303 | MainLoss:0.1303 | Alpha:0.4698 | SPLoss:0.0777 | CLSLoss:7.2109 | top1:94.1500 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8316 | MainLoss:0.8316 | SPLoss:0.2291 | CLSLoss:7.2356 | top1:73.7549 | AUROC:0.8176\n",
      "Test | 39/20 | Loss:1.3937 | MainLoss:1.3937 | SPLoss:0.2291 | CLSLoss:7.2356 | top1:59.5000 | AUROC:0.6330\n",
      "\n",
      "Epoch: [97 | 1000] LR: 0.000393\n",
      "Train | 20/20 | Loss:0.1382 | MainLoss:0.1382 | Alpha:0.4679 | SPLoss:0.0890 | CLSLoss:7.2568 | top1:94.2500 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8452 | MainLoss:0.8452 | SPLoss:0.2030 | CLSLoss:7.2584 | top1:73.4895 | AUROC:0.8178\n",
      "Test | 39/20 | Loss:1.3649 | MainLoss:1.3649 | SPLoss:0.2030 | CLSLoss:7.2584 | top1:60.6795 | AUROC:0.6420\n",
      "\n",
      "Epoch: [98 | 1000] LR: 0.000393\n",
      "Train | 20/20 | Loss:0.1348 | MainLoss:0.1348 | Alpha:0.4684 | SPLoss:0.1056 | CLSLoss:7.2529 | top1:93.8000 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8195 | MainLoss:0.8195 | SPLoss:0.2441 | CLSLoss:7.2371 | top1:73.5649 | AUROC:0.8177\n",
      "Test | 39/20 | Loss:1.3290 | MainLoss:1.3290 | SPLoss:0.2441 | CLSLoss:7.2371 | top1:60.3974 | AUROC:0.6414\n",
      "\n",
      "Epoch: [99 | 1000] LR: 0.000393\n",
      "Train | 20/20 | Loss:0.1217 | MainLoss:0.1217 | Alpha:0.4715 | SPLoss:0.0845 | CLSLoss:7.2463 | top1:94.4750 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8414 | MainLoss:0.8414 | SPLoss:0.2574 | CLSLoss:7.2845 | top1:73.7975 | AUROC:0.8173\n",
      "Test | 39/20 | Loss:1.4081 | MainLoss:1.4081 | SPLoss:0.2574 | CLSLoss:7.2845 | top1:59.6154 | AUROC:0.6357\n",
      "\n",
      "Epoch: [100 | 1000] LR: 0.000392\n",
      "Train | 20/20 | Loss:0.1276 | MainLoss:0.1276 | Alpha:0.4696 | SPLoss:0.0782 | CLSLoss:7.3117 | top1:94.1500 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8603 | MainLoss:0.8603 | SPLoss:0.2232 | CLSLoss:7.3352 | top1:73.6828 | AUROC:0.8176\n",
      "Test | 39/20 | Loss:1.4083 | MainLoss:1.4083 | SPLoss:0.2232 | CLSLoss:7.3352 | top1:60.2820 | AUROC:0.6401\n",
      "\n",
      "Epoch: [101 | 1000] LR: 0.000392\n",
      "Train | 20/20 | Loss:0.1256 | MainLoss:0.1256 | Alpha:0.4702 | SPLoss:0.1026 | CLSLoss:7.3278 | top1:94.1750 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8344 | MainLoss:0.8344 | SPLoss:0.2624 | CLSLoss:7.3233 | top1:74.0760 | AUROC:0.8192\n",
      "Test | 39/20 | Loss:1.4166 | MainLoss:1.4166 | SPLoss:0.2624 | CLSLoss:7.3233 | top1:59.9744 | AUROC:0.6372\n",
      "\n",
      "Epoch: [102 | 1000] LR: 0.000392\n",
      "Train | 20/20 | Loss:0.1297 | MainLoss:0.1297 | Alpha:0.4697 | SPLoss:0.0762 | CLSLoss:7.3477 | top1:93.5750 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8441 | MainLoss:0.8441 | SPLoss:0.1865 | CLSLoss:7.3565 | top1:74.2136 | AUROC:0.8201\n",
      "Test | 39/20 | Loss:1.4408 | MainLoss:1.4408 | SPLoss:0.1865 | CLSLoss:7.3565 | top1:59.8205 | AUROC:0.6367\n",
      "\n",
      "Epoch: [103 | 1000] LR: 0.000392\n",
      "Train | 20/20 | Loss:0.1276 | MainLoss:0.1276 | Alpha:0.4703 | SPLoss:0.0878 | CLSLoss:7.3862 | top1:94.2500 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8657 | MainLoss:0.8657 | SPLoss:0.2339 | CLSLoss:7.4021 | top1:73.7942 | AUROC:0.8200\n",
      "Test | 39/20 | Loss:1.4414 | MainLoss:1.4414 | SPLoss:0.2339 | CLSLoss:7.4021 | top1:60.2564 | AUROC:0.6360\n",
      "\n",
      "Epoch: [104 | 1000] LR: 0.000392\n",
      "Train | 20/20 | Loss:0.1435 | MainLoss:0.1435 | Alpha:0.4656 | SPLoss:0.1038 | CLSLoss:7.3834 | top1:93.3750 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8581 | MainLoss:0.8581 | SPLoss:0.2886 | CLSLoss:7.3689 | top1:73.7418 | AUROC:0.8196\n",
      "Test | 39/20 | Loss:1.4108 | MainLoss:1.4108 | SPLoss:0.2886 | CLSLoss:7.3689 | top1:60.3974 | AUROC:0.6362\n",
      "\n",
      "Epoch: [105 | 1000] LR: 0.000392\n",
      "Train | 20/20 | Loss:0.1189 | MainLoss:0.1189 | Alpha:0.4717 | SPLoss:0.0736 | CLSLoss:7.3679 | top1:94.7750 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8457 | MainLoss:0.8457 | SPLoss:0.2037 | CLSLoss:7.3908 | top1:73.9679 | AUROC:0.8185\n",
      "Test | 39/20 | Loss:1.4250 | MainLoss:1.4250 | SPLoss:0.2037 | CLSLoss:7.3908 | top1:59.9103 | AUROC:0.6346\n",
      "\n",
      "Epoch: [106 | 1000] LR: 0.000391\n",
      "Train | 20/20 | Loss:0.1314 | MainLoss:0.1314 | Alpha:0.4689 | SPLoss:0.1179 | CLSLoss:7.4106 | top1:94.2000 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8361 | MainLoss:0.8361 | SPLoss:0.2789 | CLSLoss:7.4017 | top1:74.0367 | AUROC:0.8179\n",
      "Test | 39/20 | Loss:1.4091 | MainLoss:1.4091 | SPLoss:0.2789 | CLSLoss:7.4017 | top1:59.8718 | AUROC:0.6359\n",
      "\n",
      "Epoch: [107 | 1000] LR: 0.000391\n",
      "Train | 20/20 | Loss:0.1336 | MainLoss:0.1336 | Alpha:0.4684 | SPLoss:0.0888 | CLSLoss:7.3951 | top1:94.0500 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8266 | MainLoss:0.8266 | SPLoss:0.2230 | CLSLoss:7.3912 | top1:73.9122 | AUROC:0.8186\n",
      "Test | 39/20 | Loss:1.4335 | MainLoss:1.4335 | SPLoss:0.2230 | CLSLoss:7.3912 | top1:58.9487 | AUROC:0.6250\n",
      "\n",
      "Epoch: [108 | 1000] LR: 0.000391\n",
      "Train | 20/20 | Loss:0.1167 | MainLoss:0.1167 | Alpha:0.4728 | SPLoss:0.0983 | CLSLoss:7.3929 | top1:95.1250 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8379 | MainLoss:0.8379 | SPLoss:0.2434 | CLSLoss:7.4139 | top1:74.1448 | AUROC:0.8201\n",
      "Test | 39/20 | Loss:1.4696 | MainLoss:1.4696 | SPLoss:0.2434 | CLSLoss:7.4139 | top1:59.1538 | AUROC:0.6274\n",
      "\n",
      "Epoch: [109 | 1000] LR: 0.000391\n",
      "Train | 20/20 | Loss:0.1250 | MainLoss:0.1250 | Alpha:0.4713 | SPLoss:0.0814 | CLSLoss:7.4226 | top1:94.4500 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8439 | MainLoss:0.8439 | SPLoss:0.2128 | CLSLoss:7.4213 | top1:74.1317 | AUROC:0.8209\n",
      "Test | 39/20 | Loss:1.4674 | MainLoss:1.4674 | SPLoss:0.2128 | CLSLoss:7.4213 | top1:59.4359 | AUROC:0.6259\n",
      "\n",
      "Epoch: [110 | 1000] LR: 0.000391\n",
      "Train | 20/20 | Loss:0.1356 | MainLoss:0.1356 | Alpha:0.4680 | SPLoss:0.1290 | CLSLoss:7.4039 | top1:94.1250 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8114 | MainLoss:0.8114 | SPLoss:0.3636 | CLSLoss:7.3735 | top1:73.9351 | AUROC:0.8208\n",
      "Test | 39/20 | Loss:1.3909 | MainLoss:1.3909 | SPLoss:0.3636 | CLSLoss:7.3735 | top1:59.5769 | AUROC:0.6293\n",
      "\n",
      "Epoch: [111 | 1000] LR: 0.000390\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 20/20 | Loss:0.1261 | MainLoss:0.1261 | Alpha:0.4699 | SPLoss:0.0870 | CLSLoss:7.3790 | top1:94.6500 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8170 | MainLoss:0.8170 | SPLoss:0.2368 | CLSLoss:7.3967 | top1:74.0564 | AUROC:0.8202\n",
      "Test | 39/20 | Loss:1.3886 | MainLoss:1.3886 | SPLoss:0.2368 | CLSLoss:7.3967 | top1:59.8077 | AUROC:0.6341\n",
      "\n",
      "Epoch: [112 | 1000] LR: 0.000390\n",
      "Train | 20/20 | Loss:0.1438 | MainLoss:0.1438 | Alpha:0.4663 | SPLoss:0.0892 | CLSLoss:7.3947 | top1:93.9500 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8123 | MainLoss:0.8123 | SPLoss:0.2536 | CLSLoss:7.3716 | top1:74.1284 | AUROC:0.8205\n",
      "Test | 39/20 | Loss:1.3801 | MainLoss:1.3801 | SPLoss:0.2536 | CLSLoss:7.3716 | top1:59.8077 | AUROC:0.6366\n",
      "\n",
      "Epoch: [113 | 1000] LR: 0.000390\n",
      "Train | 20/20 | Loss:0.1323 | MainLoss:0.1323 | Alpha:0.4686 | SPLoss:0.1220 | CLSLoss:7.3552 | top1:94.0000 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8035 | MainLoss:0.8035 | SPLoss:0.2651 | CLSLoss:7.3597 | top1:74.1055 | AUROC:0.8201\n",
      "Test | 39/20 | Loss:1.3689 | MainLoss:1.3689 | SPLoss:0.2651 | CLSLoss:7.3597 | top1:59.8590 | AUROC:0.6364\n",
      "\n",
      "Epoch: [114 | 1000] LR: 0.000390\n",
      "Train | 20/20 | Loss:0.1320 | MainLoss:0.1320 | Alpha:0.4692 | SPLoss:0.0885 | CLSLoss:7.3894 | top1:94.1500 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8185 | MainLoss:0.8185 | SPLoss:0.2128 | CLSLoss:7.3936 | top1:73.9450 | AUROC:0.8204\n",
      "Test | 39/20 | Loss:1.3743 | MainLoss:1.3743 | SPLoss:0.2128 | CLSLoss:7.3936 | top1:60.0769 | AUROC:0.6394\n",
      "\n",
      "Epoch: [115 | 1000] LR: 0.000390\n",
      "Train | 20/20 | Loss:0.1127 | MainLoss:0.1127 | Alpha:0.4733 | SPLoss:0.0894 | CLSLoss:7.4029 | top1:94.7000 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8588 | MainLoss:0.8588 | SPLoss:0.2226 | CLSLoss:7.4384 | top1:73.6370 | AUROC:0.8191\n",
      "Test | 39/20 | Loss:1.3989 | MainLoss:1.3989 | SPLoss:0.2226 | CLSLoss:7.4384 | top1:59.6410 | AUROC:0.6374\n",
      "\n",
      "Epoch: [116 | 1000] LR: 0.000389\n",
      "Train | 20/20 | Loss:0.1122 | MainLoss:0.1122 | Alpha:0.4735 | SPLoss:0.1287 | CLSLoss:7.4778 | top1:95.2750 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8722 | MainLoss:0.8722 | SPLoss:0.3096 | CLSLoss:7.5053 | top1:74.0564 | AUROC:0.8191\n",
      "Test | 39/20 | Loss:1.4731 | MainLoss:1.4731 | SPLoss:0.3096 | CLSLoss:7.5053 | top1:60.1026 | AUROC:0.6366\n",
      "\n",
      "Epoch: [117 | 1000] LR: 0.000389\n",
      "Train | 20/20 | Loss:0.1264 | MainLoss:0.1264 | Alpha:0.4701 | SPLoss:0.0816 | CLSLoss:7.5239 | top1:94.2250 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8492 | MainLoss:0.8492 | SPLoss:0.2513 | CLSLoss:7.4975 | top1:74.0269 | AUROC:0.8190\n",
      "Test | 39/20 | Loss:1.4603 | MainLoss:1.4603 | SPLoss:0.2513 | CLSLoss:7.4975 | top1:59.4359 | AUROC:0.6302\n",
      "\n",
      "Epoch: [118 | 1000] LR: 0.000389\n",
      "Train | 20/20 | Loss:0.1226 | MainLoss:0.1226 | Alpha:0.4706 | SPLoss:0.1217 | CLSLoss:7.4635 | top1:94.7250 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8084 | MainLoss:0.8084 | SPLoss:0.3259 | CLSLoss:7.4301 | top1:74.0170 | AUROC:0.8190\n",
      "Test | 39/20 | Loss:1.4007 | MainLoss:1.4007 | SPLoss:0.3259 | CLSLoss:7.4301 | top1:59.6154 | AUROC:0.6279\n",
      "\n",
      "Epoch: [119 | 1000] LR: 0.000389\n",
      "Train | 20/20 | Loss:0.1227 | MainLoss:0.1227 | Alpha:0.4714 | SPLoss:0.0858 | CLSLoss:7.4258 | top1:94.3250 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.7990 | MainLoss:0.7990 | SPLoss:0.2176 | CLSLoss:7.4366 | top1:74.1579 | AUROC:0.8200\n",
      "Test | 39/20 | Loss:1.3962 | MainLoss:1.3962 | SPLoss:0.2176 | CLSLoss:7.4366 | top1:59.5000 | AUROC:0.6275\n",
      "\n",
      "Epoch: [120 | 1000] LR: 0.000389\n",
      "Train | 20/20 | Loss:0.1236 | MainLoss:0.1236 | Alpha:0.4710 | SPLoss:0.0915 | CLSLoss:7.4634 | top1:94.5500 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8094 | MainLoss:0.8094 | SPLoss:0.2738 | CLSLoss:7.4808 | top1:74.2890 | AUROC:0.8205\n",
      "Test | 39/20 | Loss:1.4007 | MainLoss:1.4007 | SPLoss:0.2738 | CLSLoss:7.4808 | top1:59.5641 | AUROC:0.6312\n",
      "\n",
      "Epoch: [121 | 1000] LR: 0.000388\n",
      "Train | 20/20 | Loss:0.1194 | MainLoss:0.1194 | Alpha:0.4721 | SPLoss:0.1090 | CLSLoss:7.5033 | top1:94.2750 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8428 | MainLoss:0.8428 | SPLoss:0.3118 | CLSLoss:7.5299 | top1:74.3152 | AUROC:0.8206\n",
      "Test | 39/20 | Loss:1.4507 | MainLoss:1.4507 | SPLoss:0.3118 | CLSLoss:7.5299 | top1:59.9359 | AUROC:0.6351\n",
      "\n",
      "Epoch: [122 | 1000] LR: 0.000388\n",
      "Train | 20/20 | Loss:0.1240 | MainLoss:0.1240 | Alpha:0.4721 | SPLoss:0.1084 | CLSLoss:7.5379 | top1:94.7500 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8592 | MainLoss:0.8592 | SPLoss:0.3037 | CLSLoss:7.5307 | top1:74.4037 | AUROC:0.8213\n",
      "Test | 39/20 | Loss:1.4885 | MainLoss:1.4885 | SPLoss:0.3037 | CLSLoss:7.5307 | top1:59.8974 | AUROC:0.6338\n",
      "\n",
      "Epoch: [123 | 1000] LR: 0.000388\n",
      "Train | 20/20 | Loss:0.1330 | MainLoss:0.1330 | Alpha:0.4666 | SPLoss:0.2165 | CLSLoss:7.5359 | top1:94.0750 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8478 | MainLoss:0.8478 | SPLoss:0.5570 | CLSLoss:7.5171 | top1:74.0367 | AUROC:0.8220\n",
      "Test | 39/20 | Loss:1.4034 | MainLoss:1.4034 | SPLoss:0.5570 | CLSLoss:7.5171 | top1:60.1026 | AUROC:0.6384\n",
      "\n",
      "Epoch: [124 | 1000] LR: 0.000388\n",
      "Train | 20/20 | Loss:0.1284 | MainLoss:0.1284 | Alpha:0.4702 | SPLoss:0.1742 | CLSLoss:7.4676 | top1:94.4250 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.7929 | MainLoss:0.7929 | SPLoss:0.3772 | CLSLoss:7.4497 | top1:74.3152 | AUROC:0.8211\n",
      "Test | 39/20 | Loss:1.3495 | MainLoss:1.3495 | SPLoss:0.3772 | CLSLoss:7.4497 | top1:60.2051 | AUROC:0.6409\n",
      "\n",
      "Epoch: [125 | 1000] LR: 0.000388\n",
      "Train | 20/20 | Loss:0.1222 | MainLoss:0.1222 | Alpha:0.4711 | SPLoss:0.0892 | CLSLoss:7.4690 | top1:94.7500 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8304 | MainLoss:0.8304 | SPLoss:0.2663 | CLSLoss:7.5136 | top1:74.1907 | AUROC:0.8214\n",
      "Test | 39/20 | Loss:1.3895 | MainLoss:1.3895 | SPLoss:0.2663 | CLSLoss:7.5136 | top1:60.1410 | AUROC:0.6402\n",
      "\n",
      "Epoch: [126 | 1000] LR: 0.000387\n",
      "Train | 20/20 | Loss:0.1228 | MainLoss:0.1228 | Alpha:0.4707 | SPLoss:0.1418 | CLSLoss:7.5093 | top1:94.8000 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8235 | MainLoss:0.8235 | SPLoss:0.3562 | CLSLoss:7.5022 | top1:74.0760 | AUROC:0.8196\n",
      "Test | 39/20 | Loss:1.4117 | MainLoss:1.4117 | SPLoss:0.3562 | CLSLoss:7.5022 | top1:59.5513 | AUROC:0.6314\n",
      "\n",
      "Epoch: [127 | 1000] LR: 0.000387\n",
      "Train | 20/20 | Loss:0.1247 | MainLoss:0.1247 | Alpha:0.4706 | SPLoss:0.0838 | CLSLoss:7.5262 | top1:94.7250 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8476 | MainLoss:0.8476 | SPLoss:0.2495 | CLSLoss:7.5508 | top1:73.9613 | AUROC:0.8187\n",
      "Test | 39/20 | Loss:1.4497 | MainLoss:1.4497 | SPLoss:0.2495 | CLSLoss:7.5508 | top1:59.2949 | AUROC:0.6289\n",
      "\n",
      "Epoch: [128 | 1000] LR: 0.000387\n",
      "Train | 20/20 | Loss:0.1302 | MainLoss:0.1302 | Alpha:0.4702 | SPLoss:0.1106 | CLSLoss:7.5804 | top1:94.4250 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8506 | MainLoss:0.8506 | SPLoss:0.2939 | CLSLoss:7.5817 | top1:74.0990 | AUROC:0.8191\n",
      "Test | 39/20 | Loss:1.4796 | MainLoss:1.4796 | SPLoss:0.2939 | CLSLoss:7.5817 | top1:58.8333 | AUROC:0.6258\n",
      "\n",
      "Epoch: [129 | 1000] LR: 0.000387\n",
      "Train | 20/20 | Loss:0.1196 | MainLoss:0.1196 | Alpha:0.4717 | SPLoss:0.1132 | CLSLoss:7.5969 | top1:94.5750 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8578 | MainLoss:0.8578 | SPLoss:0.2422 | CLSLoss:7.6106 | top1:74.1940 | AUROC:0.8192\n",
      "Test | 39/20 | Loss:1.5042 | MainLoss:1.5042 | SPLoss:0.2422 | CLSLoss:7.6106 | top1:59.0513 | AUROC:0.6296\n",
      "\n",
      "Epoch: [130 | 1000] LR: 0.000386\n",
      "Train | 20/20 | Loss:0.1265 | MainLoss:0.1265 | Alpha:0.4700 | SPLoss:0.1098 | CLSLoss:7.6148 | top1:94.1750 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8743 | MainLoss:0.8743 | SPLoss:0.2426 | CLSLoss:7.6230 | top1:73.7942 | AUROC:0.8197\n",
      "Test | 39/20 | Loss:1.4617 | MainLoss:1.4617 | SPLoss:0.2426 | CLSLoss:7.6230 | top1:59.8205 | AUROC:0.6368\n",
      "\n",
      "Epoch: [131 | 1000] LR: 0.000386\n",
      "Train | 20/20 | Loss:0.1328 | MainLoss:0.1328 | Alpha:0.4687 | SPLoss:0.1326 | CLSLoss:7.6026 | top1:94.5500 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8508 | MainLoss:0.8508 | SPLoss:0.3886 | CLSLoss:7.5836 | top1:73.9319 | AUROC:0.8192\n",
      "Test | 39/20 | Loss:1.4212 | MainLoss:1.4212 | SPLoss:0.3886 | CLSLoss:7.5836 | top1:59.9744 | AUROC:0.6393\n",
      "\n",
      "Epoch: [132 | 1000] LR: 0.000386\n",
      "Train | 20/20 | Loss:0.1165 | MainLoss:0.1165 | Alpha:0.4727 | SPLoss:0.1142 | CLSLoss:7.6017 | top1:94.4500 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8656 | MainLoss:0.8656 | SPLoss:0.2994 | CLSLoss:7.6160 | top1:74.0498 | AUROC:0.8189\n",
      "Test | 39/20 | Loss:1.4418 | MainLoss:1.4418 | SPLoss:0.2994 | CLSLoss:7.6160 | top1:60.5385 | AUROC:0.6476\n",
      "\n",
      "Epoch: [133 | 1000] LR: 0.000386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 20/20 | Loss:0.1118 | MainLoss:0.1118 | Alpha:0.4734 | SPLoss:0.1257 | CLSLoss:7.6428 | top1:95.1000 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8681 | MainLoss:0.8681 | SPLoss:0.3352 | CLSLoss:7.6681 | top1:74.1579 | AUROC:0.8201\n",
      "Test | 39/20 | Loss:1.4609 | MainLoss:1.4609 | SPLoss:0.3352 | CLSLoss:7.6681 | top1:60.8205 | AUROC:0.6493\n",
      "\n",
      "Epoch: [134 | 1000] LR: 0.000385\n",
      "Train | 20/20 | Loss:0.1177 | MainLoss:0.1177 | Alpha:0.4722 | SPLoss:0.0827 | CLSLoss:7.6947 | top1:94.7750 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8865 | MainLoss:0.8865 | SPLoss:0.2295 | CLSLoss:7.7169 | top1:73.9450 | AUROC:0.8199\n",
      "Test | 39/20 | Loss:1.4771 | MainLoss:1.4771 | SPLoss:0.2295 | CLSLoss:7.7169 | top1:60.5385 | AUROC:0.6457\n",
      "\n",
      "Epoch: [135 | 1000] LR: 0.000385\n",
      "Train | 20/20 | Loss:0.1287 | MainLoss:0.1287 | Alpha:0.4699 | SPLoss:0.1423 | CLSLoss:7.6967 | top1:94.5250 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8620 | MainLoss:0.8620 | SPLoss:0.4550 | CLSLoss:7.6700 | top1:73.8762 | AUROC:0.8201\n",
      "Test | 39/20 | Loss:1.4413 | MainLoss:1.4413 | SPLoss:0.4550 | CLSLoss:7.6700 | top1:59.7564 | AUROC:0.6354\n",
      "\n",
      "Epoch: [136 | 1000] LR: 0.000385\n",
      "Train | 20/20 | Loss:0.1049 | MainLoss:0.1049 | Alpha:0.4750 | SPLoss:0.1328 | CLSLoss:7.6614 | top1:95.6000 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8747 | MainLoss:0.8747 | SPLoss:0.3316 | CLSLoss:7.6792 | top1:74.1121 | AUROC:0.8198\n",
      "Test | 39/20 | Loss:1.5014 | MainLoss:1.5014 | SPLoss:0.3316 | CLSLoss:7.6792 | top1:59.7692 | AUROC:0.6325\n",
      "\n",
      "Epoch: [137 | 1000] LR: 0.000385\n",
      "Train | 20/20 | Loss:0.1269 | MainLoss:0.1269 | Alpha:0.4695 | SPLoss:0.1430 | CLSLoss:7.6970 | top1:94.2250 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8525 | MainLoss:0.8525 | SPLoss:0.3797 | CLSLoss:7.6943 | top1:74.1514 | AUROC:0.8202\n",
      "Test | 39/20 | Loss:1.4339 | MainLoss:1.4339 | SPLoss:0.3797 | CLSLoss:7.6943 | top1:60.0128 | AUROC:0.6373\n",
      "\n",
      "Epoch: [138 | 1000] LR: 0.000385\n",
      "Train | 20/20 | Loss:0.1139 | MainLoss:0.1139 | Alpha:0.4734 | SPLoss:0.1152 | CLSLoss:7.6931 | top1:94.7000 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8566 | MainLoss:0.8566 | SPLoss:0.3161 | CLSLoss:7.7151 | top1:74.0891 | AUROC:0.8206\n",
      "Test | 39/20 | Loss:1.4268 | MainLoss:1.4268 | SPLoss:0.3161 | CLSLoss:7.7151 | top1:60.4487 | AUROC:0.6439\n",
      "\n",
      "Epoch: [139 | 1000] LR: 0.000384\n",
      "Train | 20/20 | Loss:0.1210 | MainLoss:0.1210 | Alpha:0.4718 | SPLoss:0.1299 | CLSLoss:7.7395 | top1:94.7000 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8472 | MainLoss:0.8472 | SPLoss:0.3347 | CLSLoss:7.7202 | top1:74.1317 | AUROC:0.8222\n",
      "Test | 39/20 | Loss:1.4210 | MainLoss:1.4210 | SPLoss:0.3347 | CLSLoss:7.7202 | top1:60.2820 | AUROC:0.6423\n",
      "\n",
      "Epoch: [140 | 1000] LR: 0.000384\n",
      "Train | 20/20 | Loss:0.1124 | MainLoss:0.1124 | Alpha:0.4733 | SPLoss:0.1139 | CLSLoss:7.7152 | top1:94.7250 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8445 | MainLoss:0.8445 | SPLoss:0.2928 | CLSLoss:7.7287 | top1:74.1940 | AUROC:0.8223\n",
      "Test | 39/20 | Loss:1.4299 | MainLoss:1.4299 | SPLoss:0.2928 | CLSLoss:7.7286 | top1:60.2051 | AUROC:0.6430\n",
      "\n",
      "Epoch: [141 | 1000] LR: 0.000384\n",
      "Train | 20/20 | Loss:0.1218 | MainLoss:0.1218 | Alpha:0.4720 | SPLoss:0.1237 | CLSLoss:7.7463 | top1:94.7000 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8671 | MainLoss:0.8671 | SPLoss:0.2850 | CLSLoss:7.7510 | top1:73.9908 | AUROC:0.8204\n",
      "Test | 39/20 | Loss:1.4478 | MainLoss:1.4478 | SPLoss:0.2850 | CLSLoss:7.7510 | top1:60.2051 | AUROC:0.6405\n",
      "\n",
      "Epoch: [142 | 1000] LR: 0.000384\n",
      "Train | 20/20 | Loss:0.1202 | MainLoss:0.1202 | Alpha:0.4726 | SPLoss:0.1047 | CLSLoss:7.7472 | top1:94.7250 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8735 | MainLoss:0.8735 | SPLoss:0.2809 | CLSLoss:7.7262 | top1:73.6370 | AUROC:0.8196\n",
      "Test | 39/20 | Loss:1.4212 | MainLoss:1.4212 | SPLoss:0.2809 | CLSLoss:7.7262 | top1:60.4103 | AUROC:0.6412\n",
      "\n",
      "Epoch: [143 | 1000] LR: 0.000383\n",
      "Train | 20/20 | Loss:0.1273 | MainLoss:0.1273 | Alpha:0.4695 | SPLoss:0.2176 | CLSLoss:7.7086 | top1:94.3750 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8375 | MainLoss:0.8375 | SPLoss:0.4189 | CLSLoss:7.7052 | top1:73.8073 | AUROC:0.8180\n",
      "Test | 39/20 | Loss:1.3942 | MainLoss:1.3942 | SPLoss:0.4189 | CLSLoss:7.7052 | top1:60.2436 | AUROC:0.6441\n",
      "\n",
      "Epoch: [144 | 1000] LR: 0.000383\n",
      "Train | 20/20 | Loss:0.1218 | MainLoss:0.1218 | Alpha:0.4714 | SPLoss:0.1503 | CLSLoss:7.6944 | top1:94.6500 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8355 | MainLoss:0.8355 | SPLoss:0.3078 | CLSLoss:7.6929 | top1:73.9744 | AUROC:0.8195\n",
      "Test | 39/20 | Loss:1.3942 | MainLoss:1.3942 | SPLoss:0.3078 | CLSLoss:7.6929 | top1:60.3462 | AUROC:0.6439\n",
      "\n",
      "Epoch: [145 | 1000] LR: 0.000383\n",
      "Train | 20/20 | Loss:0.1059 | MainLoss:0.1059 | Alpha:0.4749 | SPLoss:0.1280 | CLSLoss:7.7205 | top1:95.3500 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8812 | MainLoss:0.8812 | SPLoss:0.3591 | CLSLoss:7.7644 | top1:73.9122 | AUROC:0.8192\n",
      "Test | 39/20 | Loss:1.4448 | MainLoss:1.4448 | SPLoss:0.3591 | CLSLoss:7.7644 | top1:60.8462 | AUROC:0.6472\n",
      "\n",
      "Epoch: [146 | 1000] LR: 0.000383\n",
      "Train | 20/20 | Loss:0.1222 | MainLoss:0.1222 | Alpha:0.4717 | SPLoss:0.1515 | CLSLoss:7.7648 | top1:94.4000 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8703 | MainLoss:0.8703 | SPLoss:0.4446 | CLSLoss:7.7361 | top1:73.5551 | AUROC:0.8173\n",
      "Test | 39/20 | Loss:1.4069 | MainLoss:1.4069 | SPLoss:0.4446 | CLSLoss:7.7361 | top1:60.4744 | AUROC:0.6428\n",
      "\n",
      "Epoch: [147 | 1000] LR: 0.000382\n",
      "Train | 20/20 | Loss:0.1167 | MainLoss:0.1167 | Alpha:0.4727 | SPLoss:0.1278 | CLSLoss:7.7208 | top1:95.1750 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8427 | MainLoss:0.8427 | SPLoss:0.3398 | CLSLoss:7.7026 | top1:73.9548 | AUROC:0.8196\n",
      "Test | 39/20 | Loss:1.4056 | MainLoss:1.4056 | SPLoss:0.3398 | CLSLoss:7.7026 | top1:60.5769 | AUROC:0.6461\n",
      "\n",
      "Epoch: [148 | 1000] LR: 0.000382\n",
      "Train | 20/20 | Loss:0.1232 | MainLoss:0.1232 | Alpha:0.4708 | SPLoss:0.2386 | CLSLoss:7.6887 | top1:94.4500 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8248 | MainLoss:0.8248 | SPLoss:0.5458 | CLSLoss:7.6764 | top1:73.8762 | AUROC:0.8199\n",
      "Test | 39/20 | Loss:1.3662 | MainLoss:1.3662 | SPLoss:0.5458 | CLSLoss:7.6764 | top1:60.6667 | AUROC:0.6478\n",
      "\n",
      "Epoch: [149 | 1000] LR: 0.000382\n",
      "Train | 20/20 | Loss:0.1197 | MainLoss:0.1197 | Alpha:0.4722 | SPLoss:0.1503 | CLSLoss:7.7029 | top1:94.8750 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8441 | MainLoss:0.8441 | SPLoss:0.4146 | CLSLoss:7.7238 | top1:74.0170 | AUROC:0.8207\n",
      "Test | 39/20 | Loss:1.3860 | MainLoss:1.3860 | SPLoss:0.4146 | CLSLoss:7.7238 | top1:61.1154 | AUROC:0.6531\n",
      "\n",
      "Epoch: [150 | 1000] LR: 0.000381\n",
      "Train | 20/20 | Loss:0.0987 | MainLoss:0.0987 | Alpha:0.4766 | SPLoss:0.1585 | CLSLoss:7.7646 | top1:95.1750 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8916 | MainLoss:0.8916 | SPLoss:0.4489 | CLSLoss:7.8237 | top1:74.0465 | AUROC:0.8208\n",
      "Test | 39/20 | Loss:1.4597 | MainLoss:1.4597 | SPLoss:0.4489 | CLSLoss:7.8237 | top1:61.1154 | AUROC:0.6536\n",
      "\n",
      "Epoch: [151 | 1000] LR: 0.000381\n",
      "Train | 20/20 | Loss:0.1291 | MainLoss:0.1291 | Alpha:0.4696 | SPLoss:0.3248 | CLSLoss:7.7888 | top1:94.0000 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8688 | MainLoss:0.8688 | SPLoss:0.8393 | CLSLoss:7.7469 | top1:74.0236 | AUROC:0.8194\n",
      "Test | 39/20 | Loss:1.4296 | MainLoss:1.4296 | SPLoss:0.8393 | CLSLoss:7.7469 | top1:60.8846 | AUROC:0.6469\n",
      "\n",
      "Epoch: [152 | 1000] LR: 0.000381\n",
      "Train | 20/20 | Loss:0.1080 | MainLoss:0.1080 | Alpha:0.4748 | SPLoss:0.1565 | CLSLoss:7.7507 | top1:95.1500 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.9097 | MainLoss:0.9097 | SPLoss:0.4025 | CLSLoss:7.7800 | top1:73.2798 | AUROC:0.8193\n",
      "Test | 39/20 | Loss:1.4242 | MainLoss:1.4242 | SPLoss:0.4025 | CLSLoss:7.7800 | top1:60.1667 | AUROC:0.6467\n",
      "\n",
      "Epoch: [153 | 1000] LR: 0.000381\n",
      "Train | 20/20 | Loss:0.1207 | MainLoss:0.1207 | Alpha:0.4714 | SPLoss:0.2621 | CLSLoss:7.7862 | top1:95.0750 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8704 | MainLoss:0.8704 | SPLoss:0.4629 | CLSLoss:7.7762 | top1:73.8073 | AUROC:0.8202\n",
      "Test | 39/20 | Loss:1.4052 | MainLoss:1.4052 | SPLoss:0.4629 | CLSLoss:7.7762 | top1:60.5385 | AUROC:0.6490\n",
      "\n",
      "Epoch: [154 | 1000] LR: 0.000380\n",
      "Train | 20/20 | Loss:0.0997 | MainLoss:0.0997 | Alpha:0.4763 | SPLoss:0.1577 | CLSLoss:7.7634 | top1:95.5250 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8755 | MainLoss:0.8755 | SPLoss:0.3704 | CLSLoss:7.7989 | top1:74.0564 | AUROC:0.8198\n",
      "Test | 39/20 | Loss:1.4110 | MainLoss:1.4110 | SPLoss:0.3704 | CLSLoss:7.7989 | top1:61.2436 | AUROC:0.6548\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [155 | 1000] LR: 0.000380\n",
      "Train | 20/20 | Loss:0.0976 | MainLoss:0.0976 | Alpha:0.4777 | SPLoss:0.1492 | CLSLoss:7.8191 | top1:95.4250 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.9002 | MainLoss:0.9002 | SPLoss:0.3893 | CLSLoss:7.8502 | top1:73.8139 | AUROC:0.8207\n",
      "Test | 39/20 | Loss:1.4064 | MainLoss:1.4064 | SPLoss:0.3893 | CLSLoss:7.8501 | top1:61.0897 | AUROC:0.6603\n",
      "\n",
      "Epoch: [156 | 1000] LR: 0.000380\n",
      "Train | 20/20 | Loss:0.1110 | MainLoss:0.1110 | Alpha:0.4745 | SPLoss:0.1426 | CLSLoss:7.8451 | top1:95.2250 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8855 | MainLoss:0.8855 | SPLoss:0.3288 | CLSLoss:7.8571 | top1:74.0990 | AUROC:0.8222\n",
      "Test | 39/20 | Loss:1.4247 | MainLoss:1.4247 | SPLoss:0.3288 | CLSLoss:7.8571 | top1:61.1410 | AUROC:0.6567\n",
      "\n",
      "Epoch: [157 | 1000] LR: 0.000380\n",
      "Train | 20/20 | Loss:0.1146 | MainLoss:0.1146 | Alpha:0.4724 | SPLoss:0.1387 | CLSLoss:7.8610 | top1:95.0500 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8548 | MainLoss:0.8548 | SPLoss:0.4011 | CLSLoss:7.8281 | top1:74.2923 | AUROC:0.8223\n",
      "Test | 39/20 | Loss:1.3872 | MainLoss:1.3872 | SPLoss:0.4011 | CLSLoss:7.8281 | top1:61.0897 | AUROC:0.6559\n",
      "\n",
      "Epoch: [158 | 1000] LR: 0.000379\n",
      "Train | 20/20 | Loss:0.1077 | MainLoss:0.1077 | Alpha:0.4752 | SPLoss:0.1704 | CLSLoss:7.7872 | top1:95.2500 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8292 | MainLoss:0.8292 | SPLoss:0.3713 | CLSLoss:7.7817 | top1:74.2169 | AUROC:0.8217\n",
      "Test | 39/20 | Loss:1.3692 | MainLoss:1.3692 | SPLoss:0.3713 | CLSLoss:7.7817 | top1:60.8718 | AUROC:0.6482\n",
      "\n",
      "Epoch: [159 | 1000] LR: 0.000379\n",
      "Train | 20/20 | Loss:0.1135 | MainLoss:0.1135 | Alpha:0.4741 | SPLoss:0.1260 | CLSLoss:7.8194 | top1:95.4000 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8411 | MainLoss:0.8411 | SPLoss:0.3468 | CLSLoss:7.8256 | top1:74.1383 | AUROC:0.8204\n",
      "Test | 39/20 | Loss:1.4110 | MainLoss:1.4110 | SPLoss:0.3468 | CLSLoss:7.8256 | top1:60.1923 | AUROC:0.6423\n",
      "\n",
      "Epoch: [160 | 1000] LR: 0.000379\n",
      "Train | 20/20 | Loss:0.1070 | MainLoss:0.1070 | Alpha:0.4747 | SPLoss:0.1359 | CLSLoss:7.8541 | top1:95.6250 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8558 | MainLoss:0.8558 | SPLoss:0.3524 | CLSLoss:7.8931 | top1:73.9941 | AUROC:0.8213\n",
      "Test | 39/20 | Loss:1.4420 | MainLoss:1.4420 | SPLoss:0.3524 | CLSLoss:7.8931 | top1:59.9487 | AUROC:0.6378\n",
      "\n",
      "Epoch: [161 | 1000] LR: 0.000378\n",
      "Train | 20/20 | Loss:0.1235 | MainLoss:0.1235 | Alpha:0.4716 | SPLoss:0.1497 | CLSLoss:7.8851 | top1:94.2500 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8314 | MainLoss:0.8314 | SPLoss:0.4359 | CLSLoss:7.8525 | top1:74.2333 | AUROC:0.8211\n",
      "Test | 39/20 | Loss:1.4620 | MainLoss:1.4620 | SPLoss:0.4359 | CLSLoss:7.8525 | top1:59.7308 | AUROC:0.6363\n",
      "\n",
      "Epoch: [162 | 1000] LR: 0.000378\n",
      "Train | 20/20 | Loss:0.1256 | MainLoss:0.1256 | Alpha:0.4700 | SPLoss:0.2915 | CLSLoss:7.8578 | top1:94.3500 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8179 | MainLoss:0.8179 | SPLoss:0.6598 | CLSLoss:7.8315 | top1:73.9024 | AUROC:0.8204\n",
      "Test | 39/20 | Loss:1.3751 | MainLoss:1.3751 | SPLoss:0.6598 | CLSLoss:7.8315 | top1:59.9231 | AUROC:0.6384\n",
      "\n",
      "Epoch: [163 | 1000] LR: 0.000378\n",
      "Train | 20/20 | Loss:0.1082 | MainLoss:0.1082 | Alpha:0.4739 | SPLoss:0.1915 | CLSLoss:7.8491 | top1:95.3500 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8534 | MainLoss:0.8534 | SPLoss:0.4987 | CLSLoss:7.8763 | top1:74.0334 | AUROC:0.8204\n",
      "Test | 39/20 | Loss:1.4415 | MainLoss:1.4415 | SPLoss:0.4987 | CLSLoss:7.8763 | top1:59.9487 | AUROC:0.6407\n",
      "\n",
      "Epoch: [164 | 1000] LR: 0.000378\n",
      "Train | 20/20 | Loss:0.1376 | MainLoss:0.1376 | Alpha:0.4671 | SPLoss:0.2417 | CLSLoss:7.8583 | top1:94.3000 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8174 | MainLoss:0.8174 | SPLoss:0.6103 | CLSLoss:7.8193 | top1:74.2136 | AUROC:0.8210\n",
      "Test | 39/20 | Loss:1.3752 | MainLoss:1.3752 | SPLoss:0.6103 | CLSLoss:7.8193 | top1:60.7436 | AUROC:0.6508\n",
      "\n",
      "Epoch: [165 | 1000] LR: 0.000377\n",
      "Train | 20/20 | Loss:0.1155 | MainLoss:0.1155 | Alpha:0.4728 | SPLoss:0.2807 | CLSLoss:7.8170 | top1:94.7750 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8285 | MainLoss:0.8285 | SPLoss:0.3347 | CLSLoss:7.8194 | top1:74.1514 | AUROC:0.8207\n",
      "Test | 39/20 | Loss:1.3588 | MainLoss:1.3588 | SPLoss:0.3347 | CLSLoss:7.8194 | top1:61.1282 | AUROC:0.6550\n",
      "\n",
      "Epoch: [166 | 1000] LR: 0.000377\n",
      "Train | 20/20 | Loss:0.1164 | MainLoss:0.1164 | Alpha:0.4723 | SPLoss:0.1670 | CLSLoss:7.8540 | top1:94.5750 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8534 | MainLoss:0.8534 | SPLoss:0.3890 | CLSLoss:7.8707 | top1:73.7484 | AUROC:0.8192\n",
      "Test | 39/20 | Loss:1.3570 | MainLoss:1.3570 | SPLoss:0.3890 | CLSLoss:7.8707 | top1:61.2436 | AUROC:0.6570\n",
      "\n",
      "Epoch: [167 | 1000] LR: 0.000377\n",
      "Train | 20/20 | Loss:0.1123 | MainLoss:0.1123 | Alpha:0.4727 | SPLoss:0.2298 | CLSLoss:7.8442 | top1:95.0250 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8676 | MainLoss:0.8676 | SPLoss:0.5278 | CLSLoss:7.8394 | top1:73.6533 | AUROC:0.8181\n",
      "Test | 39/20 | Loss:1.3731 | MainLoss:1.3731 | SPLoss:0.5278 | CLSLoss:7.8394 | top1:61.2564 | AUROC:0.6538\n",
      "\n",
      "Epoch: [168 | 1000] LR: 0.000376\n",
      "Train | 20/20 | Loss:0.1034 | MainLoss:0.1034 | Alpha:0.4762 | SPLoss:0.1082 | CLSLoss:7.8474 | top1:95.5500 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8890 | MainLoss:0.8890 | SPLoss:0.3001 | CLSLoss:7.8563 | top1:73.4895 | AUROC:0.8178\n",
      "Test | 39/20 | Loss:1.3884 | MainLoss:1.3884 | SPLoss:0.3001 | CLSLoss:7.8563 | top1:61.1410 | AUROC:0.6552\n",
      "\n",
      "Epoch: [169 | 1000] LR: 0.000376\n",
      "Train | 20/20 | Loss:0.1140 | MainLoss:0.1140 | Alpha:0.4729 | SPLoss:0.2006 | CLSLoss:7.8378 | top1:95.0000 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8382 | MainLoss:0.8382 | SPLoss:0.5368 | CLSLoss:7.8169 | top1:73.9515 | AUROC:0.8178\n",
      "Test | 39/20 | Loss:1.3738 | MainLoss:1.3738 | SPLoss:0.5368 | CLSLoss:7.8169 | top1:60.9615 | AUROC:0.6505\n",
      "\n",
      "Epoch: [170 | 1000] LR: 0.000376\n",
      "Train | 20/20 | Loss:0.1222 | MainLoss:0.1222 | Alpha:0.4710 | SPLoss:0.1285 | CLSLoss:7.8395 | top1:94.7500 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8566 | MainLoss:0.8566 | SPLoss:0.3201 | CLSLoss:7.8416 | top1:73.8073 | AUROC:0.8178\n",
      "Test | 39/20 | Loss:1.3879 | MainLoss:1.3879 | SPLoss:0.3201 | CLSLoss:7.8416 | top1:60.5000 | AUROC:0.6458\n",
      "\n",
      "Epoch: [171 | 1000] LR: 0.000376\n",
      "Train | 20/20 | Loss:0.1114 | MainLoss:0.1114 | Alpha:0.4739 | SPLoss:0.1883 | CLSLoss:7.7969 | top1:94.9750 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8155 | MainLoss:0.8155 | SPLoss:0.4679 | CLSLoss:7.7861 | top1:73.8729 | AUROC:0.8190\n",
      "Test | 39/20 | Loss:1.3435 | MainLoss:1.3435 | SPLoss:0.4679 | CLSLoss:7.7861 | top1:60.4359 | AUROC:0.6466\n",
      "\n",
      "Epoch: [172 | 1000] LR: 0.000375\n",
      "Train | 20/20 | Loss:0.1060 | MainLoss:0.1060 | Alpha:0.4748 | SPLoss:0.1491 | CLSLoss:7.8398 | top1:95.5250 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8534 | MainLoss:0.8534 | SPLoss:0.4205 | CLSLoss:7.8684 | top1:73.8434 | AUROC:0.8194\n",
      "Test | 39/20 | Loss:1.4036 | MainLoss:1.4036 | SPLoss:0.4205 | CLSLoss:7.8684 | top1:60.5385 | AUROC:0.6462\n",
      "\n",
      "Epoch: [173 | 1000] LR: 0.000375\n",
      "Train | 20/20 | Loss:0.1131 | MainLoss:0.1131 | Alpha:0.4738 | SPLoss:0.1242 | CLSLoss:7.8854 | top1:94.9000 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8595 | MainLoss:0.8595 | SPLoss:0.3465 | CLSLoss:7.9052 | top1:73.7779 | AUROC:0.8182\n",
      "Test | 39/20 | Loss:1.4017 | MainLoss:1.4017 | SPLoss:0.3465 | CLSLoss:7.9052 | top1:60.2820 | AUROC:0.6471\n",
      "\n",
      "Epoch: [174 | 1000] LR: 0.000375\n",
      "Train | 20/20 | Loss:0.1133 | MainLoss:0.1133 | Alpha:0.4739 | SPLoss:0.1618 | CLSLoss:7.8864 | top1:95.0500 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8449 | MainLoss:0.8449 | SPLoss:0.4167 | CLSLoss:7.8972 | top1:73.7582 | AUROC:0.8174\n",
      "Test | 39/20 | Loss:1.3829 | MainLoss:1.3829 | SPLoss:0.4167 | CLSLoss:7.8972 | top1:60.1026 | AUROC:0.6446\n",
      "\n",
      "Epoch: [175 | 1000] LR: 0.000374\n",
      "Train | 20/20 | Loss:0.1287 | MainLoss:0.1287 | Alpha:0.4694 | SPLoss:0.2230 | CLSLoss:7.8579 | top1:94.3500 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8426 | MainLoss:0.8426 | SPLoss:0.5314 | CLSLoss:7.8534 | top1:73.6894 | AUROC:0.8171\n",
      "Test | 39/20 | Loss:1.4059 | MainLoss:1.4059 | SPLoss:0.5314 | CLSLoss:7.8534 | top1:59.2436 | AUROC:0.6350\n",
      "\n",
      "Epoch: [176 | 1000] LR: 0.000374\n",
      "Train | 20/20 | Loss:0.1103 | MainLoss:0.1103 | Alpha:0.4741 | SPLoss:0.2056 | CLSLoss:7.8935 | top1:95.3750 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8823 | MainLoss:0.8823 | SPLoss:0.5286 | CLSLoss:7.9191 | top1:73.9024 | AUROC:0.8174\n",
      "Test | 39/20 | Loss:1.5006 | MainLoss:1.5006 | SPLoss:0.5286 | CLSLoss:7.9191 | top1:59.3462 | AUROC:0.6322\n",
      "\n",
      "Epoch: [177 | 1000] LR: 0.000374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 20/20 | Loss:0.1128 | MainLoss:0.1128 | Alpha:0.4741 | SPLoss:0.1557 | CLSLoss:7.9354 | top1:94.7500 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8768 | MainLoss:0.8768 | SPLoss:0.4127 | CLSLoss:7.9417 | top1:73.9286 | AUROC:0.8193\n",
      "Test | 39/20 | Loss:1.5283 | MainLoss:1.5283 | SPLoss:0.4127 | CLSLoss:7.9417 | top1:58.6026 | AUROC:0.6235\n",
      "\n",
      "Epoch: [178 | 1000] LR: 0.000373\n",
      "Train | 20/20 | Loss:0.1034 | MainLoss:0.1034 | Alpha:0.4756 | SPLoss:0.1061 | CLSLoss:7.9395 | top1:95.3750 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8742 | MainLoss:0.8742 | SPLoss:0.2961 | CLSLoss:7.9600 | top1:73.8860 | AUROC:0.8189\n",
      "Test | 39/20 | Loss:1.5387 | MainLoss:1.5387 | SPLoss:0.2961 | CLSLoss:7.9600 | top1:58.5256 | AUROC:0.6199\n",
      "\n",
      "Epoch: [179 | 1000] LR: 0.000373\n",
      "Train | 20/20 | Loss:0.1039 | MainLoss:0.1039 | Alpha:0.4757 | SPLoss:0.1857 | CLSLoss:8.0019 | top1:95.6250 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.9019 | MainLoss:0.9019 | SPLoss:0.5251 | CLSLoss:8.0259 | top1:74.1776 | AUROC:0.8197\n",
      "Test | 39/20 | Loss:1.6154 | MainLoss:1.6154 | SPLoss:0.5251 | CLSLoss:8.0259 | top1:58.4744 | AUROC:0.6200\n",
      "\n",
      "Epoch: [180 | 1000] LR: 0.000373\n",
      "Train | 20/20 | Loss:0.1203 | MainLoss:0.1203 | Alpha:0.4716 | SPLoss:0.3686 | CLSLoss:7.9945 | top1:94.4750 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8727 | MainLoss:0.8727 | SPLoss:0.8796 | CLSLoss:7.9659 | top1:73.7320 | AUROC:0.8208\n",
      "Test | 39/20 | Loss:1.4697 | MainLoss:1.4697 | SPLoss:0.8796 | CLSLoss:7.9658 | top1:58.9103 | AUROC:0.6261\n",
      "\n",
      "Epoch: [181 | 1000] LR: 0.000372\n",
      "Train | 20/20 | Loss:0.1120 | MainLoss:0.1120 | Alpha:0.4741 | SPLoss:0.1487 | CLSLoss:7.9729 | top1:94.9750 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8683 | MainLoss:0.8683 | SPLoss:0.2792 | CLSLoss:8.0020 | top1:73.9810 | AUROC:0.8211\n",
      "Test | 39/20 | Loss:1.4715 | MainLoss:1.4715 | SPLoss:0.2792 | CLSLoss:8.0020 | top1:59.2436 | AUROC:0.6321\n",
      "\n",
      "Epoch: [182 | 1000] LR: 0.000372\n",
      "Train | 20/20 | Loss:0.1115 | MainLoss:0.1115 | Alpha:0.4733 | SPLoss:0.1561 | CLSLoss:8.0174 | top1:94.8000 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8772 | MainLoss:0.8772 | SPLoss:0.4968 | CLSLoss:8.0299 | top1:74.4070 | AUROC:0.8228\n",
      "Test | 39/20 | Loss:1.5638 | MainLoss:1.5638 | SPLoss:0.4968 | CLSLoss:8.0299 | top1:59.1410 | AUROC:0.6309\n",
      "\n",
      "Epoch: [183 | 1000] LR: 0.000372\n",
      "Train | 20/20 | Loss:0.1083 | MainLoss:0.1083 | Alpha:0.4739 | SPLoss:0.2861 | CLSLoss:8.0473 | top1:95.0250 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8714 | MainLoss:0.8714 | SPLoss:0.5332 | CLSLoss:8.0362 | top1:74.3250 | AUROC:0.8222\n",
      "Test | 39/20 | Loss:1.4992 | MainLoss:1.4992 | SPLoss:0.5332 | CLSLoss:8.0362 | top1:59.7179 | AUROC:0.6373\n",
      "\n",
      "Epoch: [184 | 1000] LR: 0.000372\n",
      "Train | 20/20 | Loss:0.1132 | MainLoss:0.1132 | Alpha:0.4731 | SPLoss:0.1763 | CLSLoss:8.0195 | top1:95.1250 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8503 | MainLoss:0.8503 | SPLoss:0.5250 | CLSLoss:7.9833 | top1:74.2595 | AUROC:0.8211\n",
      "Test | 39/20 | Loss:1.4708 | MainLoss:1.4708 | SPLoss:0.5250 | CLSLoss:7.9833 | top1:59.3333 | AUROC:0.6331\n",
      "\n",
      "Epoch: [185 | 1000] LR: 0.000371\n",
      "Train | 20/20 | Loss:0.1133 | MainLoss:0.1133 | Alpha:0.4736 | SPLoss:0.1886 | CLSLoss:7.9558 | top1:95.0000 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8411 | MainLoss:0.8411 | SPLoss:0.4661 | CLSLoss:7.9483 | top1:74.1710 | AUROC:0.8202\n",
      "Test | 39/20 | Loss:1.4554 | MainLoss:1.4554 | SPLoss:0.4661 | CLSLoss:7.9483 | top1:59.6923 | AUROC:0.6329\n",
      "\n",
      "Epoch: [186 | 1000] LR: 0.000371\n",
      "Train | 20/20 | Loss:0.1056 | MainLoss:0.1056 | Alpha:0.4758 | SPLoss:0.1308 | CLSLoss:7.9676 | top1:95.4000 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8519 | MainLoss:0.8519 | SPLoss:0.3750 | CLSLoss:7.9951 | top1:74.0302 | AUROC:0.8197\n",
      "Test | 39/20 | Loss:1.4824 | MainLoss:1.4824 | SPLoss:0.3750 | CLSLoss:7.9951 | top1:59.2051 | AUROC:0.6294\n",
      "\n",
      "Epoch: [187 | 1000] LR: 0.000371\n",
      "Train | 20/20 | Loss:0.1337 | MainLoss:0.1337 | Alpha:0.4684 | SPLoss:0.2001 | CLSLoss:7.9838 | top1:93.9250 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8389 | MainLoss:0.8389 | SPLoss:0.6031 | CLSLoss:7.9449 | top1:74.0105 | AUROC:0.8203\n",
      "Test | 39/20 | Loss:1.4707 | MainLoss:1.4707 | SPLoss:0.6031 | CLSLoss:7.9449 | top1:59.5128 | AUROC:0.6292\n",
      "\n",
      "Epoch: [188 | 1000] LR: 0.000370\n",
      "Train | 20/20 | Loss:0.1039 | MainLoss:0.1039 | Alpha:0.4753 | SPLoss:0.2365 | CLSLoss:8.0067 | top1:95.7500 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.9051 | MainLoss:0.9051 | SPLoss:0.6247 | CLSLoss:8.0783 | top1:73.8172 | AUROC:0.8198\n",
      "Test | 39/20 | Loss:1.5508 | MainLoss:1.5508 | SPLoss:0.6247 | CLSLoss:8.0783 | top1:59.7308 | AUROC:0.6297\n",
      "\n",
      "Epoch: [189 | 1000] LR: 0.000370\n",
      "Train | 20/20 | Loss:0.1123 | MainLoss:0.1123 | Alpha:0.4738 | SPLoss:0.1470 | CLSLoss:8.0776 | top1:94.7500 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8917 | MainLoss:0.8917 | SPLoss:0.3710 | CLSLoss:8.0688 | top1:73.8368 | AUROC:0.8196\n",
      "Test | 39/20 | Loss:1.5442 | MainLoss:1.5442 | SPLoss:0.3710 | CLSLoss:8.0688 | top1:59.3974 | AUROC:0.6288\n",
      "\n",
      "Epoch: [190 | 1000] LR: 0.000370\n",
      "Train | 20/20 | Loss:0.1050 | MainLoss:0.1050 | Alpha:0.4750 | SPLoss:0.1579 | CLSLoss:8.0505 | top1:95.3750 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8899 | MainLoss:0.8899 | SPLoss:0.3657 | CLSLoss:8.0760 | top1:73.8401 | AUROC:0.8190\n",
      "Test | 39/20 | Loss:1.5567 | MainLoss:1.5567 | SPLoss:0.3657 | CLSLoss:8.0760 | top1:59.4103 | AUROC:0.6287\n",
      "\n",
      "Epoch: [191 | 1000] LR: 0.000369\n",
      "Train | 20/20 | Loss:0.1088 | MainLoss:0.1088 | Alpha:0.4745 | SPLoss:0.1743 | CLSLoss:8.1156 | top1:94.9500 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.9221 | MainLoss:0.9221 | SPLoss:0.4212 | CLSLoss:8.1052 | top1:73.7779 | AUROC:0.8186\n",
      "Test | 39/20 | Loss:1.5925 | MainLoss:1.5925 | SPLoss:0.4212 | CLSLoss:8.1052 | top1:59.7179 | AUROC:0.6304\n",
      "\n",
      "Epoch: [192 | 1000] LR: 0.000369\n",
      "Train | 20/20 | Loss:0.1015 | MainLoss:0.1015 | Alpha:0.4763 | SPLoss:0.1207 | CLSLoss:8.0956 | top1:95.5750 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.9171 | MainLoss:0.9171 | SPLoss:0.3385 | CLSLoss:8.1010 | top1:73.9908 | AUROC:0.8201\n",
      "Test | 39/20 | Loss:1.6065 | MainLoss:1.6065 | SPLoss:0.3385 | CLSLoss:8.1010 | top1:59.3974 | AUROC:0.6276\n",
      "\n",
      "Epoch: [193 | 1000] LR: 0.000369\n",
      "Train | 20/20 | Loss:0.1193 | MainLoss:0.1193 | Alpha:0.4725 | SPLoss:0.2086 | CLSLoss:8.0883 | top1:94.6500 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8783 | MainLoss:0.8783 | SPLoss:0.5451 | CLSLoss:8.0938 | top1:73.8368 | AUROC:0.8206\n",
      "Test | 39/20 | Loss:1.5202 | MainLoss:1.5202 | SPLoss:0.5451 | CLSLoss:8.0938 | top1:59.4487 | AUROC:0.6297\n",
      "\n",
      "Epoch: [194 | 1000] LR: 0.000368\n",
      "Train | 20/20 | Loss:0.0979 | MainLoss:0.0979 | Alpha:0.4771 | SPLoss:0.2338 | CLSLoss:8.0919 | top1:95.5500 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.9077 | MainLoss:0.9077 | SPLoss:0.4392 | CLSLoss:8.1501 | top1:73.9876 | AUROC:0.8201\n",
      "Test | 39/20 | Loss:1.5594 | MainLoss:1.5594 | SPLoss:0.4392 | CLSLoss:8.1501 | top1:60.1538 | AUROC:0.6370\n",
      "\n",
      "Epoch: [195 | 1000] LR: 0.000368\n",
      "Train | 20/20 | Loss:0.1075 | MainLoss:0.1075 | Alpha:0.4748 | SPLoss:0.2034 | CLSLoss:8.1881 | top1:95.2500 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.9247 | MainLoss:0.9247 | SPLoss:0.4473 | CLSLoss:8.1930 | top1:73.7451 | AUROC:0.8200\n",
      "Test | 39/20 | Loss:1.5704 | MainLoss:1.5704 | SPLoss:0.4473 | CLSLoss:8.1930 | top1:60.2949 | AUROC:0.6362\n",
      "\n",
      "Epoch: [196 | 1000] LR: 0.000368\n",
      "Train | 20/20 | Loss:0.1035 | MainLoss:0.1035 | Alpha:0.4763 | SPLoss:0.1669 | CLSLoss:8.1732 | top1:95.8250 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8981 | MainLoss:0.8981 | SPLoss:0.4645 | CLSLoss:8.1488 | top1:74.2759 | AUROC:0.8207\n",
      "Test | 39/20 | Loss:1.5931 | MainLoss:1.5931 | SPLoss:0.4645 | CLSLoss:8.1488 | top1:59.7949 | AUROC:0.6367\n",
      "\n",
      "Epoch: [197 | 1000] LR: 0.000367\n",
      "Train | 20/20 | Loss:0.1227 | MainLoss:0.1227 | Alpha:0.4698 | SPLoss:0.3344 | CLSLoss:8.1101 | top1:94.3250 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8328 | MainLoss:0.8328 | SPLoss:1.0203 | CLSLoss:8.0635 | top1:73.9646 | AUROC:0.8214\n",
      "Test | 39/20 | Loss:1.4491 | MainLoss:1.4491 | SPLoss:1.0203 | CLSLoss:8.0635 | top1:60.1538 | AUROC:0.6361\n",
      "\n",
      "Epoch: [198 | 1000] LR: 0.000367\n",
      "Train | 20/20 | Loss:0.1152 | MainLoss:0.1152 | Alpha:0.4725 | SPLoss:0.1528 | CLSLoss:8.0684 | top1:94.5500 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8528 | MainLoss:0.8528 | SPLoss:0.4423 | CLSLoss:8.0725 | top1:74.0367 | AUROC:0.8215\n",
      "Test | 39/20 | Loss:1.4907 | MainLoss:1.4907 | SPLoss:0.4423 | CLSLoss:8.0725 | top1:59.9359 | AUROC:0.6319\n",
      "\n",
      "Epoch: [199 | 1000] LR: 0.000366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 20/20 | Loss:0.0998 | MainLoss:0.0998 | Alpha:0.4766 | SPLoss:0.1464 | CLSLoss:8.1064 | top1:95.2500 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8961 | MainLoss:0.8961 | SPLoss:0.4573 | CLSLoss:8.1374 | top1:74.0039 | AUROC:0.8201\n",
      "Test | 39/20 | Loss:1.5754 | MainLoss:1.5754 | SPLoss:0.4572 | CLSLoss:8.1374 | top1:59.8974 | AUROC:0.6330\n",
      "\n",
      "Epoch: [200 | 1000] LR: 0.000366\n",
      "Train | 20/20 | Loss:0.1061 | MainLoss:0.1061 | Alpha:0.4751 | SPLoss:0.1930 | CLSLoss:8.1852 | top1:95.2500 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.9242 | MainLoss:0.9242 | SPLoss:0.5119 | CLSLoss:8.2025 | top1:73.8434 | AUROC:0.8210\n",
      "Test | 39/20 | Loss:1.5920 | MainLoss:1.5920 | SPLoss:0.5119 | CLSLoss:8.2025 | top1:60.0128 | AUROC:0.6332\n",
      "\n",
      "Epoch: [201 | 1000] LR: 0.000366\n",
      "Train | 20/20 | Loss:0.1246 | MainLoss:0.1246 | Alpha:0.4705 | SPLoss:0.3168 | CLSLoss:8.1586 | top1:94.5000 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8621 | MainLoss:0.8621 | SPLoss:0.8399 | CLSLoss:8.0810 | top1:73.6402 | AUROC:0.8208\n",
      "Test | 39/20 | Loss:1.4464 | MainLoss:1.4464 | SPLoss:0.8399 | CLSLoss:8.0810 | top1:59.7692 | AUROC:0.6353\n",
      "\n",
      "Epoch: [202 | 1000] LR: 0.000365\n",
      "Train | 20/20 | Loss:0.1049 | MainLoss:0.1049 | Alpha:0.4748 | SPLoss:0.2360 | CLSLoss:8.0764 | top1:95.5250 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8849 | MainLoss:0.8849 | SPLoss:0.6464 | CLSLoss:8.1201 | top1:74.1088 | AUROC:0.8217\n",
      "Test | 39/20 | Loss:1.5413 | MainLoss:1.5413 | SPLoss:0.6464 | CLSLoss:8.1201 | top1:60.0128 | AUROC:0.6393\n",
      "\n",
      "Epoch: [203 | 1000] LR: 0.000365\n",
      "Train | 20/20 | Loss:0.1100 | MainLoss:0.1100 | Alpha:0.4746 | SPLoss:0.1891 | CLSLoss:8.1458 | top1:94.7750 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.9234 | MainLoss:0.9234 | SPLoss:0.5086 | CLSLoss:8.1574 | top1:74.1022 | AUROC:0.8214\n",
      "Test | 39/20 | Loss:1.6203 | MainLoss:1.6203 | SPLoss:0.5086 | CLSLoss:8.1574 | top1:59.3974 | AUROC:0.6319\n",
      "\n",
      "Epoch: [204 | 1000] LR: 0.000365\n",
      "Train | 20/20 | Loss:0.1010 | MainLoss:0.1010 | Alpha:0.4752 | SPLoss:0.1606 | CLSLoss:8.1683 | top1:95.3500 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.9333 | MainLoss:0.9333 | SPLoss:0.3592 | CLSLoss:8.1787 | top1:73.9941 | AUROC:0.8215\n",
      "Test | 39/20 | Loss:1.6271 | MainLoss:1.6271 | SPLoss:0.3592 | CLSLoss:8.1787 | top1:59.4359 | AUROC:0.6303\n",
      "\n",
      "Epoch: [205 | 1000] LR: 0.000364\n",
      "Train | 20/20 | Loss:0.1293 | MainLoss:0.1293 | Alpha:0.4699 | SPLoss:0.2468 | CLSLoss:8.1549 | top1:94.6500 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8867 | MainLoss:0.8867 | SPLoss:0.6794 | CLSLoss:8.1073 | top1:73.9548 | AUROC:0.8209\n",
      "Test | 39/20 | Loss:1.5498 | MainLoss:1.5498 | SPLoss:0.6794 | CLSLoss:8.1073 | top1:59.4744 | AUROC:0.6310\n",
      "\n",
      "Epoch: [206 | 1000] LR: 0.000364\n",
      "Train | 20/20 | Loss:0.1142 | MainLoss:0.1142 | Alpha:0.4735 | SPLoss:0.3238 | CLSLoss:8.0119 | top1:95.3750 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8330 | MainLoss:0.8330 | SPLoss:0.6688 | CLSLoss:7.9952 | top1:74.0367 | AUROC:0.8216\n",
      "Test | 39/20 | Loss:1.4451 | MainLoss:1.4451 | SPLoss:0.6688 | CLSLoss:7.9951 | top1:59.7564 | AUROC:0.6320\n",
      "\n",
      "Epoch: [207 | 1000] LR: 0.000364\n",
      "Train | 20/20 | Loss:0.1172 | MainLoss:0.1172 | Alpha:0.4725 | SPLoss:0.1863 | CLSLoss:8.0138 | top1:95.1250 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8320 | MainLoss:0.8320 | SPLoss:0.5189 | CLSLoss:8.0189 | top1:74.3414 | AUROC:0.8232\n",
      "Test | 39/20 | Loss:1.4816 | MainLoss:1.4816 | SPLoss:0.5189 | CLSLoss:8.0189 | top1:59.8846 | AUROC:0.6360\n",
      "\n",
      "Epoch: [208 | 1000] LR: 0.000363\n",
      "Train | 20/20 | Loss:0.1039 | MainLoss:0.1039 | Alpha:0.4756 | SPLoss:0.2973 | CLSLoss:8.0679 | top1:95.4500 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8637 | MainLoss:0.8637 | SPLoss:0.5551 | CLSLoss:8.0940 | top1:74.3775 | AUROC:0.8236\n",
      "Test | 39/20 | Loss:1.5259 | MainLoss:1.5259 | SPLoss:0.5551 | CLSLoss:8.0940 | top1:59.9744 | AUROC:0.6360\n",
      "\n",
      "Epoch: [209 | 1000] LR: 0.000363\n",
      "Train | 20/20 | Loss:0.1101 | MainLoss:0.1101 | Alpha:0.4749 | SPLoss:0.1854 | CLSLoss:8.1137 | top1:95.3500 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8563 | MainLoss:0.8563 | SPLoss:0.4838 | CLSLoss:8.0663 | top1:74.3087 | AUROC:0.8240\n",
      "Test | 39/20 | Loss:1.4744 | MainLoss:1.4744 | SPLoss:0.4838 | CLSLoss:8.0664 | top1:59.9231 | AUROC:0.6382\n",
      "\n",
      "Epoch: [210 | 1000] LR: 0.000363\n",
      "Train | 20/20 | Loss:0.1058 | MainLoss:0.1058 | Alpha:0.4758 | SPLoss:0.2412 | CLSLoss:8.0326 | top1:95.8000 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8716 | MainLoss:0.8716 | SPLoss:0.7160 | CLSLoss:8.0299 | top1:73.4305 | AUROC:0.8223\n",
      "Test | 39/20 | Loss:1.4147 | MainLoss:1.4147 | SPLoss:0.7160 | CLSLoss:8.0299 | top1:59.8077 | AUROC:0.6388\n",
      "\n",
      "Epoch: [211 | 1000] LR: 0.000362\n",
      "Train | 20/20 | Loss:0.1098 | MainLoss:0.1098 | Alpha:0.4735 | SPLoss:0.4036 | CLSLoss:8.0021 | top1:95.2750 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8285 | MainLoss:0.8285 | SPLoss:0.8551 | CLSLoss:7.9955 | top1:74.3512 | AUROC:0.8217\n",
      "Test | 39/20 | Loss:1.4498 | MainLoss:1.4498 | SPLoss:0.8551 | CLSLoss:7.9954 | top1:60.1026 | AUROC:0.6379\n",
      "\n",
      "Epoch: [212 | 1000] LR: 0.000362\n",
      "Train | 20/20 | Loss:0.1080 | MainLoss:0.1080 | Alpha:0.4754 | SPLoss:0.1624 | CLSLoss:8.0145 | top1:95.3250 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8540 | MainLoss:0.8540 | SPLoss:0.3892 | CLSLoss:8.0311 | top1:74.1055 | AUROC:0.8213\n",
      "Test | 39/20 | Loss:1.4971 | MainLoss:1.4971 | SPLoss:0.3892 | CLSLoss:8.0311 | top1:59.6282 | AUROC:0.6319\n",
      "\n",
      "Epoch: [213 | 1000] LR: 0.000361\n",
      "Train | 20/20 | Loss:0.0974 | MainLoss:0.0974 | Alpha:0.4777 | SPLoss:0.1226 | CLSLoss:8.0438 | top1:95.9000 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8708 | MainLoss:0.8708 | SPLoss:0.3024 | CLSLoss:8.0688 | top1:74.1809 | AUROC:0.8214\n",
      "Test | 39/20 | Loss:1.5255 | MainLoss:1.5255 | SPLoss:0.3024 | CLSLoss:8.0688 | top1:59.7692 | AUROC:0.6317\n",
      "\n",
      "Epoch: [214 | 1000] LR: 0.000361\n",
      "Train | 20/20 | Loss:0.0969 | MainLoss:0.0969 | Alpha:0.4770 | SPLoss:0.2221 | CLSLoss:8.1215 | top1:96.0750 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8974 | MainLoss:0.8974 | SPLoss:0.5651 | CLSLoss:8.1364 | top1:74.2661 | AUROC:0.8220\n",
      "Test | 39/20 | Loss:1.5640 | MainLoss:1.5640 | SPLoss:0.5651 | CLSLoss:8.1364 | top1:60.0513 | AUROC:0.6365\n",
      "\n",
      "Epoch: [215 | 1000] LR: 0.000361\n",
      "Train | 20/20 | Loss:0.1050 | MainLoss:0.1050 | Alpha:0.4749 | SPLoss:0.1446 | CLSLoss:8.1497 | top1:95.6250 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8710 | MainLoss:0.8710 | SPLoss:0.4353 | CLSLoss:8.1388 | top1:74.0072 | AUROC:0.8209\n",
      "Test | 39/20 | Loss:1.4955 | MainLoss:1.4955 | SPLoss:0.4353 | CLSLoss:8.1388 | top1:59.9359 | AUROC:0.6356\n",
      "\n",
      "Epoch: [216 | 1000] LR: 0.000360\n",
      "Train | 20/20 | Loss:0.0974 | MainLoss:0.0974 | Alpha:0.4772 | SPLoss:0.1859 | CLSLoss:8.1266 | top1:95.8000 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8602 | MainLoss:0.8602 | SPLoss:0.4978 | CLSLoss:8.1301 | top1:74.1022 | AUROC:0.8209\n",
      "Test | 39/20 | Loss:1.5357 | MainLoss:1.5357 | SPLoss:0.4978 | CLSLoss:8.1301 | top1:59.7051 | AUROC:0.6321\n",
      "\n",
      "Epoch: [217 | 1000] LR: 0.000360\n",
      "Train | 20/20 | Loss:0.1068 | MainLoss:0.1068 | Alpha:0.4740 | SPLoss:0.2531 | CLSLoss:8.1917 | top1:95.5750 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8831 | MainLoss:0.8831 | SPLoss:0.4804 | CLSLoss:8.2072 | top1:73.8336 | AUROC:0.8212\n",
      "Test | 39/20 | Loss:1.4923 | MainLoss:1.4923 | SPLoss:0.4804 | CLSLoss:8.2072 | top1:59.8205 | AUROC:0.6364\n",
      "\n",
      "Epoch: [218 | 1000] LR: 0.000360\n",
      "Train | 20/20 | Loss:0.1057 | MainLoss:0.1057 | Alpha:0.4761 | SPLoss:0.2248 | CLSLoss:8.1926 | top1:95.1250 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8787 | MainLoss:0.8787 | SPLoss:0.4759 | CLSLoss:8.2048 | top1:73.4338 | AUROC:0.8213\n",
      "Test | 39/20 | Loss:1.4681 | MainLoss:1.4681 | SPLoss:0.4759 | CLSLoss:8.2047 | top1:59.6667 | AUROC:0.6314\n",
      "\n",
      "Epoch: [219 | 1000] LR: 0.000359\n",
      "Train | 20/20 | Loss:0.0952 | MainLoss:0.0952 | Alpha:0.4770 | SPLoss:0.3038 | CLSLoss:8.2114 | top1:95.5000 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.9128 | MainLoss:0.9128 | SPLoss:0.7591 | CLSLoss:8.2581 | top1:74.0826 | AUROC:0.8220\n",
      "Test | 39/20 | Loss:1.6291 | MainLoss:1.6291 | SPLoss:0.7591 | CLSLoss:8.2582 | top1:59.3590 | AUROC:0.6267\n",
      "\n",
      "Epoch: [220 | 1000] LR: 0.000359\n",
      "Train | 20/20 | Loss:0.1095 | MainLoss:0.1095 | Alpha:0.4754 | SPLoss:0.1851 | CLSLoss:8.2809 | top1:95.4000 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8887 | MainLoss:0.8887 | SPLoss:0.5770 | CLSLoss:8.2270 | top1:74.2792 | AUROC:0.8223\n",
      "Test | 39/20 | Loss:1.6074 | MainLoss:1.6074 | SPLoss:0.5770 | CLSLoss:8.2270 | top1:59.0385 | AUROC:0.6281\n",
      "\n",
      "Epoch: [221 | 1000] LR: 0.000358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 20/20 | Loss:0.1076 | MainLoss:0.1076 | Alpha:0.4743 | SPLoss:0.3178 | CLSLoss:8.2183 | top1:95.3500 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8754 | MainLoss:0.8754 | SPLoss:0.5872 | CLSLoss:8.2188 | top1:73.9908 | AUROC:0.8216\n",
      "Test | 39/20 | Loss:1.5360 | MainLoss:1.5360 | SPLoss:0.5872 | CLSLoss:8.2188 | top1:59.2692 | AUROC:0.6283\n",
      "\n",
      "Epoch: [222 | 1000] LR: 0.000358\n",
      "Train | 20/20 | Loss:0.1025 | MainLoss:0.1025 | Alpha:0.4757 | SPLoss:0.2589 | CLSLoss:8.2258 | top1:95.2750 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.9077 | MainLoss:0.9077 | SPLoss:0.5956 | CLSLoss:8.2388 | top1:73.9450 | AUROC:0.8212\n",
      "Test | 39/20 | Loss:1.5787 | MainLoss:1.5787 | SPLoss:0.5956 | CLSLoss:8.2388 | top1:58.9359 | AUROC:0.6227\n",
      "\n",
      "Epoch: [223 | 1000] LR: 0.000358\n",
      "Train | 20/20 | Loss:0.1134 | MainLoss:0.1134 | Alpha:0.4744 | SPLoss:0.2109 | CLSLoss:8.2210 | top1:95.4750 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8389 | MainLoss:0.8389 | SPLoss:0.6845 | CLSLoss:8.1627 | top1:73.9417 | AUROC:0.8205\n",
      "Test | 39/20 | Loss:1.4925 | MainLoss:1.4925 | SPLoss:0.6845 | CLSLoss:8.1627 | top1:58.7179 | AUROC:0.6221\n",
      "\n",
      "Epoch: [224 | 1000] LR: 0.000357\n",
      "Train | 20/20 | Loss:0.1086 | MainLoss:0.1086 | Alpha:0.4744 | SPLoss:0.2215 | CLSLoss:8.1778 | top1:95.1750 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8676 | MainLoss:0.8676 | SPLoss:0.5749 | CLSLoss:8.2267 | top1:73.9056 | AUROC:0.8204\n",
      "Test | 39/20 | Loss:1.5409 | MainLoss:1.5409 | SPLoss:0.5749 | CLSLoss:8.2267 | top1:58.5641 | AUROC:0.6232\n",
      "\n",
      "Epoch: [225 | 1000] LR: 0.000357\n",
      "Train | 20/20 | Loss:0.1161 | MainLoss:0.1161 | Alpha:0.4734 | SPLoss:0.1604 | CLSLoss:8.2462 | top1:94.8500 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8891 | MainLoss:0.8891 | SPLoss:0.4419 | CLSLoss:8.2723 | top1:73.9417 | AUROC:0.8199\n",
      "Test | 39/20 | Loss:1.5609 | MainLoss:1.5609 | SPLoss:0.4419 | CLSLoss:8.2723 | top1:58.6410 | AUROC:0.6232\n",
      "\n",
      "Epoch: [226 | 1000] LR: 0.000356\n",
      "Train | 20/20 | Loss:0.0998 | MainLoss:0.0998 | Alpha:0.4770 | SPLoss:0.2012 | CLSLoss:8.2779 | top1:95.5250 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8662 | MainLoss:0.8662 | SPLoss:0.5809 | CLSLoss:8.2719 | top1:73.9187 | AUROC:0.8186\n",
      "Test | 39/20 | Loss:1.5505 | MainLoss:1.5505 | SPLoss:0.5809 | CLSLoss:8.2719 | top1:58.7564 | AUROC:0.6232\n",
      "\n",
      "Epoch: [227 | 1000] LR: 0.000356\n",
      "Train | 20/20 | Loss:0.1028 | MainLoss:0.1028 | Alpha:0.4756 | SPLoss:0.1849 | CLSLoss:8.2823 | top1:95.9250 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8813 | MainLoss:0.8813 | SPLoss:0.5146 | CLSLoss:8.3041 | top1:73.6239 | AUROC:0.8187\n",
      "Test | 39/20 | Loss:1.5121 | MainLoss:1.5121 | SPLoss:0.5146 | CLSLoss:8.3041 | top1:58.9103 | AUROC:0.6270\n",
      "\n",
      "Epoch: [228 | 1000] LR: 0.000356\n",
      "Train | 20/20 | Loss:0.1004 | MainLoss:0.1004 | Alpha:0.4761 | SPLoss:0.1878 | CLSLoss:8.3200 | top1:95.4250 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8896 | MainLoss:0.8896 | SPLoss:0.5142 | CLSLoss:8.3400 | top1:73.7877 | AUROC:0.8191\n",
      "Test | 39/20 | Loss:1.5587 | MainLoss:1.5587 | SPLoss:0.5142 | CLSLoss:8.3400 | top1:59.1282 | AUROC:0.6280\n",
      "\n",
      "Epoch: [229 | 1000] LR: 0.000355\n",
      "Train | 20/20 | Loss:0.1030 | MainLoss:0.1030 | Alpha:0.4758 | SPLoss:0.1827 | CLSLoss:8.3378 | top1:95.4250 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8818 | MainLoss:0.8818 | SPLoss:0.5609 | CLSLoss:8.3517 | top1:73.6468 | AUROC:0.8204\n",
      "Test | 39/20 | Loss:1.4992 | MainLoss:1.4992 | SPLoss:0.5609 | CLSLoss:8.3517 | top1:59.1282 | AUROC:0.6260\n",
      "\n",
      "Epoch: [230 | 1000] LR: 0.000355\n",
      "Train | 20/20 | Loss:0.1031 | MainLoss:0.1031 | Alpha:0.4756 | SPLoss:0.2286 | CLSLoss:8.3620 | top1:95.6250 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8766 | MainLoss:0.8766 | SPLoss:0.4920 | CLSLoss:8.3840 | top1:73.8827 | AUROC:0.8205\n",
      "Test | 39/20 | Loss:1.5280 | MainLoss:1.5280 | SPLoss:0.4920 | CLSLoss:8.3840 | top1:59.2051 | AUROC:0.6290\n",
      "\n",
      "Epoch: [231 | 1000] LR: 0.000355\n",
      "Train | 20/20 | Loss:0.1227 | MainLoss:0.1227 | Alpha:0.4720 | SPLoss:0.2231 | CLSLoss:8.3591 | top1:95.0250 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8384 | MainLoss:0.8384 | SPLoss:0.6134 | CLSLoss:8.3013 | top1:73.9941 | AUROC:0.8209\n",
      "Test | 39/20 | Loss:1.4766 | MainLoss:1.4766 | SPLoss:0.6134 | CLSLoss:8.3013 | top1:59.4359 | AUROC:0.6319\n",
      "\n",
      "Epoch: [232 | 1000] LR: 0.000354\n",
      "Train | 20/20 | Loss:0.0947 | MainLoss:0.0947 | Alpha:0.4779 | SPLoss:0.1273 | CLSLoss:8.3288 | top1:95.6500 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8763 | MainLoss:0.8763 | SPLoss:0.3851 | CLSLoss:8.3659 | top1:73.9581 | AUROC:0.8195\n",
      "Test | 39/20 | Loss:1.5425 | MainLoss:1.5425 | SPLoss:0.3851 | CLSLoss:8.3659 | top1:59.6538 | AUROC:0.6325\n",
      "\n",
      "Epoch: [233 | 1000] LR: 0.000354\n",
      "Train | 20/20 | Loss:0.0934 | MainLoss:0.0934 | Alpha:0.4780 | SPLoss:0.2019 | CLSLoss:8.4225 | top1:96.0000 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.9305 | MainLoss:0.9305 | SPLoss:0.5482 | CLSLoss:8.4672 | top1:73.8827 | AUROC:0.8192\n",
      "Test | 39/20 | Loss:1.6076 | MainLoss:1.6076 | SPLoss:0.5482 | CLSLoss:8.4672 | top1:60.1667 | AUROC:0.6400\n",
      "\n",
      "Epoch: [234 | 1000] LR: 0.000353\n",
      "Train | 20/20 | Loss:0.1157 | MainLoss:0.1157 | Alpha:0.4731 | SPLoss:0.2208 | CLSLoss:8.4537 | top1:95.1500 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8670 | MainLoss:0.8670 | SPLoss:0.7824 | CLSLoss:8.3760 | top1:73.8041 | AUROC:0.8206\n",
      "Test | 39/20 | Loss:1.5104 | MainLoss:1.5104 | SPLoss:0.7824 | CLSLoss:8.3760 | top1:59.6923 | AUROC:0.6297\n",
      "\n",
      "Epoch: [235 | 1000] LR: 0.000353\n",
      "Train | 20/20 | Loss:0.0977 | MainLoss:0.0977 | Alpha:0.4770 | SPLoss:0.1636 | CLSLoss:8.3654 | top1:95.6750 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8768 | MainLoss:0.8768 | SPLoss:0.4197 | CLSLoss:8.3964 | top1:73.8204 | AUROC:0.8199\n",
      "Test | 39/20 | Loss:1.5595 | MainLoss:1.5595 | SPLoss:0.4197 | CLSLoss:8.3964 | top1:59.3077 | AUROC:0.6270\n",
      "\n",
      "Epoch: [236 | 1000] LR: 0.000352\n",
      "Train | 20/20 | Loss:0.1057 | MainLoss:0.1057 | Alpha:0.4762 | SPLoss:0.2124 | CLSLoss:8.4062 | top1:95.2750 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8751 | MainLoss:0.8751 | SPLoss:0.4743 | CLSLoss:8.3740 | top1:73.7910 | AUROC:0.8197\n",
      "Test | 39/20 | Loss:1.5505 | MainLoss:1.5505 | SPLoss:0.4743 | CLSLoss:8.3740 | top1:59.2692 | AUROC:0.6258\n",
      "\n",
      "Epoch: [237 | 1000] LR: 0.000352\n",
      "Train | 20/20 | Loss:0.0999 | MainLoss:0.0999 | Alpha:0.4768 | SPLoss:0.1968 | CLSLoss:8.3873 | top1:95.3250 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8819 | MainLoss:0.8819 | SPLoss:0.4797 | CLSLoss:8.3876 | top1:73.9024 | AUROC:0.8189\n",
      "Test | 39/20 | Loss:1.5605 | MainLoss:1.5605 | SPLoss:0.4797 | CLSLoss:8.3876 | top1:59.8077 | AUROC:0.6341\n",
      "\n",
      "Epoch: [238 | 1000] LR: 0.000352\n",
      "Train | 20/20 | Loss:0.0999 | MainLoss:0.0999 | Alpha:0.4755 | SPLoss:0.1898 | CLSLoss:8.4140 | top1:95.7250 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8925 | MainLoss:0.8925 | SPLoss:0.5063 | CLSLoss:8.4248 | top1:73.6992 | AUROC:0.8183\n",
      "Test | 39/20 | Loss:1.5465 | MainLoss:1.5465 | SPLoss:0.5063 | CLSLoss:8.4248 | top1:59.8462 | AUROC:0.6321\n",
      "\n",
      "Epoch: [239 | 1000] LR: 0.000351\n",
      "Train | 20/20 | Loss:0.1058 | MainLoss:0.1058 | Alpha:0.4759 | SPLoss:0.2108 | CLSLoss:8.4020 | top1:95.6000 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8996 | MainLoss:0.8996 | SPLoss:0.5377 | CLSLoss:8.4071 | top1:73.4600 | AUROC:0.8193\n",
      "Test | 39/20 | Loss:1.4956 | MainLoss:1.4956 | SPLoss:0.5377 | CLSLoss:8.4071 | top1:59.6410 | AUROC:0.6329\n",
      "\n",
      "Epoch: [240 | 1000] LR: 0.000351\n",
      "Train | 20/20 | Loss:0.1002 | MainLoss:0.1002 | Alpha:0.4765 | SPLoss:0.3211 | CLSLoss:8.3941 | top1:95.4750 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8909 | MainLoss:0.8909 | SPLoss:0.6859 | CLSLoss:8.4063 | top1:73.6370 | AUROC:0.8195\n",
      "Test | 39/20 | Loss:1.5631 | MainLoss:1.5631 | SPLoss:0.6859 | CLSLoss:8.4063 | top1:59.4103 | AUROC:0.6282\n",
      "\n",
      "Epoch: [241 | 1000] LR: 0.000350\n",
      "Train | 20/20 | Loss:0.1157 | MainLoss:0.1157 | Alpha:0.4727 | SPLoss:0.2355 | CLSLoss:8.3754 | top1:94.9750 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8528 | MainLoss:0.8528 | SPLoss:0.6654 | CLSLoss:8.3191 | top1:73.7418 | AUROC:0.8195\n",
      "Test | 39/20 | Loss:1.5362 | MainLoss:1.5362 | SPLoss:0.6654 | CLSLoss:8.3191 | top1:59.2179 | AUROC:0.6241\n",
      "\n",
      "Epoch: [242 | 1000] LR: 0.000350\n",
      "Train | 20/20 | Loss:0.0978 | MainLoss:0.0978 | Alpha:0.4766 | SPLoss:0.2344 | CLSLoss:8.3073 | top1:95.6250 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8745 | MainLoss:0.8745 | SPLoss:0.5897 | CLSLoss:8.3640 | top1:73.5518 | AUROC:0.8182\n",
      "Test | 39/20 | Loss:1.5145 | MainLoss:1.5145 | SPLoss:0.5897 | CLSLoss:8.3640 | top1:59.3205 | AUROC:0.6289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [243 | 1000] LR: 0.000350\n",
      "Train | 20/20 | Loss:0.1006 | MainLoss:0.1006 | Alpha:0.4761 | SPLoss:0.2124 | CLSLoss:8.4087 | top1:95.6750 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.9255 | MainLoss:0.9255 | SPLoss:0.5816 | CLSLoss:8.4570 | top1:73.5157 | AUROC:0.8184\n",
      "Test | 39/20 | Loss:1.5951 | MainLoss:1.5951 | SPLoss:0.5816 | CLSLoss:8.4570 | top1:59.5000 | AUROC:0.6307\n",
      "\n",
      "Epoch: [244 | 1000] LR: 0.000349\n",
      "Train | 20/20 | Loss:0.1192 | MainLoss:0.1192 | Alpha:0.4720 | SPLoss:0.3869 | CLSLoss:8.3858 | top1:95.3500 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8499 | MainLoss:0.8499 | SPLoss:1.0797 | CLSLoss:8.3148 | top1:73.4011 | AUROC:0.8172\n",
      "Test | 39/20 | Loss:1.4557 | MainLoss:1.4557 | SPLoss:1.0797 | CLSLoss:8.3148 | top1:59.0128 | AUROC:0.6262\n",
      "\n",
      "Epoch: [245 | 1000] LR: 0.000349\n",
      "Train | 20/20 | Loss:0.0984 | MainLoss:0.0984 | Alpha:0.4779 | SPLoss:0.1700 | CLSLoss:8.3444 | top1:95.7000 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8764 | MainLoss:0.8764 | SPLoss:0.5224 | CLSLoss:8.3897 | top1:73.7287 | AUROC:0.8175\n",
      "Test | 39/20 | Loss:1.5410 | MainLoss:1.5410 | SPLoss:0.5224 | CLSLoss:8.3897 | top1:59.1923 | AUROC:0.6289\n",
      "\n",
      "Epoch: [246 | 1000] LR: 0.000348\n",
      "Train | 20/20 | Loss:0.0976 | MainLoss:0.0976 | Alpha:0.4773 | SPLoss:0.2240 | CLSLoss:8.4246 | top1:95.7750 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.9018 | MainLoss:0.9018 | SPLoss:0.6354 | CLSLoss:8.4410 | top1:73.6730 | AUROC:0.8193\n",
      "Test | 39/20 | Loss:1.5723 | MainLoss:1.5723 | SPLoss:0.6354 | CLSLoss:8.4410 | top1:59.2179 | AUROC:0.6305\n",
      "\n",
      "Epoch: [247 | 1000] LR: 0.000348\n",
      "Train | 20/20 | Loss:0.1195 | MainLoss:0.1195 | Alpha:0.4729 | SPLoss:0.3075 | CLSLoss:8.3840 | top1:95.0000 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8385 | MainLoss:0.8385 | SPLoss:0.8523 | CLSLoss:8.3298 | top1:73.6959 | AUROC:0.8216\n",
      "Test | 39/20 | Loss:1.4680 | MainLoss:1.4680 | SPLoss:0.8523 | CLSLoss:8.3298 | top1:58.4359 | AUROC:0.6230\n",
      "\n",
      "Epoch: [248 | 1000] LR: 0.000348\n",
      "Train | 20/20 | Loss:0.0920 | MainLoss:0.0920 | Alpha:0.4787 | SPLoss:0.2120 | CLSLoss:8.3610 | top1:95.9250 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.9063 | MainLoss:0.9063 | SPLoss:0.5403 | CLSLoss:8.4430 | top1:73.3716 | AUROC:0.8223\n",
      "Test | 39/20 | Loss:1.5356 | MainLoss:1.5356 | SPLoss:0.5403 | CLSLoss:8.4430 | top1:58.8590 | AUROC:0.6265\n",
      "\n",
      "Epoch: [249 | 1000] LR: 0.000347\n",
      "Train | 20/20 | Loss:0.1208 | MainLoss:0.1208 | Alpha:0.4716 | SPLoss:0.3846 | CLSLoss:8.3744 | top1:94.8500 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8461 | MainLoss:0.8461 | SPLoss:0.7315 | CLSLoss:8.3449 | top1:73.9515 | AUROC:0.8216\n",
      "Test | 39/20 | Loss:1.4840 | MainLoss:1.4840 | SPLoss:0.7315 | CLSLoss:8.3449 | top1:59.1667 | AUROC:0.6293\n",
      "\n",
      "Epoch: [250 | 1000] LR: 0.000347\n",
      "Train | 20/20 | Loss:0.1002 | MainLoss:0.1002 | Alpha:0.4760 | SPLoss:0.1889 | CLSLoss:8.3659 | top1:95.5250 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8768 | MainLoss:0.8768 | SPLoss:0.5138 | CLSLoss:8.3978 | top1:73.6730 | AUROC:0.8209\n",
      "Test | 39/20 | Loss:1.4671 | MainLoss:1.4671 | SPLoss:0.5138 | CLSLoss:8.3978 | top1:59.8077 | AUROC:0.6386\n",
      "\n",
      "Epoch: [251 | 1000] LR: 0.000346\n",
      "Train | 20/20 | Loss:0.1047 | MainLoss:0.1047 | Alpha:0.4759 | SPLoss:0.2676 | CLSLoss:8.3632 | top1:95.4250 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8652 | MainLoss:0.8652 | SPLoss:0.6475 | CLSLoss:8.3550 | top1:74.0596 | AUROC:0.8214\n",
      "Test | 39/20 | Loss:1.5046 | MainLoss:1.5046 | SPLoss:0.6475 | CLSLoss:8.3550 | top1:59.9359 | AUROC:0.6379\n",
      "\n",
      "Epoch: [252 | 1000] LR: 0.000035\n",
      "Train | 20/20 | Loss:0.1031 | MainLoss:0.1031 | Alpha:0.4752 | SPLoss:0.0028 | CLSLoss:8.3583 | top1:95.3750 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8679 | MainLoss:0.8679 | SPLoss:0.0101 | CLSLoss:8.3599 | top1:73.9744 | AUROC:0.8218\n",
      "Test | 39/20 | Loss:1.4928 | MainLoss:1.4928 | SPLoss:0.0101 | CLSLoss:8.3600 | top1:59.8590 | AUROC:0.6377\n",
      "\n",
      "Epoch: [253 | 1000] LR: 0.000035\n",
      "Train | 20/20 | Loss:0.0931 | MainLoss:0.0931 | Alpha:0.4780 | SPLoss:0.0037 | CLSLoss:8.3655 | top1:95.8750 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8764 | MainLoss:0.8764 | SPLoss:0.0093 | CLSLoss:8.3726 | top1:73.8925 | AUROC:0.8212\n",
      "Test | 39/20 | Loss:1.4929 | MainLoss:1.4929 | SPLoss:0.0093 | CLSLoss:8.3726 | top1:59.8974 | AUROC:0.6381\n",
      "\n",
      "Epoch: [254 | 1000] LR: 0.000034\n",
      "Train | 20/20 | Loss:0.0986 | MainLoss:0.0986 | Alpha:0.4763 | SPLoss:0.0027 | CLSLoss:8.3784 | top1:95.6250 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8831 | MainLoss:0.8831 | SPLoss:0.0060 | CLSLoss:8.3841 | top1:73.8172 | AUROC:0.8216\n",
      "Test | 39/20 | Loss:1.4951 | MainLoss:1.4951 | SPLoss:0.0060 | CLSLoss:8.3841 | top1:59.9231 | AUROC:0.6387\n",
      "\n",
      "Epoch: [255 | 1000] LR: 0.000034\n",
      "Train | 20/20 | Loss:0.0936 | MainLoss:0.0936 | Alpha:0.4783 | SPLoss:0.0028 | CLSLoss:8.3846 | top1:95.7500 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8808 | MainLoss:0.8808 | SPLoss:0.0071 | CLSLoss:8.3857 | top1:73.9089 | AUROC:0.8213\n",
      "Test | 39/20 | Loss:1.5047 | MainLoss:1.5047 | SPLoss:0.0071 | CLSLoss:8.3857 | top1:59.8333 | AUROC:0.6383\n",
      "\n",
      "Epoch: [256 | 1000] LR: 0.000034\n",
      "Train | 20/20 | Loss:0.0911 | MainLoss:0.0911 | Alpha:0.4783 | SPLoss:0.0019 | CLSLoss:8.3902 | top1:96.0250 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8866 | MainLoss:0.8866 | SPLoss:0.0055 | CLSLoss:8.3967 | top1:73.8532 | AUROC:0.8216\n",
      "Test | 39/20 | Loss:1.5081 | MainLoss:1.5081 | SPLoss:0.0055 | CLSLoss:8.3967 | top1:59.8333 | AUROC:0.6380\n",
      "\n",
      "Epoch: [257 | 1000] LR: 0.000034\n",
      "Train | 20/20 | Loss:0.1066 | MainLoss:0.1066 | Alpha:0.4751 | SPLoss:0.0019 | CLSLoss:8.4009 | top1:95.2000 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8855 | MainLoss:0.8855 | SPLoss:0.0063 | CLSLoss:8.4005 | top1:73.8860 | AUROC:0.8215\n",
      "Test | 39/20 | Loss:1.5118 | MainLoss:1.5118 | SPLoss:0.0063 | CLSLoss:8.4005 | top1:59.8205 | AUROC:0.6373\n",
      "\n",
      "Epoch: [258 | 1000] LR: 0.000034\n",
      "Train | 20/20 | Loss:0.1206 | MainLoss:0.1206 | Alpha:0.4714 | SPLoss:0.0079 | CLSLoss:8.3884 | top1:94.9500 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8712 | MainLoss:0.8712 | SPLoss:0.0201 | CLSLoss:8.3766 | top1:73.9515 | AUROC:0.8214\n",
      "Test | 39/20 | Loss:1.5026 | MainLoss:1.5026 | SPLoss:0.0201 | CLSLoss:8.3766 | top1:59.6667 | AUROC:0.6369\n",
      "\n",
      "Epoch: [259 | 1000] LR: 0.000034\n",
      "Train | 20/20 | Loss:0.0961 | MainLoss:0.0961 | Alpha:0.4778 | SPLoss:0.0034 | CLSLoss:8.3758 | top1:96.1500 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8713 | MainLoss:0.8713 | SPLoss:0.0073 | CLSLoss:8.3783 | top1:73.8565 | AUROC:0.8212\n",
      "Test | 39/20 | Loss:1.4930 | MainLoss:1.4930 | SPLoss:0.0073 | CLSLoss:8.3783 | top1:59.5513 | AUROC:0.6367\n",
      "\n",
      "Epoch: [260 | 1000] LR: 0.000034\n",
      "Train | 20/20 | Loss:0.1070 | MainLoss:0.1070 | Alpha:0.4758 | SPLoss:0.0029 | CLSLoss:8.3763 | top1:95.5750 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8703 | MainLoss:0.8703 | SPLoss:0.0077 | CLSLoss:8.3741 | top1:73.8270 | AUROC:0.8213\n",
      "Test | 39/20 | Loss:1.4795 | MainLoss:1.4795 | SPLoss:0.0077 | CLSLoss:8.3741 | top1:59.7436 | AUROC:0.6350\n",
      "\n",
      "Epoch: [261 | 1000] LR: 0.000034\n",
      "Train | 20/20 | Loss:0.1107 | MainLoss:0.1107 | Alpha:0.4733 | SPLoss:0.0023 | CLSLoss:8.3748 | top1:95.2500 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8699 | MainLoss:0.8699 | SPLoss:0.0065 | CLSLoss:8.3748 | top1:73.8532 | AUROC:0.8213\n",
      "Test | 39/20 | Loss:1.4787 | MainLoss:1.4787 | SPLoss:0.0065 | CLSLoss:8.3748 | top1:59.7436 | AUROC:0.6362\n",
      "\n",
      "Epoch: [262 | 1000] LR: 0.000034\n",
      "Train | 20/20 | Loss:0.0950 | MainLoss:0.0950 | Alpha:0.4773 | SPLoss:0.0023 | CLSLoss:8.3783 | top1:95.7500 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8700 | MainLoss:0.8700 | SPLoss:0.0070 | CLSLoss:8.3819 | top1:73.7975 | AUROC:0.8215\n",
      "Test | 39/20 | Loss:1.4888 | MainLoss:1.4888 | SPLoss:0.0070 | CLSLoss:8.3819 | top1:59.7436 | AUROC:0.6369\n",
      "\n",
      "Epoch: [263 | 1000] LR: 0.000034\n",
      "Train | 20/20 | Loss:0.0991 | MainLoss:0.0991 | Alpha:0.4767 | SPLoss:0.0026 | CLSLoss:8.3894 | top1:95.5500 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8764 | MainLoss:0.8764 | SPLoss:0.0077 | CLSLoss:8.3971 | top1:73.8073 | AUROC:0.8214\n",
      "Test | 39/20 | Loss:1.4949 | MainLoss:1.4949 | SPLoss:0.0077 | CLSLoss:8.3971 | top1:59.8077 | AUROC:0.6373\n",
      "\n",
      "Epoch: [264 | 1000] LR: 0.000034\n",
      "Train | 20/20 | Loss:0.1011 | MainLoss:0.1011 | Alpha:0.4763 | SPLoss:0.0034 | CLSLoss:8.3998 | top1:95.5250 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8746 | MainLoss:0.8746 | SPLoss:0.0098 | CLSLoss:8.3982 | top1:73.8565 | AUROC:0.8212\n",
      "Test | 39/20 | Loss:1.5077 | MainLoss:1.5077 | SPLoss:0.0098 | CLSLoss:8.3982 | top1:59.7436 | AUROC:0.6371\n",
      "\n",
      "Epoch: [265 | 1000] LR: 0.000034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 20/20 | Loss:0.0992 | MainLoss:0.0992 | Alpha:0.4773 | SPLoss:0.0014 | CLSLoss:8.4006 | top1:95.6750 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8755 | MainLoss:0.8755 | SPLoss:0.0033 | CLSLoss:8.4017 | top1:73.8630 | AUROC:0.8213\n",
      "Test | 39/20 | Loss:1.5094 | MainLoss:1.5094 | SPLoss:0.0033 | CLSLoss:8.4017 | top1:59.7308 | AUROC:0.6373\n",
      "\n",
      "Epoch: [266 | 1000] LR: 0.000034\n",
      "Train | 20/20 | Loss:0.1005 | MainLoss:0.1005 | Alpha:0.4766 | SPLoss:0.0037 | CLSLoss:8.4022 | top1:95.4000 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8752 | MainLoss:0.8752 | SPLoss:0.0079 | CLSLoss:8.4016 | top1:73.8106 | AUROC:0.8209\n",
      "Test | 39/20 | Loss:1.5031 | MainLoss:1.5031 | SPLoss:0.0079 | CLSLoss:8.4016 | top1:59.5897 | AUROC:0.6360\n",
      "\n",
      "Epoch: [267 | 1000] LR: 0.000034\n",
      "Train | 20/20 | Loss:0.0893 | MainLoss:0.0893 | Alpha:0.4786 | SPLoss:0.0022 | CLSLoss:8.4013 | top1:95.7750 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8771 | MainLoss:0.8771 | SPLoss:0.0071 | CLSLoss:8.4041 | top1:73.8598 | AUROC:0.8206\n",
      "Test | 39/20 | Loss:1.5119 | MainLoss:1.5119 | SPLoss:0.0071 | CLSLoss:8.4041 | top1:59.7179 | AUROC:0.6365\n",
      "\n",
      "Epoch: [268 | 1000] LR: 0.000034\n",
      "Train | 20/20 | Loss:0.1112 | MainLoss:0.1112 | Alpha:0.4729 | SPLoss:0.0024 | CLSLoss:8.4079 | top1:94.9250 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8785 | MainLoss:0.8785 | SPLoss:0.0064 | CLSLoss:8.4087 | top1:73.8696 | AUROC:0.8202\n",
      "Test | 39/20 | Loss:1.5156 | MainLoss:1.5156 | SPLoss:0.0064 | CLSLoss:8.4086 | top1:59.6538 | AUROC:0.6354\n",
      "\n",
      "Epoch: [269 | 1000] LR: 0.000034\n",
      "Train | 20/20 | Loss:0.1104 | MainLoss:0.1104 | Alpha:0.4744 | SPLoss:0.0034 | CLSLoss:8.4078 | top1:95.1500 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8784 | MainLoss:0.8784 | SPLoss:0.0100 | CLSLoss:8.4072 | top1:73.7451 | AUROC:0.8203\n",
      "Test | 39/20 | Loss:1.5021 | MainLoss:1.5021 | SPLoss:0.0100 | CLSLoss:8.4072 | top1:59.6026 | AUROC:0.6364\n",
      "\n",
      "Epoch: [270 | 1000] LR: 0.000034\n",
      "Train | 20/20 | Loss:0.0993 | MainLoss:0.0993 | Alpha:0.4767 | SPLoss:0.0020 | CLSLoss:8.4072 | top1:95.8750 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8801 | MainLoss:0.8801 | SPLoss:0.0053 | CLSLoss:8.4079 | top1:73.7516 | AUROC:0.8202\n",
      "Test | 39/20 | Loss:1.5024 | MainLoss:1.5024 | SPLoss:0.0053 | CLSLoss:8.4079 | top1:59.5641 | AUROC:0.6361\n",
      "\n",
      "Epoch: [271 | 1000] LR: 0.000034\n",
      "Train | 20/20 | Loss:0.1239 | MainLoss:0.1239 | Alpha:0.4704 | SPLoss:0.0035 | CLSLoss:8.4090 | top1:94.4500 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8773 | MainLoss:0.8773 | SPLoss:0.0086 | CLSLoss:8.4049 | top1:73.8204 | AUROC:0.8202\n",
      "Test | 39/20 | Loss:1.5036 | MainLoss:1.5036 | SPLoss:0.0086 | CLSLoss:8.4049 | top1:59.4744 | AUROC:0.6360\n",
      "\n",
      "Epoch: [272 | 1000] LR: 0.000034\n",
      "Train | 20/20 | Loss:0.0861 | MainLoss:0.0861 | Alpha:0.4801 | SPLoss:0.0020 | CLSLoss:8.4016 | top1:96.4750 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8775 | MainLoss:0.8775 | SPLoss:0.0050 | CLSLoss:8.4038 | top1:73.8467 | AUROC:0.8202\n",
      "Test | 39/20 | Loss:1.5061 | MainLoss:1.5061 | SPLoss:0.0050 | CLSLoss:8.4038 | top1:59.5897 | AUROC:0.6361\n",
      "\n",
      "Epoch: [273 | 1000] LR: 0.000034\n",
      "Train | 20/20 | Loss:0.0998 | MainLoss:0.0998 | Alpha:0.4766 | SPLoss:0.0021 | CLSLoss:8.4106 | top1:95.6500 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8831 | MainLoss:0.8831 | SPLoss:0.0057 | CLSLoss:8.4162 | top1:73.8139 | AUROC:0.8206\n",
      "Test | 39/20 | Loss:1.5136 | MainLoss:1.5136 | SPLoss:0.0057 | CLSLoss:8.4162 | top1:59.5641 | AUROC:0.6351\n",
      "\n",
      "Epoch: [274 | 1000] LR: 0.000034\n",
      "Train | 20/20 | Loss:0.0974 | MainLoss:0.0974 | Alpha:0.4768 | SPLoss:0.0026 | CLSLoss:8.4184 | top1:96.2500 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8848 | MainLoss:0.8848 | SPLoss:0.0073 | CLSLoss:8.4211 | top1:73.8270 | AUROC:0.8195\n",
      "Test | 39/20 | Loss:1.5236 | MainLoss:1.5236 | SPLoss:0.0073 | CLSLoss:8.4211 | top1:59.6282 | AUROC:0.6348\n",
      "\n",
      "Epoch: [275 | 1000] LR: 0.000034\n",
      "Train | 20/20 | Loss:0.0910 | MainLoss:0.0910 | Alpha:0.4787 | SPLoss:0.0035 | CLSLoss:8.4273 | top1:95.8250 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8893 | MainLoss:0.8893 | SPLoss:0.0110 | CLSLoss:8.4331 | top1:73.8598 | AUROC:0.8200\n",
      "Test | 39/20 | Loss:1.5414 | MainLoss:1.5414 | SPLoss:0.0110 | CLSLoss:8.4331 | top1:59.6410 | AUROC:0.6356\n",
      "\n",
      "Epoch: [276 | 1000] LR: 0.000034\n",
      "Train | 20/20 | Loss:0.1005 | MainLoss:0.1005 | Alpha:0.4769 | SPLoss:0.0020 | CLSLoss:8.4348 | top1:95.8750 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8916 | MainLoss:0.8916 | SPLoss:0.0057 | CLSLoss:8.4370 | top1:73.8204 | AUROC:0.8199\n",
      "Test | 39/20 | Loss:1.5441 | MainLoss:1.5441 | SPLoss:0.0057 | CLSLoss:8.4370 | top1:59.6538 | AUROC:0.6364\n",
      "\n",
      "Epoch: [277 | 1000] LR: 0.000033\n",
      "Train | 20/20 | Loss:0.1077 | MainLoss:0.1077 | Alpha:0.4741 | SPLoss:0.0026 | CLSLoss:8.4370 | top1:95.1250 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8932 | MainLoss:0.8932 | SPLoss:0.0092 | CLSLoss:8.4396 | top1:73.8270 | AUROC:0.8198\n",
      "Test | 39/20 | Loss:1.5354 | MainLoss:1.5354 | SPLoss:0.0092 | CLSLoss:8.4396 | top1:59.4872 | AUROC:0.6348\n",
      "\n",
      "Epoch: [278 | 1000] LR: 0.000033\n",
      "Train | 20/20 | Loss:0.0954 | MainLoss:0.0954 | Alpha:0.4780 | SPLoss:0.0019 | CLSLoss:8.4418 | top1:96.0000 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8928 | MainLoss:0.8928 | SPLoss:0.0049 | CLSLoss:8.4427 | top1:73.8762 | AUROC:0.8202\n",
      "Test | 39/20 | Loss:1.5391 | MainLoss:1.5391 | SPLoss:0.0049 | CLSLoss:8.4427 | top1:59.5128 | AUROC:0.6348\n",
      "\n",
      "Epoch: [279 | 1000] LR: 0.000033\n",
      "Train | 20/20 | Loss:0.0913 | MainLoss:0.0913 | Alpha:0.4789 | SPLoss:0.0021 | CLSLoss:8.4481 | top1:95.8500 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8981 | MainLoss:0.8981 | SPLoss:0.0056 | CLSLoss:8.4550 | top1:73.8467 | AUROC:0.8200\n",
      "Test | 39/20 | Loss:1.5455 | MainLoss:1.5455 | SPLoss:0.0056 | CLSLoss:8.4550 | top1:59.4872 | AUROC:0.6360\n",
      "\n",
      "Epoch: [280 | 1000] LR: 0.000033\n",
      "Train | 20/20 | Loss:0.0958 | MainLoss:0.0958 | Alpha:0.4779 | SPLoss:0.0025 | CLSLoss:8.4558 | top1:96.2000 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8985 | MainLoss:0.8985 | SPLoss:0.0071 | CLSLoss:8.4564 | top1:73.8729 | AUROC:0.8200\n",
      "Test | 39/20 | Loss:1.5398 | MainLoss:1.5398 | SPLoss:0.0071 | CLSLoss:8.4564 | top1:59.5256 | AUROC:0.6352\n",
      "\n",
      "Epoch: [281 | 1000] LR: 0.000033\n",
      "Train | 20/20 | Loss:0.0980 | MainLoss:0.0980 | Alpha:0.4769 | SPLoss:0.0025 | CLSLoss:8.4585 | top1:95.6000 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8994 | MainLoss:0.8994 | SPLoss:0.0059 | CLSLoss:8.4591 | top1:73.8696 | AUROC:0.8195\n",
      "Test | 39/20 | Loss:1.5314 | MainLoss:1.5314 | SPLoss:0.0059 | CLSLoss:8.4591 | top1:59.6026 | AUROC:0.6375\n",
      "\n",
      "Epoch: [282 | 1000] LR: 0.000033\n",
      "Train | 20/20 | Loss:0.0952 | MainLoss:0.0952 | Alpha:0.4777 | SPLoss:0.0016 | CLSLoss:8.4591 | top1:95.4000 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8992 | MainLoss:0.8992 | SPLoss:0.0040 | CLSLoss:8.4614 | top1:73.8991 | AUROC:0.8203\n",
      "Test | 39/20 | Loss:1.5339 | MainLoss:1.5339 | SPLoss:0.0040 | CLSLoss:8.4614 | top1:59.5513 | AUROC:0.6355\n",
      "\n",
      "Epoch: [283 | 1000] LR: 0.000033\n",
      "Train | 20/20 | Loss:0.0984 | MainLoss:0.0984 | Alpha:0.4768 | SPLoss:0.0015 | CLSLoss:8.4637 | top1:95.6750 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.9015 | MainLoss:0.9015 | SPLoss:0.0045 | CLSLoss:8.4684 | top1:73.8794 | AUROC:0.8197\n",
      "Test | 39/20 | Loss:1.5376 | MainLoss:1.5376 | SPLoss:0.0045 | CLSLoss:8.4684 | top1:59.5128 | AUROC:0.6368\n",
      "\n",
      "Epoch: [284 | 1000] LR: 0.000033\n",
      "Train | 20/20 | Loss:0.0958 | MainLoss:0.0958 | Alpha:0.4773 | SPLoss:0.0017 | CLSLoss:8.4706 | top1:95.7750 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.9016 | MainLoss:0.9016 | SPLoss:0.0058 | CLSLoss:8.4728 | top1:73.8860 | AUROC:0.8199\n",
      "Test | 39/20 | Loss:1.5430 | MainLoss:1.5430 | SPLoss:0.0058 | CLSLoss:8.4728 | top1:59.5513 | AUROC:0.6358\n",
      "\n",
      "Epoch: [285 | 1000] LR: 0.000033\n",
      "Train | 20/20 | Loss:0.1108 | MainLoss:0.1108 | Alpha:0.4745 | SPLoss:0.0025 | CLSLoss:8.4691 | top1:95.1750 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8956 | MainLoss:0.8956 | SPLoss:0.0063 | CLSLoss:8.4654 | top1:73.8893 | AUROC:0.8200\n",
      "Test | 39/20 | Loss:1.5380 | MainLoss:1.5380 | SPLoss:0.0063 | CLSLoss:8.4654 | top1:59.6282 | AUROC:0.6375\n",
      "\n",
      "Epoch: [286 | 1000] LR: 0.000033\n",
      "Train | 20/20 | Loss:0.1045 | MainLoss:0.1045 | Alpha:0.4742 | SPLoss:0.0015 | CLSLoss:8.4648 | top1:95.2000 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8930 | MainLoss:0.8930 | SPLoss:0.0043 | CLSLoss:8.4624 | top1:73.8630 | AUROC:0.8200\n",
      "Test | 39/20 | Loss:1.5353 | MainLoss:1.5353 | SPLoss:0.0043 | CLSLoss:8.4624 | top1:59.6667 | AUROC:0.6355\n",
      "\n",
      "Epoch: [287 | 1000] LR: 0.000033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 20/20 | Loss:0.0972 | MainLoss:0.0972 | Alpha:0.4772 | SPLoss:0.0040 | CLSLoss:8.4609 | top1:95.8250 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8895 | MainLoss:0.8895 | SPLoss:0.0110 | CLSLoss:8.4605 | top1:73.8499 | AUROC:0.8204\n",
      "Test | 39/20 | Loss:1.5428 | MainLoss:1.5428 | SPLoss:0.0110 | CLSLoss:8.4606 | top1:59.6410 | AUROC:0.6357\n",
      "\n",
      "Epoch: [288 | 1000] LR: 0.000033\n",
      "Train | 20/20 | Loss:0.0931 | MainLoss:0.0931 | Alpha:0.4773 | SPLoss:0.0051 | CLSLoss:8.4659 | top1:96.1000 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8957 | MainLoss:0.8957 | SPLoss:0.0175 | CLSLoss:8.4745 | top1:73.8401 | AUROC:0.8209\n",
      "Test | 39/20 | Loss:1.5329 | MainLoss:1.5329 | SPLoss:0.0175 | CLSLoss:8.4745 | top1:59.6410 | AUROC:0.6378\n",
      "\n",
      "Epoch: [289 | 1000] LR: 0.000033\n",
      "Train | 20/20 | Loss:0.0909 | MainLoss:0.0909 | Alpha:0.4780 | SPLoss:0.0034 | CLSLoss:8.4816 | top1:95.9500 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.9019 | MainLoss:0.9019 | SPLoss:0.0091 | CLSLoss:8.4888 | top1:73.8663 | AUROC:0.8203\n",
      "Test | 39/20 | Loss:1.5459 | MainLoss:1.5459 | SPLoss:0.0091 | CLSLoss:8.4888 | top1:59.6538 | AUROC:0.6357\n",
      "\n",
      "Epoch: [290 | 1000] LR: 0.000033\n",
      "Train | 20/20 | Loss:0.1044 | MainLoss:0.1044 | Alpha:0.4761 | SPLoss:0.0041 | CLSLoss:8.4899 | top1:95.5000 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.9007 | MainLoss:0.9007 | SPLoss:0.0126 | CLSLoss:8.4879 | top1:73.8991 | AUROC:0.8205\n",
      "Test | 39/20 | Loss:1.5606 | MainLoss:1.5606 | SPLoss:0.0126 | CLSLoss:8.4879 | top1:59.6923 | AUROC:0.6375\n",
      "\n",
      "Epoch: [291 | 1000] LR: 0.000033\n",
      "Train | 20/20 | Loss:0.1043 | MainLoss:0.1043 | Alpha:0.4753 | SPLoss:0.0023 | CLSLoss:8.4876 | top1:95.6250 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8975 | MainLoss:0.8975 | SPLoss:0.0065 | CLSLoss:8.4852 | top1:73.8794 | AUROC:0.8204\n",
      "Test | 39/20 | Loss:1.5639 | MainLoss:1.5639 | SPLoss:0.0065 | CLSLoss:8.4852 | top1:59.4744 | AUROC:0.6355\n",
      "\n",
      "Epoch: [292 | 1000] LR: 0.000033\n",
      "Train | 20/20 | Loss:0.0997 | MainLoss:0.0997 | Alpha:0.4759 | SPLoss:0.0022 | CLSLoss:8.4857 | top1:95.5500 | AUROC:0.0000\n",
      "Test | 153/20 | Loss:0.8949 | MainLoss:0.8949 | SPLoss:0.0064 | CLSLoss:8.4846 | top1:73.8860 | AUROC:0.8208\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(start_epoch, epochs):\n",
    "    state['lr'] = optimizer.state_dict()['param_groups'][0]['lr']\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "    print('\\nEpoch: [%d | %d] LR: %f' % (epoch + 1, epochs, state['lr']))\n",
    "    \n",
    "    train_loss, train_acc, train_auroc = train(train_loader, teacher_model, student_model, criterion, optimizer, epoch, use_cuda)\n",
    "    test_loss, test_acc, test_auroc = test(val_target_loader, student_model, criterion, epoch, use_cuda)\n",
    "    source_loss, source_acc, source_auroc = test(val_source_loader, student_model, criterion, epoch, use_cuda)\n",
    "\n",
    "\n",
    "    logger.append([state['lr'], train_loss, test_loss,  source_loss, train_acc, test_acc,source_acc, train_auroc, test_auroc, source_auroc])\n",
    "    is_best = test_acc > best_acc\n",
    "    best_acc = max(test_acc, best_acc)\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'state_dict' : student_model.state_dict(),\n",
    "        'acc': test_acc,\n",
    "        'best_acc': best_acc,\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    }, is_best, checkpoint=checkpoint)\n",
    "    scheduler_warmup.step()\n",
    "    \n",
    "    teacher_model.load_state_dict(student_model.state_dict())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
