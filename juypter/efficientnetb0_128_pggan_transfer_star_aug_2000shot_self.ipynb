{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import collections\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "\n",
    "from model_pytorch import EfficientNet\n",
    "from utils import Bar,Logger, AverageMeter, accuracy, mkdir_p, savefig\n",
    "from warmup_scheduler import GradualWarmupScheduler\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "import cv2\n",
    "\n",
    "from PIL import ImageFile, ImageOps\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU device 3: True\n"
     ]
    }
   ],
   "source": [
    "# GPU Device\n",
    "gpu_id = 3\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(\"GPU device %d:\" %(gpu_id), use_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = '/media/data2/dataset/GAN_ImageData/PGGAN_128/'\n",
    "target_dir = '/media/data2/dataset/GAN_ImageData/StarGAN_128/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained = './log/pggan/128/b0/aug/checkpoint.pth.tar'\n",
    "resume = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model_name = 'efficientnet-b0' # b0-b7 scale\n",
    "\n",
    "# Optimization\n",
    "num_classes = 2\n",
    "epochs = 1000\n",
    "start_epoch = 0\n",
    "train_batch = 250\n",
    "test_batch = 250\n",
    "lr = 0.1\n",
    "momentum = 0.1\n",
    "gamma = 0.1 # LR is multiplied by gamma on schedule\n",
    "\n",
    "# CheckPoint\n",
    "checkpoint = './log/pggan/128/b0/to_star/2000shot/self2' # dir\n",
    "if not os.path.isdir(checkpoint):\n",
    "    os.makedirs(checkpoint)\n",
    "num_workers = 8\n",
    "\n",
    "# Seed\n",
    "manual_seed = 7\n",
    "random.seed(manual_seed)\n",
    "torch.cuda.manual_seed_all(manual_seed)\n",
    "\n",
    "# Image\n",
    "size = (128, 128)\n",
    "\n",
    "# cutmix\n",
    "cm_prob = 0.5\n",
    "cm_beta = 1.0\n",
    "\n",
    "# augmentation\n",
    "blur_prob = 0.5\n",
    "blog_sig = 0.5\n",
    "jpg_prob = 0.5\n",
    "\n",
    "best_acc = 0\n",
    "\n",
    "# sp\n",
    "sp_alpha = 0.1\n",
    "sp_beta = 0.1\n",
    "fc_name = '_fc.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {}\n",
    "state['num_classes'] = num_classes\n",
    "state['epochs'] = epochs\n",
    "state['start_epoch'] = start_epoch\n",
    "state['train_batch'] = train_batch\n",
    "state['test_batch'] = test_batch\n",
    "state['lr'] = lr\n",
    "state['momentum'] = momentum\n",
    "state['gamma'] = gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_augment(img):\n",
    "    img = np.array(img)\n",
    "\n",
    "    if random.random() < blur_prob:\n",
    "        sig = np.random.uniform(0.0, 3.0)\n",
    "        gaussian_blur(img, sig)\n",
    "\n",
    "    if random.random() < jpg_prob:\n",
    "        qual = np.random.uniform(30.0, 100.0)\n",
    "        img = cv2_jpg(img, qual)\n",
    "\n",
    "    return Image.fromarray(img)\n",
    "\n",
    "\n",
    "def gaussian_blur(img, sigma):\n",
    "    gaussian_filter(img[:,:,0], output=img[:,:,0], sigma=sigma)\n",
    "    gaussian_filter(img[:,:,1], output=img[:,:,1], sigma=sigma)\n",
    "    gaussian_filter(img[:,:,2], output=img[:,:,2], sigma=sigma)\n",
    "\n",
    "\n",
    "def cv2_jpg(img, compress_val):\n",
    "    img_cv2 = img[:,:,::-1]\n",
    "    encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), compress_val]\n",
    "    result, encimg = cv2.imencode('.jpg', img_cv2, encode_param)\n",
    "    decimg = cv2.imdecode(encimg, 1)\n",
    "    return decimg[:,:,::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_bbox(size, lam):\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = np.int(W * cut_rat)\n",
    "    cut_h = np.int(H * cut_rat)\n",
    "\n",
    "    # uniform\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join(source_dir, 'star/2000_shot')\n",
    "val_target_dir = os.path.join(target_dir, 'validation')\n",
    "val_source_dir = os.path.join(source_dir, 'validation')\n",
    "\n",
    "train_aug = transforms.Compose([\n",
    "    transforms.Lambda(lambda img: data_augment(img)),\n",
    "    transforms.Resize(size),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "val_aug = transforms.Compose([\n",
    "    transforms.Resize(size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# pin_memory : cuda pin memeory use\n",
    "train_loader = DataLoader(datasets.ImageFolder(train_dir, transform=train_aug),\n",
    "                          batch_size=train_batch, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "val_target_loader = DataLoader(datasets.ImageFolder(val_target_dir, val_aug),\n",
    "                       batch_size=test_batch, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "val_source_loader = DataLoader(datasets.ImageFolder(val_source_dir, val_aug),\n",
    "                       batch_size=test_batch, shuffle=True, num_workers=num_workers, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> using pre-trained model './log/pggan/128/b0/aug/checkpoint.pth.tar'\n"
     ]
    }
   ],
   "source": [
    "teacher_model = EfficientNet.from_name(model_name, num_classes=num_classes,\n",
    "                              override_params={'dropout_rate':0.2, 'drop_connect_rate':0.2})\n",
    "student_model = EfficientNet.from_name(model_name, num_classes=num_classes,\n",
    "                              override_params={'dropout_rate':0.2, 'drop_connect_rate':0.2})\n",
    "\n",
    "# Pre-trained\n",
    "if pretrained:\n",
    "    print(\"=> using pre-trained model '{}'\".format(pretrained))\n",
    "    teacher_model.load_state_dict(torch.load(pretrained)['state_dict'])\n",
    "    student_model.load_state_dict(torch.load(pretrained)['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Total params: 4.01M\n"
     ]
    }
   ],
   "source": [
    "teacher_model.to('cuda')\n",
    "student_model.to('cuda')\n",
    "cudnn.benchmark = True\n",
    "print('    Total params: %.2fM' % (sum(p.numel() for p in teacher_model.parameters())/1000000.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = optim.SGD(student_model.parameters(), lr=lr, momentum=momentum)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, 200, gamma=0.1, last_epoch=-1)\n",
    "scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)\n",
    "scheduler_warmup = GradualWarmupScheduler(optimizer, multiplier=2, total_epoch=50, after_scheduler=scheduler_cosine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resume\n",
    "if resume:\n",
    "    print('==> Resuming from checkpoint..')\n",
    "    checkpoint = os.path.dirname(resume)\n",
    "    resume = torch.load(resume)\n",
    "    best_acc = resume['best_acc']\n",
    "    start_epoch = resume['epoch']\n",
    "    student_model.load_state_dict(resume['state_dict'])\n",
    "    optimizer.load_state_dict(resume['optimizer'])\n",
    "    logger = Logger(os.path.join(checkpoint, 'log.txt'), resume=True)\n",
    "else:\n",
    "    logger = Logger(os.path.join(checkpoint, 'log.txt'))\n",
    "    logger.set_names(['Learning Rate', 'Train Loss', 'Valid Loss', 'Source Loss', 'Train AUROC', 'Valid AUROC', 'Source AUROC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EfficientNet(\n",
       "  (_conv_stem): Conv2dStaticSamePadding(\n",
       "    3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
       "    (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "  )\n",
       "  (_gn0): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "  (_blocks): ModuleList(\n",
       "    (0): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        32, 32, kernel_size=(3, 3), stride=[1, 1], groups=32, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        32, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        8, 32, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 16, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (1): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 96, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        96, 96, kernel_size=(3, 3), stride=[2, 2], groups=96, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 96, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        96, 4, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        4, 96, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 24, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (2): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 144, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 144, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 24, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (3): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 144, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        144, 144, kernel_size=(5, 5), stride=[2, 2], groups=144, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 144, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 40, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (4): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 240, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        240, 240, kernel_size=(5, 5), stride=(1, 1), groups=240, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 240, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 40, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (5): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 240, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        240, 240, kernel_size=(3, 3), stride=[2, 2], groups=240, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 240, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 80, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (6): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 480, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 480, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 80, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (7): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 480, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 480, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 80, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (8): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 480, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        480, 480, kernel_size=(5, 5), stride=[1, 1], groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 480, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 112, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (9): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 672, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 672, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 112, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (10): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 672, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 672, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 112, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (11): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 672, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5), stride=[2, 2], groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 672, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 192, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (12): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 1152, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 1152, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 192, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (13): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 1152, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 1152, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 192, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (14): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 1152, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 1152, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 192, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (15): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 1152, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(3, 3), stride=[1, 1], groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 1152, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 320, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "  )\n",
       "  (_conv_head): Conv2dStaticSamePadding(\n",
       "    320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "    (static_padding): Identity()\n",
       "  )\n",
       "  (_gn1): GroupNorm(8, 1280, eps=1e-05, affine=True)\n",
       "  (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n",
       "  (_dropout): Dropout(p=0.2, inplace=False)\n",
       "  (_fc): Linear(in_features=1280, out_features=2, bias=True)\n",
       "  (_swish): MemoryEfficientSwish()\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for param in teacher_model.parameters():\n",
    "    param.requires_grad = False\n",
    "teacher_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_model_weights = {}\n",
    "for name, param in teacher_model.named_parameters():\n",
    "    teacher_model_weights[name] = param.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_cls(model):\n",
    "    l2_cls = torch.tensor(0.).cuda()\n",
    "    for name, param in model.named_parameters():\n",
    "        if name.startswith(fc_name):\n",
    "            l2_cls += 0.5 * torch.norm(param) ** 2\n",
    "    return l2_cls\n",
    "\n",
    "def reg_l2sp(model):\n",
    "    sp_loss = torch.tensor(0.).cuda()\n",
    "    for name, param in model.named_parameters():\n",
    "        if not name.startswith(fc_name):\n",
    "            sp_loss += 0.5 * torch.norm(param - teacher_model_weights[name]) ** 2\n",
    "    return sp_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, teacher_model, student_model, criterion, optimizer, epoch, use_cuda):\n",
    "    teacher_model.eval()\n",
    "    student_model.train()\n",
    "    \n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    arc = AverageMeter()\n",
    "    end = time.time()\n",
    "    cls_losses = AverageMeter()\n",
    "    sp_losses = AverageMeter()\n",
    "    main_losses = AverageMeter()\n",
    "    alpha = AverageMeter()\n",
    "    \n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        batch_size = inputs.size(0)\n",
    "        if batch_size < train_batch:\n",
    "            continue\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            \n",
    "        r = np.random.rand(1)\n",
    "        if cm_beta > 0 and r < cm_prob:\n",
    "            \n",
    "            rand_index = torch.randperm(inputs.size()[0]).cuda()\n",
    "            tt= targets[rand_index]\n",
    "            boolean = targets==tt\n",
    "            rand_index = rand_index[boolean]\n",
    "            lam = np.random.beta(cm_beta, cm_beta)\n",
    "            bbx1, bby1, bbx2, bby2 = rand_bbox(inputs.size(), lam)\n",
    "            inputs[boolean, :, bbx1:bbx2, bby1:bby2] = inputs[rand_index, :, bbx1:bbx2, bby1:bby2]\n",
    "\n",
    "        # compute output\n",
    "        with torch.no_grad():\n",
    "            teacher_outputs = teacher_model(inputs)\n",
    "            teacher_loss = criterion(teacher_outputs, targets)\n",
    "            sp_alpha = 0\n",
    "            sigmoid = nn.Sigmoid()\n",
    "            sp_alpha += sigmoid(-teacher_loss)\n",
    "        \n",
    "        outputs = student_model(inputs)\n",
    "        loss_main = criterion(outputs, targets)\n",
    "        loss_cls = 0\n",
    "        loss_sp = 0\n",
    "        loss_cls = reg_cls(student_model)\n",
    "        loss_sp = reg_l2sp(student_model)\n",
    "        loss =  loss_main + 0.1*loss_sp + 0.1*loss_cls\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        losses.update(loss.data.tolist(), inputs.size(0))\n",
    "        cls_losses.update(loss_cls, inputs.size(0))\n",
    "        sp_losses.update(loss_sp, inputs.size(0))\n",
    "        main_losses.update(loss_main.tolist(), inputs.size(0))\n",
    "        alpha.update(sp_alpha, inputs.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        \n",
    "    print('Train | {batch}/{size} | Loss:{loss:.4f} | MainLoss:{main:.4f} | Alpha:{alp:.4f} | SPLoss:{sp:.4f} | CLSLoss:{cls:.4f} | AUROC:{ac:.4f}'.format(\n",
    "                     batch=batch_idx+1, size=len(train_loader), loss=losses.avg, main=main_losses.avg, alp=alpha.avg, sp=sp_losses.avg, cls=cls_losses.avg, ac=arc.avg))\n",
    "    return (losses.avg, arc.avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(val_loader, model, criterion, epoch, use_cuda):\n",
    "    global best_acc\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    arc = AverageMeter()\n",
    "    cls_losses = AverageMeter()\n",
    "    sp_losses = AverageMeter()\n",
    "    main_losses = AverageMeter()\n",
    "\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(val_loader):\n",
    "            # measure data loading time\n",
    "            data_time.update(time.time() - end)\n",
    "\n",
    "            if use_cuda:\n",
    "                inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "            # compute output\n",
    "            outputs = model(inputs)\n",
    "            loss_main = criterion(outputs, targets)\n",
    "            loss_cls = 0\n",
    "            loss_sp = 0\n",
    "            loss_cls = reg_cls(model)\n",
    "            loss_sp = reg_l2sp(model)\n",
    "            loss = loss_main + 0*loss_sp + 0*loss_cls\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            auroc = roc_auc_score(targets.cpu().detach().numpy(), outputs.cpu().detach().numpy()[:,1])\n",
    "            losses.update(loss.data.tolist(), inputs.size(0))\n",
    "            arc.update(auroc, inputs.size(0))\n",
    "            cls_losses.update(loss_cls, inputs.size(0))\n",
    "            sp_losses.update(loss_sp, inputs.size(0))\n",
    "            main_losses.update(loss_main.tolist(), inputs.size(0))\n",
    "\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "    print('Test | {batch}/{size} | Loss:{loss:.4f} | MainLoss:{main:.4f} | SPLoss:{sp:.4f} | CLSLoss:{cls:.4f} | AUROC:{ac:.4f}'.format(\n",
    "                     batch=batch_idx+1, size=len(train_loader), loss=losses.avg, main=main_losses.avg, sp=sp_losses.avg, cls=cls_losses.avg, ac=arc.avg))\n",
    "    return (losses.avg, arc.avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, checkpoint='checkpoint', filename='checkpoint.pth.tar'):\n",
    "    filepath = os.path.join(checkpoint, filename)\n",
    "    torch.save(state, filepath)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filepath, os.path.join(checkpoint, 'model_best.pth.tar'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [1 | 1000] LR: 0.100000\n",
      "Train | 16/16 | Loss:1.1393 | MainLoss:0.8272 | Alpha:0.0586 | SPLoss:1.7272 | CLSLoss:1.3942 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.6933 | MainLoss:0.6933 | SPLoss:1.5800 | CLSLoss:1.1234 | AUROC:0.4871\n",
      "Test | 128/16 | Loss:0.6823 | MainLoss:0.6823 | SPLoss:1.5800 | CLSLoss:1.1234 | AUROC:0.9989\n",
      "\n",
      "Epoch: [2 | 1000] LR: 0.102000\n",
      "Train | 16/16 | Loss:0.9219 | MainLoss:0.6931 | Alpha:0.0539 | SPLoss:1.3364 | CLSLoss:0.9515 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.6933 | MainLoss:0.6933 | SPLoss:1.0932 | CLSLoss:0.7797 | AUROC:0.4970\n",
      "Test | 128/16 | Loss:0.6645 | MainLoss:0.6645 | SPLoss:1.0932 | CLSLoss:0.7797 | AUROC:0.9998\n",
      "\n",
      "Epoch: [3 | 1000] LR: 0.104000\n",
      "Train | 16/16 | Loss:0.8489 | MainLoss:0.6912 | Alpha:0.0563 | SPLoss:0.9175 | CLSLoss:0.6598 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.6931 | MainLoss:0.6931 | SPLoss:0.7431 | CLSLoss:0.5398 | AUROC:0.5100\n",
      "Test | 128/16 | Loss:0.6225 | MainLoss:0.6225 | SPLoss:0.7431 | CLSLoss:0.5398 | AUROC:1.0000\n",
      "\n",
      "Epoch: [4 | 1000] LR: 0.106000\n",
      "Train | 16/16 | Loss:0.7954 | MainLoss:0.6879 | Alpha:0.0559 | SPLoss:0.6185 | CLSLoss:0.4575 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.6946 | MainLoss:0.6946 | SPLoss:0.4855 | CLSLoss:0.3764 | AUROC:0.5305\n",
      "Test | 128/16 | Loss:0.5115 | MainLoss:0.5115 | SPLoss:0.4855 | CLSLoss:0.3764 | AUROC:1.0000\n",
      "\n",
      "Epoch: [5 | 1000] LR: 0.108000\n",
      "Train | 16/16 | Loss:0.7531 | MainLoss:0.6812 | Alpha:0.0551 | SPLoss:0.3973 | CLSLoss:0.3208 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.6872 | MainLoss:0.6872 | SPLoss:0.3062 | CLSLoss:0.2664 | AUROC:0.5701\n",
      "Test | 128/16 | Loss:0.3384 | MainLoss:0.3384 | SPLoss:0.3062 | CLSLoss:0.2664 | AUROC:1.0000\n",
      "\n",
      "Epoch: [6 | 1000] LR: 0.110000\n",
      "Train | 16/16 | Loss:0.7095 | MainLoss:0.6622 | Alpha:0.0552 | SPLoss:0.2425 | CLSLoss:0.2313 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.6629 | MainLoss:0.6629 | SPLoss:0.1880 | CLSLoss:0.1986 | AUROC:0.6411\n",
      "Test | 128/16 | Loss:0.1389 | MainLoss:0.1389 | SPLoss:0.1880 | CLSLoss:0.1986 | AUROC:1.0000\n",
      "\n",
      "Epoch: [7 | 1000] LR: 0.112000\n",
      "Train | 16/16 | Loss:0.6619 | MainLoss:0.6260 | Alpha:0.0570 | SPLoss:0.1806 | CLSLoss:0.1777 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.6088 | MainLoss:0.6088 | SPLoss:0.1943 | CLSLoss:0.1491 | AUROC:0.7309\n",
      "Test | 128/16 | Loss:0.0968 | MainLoss:0.0968 | SPLoss:0.1943 | CLSLoss:0.1491 | AUROC:1.0000\n",
      "\n",
      "Epoch: [8 | 1000] LR: 0.114000\n",
      "Train | 16/16 | Loss:0.6401 | MainLoss:0.5901 | Alpha:0.0557 | SPLoss:0.3652 | CLSLoss:0.1352 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.5654 | MainLoss:0.5654 | SPLoss:0.4305 | CLSLoss:0.1128 | AUROC:0.7864\n",
      "Test | 128/16 | Loss:0.1148 | MainLoss:0.1148 | SPLoss:0.4305 | CLSLoss:0.1128 | AUROC:1.0000\n",
      "\n",
      "Epoch: [9 | 1000] LR: 0.116000\n",
      "Train | 16/16 | Loss:0.6210 | MainLoss:0.5645 | Alpha:0.0522 | SPLoss:0.4595 | CLSLoss:0.1050 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.5530 | MainLoss:0.5530 | SPLoss:0.4904 | CLSLoss:0.1044 | AUROC:0.8199\n",
      "Test | 128/16 | Loss:0.0952 | MainLoss:0.0952 | SPLoss:0.4904 | CLSLoss:0.1044 | AUROC:0.9999\n",
      "\n",
      "Epoch: [10 | 1000] LR: 0.118000\n",
      "Train | 16/16 | Loss:0.6570 | MainLoss:0.5975 | Alpha:0.0553 | SPLoss:0.5206 | CLSLoss:0.0743 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.5344 | MainLoss:0.5344 | SPLoss:0.4972 | CLSLoss:0.0849 | AUROC:0.8142\n",
      "Test | 128/16 | Loss:0.1251 | MainLoss:0.1251 | SPLoss:0.4972 | CLSLoss:0.0849 | AUROC:1.0000\n",
      "\n",
      "Epoch: [11 | 1000] LR: 0.120000\n",
      "Train | 16/16 | Loss:0.6014 | MainLoss:0.5397 | Alpha:0.0575 | SPLoss:0.5299 | CLSLoss:0.0863 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.6286 | MainLoss:0.6286 | SPLoss:0.5764 | CLSLoss:0.0899 | AUROC:0.8334\n",
      "Test | 128/16 | Loss:0.1066 | MainLoss:0.1066 | SPLoss:0.5764 | CLSLoss:0.0899 | AUROC:0.9999\n",
      "\n",
      "Epoch: [12 | 1000] LR: 0.122000\n",
      "Train | 16/16 | Loss:0.6065 | MainLoss:0.5381 | Alpha:0.0590 | SPLoss:0.5989 | CLSLoss:0.0850 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.5040 | MainLoss:0.5040 | SPLoss:0.6426 | CLSLoss:0.0963 | AUROC:0.8514\n",
      "Test | 128/16 | Loss:0.1271 | MainLoss:0.1271 | SPLoss:0.6426 | CLSLoss:0.0963 | AUROC:0.9999\n",
      "\n",
      "Epoch: [13 | 1000] LR: 0.124000\n",
      "Train | 16/16 | Loss:0.6126 | MainLoss:0.5356 | Alpha:0.0546 | SPLoss:0.6834 | CLSLoss:0.0867 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.5505 | MainLoss:0.5505 | SPLoss:0.7317 | CLSLoss:0.0611 | AUROC:0.8438\n",
      "Test | 128/16 | Loss:0.1962 | MainLoss:0.1962 | SPLoss:0.7317 | CLSLoss:0.0611 | AUROC:0.9999\n",
      "\n",
      "Epoch: [14 | 1000] LR: 0.126000\n",
      "Train | 16/16 | Loss:0.6026 | MainLoss:0.5172 | Alpha:0.0561 | SPLoss:0.7690 | CLSLoss:0.0845 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.4751 | MainLoss:0.4751 | SPLoss:1.4114 | CLSLoss:0.0935 | AUROC:0.8574\n",
      "Test | 128/16 | Loss:0.1109 | MainLoss:0.1109 | SPLoss:1.4114 | CLSLoss:0.0935 | AUROC:0.9998\n",
      "\n",
      "Epoch: [15 | 1000] LR: 0.128000\n",
      "Train | 16/16 | Loss:0.6549 | MainLoss:0.5122 | Alpha:0.0569 | SPLoss:1.3339 | CLSLoss:0.0931 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.5323 | MainLoss:0.5323 | SPLoss:1.2472 | CLSLoss:0.0625 | AUROC:0.8549\n",
      "Test | 128/16 | Loss:0.2057 | MainLoss:0.2057 | SPLoss:1.2472 | CLSLoss:0.0625 | AUROC:0.9998\n",
      "\n",
      "Epoch: [16 | 1000] LR: 0.130000\n",
      "Train | 16/16 | Loss:0.6428 | MainLoss:0.5184 | Alpha:0.0521 | SPLoss:1.1600 | CLSLoss:0.0844 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.6001 | MainLoss:0.6001 | SPLoss:1.0805 | CLSLoss:0.0972 | AUROC:0.8519\n",
      "Test | 128/16 | Loss:0.1657 | MainLoss:0.1657 | SPLoss:1.0805 | CLSLoss:0.0972 | AUROC:0.9997\n",
      "\n",
      "Epoch: [17 | 1000] LR: 0.132000\n",
      "Train | 16/16 | Loss:0.6862 | MainLoss:0.5717 | Alpha:0.0570 | SPLoss:1.0736 | CLSLoss:0.0709 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.4929 | MainLoss:0.4929 | SPLoss:0.9774 | CLSLoss:0.0866 | AUROC:0.8497\n",
      "Test | 128/16 | Loss:0.1419 | MainLoss:0.1419 | SPLoss:0.9774 | CLSLoss:0.0866 | AUROC:0.9998\n",
      "\n",
      "Epoch: [18 | 1000] LR: 0.134000\n",
      "Train | 16/16 | Loss:0.6199 | MainLoss:0.5148 | Alpha:0.0547 | SPLoss:0.9605 | CLSLoss:0.0898 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.5524 | MainLoss:0.5524 | SPLoss:0.9169 | CLSLoss:0.0813 | AUROC:0.8540\n",
      "Test | 128/16 | Loss:0.1630 | MainLoss:0.1630 | SPLoss:0.9169 | CLSLoss:0.0813 | AUROC:0.9999\n",
      "\n",
      "Epoch: [19 | 1000] LR: 0.136000\n",
      "Train | 16/16 | Loss:0.6275 | MainLoss:0.5235 | Alpha:0.0577 | SPLoss:0.9537 | CLSLoss:0.0855 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.4891 | MainLoss:0.4891 | SPLoss:0.9267 | CLSLoss:0.0851 | AUROC:0.8583\n",
      "Test | 128/16 | Loss:0.1354 | MainLoss:0.1354 | SPLoss:0.9267 | CLSLoss:0.0851 | AUROC:0.9998\n",
      "\n",
      "Epoch: [20 | 1000] LR: 0.138000\n",
      "Train | 16/16 | Loss:0.6153 | MainLoss:0.5125 | Alpha:0.0559 | SPLoss:0.9390 | CLSLoss:0.0887 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.4647 | MainLoss:0.4647 | SPLoss:0.9240 | CLSLoss:0.0993 | AUROC:0.8631\n",
      "Test | 128/16 | Loss:0.1020 | MainLoss:0.1020 | SPLoss:0.9240 | CLSLoss:0.0993 | AUROC:0.9998\n",
      "\n",
      "Epoch: [21 | 1000] LR: 0.140000\n",
      "Train | 16/16 | Loss:1.3669 | MainLoss:0.5354 | Alpha:0.0541 | SPLoss:8.2312 | CLSLoss:0.0844 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.5698 | MainLoss:0.5698 | SPLoss:74.5051 | CLSLoss:0.0936 | AUROC:0.8415\n",
      "Test | 128/16 | Loss:0.2082 | MainLoss:0.2082 | SPLoss:74.5051 | CLSLoss:0.0936 | AUROC:0.9985\n",
      "\n",
      "Epoch: [22 | 1000] LR: 0.142000\n",
      "Train | 16/16 | Loss:8.4053 | MainLoss:0.5361 | Alpha:0.0562 | SPLoss:78.6141 | CLSLoss:0.0778 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.4871 | MainLoss:0.4871 | SPLoss:61.0954 | CLSLoss:0.0905 | AUROC:0.8515\n",
      "Test | 128/16 | Loss:0.1448 | MainLoss:0.1448 | SPLoss:61.0954 | CLSLoss:0.0905 | AUROC:0.9989\n",
      "\n",
      "Epoch: [23 | 1000] LR: 0.144000\n",
      "Train | 16/16 | Loss:5.4310 | MainLoss:0.5505 | Alpha:0.0562 | SPLoss:48.7241 | CLSLoss:0.0809 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.5923 | MainLoss:0.5923 | SPLoss:36.8328 | CLSLoss:0.0799 | AUROC:0.8501\n",
      "Test | 128/16 | Loss:0.1807 | MainLoss:0.1807 | SPLoss:36.8328 | CLSLoss:0.0799 | AUROC:0.9994\n",
      "\n",
      "Epoch: [24 | 1000] LR: 0.146000\n",
      "Train | 16/16 | Loss:3.4660 | MainLoss:0.5262 | Alpha:0.0568 | SPLoss:29.3108 | CLSLoss:0.0874 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.4688 | MainLoss:0.4688 | SPLoss:22.1365 | CLSLoss:0.0978 | AUROC:0.8634\n",
      "Test | 128/16 | Loss:0.1346 | MainLoss:0.1346 | SPLoss:22.1365 | CLSLoss:0.0978 | AUROC:0.9993\n",
      "\n",
      "Epoch: [25 | 1000] LR: 0.148000\n",
      "Train | 16/16 | Loss:29.9362 | MainLoss:0.5365 | Alpha:0.0570 | SPLoss:293.9084 | CLSLoss:0.0885 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.6752 | MainLoss:0.6752 | SPLoss:2405.5356 | CLSLoss:0.0863 | AUROC:0.7716\n",
      "Test | 128/16 | Loss:0.1785 | MainLoss:0.1785 | SPLoss:2405.5356 | CLSLoss:0.0863 | AUROC:0.9963\n",
      "\n",
      "Epoch: [26 | 1000] LR: 0.150000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 16/16 | Loss:190.6612 | MainLoss:0.5822 | Alpha:0.0559 | SPLoss:1900.7179 | CLSLoss:0.0722 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.5504 | MainLoss:0.5504 | SPLoss:1411.3712 | CLSLoss:0.0627 | AUROC:0.8228\n",
      "Test | 128/16 | Loss:0.2438 | MainLoss:0.2438 | SPLoss:1411.3713 | CLSLoss:0.0627 | AUROC:0.9978\n",
      "\n",
      "Epoch: [27 | 1000] LR: 0.152000\n",
      "Train | 16/16 | Loss:114.0621 | MainLoss:0.5731 | Alpha:0.0585 | SPLoss:1134.8213 | CLSLoss:0.0690 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.5616 | MainLoss:0.5616 | SPLoss:849.2826 | CLSLoss:0.0847 | AUROC:0.8268\n",
      "Test | 128/16 | Loss:0.2685 | MainLoss:0.2685 | SPLoss:849.2824 | CLSLoss:0.0847 | AUROC:0.9975\n",
      "\n",
      "Epoch: [28 | 1000] LR: 0.154000\n",
      "Train | 16/16 | Loss:66.9235 | MainLoss:0.5344 | Alpha:0.0549 | SPLoss:663.8080 | CLSLoss:0.0822 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.5444 | MainLoss:0.5444 | SPLoss:488.7552 | CLSLoss:0.0938 | AUROC:0.8398\n",
      "Test | 128/16 | Loss:0.2979 | MainLoss:0.2979 | SPLoss:488.7552 | CLSLoss:0.0938 | AUROC:0.9958\n",
      "\n",
      "Epoch: [29 | 1000] LR: 0.156000\n",
      "Train | 16/16 | Loss:38.6658 | MainLoss:0.5605 | Alpha:0.0521 | SPLoss:380.9733 | CLSLoss:0.0797 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.5680 | MainLoss:0.5680 | SPLoss:279.4345 | CLSLoss:0.0462 | AUROC:0.8378\n",
      "Test | 128/16 | Loss:0.3270 | MainLoss:0.3270 | SPLoss:279.4346 | CLSLoss:0.0462 | AUROC:0.9972\n",
      "\n",
      "Epoch: [30 | 1000] LR: 0.158000\n",
      "Train | 16/16 | Loss:22.2504 | MainLoss:0.5231 | Alpha:0.0562 | SPLoss:217.1936 | CLSLoss:0.0795 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.4790 | MainLoss:0.4790 | SPLoss:158.7269 | CLSLoss:0.1024 | AUROC:0.8538\n",
      "Test | 128/16 | Loss:0.2015 | MainLoss:0.2015 | SPLoss:158.7268 | CLSLoss:0.1024 | AUROC:0.9976\n",
      "\n",
      "Epoch: [31 | 1000] LR: 0.160000\n",
      "Train | 16/16 | Loss:17.9758 | MainLoss:0.5751 | Alpha:0.0574 | SPLoss:173.9290 | CLSLoss:0.0777 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.6687 | MainLoss:0.6687 | SPLoss:148.5631 | CLSLoss:0.0771 | AUROC:0.8052\n",
      "Test | 128/16 | Loss:0.4194 | MainLoss:0.4194 | SPLoss:148.5631 | CLSLoss:0.0771 | AUROC:0.9989\n",
      "\n",
      "Epoch: [32 | 1000] LR: 0.162000\n",
      "Train | 16/16 | Loss:12.0567 | MainLoss:0.5642 | Alpha:0.0555 | SPLoss:114.8448 | CLSLoss:0.0795 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.5197 | MainLoss:0.5197 | SPLoss:83.3726 | CLSLoss:0.0673 | AUROC:0.8418\n",
      "Test | 128/16 | Loss:0.2307 | MainLoss:0.2307 | SPLoss:83.3726 | CLSLoss:0.0673 | AUROC:0.9977\n",
      "\n",
      "Epoch: [33 | 1000] LR: 0.164000\n",
      "Train | 16/16 | Loss:6.9746 | MainLoss:0.5290 | Alpha:0.0570 | SPLoss:64.3695 | CLSLoss:0.0861 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.7950 | MainLoss:0.7950 | SPLoss:46.7582 | CLSLoss:0.0635 | AUROC:0.7883\n",
      "Test | 128/16 | Loss:0.5329 | MainLoss:0.5329 | SPLoss:46.7581 | CLSLoss:0.0635 | AUROC:0.9967\n",
      "\n",
      "Epoch: [34 | 1000] LR: 0.166000\n",
      "Train | 16/16 | Loss:4.1713 | MainLoss:0.5613 | Alpha:0.0541 | SPLoss:36.0283 | CLSLoss:0.0716 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.4941 | MainLoss:0.4941 | SPLoss:26.0568 | CLSLoss:0.0935 | AUROC:0.8430\n",
      "Test | 128/16 | Loss:0.1853 | MainLoss:0.1853 | SPLoss:26.0568 | CLSLoss:0.0935 | AUROC:0.9983\n",
      "\n",
      "Epoch: [35 | 1000] LR: 0.168000\n",
      "Train | 16/16 | Loss:2.5930 | MainLoss:0.5684 | Alpha:0.0534 | SPLoss:20.1701 | CLSLoss:0.0756 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.5396 | MainLoss:0.5396 | SPLoss:14.6122 | CLSLoss:0.0933 | AUROC:0.8408\n",
      "Test | 128/16 | Loss:0.1669 | MainLoss:0.1669 | SPLoss:14.6122 | CLSLoss:0.0933 | AUROC:0.9987\n",
      "\n",
      "Epoch: [36 | 1000] LR: 0.170000\n",
      "Train | 16/16 | Loss:2.0340 | MainLoss:0.5696 | Alpha:0.0564 | SPLoss:14.5670 | CLSLoss:0.0772 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.5332 | MainLoss:0.5332 | SPLoss:18.1944 | CLSLoss:0.0900 | AUROC:0.8167\n",
      "Test | 128/16 | Loss:0.2130 | MainLoss:0.2130 | SPLoss:18.1944 | CLSLoss:0.0900 | AUROC:0.9988\n",
      "\n",
      "Epoch: [37 | 1000] LR: 0.172000\n",
      "Train | 16/16 | Loss:2.6982 | MainLoss:0.5697 | Alpha:0.0581 | SPLoss:21.2030 | CLSLoss:0.0828 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.6155 | MainLoss:0.6155 | SPLoss:19.0076 | CLSLoss:0.0278 | AUROC:0.8227\n",
      "Test | 128/16 | Loss:0.4081 | MainLoss:0.4081 | SPLoss:19.0076 | CLSLoss:0.0278 | AUROC:0.9978\n",
      "\n",
      "Epoch: [38 | 1000] LR: 0.174000\n",
      "Train | 16/16 | Loss:4.3156 | MainLoss:0.5804 | Alpha:0.0600 | SPLoss:37.2889 | CLSLoss:0.0632 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.6301 | MainLoss:0.6301 | SPLoss:44.4925 | CLSLoss:0.0729 | AUROC:0.8047\n",
      "Test | 128/16 | Loss:0.2847 | MainLoss:0.2847 | SPLoss:44.4925 | CLSLoss:0.0729 | AUROC:0.9998\n",
      "\n",
      "Epoch: [39 | 1000] LR: 0.176000\n",
      "Train | 16/16 | Loss:3.9269 | MainLoss:0.5373 | Alpha:0.0552 | SPLoss:33.8105 | CLSLoss:0.0856 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.4857 | MainLoss:0.4857 | SPLoss:23.9873 | CLSLoss:0.0988 | AUROC:0.8504\n",
      "Test | 128/16 | Loss:0.1286 | MainLoss:0.1286 | SPLoss:23.9873 | CLSLoss:0.0988 | AUROC:0.9996\n",
      "\n",
      "Epoch: [40 | 1000] LR: 0.178000\n",
      "Train | 16/16 | Loss:2.4030 | MainLoss:0.5664 | Alpha:0.0548 | SPLoss:18.2878 | CLSLoss:0.0789 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.8006 | MainLoss:0.8006 | SPLoss:12.9847 | CLSLoss:0.1041 | AUROC:0.8191\n",
      "Test | 128/16 | Loss:0.2359 | MainLoss:0.2359 | SPLoss:12.9847 | CLSLoss:0.1041 | AUROC:0.9997\n",
      "\n",
      "Epoch: [41 | 1000] LR: 0.180000\n",
      "Train | 16/16 | Loss:1.8372 | MainLoss:0.6008 | Alpha:0.0565 | SPLoss:12.2954 | CLSLoss:0.0685 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.6009 | MainLoss:0.6009 | SPLoss:17.4890 | CLSLoss:0.0496 | AUROC:0.7765\n",
      "Test | 128/16 | Loss:0.2958 | MainLoss:0.2958 | SPLoss:17.4890 | CLSLoss:0.0496 | AUROC:0.9989\n",
      "\n",
      "Epoch: [42 | 1000] LR: 0.182000\n",
      "Train | 16/16 | Loss:1.9266 | MainLoss:0.5831 | Alpha:0.0556 | SPLoss:13.3643 | CLSLoss:0.0708 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.6152 | MainLoss:0.6152 | SPLoss:9.8657 | CLSLoss:0.0235 | AUROC:0.8239\n",
      "Test | 128/16 | Loss:0.4530 | MainLoss:0.4530 | SPLoss:9.8657 | CLSLoss:0.0235 | AUROC:0.9974\n",
      "\n",
      "Epoch: [43 | 1000] LR: 0.184000\n",
      "Train | 16/16 | Loss:1.3167 | MainLoss:0.5547 | Alpha:0.0571 | SPLoss:7.5456 | CLSLoss:0.0744 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.5319 | MainLoss:0.5319 | SPLoss:5.5614 | CLSLoss:0.0915 | AUROC:0.8430\n",
      "Test | 128/16 | Loss:0.2037 | MainLoss:0.2037 | SPLoss:5.5614 | CLSLoss:0.0915 | AUROC:0.9989\n",
      "\n",
      "Epoch: [44 | 1000] LR: 0.186000\n",
      "Train | 16/16 | Loss:1.0355 | MainLoss:0.5879 | Alpha:0.0539 | SPLoss:4.4032 | CLSLoss:0.0726 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.6191 | MainLoss:0.6191 | SPLoss:3.3183 | CLSLoss:0.0340 | AUROC:0.8254\n",
      "Test | 128/16 | Loss:0.3870 | MainLoss:0.3870 | SPLoss:3.3183 | CLSLoss:0.0340 | AUROC:0.9994\n",
      "\n",
      "Epoch: [45 | 1000] LR: 0.188000\n",
      "Train | 16/16 | Loss:0.8226 | MainLoss:0.5481 | Alpha:0.0560 | SPLoss:2.6614 | CLSLoss:0.0836 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.7953 | MainLoss:0.7953 | SPLoss:2.1394 | CLSLoss:0.1069 | AUROC:0.8140\n",
      "Test | 128/16 | Loss:0.1356 | MainLoss:0.1356 | SPLoss:2.1394 | CLSLoss:0.1069 | AUROC:0.9991\n",
      "\n",
      "Epoch: [46 | 1000] LR: 0.190000\n",
      "Train | 16/16 | Loss:0.9136 | MainLoss:0.5722 | Alpha:0.0595 | SPLoss:3.3327 | CLSLoss:0.0808 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.5266 | MainLoss:0.5266 | SPLoss:27.5690 | CLSLoss:0.1102 | AUROC:0.8291\n",
      "Test | 128/16 | Loss:0.2662 | MainLoss:0.2662 | SPLoss:27.5690 | CLSLoss:0.1102 | AUROC:0.9857\n",
      "\n",
      "Epoch: [47 | 1000] LR: 0.192000\n",
      "Train | 16/16 | Loss:3.1935 | MainLoss:0.5772 | Alpha:0.0538 | SPLoss:26.0853 | CLSLoss:0.0782 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.5834 | MainLoss:0.5834 | SPLoss:20.9482 | CLSLoss:0.0387 | AUROC:0.8289\n",
      "Test | 128/16 | Loss:0.3509 | MainLoss:0.3509 | SPLoss:20.9482 | CLSLoss:0.0387 | AUROC:0.9982\n",
      "\n",
      "Epoch: [48 | 1000] LR: 0.194000\n",
      "Train | 16/16 | Loss:2.1032 | MainLoss:0.5355 | Alpha:0.0573 | SPLoss:15.5960 | CLSLoss:0.0807 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.6974 | MainLoss:0.6974 | SPLoss:10.8132 | CLSLoss:0.0924 | AUROC:0.8211\n",
      "Test | 128/16 | Loss:0.2874 | MainLoss:0.2874 | SPLoss:10.8132 | CLSLoss:0.0924 | AUROC:0.9989\n",
      "\n",
      "Epoch: [49 | 1000] LR: 0.196000\n",
      "Train | 16/16 | Loss:1.3961 | MainLoss:0.5713 | Alpha:0.0535 | SPLoss:8.1756 | CLSLoss:0.0726 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.6563 | MainLoss:0.6563 | SPLoss:5.7952 | CLSLoss:0.0749 | AUROC:0.8263\n",
      "Test | 128/16 | Loss:0.1825 | MainLoss:0.1825 | SPLoss:5.7952 | CLSLoss:0.0749 | AUROC:0.9990\n",
      "\n",
      "Epoch: [50 | 1000] LR: 0.198000\n",
      "Train | 16/16 | Loss:1.0271 | MainLoss:0.5686 | Alpha:0.0545 | SPLoss:4.5107 | CLSLoss:0.0737 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.5661 | MainLoss:0.5661 | SPLoss:3.3750 | CLSLoss:0.0466 | AUROC:0.8096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 128/16 | Loss:0.2836 | MainLoss:0.2836 | SPLoss:3.3750 | CLSLoss:0.0466 | AUROC:0.9989\n",
      "\n",
      "Epoch: [51 | 1000] LR: 0.200000\n",
      "Train | 16/16 | Loss:0.9598 | MainLoss:0.5536 | Alpha:0.0546 | SPLoss:3.9915 | CLSLoss:0.0709 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.5106 | MainLoss:0.5106 | SPLoss:11.0983 | CLSLoss:0.0883 | AUROC:0.8431\n",
      "Test | 128/16 | Loss:0.1325 | MainLoss:0.1325 | SPLoss:11.0983 | CLSLoss:0.0883 | AUROC:0.9996\n",
      "\n",
      "Epoch: [52 | 1000] LR: 0.200000\n",
      "Train | 16/16 | Loss:1.4454 | MainLoss:0.5942 | Alpha:0.0583 | SPLoss:8.4461 | CLSLoss:0.0666 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.5293 | MainLoss:0.5293 | SPLoss:5.8809 | CLSLoss:0.0825 | AUROC:0.8351\n",
      "Test | 128/16 | Loss:0.2255 | MainLoss:0.2255 | SPLoss:5.8809 | CLSLoss:0.0825 | AUROC:0.9994\n",
      "\n",
      "Epoch: [53 | 1000] LR: 0.200000\n",
      "Train | 16/16 | Loss:1.0581 | MainLoss:0.5534 | Alpha:0.0579 | SPLoss:4.9526 | CLSLoss:0.0940 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.5324 | MainLoss:0.5324 | SPLoss:4.2228 | CLSLoss:0.0588 | AUROC:0.8371\n",
      "Test | 128/16 | Loss:0.2486 | MainLoss:0.2486 | SPLoss:4.2228 | CLSLoss:0.0588 | AUROC:0.9988\n",
      "\n",
      "Epoch: [54 | 1000] LR: 0.199998\n",
      "Train | 16/16 | Loss:0.8888 | MainLoss:0.5490 | Alpha:0.0577 | SPLoss:3.3229 | CLSLoss:0.0746 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.4989 | MainLoss:0.4989 | SPLoss:2.4796 | CLSLoss:0.0878 | AUROC:0.8399\n",
      "Test | 128/16 | Loss:0.1471 | MainLoss:0.1471 | SPLoss:2.4796 | CLSLoss:0.0878 | AUROC:0.9996\n",
      "\n",
      "Epoch: [55 | 1000] LR: 0.199996\n",
      "Train | 16/16 | Loss:0.8105 | MainLoss:0.5916 | Alpha:0.0545 | SPLoss:2.1265 | CLSLoss:0.0618 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.5150 | MainLoss:0.5150 | SPLoss:1.6591 | CLSLoss:0.0821 | AUROC:0.8283\n",
      "Test | 128/16 | Loss:0.1654 | MainLoss:0.1654 | SPLoss:1.6591 | CLSLoss:0.0821 | AUROC:0.9996\n",
      "\n",
      "Epoch: [56 | 1000] LR: 0.199992\n",
      "Train | 16/16 | Loss:2.1817 | MainLoss:0.5715 | Alpha:0.0541 | SPLoss:16.0327 | CLSLoss:0.0688 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.5028 | MainLoss:0.5028 | SPLoss:17.1040 | CLSLoss:0.0865 | AUROC:0.8389\n",
      "Test | 128/16 | Loss:0.1629 | MainLoss:0.1629 | SPLoss:17.1040 | CLSLoss:0.0865 | AUROC:0.9992\n",
      "\n",
      "Epoch: [57 | 1000] LR: 0.199988\n",
      "Train | 16/16 | Loss:2.1715 | MainLoss:0.5807 | Alpha:0.0558 | SPLoss:15.8393 | CLSLoss:0.0692 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.5177 | MainLoss:0.5177 | SPLoss:11.7629 | CLSLoss:0.0732 | AUROC:0.8343\n",
      "Test | 128/16 | Loss:0.1825 | MainLoss:0.1825 | SPLoss:11.7629 | CLSLoss:0.0732 | AUROC:0.9997\n",
      "\n",
      "Epoch: [58 | 1000] LR: 0.199982\n",
      "Train | 16/16 | Loss:1.4650 | MainLoss:0.5753 | Alpha:0.0546 | SPLoss:8.8212 | CLSLoss:0.0762 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.6272 | MainLoss:0.6272 | SPLoss:6.2846 | CLSLoss:0.0240 | AUROC:0.8303\n",
      "Test | 128/16 | Loss:0.4343 | MainLoss:0.4343 | SPLoss:6.2846 | CLSLoss:0.0240 | AUROC:0.9992\n",
      "\n",
      "Epoch: [59 | 1000] LR: 0.199976\n",
      "Train | 16/16 | Loss:1.0372 | MainLoss:0.5545 | Alpha:0.0591 | SPLoss:4.7500 | CLSLoss:0.0767 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.4964 | MainLoss:0.4964 | SPLoss:3.4230 | CLSLoss:0.1078 | AUROC:0.8411\n",
      "Test | 128/16 | Loss:0.1554 | MainLoss:0.1554 | SPLoss:3.4230 | CLSLoss:0.1078 | AUROC:0.9993\n",
      "\n",
      "Epoch: [60 | 1000] LR: 0.199968\n",
      "Train | 16/16 | Loss:0.8466 | MainLoss:0.5607 | Alpha:0.0548 | SPLoss:2.7738 | CLSLoss:0.0854 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.6485 | MainLoss:0.6485 | SPLoss:3.5782 | CLSLoss:0.0931 | AUROC:0.8151\n",
      "Test | 128/16 | Loss:0.2405 | MainLoss:0.2405 | SPLoss:3.5782 | CLSLoss:0.0931 | AUROC:0.9994\n",
      "\n",
      "Epoch: [61 | 1000] LR: 0.199960\n",
      "Train | 16/16 | Loss:2.1671 | MainLoss:0.5658 | Alpha:0.0565 | SPLoss:15.9370 | CLSLoss:0.0756 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.6322 | MainLoss:0.6322 | SPLoss:11.8960 | CLSLoss:0.1044 | AUROC:0.8286\n",
      "Test | 128/16 | Loss:0.1908 | MainLoss:0.1908 | SPLoss:11.8960 | CLSLoss:0.1044 | AUROC:0.9995\n",
      "\n",
      "Epoch: [62 | 1000] LR: 0.199951\n",
      "Train | 16/16 | Loss:1.6609 | MainLoss:0.5800 | Alpha:0.0569 | SPLoss:10.7341 | CLSLoss:0.0750 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.5205 | MainLoss:0.5205 | SPLoss:8.9598 | CLSLoss:0.0962 | AUROC:0.8379\n",
      "Test | 128/16 | Loss:0.1415 | MainLoss:0.1415 | SPLoss:8.9598 | CLSLoss:0.0962 | AUROC:0.9997\n",
      "\n",
      "Epoch: [63 | 1000] LR: 0.199940\n",
      "Train | 16/16 | Loss:1.2669 | MainLoss:0.5805 | Alpha:0.0545 | SPLoss:6.7915 | CLSLoss:0.0719 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.5065 | MainLoss:0.5065 | SPLoss:4.7856 | CLSLoss:0.0841 | AUROC:0.8379\n",
      "Test | 128/16 | Loss:0.1992 | MainLoss:0.1992 | SPLoss:4.7856 | CLSLoss:0.0841 | AUROC:0.9990\n",
      "\n",
      "Epoch: [64 | 1000] LR: 0.199929\n",
      "Train | 16/16 | Loss:0.9478 | MainLoss:0.5662 | Alpha:0.0562 | SPLoss:3.7419 | CLSLoss:0.0740 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.5436 | MainLoss:0.5436 | SPLoss:2.7597 | CLSLoss:0.1051 | AUROC:0.8358\n",
      "Test | 128/16 | Loss:0.1293 | MainLoss:0.1293 | SPLoss:2.7597 | CLSLoss:0.1051 | AUROC:0.9991\n",
      "\n",
      "Epoch: [65 | 1000] LR: 0.199917\n",
      "Train | 16/16 | Loss:0.9204 | MainLoss:0.5637 | Alpha:0.0591 | SPLoss:3.4830 | CLSLoss:0.0844 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.6973 | MainLoss:0.6973 | SPLoss:6.5111 | CLSLoss:0.0923 | AUROC:0.8078\n",
      "Test | 128/16 | Loss:0.2839 | MainLoss:0.2839 | SPLoss:6.5111 | CLSLoss:0.0923 | AUROC:0.9993\n",
      "\n",
      "Epoch: [66 | 1000] LR: 0.199903\n",
      "Train | 16/16 | Loss:1.1661 | MainLoss:0.6070 | Alpha:0.0593 | SPLoss:5.5276 | CLSLoss:0.0641 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.5523 | MainLoss:0.5523 | SPLoss:5.0934 | CLSLoss:0.0961 | AUROC:0.8036\n",
      "Test | 128/16 | Loss:0.1838 | MainLoss:0.1838 | SPLoss:5.0934 | CLSLoss:0.0961 | AUROC:0.9997\n",
      "\n",
      "Epoch: [67 | 1000] LR: 0.199889\n",
      "Train | 16/16 | Loss:1.1762 | MainLoss:0.5951 | Alpha:0.0605 | SPLoss:5.7378 | CLSLoss:0.0731 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.5460 | MainLoss:0.5460 | SPLoss:4.8223 | CLSLoss:0.0671 | AUROC:0.8129\n",
      "Test | 128/16 | Loss:0.2520 | MainLoss:0.2520 | SPLoss:4.8223 | CLSLoss:0.0671 | AUROC:0.9975\n",
      "\n",
      "Epoch: [68 | 1000] LR: 0.199874\n",
      "Train | 16/16 | Loss:1.0635 | MainLoss:0.5547 | Alpha:0.0562 | SPLoss:5.0012 | CLSLoss:0.0868 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.7444 | MainLoss:0.7444 | SPLoss:4.2061 | CLSLoss:0.0690 | AUROC:0.7865\n",
      "Test | 128/16 | Loss:0.3903 | MainLoss:0.3903 | SPLoss:4.2061 | CLSLoss:0.0690 | AUROC:0.9998\n",
      "\n",
      "Epoch: [69 | 1000] LR: 0.199857\n",
      "Train | 16/16 | Loss:0.9738 | MainLoss:0.5771 | Alpha:0.0552 | SPLoss:3.8946 | CLSLoss:0.0724 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.5193 | MainLoss:0.5193 | SPLoss:4.9488 | CLSLoss:0.0792 | AUROC:0.8284\n",
      "Test | 128/16 | Loss:0.1924 | MainLoss:0.1924 | SPLoss:4.9488 | CLSLoss:0.0792 | AUROC:0.9990\n",
      "\n",
      "Epoch: [70 | 1000] LR: 0.199840\n",
      "Train | 16/16 | Loss:0.9595 | MainLoss:0.5619 | Alpha:0.0575 | SPLoss:3.8971 | CLSLoss:0.0790 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.5733 | MainLoss:0.5733 | SPLoss:2.9234 | CLSLoss:0.0570 | AUROC:0.8249\n",
      "Test | 128/16 | Loss:0.2216 | MainLoss:0.2216 | SPLoss:2.9234 | CLSLoss:0.0570 | AUROC:0.9995\n",
      "\n",
      "Epoch: [71 | 1000] LR: 0.199822\n",
      "Train | 16/16 | Loss:0.8345 | MainLoss:0.5728 | Alpha:0.0520 | SPLoss:2.5465 | CLSLoss:0.0710 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.5769 | MainLoss:0.5769 | SPLoss:2.3163 | CLSLoss:0.0510 | AUROC:0.8081\n",
      "Test | 128/16 | Loss:0.2776 | MainLoss:0.2776 | SPLoss:2.3163 | CLSLoss:0.0510 | AUROC:0.9995\n",
      "\n",
      "Epoch: [72 | 1000] LR: 0.199803\n",
      "Train | 16/16 | Loss:1.0428 | MainLoss:0.5739 | Alpha:0.0593 | SPLoss:4.6151 | CLSLoss:0.0733 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.6524 | MainLoss:0.6524 | SPLoss:10.1790 | CLSLoss:0.0718 | AUROC:0.7631\n",
      "Test | 128/16 | Loss:0.2948 | MainLoss:0.2948 | SPLoss:10.1790 | CLSLoss:0.0718 | AUROC:0.9974\n",
      "\n",
      "Epoch: [73 | 1000] LR: 0.199782\n",
      "Train | 16/16 | Loss:2.1090 | MainLoss:0.5838 | Alpha:0.0584 | SPLoss:15.1834 | CLSLoss:0.0689 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.6288 | MainLoss:0.6288 | SPLoss:11.1311 | CLSLoss:0.0564 | AUROC:0.7869\n",
      "Test | 128/16 | Loss:0.2120 | MainLoss:0.2120 | SPLoss:11.1311 | CLSLoss:0.0564 | AUROC:0.9995\n",
      "\n",
      "Epoch: [74 | 1000] LR: 0.199761\n",
      "Train | 16/16 | Loss:1.4437 | MainLoss:0.6043 | Alpha:0.0549 | SPLoss:8.3359 | CLSLoss:0.0578 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.5550 | MainLoss:0.5550 | SPLoss:7.4494 | CLSLoss:0.0726 | AUROC:0.7990\n",
      "Test | 128/16 | Loss:0.2348 | MainLoss:0.2348 | SPLoss:7.4494 | CLSLoss:0.0726 | AUROC:0.9994\n",
      "\n",
      "Epoch: [75 | 1000] LR: 0.199739\n",
      "Train | 16/16 | Loss:1.2825 | MainLoss:0.6037 | Alpha:0.0553 | SPLoss:6.7234 | CLSLoss:0.0643 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.5786 | MainLoss:0.5786 | SPLoss:4.8091 | CLSLoss:0.0617 | AUROC:0.7820\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 128/16 | Loss:0.2721 | MainLoss:0.2721 | SPLoss:4.8091 | CLSLoss:0.0617 | AUROC:0.9996\n",
      "\n",
      "Epoch: [76 | 1000] LR: 0.199716\n",
      "Train | 16/16 | Loss:1.2855 | MainLoss:0.6017 | Alpha:0.0561 | SPLoss:6.7678 | CLSLoss:0.0704 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.6172 | MainLoss:0.6172 | SPLoss:8.1422 | CLSLoss:0.0304 | AUROC:0.7924\n",
      "Test | 128/16 | Loss:0.4243 | MainLoss:0.4243 | SPLoss:8.1422 | CLSLoss:0.0304 | AUROC:0.9985\n",
      "\n",
      "Epoch: [77 | 1000] LR: 0.199692\n",
      "Train | 16/16 | Loss:1.2114 | MainLoss:0.5860 | Alpha:0.0565 | SPLoss:6.1851 | CLSLoss:0.0687 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.6317 | MainLoss:0.6317 | SPLoss:4.5992 | CLSLoss:0.0347 | AUROC:0.7654\n",
      "Test | 128/16 | Loss:0.3512 | MainLoss:0.3512 | SPLoss:4.5992 | CLSLoss:0.0347 | AUROC:0.9996\n",
      "\n",
      "Epoch: [78 | 1000] LR: 0.199667\n",
      "Train | 16/16 | Loss:0.9639 | MainLoss:0.5888 | Alpha:0.0571 | SPLoss:3.6839 | CLSLoss:0.0672 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.5715 | MainLoss:0.5715 | SPLoss:3.1963 | CLSLoss:0.0601 | AUROC:0.8016\n",
      "Test | 128/16 | Loss:0.2422 | MainLoss:0.2422 | SPLoss:3.1963 | CLSLoss:0.0601 | AUROC:0.9992\n",
      "\n",
      "Epoch: [79 | 1000] LR: 0.199640\n",
      "Train | 16/16 | Loss:0.8591 | MainLoss:0.5959 | Alpha:0.0563 | SPLoss:2.5611 | CLSLoss:0.0712 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.6500 | MainLoss:0.6500 | SPLoss:2.0623 | CLSLoss:0.0193 | AUROC:0.7883\n",
      "Test | 128/16 | Loss:0.4714 | MainLoss:0.4714 | SPLoss:2.0623 | CLSLoss:0.0193 | AUROC:0.9996\n",
      "\n",
      "Epoch: [80 | 1000] LR: 0.199613\n",
      "Train | 16/16 | Loss:3.4401 | MainLoss:0.5997 | Alpha:0.0556 | SPLoss:28.3444 | CLSLoss:0.0591 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.5691 | MainLoss:0.5691 | SPLoss:96.7817 | CLSLoss:0.0571 | AUROC:0.7859\n",
      "Test | 128/16 | Loss:0.2834 | MainLoss:0.2834 | SPLoss:96.7817 | CLSLoss:0.0571 | AUROC:0.9992\n",
      "\n",
      "Epoch: [81 | 1000] LR: 0.199585\n",
      "Train | 16/16 | Loss:7.7641 | MainLoss:0.5795 | Alpha:0.0550 | SPLoss:71.7785 | CLSLoss:0.0677 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.5203 | MainLoss:0.5203 | SPLoss:48.7630 | CLSLoss:0.0962 | AUROC:0.8240\n",
      "Test | 128/16 | Loss:0.1482 | MainLoss:0.1482 | SPLoss:48.7630 | CLSLoss:0.0962 | AUROC:0.9996\n",
      "\n",
      "Epoch: [82 | 1000] LR: 0.199556\n",
      "Train | 16/16 | Loss:4.1723 | MainLoss:0.5881 | Alpha:0.0552 | SPLoss:35.7728 | CLSLoss:0.0690 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.5671 | MainLoss:0.5671 | SPLoss:24.1235 | CLSLoss:0.0679 | AUROC:0.8302\n",
      "Test | 128/16 | Loss:0.1796 | MainLoss:0.1796 | SPLoss:24.1235 | CLSLoss:0.0679 | AUROC:0.9997\n",
      "\n",
      "Epoch: [83 | 1000] LR: 0.199526\n",
      "Train | 16/16 | Loss:2.3772 | MainLoss:0.5591 | Alpha:0.0589 | SPLoss:18.1089 | CLSLoss:0.0715 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.5196 | MainLoss:0.5196 | SPLoss:12.5360 | CLSLoss:0.0982 | AUROC:0.8290\n",
      "Test | 128/16 | Loss:0.1464 | MainLoss:0.1464 | SPLoss:12.5360 | CLSLoss:0.0982 | AUROC:0.9993\n",
      "\n",
      "Epoch: [84 | 1000] LR: 0.199495\n",
      "Train | 16/16 | Loss:1.5057 | MainLoss:0.5610 | Alpha:0.0561 | SPLoss:9.3712 | CLSLoss:0.0766 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.6125 | MainLoss:0.6125 | SPLoss:6.4877 | CLSLoss:0.0949 | AUROC:0.8235\n",
      "Test | 128/16 | Loss:0.2259 | MainLoss:0.2259 | SPLoss:6.4877 | CLSLoss:0.0949 | AUROC:0.9996\n",
      "\n",
      "Epoch: [85 | 1000] LR: 0.199463\n",
      "Train | 16/16 | Loss:1.1455 | MainLoss:0.5395 | Alpha:0.0566 | SPLoss:5.9767 | CLSLoss:0.0841 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.8593 | MainLoss:0.8593 | SPLoss:4.4183 | CLSLoss:0.1032 | AUROC:0.8113\n",
      "Test | 128/16 | Loss:0.3681 | MainLoss:0.3681 | SPLoss:4.4183 | CLSLoss:0.1032 | AUROC:0.9992\n",
      "\n",
      "Epoch: [86 | 1000] LR: 0.199430\n",
      "Train | 16/16 | Loss:1.4347 | MainLoss:0.5988 | Alpha:0.0578 | SPLoss:8.2895 | CLSLoss:0.0698 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.5588 | MainLoss:0.5588 | SPLoss:18.5084 | CLSLoss:0.0573 | AUROC:0.8346\n",
      "Test | 128/16 | Loss:0.2799 | MainLoss:0.2799 | SPLoss:18.5084 | CLSLoss:0.0573 | AUROC:0.9995\n",
      "\n",
      "Epoch: [87 | 1000] LR: 0.199396\n",
      "Train | 16/16 | Loss:1.9503 | MainLoss:0.5598 | Alpha:0.0560 | SPLoss:13.8214 | CLSLoss:0.0834 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.6601 | MainLoss:0.6601 | SPLoss:9.6005 | CLSLoss:0.0608 | AUROC:0.8236\n",
      "Test | 128/16 | Loss:0.2628 | MainLoss:0.2628 | SPLoss:9.6005 | CLSLoss:0.0608 | AUROC:0.9981\n",
      "\n",
      "Epoch: [88 | 1000] LR: 0.199361\n",
      "Train | 16/16 | Loss:1.2959 | MainLoss:0.5688 | Alpha:0.0567 | SPLoss:7.1968 | CLSLoss:0.0747 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.5038 | MainLoss:0.5038 | SPLoss:5.0643 | CLSLoss:0.0997 | AUROC:0.8466\n",
      "Test | 128/16 | Loss:0.1293 | MainLoss:0.1293 | SPLoss:5.0643 | CLSLoss:0.0997 | AUROC:0.9998\n",
      "\n",
      "Epoch: [89 | 1000] LR: 0.199325\n",
      "Train | 16/16 | Loss:1.4442 | MainLoss:0.6209 | Alpha:0.0587 | SPLoss:8.1655 | CLSLoss:0.0678 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.5546 | MainLoss:0.5546 | SPLoss:7.9408 | CLSLoss:0.0632 | AUROC:0.8338\n",
      "Test | 128/16 | Loss:0.2793 | MainLoss:0.2793 | SPLoss:7.9408 | CLSLoss:0.0632 | AUROC:0.9994\n",
      "\n",
      "Epoch: [90 | 1000] LR: 0.199288\n",
      "Train | 16/16 | Loss:1.2363 | MainLoss:0.5765 | Alpha:0.0562 | SPLoss:6.5068 | CLSLoss:0.0911 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.6603 | MainLoss:0.6603 | SPLoss:9.4134 | CLSLoss:0.0554 | AUROC:0.8013\n",
      "Test | 128/16 | Loss:0.3937 | MainLoss:0.3937 | SPLoss:9.4134 | CLSLoss:0.0554 | AUROC:0.9993\n",
      "\n",
      "Epoch: [91 | 1000] LR: 0.199250\n",
      "Train | 16/16 | Loss:1.3386 | MainLoss:0.5971 | Alpha:0.0563 | SPLoss:7.3475 | CLSLoss:0.0670 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.5916 | MainLoss:0.5916 | SPLoss:5.3256 | CLSLoss:0.0858 | AUROC:0.7852\n",
      "Test | 128/16 | Loss:0.1838 | MainLoss:0.1838 | SPLoss:5.3256 | CLSLoss:0.0858 | AUROC:0.9991\n",
      "\n",
      "Epoch: [92 | 1000] LR: 0.199211\n",
      "Train | 16/16 | Loss:1.2143 | MainLoss:0.5890 | Alpha:0.0551 | SPLoss:6.1776 | CLSLoss:0.0756 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.5634 | MainLoss:0.5634 | SPLoss:4.7677 | CLSLoss:0.0726 | AUROC:0.8107\n",
      "Test | 128/16 | Loss:0.2258 | MainLoss:0.2258 | SPLoss:4.7677 | CLSLoss:0.0726 | AUROC:0.9971\n",
      "\n",
      "Epoch: [93 | 1000] LR: 0.199172\n",
      "Train | 16/16 | Loss:0.9894 | MainLoss:0.5547 | Alpha:0.0645 | SPLoss:4.2618 | CLSLoss:0.0845 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.6035 | MainLoss:0.6035 | SPLoss:3.1481 | CLSLoss:0.0978 | AUROC:0.8299\n",
      "Test | 128/16 | Loss:0.1834 | MainLoss:0.1834 | SPLoss:3.1481 | CLSLoss:0.0978 | AUROC:0.9996\n",
      "\n",
      "Epoch: [94 | 1000] LR: 0.199131\n",
      "Train | 16/16 | Loss:1.5827 | MainLoss:0.5795 | Alpha:0.0527 | SPLoss:9.9627 | CLSLoss:0.0695 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.6086 | MainLoss:0.6086 | SPLoss:21.0688 | CLSLoss:0.0987 | AUROC:0.8259\n",
      "Test | 128/16 | Loss:0.2127 | MainLoss:0.2127 | SPLoss:21.0688 | CLSLoss:0.0987 | AUROC:0.9993\n",
      "\n",
      "Epoch: [95 | 1000] LR: 0.199089\n",
      "Train | 16/16 | Loss:2.1798 | MainLoss:0.5492 | Alpha:0.0542 | SPLoss:16.2288 | CLSLoss:0.0770 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.8883 | MainLoss:0.8883 | SPLoss:11.2830 | CLSLoss:0.1073 | AUROC:0.8074\n",
      "Test | 128/16 | Loss:0.2935 | MainLoss:0.2935 | SPLoss:11.2830 | CLSLoss:0.1073 | AUROC:0.9995\n",
      "\n",
      "Epoch: [96 | 1000] LR: 0.199046\n",
      "Train | 16/16 | Loss:1.4544 | MainLoss:0.6001 | Alpha:0.0573 | SPLoss:8.4794 | CLSLoss:0.0635 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.5088 | MainLoss:0.5088 | SPLoss:5.8904 | CLSLoss:0.0756 | AUROC:0.8392\n",
      "Test | 128/16 | Loss:0.1641 | MainLoss:0.1641 | SPLoss:5.8904 | CLSLoss:0.0756 | AUROC:0.9999\n",
      "\n",
      "Epoch: [97 | 1000] LR: 0.199002\n",
      "Train | 16/16 | Loss:1.0101 | MainLoss:0.5428 | Alpha:0.0577 | SPLoss:4.5910 | CLSLoss:0.0815 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.5415 | MainLoss:0.5415 | SPLoss:3.5098 | CLSLoss:0.0959 | AUROC:0.8293\n",
      "Test | 128/16 | Loss:0.1350 | MainLoss:0.1350 | SPLoss:3.5098 | CLSLoss:0.0959 | AUROC:0.9998\n",
      "\n",
      "Epoch: [98 | 1000] LR: 0.198958\n",
      "Train | 16/16 | Loss:1.0162 | MainLoss:0.6048 | Alpha:0.0568 | SPLoss:4.0476 | CLSLoss:0.0668 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.6055 | MainLoss:0.6055 | SPLoss:6.7452 | CLSLoss:0.0353 | AUROC:0.8337\n",
      "Test | 128/16 | Loss:0.3472 | MainLoss:0.3472 | SPLoss:6.7452 | CLSLoss:0.0353 | AUROC:0.9996\n",
      "\n",
      "Epoch: [99 | 1000] LR: 0.198912\n",
      "Train | 16/16 | Loss:1.1076 | MainLoss:0.5853 | Alpha:0.0539 | SPLoss:5.1564 | CLSLoss:0.0669 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.5305 | MainLoss:0.5305 | SPLoss:3.7382 | CLSLoss:0.0637 | AUROC:0.8347\n",
      "Test | 128/16 | Loss:0.2276 | MainLoss:0.2276 | SPLoss:3.7382 | CLSLoss:0.0637 | AUROC:0.9996\n",
      "\n",
      "Epoch: [100 | 1000] LR: 0.198865\n",
      "Train | 16/16 | Loss:0.8858 | MainLoss:0.5597 | Alpha:0.0571 | SPLoss:3.1774 | CLSLoss:0.0832 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.5683 | MainLoss:0.5683 | SPLoss:2.5719 | CLSLoss:0.0471 | AUROC:0.8356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 128/16 | Loss:0.2905 | MainLoss:0.2905 | SPLoss:2.5719 | CLSLoss:0.0471 | AUROC:0.9994\n",
      "\n",
      "Epoch: [101 | 1000] LR: 0.198817\n",
      "Train | 16/16 | Loss:0.5603 | MainLoss:0.5436 | Alpha:0.3631 | SPLoss:0.0816 | CLSLoss:0.0854 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.4975 | MainLoss:0.4975 | SPLoss:0.1508 | CLSLoss:0.0836 | AUROC:0.8552\n",
      "Test | 128/16 | Loss:0.2205 | MainLoss:0.2205 | SPLoss:0.1508 | CLSLoss:0.0836 | AUROC:0.9991\n",
      "\n",
      "Epoch: [102 | 1000] LR: 0.198769\n",
      "Train | 16/16 | Loss:0.5438 | MainLoss:0.5127 | Alpha:0.3634 | SPLoss:0.2079 | CLSLoss:0.1029 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.5219 | MainLoss:0.5219 | SPLoss:0.2646 | CLSLoss:0.0741 | AUROC:0.8624\n",
      "Test | 128/16 | Loss:0.2173 | MainLoss:0.2173 | SPLoss:0.2646 | CLSLoss:0.0741 | AUROC:0.9994\n",
      "\n",
      "Epoch: [103 | 1000] LR: 0.198719\n",
      "Train | 16/16 | Loss:0.5592 | MainLoss:0.5184 | Alpha:0.3617 | SPLoss:0.3061 | CLSLoss:0.1024 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.6464 | MainLoss:0.6464 | SPLoss:0.3825 | CLSLoss:0.0804 | AUROC:0.8594\n",
      "Test | 128/16 | Loss:0.3437 | MainLoss:0.3437 | SPLoss:0.3825 | CLSLoss:0.0804 | AUROC:0.9992\n",
      "\n",
      "Epoch: [104 | 1000] LR: 0.198669\n",
      "Train | 16/16 | Loss:0.5382 | MainLoss:0.4893 | Alpha:0.3639 | SPLoss:0.3837 | CLSLoss:0.1061 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.4522 | MainLoss:0.4522 | SPLoss:3.8371 | CLSLoss:0.1203 | AUROC:0.8825\n",
      "Test | 128/16 | Loss:0.1386 | MainLoss:0.1386 | SPLoss:3.8371 | CLSLoss:0.1203 | AUROC:0.9985\n",
      "\n",
      "Epoch: [105 | 1000] LR: 0.198617\n",
      "Train | 16/16 | Loss:0.8939 | MainLoss:0.4990 | Alpha:0.3634 | SPLoss:3.8357 | CLSLoss:0.1127 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.4374 | MainLoss:0.4374 | SPLoss:2.7883 | CLSLoss:0.1320 | AUROC:0.8798\n",
      "Test | 128/16 | Loss:0.1357 | MainLoss:0.1357 | SPLoss:2.7883 | CLSLoss:0.1320 | AUROC:0.9985\n",
      "\n",
      "Epoch: [106 | 1000] LR: 0.198564\n",
      "Train | 16/16 | Loss:0.7184 | MainLoss:0.4873 | Alpha:0.3636 | SPLoss:2.1957 | CLSLoss:0.1145 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.4487 | MainLoss:0.4487 | SPLoss:1.6284 | CLSLoss:0.1059 | AUROC:0.8768\n",
      "Test | 128/16 | Loss:0.1648 | MainLoss:0.1648 | SPLoss:1.6284 | CLSLoss:0.1059 | AUROC:0.9986\n",
      "\n",
      "Epoch: [107 | 1000] LR: 0.198511\n",
      "Train | 16/16 | Loss:0.6328 | MainLoss:0.4888 | Alpha:0.3630 | SPLoss:1.3296 | CLSLoss:0.1108 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.4794 | MainLoss:0.4794 | SPLoss:1.0630 | CLSLoss:0.1066 | AUROC:0.8751\n",
      "Test | 128/16 | Loss:0.1230 | MainLoss:0.1230 | SPLoss:1.0630 | CLSLoss:0.1066 | AUROC:0.9994\n",
      "\n",
      "Epoch: [108 | 1000] LR: 0.198456\n",
      "Train | 16/16 | Loss:0.8803 | MainLoss:0.5160 | Alpha:0.3622 | SPLoss:3.5382 | CLSLoss:0.1042 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.4663 | MainLoss:0.4663 | SPLoss:3.4745 | CLSLoss:0.0962 | AUROC:0.8800\n",
      "Test | 128/16 | Loss:0.2139 | MainLoss:0.2139 | SPLoss:3.4745 | CLSLoss:0.0962 | AUROC:0.9983\n",
      "\n",
      "Epoch: [109 | 1000] LR: 0.198401\n",
      "Train | 16/16 | Loss:0.7491 | MainLoss:0.4666 | Alpha:0.3633 | SPLoss:2.7053 | CLSLoss:0.1198 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.5231 | MainLoss:0.5231 | SPLoss:2.0243 | CLSLoss:0.1201 | AUROC:0.8835\n",
      "Test | 128/16 | Loss:0.1348 | MainLoss:0.1348 | SPLoss:2.0243 | CLSLoss:0.1201 | AUROC:0.9975\n",
      "\n",
      "Epoch: [110 | 1000] LR: 0.198345\n",
      "Train | 16/16 | Loss:0.6679 | MainLoss:0.4924 | Alpha:0.3635 | SPLoss:1.6435 | CLSLoss:0.1115 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.5156 | MainLoss:0.5156 | SPLoss:1.2868 | CLSLoss:0.0935 | AUROC:0.8776\n",
      "Test | 128/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:1.2868 | CLSLoss:0.0935 | AUROC:0.9988\n",
      "\n",
      "Epoch: [111 | 1000] LR: 0.198287\n",
      "Train | 16/16 | Loss:0.6041 | MainLoss:0.4802 | Alpha:0.3633 | SPLoss:1.1172 | CLSLoss:0.1212 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.5251 | MainLoss:0.5251 | SPLoss:0.9514 | CLSLoss:0.0670 | AUROC:0.8756\n",
      "Test | 128/16 | Loss:0.2972 | MainLoss:0.2972 | SPLoss:0.9514 | CLSLoss:0.0670 | AUROC:0.9985\n",
      "\n",
      "Epoch: [112 | 1000] LR: 0.198229\n",
      "Train | 16/16 | Loss:0.6797 | MainLoss:0.4934 | Alpha:0.3639 | SPLoss:1.7538 | CLSLoss:0.1098 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.5519 | MainLoss:0.5519 | SPLoss:2.0433 | CLSLoss:0.1600 | AUROC:0.8721\n",
      "Test | 128/16 | Loss:0.1933 | MainLoss:0.1933 | SPLoss:2.0433 | CLSLoss:0.1601 | AUROC:0.9967\n",
      "\n",
      "Epoch: [113 | 1000] LR: 0.198169\n",
      "Train | 16/16 | Loss:0.6829 | MainLoss:0.5053 | Alpha:0.3637 | SPLoss:1.6492 | CLSLoss:0.1267 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.4591 | MainLoss:0.4591 | SPLoss:1.2674 | CLSLoss:0.1130 | AUROC:0.8791\n",
      "Test | 128/16 | Loss:0.1888 | MainLoss:0.1888 | SPLoss:1.2674 | CLSLoss:0.1130 | AUROC:0.9978\n",
      "\n",
      "Epoch: [114 | 1000] LR: 0.198109\n",
      "Train | 16/16 | Loss:0.5995 | MainLoss:0.4796 | Alpha:0.3628 | SPLoss:1.0720 | CLSLoss:0.1275 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.4720 | MainLoss:0.4720 | SPLoss:0.9031 | CLSLoss:0.1237 | AUROC:0.8795\n",
      "Test | 128/16 | Loss:0.1571 | MainLoss:0.1571 | SPLoss:0.9031 | CLSLoss:0.1237 | AUROC:0.9994\n",
      "\n",
      "Epoch: [115 | 1000] LR: 0.198048\n",
      "Train | 16/16 | Loss:0.5826 | MainLoss:0.4714 | Alpha:0.3625 | SPLoss:0.9816 | CLSLoss:0.1310 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.5392 | MainLoss:0.5392 | SPLoss:1.3862 | CLSLoss:0.0622 | AUROC:0.8540\n",
      "Test | 128/16 | Loss:0.3107 | MainLoss:0.3107 | SPLoss:1.3862 | CLSLoss:0.0622 | AUROC:0.9971\n",
      "\n",
      "Epoch: [116 | 1000] LR: 0.197986\n",
      "Train | 16/16 | Loss:0.6280 | MainLoss:0.5039 | Alpha:0.3631 | SPLoss:1.1358 | CLSLoss:0.1057 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.4891 | MainLoss:0.4891 | SPLoss:0.9256 | CLSLoss:0.1431 | AUROC:0.8756\n",
      "Test | 128/16 | Loss:0.1642 | MainLoss:0.1642 | SPLoss:0.9256 | CLSLoss:0.1431 | AUROC:0.9990\n",
      "\n",
      "Epoch: [117 | 1000] LR: 0.197922\n",
      "Train | 16/16 | Loss:0.5694 | MainLoss:0.4742 | Alpha:0.3634 | SPLoss:0.8252 | CLSLoss:0.1267 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.4372 | MainLoss:0.4372 | SPLoss:0.7267 | CLSLoss:0.1330 | AUROC:0.8845\n",
      "Test | 128/16 | Loss:0.1288 | MainLoss:0.1288 | SPLoss:0.7267 | CLSLoss:0.1330 | AUROC:0.9994\n",
      "\n",
      "Epoch: [118 | 1000] LR: 0.197858\n",
      "Train | 16/16 | Loss:0.5652 | MainLoss:0.4841 | Alpha:0.3640 | SPLoss:0.6902 | CLSLoss:0.1206 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.7414 | MainLoss:0.7414 | SPLoss:0.6910 | CLSLoss:0.1140 | AUROC:0.8539\n",
      "Test | 128/16 | Loss:0.3264 | MainLoss:0.3264 | SPLoss:0.6910 | CLSLoss:0.1140 | AUROC:0.9972\n",
      "\n",
      "Epoch: [119 | 1000] LR: 0.197793\n",
      "Train | 16/16 | Loss:0.7165 | MainLoss:0.4846 | Alpha:0.3635 | SPLoss:2.2008 | CLSLoss:0.1180 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.4356 | MainLoss:0.4356 | SPLoss:4.2124 | CLSLoss:0.1248 | AUROC:0.8832\n",
      "Test | 128/16 | Loss:0.1343 | MainLoss:0.1343 | SPLoss:4.2124 | CLSLoss:0.1248 | AUROC:0.9994\n",
      "\n",
      "Epoch: [120 | 1000] LR: 0.197727\n",
      "Train | 16/16 | Loss:0.8574 | MainLoss:0.4905 | Alpha:0.3641 | SPLoss:3.5497 | CLSLoss:0.1197 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.6674 | MainLoss:0.6674 | SPLoss:3.4895 | CLSLoss:0.1146 | AUROC:0.8584\n",
      "Test | 128/16 | Loss:0.1440 | MainLoss:0.1440 | SPLoss:3.4895 | CLSLoss:0.1146 | AUROC:0.9991\n",
      "\n",
      "Epoch: [121 | 1000] LR: 0.197660\n",
      "Train | 16/16 | Loss:0.7571 | MainLoss:0.4752 | Alpha:0.3635 | SPLoss:2.7022 | CLSLoss:0.1173 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.5249 | MainLoss:0.5249 | SPLoss:2.0032 | CLSLoss:0.1130 | AUROC:0.8764\n",
      "Test | 128/16 | Loss:0.1343 | MainLoss:0.1343 | SPLoss:2.0032 | CLSLoss:0.1130 | AUROC:0.9989\n",
      "\n",
      "Epoch: [122 | 1000] LR: 0.197592\n",
      "Train | 16/16 | Loss:0.6706 | MainLoss:0.4816 | Alpha:0.3635 | SPLoss:1.7747 | CLSLoss:0.1144 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.4429 | MainLoss:0.4429 | SPLoss:1.3863 | CLSLoss:0.1198 | AUROC:0.8770\n",
      "Test | 128/16 | Loss:0.1299 | MainLoss:0.1299 | SPLoss:1.3863 | CLSLoss:0.1198 | AUROC:0.9986\n",
      "\n",
      "Epoch: [123 | 1000] LR: 0.197523\n",
      "Train | 16/16 | Loss:0.6191 | MainLoss:0.4887 | Alpha:0.3629 | SPLoss:1.1919 | CLSLoss:0.1114 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.4394 | MainLoss:0.4394 | SPLoss:0.9995 | CLSLoss:0.1105 | AUROC:0.8862\n",
      "Test | 128/16 | Loss:0.1853 | MainLoss:0.1853 | SPLoss:0.9995 | CLSLoss:0.1105 | AUROC:0.9982\n",
      "\n",
      "Epoch: [124 | 1000] LR: 0.197453\n",
      "Train | 16/16 | Loss:0.5904 | MainLoss:0.4880 | Alpha:0.3632 | SPLoss:0.9036 | CLSLoss:0.1195 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.6188 | MainLoss:0.6188 | SPLoss:0.9558 | CLSLoss:0.0400 | AUROC:0.8208\n",
      "Test | 128/16 | Loss:0.3890 | MainLoss:0.3890 | SPLoss:0.9558 | CLSLoss:0.0400 | AUROC:0.9986\n",
      "\n",
      "Epoch: [125 | 1000] LR: 0.197382\n",
      "Train | 16/16 | Loss:0.5966 | MainLoss:0.5051 | Alpha:0.3634 | SPLoss:0.8168 | CLSLoss:0.0980 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.4667 | MainLoss:0.4667 | SPLoss:0.7563 | CLSLoss:0.1348 | AUROC:0.8728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 128/16 | Loss:0.1500 | MainLoss:0.1500 | SPLoss:0.7563 | CLSLoss:0.1348 | AUROC:0.9989\n",
      "\n",
      "Epoch: [126 | 1000] LR: 0.197310\n",
      "Train | 16/16 | Loss:0.5857 | MainLoss:0.4977 | Alpha:0.3641 | SPLoss:0.7649 | CLSLoss:0.1158 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.4509 | MainLoss:0.4509 | SPLoss:0.7125 | CLSLoss:0.1230 | AUROC:0.8745\n",
      "Test | 128/16 | Loss:0.1603 | MainLoss:0.1603 | SPLoss:0.7125 | CLSLoss:0.1230 | AUROC:0.9981\n",
      "\n",
      "Epoch: [127 | 1000] LR: 0.197237\n",
      "Train | 16/16 | Loss:0.5684 | MainLoss:0.4831 | Alpha:0.3626 | SPLoss:0.7320 | CLSLoss:0.1207 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.5869 | MainLoss:0.5869 | SPLoss:0.7307 | CLSLoss:0.1381 | AUROC:0.8653\n",
      "Test | 128/16 | Loss:0.1042 | MainLoss:0.1042 | SPLoss:0.7307 | CLSLoss:0.1381 | AUROC:0.9987\n",
      "\n",
      "Epoch: [128 | 1000] LR: 0.197163\n",
      "Train | 16/16 | Loss:0.5694 | MainLoss:0.4889 | Alpha:0.3637 | SPLoss:0.6911 | CLSLoss:0.1141 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.4467 | MainLoss:0.4467 | SPLoss:0.6423 | CLSLoss:0.1316 | AUROC:0.8867\n",
      "Test | 128/16 | Loss:0.1233 | MainLoss:0.1233 | SPLoss:0.6423 | CLSLoss:0.1316 | AUROC:0.9978\n",
      "\n",
      "Epoch: [129 | 1000] LR: 0.197088\n",
      "Train | 16/16 | Loss:0.5161 | MainLoss:0.4393 | Alpha:0.3643 | SPLoss:0.6401 | CLSLoss:0.1279 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.4386 | MainLoss:0.4386 | SPLoss:0.6177 | CLSLoss:0.1369 | AUROC:0.8864\n",
      "Test | 128/16 | Loss:0.1076 | MainLoss:0.1076 | SPLoss:0.6177 | CLSLoss:0.1369 | AUROC:0.9986\n",
      "\n",
      "Epoch: [130 | 1000] LR: 0.197013\n",
      "Train | 16/16 | Loss:0.5819 | MainLoss:0.5041 | Alpha:0.3635 | SPLoss:0.6697 | CLSLoss:0.1085 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.5173 | MainLoss:0.5173 | SPLoss:0.6302 | CLSLoss:0.1362 | AUROC:0.8711\n",
      "Test | 128/16 | Loss:0.0876 | MainLoss:0.0876 | SPLoss:0.6302 | CLSLoss:0.1362 | AUROC:0.9995\n",
      "\n",
      "Epoch: [131 | 1000] LR: 0.196936\n",
      "Train | 16/16 | Loss:0.5667 | MainLoss:0.4882 | Alpha:0.3642 | SPLoss:0.6623 | CLSLoss:0.1222 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.6140 | MainLoss:0.6140 | SPLoss:0.6876 | CLSLoss:0.1019 | AUROC:0.8661\n",
      "Test | 128/16 | Loss:0.1519 | MainLoss:0.1519 | SPLoss:0.6876 | CLSLoss:0.1019 | AUROC:0.9986\n",
      "\n",
      "Epoch: [132 | 1000] LR: 0.196858\n",
      "Train | 16/16 | Loss:0.6163 | MainLoss:0.5358 | Alpha:0.3636 | SPLoss:0.7111 | CLSLoss:0.0942 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.5089 | MainLoss:0.5089 | SPLoss:0.6324 | CLSLoss:0.1285 | AUROC:0.8576\n",
      "Test | 128/16 | Loss:0.1665 | MainLoss:0.1665 | SPLoss:0.6324 | CLSLoss:0.1285 | AUROC:0.9992\n",
      "\n",
      "Epoch: [133 | 1000] LR: 0.196780\n",
      "Train | 16/16 | Loss:0.5724 | MainLoss:0.4967 | Alpha:0.3626 | SPLoss:0.6360 | CLSLoss:0.1216 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.4384 | MainLoss:0.4384 | SPLoss:0.6168 | CLSLoss:0.1267 | AUROC:0.8826\n",
      "Test | 128/16 | Loss:0.1292 | MainLoss:0.1292 | SPLoss:0.6168 | CLSLoss:0.1267 | AUROC:0.9990\n",
      "\n",
      "Epoch: [134 | 1000] LR: 0.196700\n",
      "Train | 16/16 | Loss:0.5466 | MainLoss:0.4707 | Alpha:0.3639 | SPLoss:0.6327 | CLSLoss:0.1261 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.4293 | MainLoss:0.4293 | SPLoss:0.6104 | CLSLoss:0.1325 | AUROC:0.8848\n",
      "Test | 128/16 | Loss:0.1400 | MainLoss:0.1400 | SPLoss:0.6104 | CLSLoss:0.1325 | AUROC:0.9989\n",
      "\n",
      "Epoch: [135 | 1000] LR: 0.196620\n",
      "Train | 16/16 | Loss:0.5738 | MainLoss:0.4978 | Alpha:0.3631 | SPLoss:0.6382 | CLSLoss:0.1217 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.4423 | MainLoss:0.4423 | SPLoss:0.6659 | CLSLoss:0.1244 | AUROC:0.8799\n",
      "Test | 128/16 | Loss:0.1521 | MainLoss:0.1521 | SPLoss:0.6659 | CLSLoss:0.1244 | AUROC:0.9968\n",
      "\n",
      "Epoch: [136 | 1000] LR: 0.196538\n",
      "Train | 16/16 | Loss:0.5674 | MainLoss:0.4860 | Alpha:0.3636 | SPLoss:0.6926 | CLSLoss:0.1214 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.5093 | MainLoss:0.5093 | SPLoss:0.7345 | CLSLoss:0.0897 | AUROC:0.8426\n",
      "Test | 128/16 | Loss:0.2088 | MainLoss:0.2088 | SPLoss:0.7345 | CLSLoss:0.0897 | AUROC:0.9966\n",
      "\n",
      "Epoch: [137 | 1000] LR: 0.196456\n",
      "Train | 16/16 | Loss:0.5650 | MainLoss:0.4825 | Alpha:0.3629 | SPLoss:0.7098 | CLSLoss:0.1148 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.5123 | MainLoss:0.5123 | SPLoss:0.6970 | CLSLoss:0.1401 | AUROC:0.8749\n",
      "Test | 128/16 | Loss:0.1917 | MainLoss:0.1917 | SPLoss:0.6970 | CLSLoss:0.1401 | AUROC:0.9970\n",
      "\n",
      "Epoch: [138 | 1000] LR: 0.196372\n",
      "Train | 16/16 | Loss:0.5870 | MainLoss:0.5057 | Alpha:0.3634 | SPLoss:0.7034 | CLSLoss:0.1093 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.6161 | MainLoss:0.6161 | SPLoss:0.6892 | CLSLoss:0.1104 | AUROC:0.8675\n",
      "Test | 128/16 | Loss:0.1343 | MainLoss:0.1343 | SPLoss:0.6892 | CLSLoss:0.1104 | AUROC:0.9978\n",
      "\n",
      "Epoch: [139 | 1000] LR: 0.196288\n",
      "Train | 16/16 | Loss:0.5699 | MainLoss:0.4927 | Alpha:0.3636 | SPLoss:0.6641 | CLSLoss:0.1073 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.4503 | MainLoss:0.4503 | SPLoss:0.6223 | CLSLoss:0.1351 | AUROC:0.8829\n",
      "Test | 128/16 | Loss:0.1252 | MainLoss:0.1252 | SPLoss:0.6223 | CLSLoss:0.1351 | AUROC:0.9991\n",
      "\n",
      "Epoch: [140 | 1000] LR: 0.196203\n",
      "Train | 16/16 | Loss:0.5799 | MainLoss:0.4816 | Alpha:0.3634 | SPLoss:0.8654 | CLSLoss:0.1176 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.4769 | MainLoss:0.4769 | SPLoss:1.1548 | CLSLoss:0.1384 | AUROC:0.8782\n",
      "Test | 128/16 | Loss:0.1429 | MainLoss:0.1429 | SPLoss:1.1548 | CLSLoss:0.1384 | AUROC:0.9993\n",
      "\n",
      "Epoch: [141 | 1000] LR: 0.196117\n",
      "Train | 16/16 | Loss:0.5894 | MainLoss:0.4732 | Alpha:0.3637 | SPLoss:1.0390 | CLSLoss:0.1230 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.4298 | MainLoss:0.4298 | SPLoss:0.8856 | CLSLoss:0.1247 | AUROC:0.8860\n",
      "Test | 128/16 | Loss:0.1271 | MainLoss:0.1271 | SPLoss:0.8856 | CLSLoss:0.1247 | AUROC:0.9990\n",
      "\n",
      "Epoch: [142 | 1000] LR: 0.196029\n",
      "Train | 16/16 | Loss:0.5958 | MainLoss:0.4977 | Alpha:0.3635 | SPLoss:0.8628 | CLSLoss:0.1183 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.6303 | MainLoss:0.6303 | SPLoss:0.8632 | CLSLoss:0.0300 | AUROC:0.8507\n",
      "Test | 128/16 | Loss:0.4546 | MainLoss:0.4546 | SPLoss:0.8632 | CLSLoss:0.0300 | AUROC:0.9987\n",
      "\n",
      "Epoch: [143 | 1000] LR: 0.195941\n",
      "Train | 16/16 | Loss:0.5740 | MainLoss:0.4897 | Alpha:0.3628 | SPLoss:0.7332 | CLSLoss:0.1095 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.7942 | MainLoss:0.7942 | SPLoss:0.7313 | CLSLoss:0.1450 | AUROC:0.8528\n",
      "Test | 128/16 | Loss:0.3142 | MainLoss:0.3142 | SPLoss:0.7313 | CLSLoss:0.1450 | AUROC:0.9985\n",
      "\n",
      "Epoch: [144 | 1000] LR: 0.195852\n",
      "Train | 16/16 | Loss:0.5544 | MainLoss:0.4747 | Alpha:0.3631 | SPLoss:0.6748 | CLSLoss:0.1225 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.4358 | MainLoss:0.4358 | SPLoss:0.6312 | CLSLoss:0.1440 | AUROC:0.8832\n",
      "Test | 128/16 | Loss:0.1416 | MainLoss:0.1416 | SPLoss:0.6312 | CLSLoss:0.1440 | AUROC:0.9989\n",
      "\n",
      "Epoch: [145 | 1000] LR: 0.195762\n",
      "Train | 16/16 | Loss:0.6243 | MainLoss:0.5243 | Alpha:0.3630 | SPLoss:0.8931 | CLSLoss:0.1063 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.4577 | MainLoss:0.4577 | SPLoss:0.7946 | CLSLoss:0.1108 | AUROC:0.8763\n",
      "Test | 128/16 | Loss:0.1643 | MainLoss:0.1643 | SPLoss:0.7946 | CLSLoss:0.1108 | AUROC:0.9990\n",
      "\n",
      "Epoch: [146 | 1000] LR: 0.195671\n",
      "Train | 16/16 | Loss:0.5491 | MainLoss:0.4624 | Alpha:0.3645 | SPLoss:0.7345 | CLSLoss:0.1321 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.4632 | MainLoss:0.4632 | SPLoss:0.6687 | CLSLoss:0.1064 | AUROC:0.8741\n",
      "Test | 128/16 | Loss:0.1849 | MainLoss:0.1849 | SPLoss:0.6687 | CLSLoss:0.1064 | AUROC:0.9973\n",
      "\n",
      "Epoch: [147 | 1000] LR: 0.195579\n",
      "Train | 16/16 | Loss:0.5570 | MainLoss:0.4806 | Alpha:0.3630 | SPLoss:0.6384 | CLSLoss:0.1259 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.5448 | MainLoss:0.5448 | SPLoss:1.2913 | CLSLoss:0.0899 | AUROC:0.8486\n",
      "Test | 128/16 | Loss:0.1737 | MainLoss:0.1737 | SPLoss:1.2913 | CLSLoss:0.0899 | AUROC:0.9984\n",
      "\n",
      "Epoch: [148 | 1000] LR: 0.195486\n",
      "Train | 16/16 | Loss:0.6368 | MainLoss:0.5024 | Alpha:0.3634 | SPLoss:1.2342 | CLSLoss:0.1096 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.5583 | MainLoss:0.5583 | SPLoss:1.0816 | CLSLoss:0.0622 | AUROC:0.8208\n",
      "Test | 128/16 | Loss:0.3062 | MainLoss:0.3062 | SPLoss:1.0816 | CLSLoss:0.0622 | AUROC:0.9964\n",
      "\n",
      "Epoch: [149 | 1000] LR: 0.195393\n",
      "Train | 16/16 | Loss:0.5607 | MainLoss:0.4585 | Alpha:0.3631 | SPLoss:0.9040 | CLSLoss:0.1180 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.4325 | MainLoss:0.4325 | SPLoss:0.7918 | CLSLoss:0.1516 | AUROC:0.8848\n",
      "Test | 128/16 | Loss:0.0969 | MainLoss:0.0969 | SPLoss:0.7918 | CLSLoss:0.1516 | AUROC:0.9995\n",
      "\n",
      "Epoch: [150 | 1000] LR: 0.195298\n",
      "Train | 16/16 | Loss:0.5900 | MainLoss:0.5009 | Alpha:0.3635 | SPLoss:0.7694 | CLSLoss:0.1214 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.6197 | MainLoss:0.6197 | SPLoss:0.6947 | CLSLoss:0.1136 | AUROC:0.8573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 128/16 | Loss:0.3004 | MainLoss:0.3004 | SPLoss:0.6947 | CLSLoss:0.1136 | AUROC:0.9978\n",
      "\n",
      "Epoch: [151 | 1000] LR: 0.195202\n",
      "Train | 16/16 | Loss:0.5530 | MainLoss:0.4752 | Alpha:0.3637 | SPLoss:0.6449 | CLSLoss:0.1323 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.5916 | MainLoss:0.5916 | SPLoss:0.6546 | CLSLoss:0.0918 | AUROC:0.8565\n",
      "Test | 128/16 | Loss:0.3246 | MainLoss:0.3246 | SPLoss:0.6546 | CLSLoss:0.0918 | AUROC:0.9977\n",
      "\n",
      "Epoch: [152 | 1000] LR: 0.195106\n",
      "Train | 16/16 | Loss:0.5835 | MainLoss:0.5061 | Alpha:0.3634 | SPLoss:0.6645 | CLSLoss:0.1088 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.4982 | MainLoss:0.4982 | SPLoss:0.6729 | CLSLoss:0.0999 | AUROC:0.8511\n",
      "Test | 128/16 | Loss:0.1990 | MainLoss:0.1990 | SPLoss:0.6729 | CLSLoss:0.0999 | AUROC:0.9981\n",
      "\n",
      "Epoch: [153 | 1000] LR: 0.195008\n",
      "Train | 16/16 | Loss:0.5384 | MainLoss:0.4622 | Alpha:0.3633 | SPLoss:0.6427 | CLSLoss:0.1198 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.5419 | MainLoss:0.5419 | SPLoss:0.6251 | CLSLoss:0.1276 | AUROC:0.8722\n",
      "Test | 128/16 | Loss:0.1042 | MainLoss:0.1042 | SPLoss:0.6251 | CLSLoss:0.1276 | AUROC:0.9988\n",
      "\n",
      "Epoch: [154 | 1000] LR: 0.194910\n",
      "Train | 16/16 | Loss:0.5700 | MainLoss:0.4944 | Alpha:0.3641 | SPLoss:0.6397 | CLSLoss:0.1155 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.5863 | MainLoss:0.5863 | SPLoss:0.6512 | CLSLoss:0.0787 | AUROC:0.8569\n",
      "Test | 128/16 | Loss:0.2169 | MainLoss:0.2169 | SPLoss:0.6512 | CLSLoss:0.0787 | AUROC:0.9955\n",
      "\n",
      "Epoch: [155 | 1000] LR: 0.194810\n",
      "Train | 16/16 | Loss:0.5648 | MainLoss:0.4918 | Alpha:0.3640 | SPLoss:0.6227 | CLSLoss:0.1081 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.5314 | MainLoss:0.5314 | SPLoss:0.6059 | CLSLoss:0.0997 | AUROC:0.8718\n",
      "Test | 128/16 | Loss:0.1857 | MainLoss:0.1857 | SPLoss:0.6059 | CLSLoss:0.0997 | AUROC:0.9972\n",
      "\n",
      "Epoch: [156 | 1000] LR: 0.194710\n",
      "Train | 16/16 | Loss:0.5523 | MainLoss:0.4785 | Alpha:0.3637 | SPLoss:0.6131 | CLSLoss:0.1252 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.5472 | MainLoss:0.5472 | SPLoss:0.6580 | CLSLoss:0.0662 | AUROC:0.8459\n",
      "Test | 128/16 | Loss:0.3082 | MainLoss:0.3082 | SPLoss:0.6580 | CLSLoss:0.0662 | AUROC:0.9976\n",
      "\n",
      "Epoch: [157 | 1000] LR: 0.194609\n",
      "Train | 16/16 | Loss:0.5760 | MainLoss:0.5028 | Alpha:0.3637 | SPLoss:0.6250 | CLSLoss:0.1074 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.4584 | MainLoss:0.4584 | SPLoss:0.5773 | CLSLoss:0.1073 | AUROC:0.8758\n",
      "Test | 128/16 | Loss:0.1597 | MainLoss:0.1597 | SPLoss:0.5773 | CLSLoss:0.1073 | AUROC:0.9991\n",
      "\n",
      "Epoch: [158 | 1000] LR: 0.194506\n",
      "Train | 16/16 | Loss:2.7424 | MainLoss:0.4732 | Alpha:0.3640 | SPLoss:22.5772 | CLSLoss:0.1142 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.4685 | MainLoss:0.4685 | SPLoss:46.0851 | CLSLoss:0.1190 | AUROC:0.8722\n",
      "Test | 128/16 | Loss:0.1546 | MainLoss:0.1546 | SPLoss:46.0851 | CLSLoss:0.1190 | AUROC:0.9986\n",
      "\n",
      "Epoch: [159 | 1000] LR: 0.194403\n",
      "Train | 16/16 | Loss:3.9178 | MainLoss:0.4884 | Alpha:0.3633 | SPLoss:34.1784 | CLSLoss:0.1163 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.4472 | MainLoss:0.4472 | SPLoss:23.2938 | CLSLoss:0.1023 | AUROC:0.8770\n",
      "Test | 128/16 | Loss:0.1673 | MainLoss:0.1673 | SPLoss:23.2938 | CLSLoss:0.1023 | AUROC:0.9962\n",
      "\n",
      "Epoch: [160 | 1000] LR: 0.194299\n",
      "Train | 16/16 | Loss:2.2192 | MainLoss:0.4796 | Alpha:0.3638 | SPLoss:17.2882 | CLSLoss:0.1077 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.4371 | MainLoss:0.4371 | SPLoss:11.8419 | CLSLoss:0.1271 | AUROC:0.8802\n",
      "Test | 128/16 | Loss:0.1310 | MainLoss:0.1310 | SPLoss:11.8419 | CLSLoss:0.1271 | AUROC:0.9982\n",
      "\n",
      "Epoch: [161 | 1000] LR: 0.194194\n",
      "Train | 16/16 | Loss:1.3919 | MainLoss:0.4885 | Alpha:0.3640 | SPLoss:8.9233 | CLSLoss:0.1101 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.4863 | MainLoss:0.4863 | SPLoss:6.2564 | CLSLoss:0.1226 | AUROC:0.8780\n",
      "Test | 128/16 | Loss:0.1849 | MainLoss:0.1849 | SPLoss:6.2564 | CLSLoss:0.1226 | AUROC:0.9987\n",
      "\n",
      "Epoch: [162 | 1000] LR: 0.194088\n",
      "Train | 16/16 | Loss:0.9895 | MainLoss:0.4947 | Alpha:0.3631 | SPLoss:4.8396 | CLSLoss:0.1088 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.4582 | MainLoss:0.4582 | SPLoss:3.5108 | CLSLoss:0.0979 | AUROC:0.8829\n",
      "Test | 128/16 | Loss:0.1686 | MainLoss:0.1686 | SPLoss:3.5108 | CLSLoss:0.0979 | AUROC:0.9988\n",
      "\n",
      "Epoch: [163 | 1000] LR: 0.193981\n",
      "Train | 16/16 | Loss:0.7793 | MainLoss:0.4917 | Alpha:0.3633 | SPLoss:2.7659 | CLSLoss:0.1106 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.4480 | MainLoss:0.4480 | SPLoss:2.0577 | CLSLoss:0.1118 | AUROC:0.8846\n",
      "Test | 128/16 | Loss:0.1792 | MainLoss:0.1792 | SPLoss:2.0577 | CLSLoss:0.1118 | AUROC:0.9969\n",
      "\n",
      "Epoch: [164 | 1000] LR: 0.193873\n",
      "Train | 16/16 | Loss:0.8208 | MainLoss:0.4988 | Alpha:0.3632 | SPLoss:3.1072 | CLSLoss:0.1121 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.5268 | MainLoss:0.5268 | SPLoss:3.5687 | CLSLoss:0.1251 | AUROC:0.8702\n",
      "Test | 128/16 | Loss:0.2181 | MainLoss:0.2181 | SPLoss:3.5687 | CLSLoss:0.1251 | AUROC:0.9977\n",
      "\n",
      "Epoch: [165 | 1000] LR: 0.193765\n",
      "Train | 16/16 | Loss:0.7894 | MainLoss:0.5001 | Alpha:0.3635 | SPLoss:2.7782 | CLSLoss:0.1140 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.5101 | MainLoss:0.5101 | SPLoss:2.0998 | CLSLoss:0.1128 | AUROC:0.8646\n",
      "Test | 128/16 | Loss:0.1458 | MainLoss:0.1458 | SPLoss:2.0998 | CLSLoss:0.1128 | AUROC:0.9973\n",
      "\n",
      "Epoch: [166 | 1000] LR: 0.193655\n",
      "Train | 16/16 | Loss:0.6533 | MainLoss:0.4683 | Alpha:0.3637 | SPLoss:1.7289 | CLSLoss:0.1211 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.4199 | MainLoss:0.4199 | SPLoss:1.3407 | CLSLoss:0.1422 | AUROC:0.8898\n",
      "Test | 128/16 | Loss:0.1050 | MainLoss:0.1050 | SPLoss:1.3407 | CLSLoss:0.1422 | AUROC:0.9993\n",
      "\n",
      "Epoch: [167 | 1000] LR: 0.193544\n",
      "Train | 16/16 | Loss:0.6493 | MainLoss:0.5211 | Alpha:0.3630 | SPLoss:1.1754 | CLSLoss:0.1067 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.4645 | MainLoss:0.4645 | SPLoss:0.9550 | CLSLoss:0.1029 | AUROC:0.8832\n",
      "Test | 128/16 | Loss:0.1532 | MainLoss:0.1532 | SPLoss:0.9550 | CLSLoss:0.1029 | AUROC:0.9984\n",
      "\n",
      "Epoch: [168 | 1000] LR: 0.193433\n",
      "Train | 16/16 | Loss:0.5846 | MainLoss:0.4829 | Alpha:0.3634 | SPLoss:0.9043 | CLSLoss:0.1126 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.5649 | MainLoss:0.5649 | SPLoss:0.9302 | CLSLoss:0.1000 | AUROC:0.8639\n",
      "Test | 128/16 | Loss:0.2439 | MainLoss:0.2439 | SPLoss:0.9302 | CLSLoss:0.1000 | AUROC:0.9987\n",
      "\n",
      "Epoch: [169 | 1000] LR: 0.193320\n",
      "Train | 16/16 | Loss:0.5735 | MainLoss:0.4766 | Alpha:0.3632 | SPLoss:0.8559 | CLSLoss:0.1131 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.5914 | MainLoss:0.5914 | SPLoss:0.7881 | CLSLoss:0.1188 | AUROC:0.8644\n",
      "Test | 128/16 | Loss:0.2163 | MainLoss:0.2163 | SPLoss:0.7881 | CLSLoss:0.1188 | AUROC:0.9994\n",
      "\n",
      "Epoch: [170 | 1000] LR: 0.193207\n",
      "Train | 16/16 | Loss:0.6630 | MainLoss:0.4810 | Alpha:0.3631 | SPLoss:1.7035 | CLSLoss:0.1163 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.4501 | MainLoss:0.4501 | SPLoss:5.2480 | CLSLoss:0.1326 | AUROC:0.8813\n",
      "Test | 128/16 | Loss:0.1300 | MainLoss:0.1300 | SPLoss:5.2480 | CLSLoss:0.1326 | AUROC:0.9991\n",
      "\n",
      "Epoch: [171 | 1000] LR: 0.193093\n",
      "Train | 16/16 | Loss:0.9044 | MainLoss:0.4858 | Alpha:0.3634 | SPLoss:4.0652 | CLSLoss:0.1206 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.5055 | MainLoss:0.5055 | SPLoss:2.9505 | CLSLoss:0.1167 | AUROC:0.8731\n",
      "Test | 128/16 | Loss:0.1620 | MainLoss:0.1620 | SPLoss:2.9505 | CLSLoss:0.1167 | AUROC:0.9995\n",
      "\n",
      "Epoch: [172 | 1000] LR: 0.192978\n",
      "Train | 16/16 | Loss:0.7293 | MainLoss:0.4752 | Alpha:0.3637 | SPLoss:2.4261 | CLSLoss:0.1154 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.4648 | MainLoss:0.4648 | SPLoss:2.1009 | CLSLoss:0.1225 | AUROC:0.8782\n",
      "Test | 128/16 | Loss:0.1278 | MainLoss:0.1278 | SPLoss:2.1009 | CLSLoss:0.1225 | AUROC:0.9996\n",
      "\n",
      "Epoch: [173 | 1000] LR: 0.192862\n",
      "Train | 16/16 | Loss:0.6585 | MainLoss:0.4760 | Alpha:0.3638 | SPLoss:1.7120 | CLSLoss:0.1130 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.4344 | MainLoss:0.4344 | SPLoss:1.3613 | CLSLoss:0.1397 | AUROC:0.8840\n",
      "Test | 128/16 | Loss:0.1091 | MainLoss:0.1091 | SPLoss:1.3613 | CLSLoss:0.1397 | AUROC:0.9992\n",
      "\n",
      "Epoch: [174 | 1000] LR: 0.192745\n",
      "Train | 16/16 | Loss:0.7844 | MainLoss:0.4670 | Alpha:0.3640 | SPLoss:3.0485 | CLSLoss:0.1255 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.4607 | MainLoss:0.4607 | SPLoss:4.2149 | CLSLoss:0.1501 | AUROC:0.8732\n",
      "Test | 128/16 | Loss:0.0848 | MainLoss:0.0848 | SPLoss:4.2149 | CLSLoss:0.1501 | AUROC:0.9995\n",
      "\n",
      "Epoch: [175 | 1000] LR: 0.192627\n",
      "Train | 16/16 | Loss:0.9325 | MainLoss:0.4919 | Alpha:0.3638 | SPLoss:4.2864 | CLSLoss:0.1194 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.4421 | MainLoss:0.4421 | SPLoss:5.6910 | CLSLoss:0.1425 | AUROC:0.8782\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 128/16 | Loss:0.1159 | MainLoss:0.1159 | SPLoss:5.6910 | CLSLoss:0.1425 | AUROC:0.9991\n",
      "\n",
      "Epoch: [176 | 1000] LR: 0.192508\n",
      "Train | 16/16 | Loss:0.9824 | MainLoss:0.5309 | Alpha:0.3636 | SPLoss:4.4089 | CLSLoss:0.1061 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.5299 | MainLoss:0.5299 | SPLoss:3.2787 | CLSLoss:0.0843 | AUROC:0.8563\n",
      "Test | 128/16 | Loss:0.1787 | MainLoss:0.1787 | SPLoss:3.2787 | CLSLoss:0.0843 | AUROC:0.9990\n",
      "\n",
      "Epoch: [177 | 1000] LR: 0.192388\n",
      "Train | 16/16 | Loss:0.7878 | MainLoss:0.4977 | Alpha:0.3635 | SPLoss:2.7953 | CLSLoss:0.1050 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.5114 | MainLoss:0.5114 | SPLoss:2.1781 | CLSLoss:0.1161 | AUROC:0.8756\n",
      "Test | 128/16 | Loss:0.1102 | MainLoss:0.1102 | SPLoss:2.1781 | CLSLoss:0.1161 | AUROC:0.9992\n",
      "\n",
      "Epoch: [178 | 1000] LR: 0.192267\n",
      "Train | 16/16 | Loss:0.6536 | MainLoss:0.4652 | Alpha:0.3639 | SPLoss:1.7654 | CLSLoss:0.1180 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.4939 | MainLoss:0.4939 | SPLoss:1.4100 | CLSLoss:0.1367 | AUROC:0.8785\n",
      "Test | 128/16 | Loss:0.0972 | MainLoss:0.0972 | SPLoss:1.4100 | CLSLoss:0.1367 | AUROC:0.9988\n",
      "\n",
      "Epoch: [179 | 1000] LR: 0.192146\n",
      "Train | 16/16 | Loss:0.8665 | MainLoss:0.5006 | Alpha:0.3631 | SPLoss:3.5403 | CLSLoss:0.1194 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.5058 | MainLoss:0.5058 | SPLoss:2.9828 | CLSLoss:0.0787 | AUROC:0.8804\n",
      "Test | 128/16 | Loss:0.2630 | MainLoss:0.2630 | SPLoss:2.9828 | CLSLoss:0.0787 | AUROC:0.9975\n",
      "\n",
      "Epoch: [180 | 1000] LR: 0.192023\n",
      "Train | 16/16 | Loss:0.7281 | MainLoss:0.4775 | Alpha:0.3624 | SPLoss:2.3905 | CLSLoss:0.1157 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.4461 | MainLoss:0.4461 | SPLoss:1.8530 | CLSLoss:0.1172 | AUROC:0.8835\n",
      "Test | 128/16 | Loss:0.1193 | MainLoss:0.1193 | SPLoss:1.8530 | CLSLoss:0.1172 | AUROC:0.9988\n",
      "\n",
      "Epoch: [181 | 1000] LR: 0.191900\n",
      "Train | 16/16 | Loss:0.6455 | MainLoss:0.4780 | Alpha:0.3628 | SPLoss:1.5579 | CLSLoss:0.1177 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.5955 | MainLoss:0.5955 | SPLoss:1.2638 | CLSLoss:0.1380 | AUROC:0.8702\n",
      "Test | 128/16 | Loss:0.1904 | MainLoss:0.1904 | SPLoss:1.2638 | CLSLoss:0.1380 | AUROC:0.9993\n",
      "\n",
      "Epoch: [182 | 1000] LR: 0.191775\n",
      "Train | 16/16 | Loss:0.5994 | MainLoss:0.4780 | Alpha:0.3635 | SPLoss:1.0965 | CLSLoss:0.1173 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.4357 | MainLoss:0.4357 | SPLoss:0.9244 | CLSLoss:0.1275 | AUROC:0.8886\n",
      "Test | 128/16 | Loss:0.1594 | MainLoss:0.1594 | SPLoss:0.9244 | CLSLoss:0.1275 | AUROC:0.9982\n",
      "\n",
      "Epoch: [183 | 1000] LR: 0.191650\n",
      "Train | 16/16 | Loss:0.5855 | MainLoss:0.4855 | Alpha:0.3629 | SPLoss:0.8833 | CLSLoss:0.1161 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.4541 | MainLoss:0.4541 | SPLoss:0.8313 | CLSLoss:0.1140 | AUROC:0.8830\n",
      "Test | 128/16 | Loss:0.1667 | MainLoss:0.1667 | SPLoss:0.8313 | CLSLoss:0.1140 | AUROC:0.9987\n",
      "\n",
      "Epoch: [184 | 1000] LR: 0.191524\n",
      "Train | 16/16 | Loss:0.6020 | MainLoss:0.4779 | Alpha:0.3634 | SPLoss:1.1207 | CLSLoss:0.1205 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.5200 | MainLoss:0.5200 | SPLoss:3.0714 | CLSLoss:0.0629 | AUROC:0.8732\n",
      "Test | 128/16 | Loss:0.2635 | MainLoss:0.2635 | SPLoss:3.0714 | CLSLoss:0.0629 | AUROC:0.9988\n",
      "\n",
      "Epoch: [185 | 1000] LR: 0.191397\n",
      "Train | 16/16 | Loss:0.7417 | MainLoss:0.4886 | Alpha:0.3637 | SPLoss:2.4177 | CLSLoss:0.1132 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.5390 | MainLoss:0.5390 | SPLoss:1.9342 | CLSLoss:0.0496 | AUROC:0.8687\n",
      "Test | 128/16 | Loss:0.3399 | MainLoss:0.3399 | SPLoss:1.9342 | CLSLoss:0.0496 | AUROC:0.9926\n",
      "\n",
      "Epoch: [186 | 1000] LR: 0.191269\n",
      "Train | 16/16 | Loss:0.6731 | MainLoss:0.4898 | Alpha:0.3620 | SPLoss:1.7275 | CLSLoss:0.1057 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.5406 | MainLoss:0.5406 | SPLoss:1.7200 | CLSLoss:0.1078 | AUROC:0.8672\n",
      "Test | 128/16 | Loss:0.1820 | MainLoss:0.1820 | SPLoss:1.7200 | CLSLoss:0.1078 | AUROC:0.9996\n",
      "\n",
      "Epoch: [187 | 1000] LR: 0.191140\n",
      "Train | 16/16 | Loss:0.7705 | MainLoss:0.4795 | Alpha:0.3630 | SPLoss:2.7996 | CLSLoss:0.1109 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.4389 | MainLoss:0.4389 | SPLoss:6.1633 | CLSLoss:0.1310 | AUROC:0.8799\n",
      "Test | 128/16 | Loss:0.1364 | MainLoss:0.1364 | SPLoss:6.1633 | CLSLoss:0.1310 | AUROC:0.9986\n",
      "\n",
      "Epoch: [188 | 1000] LR: 0.191011\n",
      "Train | 16/16 | Loss:0.9578 | MainLoss:0.4693 | Alpha:0.3631 | SPLoss:4.7647 | CLSLoss:0.1205 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.4839 | MainLoss:0.4839 | SPLoss:3.4885 | CLSLoss:0.1311 | AUROC:0.8745\n",
      "Test | 128/16 | Loss:0.1463 | MainLoss:0.1463 | SPLoss:3.4885 | CLSLoss:0.1311 | AUROC:0.9985\n",
      "\n",
      "Epoch: [189 | 1000] LR: 0.190880\n",
      "Train | 16/16 | Loss:0.7759 | MainLoss:0.4830 | Alpha:0.3634 | SPLoss:2.8163 | CLSLoss:0.1132 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.5402 | MainLoss:0.5402 | SPLoss:2.1499 | CLSLoss:0.1040 | AUROC:0.8803\n",
      "Test | 128/16 | Loss:0.1406 | MainLoss:0.1406 | SPLoss:2.1499 | CLSLoss:0.1040 | AUROC:0.9982\n",
      "\n",
      "Epoch: [190 | 1000] LR: 0.190748\n",
      "Train | 16/16 | Loss:0.6702 | MainLoss:0.4840 | Alpha:0.3636 | SPLoss:1.7518 | CLSLoss:0.1107 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.4416 | MainLoss:0.4416 | SPLoss:1.3598 | CLSLoss:0.1086 | AUROC:0.8823\n",
      "Test | 128/16 | Loss:0.1520 | MainLoss:0.1520 | SPLoss:1.3598 | CLSLoss:0.1086 | AUROC:0.9986\n",
      "\n",
      "Epoch: [191 | 1000] LR: 0.190616\n",
      "Train | 16/16 | Loss:0.6259 | MainLoss:0.4938 | Alpha:0.3629 | SPLoss:1.2105 | CLSLoss:0.1108 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.4287 | MainLoss:0.4287 | SPLoss:1.0522 | CLSLoss:0.1289 | AUROC:0.8851\n",
      "Test | 128/16 | Loss:0.1335 | MainLoss:0.1335 | SPLoss:1.0522 | CLSLoss:0.1289 | AUROC:0.9982\n",
      "\n",
      "Epoch: [192 | 1000] LR: 0.190483\n",
      "Train | 16/16 | Loss:0.6072 | MainLoss:0.5008 | Alpha:0.3632 | SPLoss:0.9532 | CLSLoss:0.1104 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.4365 | MainLoss:0.4365 | SPLoss:0.8415 | CLSLoss:0.1280 | AUROC:0.8815\n",
      "Test | 128/16 | Loss:0.1279 | MainLoss:0.1279 | SPLoss:0.8415 | CLSLoss:0.1280 | AUROC:0.9984\n",
      "\n",
      "Epoch: [193 | 1000] LR: 0.190348\n",
      "Train | 16/16 | Loss:0.5585 | MainLoss:0.4612 | Alpha:0.3638 | SPLoss:0.8478 | CLSLoss:0.1249 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.4339 | MainLoss:0.4339 | SPLoss:0.7722 | CLSLoss:0.1417 | AUROC:0.8867\n",
      "Test | 128/16 | Loss:0.1420 | MainLoss:0.1420 | SPLoss:0.7722 | CLSLoss:0.1417 | AUROC:0.9979\n",
      "\n",
      "Epoch: [194 | 1000] LR: 0.190213\n",
      "Train | 16/16 | Loss:0.6112 | MainLoss:0.4938 | Alpha:0.3635 | SPLoss:1.0535 | CLSLoss:0.1203 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.4619 | MainLoss:0.4619 | SPLoss:3.2563 | CLSLoss:0.1299 | AUROC:0.8737\n",
      "Test | 128/16 | Loss:0.1419 | MainLoss:0.1419 | SPLoss:3.2563 | CLSLoss:0.1299 | AUROC:0.9988\n",
      "\n",
      "Epoch: [195 | 1000] LR: 0.190077\n",
      "Train | 16/16 | Loss:0.7301 | MainLoss:0.4570 | Alpha:0.3634 | SPLoss:2.5976 | CLSLoss:0.1329 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.6115 | MainLoss:0.6115 | SPLoss:1.9778 | CLSLoss:0.1168 | AUROC:0.8639\n",
      "Test | 128/16 | Loss:0.1742 | MainLoss:0.1742 | SPLoss:1.9778 | CLSLoss:0.1168 | AUROC:0.9956\n",
      "\n",
      "Epoch: [196 | 1000] LR: 0.189941\n",
      "Train | 16/16 | Loss:0.6785 | MainLoss:0.4962 | Alpha:0.3631 | SPLoss:1.7080 | CLSLoss:0.1152 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.4766 | MainLoss:0.4766 | SPLoss:1.8028 | CLSLoss:0.0761 | AUROC:0.8799\n",
      "Test | 128/16 | Loss:0.2437 | MainLoss:0.2437 | SPLoss:1.8028 | CLSLoss:0.0761 | AUROC:0.9960\n",
      "\n",
      "Epoch: [197 | 1000] LR: 0.189803\n",
      "Train | 16/16 | Loss:0.7034 | MainLoss:0.4448 | Alpha:0.3639 | SPLoss:2.4671 | CLSLoss:0.1190 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.5173 | MainLoss:0.5173 | SPLoss:1.9925 | CLSLoss:0.1156 | AUROC:0.8782\n",
      "Test | 128/16 | Loss:0.1294 | MainLoss:0.1294 | SPLoss:1.9925 | CLSLoss:0.1156 | AUROC:0.9983\n",
      "\n",
      "Epoch: [198 | 1000] LR: 0.189664\n",
      "Train | 16/16 | Loss:0.6541 | MainLoss:0.4790 | Alpha:0.3629 | SPLoss:1.6412 | CLSLoss:0.1101 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.4355 | MainLoss:0.4355 | SPLoss:1.2875 | CLSLoss:0.1194 | AUROC:0.8861\n",
      "Test | 128/16 | Loss:0.1300 | MainLoss:0.1300 | SPLoss:1.2875 | CLSLoss:0.1194 | AUROC:0.9983\n",
      "\n",
      "Epoch: [199 | 1000] LR: 0.189525\n",
      "Train | 16/16 | Loss:1.8602 | MainLoss:0.4878 | Alpha:0.3628 | SPLoss:13.6103 | CLSLoss:0.1142 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.4811 | MainLoss:0.4811 | SPLoss:15.5991 | CLSLoss:0.0885 | AUROC:0.8820\n",
      "Test | 128/16 | Loss:0.2352 | MainLoss:0.2352 | SPLoss:15.5991 | CLSLoss:0.0885 | AUROC:0.9965\n",
      "\n",
      "Epoch: [200 | 1000] LR: 0.189384\n",
      "Train | 16/16 | Loss:1.6717 | MainLoss:0.4846 | Alpha:0.3635 | SPLoss:11.7595 | CLSLoss:0.1110 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.5441 | MainLoss:0.5441 | SPLoss:8.3261 | CLSLoss:0.1314 | AUROC:0.8704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 128/16 | Loss:0.1161 | MainLoss:0.1161 | SPLoss:8.3261 | CLSLoss:0.1314 | AUROC:0.9984\n",
      "\n",
      "Epoch: [201 | 1000] LR: 0.018924\n",
      "Train | 16/16 | Loss:0.4338 | MainLoss:0.4197 | Alpha:0.3790 | SPLoss:0.0079 | CLSLoss:0.1338 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.4283 | MainLoss:0.4283 | SPLoss:0.0115 | CLSLoss:0.1400 | AUROC:0.8868\n",
      "Test | 128/16 | Loss:0.1179 | MainLoss:0.1179 | SPLoss:0.0115 | CLSLoss:0.1400 | AUROC:0.9984\n",
      "\n",
      "Epoch: [202 | 1000] LR: 0.018910\n",
      "Train | 16/16 | Loss:0.4117 | MainLoss:0.3958 | Alpha:0.3772 | SPLoss:0.0157 | CLSLoss:0.1442 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.4204 | MainLoss:0.4204 | SPLoss:0.0193 | CLSLoss:0.1462 | AUROC:0.8905\n",
      "Test | 128/16 | Loss:0.1089 | MainLoss:0.1089 | SPLoss:0.0193 | CLSLoss:0.1462 | AUROC:0.9985\n",
      "\n",
      "Epoch: [203 | 1000] LR: 0.018896\n",
      "Train | 16/16 | Loss:0.3944 | MainLoss:0.3770 | Alpha:0.3761 | SPLoss:0.0239 | CLSLoss:0.1498 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.4183 | MainLoss:0.4183 | SPLoss:0.0276 | CLSLoss:0.1518 | AUROC:0.8918\n",
      "Test | 128/16 | Loss:0.0985 | MainLoss:0.0985 | SPLoss:0.0276 | CLSLoss:0.1518 | AUROC:0.9986\n",
      "\n",
      "Epoch: [204 | 1000] LR: 0.018881\n",
      "Train | 16/16 | Loss:0.3947 | MainLoss:0.3759 | Alpha:0.3749 | SPLoss:0.0330 | CLSLoss:0.1542 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.4148 | MainLoss:0.4148 | SPLoss:0.0379 | CLSLoss:0.1536 | AUROC:0.8942\n",
      "Test | 128/16 | Loss:0.1006 | MainLoss:0.1006 | SPLoss:0.0379 | CLSLoss:0.1536 | AUROC:0.9986\n",
      "\n",
      "Epoch: [205 | 1000] LR: 0.018867\n",
      "Train | 16/16 | Loss:0.3898 | MainLoss:0.3701 | Alpha:0.3773 | SPLoss:0.0424 | CLSLoss:0.1552 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.4104 | MainLoss:0.4104 | SPLoss:0.0468 | CLSLoss:0.1543 | AUROC:0.8964\n",
      "Test | 128/16 | Loss:0.0959 | MainLoss:0.0959 | SPLoss:0.0468 | CLSLoss:0.1543 | AUROC:0.9987\n",
      "\n",
      "Epoch: [206 | 1000] LR: 0.018852\n",
      "Train | 16/16 | Loss:0.3730 | MainLoss:0.3522 | Alpha:0.3778 | SPLoss:0.0514 | CLSLoss:0.1564 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.4092 | MainLoss:0.4092 | SPLoss:0.0571 | CLSLoss:0.1599 | AUROC:0.8975\n",
      "Test | 128/16 | Loss:0.0922 | MainLoss:0.0922 | SPLoss:0.0571 | CLSLoss:0.1599 | AUROC:0.9988\n",
      "\n",
      "Epoch: [207 | 1000] LR: 0.018838\n",
      "Train | 16/16 | Loss:0.3893 | MainLoss:0.3672 | Alpha:0.3765 | SPLoss:0.0611 | CLSLoss:0.1598 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.4078 | MainLoss:0.4078 | SPLoss:0.0647 | CLSLoss:0.1571 | AUROC:0.8986\n",
      "Test | 128/16 | Loss:0.0888 | MainLoss:0.0888 | SPLoss:0.0647 | CLSLoss:0.1571 | AUROC:0.9989\n",
      "\n",
      "Epoch: [208 | 1000] LR: 0.018823\n",
      "Train | 16/16 | Loss:0.3943 | MainLoss:0.3716 | Alpha:0.3746 | SPLoss:0.0700 | CLSLoss:0.1568 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.4036 | MainLoss:0.4036 | SPLoss:0.0736 | CLSLoss:0.1554 | AUROC:0.9004\n",
      "Test | 128/16 | Loss:0.0918 | MainLoss:0.0918 | SPLoss:0.0736 | CLSLoss:0.1554 | AUROC:0.9988\n",
      "\n",
      "Epoch: [209 | 1000] LR: 0.018808\n",
      "Train | 16/16 | Loss:0.3851 | MainLoss:0.3615 | Alpha:0.3738 | SPLoss:0.0791 | CLSLoss:0.1563 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.4038 | MainLoss:0.4038 | SPLoss:0.0835 | CLSLoss:0.1572 | AUROC:0.9001\n",
      "Test | 128/16 | Loss:0.0915 | MainLoss:0.0915 | SPLoss:0.0835 | CLSLoss:0.1572 | AUROC:0.9988\n",
      "\n",
      "Epoch: [210 | 1000] LR: 0.018793\n",
      "Train | 16/16 | Loss:0.3701 | MainLoss:0.3454 | Alpha:0.3760 | SPLoss:0.0883 | CLSLoss:0.1585 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.4046 | MainLoss:0.4046 | SPLoss:0.0923 | CLSLoss:0.1609 | AUROC:0.9009\n",
      "Test | 128/16 | Loss:0.0861 | MainLoss:0.0861 | SPLoss:0.0923 | CLSLoss:0.1609 | AUROC:0.9989\n",
      "\n",
      "Epoch: [211 | 1000] LR: 0.018778\n",
      "Train | 16/16 | Loss:0.3765 | MainLoss:0.3506 | Alpha:0.3736 | SPLoss:0.0988 | CLSLoss:0.1602 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.4010 | MainLoss:0.4010 | SPLoss:0.1047 | CLSLoss:0.1597 | AUROC:0.9022\n",
      "Test | 128/16 | Loss:0.0917 | MainLoss:0.0917 | SPLoss:0.1047 | CLSLoss:0.1597 | AUROC:0.9988\n",
      "\n",
      "Epoch: [212 | 1000] LR: 0.018763\n",
      "Train | 16/16 | Loss:0.3617 | MainLoss:0.3346 | Alpha:0.3760 | SPLoss:0.1093 | CLSLoss:0.1612 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3988 | MainLoss:0.3988 | SPLoss:0.1156 | CLSLoss:0.1606 | AUROC:0.9035\n",
      "Test | 128/16 | Loss:0.0882 | MainLoss:0.0882 | SPLoss:0.1156 | CLSLoss:0.1606 | AUROC:0.9988\n",
      "\n",
      "Epoch: [213 | 1000] LR: 0.018748\n",
      "Train | 16/16 | Loss:0.3598 | MainLoss:0.3315 | Alpha:0.3766 | SPLoss:0.1205 | CLSLoss:0.1624 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3985 | MainLoss:0.3985 | SPLoss:0.1262 | CLSLoss:0.1620 | AUROC:0.9037\n",
      "Test | 128/16 | Loss:0.0875 | MainLoss:0.0875 | SPLoss:0.1262 | CLSLoss:0.1620 | AUROC:0.9989\n",
      "\n",
      "Epoch: [214 | 1000] LR: 0.018733\n",
      "Train | 16/16 | Loss:0.3638 | MainLoss:0.3345 | Alpha:0.3769 | SPLoss:0.1295 | CLSLoss:0.1633 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3996 | MainLoss:0.3996 | SPLoss:0.1341 | CLSLoss:0.1626 | AUROC:0.9039\n",
      "Test | 128/16 | Loss:0.0822 | MainLoss:0.0822 | SPLoss:0.1341 | CLSLoss:0.1626 | AUROC:0.9990\n",
      "\n",
      "Epoch: [215 | 1000] LR: 0.018717\n",
      "Train | 16/16 | Loss:0.3570 | MainLoss:0.3269 | Alpha:0.3794 | SPLoss:0.1380 | CLSLoss:0.1636 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3951 | MainLoss:0.3951 | SPLoss:0.1428 | CLSLoss:0.1626 | AUROC:0.9052\n",
      "Test | 128/16 | Loss:0.0840 | MainLoss:0.0840 | SPLoss:0.1428 | CLSLoss:0.1626 | AUROC:0.9990\n",
      "\n",
      "Epoch: [216 | 1000] LR: 0.018702\n",
      "Train | 16/16 | Loss:0.3598 | MainLoss:0.3288 | Alpha:0.3778 | SPLoss:0.1476 | CLSLoss:0.1625 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3951 | MainLoss:0.3951 | SPLoss:0.1519 | CLSLoss:0.1627 | AUROC:0.9055\n",
      "Test | 128/16 | Loss:0.0847 | MainLoss:0.0847 | SPLoss:0.1519 | CLSLoss:0.1627 | AUROC:0.9989\n",
      "\n",
      "Epoch: [217 | 1000] LR: 0.018686\n",
      "Train | 16/16 | Loss:0.3602 | MainLoss:0.3283 | Alpha:0.3767 | SPLoss:0.1566 | CLSLoss:0.1631 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3949 | MainLoss:0.3949 | SPLoss:0.1634 | CLSLoss:0.1630 | AUROC:0.9068\n",
      "Test | 128/16 | Loss:0.0879 | MainLoss:0.0879 | SPLoss:0.1634 | CLSLoss:0.1630 | AUROC:0.9989\n",
      "\n",
      "Epoch: [218 | 1000] LR: 0.018671\n",
      "Train | 16/16 | Loss:0.3530 | MainLoss:0.3200 | Alpha:0.3772 | SPLoss:0.1677 | CLSLoss:0.1625 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3928 | MainLoss:0.3928 | SPLoss:0.1731 | CLSLoss:0.1642 | AUROC:0.9081\n",
      "Test | 128/16 | Loss:0.0814 | MainLoss:0.0814 | SPLoss:0.1731 | CLSLoss:0.1642 | AUROC:0.9990\n",
      "\n",
      "Epoch: [219 | 1000] LR: 0.018655\n",
      "Train | 16/16 | Loss:0.3540 | MainLoss:0.3200 | Alpha:0.3793 | SPLoss:0.1767 | CLSLoss:0.1635 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3938 | MainLoss:0.3938 | SPLoss:0.1810 | CLSLoss:0.1638 | AUROC:0.9076\n",
      "Test | 128/16 | Loss:0.0811 | MainLoss:0.0811 | SPLoss:0.1810 | CLSLoss:0.1638 | AUROC:0.9990\n",
      "\n",
      "Epoch: [220 | 1000] LR: 0.018639\n",
      "Train | 16/16 | Loss:0.3500 | MainLoss:0.3151 | Alpha:0.3783 | SPLoss:0.1859 | CLSLoss:0.1638 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3933 | MainLoss:0.3933 | SPLoss:0.1933 | CLSLoss:0.1643 | AUROC:0.9080\n",
      "Test | 128/16 | Loss:0.0805 | MainLoss:0.0805 | SPLoss:0.1933 | CLSLoss:0.1643 | AUROC:0.9990\n",
      "\n",
      "Epoch: [221 | 1000] LR: 0.018623\n",
      "Train | 16/16 | Loss:0.3461 | MainLoss:0.3098 | Alpha:0.3777 | SPLoss:0.1983 | CLSLoss:0.1645 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3945 | MainLoss:0.3945 | SPLoss:0.2038 | CLSLoss:0.1647 | AUROC:0.9075\n",
      "Test | 128/16 | Loss:0.0768 | MainLoss:0.0768 | SPLoss:0.2038 | CLSLoss:0.1647 | AUROC:0.9991\n",
      "\n",
      "Epoch: [222 | 1000] LR: 0.018607\n",
      "Train | 16/16 | Loss:0.3681 | MainLoss:0.3311 | Alpha:0.3774 | SPLoss:0.2066 | CLSLoss:0.1626 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3890 | MainLoss:0.3890 | SPLoss:0.2108 | CLSLoss:0.1610 | AUROC:0.9089\n",
      "Test | 128/16 | Loss:0.0899 | MainLoss:0.0899 | SPLoss:0.2108 | CLSLoss:0.1610 | AUROC:0.9988\n",
      "\n",
      "Epoch: [223 | 1000] LR: 0.018591\n",
      "Train | 16/16 | Loss:0.3634 | MainLoss:0.3257 | Alpha:0.3755 | SPLoss:0.2152 | CLSLoss:0.1619 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3900 | MainLoss:0.3900 | SPLoss:0.2205 | CLSLoss:0.1600 | AUROC:0.9089\n",
      "Test | 128/16 | Loss:0.0823 | MainLoss:0.0823 | SPLoss:0.2205 | CLSLoss:0.1600 | AUROC:0.9990\n",
      "\n",
      "Epoch: [224 | 1000] LR: 0.018575\n",
      "Train | 16/16 | Loss:0.3482 | MainLoss:0.3097 | Alpha:0.3790 | SPLoss:0.2246 | CLSLoss:0.1612 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3895 | MainLoss:0.3895 | SPLoss:0.2301 | CLSLoss:0.1609 | AUROC:0.9091\n",
      "Test | 128/16 | Loss:0.0818 | MainLoss:0.0818 | SPLoss:0.2301 | CLSLoss:0.1609 | AUROC:0.9990\n",
      "\n",
      "Epoch: [225 | 1000] LR: 0.018559\n",
      "Train | 16/16 | Loss:0.3547 | MainLoss:0.3152 | Alpha:0.3760 | SPLoss:0.2346 | CLSLoss:0.1611 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3909 | MainLoss:0.3909 | SPLoss:0.2408 | CLSLoss:0.1598 | AUROC:0.9098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 128/16 | Loss:0.0875 | MainLoss:0.0875 | SPLoss:0.2408 | CLSLoss:0.1598 | AUROC:0.9990\n",
      "\n",
      "Epoch: [226 | 1000] LR: 0.018543\n",
      "Train | 16/16 | Loss:0.3484 | MainLoss:0.3080 | Alpha:0.3774 | SPLoss:0.2426 | CLSLoss:0.1613 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3918 | MainLoss:0.3918 | SPLoss:0.2451 | CLSLoss:0.1628 | AUROC:0.9098\n",
      "Test | 128/16 | Loss:0.0752 | MainLoss:0.0752 | SPLoss:0.2451 | CLSLoss:0.1628 | AUROC:0.9990\n",
      "\n",
      "Epoch: [227 | 1000] LR: 0.018526\n",
      "Train | 16/16 | Loss:0.3547 | MainLoss:0.3137 | Alpha:0.3767 | SPLoss:0.2489 | CLSLoss:0.1616 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3886 | MainLoss:0.3886 | SPLoss:0.2536 | CLSLoss:0.1618 | AUROC:0.9098\n",
      "Test | 128/16 | Loss:0.0789 | MainLoss:0.0789 | SPLoss:0.2536 | CLSLoss:0.1618 | AUROC:0.9990\n",
      "\n",
      "Epoch: [228 | 1000] LR: 0.018510\n",
      "Train | 16/16 | Loss:0.3653 | MainLoss:0.3236 | Alpha:0.3756 | SPLoss:0.2575 | CLSLoss:0.1597 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3870 | MainLoss:0.3870 | SPLoss:0.2621 | CLSLoss:0.1600 | AUROC:0.9099\n",
      "Test | 128/16 | Loss:0.0856 | MainLoss:0.0856 | SPLoss:0.2621 | CLSLoss:0.1600 | AUROC:0.9990\n",
      "\n",
      "Epoch: [229 | 1000] LR: 0.018493\n",
      "Train | 16/16 | Loss:0.3537 | MainLoss:0.3111 | Alpha:0.3759 | SPLoss:0.2654 | CLSLoss:0.1602 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3874 | MainLoss:0.3874 | SPLoss:0.2685 | CLSLoss:0.1613 | AUROC:0.9113\n",
      "Test | 128/16 | Loss:0.0796 | MainLoss:0.0796 | SPLoss:0.2685 | CLSLoss:0.1613 | AUROC:0.9988\n",
      "\n",
      "Epoch: [230 | 1000] LR: 0.018477\n",
      "Train | 16/16 | Loss:0.3591 | MainLoss:0.3159 | Alpha:0.3770 | SPLoss:0.2722 | CLSLoss:0.1598 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3893 | MainLoss:0.3893 | SPLoss:0.2742 | CLSLoss:0.1602 | AUROC:0.9119\n",
      "Test | 128/16 | Loss:0.0759 | MainLoss:0.0759 | SPLoss:0.2742 | CLSLoss:0.1602 | AUROC:0.9990\n",
      "\n",
      "Epoch: [231 | 1000] LR: 0.018460\n",
      "Train | 16/16 | Loss:0.3293 | MainLoss:0.2851 | Alpha:0.3795 | SPLoss:0.2800 | CLSLoss:0.1625 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3916 | MainLoss:0.3916 | SPLoss:0.2856 | CLSLoss:0.1658 | AUROC:0.9115\n",
      "Test | 128/16 | Loss:0.0751 | MainLoss:0.0751 | SPLoss:0.2856 | CLSLoss:0.1658 | AUROC:0.9989\n",
      "\n",
      "Epoch: [232 | 1000] LR: 0.018443\n",
      "Train | 16/16 | Loss:0.3443 | MainLoss:0.2987 | Alpha:0.3759 | SPLoss:0.2899 | CLSLoss:0.1654 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3886 | MainLoss:0.3886 | SPLoss:0.2949 | CLSLoss:0.1621 | AUROC:0.9108\n",
      "Test | 128/16 | Loss:0.0785 | MainLoss:0.0785 | SPLoss:0.2949 | CLSLoss:0.1621 | AUROC:0.9990\n",
      "\n",
      "Epoch: [233 | 1000] LR: 0.018426\n",
      "Train | 16/16 | Loss:0.3582 | MainLoss:0.3122 | Alpha:0.3772 | SPLoss:0.2990 | CLSLoss:0.1609 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3892 | MainLoss:0.3892 | SPLoss:0.3017 | CLSLoss:0.1599 | AUROC:0.9117\n",
      "Test | 128/16 | Loss:0.0750 | MainLoss:0.0750 | SPLoss:0.3017 | CLSLoss:0.1599 | AUROC:0.9992\n",
      "\n",
      "Epoch: [234 | 1000] LR: 0.018409\n",
      "Train | 16/16 | Loss:0.3552 | MainLoss:0.3088 | Alpha:0.3766 | SPLoss:0.3044 | CLSLoss:0.1599 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3858 | MainLoss:0.3858 | SPLoss:0.3076 | CLSLoss:0.1596 | AUROC:0.9113\n",
      "Test | 128/16 | Loss:0.0800 | MainLoss:0.0800 | SPLoss:0.3076 | CLSLoss:0.1596 | AUROC:0.9991\n",
      "\n",
      "Epoch: [235 | 1000] LR: 0.018392\n",
      "Train | 16/16 | Loss:0.3554 | MainLoss:0.3084 | Alpha:0.3775 | SPLoss:0.3114 | CLSLoss:0.1593 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3887 | MainLoss:0.3887 | SPLoss:0.3141 | CLSLoss:0.1580 | AUROC:0.9118\n",
      "Test | 128/16 | Loss:0.0765 | MainLoss:0.0765 | SPLoss:0.3141 | CLSLoss:0.1580 | AUROC:0.9991\n",
      "\n",
      "Epoch: [236 | 1000] LR: 0.018375\n",
      "Train | 16/16 | Loss:0.3470 | MainLoss:0.2994 | Alpha:0.3767 | SPLoss:0.3179 | CLSLoss:0.1589 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3872 | MainLoss:0.3872 | SPLoss:0.3236 | CLSLoss:0.1603 | AUROC:0.9117\n",
      "Test | 128/16 | Loss:0.0813 | MainLoss:0.0813 | SPLoss:0.3236 | CLSLoss:0.1603 | AUROC:0.9992\n",
      "\n",
      "Epoch: [237 | 1000] LR: 0.018358\n",
      "Train | 16/16 | Loss:0.3423 | MainLoss:0.2931 | Alpha:0.3783 | SPLoss:0.3292 | CLSLoss:0.1620 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3856 | MainLoss:0.3856 | SPLoss:0.3344 | CLSLoss:0.1611 | AUROC:0.9124\n",
      "Test | 128/16 | Loss:0.0789 | MainLoss:0.0789 | SPLoss:0.3344 | CLSLoss:0.1611 | AUROC:0.9991\n",
      "\n",
      "Epoch: [238 | 1000] LR: 0.018341\n",
      "Train | 16/16 | Loss:0.3567 | MainLoss:0.3068 | Alpha:0.3778 | SPLoss:0.3377 | CLSLoss:0.1608 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3847 | MainLoss:0.3847 | SPLoss:0.3386 | CLSLoss:0.1595 | AUROC:0.9125\n",
      "Test | 128/16 | Loss:0.0817 | MainLoss:0.0817 | SPLoss:0.3386 | CLSLoss:0.1595 | AUROC:0.9989\n",
      "\n",
      "Epoch: [239 | 1000] LR: 0.018323\n",
      "Train | 16/16 | Loss:0.3513 | MainLoss:0.3009 | Alpha:0.3755 | SPLoss:0.3430 | CLSLoss:0.1608 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3856 | MainLoss:0.3856 | SPLoss:0.3450 | CLSLoss:0.1588 | AUROC:0.9126\n",
      "Test | 128/16 | Loss:0.0749 | MainLoss:0.0749 | SPLoss:0.3450 | CLSLoss:0.1588 | AUROC:0.9991\n",
      "\n",
      "Epoch: [240 | 1000] LR: 0.018306\n",
      "Train | 16/16 | Loss:0.3500 | MainLoss:0.2992 | Alpha:0.3753 | SPLoss:0.3497 | CLSLoss:0.1584 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3993 | MainLoss:0.3993 | SPLoss:0.3557 | CLSLoss:0.1589 | AUROC:0.9104\n",
      "Test | 128/16 | Loss:0.0857 | MainLoss:0.0857 | SPLoss:0.3557 | CLSLoss:0.1589 | AUROC:0.9990\n",
      "\n",
      "Epoch: [241 | 1000] LR: 0.018288\n",
      "Train | 16/16 | Loss:0.3409 | MainLoss:0.2895 | Alpha:0.3783 | SPLoss:0.3537 | CLSLoss:0.1596 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3901 | MainLoss:0.3901 | SPLoss:0.3567 | CLSLoss:0.1608 | AUROC:0.9115\n",
      "Test | 128/16 | Loss:0.0756 | MainLoss:0.0756 | SPLoss:0.3567 | CLSLoss:0.1608 | AUROC:0.9990\n",
      "\n",
      "Epoch: [242 | 1000] LR: 0.018271\n",
      "Train | 16/16 | Loss:0.3548 | MainLoss:0.3030 | Alpha:0.3750 | SPLoss:0.3574 | CLSLoss:0.1603 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3864 | MainLoss:0.3864 | SPLoss:0.3595 | CLSLoss:0.1591 | AUROC:0.9131\n",
      "Test | 128/16 | Loss:0.0775 | MainLoss:0.0775 | SPLoss:0.3595 | CLSLoss:0.1591 | AUROC:0.9990\n",
      "\n",
      "Epoch: [243 | 1000] LR: 0.018253\n",
      "Train | 16/16 | Loss:0.3581 | MainLoss:0.3062 | Alpha:0.3758 | SPLoss:0.3613 | CLSLoss:0.1579 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3839 | MainLoss:0.3839 | SPLoss:0.3660 | CLSLoss:0.1580 | AUROC:0.9130\n",
      "Test | 128/16 | Loss:0.0774 | MainLoss:0.0774 | SPLoss:0.3660 | CLSLoss:0.1580 | AUROC:0.9990\n",
      "\n",
      "Epoch: [244 | 1000] LR: 0.018235\n",
      "Train | 16/16 | Loss:0.3481 | MainLoss:0.2954 | Alpha:0.3768 | SPLoss:0.3684 | CLSLoss:0.1589 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3872 | MainLoss:0.3872 | SPLoss:0.3713 | CLSLoss:0.1581 | AUROC:0.9126\n",
      "Test | 128/16 | Loss:0.0747 | MainLoss:0.0747 | SPLoss:0.3713 | CLSLoss:0.1581 | AUROC:0.9991\n",
      "\n",
      "Epoch: [245 | 1000] LR: 0.018217\n",
      "Train | 16/16 | Loss:0.3543 | MainLoss:0.3010 | Alpha:0.3771 | SPLoss:0.3740 | CLSLoss:0.1587 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3841 | MainLoss:0.3841 | SPLoss:0.3772 | CLSLoss:0.1571 | AUROC:0.9134\n",
      "Test | 128/16 | Loss:0.0751 | MainLoss:0.0751 | SPLoss:0.3772 | CLSLoss:0.1571 | AUROC:0.9992\n",
      "\n",
      "Epoch: [246 | 1000] LR: 0.018200\n",
      "Train | 16/16 | Loss:0.3528 | MainLoss:0.2991 | Alpha:0.3770 | SPLoss:0.3787 | CLSLoss:0.1581 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3849 | MainLoss:0.3849 | SPLoss:0.3798 | CLSLoss:0.1564 | AUROC:0.9128\n",
      "Test | 128/16 | Loss:0.0739 | MainLoss:0.0739 | SPLoss:0.3798 | CLSLoss:0.1564 | AUROC:0.9990\n",
      "\n",
      "Epoch: [247 | 1000] LR: 0.018181\n",
      "Train | 16/16 | Loss:0.3454 | MainLoss:0.2913 | Alpha:0.3773 | SPLoss:0.3840 | CLSLoss:0.1570 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3842 | MainLoss:0.3842 | SPLoss:0.3870 | CLSLoss:0.1580 | AUROC:0.9136\n",
      "Test | 128/16 | Loss:0.0763 | MainLoss:0.0763 | SPLoss:0.3870 | CLSLoss:0.1580 | AUROC:0.9989\n",
      "\n",
      "Epoch: [248 | 1000] LR: 0.018163\n",
      "Train | 16/16 | Loss:0.3417 | MainLoss:0.2868 | Alpha:0.3784 | SPLoss:0.3900 | CLSLoss:0.1591 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3913 | MainLoss:0.3913 | SPLoss:0.3913 | CLSLoss:0.1597 | AUROC:0.9128\n",
      "Test | 128/16 | Loss:0.0739 | MainLoss:0.0739 | SPLoss:0.3913 | CLSLoss:0.1597 | AUROC:0.9989\n",
      "\n",
      "Epoch: [249 | 1000] LR: 0.018145\n",
      "Train | 16/16 | Loss:0.3420 | MainLoss:0.2863 | Alpha:0.3751 | SPLoss:0.3963 | CLSLoss:0.1606 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3834 | MainLoss:0.3834 | SPLoss:0.3993 | CLSLoss:0.1610 | AUROC:0.9143\n",
      "Test | 128/16 | Loss:0.0772 | MainLoss:0.0772 | SPLoss:0.3993 | CLSLoss:0.1610 | AUROC:0.9988\n",
      "\n",
      "Epoch: [250 | 1000] LR: 0.018127\n",
      "Train | 16/16 | Loss:0.3426 | MainLoss:0.2863 | Alpha:0.3782 | SPLoss:0.4009 | CLSLoss:0.1623 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3858 | MainLoss:0.3858 | SPLoss:0.4067 | CLSLoss:0.1613 | AUROC:0.9135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 128/16 | Loss:0.0779 | MainLoss:0.0779 | SPLoss:0.4067 | CLSLoss:0.1613 | AUROC:0.9989\n",
      "\n",
      "Epoch: [251 | 1000] LR: 0.018109\n",
      "Train | 16/16 | Loss:0.3402 | MainLoss:0.2829 | Alpha:0.3775 | SPLoss:0.4103 | CLSLoss:0.1625 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3893 | MainLoss:0.3893 | SPLoss:0.4146 | CLSLoss:0.1625 | AUROC:0.9139\n",
      "Test | 128/16 | Loss:0.0790 | MainLoss:0.0790 | SPLoss:0.4146 | CLSLoss:0.1625 | AUROC:0.9989\n",
      "\n",
      "Epoch: [252 | 1000] LR: 0.018090\n",
      "Train | 16/16 | Loss:0.3484 | MainLoss:0.2908 | Alpha:0.3762 | SPLoss:0.4145 | CLSLoss:0.1616 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3873 | MainLoss:0.3873 | SPLoss:0.4187 | CLSLoss:0.1621 | AUROC:0.9128\n",
      "Test | 128/16 | Loss:0.0734 | MainLoss:0.0734 | SPLoss:0.4187 | CLSLoss:0.1621 | AUROC:0.9990\n",
      "\n",
      "Epoch: [253 | 1000] LR: 0.018072\n",
      "Train | 16/16 | Loss:0.3405 | MainLoss:0.2819 | Alpha:0.3777 | SPLoss:0.4212 | CLSLoss:0.1645 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3868 | MainLoss:0.3868 | SPLoss:0.4213 | CLSLoss:0.1643 | AUROC:0.9133\n",
      "Test | 128/16 | Loss:0.0708 | MainLoss:0.0708 | SPLoss:0.4213 | CLSLoss:0.1643 | AUROC:0.9991\n",
      "\n",
      "Epoch: [254 | 1000] LR: 0.018053\n",
      "Train | 16/16 | Loss:0.3367 | MainLoss:0.2778 | Alpha:0.3769 | SPLoss:0.4242 | CLSLoss:0.1656 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3908 | MainLoss:0.3908 | SPLoss:0.4288 | CLSLoss:0.1657 | AUROC:0.9131\n",
      "Test | 128/16 | Loss:0.0747 | MainLoss:0.0747 | SPLoss:0.4288 | CLSLoss:0.1657 | AUROC:0.9987\n",
      "\n",
      "Epoch: [255 | 1000] LR: 0.018034\n",
      "Train | 16/16 | Loss:0.3539 | MainLoss:0.2947 | Alpha:0.3773 | SPLoss:0.4292 | CLSLoss:0.1634 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3847 | MainLoss:0.3847 | SPLoss:0.4318 | CLSLoss:0.1617 | AUROC:0.9135\n",
      "Test | 128/16 | Loss:0.0729 | MainLoss:0.0729 | SPLoss:0.4318 | CLSLoss:0.1617 | AUROC:0.9990\n",
      "\n",
      "Epoch: [256 | 1000] LR: 0.018016\n",
      "Train | 16/16 | Loss:0.3573 | MainLoss:0.2978 | Alpha:0.3756 | SPLoss:0.4337 | CLSLoss:0.1612 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3861 | MainLoss:0.3861 | SPLoss:0.4352 | CLSLoss:0.1588 | AUROC:0.9135\n",
      "Test | 128/16 | Loss:0.0718 | MainLoss:0.0718 | SPLoss:0.4352 | CLSLoss:0.1588 | AUROC:0.9990\n",
      "\n",
      "Epoch: [257 | 1000] LR: 0.017997\n",
      "Train | 16/16 | Loss:0.3333 | MainLoss:0.2733 | Alpha:0.3784 | SPLoss:0.4383 | CLSLoss:0.1614 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3896 | MainLoss:0.3896 | SPLoss:0.4414 | CLSLoss:0.1632 | AUROC:0.9131\n",
      "Test | 128/16 | Loss:0.0751 | MainLoss:0.0751 | SPLoss:0.4414 | CLSLoss:0.1632 | AUROC:0.9991\n",
      "\n",
      "Epoch: [258 | 1000] LR: 0.017978\n",
      "Train | 16/16 | Loss:0.3404 | MainLoss:0.2799 | Alpha:0.3789 | SPLoss:0.4420 | CLSLoss:0.1633 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3899 | MainLoss:0.3899 | SPLoss:0.4452 | CLSLoss:0.1630 | AUROC:0.9127\n",
      "Test | 128/16 | Loss:0.0655 | MainLoss:0.0655 | SPLoss:0.4452 | CLSLoss:0.1630 | AUROC:0.9992\n",
      "\n",
      "Epoch: [259 | 1000] LR: 0.017959\n",
      "Train | 16/16 | Loss:0.3425 | MainLoss:0.2818 | Alpha:0.3779 | SPLoss:0.4443 | CLSLoss:0.1633 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3847 | MainLoss:0.3847 | SPLoss:0.4464 | CLSLoss:0.1616 | AUROC:0.9136\n",
      "Test | 128/16 | Loss:0.0700 | MainLoss:0.0700 | SPLoss:0.4464 | CLSLoss:0.1616 | AUROC:0.9991\n",
      "\n",
      "Epoch: [260 | 1000] LR: 0.017940\n",
      "Train | 16/16 | Loss:0.3421 | MainLoss:0.2811 | Alpha:0.3755 | SPLoss:0.4478 | CLSLoss:0.1620 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3867 | MainLoss:0.3867 | SPLoss:0.4484 | CLSLoss:0.1623 | AUROC:0.9147\n",
      "Test | 128/16 | Loss:0.0699 | MainLoss:0.0699 | SPLoss:0.4484 | CLSLoss:0.1623 | AUROC:0.9989\n",
      "\n",
      "Epoch: [261 | 1000] LR: 0.017921\n",
      "Train | 16/16 | Loss:0.3315 | MainLoss:0.2699 | Alpha:0.3797 | SPLoss:0.4521 | CLSLoss:0.1637 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3891 | MainLoss:0.3891 | SPLoss:0.4540 | CLSLoss:0.1644 | AUROC:0.9133\n",
      "Test | 128/16 | Loss:0.0735 | MainLoss:0.0735 | SPLoss:0.4540 | CLSLoss:0.1644 | AUROC:0.9989\n",
      "\n",
      "Epoch: [262 | 1000] LR: 0.017902\n",
      "Train | 16/16 | Loss:0.3500 | MainLoss:0.2879 | Alpha:0.3768 | SPLoss:0.4569 | CLSLoss:0.1641 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3875 | MainLoss:0.3875 | SPLoss:0.4590 | CLSLoss:0.1614 | AUROC:0.9138\n",
      "Test | 128/16 | Loss:0.0707 | MainLoss:0.0707 | SPLoss:0.4590 | CLSLoss:0.1614 | AUROC:0.9990\n",
      "\n",
      "Epoch: [263 | 1000] LR: 0.017882\n",
      "Train | 16/16 | Loss:0.3542 | MainLoss:0.2919 | Alpha:0.3750 | SPLoss:0.4617 | CLSLoss:0.1611 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3826 | MainLoss:0.3826 | SPLoss:0.4622 | CLSLoss:0.1589 | AUROC:0.9149\n",
      "Test | 128/16 | Loss:0.0712 | MainLoss:0.0712 | SPLoss:0.4622 | CLSLoss:0.1589 | AUROC:0.9991\n",
      "\n",
      "Epoch: [264 | 1000] LR: 0.017863\n",
      "Train | 16/16 | Loss:0.3325 | MainLoss:0.2701 | Alpha:0.3787 | SPLoss:0.4647 | CLSLoss:0.1602 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3874 | MainLoss:0.3874 | SPLoss:0.4663 | CLSLoss:0.1621 | AUROC:0.9145\n",
      "Test | 128/16 | Loss:0.0683 | MainLoss:0.0683 | SPLoss:0.4663 | CLSLoss:0.1621 | AUROC:0.9991\n",
      "\n",
      "Epoch: [265 | 1000] LR: 0.017843\n",
      "Train | 16/16 | Loss:0.3601 | MainLoss:0.2973 | Alpha:0.3762 | SPLoss:0.4686 | CLSLoss:0.1599 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3875 | MainLoss:0.3875 | SPLoss:0.4679 | CLSLoss:0.1585 | AUROC:0.9147\n",
      "Test | 128/16 | Loss:0.0692 | MainLoss:0.0692 | SPLoss:0.4679 | CLSLoss:0.1585 | AUROC:0.9990\n",
      "\n",
      "Epoch: [266 | 1000] LR: 0.017824\n",
      "Train | 16/16 | Loss:0.3416 | MainLoss:0.2784 | Alpha:0.3773 | SPLoss:0.4720 | CLSLoss:0.1600 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3849 | MainLoss:0.3849 | SPLoss:0.4749 | CLSLoss:0.1603 | AUROC:0.9143\n",
      "Test | 128/16 | Loss:0.0780 | MainLoss:0.0780 | SPLoss:0.4749 | CLSLoss:0.1603 | AUROC:0.9989\n",
      "\n",
      "Epoch: [267 | 1000] LR: 0.017804\n",
      "Train | 16/16 | Loss:0.3632 | MainLoss:0.2997 | Alpha:0.3752 | SPLoss:0.4756 | CLSLoss:0.1596 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3859 | MainLoss:0.3859 | SPLoss:0.4762 | CLSLoss:0.1554 | AUROC:0.9136\n",
      "Test | 128/16 | Loss:0.0810 | MainLoss:0.0810 | SPLoss:0.4762 | CLSLoss:0.1554 | AUROC:0.9991\n",
      "\n",
      "Epoch: [268 | 1000] LR: 0.017785\n",
      "Train | 16/16 | Loss:0.3543 | MainLoss:0.2910 | Alpha:0.3756 | SPLoss:0.4769 | CLSLoss:0.1562 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3837 | MainLoss:0.3837 | SPLoss:0.4788 | CLSLoss:0.1561 | AUROC:0.9135\n",
      "Test | 128/16 | Loss:0.0722 | MainLoss:0.0722 | SPLoss:0.4788 | CLSLoss:0.1561 | AUROC:0.9993\n",
      "\n",
      "Epoch: [269 | 1000] LR: 0.017765\n",
      "Train | 16/16 | Loss:0.3484 | MainLoss:0.2847 | Alpha:0.3746 | SPLoss:0.4804 | CLSLoss:0.1572 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3840 | MainLoss:0.3840 | SPLoss:0.4811 | CLSLoss:0.1576 | AUROC:0.9151\n",
      "Test | 128/16 | Loss:0.0790 | MainLoss:0.0790 | SPLoss:0.4811 | CLSLoss:0.1576 | AUROC:0.9991\n",
      "\n",
      "Epoch: [270 | 1000] LR: 0.017745\n",
      "Train | 16/16 | Loss:0.3378 | MainLoss:0.2737 | Alpha:0.3774 | SPLoss:0.4827 | CLSLoss:0.1588 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3877 | MainLoss:0.3877 | SPLoss:0.4866 | CLSLoss:0.1599 | AUROC:0.9147\n",
      "Test | 128/16 | Loss:0.0761 | MainLoss:0.0761 | SPLoss:0.4866 | CLSLoss:0.1599 | AUROC:0.9991\n",
      "\n",
      "Epoch: [271 | 1000] LR: 0.017725\n",
      "Train | 16/16 | Loss:0.3446 | MainLoss:0.2801 | Alpha:0.3776 | SPLoss:0.4861 | CLSLoss:0.1594 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3871 | MainLoss:0.3871 | SPLoss:0.4850 | CLSLoss:0.1598 | AUROC:0.9142\n",
      "Test | 128/16 | Loss:0.0757 | MainLoss:0.0757 | SPLoss:0.4850 | CLSLoss:0.1598 | AUROC:0.9989\n",
      "\n",
      "Epoch: [272 | 1000] LR: 0.017705\n",
      "Train | 16/16 | Loss:0.3387 | MainLoss:0.2741 | Alpha:0.3768 | SPLoss:0.4866 | CLSLoss:0.1594 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3861 | MainLoss:0.3861 | SPLoss:0.4864 | CLSLoss:0.1609 | AUROC:0.9147\n",
      "Test | 128/16 | Loss:0.0740 | MainLoss:0.0740 | SPLoss:0.4864 | CLSLoss:0.1609 | AUROC:0.9990\n",
      "\n",
      "Epoch: [273 | 1000] LR: 0.017685\n",
      "Train | 16/16 | Loss:0.3513 | MainLoss:0.2866 | Alpha:0.3774 | SPLoss:0.4875 | CLSLoss:0.1592 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3818 | MainLoss:0.3818 | SPLoss:0.4897 | CLSLoss:0.1587 | AUROC:0.9157\n",
      "Test | 128/16 | Loss:0.0792 | MainLoss:0.0792 | SPLoss:0.4897 | CLSLoss:0.1587 | AUROC:0.9989\n",
      "\n",
      "Epoch: [274 | 1000] LR: 0.017665\n",
      "Train | 16/16 | Loss:0.3335 | MainLoss:0.2683 | Alpha:0.3774 | SPLoss:0.4922 | CLSLoss:0.1598 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3871 | MainLoss:0.3871 | SPLoss:0.4967 | CLSLoss:0.1612 | AUROC:0.9148\n",
      "Test | 128/16 | Loss:0.0735 | MainLoss:0.0735 | SPLoss:0.4967 | CLSLoss:0.1612 | AUROC:0.9989\n",
      "\n",
      "Epoch: [275 | 1000] LR: 0.017645\n",
      "Train | 16/16 | Loss:0.3220 | MainLoss:0.2559 | Alpha:0.3794 | SPLoss:0.4985 | CLSLoss:0.1626 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3921 | MainLoss:0.3921 | SPLoss:0.5046 | CLSLoss:0.1633 | AUROC:0.9136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 128/16 | Loss:0.0779 | MainLoss:0.0779 | SPLoss:0.5046 | CLSLoss:0.1633 | AUROC:0.9989\n",
      "\n",
      "Epoch: [276 | 1000] LR: 0.017624\n",
      "Train | 16/16 | Loss:0.3467 | MainLoss:0.2802 | Alpha:0.3772 | SPLoss:0.5042 | CLSLoss:0.1611 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3905 | MainLoss:0.3905 | SPLoss:0.5071 | CLSLoss:0.1613 | AUROC:0.9139\n",
      "Test | 128/16 | Loss:0.0761 | MainLoss:0.0761 | SPLoss:0.5071 | CLSLoss:0.1613 | AUROC:0.9989\n",
      "\n",
      "Epoch: [277 | 1000] LR: 0.017604\n",
      "Train | 16/16 | Loss:0.3422 | MainLoss:0.2755 | Alpha:0.3773 | SPLoss:0.5065 | CLSLoss:0.1607 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3870 | MainLoss:0.3870 | SPLoss:0.5080 | CLSLoss:0.1599 | AUROC:0.9153\n",
      "Test | 128/16 | Loss:0.0710 | MainLoss:0.0710 | SPLoss:0.5080 | CLSLoss:0.1599 | AUROC:0.9989\n",
      "\n",
      "Epoch: [278 | 1000] LR: 0.017584\n",
      "Train | 16/16 | Loss:0.3366 | MainLoss:0.2695 | Alpha:0.3779 | SPLoss:0.5108 | CLSLoss:0.1602 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3857 | MainLoss:0.3857 | SPLoss:0.5132 | CLSLoss:0.1607 | AUROC:0.9140\n",
      "Test | 128/16 | Loss:0.0731 | MainLoss:0.0731 | SPLoss:0.5132 | CLSLoss:0.1607 | AUROC:0.9990\n",
      "\n",
      "Epoch: [279 | 1000] LR: 0.017563\n",
      "Train | 16/16 | Loss:0.3612 | MainLoss:0.2940 | Alpha:0.3756 | SPLoss:0.5123 | CLSLoss:0.1593 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3850 | MainLoss:0.3850 | SPLoss:0.5118 | CLSLoss:0.1592 | AUROC:0.9142\n",
      "Test | 128/16 | Loss:0.0698 | MainLoss:0.0698 | SPLoss:0.5118 | CLSLoss:0.1592 | AUROC:0.9990\n",
      "\n",
      "Epoch: [280 | 1000] LR: 0.017543\n",
      "Train | 16/16 | Loss:0.3629 | MainLoss:0.2960 | Alpha:0.3758 | SPLoss:0.5107 | CLSLoss:0.1579 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3855 | MainLoss:0.3855 | SPLoss:0.5125 | CLSLoss:0.1577 | AUROC:0.9138\n",
      "Test | 128/16 | Loss:0.0724 | MainLoss:0.0724 | SPLoss:0.5125 | CLSLoss:0.1577 | AUROC:0.9991\n",
      "\n",
      "Epoch: [281 | 1000] LR: 0.017522\n",
      "Train | 16/16 | Loss:0.3482 | MainLoss:0.2810 | Alpha:0.3760 | SPLoss:0.5136 | CLSLoss:0.1585 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3852 | MainLoss:0.3852 | SPLoss:0.5149 | CLSLoss:0.1588 | AUROC:0.9148\n",
      "Test | 128/16 | Loss:0.0712 | MainLoss:0.0712 | SPLoss:0.5149 | CLSLoss:0.1588 | AUROC:0.9992\n",
      "\n",
      "Epoch: [282 | 1000] LR: 0.017501\n",
      "Train | 16/16 | Loss:0.3332 | MainLoss:0.2657 | Alpha:0.3778 | SPLoss:0.5154 | CLSLoss:0.1597 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3951 | MainLoss:0.3951 | SPLoss:0.5181 | CLSLoss:0.1618 | AUROC:0.9137\n",
      "Test | 128/16 | Loss:0.0668 | MainLoss:0.0668 | SPLoss:0.5181 | CLSLoss:0.1618 | AUROC:0.9991\n",
      "\n",
      "Epoch: [283 | 1000] LR: 0.017480\n",
      "Train | 16/16 | Loss:0.3502 | MainLoss:0.2826 | Alpha:0.3767 | SPLoss:0.5174 | CLSLoss:0.1596 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3912 | MainLoss:0.3912 | SPLoss:0.5163 | CLSLoss:0.1592 | AUROC:0.9146\n",
      "Test | 128/16 | Loss:0.0656 | MainLoss:0.0656 | SPLoss:0.5163 | CLSLoss:0.1592 | AUROC:0.9993\n",
      "\n",
      "Epoch: [284 | 1000] LR: 0.017459\n",
      "Train | 16/16 | Loss:0.3355 | MainLoss:0.2677 | Alpha:0.3781 | SPLoss:0.5176 | CLSLoss:0.1600 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3891 | MainLoss:0.3891 | SPLoss:0.5196 | CLSLoss:0.1594 | AUROC:0.9139\n",
      "Test | 128/16 | Loss:0.0666 | MainLoss:0.0666 | SPLoss:0.5196 | CLSLoss:0.1594 | AUROC:0.9993\n",
      "\n",
      "Epoch: [285 | 1000] LR: 0.017438\n",
      "Train | 16/16 | Loss:0.3410 | MainLoss:0.2729 | Alpha:0.3788 | SPLoss:0.5210 | CLSLoss:0.1604 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3894 | MainLoss:0.3894 | SPLoss:0.5201 | CLSLoss:0.1599 | AUROC:0.9135\n",
      "Test | 128/16 | Loss:0.0670 | MainLoss:0.0670 | SPLoss:0.5201 | CLSLoss:0.1599 | AUROC:0.9994\n",
      "\n",
      "Epoch: [286 | 1000] LR: 0.017417\n",
      "Train | 16/16 | Loss:0.3542 | MainLoss:0.2862 | Alpha:0.3748 | SPLoss:0.5218 | CLSLoss:0.1582 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3836 | MainLoss:0.3836 | SPLoss:0.5229 | CLSLoss:0.1593 | AUROC:0.9154\n",
      "Test | 128/16 | Loss:0.0708 | MainLoss:0.0708 | SPLoss:0.5229 | CLSLoss:0.1593 | AUROC:0.9992\n",
      "\n",
      "Epoch: [287 | 1000] LR: 0.017396\n",
      "Train | 16/16 | Loss:0.3409 | MainLoss:0.2727 | Alpha:0.3781 | SPLoss:0.5224 | CLSLoss:0.1593 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3882 | MainLoss:0.3882 | SPLoss:0.5222 | CLSLoss:0.1603 | AUROC:0.9152\n",
      "Test | 128/16 | Loss:0.0735 | MainLoss:0.0735 | SPLoss:0.5222 | CLSLoss:0.1603 | AUROC:0.9992\n",
      "\n",
      "Epoch: [288 | 1000] LR: 0.017375\n",
      "Train | 16/16 | Loss:0.3235 | MainLoss:0.2547 | Alpha:0.3799 | SPLoss:0.5268 | CLSLoss:0.1614 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3898 | MainLoss:0.3898 | SPLoss:0.5299 | CLSLoss:0.1628 | AUROC:0.9146\n",
      "Test | 128/16 | Loss:0.0697 | MainLoss:0.0697 | SPLoss:0.5299 | CLSLoss:0.1628 | AUROC:0.9992\n",
      "\n",
      "Epoch: [289 | 1000] LR: 0.017354\n",
      "Train | 16/16 | Loss:0.3368 | MainLoss:0.2672 | Alpha:0.3747 | SPLoss:0.5329 | CLSLoss:0.1632 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3892 | MainLoss:0.3892 | SPLoss:0.5377 | CLSLoss:0.1617 | AUROC:0.9145\n",
      "Test | 128/16 | Loss:0.0785 | MainLoss:0.0785 | SPLoss:0.5377 | CLSLoss:0.1617 | AUROC:0.9991\n",
      "\n",
      "Epoch: [290 | 1000] LR: 0.017333\n",
      "Train | 16/16 | Loss:0.3352 | MainLoss:0.2654 | Alpha:0.3780 | SPLoss:0.5369 | CLSLoss:0.1616 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3891 | MainLoss:0.3891 | SPLoss:0.5378 | CLSLoss:0.1631 | AUROC:0.9147\n",
      "Test | 128/16 | Loss:0.0690 | MainLoss:0.0690 | SPLoss:0.5378 | CLSLoss:0.1631 | AUROC:0.9992\n",
      "\n",
      "Epoch: [291 | 1000] LR: 0.017311\n",
      "Train | 16/16 | Loss:0.3451 | MainLoss:0.2748 | Alpha:0.3749 | SPLoss:0.5406 | CLSLoss:0.1621 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3918 | MainLoss:0.3918 | SPLoss:0.5409 | CLSLoss:0.1610 | AUROC:0.9140\n",
      "Test | 128/16 | Loss:0.0731 | MainLoss:0.0731 | SPLoss:0.5409 | CLSLoss:0.1610 | AUROC:0.9990\n",
      "\n",
      "Epoch: [292 | 1000] LR: 0.017290\n",
      "Train | 16/16 | Loss:0.3394 | MainLoss:0.2692 | Alpha:0.3778 | SPLoss:0.5425 | CLSLoss:0.1596 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3930 | MainLoss:0.3930 | SPLoss:0.5438 | CLSLoss:0.1599 | AUROC:0.9145\n",
      "Test | 128/16 | Loss:0.0680 | MainLoss:0.0680 | SPLoss:0.5438 | CLSLoss:0.1599 | AUROC:0.9991\n",
      "\n",
      "Epoch: [293 | 1000] LR: 0.017268\n",
      "Train | 16/16 | Loss:0.3421 | MainLoss:0.2716 | Alpha:0.3787 | SPLoss:0.5443 | CLSLoss:0.1602 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3978 | MainLoss:0.3978 | SPLoss:0.5410 | CLSLoss:0.1577 | AUROC:0.9147\n",
      "Test | 128/16 | Loss:0.0669 | MainLoss:0.0669 | SPLoss:0.5410 | CLSLoss:0.1577 | AUROC:0.9990\n",
      "\n",
      "Epoch: [294 | 1000] LR: 0.017247\n",
      "Train | 16/16 | Loss:0.3294 | MainLoss:0.2591 | Alpha:0.3784 | SPLoss:0.5441 | CLSLoss:0.1590 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3902 | MainLoss:0.3902 | SPLoss:0.5480 | CLSLoss:0.1618 | AUROC:0.9152\n",
      "Test | 128/16 | Loss:0.0779 | MainLoss:0.0779 | SPLoss:0.5480 | CLSLoss:0.1618 | AUROC:0.9989\n",
      "\n",
      "Epoch: [295 | 1000] LR: 0.017225\n",
      "Train | 16/16 | Loss:0.3464 | MainLoss:0.2755 | Alpha:0.3752 | SPLoss:0.5491 | CLSLoss:0.1597 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3875 | MainLoss:0.3875 | SPLoss:0.5496 | CLSLoss:0.1595 | AUROC:0.9153\n",
      "Test | 128/16 | Loss:0.0728 | MainLoss:0.0728 | SPLoss:0.5496 | CLSLoss:0.1595 | AUROC:0.9988\n",
      "\n",
      "Epoch: [296 | 1000] LR: 0.017203\n",
      "Train | 16/16 | Loss:0.3445 | MainLoss:0.2737 | Alpha:0.3788 | SPLoss:0.5486 | CLSLoss:0.1587 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3871 | MainLoss:0.3871 | SPLoss:0.5479 | CLSLoss:0.1598 | AUROC:0.9151\n",
      "Test | 128/16 | Loss:0.0839 | MainLoss:0.0839 | SPLoss:0.5479 | CLSLoss:0.1598 | AUROC:0.9987\n",
      "\n",
      "Epoch: [297 | 1000] LR: 0.017181\n",
      "Train | 16/16 | Loss:0.3374 | MainLoss:0.2665 | Alpha:0.3756 | SPLoss:0.5484 | CLSLoss:0.1603 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3894 | MainLoss:0.3894 | SPLoss:0.5509 | CLSLoss:0.1615 | AUROC:0.9148\n",
      "Test | 128/16 | Loss:0.0714 | MainLoss:0.0714 | SPLoss:0.5509 | CLSLoss:0.1615 | AUROC:0.9989\n",
      "\n",
      "Epoch: [298 | 1000] LR: 0.017159\n",
      "Train | 16/16 | Loss:0.3467 | MainLoss:0.2753 | Alpha:0.3771 | SPLoss:0.5536 | CLSLoss:0.1611 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3885 | MainLoss:0.3885 | SPLoss:0.5534 | CLSLoss:0.1594 | AUROC:0.9135\n",
      "Test | 128/16 | Loss:0.0738 | MainLoss:0.0738 | SPLoss:0.5534 | CLSLoss:0.1594 | AUROC:0.9990\n",
      "\n",
      "Epoch: [299 | 1000] LR: 0.017137\n",
      "Train | 16/16 | Loss:0.3412 | MainLoss:0.2698 | Alpha:0.3773 | SPLoss:0.5547 | CLSLoss:0.1589 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3867 | MainLoss:0.3867 | SPLoss:0.5588 | CLSLoss:0.1610 | AUROC:0.9148\n",
      "Test | 128/16 | Loss:0.0750 | MainLoss:0.0750 | SPLoss:0.5588 | CLSLoss:0.1610 | AUROC:0.9990\n",
      "\n",
      "Epoch: [300 | 1000] LR: 0.017115\n",
      "Train | 16/16 | Loss:0.3249 | MainLoss:0.2524 | Alpha:0.3803 | SPLoss:0.5618 | CLSLoss:0.1625 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3923 | MainLoss:0.3923 | SPLoss:0.5626 | CLSLoss:0.1646 | AUROC:0.9140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 128/16 | Loss:0.0707 | MainLoss:0.0707 | SPLoss:0.5626 | CLSLoss:0.1646 | AUROC:0.9991\n",
      "\n",
      "Epoch: [301 | 1000] LR: 0.017093\n",
      "Train | 16/16 | Loss:0.2736 | MainLoss:0.2568 | Alpha:0.4400 | SPLoss:0.0027 | CLSLoss:0.1654 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3923 | MainLoss:0.3923 | SPLoss:0.0053 | CLSLoss:0.1643 | AUROC:0.9139\n",
      "Test | 128/16 | Loss:0.0755 | MainLoss:0.0755 | SPLoss:0.0053 | CLSLoss:0.1643 | AUROC:0.9990\n",
      "\n",
      "Epoch: [302 | 1000] LR: 0.017071\n",
      "Train | 16/16 | Loss:0.2842 | MainLoss:0.2671 | Alpha:0.4355 | SPLoss:0.0080 | CLSLoss:0.1627 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3928 | MainLoss:0.3928 | SPLoss:0.0108 | CLSLoss:0.1624 | AUROC:0.9149\n",
      "Test | 128/16 | Loss:0.0658 | MainLoss:0.0658 | SPLoss:0.0108 | CLSLoss:0.1624 | AUROC:0.9991\n",
      "\n",
      "Epoch: [303 | 1000] LR: 0.017049\n",
      "Train | 16/16 | Loss:0.2987 | MainLoss:0.2813 | Alpha:0.4334 | SPLoss:0.0135 | CLSLoss:0.1596 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3864 | MainLoss:0.3864 | SPLoss:0.0162 | CLSLoss:0.1576 | AUROC:0.9150\n",
      "Test | 128/16 | Loss:0.0717 | MainLoss:0.0717 | SPLoss:0.0162 | CLSLoss:0.1576 | AUROC:0.9990\n",
      "\n",
      "Epoch: [304 | 1000] LR: 0.017026\n",
      "Train | 16/16 | Loss:0.2637 | MainLoss:0.2460 | Alpha:0.4408 | SPLoss:0.0186 | CLSLoss:0.1586 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3920 | MainLoss:0.3920 | SPLoss:0.0209 | CLSLoss:0.1613 | AUROC:0.9170\n",
      "Test | 128/16 | Loss:0.0716 | MainLoss:0.0716 | SPLoss:0.0209 | CLSLoss:0.1613 | AUROC:0.9989\n",
      "\n",
      "Epoch: [305 | 1000] LR: 0.017004\n",
      "Train | 16/16 | Loss:0.2788 | MainLoss:0.2605 | Alpha:0.4369 | SPLoss:0.0236 | CLSLoss:0.1594 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3847 | MainLoss:0.3847 | SPLoss:0.0270 | CLSLoss:0.1573 | AUROC:0.9186\n",
      "Test | 128/16 | Loss:0.0726 | MainLoss:0.0726 | SPLoss:0.0270 | CLSLoss:0.1573 | AUROC:0.9989\n",
      "\n",
      "Epoch: [306 | 1000] LR: 0.016982\n",
      "Train | 16/16 | Loss:0.2765 | MainLoss:0.2578 | Alpha:0.4366 | SPLoss:0.0304 | CLSLoss:0.1567 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3829 | MainLoss:0.3829 | SPLoss:0.0339 | CLSLoss:0.1569 | AUROC:0.9186\n",
      "Test | 128/16 | Loss:0.0766 | MainLoss:0.0766 | SPLoss:0.0339 | CLSLoss:0.1569 | AUROC:0.9989\n",
      "\n",
      "Epoch: [307 | 1000] LR: 0.016959\n",
      "Train | 16/16 | Loss:0.2665 | MainLoss:0.2470 | Alpha:0.4383 | SPLoss:0.0369 | CLSLoss:0.1581 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3859 | MainLoss:0.3859 | SPLoss:0.0397 | CLSLoss:0.1566 | AUROC:0.9188\n",
      "Test | 128/16 | Loss:0.0772 | MainLoss:0.0772 | SPLoss:0.0397 | CLSLoss:0.1566 | AUROC:0.9990\n",
      "\n",
      "Epoch: [308 | 1000] LR: 0.016937\n",
      "Train | 16/16 | Loss:0.2785 | MainLoss:0.2586 | Alpha:0.4360 | SPLoss:0.0428 | CLSLoss:0.1559 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3828 | MainLoss:0.3828 | SPLoss:0.0455 | CLSLoss:0.1554 | AUROC:0.9185\n",
      "Test | 128/16 | Loss:0.0717 | MainLoss:0.0717 | SPLoss:0.0455 | CLSLoss:0.1554 | AUROC:0.9990\n",
      "\n",
      "Epoch: [309 | 1000] LR: 0.016914\n",
      "Train | 16/16 | Loss:0.2687 | MainLoss:0.2483 | Alpha:0.4382 | SPLoss:0.0481 | CLSLoss:0.1560 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3880 | MainLoss:0.3880 | SPLoss:0.0506 | CLSLoss:0.1556 | AUROC:0.9186\n",
      "Test | 128/16 | Loss:0.0661 | MainLoss:0.0661 | SPLoss:0.0506 | CLSLoss:0.1556 | AUROC:0.9991\n",
      "\n",
      "Epoch: [310 | 1000] LR: 0.016891\n",
      "Train | 16/16 | Loss:0.2516 | MainLoss:0.2305 | Alpha:0.4415 | SPLoss:0.0534 | CLSLoss:0.1570 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3929 | MainLoss:0.3929 | SPLoss:0.0563 | CLSLoss:0.1565 | AUROC:0.9174\n",
      "Test | 128/16 | Loss:0.0692 | MainLoss:0.0692 | SPLoss:0.0563 | CLSLoss:0.1565 | AUROC:0.9991\n",
      "\n",
      "Epoch: [311 | 1000] LR: 0.016868\n",
      "Train | 16/16 | Loss:0.2711 | MainLoss:0.2496 | Alpha:0.4363 | SPLoss:0.0596 | CLSLoss:0.1549 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3897 | MainLoss:0.3897 | SPLoss:0.0627 | CLSLoss:0.1543 | AUROC:0.9194\n",
      "Test | 128/16 | Loss:0.0644 | MainLoss:0.0644 | SPLoss:0.0627 | CLSLoss:0.1543 | AUROC:0.9992\n",
      "\n",
      "Epoch: [312 | 1000] LR: 0.016845\n",
      "Train | 16/16 | Loss:0.2856 | MainLoss:0.2639 | Alpha:0.4332 | SPLoss:0.0660 | CLSLoss:0.1519 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.4089 | MainLoss:0.4089 | SPLoss:0.0709 | CLSLoss:0.1507 | AUROC:0.9166\n",
      "Test | 128/16 | Loss:0.0806 | MainLoss:0.0806 | SPLoss:0.0709 | CLSLoss:0.1507 | AUROC:0.9993\n",
      "\n",
      "Epoch: [313 | 1000] LR: 0.016823\n",
      "Train | 16/16 | Loss:0.2794 | MainLoss:0.2570 | Alpha:0.4341 | SPLoss:0.0736 | CLSLoss:0.1505 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3825 | MainLoss:0.3825 | SPLoss:0.0764 | CLSLoss:0.1509 | AUROC:0.9187\n",
      "Test | 128/16 | Loss:0.0691 | MainLoss:0.0691 | SPLoss:0.0764 | CLSLoss:0.1509 | AUROC:0.9993\n",
      "\n",
      "Epoch: [314 | 1000] LR: 0.016800\n",
      "Train | 16/16 | Loss:0.2540 | MainLoss:0.2308 | Alpha:0.4403 | SPLoss:0.0792 | CLSLoss:0.1527 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3861 | MainLoss:0.3861 | SPLoss:0.0820 | CLSLoss:0.1540 | AUROC:0.9195\n",
      "Test | 128/16 | Loss:0.0692 | MainLoss:0.0692 | SPLoss:0.0820 | CLSLoss:0.1540 | AUROC:0.9992\n",
      "\n",
      "Epoch: [315 | 1000] LR: 0.016776\n",
      "Train | 16/16 | Loss:0.2553 | MainLoss:0.2314 | Alpha:0.4393 | SPLoss:0.0853 | CLSLoss:0.1534 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3994 | MainLoss:0.3994 | SPLoss:0.0883 | CLSLoss:0.1541 | AUROC:0.9187\n",
      "Test | 128/16 | Loss:0.0623 | MainLoss:0.0623 | SPLoss:0.0883 | CLSLoss:0.1541 | AUROC:0.9990\n",
      "\n",
      "Epoch: [316 | 1000] LR: 0.016753\n",
      "Train | 16/16 | Loss:0.2563 | MainLoss:0.2318 | Alpha:0.4399 | SPLoss:0.0915 | CLSLoss:0.1532 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3951 | MainLoss:0.3951 | SPLoss:0.0949 | CLSLoss:0.1546 | AUROC:0.9191\n",
      "Test | 128/16 | Loss:0.0760 | MainLoss:0.0760 | SPLoss:0.0949 | CLSLoss:0.1546 | AUROC:0.9989\n",
      "\n",
      "Epoch: [317 | 1000] LR: 0.016730\n",
      "Train | 16/16 | Loss:0.2569 | MainLoss:0.2316 | Alpha:0.4380 | SPLoss:0.0984 | CLSLoss:0.1546 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3901 | MainLoss:0.3901 | SPLoss:0.1017 | CLSLoss:0.1541 | AUROC:0.9198\n",
      "Test | 128/16 | Loss:0.0729 | MainLoss:0.0729 | SPLoss:0.1017 | CLSLoss:0.1541 | AUROC:0.9989\n",
      "\n",
      "Epoch: [318 | 1000] LR: 0.016707\n",
      "Train | 16/16 | Loss:0.2803 | MainLoss:0.2546 | Alpha:0.4327 | SPLoss:0.1052 | CLSLoss:0.1523 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3837 | MainLoss:0.3837 | SPLoss:0.1084 | CLSLoss:0.1491 | AUROC:0.9188\n",
      "Test | 128/16 | Loss:0.0704 | MainLoss:0.0704 | SPLoss:0.1084 | CLSLoss:0.1491 | AUROC:0.9990\n",
      "\n",
      "Epoch: [319 | 1000] LR: 0.016684\n",
      "Train | 16/16 | Loss:0.2689 | MainLoss:0.2427 | Alpha:0.4349 | SPLoss:0.1112 | CLSLoss:0.1501 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3953 | MainLoss:0.3953 | SPLoss:0.1145 | CLSLoss:0.1496 | AUROC:0.9195\n",
      "Test | 128/16 | Loss:0.0607 | MainLoss:0.0607 | SPLoss:0.1145 | CLSLoss:0.1496 | AUROC:0.9990\n",
      "\n",
      "Epoch: [320 | 1000] LR: 0.016660\n",
      "Train | 16/16 | Loss:0.2521 | MainLoss:0.2252 | Alpha:0.4396 | SPLoss:0.1175 | CLSLoss:0.1519 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3917 | MainLoss:0.3917 | SPLoss:0.1202 | CLSLoss:0.1527 | AUROC:0.9180\n",
      "Test | 128/16 | Loss:0.0628 | MainLoss:0.0628 | SPLoss:0.1202 | CLSLoss:0.1527 | AUROC:0.9991\n",
      "\n",
      "Epoch: [321 | 1000] LR: 0.016637\n",
      "Train | 16/16 | Loss:0.2421 | MainLoss:0.2144 | Alpha:0.4405 | SPLoss:0.1232 | CLSLoss:0.1543 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3954 | MainLoss:0.3954 | SPLoss:0.1256 | CLSLoss:0.1550 | AUROC:0.9201\n",
      "Test | 128/16 | Loss:0.0663 | MainLoss:0.0663 | SPLoss:0.1256 | CLSLoss:0.1550 | AUROC:0.9991\n",
      "\n",
      "Epoch: [322 | 1000] LR: 0.016613\n",
      "Train | 16/16 | Loss:0.2749 | MainLoss:0.2467 | Alpha:0.4334 | SPLoss:0.1288 | CLSLoss:0.1531 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3948 | MainLoss:0.3948 | SPLoss:0.1321 | CLSLoss:0.1510 | AUROC:0.9197\n",
      "Test | 128/16 | Loss:0.0642 | MainLoss:0.0642 | SPLoss:0.1321 | CLSLoss:0.1510 | AUROC:0.9992\n",
      "\n",
      "Epoch: [323 | 1000] LR: 0.016590\n",
      "Train | 16/16 | Loss:0.2648 | MainLoss:0.2361 | Alpha:0.4355 | SPLoss:0.1346 | CLSLoss:0.1518 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3860 | MainLoss:0.3860 | SPLoss:0.1378 | CLSLoss:0.1495 | AUROC:0.9193\n",
      "Test | 128/16 | Loss:0.0752 | MainLoss:0.0752 | SPLoss:0.1378 | CLSLoss:0.1495 | AUROC:0.9993\n",
      "\n",
      "Epoch: [324 | 1000] LR: 0.016566\n",
      "Train | 16/16 | Loss:0.2468 | MainLoss:0.2176 | Alpha:0.4402 | SPLoss:0.1404 | CLSLoss:0.1516 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3906 | MainLoss:0.3906 | SPLoss:0.1433 | CLSLoss:0.1522 | AUROC:0.9205\n",
      "Test | 128/16 | Loss:0.0634 | MainLoss:0.0634 | SPLoss:0.1433 | CLSLoss:0.1522 | AUROC:0.9991\n",
      "\n",
      "Epoch: [325 | 1000] LR: 0.016542\n",
      "Train | 16/16 | Loss:0.2464 | MainLoss:0.2163 | Alpha:0.4407 | SPLoss:0.1470 | CLSLoss:0.1541 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3971 | MainLoss:0.3971 | SPLoss:0.1505 | CLSLoss:0.1526 | AUROC:0.9198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 128/16 | Loss:0.0645 | MainLoss:0.0645 | SPLoss:0.1505 | CLSLoss:0.1526 | AUROC:0.9989\n",
      "\n",
      "Epoch: [326 | 1000] LR: 0.016518\n",
      "Train | 16/16 | Loss:0.2733 | MainLoss:0.2429 | Alpha:0.4349 | SPLoss:0.1526 | CLSLoss:0.1517 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3866 | MainLoss:0.3866 | SPLoss:0.1553 | CLSLoss:0.1489 | AUROC:0.9200\n",
      "Test | 128/16 | Loss:0.0807 | MainLoss:0.0807 | SPLoss:0.1553 | CLSLoss:0.1489 | AUROC:0.9989\n",
      "\n",
      "Epoch: [327 | 1000] LR: 0.016494\n",
      "Train | 16/16 | Loss:0.2704 | MainLoss:0.2397 | Alpha:0.4343 | SPLoss:0.1582 | CLSLoss:0.1488 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3926 | MainLoss:0.3926 | SPLoss:0.1614 | CLSLoss:0.1485 | AUROC:0.9196\n",
      "Test | 128/16 | Loss:0.0877 | MainLoss:0.0877 | SPLoss:0.1614 | CLSLoss:0.1485 | AUROC:0.9989\n",
      "\n",
      "Epoch: [328 | 1000] LR: 0.016471\n",
      "Train | 16/16 | Loss:0.2579 | MainLoss:0.2267 | Alpha:0.4378 | SPLoss:0.1629 | CLSLoss:0.1496 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3895 | MainLoss:0.3895 | SPLoss:0.1654 | CLSLoss:0.1504 | AUROC:0.9205\n",
      "Test | 128/16 | Loss:0.0663 | MainLoss:0.0663 | SPLoss:0.1654 | CLSLoss:0.1504 | AUROC:0.9989\n",
      "\n",
      "Epoch: [329 | 1000] LR: 0.016447\n",
      "Train | 16/16 | Loss:0.2576 | MainLoss:0.2258 | Alpha:0.4371 | SPLoss:0.1679 | CLSLoss:0.1502 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3937 | MainLoss:0.3937 | SPLoss:0.1711 | CLSLoss:0.1503 | AUROC:0.9196\n",
      "Test | 128/16 | Loss:0.0687 | MainLoss:0.0687 | SPLoss:0.1711 | CLSLoss:0.1503 | AUROC:0.9989\n",
      "\n",
      "Epoch: [330 | 1000] LR: 0.016423\n",
      "Train | 16/16 | Loss:0.2344 | MainLoss:0.2017 | Alpha:0.4411 | SPLoss:0.1735 | CLSLoss:0.1536 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3913 | MainLoss:0.3913 | SPLoss:0.1765 | CLSLoss:0.1537 | AUROC:0.9208\n",
      "Test | 128/16 | Loss:0.0708 | MainLoss:0.0708 | SPLoss:0.1765 | CLSLoss:0.1537 | AUROC:0.9990\n",
      "\n",
      "Epoch: [331 | 1000] LR: 0.016398\n",
      "Train | 16/16 | Loss:0.2712 | MainLoss:0.2383 | Alpha:0.4356 | SPLoss:0.1780 | CLSLoss:0.1511 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3862 | MainLoss:0.3862 | SPLoss:0.1797 | CLSLoss:0.1504 | AUROC:0.9215\n",
      "Test | 128/16 | Loss:0.0683 | MainLoss:0.0683 | SPLoss:0.1797 | CLSLoss:0.1504 | AUROC:0.9990\n",
      "\n",
      "Epoch: [332 | 1000] LR: 0.016374\n",
      "Train | 16/16 | Loss:0.2652 | MainLoss:0.2318 | Alpha:0.4365 | SPLoss:0.1829 | CLSLoss:0.1502 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3819 | MainLoss:0.3819 | SPLoss:0.1853 | CLSLoss:0.1475 | AUROC:0.9224\n",
      "Test | 128/16 | Loss:0.0663 | MainLoss:0.0663 | SPLoss:0.1853 | CLSLoss:0.1475 | AUROC:0.9991\n",
      "\n",
      "Epoch: [333 | 1000] LR: 0.016350\n",
      "Train | 16/16 | Loss:0.2563 | MainLoss:0.2228 | Alpha:0.4389 | SPLoss:0.1872 | CLSLoss:0.1480 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3827 | MainLoss:0.3827 | SPLoss:0.1890 | CLSLoss:0.1486 | AUROC:0.9216\n",
      "Test | 128/16 | Loss:0.0700 | MainLoss:0.0700 | SPLoss:0.1890 | CLSLoss:0.1486 | AUROC:0.9992\n",
      "\n",
      "Epoch: [334 | 1000] LR: 0.016326\n",
      "Train | 16/16 | Loss:0.2458 | MainLoss:0.2118 | Alpha:0.4385 | SPLoss:0.1903 | CLSLoss:0.1497 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3894 | MainLoss:0.3894 | SPLoss:0.1927 | CLSLoss:0.1506 | AUROC:0.9209\n",
      "Test | 128/16 | Loss:0.0696 | MainLoss:0.0696 | SPLoss:0.1927 | CLSLoss:0.1506 | AUROC:0.9991\n",
      "\n",
      "Epoch: [335 | 1000] LR: 0.016301\n",
      "Train | 16/16 | Loss:0.2499 | MainLoss:0.2153 | Alpha:0.4387 | SPLoss:0.1948 | CLSLoss:0.1511 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3932 | MainLoss:0.3932 | SPLoss:0.1962 | CLSLoss:0.1520 | AUROC:0.9220\n",
      "Test | 128/16 | Loss:0.0702 | MainLoss:0.0702 | SPLoss:0.1962 | CLSLoss:0.1520 | AUROC:0.9990\n",
      "\n",
      "Epoch: [336 | 1000] LR: 0.016277\n",
      "Train | 16/16 | Loss:0.2676 | MainLoss:0.2328 | Alpha:0.4348 | SPLoss:0.1983 | CLSLoss:0.1503 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3911 | MainLoss:0.3911 | SPLoss:0.2009 | CLSLoss:0.1482 | AUROC:0.9218\n",
      "Test | 128/16 | Loss:0.0780 | MainLoss:0.0780 | SPLoss:0.2009 | CLSLoss:0.1482 | AUROC:0.9988\n",
      "\n",
      "Epoch: [337 | 1000] LR: 0.016252\n",
      "Train | 16/16 | Loss:0.2631 | MainLoss:0.2281 | Alpha:0.4348 | SPLoss:0.2022 | CLSLoss:0.1479 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3861 | MainLoss:0.3861 | SPLoss:0.2039 | CLSLoss:0.1470 | AUROC:0.9219\n",
      "Test | 128/16 | Loss:0.0643 | MainLoss:0.0643 | SPLoss:0.2039 | CLSLoss:0.1470 | AUROC:0.9990\n",
      "\n",
      "Epoch: [338 | 1000] LR: 0.016228\n",
      "Train | 16/16 | Loss:0.2711 | MainLoss:0.2360 | Alpha:0.4334 | SPLoss:0.2055 | CLSLoss:0.1461 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3866 | MainLoss:0.3866 | SPLoss:0.2090 | CLSLoss:0.1453 | AUROC:0.9203\n",
      "Test | 128/16 | Loss:0.0711 | MainLoss:0.0711 | SPLoss:0.2090 | CLSLoss:0.1453 | AUROC:0.9989\n",
      "\n",
      "Epoch: [339 | 1000] LR: 0.016203\n",
      "Train | 16/16 | Loss:0.2523 | MainLoss:0.2165 | Alpha:0.4358 | SPLoss:0.2113 | CLSLoss:0.1470 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3933 | MainLoss:0.3933 | SPLoss:0.2132 | CLSLoss:0.1478 | AUROC:0.9208\n",
      "Test | 128/16 | Loss:0.0712 | MainLoss:0.0712 | SPLoss:0.2132 | CLSLoss:0.1478 | AUROC:0.9991\n",
      "\n",
      "Epoch: [340 | 1000] LR: 0.016179\n",
      "Train | 16/16 | Loss:0.2407 | MainLoss:0.2043 | Alpha:0.4396 | SPLoss:0.2151 | CLSLoss:0.1495 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3902 | MainLoss:0.3902 | SPLoss:0.2170 | CLSLoss:0.1500 | AUROC:0.9213\n",
      "Test | 128/16 | Loss:0.0680 | MainLoss:0.0680 | SPLoss:0.2170 | CLSLoss:0.1500 | AUROC:0.9991\n",
      "\n",
      "Epoch: [341 | 1000] LR: 0.016154\n",
      "Train | 16/16 | Loss:0.2501 | MainLoss:0.2131 | Alpha:0.4385 | SPLoss:0.2197 | CLSLoss:0.1504 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3934 | MainLoss:0.3934 | SPLoss:0.2219 | CLSLoss:0.1509 | AUROC:0.9216\n",
      "Test | 128/16 | Loss:0.0658 | MainLoss:0.0658 | SPLoss:0.2219 | CLSLoss:0.1509 | AUROC:0.9992\n",
      "\n",
      "Epoch: [342 | 1000] LR: 0.016129\n",
      "Train | 16/16 | Loss:0.2750 | MainLoss:0.2379 | Alpha:0.4325 | SPLoss:0.2228 | CLSLoss:0.1475 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3915 | MainLoss:0.3915 | SPLoss:0.2249 | CLSLoss:0.1477 | AUROC:0.9207\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.2249 | CLSLoss:0.1477 | AUROC:0.9990\n",
      "\n",
      "Epoch: [343 | 1000] LR: 0.016104\n",
      "Train | 16/16 | Loss:0.2466 | MainLoss:0.2091 | Alpha:0.4394 | SPLoss:0.2267 | CLSLoss:0.1487 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3941 | MainLoss:0.3941 | SPLoss:0.2287 | CLSLoss:0.1492 | AUROC:0.9210\n",
      "Test | 128/16 | Loss:0.0686 | MainLoss:0.0686 | SPLoss:0.2287 | CLSLoss:0.1492 | AUROC:0.9990\n",
      "\n",
      "Epoch: [344 | 1000] LR: 0.016079\n",
      "Train | 16/16 | Loss:0.2635 | MainLoss:0.2257 | Alpha:0.4357 | SPLoss:0.2299 | CLSLoss:0.1476 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3911 | MainLoss:0.3911 | SPLoss:0.2309 | CLSLoss:0.1480 | AUROC:0.9206\n",
      "Test | 128/16 | Loss:0.0674 | MainLoss:0.0674 | SPLoss:0.2309 | CLSLoss:0.1480 | AUROC:0.9991\n",
      "\n",
      "Epoch: [345 | 1000] LR: 0.016054\n",
      "Train | 16/16 | Loss:0.2632 | MainLoss:0.2252 | Alpha:0.4361 | SPLoss:0.2322 | CLSLoss:0.1477 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3874 | MainLoss:0.3874 | SPLoss:0.2331 | CLSLoss:0.1463 | AUROC:0.9222\n",
      "Test | 128/16 | Loss:0.0695 | MainLoss:0.0695 | SPLoss:0.2331 | CLSLoss:0.1463 | AUROC:0.9991\n",
      "\n",
      "Epoch: [346 | 1000] LR: 0.016029\n",
      "Train | 16/16 | Loss:0.2721 | MainLoss:0.2342 | Alpha:0.4330 | SPLoss:0.2348 | CLSLoss:0.1451 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3896 | MainLoss:0.3896 | SPLoss:0.2366 | CLSLoss:0.1437 | AUROC:0.9217\n",
      "Test | 128/16 | Loss:0.0599 | MainLoss:0.0599 | SPLoss:0.2366 | CLSLoss:0.1437 | AUROC:0.9993\n",
      "\n",
      "Epoch: [347 | 1000] LR: 0.016004\n",
      "Train | 16/16 | Loss:0.2632 | MainLoss:0.2250 | Alpha:0.4355 | SPLoss:0.2382 | CLSLoss:0.1438 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3946 | MainLoss:0.3946 | SPLoss:0.2398 | CLSLoss:0.1433 | AUROC:0.9236\n",
      "Test | 128/16 | Loss:0.0573 | MainLoss:0.0573 | SPLoss:0.2398 | CLSLoss:0.1433 | AUROC:0.9993\n",
      "\n",
      "Epoch: [348 | 1000] LR: 0.015979\n",
      "Train | 16/16 | Loss:0.2617 | MainLoss:0.2232 | Alpha:0.4365 | SPLoss:0.2414 | CLSLoss:0.1438 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3997 | MainLoss:0.3997 | SPLoss:0.2432 | CLSLoss:0.1441 | AUROC:0.9219\n",
      "Test | 128/16 | Loss:0.0761 | MainLoss:0.0761 | SPLoss:0.2432 | CLSLoss:0.1441 | AUROC:0.9992\n",
      "\n",
      "Epoch: [349 | 1000] LR: 0.015954\n",
      "Train | 16/16 | Loss:0.2505 | MainLoss:0.2115 | Alpha:0.4378 | SPLoss:0.2439 | CLSLoss:0.1456 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.4065 | MainLoss:0.4065 | SPLoss:0.2462 | CLSLoss:0.1450 | AUROC:0.9213\n",
      "Test | 128/16 | Loss:0.0608 | MainLoss:0.0608 | SPLoss:0.2462 | CLSLoss:0.1450 | AUROC:0.9991\n",
      "\n",
      "Epoch: [350 | 1000] LR: 0.015929\n",
      "Train | 16/16 | Loss:0.2441 | MainLoss:0.2048 | Alpha:0.4393 | SPLoss:0.2474 | CLSLoss:0.1455 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3978 | MainLoss:0.3978 | SPLoss:0.2494 | CLSLoss:0.1470 | AUROC:0.9219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 128/16 | Loss:0.0622 | MainLoss:0.0622 | SPLoss:0.2494 | CLSLoss:0.1470 | AUROC:0.9992\n",
      "\n",
      "Epoch: [351 | 1000] LR: 0.015903\n",
      "Train | 16/16 | Loss:0.2622 | MainLoss:0.2225 | Alpha:0.4353 | SPLoss:0.2507 | CLSLoss:0.1463 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3964 | MainLoss:0.3964 | SPLoss:0.2525 | CLSLoss:0.1430 | AUROC:0.9221\n",
      "Test | 128/16 | Loss:0.0767 | MainLoss:0.0767 | SPLoss:0.2525 | CLSLoss:0.1430 | AUROC:0.9992\n",
      "\n",
      "Epoch: [352 | 1000] LR: 0.015878\n",
      "Train | 16/16 | Loss:0.2591 | MainLoss:0.2195 | Alpha:0.4372 | SPLoss:0.2531 | CLSLoss:0.1430 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3874 | MainLoss:0.3874 | SPLoss:0.2540 | CLSLoss:0.1440 | AUROC:0.9221\n",
      "Test | 128/16 | Loss:0.0769 | MainLoss:0.0769 | SPLoss:0.2540 | CLSLoss:0.1440 | AUROC:0.9992\n",
      "\n",
      "Epoch: [353 | 1000] LR: 0.015852\n",
      "Train | 16/16 | Loss:0.2383 | MainLoss:0.1980 | Alpha:0.4394 | SPLoss:0.2569 | CLSLoss:0.1465 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3907 | MainLoss:0.3907 | SPLoss:0.2592 | CLSLoss:0.1468 | AUROC:0.9229\n",
      "Test | 128/16 | Loss:0.0710 | MainLoss:0.0710 | SPLoss:0.2592 | CLSLoss:0.1468 | AUROC:0.9992\n",
      "\n",
      "Epoch: [354 | 1000] LR: 0.015827\n",
      "Train | 16/16 | Loss:0.2517 | MainLoss:0.2111 | Alpha:0.4394 | SPLoss:0.2599 | CLSLoss:0.1466 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3936 | MainLoss:0.3936 | SPLoss:0.2598 | CLSLoss:0.1473 | AUROC:0.9223\n",
      "Test | 128/16 | Loss:0.0684 | MainLoss:0.0684 | SPLoss:0.2598 | CLSLoss:0.1473 | AUROC:0.9993\n",
      "\n",
      "Epoch: [355 | 1000] LR: 0.015801\n",
      "Train | 16/16 | Loss:0.2475 | MainLoss:0.2067 | Alpha:0.4406 | SPLoss:0.2600 | CLSLoss:0.1479 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.4071 | MainLoss:0.4071 | SPLoss:0.2602 | CLSLoss:0.1463 | AUROC:0.9210\n",
      "Test | 128/16 | Loss:0.0567 | MainLoss:0.0567 | SPLoss:0.2602 | CLSLoss:0.1463 | AUROC:0.9993\n",
      "\n",
      "Epoch: [356 | 1000] LR: 0.015776\n",
      "Train | 16/16 | Loss:0.2427 | MainLoss:0.2018 | Alpha:0.4395 | SPLoss:0.2617 | CLSLoss:0.1473 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3932 | MainLoss:0.3932 | SPLoss:0.2633 | CLSLoss:0.1480 | AUROC:0.9224\n",
      "Test | 128/16 | Loss:0.0650 | MainLoss:0.0650 | SPLoss:0.2633 | CLSLoss:0.1480 | AUROC:0.9991\n",
      "\n",
      "Epoch: [357 | 1000] LR: 0.015750\n",
      "Train | 16/16 | Loss:0.2444 | MainLoss:0.2031 | Alpha:0.4394 | SPLoss:0.2651 | CLSLoss:0.1480 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3994 | MainLoss:0.3994 | SPLoss:0.2659 | CLSLoss:0.1481 | AUROC:0.9215\n",
      "Test | 128/16 | Loss:0.0591 | MainLoss:0.0591 | SPLoss:0.2659 | CLSLoss:0.1481 | AUROC:0.9992\n",
      "\n",
      "Epoch: [358 | 1000] LR: 0.015724\n",
      "Train | 16/16 | Loss:0.2282 | MainLoss:0.1864 | Alpha:0.4405 | SPLoss:0.2678 | CLSLoss:0.1507 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.4035 | MainLoss:0.4035 | SPLoss:0.2699 | CLSLoss:0.1513 | AUROC:0.9212\n",
      "Test | 128/16 | Loss:0.0659 | MainLoss:0.0659 | SPLoss:0.2699 | CLSLoss:0.1513 | AUROC:0.9992\n",
      "\n",
      "Epoch: [359 | 1000] LR: 0.015699\n",
      "Train | 16/16 | Loss:0.2379 | MainLoss:0.1957 | Alpha:0.4416 | SPLoss:0.2718 | CLSLoss:0.1507 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.4043 | MainLoss:0.4043 | SPLoss:0.2737 | CLSLoss:0.1508 | AUROC:0.9216\n",
      "Test | 128/16 | Loss:0.0626 | MainLoss:0.0626 | SPLoss:0.2737 | CLSLoss:0.1508 | AUROC:0.9990\n",
      "\n",
      "Epoch: [360 | 1000] LR: 0.015673\n",
      "Train | 16/16 | Loss:0.2527 | MainLoss:0.2104 | Alpha:0.4373 | SPLoss:0.2748 | CLSLoss:0.1491 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3937 | MainLoss:0.3937 | SPLoss:0.2751 | CLSLoss:0.1490 | AUROC:0.9223\n",
      "Test | 128/16 | Loss:0.0653 | MainLoss:0.0653 | SPLoss:0.2751 | CLSLoss:0.1490 | AUROC:0.9989\n",
      "\n",
      "Epoch: [361 | 1000] LR: 0.015647\n",
      "Train | 16/16 | Loss:0.2609 | MainLoss:0.2185 | Alpha:0.4355 | SPLoss:0.2759 | CLSLoss:0.1481 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3870 | MainLoss:0.3870 | SPLoss:0.2770 | CLSLoss:0.1470 | AUROC:0.9220\n",
      "Test | 128/16 | Loss:0.0644 | MainLoss:0.0644 | SPLoss:0.2770 | CLSLoss:0.1470 | AUROC:0.9991\n",
      "\n",
      "Epoch: [362 | 1000] LR: 0.015621\n",
      "Train | 16/16 | Loss:0.2701 | MainLoss:0.2277 | Alpha:0.4336 | SPLoss:0.2778 | CLSLoss:0.1464 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3868 | MainLoss:0.3868 | SPLoss:0.2783 | CLSLoss:0.1449 | AUROC:0.9223\n",
      "Test | 128/16 | Loss:0.0627 | MainLoss:0.0627 | SPLoss:0.2783 | CLSLoss:0.1449 | AUROC:0.9991\n",
      "\n",
      "Epoch: [363 | 1000] LR: 0.015595\n",
      "Train | 16/16 | Loss:0.2510 | MainLoss:0.2084 | Alpha:0.4363 | SPLoss:0.2800 | CLSLoss:0.1463 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3908 | MainLoss:0.3908 | SPLoss:0.2815 | CLSLoss:0.1471 | AUROC:0.9222\n",
      "Test | 128/16 | Loss:0.0690 | MainLoss:0.0690 | SPLoss:0.2815 | CLSLoss:0.1471 | AUROC:0.9992\n",
      "\n",
      "Epoch: [364 | 1000] LR: 0.015569\n",
      "Train | 16/16 | Loss:0.2517 | MainLoss:0.2086 | Alpha:0.4374 | SPLoss:0.2829 | CLSLoss:0.1474 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3874 | MainLoss:0.3874 | SPLoss:0.2827 | CLSLoss:0.1471 | AUROC:0.9227\n",
      "Test | 128/16 | Loss:0.0641 | MainLoss:0.0641 | SPLoss:0.2827 | CLSLoss:0.1471 | AUROC:0.9993\n",
      "\n",
      "Epoch: [365 | 1000] LR: 0.015543\n",
      "Train | 16/16 | Loss:0.2548 | MainLoss:0.2118 | Alpha:0.4351 | SPLoss:0.2832 | CLSLoss:0.1469 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.4128 | MainLoss:0.4128 | SPLoss:0.2843 | CLSLoss:0.1487 | AUROC:0.9220\n",
      "Test | 128/16 | Loss:0.0800 | MainLoss:0.0800 | SPLoss:0.2843 | CLSLoss:0.1487 | AUROC:0.9992\n",
      "\n",
      "Epoch: [366 | 1000] LR: 0.015516\n",
      "Train | 16/16 | Loss:0.2435 | MainLoss:0.2001 | Alpha:0.4409 | SPLoss:0.2848 | CLSLoss:0.1492 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3978 | MainLoss:0.3978 | SPLoss:0.2855 | CLSLoss:0.1480 | AUROC:0.9217\n",
      "Test | 128/16 | Loss:0.0700 | MainLoss:0.0700 | SPLoss:0.2855 | CLSLoss:0.1480 | AUROC:0.9992\n",
      "\n",
      "Epoch: [367 | 1000] LR: 0.015490\n",
      "Train | 16/16 | Loss:0.2678 | MainLoss:0.2246 | Alpha:0.4352 | SPLoss:0.2863 | CLSLoss:0.1462 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3914 | MainLoss:0.3914 | SPLoss:0.2875 | CLSLoss:0.1450 | AUROC:0.9209\n",
      "Test | 128/16 | Loss:0.0713 | MainLoss:0.0713 | SPLoss:0.2875 | CLSLoss:0.1450 | AUROC:0.9992\n",
      "\n",
      "Epoch: [368 | 1000] LR: 0.015464\n",
      "Train | 16/16 | Loss:0.2506 | MainLoss:0.2073 | Alpha:0.4365 | SPLoss:0.2885 | CLSLoss:0.1449 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3959 | MainLoss:0.3959 | SPLoss:0.2898 | CLSLoss:0.1461 | AUROC:0.9217\n",
      "Test | 128/16 | Loss:0.0626 | MainLoss:0.0626 | SPLoss:0.2898 | CLSLoss:0.1461 | AUROC:0.9992\n",
      "\n",
      "Epoch: [369 | 1000] LR: 0.015438\n",
      "Train | 16/16 | Loss:0.2566 | MainLoss:0.2131 | Alpha:0.4385 | SPLoss:0.2895 | CLSLoss:0.1451 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3856 | MainLoss:0.3856 | SPLoss:0.2898 | CLSLoss:0.1450 | AUROC:0.9244\n",
      "Test | 128/16 | Loss:0.0648 | MainLoss:0.0648 | SPLoss:0.2898 | CLSLoss:0.1450 | AUROC:0.9992\n",
      "\n",
      "Epoch: [370 | 1000] LR: 0.015411\n",
      "Train | 16/16 | Loss:0.2474 | MainLoss:0.2038 | Alpha:0.4389 | SPLoss:0.2904 | CLSLoss:0.1458 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3918 | MainLoss:0.3918 | SPLoss:0.2903 | CLSLoss:0.1457 | AUROC:0.9221\n",
      "Test | 128/16 | Loss:0.0602 | MainLoss:0.0602 | SPLoss:0.2903 | CLSLoss:0.1457 | AUROC:0.9992\n",
      "\n",
      "Epoch: [371 | 1000] LR: 0.015385\n",
      "Train | 16/16 | Loss:0.2680 | MainLoss:0.2245 | Alpha:0.4344 | SPLoss:0.2905 | CLSLoss:0.1450 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3839 | MainLoss:0.3839 | SPLoss:0.2916 | CLSLoss:0.1418 | AUROC:0.9223\n",
      "Test | 128/16 | Loss:0.0616 | MainLoss:0.0616 | SPLoss:0.2916 | CLSLoss:0.1418 | AUROC:0.9992\n",
      "\n",
      "Epoch: [372 | 1000] LR: 0.015358\n",
      "Train | 16/16 | Loss:0.2490 | MainLoss:0.2052 | Alpha:0.4375 | SPLoss:0.2937 | CLSLoss:0.1436 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3962 | MainLoss:0.3962 | SPLoss:0.2952 | CLSLoss:0.1440 | AUROC:0.9234\n",
      "Test | 128/16 | Loss:0.0611 | MainLoss:0.0611 | SPLoss:0.2952 | CLSLoss:0.1440 | AUROC:0.9991\n",
      "\n",
      "Epoch: [373 | 1000] LR: 0.015332\n",
      "Train | 16/16 | Loss:0.2404 | MainLoss:0.1963 | Alpha:0.4390 | SPLoss:0.2955 | CLSLoss:0.1449 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.4145 | MainLoss:0.4145 | SPLoss:0.2968 | CLSLoss:0.1457 | AUROC:0.9230\n",
      "Test | 128/16 | Loss:0.0572 | MainLoss:0.0572 | SPLoss:0.2968 | CLSLoss:0.1457 | AUROC:0.9991\n",
      "\n",
      "Epoch: [374 | 1000] LR: 0.015305\n",
      "Train | 16/16 | Loss:0.2727 | MainLoss:0.2286 | Alpha:0.4345 | SPLoss:0.2974 | CLSLoss:0.1441 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3890 | MainLoss:0.3890 | SPLoss:0.2976 | CLSLoss:0.1422 | AUROC:0.9234\n",
      "Test | 128/16 | Loss:0.0607 | MainLoss:0.0607 | SPLoss:0.2976 | CLSLoss:0.1422 | AUROC:0.9990\n",
      "\n",
      "Epoch: [375 | 1000] LR: 0.015278\n",
      "Train | 16/16 | Loss:0.2496 | MainLoss:0.2055 | Alpha:0.4361 | SPLoss:0.2980 | CLSLoss:0.1429 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3869 | MainLoss:0.3869 | SPLoss:0.2988 | CLSLoss:0.1444 | AUROC:0.9230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 128/16 | Loss:0.0677 | MainLoss:0.0677 | SPLoss:0.2988 | CLSLoss:0.1444 | AUROC:0.9991\n",
      "\n",
      "Epoch: [376 | 1000] LR: 0.015252\n",
      "Train | 16/16 | Loss:0.2529 | MainLoss:0.2086 | Alpha:0.4366 | SPLoss:0.2989 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3901 | MainLoss:0.3901 | SPLoss:0.2996 | CLSLoss:0.1437 | AUROC:0.9228\n",
      "Test | 128/16 | Loss:0.0700 | MainLoss:0.0700 | SPLoss:0.2996 | CLSLoss:0.1437 | AUROC:0.9990\n",
      "\n",
      "Epoch: [377 | 1000] LR: 0.015225\n",
      "Train | 16/16 | Loss:0.2622 | MainLoss:0.2179 | Alpha:0.4379 | SPLoss:0.2997 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3863 | MainLoss:0.3863 | SPLoss:0.2991 | CLSLoss:0.1418 | AUROC:0.9222\n",
      "Test | 128/16 | Loss:0.0706 | MainLoss:0.0706 | SPLoss:0.2991 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [378 | 1000] LR: 0.015198\n",
      "Train | 16/16 | Loss:0.2506 | MainLoss:0.2063 | Alpha:0.4359 | SPLoss:0.2994 | CLSLoss:0.1434 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.4127 | MainLoss:0.4127 | SPLoss:0.3008 | CLSLoss:0.1436 | AUROC:0.9211\n",
      "Test | 128/16 | Loss:0.0902 | MainLoss:0.0902 | SPLoss:0.3008 | CLSLoss:0.1436 | AUROC:0.9987\n",
      "\n",
      "Epoch: [379 | 1000] LR: 0.015171\n",
      "Train | 16/16 | Loss:0.2381 | MainLoss:0.1934 | Alpha:0.4383 | SPLoss:0.3022 | CLSLoss:0.1446 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3936 | MainLoss:0.3936 | SPLoss:0.3037 | CLSLoss:0.1476 | AUROC:0.9238\n",
      "Test | 128/16 | Loss:0.0657 | MainLoss:0.0657 | SPLoss:0.3037 | CLSLoss:0.1476 | AUROC:0.9989\n",
      "\n",
      "Epoch: [380 | 1000] LR: 0.015144\n",
      "Train | 16/16 | Loss:0.2415 | MainLoss:0.1964 | Alpha:0.4401 | SPLoss:0.3040 | CLSLoss:0.1470 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3960 | MainLoss:0.3960 | SPLoss:0.3057 | CLSLoss:0.1481 | AUROC:0.9235\n",
      "Test | 128/16 | Loss:0.0700 | MainLoss:0.0700 | SPLoss:0.3057 | CLSLoss:0.1481 | AUROC:0.9989\n",
      "\n",
      "Epoch: [381 | 1000] LR: 0.015117\n",
      "Train | 16/16 | Loss:0.2646 | MainLoss:0.2194 | Alpha:0.4339 | SPLoss:0.3062 | CLSLoss:0.1468 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.4097 | MainLoss:0.4097 | SPLoss:0.3075 | CLSLoss:0.1436 | AUROC:0.9220\n",
      "Test | 128/16 | Loss:0.0964 | MainLoss:0.0964 | SPLoss:0.3075 | CLSLoss:0.1436 | AUROC:0.9986\n",
      "\n",
      "Epoch: [382 | 1000] LR: 0.015090\n",
      "Train | 16/16 | Loss:0.2562 | MainLoss:0.2112 | Alpha:0.4381 | SPLoss:0.3069 | CLSLoss:0.1435 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3890 | MainLoss:0.3890 | SPLoss:0.3134 | CLSLoss:0.1444 | AUROC:0.9241\n",
      "Test | 128/16 | Loss:0.0775 | MainLoss:0.0775 | SPLoss:0.3134 | CLSLoss:0.1444 | AUROC:0.9987\n",
      "\n",
      "Epoch: [383 | 1000] LR: 0.015063\n",
      "Train | 16/16 | Loss:0.2439 | MainLoss:0.1981 | Alpha:0.4389 | SPLoss:0.3147 | CLSLoss:0.1440 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3929 | MainLoss:0.3929 | SPLoss:0.3154 | CLSLoss:0.1461 | AUROC:0.9237\n",
      "Test | 128/16 | Loss:0.0783 | MainLoss:0.0783 | SPLoss:0.3154 | CLSLoss:0.1461 | AUROC:0.9987\n",
      "\n",
      "Epoch: [384 | 1000] LR: 0.015036\n",
      "Train | 16/16 | Loss:0.2643 | MainLoss:0.2181 | Alpha:0.4340 | SPLoss:0.3164 | CLSLoss:0.1449 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3877 | MainLoss:0.3877 | SPLoss:0.3180 | CLSLoss:0.1430 | AUROC:0.9245\n",
      "Test | 128/16 | Loss:0.0724 | MainLoss:0.0724 | SPLoss:0.3180 | CLSLoss:0.1430 | AUROC:0.9987\n",
      "\n",
      "Epoch: [385 | 1000] LR: 0.015009\n",
      "Train | 16/16 | Loss:0.2479 | MainLoss:0.2018 | Alpha:0.4380 | SPLoss:0.3180 | CLSLoss:0.1430 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3920 | MainLoss:0.3920 | SPLoss:0.3182 | CLSLoss:0.1442 | AUROC:0.9242\n",
      "Test | 128/16 | Loss:0.0898 | MainLoss:0.0898 | SPLoss:0.3182 | CLSLoss:0.1442 | AUROC:0.9984\n",
      "\n",
      "Epoch: [386 | 1000] LR: 0.014982\n",
      "Train | 16/16 | Loss:0.2899 | MainLoss:0.2438 | Alpha:0.4299 | SPLoss:0.3204 | CLSLoss:0.1414 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3859 | MainLoss:0.3859 | SPLoss:0.3217 | CLSLoss:0.1393 | AUROC:0.9231\n",
      "Test | 128/16 | Loss:0.0646 | MainLoss:0.0646 | SPLoss:0.3217 | CLSLoss:0.1393 | AUROC:0.9990\n",
      "\n",
      "Epoch: [387 | 1000] LR: 0.014955\n",
      "Train | 16/16 | Loss:0.2724 | MainLoss:0.2263 | Alpha:0.4340 | SPLoss:0.3211 | CLSLoss:0.1402 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3784 | MainLoss:0.3784 | SPLoss:0.3208 | CLSLoss:0.1401 | AUROC:0.9249\n",
      "Test | 128/16 | Loss:0.0636 | MainLoss:0.0636 | SPLoss:0.3208 | CLSLoss:0.1401 | AUROC:0.9992\n",
      "\n",
      "Epoch: [388 | 1000] LR: 0.014927\n",
      "Train | 16/16 | Loss:0.2565 | MainLoss:0.2102 | Alpha:0.4373 | SPLoss:0.3214 | CLSLoss:0.1416 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3851 | MainLoss:0.3851 | SPLoss:0.3211 | CLSLoss:0.1435 | AUROC:0.9238\n",
      "Test | 128/16 | Loss:0.0667 | MainLoss:0.0667 | SPLoss:0.3211 | CLSLoss:0.1435 | AUROC:0.9993\n",
      "\n",
      "Epoch: [389 | 1000] LR: 0.014900\n",
      "Train | 16/16 | Loss:0.2558 | MainLoss:0.2092 | Alpha:0.4358 | SPLoss:0.3223 | CLSLoss:0.1436 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3864 | MainLoss:0.3864 | SPLoss:0.3222 | CLSLoss:0.1437 | AUROC:0.9239\n",
      "Test | 128/16 | Loss:0.0713 | MainLoss:0.0713 | SPLoss:0.3222 | CLSLoss:0.1437 | AUROC:0.9991\n",
      "\n",
      "Epoch: [390 | 1000] LR: 0.014873\n",
      "Train | 16/16 | Loss:0.2786 | MainLoss:0.2322 | Alpha:0.4321 | SPLoss:0.3226 | CLSLoss:0.1413 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3803 | MainLoss:0.3803 | SPLoss:0.3220 | CLSLoss:0.1404 | AUROC:0.9235\n",
      "Test | 128/16 | Loss:0.0697 | MainLoss:0.0697 | SPLoss:0.3220 | CLSLoss:0.1404 | AUROC:0.9992\n",
      "\n",
      "Epoch: [391 | 1000] LR: 0.014845\n",
      "Train | 16/16 | Loss:0.2384 | MainLoss:0.1920 | Alpha:0.4406 | SPLoss:0.3226 | CLSLoss:0.1414 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3929 | MainLoss:0.3929 | SPLoss:0.3237 | CLSLoss:0.1461 | AUROC:0.9243\n",
      "Test | 128/16 | Loss:0.0676 | MainLoss:0.0676 | SPLoss:0.3237 | CLSLoss:0.1461 | AUROC:0.9991\n",
      "\n",
      "Epoch: [392 | 1000] LR: 0.014818\n",
      "Train | 16/16 | Loss:0.2542 | MainLoss:0.2073 | Alpha:0.4362 | SPLoss:0.3245 | CLSLoss:0.1449 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3947 | MainLoss:0.3947 | SPLoss:0.3245 | CLSLoss:0.1452 | AUROC:0.9232\n",
      "Test | 128/16 | Loss:0.0647 | MainLoss:0.0647 | SPLoss:0.3245 | CLSLoss:0.1452 | AUROC:0.9992\n",
      "\n",
      "Epoch: [393 | 1000] LR: 0.014790\n",
      "Train | 16/16 | Loss:0.2761 | MainLoss:0.2294 | Alpha:0.4331 | SPLoss:0.3250 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3999 | MainLoss:0.3999 | SPLoss:0.3237 | CLSLoss:0.1394 | AUROC:0.9241\n",
      "Test | 128/16 | Loss:0.0591 | MainLoss:0.0591 | SPLoss:0.3237 | CLSLoss:0.1394 | AUROC:0.9991\n",
      "\n",
      "Epoch: [394 | 1000] LR: 0.014762\n",
      "Train | 16/16 | Loss:0.2380 | MainLoss:0.1915 | Alpha:0.4420 | SPLoss:0.3232 | CLSLoss:0.1412 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3880 | MainLoss:0.3880 | SPLoss:0.3227 | CLSLoss:0.1431 | AUROC:0.9247\n",
      "Test | 128/16 | Loss:0.0694 | MainLoss:0.0694 | SPLoss:0.3227 | CLSLoss:0.1431 | AUROC:0.9991\n",
      "\n",
      "Epoch: [395 | 1000] LR: 0.014735\n",
      "Train | 16/16 | Loss:0.2706 | MainLoss:0.2242 | Alpha:0.4336 | SPLoss:0.3230 | CLSLoss:0.1408 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3838 | MainLoss:0.3838 | SPLoss:0.3224 | CLSLoss:0.1398 | AUROC:0.9249\n",
      "Test | 128/16 | Loss:0.0661 | MainLoss:0.0661 | SPLoss:0.3224 | CLSLoss:0.1398 | AUROC:0.9990\n",
      "\n",
      "Epoch: [396 | 1000] LR: 0.014707\n",
      "Train | 16/16 | Loss:0.2487 | MainLoss:0.2024 | Alpha:0.4382 | SPLoss:0.3227 | CLSLoss:0.1403 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3898 | MainLoss:0.3898 | SPLoss:0.3221 | CLSLoss:0.1424 | AUROC:0.9236\n",
      "Test | 128/16 | Loss:0.0693 | MainLoss:0.0693 | SPLoss:0.3221 | CLSLoss:0.1424 | AUROC:0.9991\n",
      "\n",
      "Epoch: [397 | 1000] LR: 0.014679\n",
      "Train | 16/16 | Loss:0.2577 | MainLoss:0.2113 | Alpha:0.4360 | SPLoss:0.3222 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3914 | MainLoss:0.3914 | SPLoss:0.3209 | CLSLoss:0.1408 | AUROC:0.9233\n",
      "Test | 128/16 | Loss:0.0612 | MainLoss:0.0612 | SPLoss:0.3209 | CLSLoss:0.1408 | AUROC:0.9991\n",
      "\n",
      "Epoch: [398 | 1000] LR: 0.014652\n",
      "Train | 16/16 | Loss:0.2453 | MainLoss:0.1991 | Alpha:0.4388 | SPLoss:0.3205 | CLSLoss:0.1415 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3880 | MainLoss:0.3880 | SPLoss:0.3209 | CLSLoss:0.1434 | AUROC:0.9242\n",
      "Test | 128/16 | Loss:0.0699 | MainLoss:0.0699 | SPLoss:0.3209 | CLSLoss:0.1434 | AUROC:0.9989\n",
      "\n",
      "Epoch: [399 | 1000] LR: 0.014624\n",
      "Train | 16/16 | Loss:0.2519 | MainLoss:0.2054 | Alpha:0.4379 | SPLoss:0.3220 | CLSLoss:0.1434 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3880 | MainLoss:0.3880 | SPLoss:0.3219 | CLSLoss:0.1435 | AUROC:0.9245\n",
      "Test | 128/16 | Loss:0.0708 | MainLoss:0.0708 | SPLoss:0.3219 | CLSLoss:0.1435 | AUROC:0.9988\n",
      "\n",
      "Epoch: [400 | 1000] LR: 0.014596\n",
      "Train | 16/16 | Loss:0.2508 | MainLoss:0.2042 | Alpha:0.4368 | SPLoss:0.3228 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3861 | MainLoss:0.3861 | SPLoss:0.3229 | CLSLoss:0.1434 | AUROC:0.9234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 128/16 | Loss:0.0686 | MainLoss:0.0686 | SPLoss:0.3229 | CLSLoss:0.1434 | AUROC:0.9990\n",
      "\n",
      "Epoch: [401 | 1000] LR: 0.001457\n",
      "Train | 16/16 | Loss:0.2208 | MainLoss:0.2064 | Alpha:0.4535 | SPLoss:0.0000 | CLSLoss:0.1434 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3859 | MainLoss:0.3859 | SPLoss:0.0001 | CLSLoss:0.1435 | AUROC:0.9240\n",
      "Test | 128/16 | Loss:0.0659 | MainLoss:0.0659 | SPLoss:0.0001 | CLSLoss:0.1435 | AUROC:0.9990\n",
      "\n",
      "Epoch: [402 | 1000] LR: 0.001454\n",
      "Train | 16/16 | Loss:0.2259 | MainLoss:0.2115 | Alpha:0.4499 | SPLoss:0.0001 | CLSLoss:0.1435 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3864 | MainLoss:0.3864 | SPLoss:0.0001 | CLSLoss:0.1436 | AUROC:0.9244\n",
      "Test | 128/16 | Loss:0.0651 | MainLoss:0.0651 | SPLoss:0.0001 | CLSLoss:0.1436 | AUROC:0.9990\n",
      "\n",
      "Epoch: [403 | 1000] LR: 0.001451\n",
      "Train | 16/16 | Loss:0.1933 | MainLoss:0.1789 | Alpha:0.4572 | SPLoss:0.0002 | CLSLoss:0.1439 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3871 | MainLoss:0.3871 | SPLoss:0.0002 | CLSLoss:0.1442 | AUROC:0.9241\n",
      "Test | 128/16 | Loss:0.0664 | MainLoss:0.0664 | SPLoss:0.0002 | CLSLoss:0.1442 | AUROC:0.9990\n",
      "\n",
      "Epoch: [404 | 1000] LR: 0.001448\n",
      "Train | 16/16 | Loss:0.2284 | MainLoss:0.2139 | Alpha:0.4493 | SPLoss:0.0002 | CLSLoss:0.1442 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3868 | MainLoss:0.3868 | SPLoss:0.0002 | CLSLoss:0.1439 | AUROC:0.9242\n",
      "Test | 128/16 | Loss:0.0675 | MainLoss:0.0675 | SPLoss:0.0002 | CLSLoss:0.1439 | AUROC:0.9990\n",
      "\n",
      "Epoch: [405 | 1000] LR: 0.001446\n",
      "Train | 16/16 | Loss:0.2156 | MainLoss:0.2012 | Alpha:0.4536 | SPLoss:0.0003 | CLSLoss:0.1439 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3864 | MainLoss:0.3864 | SPLoss:0.0003 | CLSLoss:0.1439 | AUROC:0.9240\n",
      "Test | 128/16 | Loss:0.0665 | MainLoss:0.0665 | SPLoss:0.0003 | CLSLoss:0.1439 | AUROC:0.9991\n",
      "\n",
      "Epoch: [406 | 1000] LR: 0.001443\n",
      "Train | 16/16 | Loss:0.2090 | MainLoss:0.1946 | Alpha:0.4545 | SPLoss:0.0004 | CLSLoss:0.1441 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3869 | MainLoss:0.3869 | SPLoss:0.0004 | CLSLoss:0.1442 | AUROC:0.9240\n",
      "Test | 128/16 | Loss:0.0688 | MainLoss:0.0688 | SPLoss:0.0004 | CLSLoss:0.1442 | AUROC:0.9991\n",
      "\n",
      "Epoch: [407 | 1000] LR: 0.001440\n",
      "Train | 16/16 | Loss:0.2139 | MainLoss:0.1995 | Alpha:0.4528 | SPLoss:0.0005 | CLSLoss:0.1442 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3872 | MainLoss:0.3872 | SPLoss:0.0005 | CLSLoss:0.1443 | AUROC:0.9240\n",
      "Test | 128/16 | Loss:0.0675 | MainLoss:0.0675 | SPLoss:0.0005 | CLSLoss:0.1443 | AUROC:0.9990\n",
      "\n",
      "Epoch: [408 | 1000] LR: 0.001437\n",
      "Train | 16/16 | Loss:0.2028 | MainLoss:0.1883 | Alpha:0.4553 | SPLoss:0.0006 | CLSLoss:0.1443 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3876 | MainLoss:0.3876 | SPLoss:0.0006 | CLSLoss:0.1446 | AUROC:0.9246\n",
      "Test | 128/16 | Loss:0.0678 | MainLoss:0.0678 | SPLoss:0.0006 | CLSLoss:0.1446 | AUROC:0.9990\n",
      "\n",
      "Epoch: [409 | 1000] LR: 0.001434\n",
      "Train | 16/16 | Loss:0.2292 | MainLoss:0.2147 | Alpha:0.4486 | SPLoss:0.0007 | CLSLoss:0.1443 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3876 | MainLoss:0.3876 | SPLoss:0.0007 | CLSLoss:0.1443 | AUROC:0.9250\n",
      "Test | 128/16 | Loss:0.0668 | MainLoss:0.0668 | SPLoss:0.0007 | CLSLoss:0.1443 | AUROC:0.9990\n",
      "\n",
      "Epoch: [410 | 1000] LR: 0.001431\n",
      "Train | 16/16 | Loss:0.2086 | MainLoss:0.1942 | Alpha:0.4543 | SPLoss:0.0008 | CLSLoss:0.1442 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3878 | MainLoss:0.3878 | SPLoss:0.0008 | CLSLoss:0.1444 | AUROC:0.9247\n",
      "Test | 128/16 | Loss:0.0688 | MainLoss:0.0688 | SPLoss:0.0008 | CLSLoss:0.1444 | AUROC:0.9990\n",
      "\n",
      "Epoch: [411 | 1000] LR: 0.001429\n",
      "Train | 16/16 | Loss:0.1981 | MainLoss:0.1835 | Alpha:0.4559 | SPLoss:0.0009 | CLSLoss:0.1447 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3897 | MainLoss:0.3897 | SPLoss:0.0010 | CLSLoss:0.1448 | AUROC:0.9245\n",
      "Test | 128/16 | Loss:0.0660 | MainLoss:0.0660 | SPLoss:0.0010 | CLSLoss:0.1448 | AUROC:0.9990\n",
      "\n",
      "Epoch: [412 | 1000] LR: 0.001426\n",
      "Train | 16/16 | Loss:0.2048 | MainLoss:0.1902 | Alpha:0.4552 | SPLoss:0.0010 | CLSLoss:0.1449 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3890 | MainLoss:0.3890 | SPLoss:0.0011 | CLSLoss:0.1450 | AUROC:0.9250\n",
      "Test | 128/16 | Loss:0.0671 | MainLoss:0.0671 | SPLoss:0.0011 | CLSLoss:0.1450 | AUROC:0.9990\n",
      "\n",
      "Epoch: [413 | 1000] LR: 0.001423\n",
      "Train | 16/16 | Loss:0.2222 | MainLoss:0.2076 | Alpha:0.4514 | SPLoss:0.0011 | CLSLoss:0.1450 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3883 | MainLoss:0.3883 | SPLoss:0.0012 | CLSLoss:0.1448 | AUROC:0.9250\n",
      "Test | 128/16 | Loss:0.0683 | MainLoss:0.0683 | SPLoss:0.0012 | CLSLoss:0.1448 | AUROC:0.9990\n",
      "\n",
      "Epoch: [414 | 1000] LR: 0.001420\n",
      "Train | 16/16 | Loss:0.2020 | MainLoss:0.1873 | Alpha:0.4545 | SPLoss:0.0012 | CLSLoss:0.1450 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3887 | MainLoss:0.3887 | SPLoss:0.0013 | CLSLoss:0.1451 | AUROC:0.9245\n",
      "Test | 128/16 | Loss:0.0687 | MainLoss:0.0687 | SPLoss:0.0013 | CLSLoss:0.1451 | AUROC:0.9990\n",
      "\n",
      "Epoch: [415 | 1000] LR: 0.001417\n",
      "Train | 16/16 | Loss:0.2181 | MainLoss:0.2034 | Alpha:0.4528 | SPLoss:0.0014 | CLSLoss:0.1451 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3895 | MainLoss:0.3895 | SPLoss:0.0014 | CLSLoss:0.1449 | AUROC:0.9245\n",
      "Test | 128/16 | Loss:0.0663 | MainLoss:0.0663 | SPLoss:0.0014 | CLSLoss:0.1449 | AUROC:0.9990\n",
      "\n",
      "Epoch: [416 | 1000] LR: 0.001414\n",
      "Train | 16/16 | Loss:0.2267 | MainLoss:0.2120 | Alpha:0.4495 | SPLoss:0.0015 | CLSLoss:0.1448 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3880 | MainLoss:0.3880 | SPLoss:0.0016 | CLSLoss:0.1447 | AUROC:0.9245\n",
      "Test | 128/16 | Loss:0.0681 | MainLoss:0.0681 | SPLoss:0.0016 | CLSLoss:0.1447 | AUROC:0.9991\n",
      "\n",
      "Epoch: [417 | 1000] LR: 0.001412\n",
      "Train | 16/16 | Loss:0.2063 | MainLoss:0.1916 | Alpha:0.4545 | SPLoss:0.0016 | CLSLoss:0.1448 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3889 | MainLoss:0.3889 | SPLoss:0.0017 | CLSLoss:0.1448 | AUROC:0.9244\n",
      "Test | 128/16 | Loss:0.0676 | MainLoss:0.0676 | SPLoss:0.0017 | CLSLoss:0.1448 | AUROC:0.9990\n",
      "\n",
      "Epoch: [418 | 1000] LR: 0.001409\n",
      "Train | 16/16 | Loss:0.2234 | MainLoss:0.2088 | Alpha:0.4503 | SPLoss:0.0018 | CLSLoss:0.1448 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3885 | MainLoss:0.3885 | SPLoss:0.0018 | CLSLoss:0.1446 | AUROC:0.9245\n",
      "Test | 128/16 | Loss:0.0673 | MainLoss:0.0673 | SPLoss:0.0018 | CLSLoss:0.1446 | AUROC:0.9990\n",
      "\n",
      "Epoch: [419 | 1000] LR: 0.001406\n",
      "Train | 16/16 | Loss:0.2035 | MainLoss:0.1889 | Alpha:0.4548 | SPLoss:0.0019 | CLSLoss:0.1447 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3892 | MainLoss:0.3892 | SPLoss:0.0020 | CLSLoss:0.1448 | AUROC:0.9245\n",
      "Test | 128/16 | Loss:0.0668 | MainLoss:0.0668 | SPLoss:0.0020 | CLSLoss:0.1448 | AUROC:0.9990\n",
      "\n",
      "Epoch: [420 | 1000] LR: 0.001403\n",
      "Train | 16/16 | Loss:0.2135 | MainLoss:0.1988 | Alpha:0.4526 | SPLoss:0.0020 | CLSLoss:0.1448 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3882 | MainLoss:0.3882 | SPLoss:0.0021 | CLSLoss:0.1447 | AUROC:0.9246\n",
      "Test | 128/16 | Loss:0.0671 | MainLoss:0.0671 | SPLoss:0.0021 | CLSLoss:0.1447 | AUROC:0.9991\n",
      "\n",
      "Epoch: [421 | 1000] LR: 0.001400\n",
      "Train | 16/16 | Loss:0.2209 | MainLoss:0.2062 | Alpha:0.4510 | SPLoss:0.0021 | CLSLoss:0.1447 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3869 | MainLoss:0.3869 | SPLoss:0.0022 | CLSLoss:0.1445 | AUROC:0.9247\n",
      "Test | 128/16 | Loss:0.0694 | MainLoss:0.0694 | SPLoss:0.0022 | CLSLoss:0.1445 | AUROC:0.9990\n",
      "\n",
      "Epoch: [422 | 1000] LR: 0.001397\n",
      "Train | 16/16 | Loss:0.1985 | MainLoss:0.1838 | Alpha:0.4553 | SPLoss:0.0022 | CLSLoss:0.1447 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3880 | MainLoss:0.3880 | SPLoss:0.0023 | CLSLoss:0.1448 | AUROC:0.9249\n",
      "Test | 128/16 | Loss:0.0670 | MainLoss:0.0670 | SPLoss:0.0023 | CLSLoss:0.1448 | AUROC:0.9991\n",
      "\n",
      "Epoch: [423 | 1000] LR: 0.001394\n",
      "Train | 16/16 | Loss:0.2202 | MainLoss:0.2055 | Alpha:0.4492 | SPLoss:0.0024 | CLSLoss:0.1447 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3872 | MainLoss:0.3872 | SPLoss:0.0025 | CLSLoss:0.1447 | AUROC:0.9251\n",
      "Test | 128/16 | Loss:0.0680 | MainLoss:0.0680 | SPLoss:0.0025 | CLSLoss:0.1447 | AUROC:0.9991\n",
      "\n",
      "Epoch: [424 | 1000] LR: 0.001391\n",
      "Train | 16/16 | Loss:0.2299 | MainLoss:0.2152 | Alpha:0.4480 | SPLoss:0.0026 | CLSLoss:0.1445 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3859 | MainLoss:0.3859 | SPLoss:0.0026 | CLSLoss:0.1443 | AUROC:0.9254\n",
      "Test | 128/16 | Loss:0.0681 | MainLoss:0.0681 | SPLoss:0.0026 | CLSLoss:0.1443 | AUROC:0.9990\n",
      "\n",
      "Epoch: [425 | 1000] LR: 0.001388\n",
      "Train | 16/16 | Loss:0.2437 | MainLoss:0.2290 | Alpha:0.4446 | SPLoss:0.0027 | CLSLoss:0.1439 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3852 | MainLoss:0.3852 | SPLoss:0.0028 | CLSLoss:0.1438 | AUROC:0.9250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 128/16 | Loss:0.0689 | MainLoss:0.0689 | SPLoss:0.0028 | CLSLoss:0.1438 | AUROC:0.9990\n",
      "\n",
      "Epoch: [426 | 1000] LR: 0.001386\n",
      "Train | 16/16 | Loss:0.2084 | MainLoss:0.1937 | Alpha:0.4531 | SPLoss:0.0029 | CLSLoss:0.1437 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3860 | MainLoss:0.3860 | SPLoss:0.0030 | CLSLoss:0.1439 | AUROC:0.9254\n",
      "Test | 128/16 | Loss:0.0681 | MainLoss:0.0681 | SPLoss:0.0030 | CLSLoss:0.1439 | AUROC:0.9990\n",
      "\n",
      "Epoch: [427 | 1000] LR: 0.001383\n",
      "Train | 16/16 | Loss:0.2121 | MainLoss:0.1974 | Alpha:0.4532 | SPLoss:0.0030 | CLSLoss:0.1440 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3867 | MainLoss:0.3867 | SPLoss:0.0031 | CLSLoss:0.1440 | AUROC:0.9254\n",
      "Test | 128/16 | Loss:0.0683 | MainLoss:0.0683 | SPLoss:0.0031 | CLSLoss:0.1440 | AUROC:0.9990\n",
      "\n",
      "Epoch: [428 | 1000] LR: 0.001380\n",
      "Train | 16/16 | Loss:0.2127 | MainLoss:0.1980 | Alpha:0.4514 | SPLoss:0.0032 | CLSLoss:0.1440 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3867 | MainLoss:0.3867 | SPLoss:0.0032 | CLSLoss:0.1440 | AUROC:0.9251\n",
      "Test | 128/16 | Loss:0.0670 | MainLoss:0.0670 | SPLoss:0.0032 | CLSLoss:0.1440 | AUROC:0.9991\n",
      "\n",
      "Epoch: [429 | 1000] LR: 0.001377\n",
      "Train | 16/16 | Loss:0.2215 | MainLoss:0.2068 | Alpha:0.4502 | SPLoss:0.0033 | CLSLoss:0.1439 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3861 | MainLoss:0.3861 | SPLoss:0.0034 | CLSLoss:0.1439 | AUROC:0.9255\n",
      "Test | 128/16 | Loss:0.0698 | MainLoss:0.0698 | SPLoss:0.0034 | CLSLoss:0.1439 | AUROC:0.9990\n",
      "\n",
      "Epoch: [430 | 1000] LR: 0.001374\n",
      "Train | 16/16 | Loss:0.2017 | MainLoss:0.1870 | Alpha:0.4549 | SPLoss:0.0034 | CLSLoss:0.1439 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3868 | MainLoss:0.3868 | SPLoss:0.0035 | CLSLoss:0.1442 | AUROC:0.9256\n",
      "Test | 128/16 | Loss:0.0700 | MainLoss:0.0700 | SPLoss:0.0035 | CLSLoss:0.1442 | AUROC:0.9990\n",
      "\n",
      "Epoch: [431 | 1000] LR: 0.001371\n",
      "Train | 16/16 | Loss:0.2162 | MainLoss:0.2014 | Alpha:0.4521 | SPLoss:0.0035 | CLSLoss:0.1441 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3865 | MainLoss:0.3865 | SPLoss:0.0036 | CLSLoss:0.1441 | AUROC:0.9254\n",
      "Test | 128/16 | Loss:0.0698 | MainLoss:0.0698 | SPLoss:0.0036 | CLSLoss:0.1441 | AUROC:0.9990\n",
      "\n",
      "Epoch: [432 | 1000] LR: 0.001368\n",
      "Train | 16/16 | Loss:0.2131 | MainLoss:0.1983 | Alpha:0.4521 | SPLoss:0.0037 | CLSLoss:0.1440 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3872 | MainLoss:0.3872 | SPLoss:0.0038 | CLSLoss:0.1440 | AUROC:0.9251\n",
      "Test | 128/16 | Loss:0.0681 | MainLoss:0.0681 | SPLoss:0.0038 | CLSLoss:0.1440 | AUROC:0.9990\n",
      "\n",
      "Epoch: [433 | 1000] LR: 0.001365\n",
      "Train | 16/16 | Loss:0.2002 | MainLoss:0.1854 | Alpha:0.4549 | SPLoss:0.0039 | CLSLoss:0.1441 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3879 | MainLoss:0.3879 | SPLoss:0.0040 | CLSLoss:0.1443 | AUROC:0.9252\n",
      "Test | 128/16 | Loss:0.0682 | MainLoss:0.0682 | SPLoss:0.0040 | CLSLoss:0.1443 | AUROC:0.9990\n",
      "\n",
      "Epoch: [434 | 1000] LR: 0.001362\n",
      "Train | 16/16 | Loss:0.2098 | MainLoss:0.1950 | Alpha:0.4529 | SPLoss:0.0040 | CLSLoss:0.1442 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3883 | MainLoss:0.3883 | SPLoss:0.0041 | CLSLoss:0.1443 | AUROC:0.9247\n",
      "Test | 128/16 | Loss:0.0689 | MainLoss:0.0689 | SPLoss:0.0041 | CLSLoss:0.1443 | AUROC:0.9991\n",
      "\n",
      "Epoch: [435 | 1000] LR: 0.001359\n",
      "Train | 16/16 | Loss:0.2164 | MainLoss:0.2015 | Alpha:0.4513 | SPLoss:0.0042 | CLSLoss:0.1442 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3886 | MainLoss:0.3886 | SPLoss:0.0043 | CLSLoss:0.1443 | AUROC:0.9247\n",
      "Test | 128/16 | Loss:0.0695 | MainLoss:0.0695 | SPLoss:0.0043 | CLSLoss:0.1443 | AUROC:0.9990\n",
      "\n",
      "Epoch: [436 | 1000] LR: 0.001356\n",
      "Train | 16/16 | Loss:0.1989 | MainLoss:0.1840 | Alpha:0.4537 | SPLoss:0.0044 | CLSLoss:0.1444 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3890 | MainLoss:0.3890 | SPLoss:0.0045 | CLSLoss:0.1445 | AUROC:0.9250\n",
      "Test | 128/16 | Loss:0.0701 | MainLoss:0.0701 | SPLoss:0.0045 | CLSLoss:0.1445 | AUROC:0.9990\n",
      "\n",
      "Epoch: [437 | 1000] LR: 0.001353\n",
      "Train | 16/16 | Loss:0.2082 | MainLoss:0.1933 | Alpha:0.4537 | SPLoss:0.0045 | CLSLoss:0.1446 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3898 | MainLoss:0.3898 | SPLoss:0.0046 | CLSLoss:0.1446 | AUROC:0.9251\n",
      "Test | 128/16 | Loss:0.0681 | MainLoss:0.0681 | SPLoss:0.0046 | CLSLoss:0.1446 | AUROC:0.9990\n",
      "\n",
      "Epoch: [438 | 1000] LR: 0.001351\n",
      "Train | 16/16 | Loss:0.2159 | MainLoss:0.2010 | Alpha:0.4508 | SPLoss:0.0047 | CLSLoss:0.1444 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3887 | MainLoss:0.3887 | SPLoss:0.0048 | CLSLoss:0.1443 | AUROC:0.9251\n",
      "Test | 128/16 | Loss:0.0703 | MainLoss:0.0703 | SPLoss:0.0048 | CLSLoss:0.1443 | AUROC:0.9991\n",
      "\n",
      "Epoch: [439 | 1000] LR: 0.001348\n",
      "Train | 16/16 | Loss:0.1936 | MainLoss:0.1786 | Alpha:0.4566 | SPLoss:0.0049 | CLSLoss:0.1444 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3894 | MainLoss:0.3894 | SPLoss:0.0050 | CLSLoss:0.1447 | AUROC:0.9251\n",
      "Test | 128/16 | Loss:0.0695 | MainLoss:0.0695 | SPLoss:0.0050 | CLSLoss:0.1447 | AUROC:0.9990\n",
      "\n",
      "Epoch: [440 | 1000] LR: 0.001345\n",
      "Train | 16/16 | Loss:0.2210 | MainLoss:0.2060 | Alpha:0.4504 | SPLoss:0.0051 | CLSLoss:0.1447 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3890 | MainLoss:0.3890 | SPLoss:0.0051 | CLSLoss:0.1444 | AUROC:0.9251\n",
      "Test | 128/16 | Loss:0.0695 | MainLoss:0.0695 | SPLoss:0.0051 | CLSLoss:0.1444 | AUROC:0.9990\n",
      "\n",
      "Epoch: [441 | 1000] LR: 0.001342\n",
      "Train | 16/16 | Loss:0.1995 | MainLoss:0.1845 | Alpha:0.4541 | SPLoss:0.0052 | CLSLoss:0.1446 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3897 | MainLoss:0.3897 | SPLoss:0.0053 | CLSLoss:0.1446 | AUROC:0.9251\n",
      "Test | 128/16 | Loss:0.0696 | MainLoss:0.0696 | SPLoss:0.0053 | CLSLoss:0.1446 | AUROC:0.9990\n",
      "\n",
      "Epoch: [442 | 1000] LR: 0.001339\n",
      "Train | 16/16 | Loss:0.2169 | MainLoss:0.2019 | Alpha:0.4502 | SPLoss:0.0054 | CLSLoss:0.1446 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3895 | MainLoss:0.3895 | SPLoss:0.0055 | CLSLoss:0.1444 | AUROC:0.9254\n",
      "Test | 128/16 | Loss:0.0689 | MainLoss:0.0689 | SPLoss:0.0055 | CLSLoss:0.1444 | AUROC:0.9990\n",
      "\n",
      "Epoch: [443 | 1000] LR: 0.001336\n",
      "Train | 16/16 | Loss:0.2086 | MainLoss:0.1936 | Alpha:0.4530 | SPLoss:0.0056 | CLSLoss:0.1445 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3893 | MainLoss:0.3893 | SPLoss:0.0057 | CLSLoss:0.1445 | AUROC:0.9255\n",
      "Test | 128/16 | Loss:0.0688 | MainLoss:0.0688 | SPLoss:0.0057 | CLSLoss:0.1445 | AUROC:0.9990\n",
      "\n",
      "Epoch: [444 | 1000] LR: 0.001333\n",
      "Train | 16/16 | Loss:0.2148 | MainLoss:0.1998 | Alpha:0.4506 | SPLoss:0.0058 | CLSLoss:0.1444 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3889 | MainLoss:0.3889 | SPLoss:0.0059 | CLSLoss:0.1443 | AUROC:0.9252\n",
      "Test | 128/16 | Loss:0.0685 | MainLoss:0.0685 | SPLoss:0.0059 | CLSLoss:0.1443 | AUROC:0.9990\n",
      "\n",
      "Epoch: [445 | 1000] LR: 0.001330\n",
      "Train | 16/16 | Loss:0.2198 | MainLoss:0.2048 | Alpha:0.4505 | SPLoss:0.0059 | CLSLoss:0.1442 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3920 | MainLoss:0.3920 | SPLoss:0.0060 | CLSLoss:0.1441 | AUROC:0.9242\n",
      "Test | 128/16 | Loss:0.0696 | MainLoss:0.0696 | SPLoss:0.0060 | CLSLoss:0.1441 | AUROC:0.9989\n",
      "\n",
      "Epoch: [446 | 1000] LR: 0.001327\n",
      "Train | 16/16 | Loss:0.2078 | MainLoss:0.1928 | Alpha:0.4537 | SPLoss:0.0061 | CLSLoss:0.1440 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3882 | MainLoss:0.3882 | SPLoss:0.0062 | CLSLoss:0.1440 | AUROC:0.9256\n",
      "Test | 128/16 | Loss:0.0677 | MainLoss:0.0677 | SPLoss:0.0062 | CLSLoss:0.1440 | AUROC:0.9990\n",
      "\n",
      "Epoch: [447 | 1000] LR: 0.001324\n",
      "Train | 16/16 | Loss:0.2145 | MainLoss:0.1995 | Alpha:0.4512 | SPLoss:0.0063 | CLSLoss:0.1438 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3877 | MainLoss:0.3877 | SPLoss:0.0064 | CLSLoss:0.1439 | AUROC:0.9252\n",
      "Test | 128/16 | Loss:0.0692 | MainLoss:0.0692 | SPLoss:0.0064 | CLSLoss:0.1439 | AUROC:0.9990\n",
      "\n",
      "Epoch: [448 | 1000] LR: 0.001321\n",
      "Train | 16/16 | Loss:0.2195 | MainLoss:0.2044 | Alpha:0.4509 | SPLoss:0.0064 | CLSLoss:0.1438 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3879 | MainLoss:0.3879 | SPLoss:0.0065 | CLSLoss:0.1439 | AUROC:0.9256\n",
      "Test | 128/16 | Loss:0.0699 | MainLoss:0.0699 | SPLoss:0.0065 | CLSLoss:0.1439 | AUROC:0.9990\n",
      "\n",
      "Epoch: [449 | 1000] LR: 0.001318\n",
      "Train | 16/16 | Loss:0.2220 | MainLoss:0.2069 | Alpha:0.4499 | SPLoss:0.0066 | CLSLoss:0.1438 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3873 | MainLoss:0.3873 | SPLoss:0.0067 | CLSLoss:0.1435 | AUROC:0.9251\n",
      "Test | 128/16 | Loss:0.0699 | MainLoss:0.0699 | SPLoss:0.0067 | CLSLoss:0.1435 | AUROC:0.9990\n",
      "\n",
      "Epoch: [450 | 1000] LR: 0.001315\n",
      "Train | 16/16 | Loss:0.2122 | MainLoss:0.1971 | Alpha:0.4517 | SPLoss:0.0068 | CLSLoss:0.1435 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3873 | MainLoss:0.3873 | SPLoss:0.0069 | CLSLoss:0.1435 | AUROC:0.9256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 128/16 | Loss:0.0699 | MainLoss:0.0699 | SPLoss:0.0069 | CLSLoss:0.1435 | AUROC:0.9990\n",
      "\n",
      "Epoch: [451 | 1000] LR: 0.001312\n",
      "Train | 16/16 | Loss:0.2289 | MainLoss:0.2139 | Alpha:0.4474 | SPLoss:0.0070 | CLSLoss:0.1434 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3864 | MainLoss:0.3864 | SPLoss:0.0070 | CLSLoss:0.1432 | AUROC:0.9254\n",
      "Test | 128/16 | Loss:0.0699 | MainLoss:0.0699 | SPLoss:0.0070 | CLSLoss:0.1432 | AUROC:0.9990\n",
      "\n",
      "Epoch: [452 | 1000] LR: 0.001309\n",
      "Train | 16/16 | Loss:0.2006 | MainLoss:0.1856 | Alpha:0.4536 | SPLoss:0.0072 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3875 | MainLoss:0.3875 | SPLoss:0.0073 | CLSLoss:0.1434 | AUROC:0.9253\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0073 | CLSLoss:0.1434 | AUROC:0.9990\n",
      "\n",
      "Epoch: [453 | 1000] LR: 0.001306\n",
      "Train | 16/16 | Loss:0.1957 | MainLoss:0.1807 | Alpha:0.4549 | SPLoss:0.0074 | CLSLoss:0.1435 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3882 | MainLoss:0.3882 | SPLoss:0.0075 | CLSLoss:0.1436 | AUROC:0.9256\n",
      "Test | 128/16 | Loss:0.0671 | MainLoss:0.0671 | SPLoss:0.0075 | CLSLoss:0.1436 | AUROC:0.9990\n",
      "\n",
      "Epoch: [454 | 1000] LR: 0.001303\n",
      "Train | 16/16 | Loss:0.1931 | MainLoss:0.1780 | Alpha:0.4560 | SPLoss:0.0076 | CLSLoss:0.1437 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3888 | MainLoss:0.3888 | SPLoss:0.0076 | CLSLoss:0.1439 | AUROC:0.9249\n",
      "Test | 128/16 | Loss:0.0688 | MainLoss:0.0688 | SPLoss:0.0076 | CLSLoss:0.1439 | AUROC:0.9990\n",
      "\n",
      "Epoch: [455 | 1000] LR: 0.001300\n",
      "Train | 16/16 | Loss:0.2200 | MainLoss:0.2049 | Alpha:0.4505 | SPLoss:0.0077 | CLSLoss:0.1438 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3888 | MainLoss:0.3888 | SPLoss:0.0078 | CLSLoss:0.1437 | AUROC:0.9256\n",
      "Test | 128/16 | Loss:0.0670 | MainLoss:0.0670 | SPLoss:0.0078 | CLSLoss:0.1437 | AUROC:0.9990\n",
      "\n",
      "Epoch: [456 | 1000] LR: 0.001297\n",
      "Train | 16/16 | Loss:0.2017 | MainLoss:0.1866 | Alpha:0.4537 | SPLoss:0.0079 | CLSLoss:0.1438 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3890 | MainLoss:0.3890 | SPLoss:0.0080 | CLSLoss:0.1438 | AUROC:0.9249\n",
      "Test | 128/16 | Loss:0.0675 | MainLoss:0.0675 | SPLoss:0.0080 | CLSLoss:0.1438 | AUROC:0.9990\n",
      "\n",
      "Epoch: [457 | 1000] LR: 0.001294\n",
      "Train | 16/16 | Loss:0.2046 | MainLoss:0.1894 | Alpha:0.4541 | SPLoss:0.0081 | CLSLoss:0.1438 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3897 | MainLoss:0.3897 | SPLoss:0.0082 | CLSLoss:0.1438 | AUROC:0.9254\n",
      "Test | 128/16 | Loss:0.0665 | MainLoss:0.0665 | SPLoss:0.0082 | CLSLoss:0.1438 | AUROC:0.9990\n",
      "\n",
      "Epoch: [458 | 1000] LR: 0.001291\n",
      "Train | 16/16 | Loss:0.2050 | MainLoss:0.1898 | Alpha:0.4541 | SPLoss:0.0083 | CLSLoss:0.1438 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3903 | MainLoss:0.3903 | SPLoss:0.0084 | CLSLoss:0.1438 | AUROC:0.9253\n",
      "Test | 128/16 | Loss:0.0656 | MainLoss:0.0656 | SPLoss:0.0084 | CLSLoss:0.1438 | AUROC:0.9990\n",
      "\n",
      "Epoch: [459 | 1000] LR: 0.001288\n",
      "Train | 16/16 | Loss:0.2202 | MainLoss:0.2050 | Alpha:0.4499 | SPLoss:0.0084 | CLSLoss:0.1437 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3887 | MainLoss:0.3887 | SPLoss:0.0085 | CLSLoss:0.1436 | AUROC:0.9252\n",
      "Test | 128/16 | Loss:0.0689 | MainLoss:0.0689 | SPLoss:0.0085 | CLSLoss:0.1436 | AUROC:0.9990\n",
      "\n",
      "Epoch: [460 | 1000] LR: 0.001285\n",
      "Train | 16/16 | Loss:0.2169 | MainLoss:0.2017 | Alpha:0.4498 | SPLoss:0.0086 | CLSLoss:0.1434 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3888 | MainLoss:0.3888 | SPLoss:0.0087 | CLSLoss:0.1434 | AUROC:0.9255\n",
      "Test | 128/16 | Loss:0.0677 | MainLoss:0.0677 | SPLoss:0.0087 | CLSLoss:0.1434 | AUROC:0.9990\n",
      "\n",
      "Epoch: [461 | 1000] LR: 0.001282\n",
      "Train | 16/16 | Loss:0.2152 | MainLoss:0.2000 | Alpha:0.4518 | SPLoss:0.0088 | CLSLoss:0.1434 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3890 | MainLoss:0.3890 | SPLoss:0.0089 | CLSLoss:0.1434 | AUROC:0.9252\n",
      "Test | 128/16 | Loss:0.0665 | MainLoss:0.0665 | SPLoss:0.0089 | CLSLoss:0.1434 | AUROC:0.9990\n",
      "\n",
      "Epoch: [462 | 1000] LR: 0.001279\n",
      "Train | 16/16 | Loss:0.2058 | MainLoss:0.1905 | Alpha:0.4534 | SPLoss:0.0090 | CLSLoss:0.1434 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3899 | MainLoss:0.3899 | SPLoss:0.0091 | CLSLoss:0.1434 | AUROC:0.9252\n",
      "Test | 128/16 | Loss:0.0664 | MainLoss:0.0664 | SPLoss:0.0091 | CLSLoss:0.1434 | AUROC:0.9990\n",
      "\n",
      "Epoch: [463 | 1000] LR: 0.001276\n",
      "Train | 16/16 | Loss:0.2009 | MainLoss:0.1856 | Alpha:0.4545 | SPLoss:0.0091 | CLSLoss:0.1434 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3894 | MainLoss:0.3894 | SPLoss:0.0093 | CLSLoss:0.1435 | AUROC:0.9255\n",
      "Test | 128/16 | Loss:0.0664 | MainLoss:0.0664 | SPLoss:0.0093 | CLSLoss:0.1435 | AUROC:0.9990\n",
      "\n",
      "Epoch: [464 | 1000] LR: 0.001273\n",
      "Train | 16/16 | Loss:0.2044 | MainLoss:0.1891 | Alpha:0.4530 | SPLoss:0.0094 | CLSLoss:0.1436 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3890 | MainLoss:0.3890 | SPLoss:0.0095 | CLSLoss:0.1436 | AUROC:0.9251\n",
      "Test | 128/16 | Loss:0.0670 | MainLoss:0.0670 | SPLoss:0.0095 | CLSLoss:0.1436 | AUROC:0.9990\n",
      "\n",
      "Epoch: [465 | 1000] LR: 0.001270\n",
      "Train | 16/16 | Loss:0.1911 | MainLoss:0.1757 | Alpha:0.4561 | SPLoss:0.0096 | CLSLoss:0.1438 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3892 | MainLoss:0.3892 | SPLoss:0.0097 | CLSLoss:0.1440 | AUROC:0.9252\n",
      "Test | 128/16 | Loss:0.0679 | MainLoss:0.0679 | SPLoss:0.0097 | CLSLoss:0.1440 | AUROC:0.9990\n",
      "\n",
      "Epoch: [466 | 1000] LR: 0.001267\n",
      "Train | 16/16 | Loss:0.2019 | MainLoss:0.1865 | Alpha:0.4537 | SPLoss:0.0098 | CLSLoss:0.1441 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3894 | MainLoss:0.3894 | SPLoss:0.0099 | CLSLoss:0.1440 | AUROC:0.9257\n",
      "Test | 128/16 | Loss:0.0683 | MainLoss:0.0683 | SPLoss:0.0099 | CLSLoss:0.1440 | AUROC:0.9990\n",
      "\n",
      "Epoch: [467 | 1000] LR: 0.001264\n",
      "Train | 16/16 | Loss:0.2020 | MainLoss:0.1866 | Alpha:0.4546 | SPLoss:0.0100 | CLSLoss:0.1441 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3898 | MainLoss:0.3898 | SPLoss:0.0101 | CLSLoss:0.1441 | AUROC:0.9255\n",
      "Test | 128/16 | Loss:0.0682 | MainLoss:0.0682 | SPLoss:0.0101 | CLSLoss:0.1441 | AUROC:0.9989\n",
      "\n",
      "Epoch: [468 | 1000] LR: 0.001261\n",
      "Train | 16/16 | Loss:0.1968 | MainLoss:0.1814 | Alpha:0.4539 | SPLoss:0.0102 | CLSLoss:0.1442 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3904 | MainLoss:0.3904 | SPLoss:0.0103 | CLSLoss:0.1443 | AUROC:0.9255\n",
      "Test | 128/16 | Loss:0.0688 | MainLoss:0.0688 | SPLoss:0.0103 | CLSLoss:0.1443 | AUROC:0.9990\n",
      "\n",
      "Epoch: [469 | 1000] LR: 0.001258\n",
      "Train | 16/16 | Loss:0.1924 | MainLoss:0.1769 | Alpha:0.4557 | SPLoss:0.0104 | CLSLoss:0.1444 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3912 | MainLoss:0.3912 | SPLoss:0.0106 | CLSLoss:0.1445 | AUROC:0.9252\n",
      "Test | 128/16 | Loss:0.0686 | MainLoss:0.0686 | SPLoss:0.0106 | CLSLoss:0.1445 | AUROC:0.9990\n",
      "\n",
      "Epoch: [470 | 1000] LR: 0.001255\n",
      "Train | 16/16 | Loss:0.2051 | MainLoss:0.1896 | Alpha:0.4526 | SPLoss:0.0107 | CLSLoss:0.1445 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3919 | MainLoss:0.3919 | SPLoss:0.0108 | CLSLoss:0.1446 | AUROC:0.9253\n",
      "Test | 128/16 | Loss:0.0669 | MainLoss:0.0669 | SPLoss:0.0108 | CLSLoss:0.1446 | AUROC:0.9990\n",
      "\n",
      "Epoch: [471 | 1000] LR: 0.001252\n",
      "Train | 16/16 | Loss:0.2208 | MainLoss:0.2053 | Alpha:0.4510 | SPLoss:0.0108 | CLSLoss:0.1443 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3903 | MainLoss:0.3903 | SPLoss:0.0109 | CLSLoss:0.1442 | AUROC:0.9257\n",
      "Test | 128/16 | Loss:0.0676 | MainLoss:0.0676 | SPLoss:0.0109 | CLSLoss:0.1442 | AUROC:0.9990\n",
      "\n",
      "Epoch: [472 | 1000] LR: 0.001249\n",
      "Train | 16/16 | Loss:0.2006 | MainLoss:0.1850 | Alpha:0.4534 | SPLoss:0.0110 | CLSLoss:0.1441 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3910 | MainLoss:0.3910 | SPLoss:0.0111 | CLSLoss:0.1443 | AUROC:0.9254\n",
      "Test | 128/16 | Loss:0.0665 | MainLoss:0.0665 | SPLoss:0.0111 | CLSLoss:0.1443 | AUROC:0.9989\n",
      "\n",
      "Epoch: [473 | 1000] LR: 0.001246\n",
      "Train | 16/16 | Loss:0.1959 | MainLoss:0.1803 | Alpha:0.4544 | SPLoss:0.0112 | CLSLoss:0.1445 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3910 | MainLoss:0.3910 | SPLoss:0.0113 | CLSLoss:0.1444 | AUROC:0.9253\n",
      "Test | 128/16 | Loss:0.0708 | MainLoss:0.0708 | SPLoss:0.0113 | CLSLoss:0.1444 | AUROC:0.9990\n",
      "\n",
      "Epoch: [474 | 1000] LR: 0.001243\n",
      "Train | 16/16 | Loss:0.2032 | MainLoss:0.1877 | Alpha:0.4539 | SPLoss:0.0114 | CLSLoss:0.1445 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3901 | MainLoss:0.3901 | SPLoss:0.0115 | CLSLoss:0.1445 | AUROC:0.9254\n",
      "Test | 128/16 | Loss:0.0689 | MainLoss:0.0689 | SPLoss:0.0115 | CLSLoss:0.1445 | AUROC:0.9990\n",
      "\n",
      "Epoch: [475 | 1000] LR: 0.001240\n",
      "Train | 16/16 | Loss:0.1950 | MainLoss:0.1794 | Alpha:0.4547 | SPLoss:0.0116 | CLSLoss:0.1446 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3908 | MainLoss:0.3908 | SPLoss:0.0117 | CLSLoss:0.1446 | AUROC:0.9256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 128/16 | Loss:0.0671 | MainLoss:0.0671 | SPLoss:0.0117 | CLSLoss:0.1446 | AUROC:0.9990\n",
      "\n",
      "Epoch: [476 | 1000] LR: 0.001236\n",
      "Train | 16/16 | Loss:0.2104 | MainLoss:0.1947 | Alpha:0.4503 | SPLoss:0.0118 | CLSLoss:0.1445 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3912 | MainLoss:0.3912 | SPLoss:0.0119 | CLSLoss:0.1444 | AUROC:0.9258\n",
      "Test | 128/16 | Loss:0.0663 | MainLoss:0.0663 | SPLoss:0.0119 | CLSLoss:0.1444 | AUROC:0.9990\n",
      "\n",
      "Epoch: [477 | 1000] LR: 0.001233\n",
      "Train | 16/16 | Loss:0.1788 | MainLoss:0.1631 | Alpha:0.4589 | SPLoss:0.0120 | CLSLoss:0.1446 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3925 | MainLoss:0.3925 | SPLoss:0.0121 | CLSLoss:0.1449 | AUROC:0.9255\n",
      "Test | 128/16 | Loss:0.0664 | MainLoss:0.0664 | SPLoss:0.0121 | CLSLoss:0.1449 | AUROC:0.9990\n",
      "\n",
      "Epoch: [478 | 1000] LR: 0.001230\n",
      "Train | 16/16 | Loss:0.1927 | MainLoss:0.1770 | Alpha:0.4557 | SPLoss:0.0122 | CLSLoss:0.1449 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3933 | MainLoss:0.3933 | SPLoss:0.0123 | CLSLoss:0.1450 | AUROC:0.9258\n",
      "Test | 128/16 | Loss:0.0663 | MainLoss:0.0663 | SPLoss:0.0123 | CLSLoss:0.1450 | AUROC:0.9990\n",
      "\n",
      "Epoch: [479 | 1000] LR: 0.001227\n",
      "Train | 16/16 | Loss:0.2055 | MainLoss:0.1898 | Alpha:0.4535 | SPLoss:0.0124 | CLSLoss:0.1450 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3928 | MainLoss:0.3928 | SPLoss:0.0125 | CLSLoss:0.1449 | AUROC:0.9254\n",
      "Test | 128/16 | Loss:0.0668 | MainLoss:0.0668 | SPLoss:0.0125 | CLSLoss:0.1449 | AUROC:0.9990\n",
      "\n",
      "Epoch: [480 | 1000] LR: 0.001224\n",
      "Train | 16/16 | Loss:0.2073 | MainLoss:0.1915 | Alpha:0.4521 | SPLoss:0.0126 | CLSLoss:0.1449 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3927 | MainLoss:0.3927 | SPLoss:0.0127 | CLSLoss:0.1447 | AUROC:0.9256\n",
      "Test | 128/16 | Loss:0.0666 | MainLoss:0.0666 | SPLoss:0.0127 | CLSLoss:0.1447 | AUROC:0.9990\n",
      "\n",
      "Epoch: [481 | 1000] LR: 0.001221\n",
      "Train | 16/16 | Loss:0.2224 | MainLoss:0.2066 | Alpha:0.4483 | SPLoss:0.0128 | CLSLoss:0.1446 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3924 | MainLoss:0.3924 | SPLoss:0.0129 | CLSLoss:0.1443 | AUROC:0.9253\n",
      "Test | 128/16 | Loss:0.0656 | MainLoss:0.0656 | SPLoss:0.0129 | CLSLoss:0.1443 | AUROC:0.9990\n",
      "\n",
      "Epoch: [482 | 1000] LR: 0.001218\n",
      "Train | 16/16 | Loss:0.2167 | MainLoss:0.2010 | Alpha:0.4510 | SPLoss:0.0130 | CLSLoss:0.1442 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3918 | MainLoss:0.3918 | SPLoss:0.0131 | CLSLoss:0.1441 | AUROC:0.9256\n",
      "Test | 128/16 | Loss:0.0656 | MainLoss:0.0656 | SPLoss:0.0131 | CLSLoss:0.1441 | AUROC:0.9990\n",
      "\n",
      "Epoch: [483 | 1000] LR: 0.001215\n",
      "Train | 16/16 | Loss:0.2032 | MainLoss:0.1875 | Alpha:0.4533 | SPLoss:0.0132 | CLSLoss:0.1440 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3917 | MainLoss:0.3917 | SPLoss:0.0133 | CLSLoss:0.1441 | AUROC:0.9257\n",
      "Test | 128/16 | Loss:0.0668 | MainLoss:0.0668 | SPLoss:0.0133 | CLSLoss:0.1441 | AUROC:0.9990\n",
      "\n",
      "Epoch: [484 | 1000] LR: 0.001212\n",
      "Train | 16/16 | Loss:0.2253 | MainLoss:0.2096 | Alpha:0.4480 | SPLoss:0.0134 | CLSLoss:0.1439 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3913 | MainLoss:0.3913 | SPLoss:0.0135 | CLSLoss:0.1437 | AUROC:0.9252\n",
      "Test | 128/16 | Loss:0.0671 | MainLoss:0.0671 | SPLoss:0.0135 | CLSLoss:0.1437 | AUROC:0.9990\n",
      "\n",
      "Epoch: [485 | 1000] LR: 0.001209\n",
      "Train | 16/16 | Loss:0.1941 | MainLoss:0.1783 | Alpha:0.4544 | SPLoss:0.0136 | CLSLoss:0.1438 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3921 | MainLoss:0.3921 | SPLoss:0.0138 | CLSLoss:0.1438 | AUROC:0.9249\n",
      "Test | 128/16 | Loss:0.0654 | MainLoss:0.0654 | SPLoss:0.0138 | CLSLoss:0.1438 | AUROC:0.9990\n",
      "\n",
      "Epoch: [486 | 1000] LR: 0.001206\n",
      "Train | 16/16 | Loss:0.1926 | MainLoss:0.1768 | Alpha:0.4558 | SPLoss:0.0139 | CLSLoss:0.1439 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3926 | MainLoss:0.3926 | SPLoss:0.0140 | CLSLoss:0.1440 | AUROC:0.9250\n",
      "Test | 128/16 | Loss:0.0642 | MainLoss:0.0642 | SPLoss:0.0140 | CLSLoss:0.1440 | AUROC:0.9990\n",
      "\n",
      "Epoch: [487 | 1000] LR: 0.001203\n",
      "Train | 16/16 | Loss:0.2025 | MainLoss:0.1867 | Alpha:0.4530 | SPLoss:0.0141 | CLSLoss:0.1440 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3929 | MainLoss:0.3929 | SPLoss:0.0142 | CLSLoss:0.1440 | AUROC:0.9251\n",
      "Test | 128/16 | Loss:0.0634 | MainLoss:0.0634 | SPLoss:0.0142 | CLSLoss:0.1440 | AUROC:0.9990\n",
      "\n",
      "Epoch: [488 | 1000] LR: 0.001200\n",
      "Train | 16/16 | Loss:0.1990 | MainLoss:0.1832 | Alpha:0.4532 | SPLoss:0.0144 | CLSLoss:0.1441 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3943 | MainLoss:0.3943 | SPLoss:0.0145 | CLSLoss:0.1441 | AUROC:0.9251\n",
      "Test | 128/16 | Loss:0.0624 | MainLoss:0.0624 | SPLoss:0.0145 | CLSLoss:0.1441 | AUROC:0.9990\n",
      "\n",
      "Epoch: [489 | 1000] LR: 0.001197\n",
      "Train | 16/16 | Loss:0.1966 | MainLoss:0.1807 | Alpha:0.4542 | SPLoss:0.0146 | CLSLoss:0.1442 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3927 | MainLoss:0.3927 | SPLoss:0.0147 | CLSLoss:0.1442 | AUROC:0.9252\n",
      "Test | 128/16 | Loss:0.0644 | MainLoss:0.0644 | SPLoss:0.0147 | CLSLoss:0.1442 | AUROC:0.9991\n",
      "\n",
      "Epoch: [490 | 1000] LR: 0.001194\n",
      "Train | 16/16 | Loss:0.2089 | MainLoss:0.1930 | Alpha:0.4523 | SPLoss:0.0148 | CLSLoss:0.1441 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3928 | MainLoss:0.3928 | SPLoss:0.0150 | CLSLoss:0.1441 | AUROC:0.9251\n",
      "Test | 128/16 | Loss:0.0638 | MainLoss:0.0638 | SPLoss:0.0150 | CLSLoss:0.1441 | AUROC:0.9991\n",
      "\n",
      "Epoch: [491 | 1000] LR: 0.001190\n",
      "Train | 16/16 | Loss:0.1926 | MainLoss:0.1767 | Alpha:0.4543 | SPLoss:0.0151 | CLSLoss:0.1442 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3928 | MainLoss:0.3928 | SPLoss:0.0152 | CLSLoss:0.1443 | AUROC:0.9252\n",
      "Test | 128/16 | Loss:0.0648 | MainLoss:0.0648 | SPLoss:0.0152 | CLSLoss:0.1443 | AUROC:0.9990\n",
      "\n",
      "Epoch: [492 | 1000] LR: 0.001187\n",
      "Train | 16/16 | Loss:0.2100 | MainLoss:0.1941 | Alpha:0.4515 | SPLoss:0.0153 | CLSLoss:0.1441 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3923 | MainLoss:0.3923 | SPLoss:0.0154 | CLSLoss:0.1442 | AUROC:0.9250\n",
      "Test | 128/16 | Loss:0.0666 | MainLoss:0.0666 | SPLoss:0.0154 | CLSLoss:0.1442 | AUROC:0.9991\n",
      "\n",
      "Epoch: [493 | 1000] LR: 0.001184\n",
      "Train | 16/16 | Loss:0.2120 | MainLoss:0.1960 | Alpha:0.4511 | SPLoss:0.0155 | CLSLoss:0.1441 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3923 | MainLoss:0.3923 | SPLoss:0.0157 | CLSLoss:0.1440 | AUROC:0.9253\n",
      "Test | 128/16 | Loss:0.0656 | MainLoss:0.0656 | SPLoss:0.0157 | CLSLoss:0.1440 | AUROC:0.9990\n",
      "\n",
      "Epoch: [494 | 1000] LR: 0.001181\n",
      "Train | 16/16 | Loss:0.1978 | MainLoss:0.1818 | Alpha:0.4547 | SPLoss:0.0157 | CLSLoss:0.1441 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3943 | MainLoss:0.3943 | SPLoss:0.0158 | CLSLoss:0.1443 | AUROC:0.9251\n",
      "Test | 128/16 | Loss:0.0639 | MainLoss:0.0639 | SPLoss:0.0158 | CLSLoss:0.1443 | AUROC:0.9990\n",
      "\n",
      "Epoch: [495 | 1000] LR: 0.001178\n",
      "Train | 16/16 | Loss:0.2176 | MainLoss:0.2016 | Alpha:0.4506 | SPLoss:0.0159 | CLSLoss:0.1442 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3922 | MainLoss:0.3922 | SPLoss:0.0160 | CLSLoss:0.1440 | AUROC:0.9255\n",
      "Test | 128/16 | Loss:0.0652 | MainLoss:0.0652 | SPLoss:0.0160 | CLSLoss:0.1440 | AUROC:0.9990\n",
      "\n",
      "Epoch: [496 | 1000] LR: 0.001175\n",
      "Train | 16/16 | Loss:0.2089 | MainLoss:0.1928 | Alpha:0.4506 | SPLoss:0.0161 | CLSLoss:0.1440 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3925 | MainLoss:0.3925 | SPLoss:0.0163 | CLSLoss:0.1439 | AUROC:0.9257\n",
      "Test | 128/16 | Loss:0.0639 | MainLoss:0.0639 | SPLoss:0.0163 | CLSLoss:0.1439 | AUROC:0.9990\n",
      "\n",
      "Epoch: [497 | 1000] LR: 0.001172\n",
      "Train | 16/16 | Loss:0.1998 | MainLoss:0.1837 | Alpha:0.4535 | SPLoss:0.0164 | CLSLoss:0.1439 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3917 | MainLoss:0.3917 | SPLoss:0.0165 | CLSLoss:0.1439 | AUROC:0.9256\n",
      "Test | 128/16 | Loss:0.0657 | MainLoss:0.0657 | SPLoss:0.0165 | CLSLoss:0.1439 | AUROC:0.9990\n",
      "\n",
      "Epoch: [498 | 1000] LR: 0.001169\n",
      "Train | 16/16 | Loss:0.1998 | MainLoss:0.1837 | Alpha:0.4546 | SPLoss:0.0166 | CLSLoss:0.1439 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3906 | MainLoss:0.3906 | SPLoss:0.0167 | CLSLoss:0.1440 | AUROC:0.9251\n",
      "Test | 128/16 | Loss:0.0669 | MainLoss:0.0669 | SPLoss:0.0167 | CLSLoss:0.1440 | AUROC:0.9990\n",
      "\n",
      "Epoch: [499 | 1000] LR: 0.001166\n",
      "Train | 16/16 | Loss:0.2106 | MainLoss:0.1945 | Alpha:0.4515 | SPLoss:0.0168 | CLSLoss:0.1439 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3905 | MainLoss:0.3905 | SPLoss:0.0169 | CLSLoss:0.1438 | AUROC:0.9257\n",
      "Test | 128/16 | Loss:0.0667 | MainLoss:0.0667 | SPLoss:0.0169 | CLSLoss:0.1438 | AUROC:0.9990\n",
      "\n",
      "Epoch: [500 | 1000] LR: 0.001163\n",
      "Train | 16/16 | Loss:0.1946 | MainLoss:0.1786 | Alpha:0.4567 | SPLoss:0.0170 | CLSLoss:0.1438 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3908 | MainLoss:0.3908 | SPLoss:0.0171 | CLSLoss:0.1439 | AUROC:0.9255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 128/16 | Loss:0.0673 | MainLoss:0.0673 | SPLoss:0.0171 | CLSLoss:0.1439 | AUROC:0.9989\n",
      "\n",
      "Epoch: [501 | 1000] LR: 0.001160\n",
      "Train | 16/16 | Loss:0.1930 | MainLoss:0.1786 | Alpha:0.4587 | SPLoss:0.0000 | CLSLoss:0.1441 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3921 | MainLoss:0.3921 | SPLoss:0.0000 | CLSLoss:0.1440 | AUROC:0.9259\n",
      "Test | 128/16 | Loss:0.0647 | MainLoss:0.0647 | SPLoss:0.0000 | CLSLoss:0.1440 | AUROC:0.9990\n",
      "\n",
      "Epoch: [502 | 1000] LR: 0.001156\n",
      "Train | 16/16 | Loss:0.1985 | MainLoss:0.1841 | Alpha:0.4581 | SPLoss:0.0001 | CLSLoss:0.1441 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3927 | MainLoss:0.3927 | SPLoss:0.0001 | CLSLoss:0.1441 | AUROC:0.9252\n",
      "Test | 128/16 | Loss:0.0646 | MainLoss:0.0646 | SPLoss:0.0001 | CLSLoss:0.1441 | AUROC:0.9990\n",
      "\n",
      "Epoch: [503 | 1000] LR: 0.001153\n",
      "Train | 16/16 | Loss:0.2090 | MainLoss:0.1946 | Alpha:0.4543 | SPLoss:0.0001 | CLSLoss:0.1442 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3916 | MainLoss:0.3916 | SPLoss:0.0001 | CLSLoss:0.1439 | AUROC:0.9259\n",
      "Test | 128/16 | Loss:0.0663 | MainLoss:0.0663 | SPLoss:0.0001 | CLSLoss:0.1439 | AUROC:0.9990\n",
      "\n",
      "Epoch: [504 | 1000] LR: 0.001150\n",
      "Train | 16/16 | Loss:0.1946 | MainLoss:0.1802 | Alpha:0.4579 | SPLoss:0.0001 | CLSLoss:0.1440 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3919 | MainLoss:0.3919 | SPLoss:0.0002 | CLSLoss:0.1441 | AUROC:0.9264\n",
      "Test | 128/16 | Loss:0.0664 | MainLoss:0.0664 | SPLoss:0.0002 | CLSLoss:0.1441 | AUROC:0.9990\n",
      "\n",
      "Epoch: [505 | 1000] LR: 0.001147\n",
      "Train | 16/16 | Loss:0.2001 | MainLoss:0.1856 | Alpha:0.4563 | SPLoss:0.0002 | CLSLoss:0.1440 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3922 | MainLoss:0.3922 | SPLoss:0.0002 | CLSLoss:0.1440 | AUROC:0.9258\n",
      "Test | 128/16 | Loss:0.0655 | MainLoss:0.0655 | SPLoss:0.0002 | CLSLoss:0.1440 | AUROC:0.9989\n",
      "\n",
      "Epoch: [506 | 1000] LR: 0.001144\n",
      "Train | 16/16 | Loss:0.1884 | MainLoss:0.1740 | Alpha:0.4585 | SPLoss:0.0002 | CLSLoss:0.1441 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3929 | MainLoss:0.3929 | SPLoss:0.0003 | CLSLoss:0.1442 | AUROC:0.9259\n",
      "Test | 128/16 | Loss:0.0659 | MainLoss:0.0659 | SPLoss:0.0003 | CLSLoss:0.1442 | AUROC:0.9990\n",
      "\n",
      "Epoch: [507 | 1000] LR: 0.001141\n",
      "Train | 16/16 | Loss:0.1926 | MainLoss:0.1781 | Alpha:0.4581 | SPLoss:0.0003 | CLSLoss:0.1443 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3937 | MainLoss:0.3937 | SPLoss:0.0003 | CLSLoss:0.1442 | AUROC:0.9259\n",
      "Test | 128/16 | Loss:0.0652 | MainLoss:0.0652 | SPLoss:0.0003 | CLSLoss:0.1442 | AUROC:0.9989\n",
      "\n",
      "Epoch: [508 | 1000] LR: 0.001138\n",
      "Train | 16/16 | Loss:0.1855 | MainLoss:0.1710 | Alpha:0.4597 | SPLoss:0.0003 | CLSLoss:0.1443 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3938 | MainLoss:0.3938 | SPLoss:0.0004 | CLSLoss:0.1444 | AUROC:0.9259\n",
      "Test | 128/16 | Loss:0.0651 | MainLoss:0.0651 | SPLoss:0.0004 | CLSLoss:0.1444 | AUROC:0.9990\n",
      "\n",
      "Epoch: [509 | 1000] LR: 0.001135\n",
      "Train | 16/16 | Loss:0.1897 | MainLoss:0.1752 | Alpha:0.4591 | SPLoss:0.0004 | CLSLoss:0.1445 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3943 | MainLoss:0.3943 | SPLoss:0.0004 | CLSLoss:0.1446 | AUROC:0.9261\n",
      "Test | 128/16 | Loss:0.0650 | MainLoss:0.0650 | SPLoss:0.0004 | CLSLoss:0.1446 | AUROC:0.9990\n",
      "\n",
      "Epoch: [510 | 1000] LR: 0.001132\n",
      "Train | 16/16 | Loss:0.2001 | MainLoss:0.1856 | Alpha:0.4575 | SPLoss:0.0004 | CLSLoss:0.1445 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3938 | MainLoss:0.3938 | SPLoss:0.0005 | CLSLoss:0.1445 | AUROC:0.9260\n",
      "Test | 128/16 | Loss:0.0660 | MainLoss:0.0660 | SPLoss:0.0005 | CLSLoss:0.1445 | AUROC:0.9990\n",
      "\n",
      "Epoch: [511 | 1000] LR: 0.001128\n",
      "Train | 16/16 | Loss:0.2154 | MainLoss:0.2010 | Alpha:0.4547 | SPLoss:0.0005 | CLSLoss:0.1444 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3930 | MainLoss:0.3930 | SPLoss:0.0005 | CLSLoss:0.1442 | AUROC:0.9260\n",
      "Test | 128/16 | Loss:0.0661 | MainLoss:0.0661 | SPLoss:0.0005 | CLSLoss:0.1442 | AUROC:0.9990\n",
      "\n",
      "Epoch: [512 | 1000] LR: 0.001125\n",
      "Train | 16/16 | Loss:0.1883 | MainLoss:0.1738 | Alpha:0.4602 | SPLoss:0.0005 | CLSLoss:0.1443 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3932 | MainLoss:0.3932 | SPLoss:0.0006 | CLSLoss:0.1443 | AUROC:0.9258\n",
      "Test | 128/16 | Loss:0.0669 | MainLoss:0.0669 | SPLoss:0.0006 | CLSLoss:0.1443 | AUROC:0.9990\n",
      "\n",
      "Epoch: [513 | 1000] LR: 0.001122\n",
      "Train | 16/16 | Loss:0.2026 | MainLoss:0.1881 | Alpha:0.4569 | SPLoss:0.0006 | CLSLoss:0.1443 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3934 | MainLoss:0.3934 | SPLoss:0.0006 | CLSLoss:0.1443 | AUROC:0.9260\n",
      "Test | 128/16 | Loss:0.0666 | MainLoss:0.0666 | SPLoss:0.0006 | CLSLoss:0.1443 | AUROC:0.9989\n",
      "\n",
      "Epoch: [514 | 1000] LR: 0.001119\n",
      "Train | 16/16 | Loss:0.2091 | MainLoss:0.1946 | Alpha:0.4552 | SPLoss:0.0006 | CLSLoss:0.1441 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3924 | MainLoss:0.3924 | SPLoss:0.0007 | CLSLoss:0.1441 | AUROC:0.9261\n",
      "Test | 128/16 | Loss:0.0670 | MainLoss:0.0670 | SPLoss:0.0007 | CLSLoss:0.1441 | AUROC:0.9989\n",
      "\n",
      "Epoch: [515 | 1000] LR: 0.001116\n",
      "Train | 16/16 | Loss:0.2148 | MainLoss:0.2003 | Alpha:0.4534 | SPLoss:0.0007 | CLSLoss:0.1440 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3918 | MainLoss:0.3918 | SPLoss:0.0007 | CLSLoss:0.1438 | AUROC:0.9265\n",
      "Test | 128/16 | Loss:0.0666 | MainLoss:0.0666 | SPLoss:0.0007 | CLSLoss:0.1438 | AUROC:0.9990\n",
      "\n",
      "Epoch: [516 | 1000] LR: 0.001113\n",
      "Train | 16/16 | Loss:0.1981 | MainLoss:0.1836 | Alpha:0.4567 | SPLoss:0.0008 | CLSLoss:0.1439 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3920 | MainLoss:0.3920 | SPLoss:0.0008 | CLSLoss:0.1438 | AUROC:0.9260\n",
      "Test | 128/16 | Loss:0.0669 | MainLoss:0.0669 | SPLoss:0.0008 | CLSLoss:0.1438 | AUROC:0.9990\n",
      "\n",
      "Epoch: [517 | 1000] LR: 0.001110\n",
      "Train | 16/16 | Loss:0.1879 | MainLoss:0.1734 | Alpha:0.4594 | SPLoss:0.0009 | CLSLoss:0.1438 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0009 | CLSLoss:0.1439 | AUROC:0.9261\n",
      "Test | 128/16 | Loss:0.0658 | MainLoss:0.0658 | SPLoss:0.0009 | CLSLoss:0.1439 | AUROC:0.9990\n",
      "\n",
      "Epoch: [518 | 1000] LR: 0.001107\n",
      "Train | 16/16 | Loss:0.2076 | MainLoss:0.1931 | Alpha:0.4554 | SPLoss:0.0009 | CLSLoss:0.1440 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3922 | MainLoss:0.3922 | SPLoss:0.0009 | CLSLoss:0.1437 | AUROC:0.9258\n",
      "Test | 128/16 | Loss:0.0667 | MainLoss:0.0667 | SPLoss:0.0009 | CLSLoss:0.1437 | AUROC:0.9990\n",
      "\n",
      "Epoch: [519 | 1000] LR: 0.001103\n",
      "Train | 16/16 | Loss:0.1989 | MainLoss:0.1844 | Alpha:0.4565 | SPLoss:0.0010 | CLSLoss:0.1437 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3926 | MainLoss:0.3926 | SPLoss:0.0010 | CLSLoss:0.1436 | AUROC:0.9262\n",
      "Test | 128/16 | Loss:0.0660 | MainLoss:0.0660 | SPLoss:0.0010 | CLSLoss:0.1436 | AUROC:0.9990\n",
      "\n",
      "Epoch: [520 | 1000] LR: 0.001100\n",
      "Train | 16/16 | Loss:0.1965 | MainLoss:0.1820 | Alpha:0.4566 | SPLoss:0.0010 | CLSLoss:0.1436 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3934 | MainLoss:0.3934 | SPLoss:0.0011 | CLSLoss:0.1437 | AUROC:0.9263\n",
      "Test | 128/16 | Loss:0.0654 | MainLoss:0.0654 | SPLoss:0.0011 | CLSLoss:0.1437 | AUROC:0.9990\n",
      "\n",
      "Epoch: [521 | 1000] LR: 0.001097\n",
      "Train | 16/16 | Loss:0.1847 | MainLoss:0.1702 | Alpha:0.4600 | SPLoss:0.0011 | CLSLoss:0.1438 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3929 | MainLoss:0.3929 | SPLoss:0.0011 | CLSLoss:0.1440 | AUROC:0.9258\n",
      "Test | 128/16 | Loss:0.0668 | MainLoss:0.0668 | SPLoss:0.0011 | CLSLoss:0.1440 | AUROC:0.9990\n",
      "\n",
      "Epoch: [522 | 1000] LR: 0.001094\n",
      "Train | 16/16 | Loss:0.1924 | MainLoss:0.1779 | Alpha:0.4570 | SPLoss:0.0012 | CLSLoss:0.1441 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3934 | MainLoss:0.3934 | SPLoss:0.0012 | CLSLoss:0.1441 | AUROC:0.9262\n",
      "Test | 128/16 | Loss:0.0663 | MainLoss:0.0663 | SPLoss:0.0012 | CLSLoss:0.1441 | AUROC:0.9990\n",
      "\n",
      "Epoch: [523 | 1000] LR: 0.001091\n",
      "Train | 16/16 | Loss:0.1922 | MainLoss:0.1776 | Alpha:0.4575 | SPLoss:0.0012 | CLSLoss:0.1440 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3940 | MainLoss:0.3940 | SPLoss:0.0013 | CLSLoss:0.1441 | AUROC:0.9259\n",
      "Test | 128/16 | Loss:0.0664 | MainLoss:0.0664 | SPLoss:0.0013 | CLSLoss:0.1441 | AUROC:0.9990\n",
      "\n",
      "Epoch: [524 | 1000] LR: 0.001088\n",
      "Train | 16/16 | Loss:0.2209 | MainLoss:0.2064 | Alpha:0.4514 | SPLoss:0.0013 | CLSLoss:0.1439 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3928 | MainLoss:0.3928 | SPLoss:0.0014 | CLSLoss:0.1437 | AUROC:0.9254\n",
      "Test | 128/16 | Loss:0.0679 | MainLoss:0.0679 | SPLoss:0.0014 | CLSLoss:0.1437 | AUROC:0.9990\n",
      "\n",
      "Epoch: [525 | 1000] LR: 0.001085\n",
      "Train | 16/16 | Loss:0.2085 | MainLoss:0.1940 | Alpha:0.4548 | SPLoss:0.0014 | CLSLoss:0.1435 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3924 | MainLoss:0.3924 | SPLoss:0.0014 | CLSLoss:0.1435 | AUROC:0.9257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 128/16 | Loss:0.0676 | MainLoss:0.0676 | SPLoss:0.0014 | CLSLoss:0.1435 | AUROC:0.9990\n",
      "\n",
      "Epoch: [526 | 1000] LR: 0.001082\n",
      "Train | 16/16 | Loss:0.1996 | MainLoss:0.1851 | Alpha:0.4570 | SPLoss:0.0015 | CLSLoss:0.1436 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3922 | MainLoss:0.3922 | SPLoss:0.0015 | CLSLoss:0.1435 | AUROC:0.9260\n",
      "Test | 128/16 | Loss:0.0672 | MainLoss:0.0672 | SPLoss:0.0015 | CLSLoss:0.1435 | AUROC:0.9990\n",
      "\n",
      "Epoch: [527 | 1000] LR: 0.001078\n",
      "Train | 16/16 | Loss:0.2203 | MainLoss:0.2058 | Alpha:0.4523 | SPLoss:0.0016 | CLSLoss:0.1434 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3920 | MainLoss:0.3920 | SPLoss:0.0016 | CLSLoss:0.1431 | AUROC:0.9259\n",
      "Test | 128/16 | Loss:0.0652 | MainLoss:0.0652 | SPLoss:0.0016 | CLSLoss:0.1431 | AUROC:0.9990\n",
      "\n",
      "Epoch: [528 | 1000] LR: 0.001075\n",
      "Train | 16/16 | Loss:0.1954 | MainLoss:0.1809 | Alpha:0.4576 | SPLoss:0.0016 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3918 | MainLoss:0.3918 | SPLoss:0.0017 | CLSLoss:0.1431 | AUROC:0.9255\n",
      "Test | 128/16 | Loss:0.0664 | MainLoss:0.0664 | SPLoss:0.0017 | CLSLoss:0.1431 | AUROC:0.9990\n",
      "\n",
      "Epoch: [529 | 1000] LR: 0.001072\n",
      "Train | 16/16 | Loss:0.2112 | MainLoss:0.1967 | Alpha:0.4532 | SPLoss:0.0017 | CLSLoss:0.1430 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3916 | MainLoss:0.3916 | SPLoss:0.0018 | CLSLoss:0.1430 | AUROC:0.9256\n",
      "Test | 128/16 | Loss:0.0695 | MainLoss:0.0695 | SPLoss:0.0018 | CLSLoss:0.1430 | AUROC:0.9989\n",
      "\n",
      "Epoch: [530 | 1000] LR: 0.001069\n",
      "Train | 16/16 | Loss:0.1932 | MainLoss:0.1787 | Alpha:0.4587 | SPLoss:0.0018 | CLSLoss:0.1430 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3919 | MainLoss:0.3919 | SPLoss:0.0019 | CLSLoss:0.1431 | AUROC:0.9254\n",
      "Test | 128/16 | Loss:0.0672 | MainLoss:0.0672 | SPLoss:0.0019 | CLSLoss:0.1431 | AUROC:0.9990\n",
      "\n",
      "Epoch: [531 | 1000] LR: 0.001066\n",
      "Train | 16/16 | Loss:0.1965 | MainLoss:0.1821 | Alpha:0.4576 | SPLoss:0.0019 | CLSLoss:0.1430 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3922 | MainLoss:0.3922 | SPLoss:0.0019 | CLSLoss:0.1431 | AUROC:0.9258\n",
      "Test | 128/16 | Loss:0.0674 | MainLoss:0.0674 | SPLoss:0.0019 | CLSLoss:0.1431 | AUROC:0.9990\n",
      "\n",
      "Epoch: [532 | 1000] LR: 0.001063\n",
      "Train | 16/16 | Loss:0.1865 | MainLoss:0.1720 | Alpha:0.4600 | SPLoss:0.0020 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3930 | MainLoss:0.3930 | SPLoss:0.0020 | CLSLoss:0.1433 | AUROC:0.9257\n",
      "Test | 128/16 | Loss:0.0668 | MainLoss:0.0668 | SPLoss:0.0020 | CLSLoss:0.1433 | AUROC:0.9991\n",
      "\n",
      "Epoch: [533 | 1000] LR: 0.001060\n",
      "Train | 16/16 | Loss:0.1849 | MainLoss:0.1704 | Alpha:0.4604 | SPLoss:0.0021 | CLSLoss:0.1434 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3937 | MainLoss:0.3937 | SPLoss:0.0021 | CLSLoss:0.1435 | AUROC:0.9258\n",
      "Test | 128/16 | Loss:0.0661 | MainLoss:0.0661 | SPLoss:0.0021 | CLSLoss:0.1435 | AUROC:0.9990\n",
      "\n",
      "Epoch: [534 | 1000] LR: 0.001057\n",
      "Train | 16/16 | Loss:0.2011 | MainLoss:0.1866 | Alpha:0.4565 | SPLoss:0.0022 | CLSLoss:0.1434 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3933 | MainLoss:0.3933 | SPLoss:0.0022 | CLSLoss:0.1434 | AUROC:0.9262\n",
      "Test | 128/16 | Loss:0.0667 | MainLoss:0.0667 | SPLoss:0.0022 | CLSLoss:0.1434 | AUROC:0.9990\n",
      "\n",
      "Epoch: [535 | 1000] LR: 0.001053\n",
      "Train | 16/16 | Loss:0.1782 | MainLoss:0.1636 | Alpha:0.4626 | SPLoss:0.0022 | CLSLoss:0.1435 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3950 | MainLoss:0.3950 | SPLoss:0.0023 | CLSLoss:0.1437 | AUROC:0.9259\n",
      "Test | 128/16 | Loss:0.0650 | MainLoss:0.0650 | SPLoss:0.0023 | CLSLoss:0.1437 | AUROC:0.9990\n",
      "\n",
      "Epoch: [536 | 1000] LR: 0.001050\n",
      "Train | 16/16 | Loss:0.2006 | MainLoss:0.1860 | Alpha:0.4566 | SPLoss:0.0023 | CLSLoss:0.1438 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3943 | MainLoss:0.3943 | SPLoss:0.0024 | CLSLoss:0.1437 | AUROC:0.9259\n",
      "Test | 128/16 | Loss:0.0657 | MainLoss:0.0657 | SPLoss:0.0024 | CLSLoss:0.1437 | AUROC:0.9990\n",
      "\n",
      "Epoch: [537 | 1000] LR: 0.001047\n",
      "Train | 16/16 | Loss:0.1805 | MainLoss:0.1659 | Alpha:0.4608 | SPLoss:0.0024 | CLSLoss:0.1437 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3947 | MainLoss:0.3947 | SPLoss:0.0025 | CLSLoss:0.1439 | AUROC:0.9258\n",
      "Test | 128/16 | Loss:0.0657 | MainLoss:0.0657 | SPLoss:0.0025 | CLSLoss:0.1439 | AUROC:0.9990\n",
      "\n",
      "Epoch: [538 | 1000] LR: 0.001044\n",
      "Train | 16/16 | Loss:0.2132 | MainLoss:0.1986 | Alpha:0.4535 | SPLoss:0.0025 | CLSLoss:0.1437 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3940 | MainLoss:0.3940 | SPLoss:0.0026 | CLSLoss:0.1436 | AUROC:0.9258\n",
      "Test | 128/16 | Loss:0.0661 | MainLoss:0.0661 | SPLoss:0.0026 | CLSLoss:0.1436 | AUROC:0.9990\n",
      "\n",
      "Epoch: [539 | 1000] LR: 0.001041\n",
      "Train | 16/16 | Loss:0.1994 | MainLoss:0.1848 | Alpha:0.4562 | SPLoss:0.0026 | CLSLoss:0.1436 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3940 | MainLoss:0.3940 | SPLoss:0.0026 | CLSLoss:0.1436 | AUROC:0.9259\n",
      "Test | 128/16 | Loss:0.0660 | MainLoss:0.0660 | SPLoss:0.0026 | CLSLoss:0.1436 | AUROC:0.9991\n",
      "\n",
      "Epoch: [540 | 1000] LR: 0.001038\n",
      "Train | 16/16 | Loss:0.1948 | MainLoss:0.1801 | Alpha:0.4576 | SPLoss:0.0027 | CLSLoss:0.1436 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3934 | MainLoss:0.3934 | SPLoss:0.0027 | CLSLoss:0.1436 | AUROC:0.9257\n",
      "Test | 128/16 | Loss:0.0670 | MainLoss:0.0670 | SPLoss:0.0027 | CLSLoss:0.1436 | AUROC:0.9990\n",
      "\n",
      "Epoch: [541 | 1000] LR: 0.001035\n",
      "Train | 16/16 | Loss:0.1915 | MainLoss:0.1769 | Alpha:0.4571 | SPLoss:0.0028 | CLSLoss:0.1436 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3935 | MainLoss:0.3935 | SPLoss:0.0028 | CLSLoss:0.1437 | AUROC:0.9258\n",
      "Test | 128/16 | Loss:0.0671 | MainLoss:0.0671 | SPLoss:0.0028 | CLSLoss:0.1437 | AUROC:0.9989\n",
      "\n",
      "Epoch: [542 | 1000] LR: 0.001031\n",
      "Train | 16/16 | Loss:0.2023 | MainLoss:0.1877 | Alpha:0.4562 | SPLoss:0.0029 | CLSLoss:0.1437 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3934 | MainLoss:0.3934 | SPLoss:0.0029 | CLSLoss:0.1436 | AUROC:0.9260\n",
      "Test | 128/16 | Loss:0.0665 | MainLoss:0.0665 | SPLoss:0.0029 | CLSLoss:0.1436 | AUROC:0.9990\n",
      "\n",
      "Epoch: [543 | 1000] LR: 0.001028\n",
      "Train | 16/16 | Loss:0.1915 | MainLoss:0.1768 | Alpha:0.4572 | SPLoss:0.0030 | CLSLoss:0.1436 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3940 | MainLoss:0.3940 | SPLoss:0.0030 | CLSLoss:0.1437 | AUROC:0.9263\n",
      "Test | 128/16 | Loss:0.0655 | MainLoss:0.0655 | SPLoss:0.0030 | CLSLoss:0.1437 | AUROC:0.9990\n",
      "\n",
      "Epoch: [544 | 1000] LR: 0.001025\n",
      "Train | 16/16 | Loss:0.2090 | MainLoss:0.1944 | Alpha:0.4538 | SPLoss:0.0031 | CLSLoss:0.1437 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3940 | MainLoss:0.3940 | SPLoss:0.0031 | CLSLoss:0.1436 | AUROC:0.9260\n",
      "Test | 128/16 | Loss:0.0656 | MainLoss:0.0656 | SPLoss:0.0031 | CLSLoss:0.1436 | AUROC:0.9990\n",
      "\n",
      "Epoch: [545 | 1000] LR: 0.001022\n",
      "Train | 16/16 | Loss:0.1844 | MainLoss:0.1697 | Alpha:0.4603 | SPLoss:0.0032 | CLSLoss:0.1437 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3937 | MainLoss:0.3937 | SPLoss:0.0032 | CLSLoss:0.1437 | AUROC:0.9261\n",
      "Test | 128/16 | Loss:0.0665 | MainLoss:0.0665 | SPLoss:0.0032 | CLSLoss:0.1437 | AUROC:0.9990\n",
      "\n",
      "Epoch: [546 | 1000] LR: 0.001019\n",
      "Train | 16/16 | Loss:0.1990 | MainLoss:0.1843 | Alpha:0.4570 | SPLoss:0.0032 | CLSLoss:0.1436 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3936 | MainLoss:0.3936 | SPLoss:0.0033 | CLSLoss:0.1436 | AUROC:0.9260\n",
      "Test | 128/16 | Loss:0.0664 | MainLoss:0.0664 | SPLoss:0.0033 | CLSLoss:0.1436 | AUROC:0.9989\n",
      "\n",
      "Epoch: [547 | 1000] LR: 0.001016\n",
      "Train | 16/16 | Loss:0.2060 | MainLoss:0.1913 | Alpha:0.4536 | SPLoss:0.0033 | CLSLoss:0.1435 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3928 | MainLoss:0.3928 | SPLoss:0.0034 | CLSLoss:0.1434 | AUROC:0.9261\n",
      "Test | 128/16 | Loss:0.0670 | MainLoss:0.0670 | SPLoss:0.0034 | CLSLoss:0.1434 | AUROC:0.9990\n",
      "\n",
      "Epoch: [548 | 1000] LR: 0.001013\n",
      "Train | 16/16 | Loss:0.2164 | MainLoss:0.2017 | Alpha:0.4528 | SPLoss:0.0034 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3924 | MainLoss:0.3924 | SPLoss:0.0035 | CLSLoss:0.1432 | AUROC:0.9259\n",
      "Test | 128/16 | Loss:0.0685 | MainLoss:0.0685 | SPLoss:0.0035 | CLSLoss:0.1432 | AUROC:0.9990\n",
      "\n",
      "Epoch: [549 | 1000] LR: 0.001009\n",
      "Train | 16/16 | Loss:0.2017 | MainLoss:0.1870 | Alpha:0.4547 | SPLoss:0.0035 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3933 | MainLoss:0.3933 | SPLoss:0.0036 | CLSLoss:0.1431 | AUROC:0.9262\n",
      "Test | 128/16 | Loss:0.0663 | MainLoss:0.0663 | SPLoss:0.0036 | CLSLoss:0.1431 | AUROC:0.9990\n",
      "\n",
      "Epoch: [550 | 1000] LR: 0.001006\n",
      "Train | 16/16 | Loss:0.1950 | MainLoss:0.1803 | Alpha:0.4575 | SPLoss:0.0037 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3932 | MainLoss:0.3932 | SPLoss:0.0037 | CLSLoss:0.1432 | AUROC:0.9261\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 128/16 | Loss:0.0667 | MainLoss:0.0667 | SPLoss:0.0037 | CLSLoss:0.1432 | AUROC:0.9990\n",
      "\n",
      "Epoch: [551 | 1000] LR: 0.001003\n",
      "Train | 16/16 | Loss:0.1893 | MainLoss:0.1746 | Alpha:0.4578 | SPLoss:0.0037 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3928 | MainLoss:0.3928 | SPLoss:0.0038 | CLSLoss:0.1433 | AUROC:0.9263\n",
      "Test | 128/16 | Loss:0.0659 | MainLoss:0.0659 | SPLoss:0.0038 | CLSLoss:0.1433 | AUROC:0.9990\n",
      "\n",
      "Epoch: [552 | 1000] LR: 0.001000\n",
      "Train | 16/16 | Loss:0.2151 | MainLoss:0.2005 | Alpha:0.4522 | SPLoss:0.0038 | CLSLoss:0.1430 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3921 | MainLoss:0.3921 | SPLoss:0.0039 | CLSLoss:0.1430 | AUROC:0.9263\n",
      "Test | 128/16 | Loss:0.0663 | MainLoss:0.0663 | SPLoss:0.0039 | CLSLoss:0.1430 | AUROC:0.9990\n",
      "\n",
      "Epoch: [553 | 1000] LR: 0.000997\n",
      "Train | 16/16 | Loss:0.2051 | MainLoss:0.1904 | Alpha:0.4538 | SPLoss:0.0039 | CLSLoss:0.1430 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3914 | MainLoss:0.3914 | SPLoss:0.0040 | CLSLoss:0.1428 | AUROC:0.9262\n",
      "Test | 128/16 | Loss:0.0672 | MainLoss:0.0672 | SPLoss:0.0040 | CLSLoss:0.1428 | AUROC:0.9990\n",
      "\n",
      "Epoch: [554 | 1000] LR: 0.000994\n",
      "Train | 16/16 | Loss:0.1751 | MainLoss:0.1604 | Alpha:0.4618 | SPLoss:0.0040 | CLSLoss:0.1429 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3921 | MainLoss:0.3921 | SPLoss:0.0041 | CLSLoss:0.1431 | AUROC:0.9260\n",
      "Test | 128/16 | Loss:0.0678 | MainLoss:0.0678 | SPLoss:0.0041 | CLSLoss:0.1431 | AUROC:0.9990\n",
      "\n",
      "Epoch: [555 | 1000] LR: 0.000991\n",
      "Train | 16/16 | Loss:0.1880 | MainLoss:0.1733 | Alpha:0.4587 | SPLoss:0.0041 | CLSLoss:0.1431 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3926 | MainLoss:0.3926 | SPLoss:0.0042 | CLSLoss:0.1432 | AUROC:0.9259\n",
      "Test | 128/16 | Loss:0.0672 | MainLoss:0.0672 | SPLoss:0.0042 | CLSLoss:0.1432 | AUROC:0.9990\n",
      "\n",
      "Epoch: [556 | 1000] LR: 0.000987\n",
      "Train | 16/16 | Loss:0.1796 | MainLoss:0.1649 | Alpha:0.4617 | SPLoss:0.0042 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3936 | MainLoss:0.3936 | SPLoss:0.0043 | CLSLoss:0.1434 | AUROC:0.9264\n",
      "Test | 128/16 | Loss:0.0653 | MainLoss:0.0653 | SPLoss:0.0043 | CLSLoss:0.1434 | AUROC:0.9990\n",
      "\n",
      "Epoch: [557 | 1000] LR: 0.000984\n",
      "Train | 16/16 | Loss:0.1967 | MainLoss:0.1819 | Alpha:0.4577 | SPLoss:0.0043 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3934 | MainLoss:0.3934 | SPLoss:0.0044 | CLSLoss:0.1433 | AUROC:0.9263\n",
      "Test | 128/16 | Loss:0.0655 | MainLoss:0.0655 | SPLoss:0.0044 | CLSLoss:0.1433 | AUROC:0.9990\n",
      "\n",
      "Epoch: [558 | 1000] LR: 0.000981\n",
      "Train | 16/16 | Loss:0.1900 | MainLoss:0.1753 | Alpha:0.4582 | SPLoss:0.0044 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3936 | MainLoss:0.3936 | SPLoss:0.0045 | CLSLoss:0.1434 | AUROC:0.9262\n",
      "Test | 128/16 | Loss:0.0667 | MainLoss:0.0667 | SPLoss:0.0045 | CLSLoss:0.1434 | AUROC:0.9990\n",
      "\n",
      "Epoch: [559 | 1000] LR: 0.000978\n",
      "Train | 16/16 | Loss:0.2106 | MainLoss:0.1959 | Alpha:0.4536 | SPLoss:0.0045 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3937 | MainLoss:0.3937 | SPLoss:0.0046 | CLSLoss:0.1432 | AUROC:0.9264\n",
      "Test | 128/16 | Loss:0.0658 | MainLoss:0.0658 | SPLoss:0.0046 | CLSLoss:0.1432 | AUROC:0.9990\n",
      "\n",
      "Epoch: [560 | 1000] LR: 0.000975\n",
      "Train | 16/16 | Loss:0.1960 | MainLoss:0.1812 | Alpha:0.4567 | SPLoss:0.0046 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3940 | MainLoss:0.3940 | SPLoss:0.0047 | CLSLoss:0.1431 | AUROC:0.9261\n",
      "Test | 128/16 | Loss:0.0640 | MainLoss:0.0640 | SPLoss:0.0047 | CLSLoss:0.1431 | AUROC:0.9990\n",
      "\n",
      "Epoch: [561 | 1000] LR: 0.000972\n",
      "Train | 16/16 | Loss:0.2012 | MainLoss:0.1864 | Alpha:0.4552 | SPLoss:0.0047 | CLSLoss:0.1430 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3930 | MainLoss:0.3930 | SPLoss:0.0048 | CLSLoss:0.1430 | AUROC:0.9262\n",
      "Test | 128/16 | Loss:0.0654 | MainLoss:0.0654 | SPLoss:0.0048 | CLSLoss:0.1430 | AUROC:0.9990\n",
      "\n",
      "Epoch: [562 | 1000] LR: 0.000969\n",
      "Train | 16/16 | Loss:0.1943 | MainLoss:0.1795 | Alpha:0.4570 | SPLoss:0.0048 | CLSLoss:0.1430 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3940 | MainLoss:0.3940 | SPLoss:0.0049 | CLSLoss:0.1430 | AUROC:0.9258\n",
      "Test | 128/16 | Loss:0.0645 | MainLoss:0.0645 | SPLoss:0.0049 | CLSLoss:0.1430 | AUROC:0.9990\n",
      "\n",
      "Epoch: [563 | 1000] LR: 0.000965\n",
      "Train | 16/16 | Loss:0.1909 | MainLoss:0.1761 | Alpha:0.4579 | SPLoss:0.0050 | CLSLoss:0.1430 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3941 | MainLoss:0.3941 | SPLoss:0.0050 | CLSLoss:0.1431 | AUROC:0.9260\n",
      "Test | 128/16 | Loss:0.0644 | MainLoss:0.0644 | SPLoss:0.0050 | CLSLoss:0.1431 | AUROC:0.9990\n",
      "\n",
      "Epoch: [564 | 1000] LR: 0.000962\n",
      "Train | 16/16 | Loss:0.2189 | MainLoss:0.2041 | Alpha:0.4519 | SPLoss:0.0051 | CLSLoss:0.1429 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3930 | MainLoss:0.3930 | SPLoss:0.0051 | CLSLoss:0.1427 | AUROC:0.9261\n",
      "Test | 128/16 | Loss:0.0643 | MainLoss:0.0643 | SPLoss:0.0051 | CLSLoss:0.1427 | AUROC:0.9990\n",
      "\n",
      "Epoch: [565 | 1000] LR: 0.000959\n",
      "Train | 16/16 | Loss:0.1941 | MainLoss:0.1794 | Alpha:0.4567 | SPLoss:0.0052 | CLSLoss:0.1427 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3926 | MainLoss:0.3926 | SPLoss:0.0052 | CLSLoss:0.1428 | AUROC:0.9261\n",
      "Test | 128/16 | Loss:0.0650 | MainLoss:0.0650 | SPLoss:0.0052 | CLSLoss:0.1428 | AUROC:0.9990\n",
      "\n",
      "Epoch: [566 | 1000] LR: 0.000956\n",
      "Train | 16/16 | Loss:0.1733 | MainLoss:0.1585 | Alpha:0.4615 | SPLoss:0.0053 | CLSLoss:0.1429 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3932 | MainLoss:0.3932 | SPLoss:0.0053 | CLSLoss:0.1430 | AUROC:0.9260\n",
      "Test | 128/16 | Loss:0.0665 | MainLoss:0.0665 | SPLoss:0.0053 | CLSLoss:0.1430 | AUROC:0.9991\n",
      "\n",
      "Epoch: [567 | 1000] LR: 0.000953\n",
      "Train | 16/16 | Loss:0.1959 | MainLoss:0.1810 | Alpha:0.4573 | SPLoss:0.0054 | CLSLoss:0.1430 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3933 | MainLoss:0.3933 | SPLoss:0.0054 | CLSLoss:0.1430 | AUROC:0.9256\n",
      "Test | 128/16 | Loss:0.0670 | MainLoss:0.0670 | SPLoss:0.0054 | CLSLoss:0.1430 | AUROC:0.9990\n",
      "\n",
      "Epoch: [568 | 1000] LR: 0.000950\n",
      "Train | 16/16 | Loss:0.2035 | MainLoss:0.1887 | Alpha:0.4545 | SPLoss:0.0055 | CLSLoss:0.1429 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3946 | MainLoss:0.3946 | SPLoss:0.0055 | CLSLoss:0.1428 | AUROC:0.9261\n",
      "Test | 128/16 | Loss:0.0638 | MainLoss:0.0638 | SPLoss:0.0055 | CLSLoss:0.1428 | AUROC:0.9990\n",
      "\n",
      "Epoch: [569 | 1000] LR: 0.000947\n",
      "Train | 16/16 | Loss:0.2087 | MainLoss:0.1939 | Alpha:0.4533 | SPLoss:0.0056 | CLSLoss:0.1427 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3930 | MainLoss:0.3930 | SPLoss:0.0056 | CLSLoss:0.1426 | AUROC:0.9260\n",
      "Test | 128/16 | Loss:0.0658 | MainLoss:0.0658 | SPLoss:0.0056 | CLSLoss:0.1426 | AUROC:0.9990\n",
      "\n",
      "Epoch: [570 | 1000] LR: 0.000943\n",
      "Train | 16/16 | Loss:0.2109 | MainLoss:0.1960 | Alpha:0.4527 | SPLoss:0.0057 | CLSLoss:0.1425 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3932 | MainLoss:0.3932 | SPLoss:0.0057 | CLSLoss:0.1423 | AUROC:0.9258\n",
      "Test | 128/16 | Loss:0.0653 | MainLoss:0.0653 | SPLoss:0.0057 | CLSLoss:0.1423 | AUROC:0.9990\n",
      "\n",
      "Epoch: [571 | 1000] LR: 0.000940\n",
      "Train | 16/16 | Loss:0.1909 | MainLoss:0.1761 | Alpha:0.4581 | SPLoss:0.0058 | CLSLoss:0.1423 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3935 | MainLoss:0.3935 | SPLoss:0.0058 | CLSLoss:0.1423 | AUROC:0.9261\n",
      "Test | 128/16 | Loss:0.0651 | MainLoss:0.0651 | SPLoss:0.0058 | CLSLoss:0.1423 | AUROC:0.9990\n",
      "\n",
      "Epoch: [572 | 1000] LR: 0.000937\n",
      "Train | 16/16 | Loss:0.2043 | MainLoss:0.1895 | Alpha:0.4549 | SPLoss:0.0059 | CLSLoss:0.1422 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3921 | MainLoss:0.3921 | SPLoss:0.0059 | CLSLoss:0.1422 | AUROC:0.9264\n",
      "Test | 128/16 | Loss:0.0674 | MainLoss:0.0674 | SPLoss:0.0059 | CLSLoss:0.1422 | AUROC:0.9990\n",
      "\n",
      "Epoch: [573 | 1000] LR: 0.000934\n",
      "Train | 16/16 | Loss:0.1866 | MainLoss:0.1718 | Alpha:0.4588 | SPLoss:0.0060 | CLSLoss:0.1422 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3926 | MainLoss:0.3926 | SPLoss:0.0060 | CLSLoss:0.1423 | AUROC:0.9261\n",
      "Test | 128/16 | Loss:0.0671 | MainLoss:0.0671 | SPLoss:0.0060 | CLSLoss:0.1423 | AUROC:0.9990\n",
      "\n",
      "Epoch: [574 | 1000] LR: 0.000931\n",
      "Train | 16/16 | Loss:0.2026 | MainLoss:0.1877 | Alpha:0.4551 | SPLoss:0.0061 | CLSLoss:0.1423 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3924 | MainLoss:0.3924 | SPLoss:0.0061 | CLSLoss:0.1423 | AUROC:0.9262\n",
      "Test | 128/16 | Loss:0.0664 | MainLoss:0.0664 | SPLoss:0.0061 | CLSLoss:0.1423 | AUROC:0.9990\n",
      "\n",
      "Epoch: [575 | 1000] LR: 0.000928\n",
      "Train | 16/16 | Loss:0.2034 | MainLoss:0.1886 | Alpha:0.4544 | SPLoss:0.0062 | CLSLoss:0.1423 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3920 | MainLoss:0.3920 | SPLoss:0.0062 | CLSLoss:0.1421 | AUROC:0.9256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 128/16 | Loss:0.0681 | MainLoss:0.0681 | SPLoss:0.0062 | CLSLoss:0.1421 | AUROC:0.9990\n",
      "\n",
      "Epoch: [576 | 1000] LR: 0.000925\n",
      "Train | 16/16 | Loss:0.2102 | MainLoss:0.1954 | Alpha:0.4532 | SPLoss:0.0063 | CLSLoss:0.1421 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3920 | MainLoss:0.3920 | SPLoss:0.0064 | CLSLoss:0.1420 | AUROC:0.9261\n",
      "Test | 128/16 | Loss:0.0670 | MainLoss:0.0670 | SPLoss:0.0064 | CLSLoss:0.1420 | AUROC:0.9989\n",
      "\n",
      "Epoch: [577 | 1000] LR: 0.000922\n",
      "Train | 16/16 | Loss:0.1883 | MainLoss:0.1734 | Alpha:0.4581 | SPLoss:0.0064 | CLSLoss:0.1421 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3925 | MainLoss:0.3925 | SPLoss:0.0065 | CLSLoss:0.1422 | AUROC:0.9260\n",
      "Test | 128/16 | Loss:0.0674 | MainLoss:0.0674 | SPLoss:0.0065 | CLSLoss:0.1422 | AUROC:0.9989\n",
      "\n",
      "Epoch: [578 | 1000] LR: 0.000918\n",
      "Train | 16/16 | Loss:0.2078 | MainLoss:0.1929 | Alpha:0.4544 | SPLoss:0.0065 | CLSLoss:0.1422 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3926 | MainLoss:0.3926 | SPLoss:0.0066 | CLSLoss:0.1421 | AUROC:0.9267\n",
      "Test | 128/16 | Loss:0.0667 | MainLoss:0.0667 | SPLoss:0.0066 | CLSLoss:0.1421 | AUROC:0.9990\n",
      "\n",
      "Epoch: [579 | 1000] LR: 0.000915\n",
      "Train | 16/16 | Loss:0.1775 | MainLoss:0.1626 | Alpha:0.4619 | SPLoss:0.0066 | CLSLoss:0.1422 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3933 | MainLoss:0.3933 | SPLoss:0.0067 | CLSLoss:0.1423 | AUROC:0.9260\n",
      "Test | 128/16 | Loss:0.0667 | MainLoss:0.0667 | SPLoss:0.0067 | CLSLoss:0.1423 | AUROC:0.9990\n",
      "\n",
      "Epoch: [580 | 1000] LR: 0.000912\n",
      "Train | 16/16 | Loss:0.2021 | MainLoss:0.1872 | Alpha:0.4549 | SPLoss:0.0067 | CLSLoss:0.1423 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3918 | MainLoss:0.3918 | SPLoss:0.0068 | CLSLoss:0.1422 | AUROC:0.9264\n",
      "Test | 128/16 | Loss:0.0686 | MainLoss:0.0686 | SPLoss:0.0068 | CLSLoss:0.1422 | AUROC:0.9990\n",
      "\n",
      "Epoch: [581 | 1000] LR: 0.000909\n",
      "Train | 16/16 | Loss:0.1837 | MainLoss:0.1688 | Alpha:0.4585 | SPLoss:0.0068 | CLSLoss:0.1422 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3927 | MainLoss:0.3927 | SPLoss:0.0069 | CLSLoss:0.1423 | AUROC:0.9260\n",
      "Test | 128/16 | Loss:0.0667 | MainLoss:0.0667 | SPLoss:0.0069 | CLSLoss:0.1423 | AUROC:0.9990\n",
      "\n",
      "Epoch: [582 | 1000] LR: 0.000906\n",
      "Train | 16/16 | Loss:0.2012 | MainLoss:0.1863 | Alpha:0.4557 | SPLoss:0.0069 | CLSLoss:0.1422 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3920 | MainLoss:0.3920 | SPLoss:0.0070 | CLSLoss:0.1421 | AUROC:0.9266\n",
      "Test | 128/16 | Loss:0.0684 | MainLoss:0.0684 | SPLoss:0.0070 | CLSLoss:0.1421 | AUROC:0.9989\n",
      "\n",
      "Epoch: [583 | 1000] LR: 0.000903\n",
      "Train | 16/16 | Loss:0.1964 | MainLoss:0.1814 | Alpha:0.4551 | SPLoss:0.0070 | CLSLoss:0.1422 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3929 | MainLoss:0.3929 | SPLoss:0.0071 | CLSLoss:0.1421 | AUROC:0.9266\n",
      "Test | 128/16 | Loss:0.0667 | MainLoss:0.0667 | SPLoss:0.0071 | CLSLoss:0.1421 | AUROC:0.9990\n",
      "\n",
      "Epoch: [584 | 1000] LR: 0.000900\n",
      "Train | 16/16 | Loss:0.1733 | MainLoss:0.1584 | Alpha:0.4621 | SPLoss:0.0072 | CLSLoss:0.1422 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3935 | MainLoss:0.3935 | SPLoss:0.0072 | CLSLoss:0.1424 | AUROC:0.9260\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0072 | CLSLoss:0.1424 | AUROC:0.9990\n",
      "\n",
      "Epoch: [585 | 1000] LR: 0.000897\n",
      "Train | 16/16 | Loss:0.2147 | MainLoss:0.1998 | Alpha:0.4524 | SPLoss:0.0073 | CLSLoss:0.1423 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3925 | MainLoss:0.3925 | SPLoss:0.0073 | CLSLoss:0.1422 | AUROC:0.9266\n",
      "Test | 128/16 | Loss:0.0672 | MainLoss:0.0672 | SPLoss:0.0073 | CLSLoss:0.1422 | AUROC:0.9990\n",
      "\n",
      "Epoch: [586 | 1000] LR: 0.000893\n",
      "Train | 16/16 | Loss:0.2222 | MainLoss:0.2073 | Alpha:0.4497 | SPLoss:0.0074 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3918 | MainLoss:0.3918 | SPLoss:0.0074 | CLSLoss:0.1418 | AUROC:0.9263\n",
      "Test | 128/16 | Loss:0.0665 | MainLoss:0.0665 | SPLoss:0.0074 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [587 | 1000] LR: 0.000890\n",
      "Train | 16/16 | Loss:0.1962 | MainLoss:0.1813 | Alpha:0.4567 | SPLoss:0.0075 | CLSLoss:0.1417 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3915 | MainLoss:0.3915 | SPLoss:0.0075 | CLSLoss:0.1418 | AUROC:0.9264\n",
      "Test | 128/16 | Loss:0.0663 | MainLoss:0.0663 | SPLoss:0.0075 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [588 | 1000] LR: 0.000887\n",
      "Train | 16/16 | Loss:0.1905 | MainLoss:0.1756 | Alpha:0.4575 | SPLoss:0.0076 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3921 | MainLoss:0.3921 | SPLoss:0.0076 | CLSLoss:0.1419 | AUROC:0.9266\n",
      "Test | 128/16 | Loss:0.0660 | MainLoss:0.0660 | SPLoss:0.0076 | CLSLoss:0.1419 | AUROC:0.9990\n",
      "\n",
      "Epoch: [589 | 1000] LR: 0.000884\n",
      "Train | 16/16 | Loss:0.2022 | MainLoss:0.1872 | Alpha:0.4541 | SPLoss:0.0077 | CLSLoss:0.1419 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3919 | MainLoss:0.3919 | SPLoss:0.0077 | CLSLoss:0.1418 | AUROC:0.9263\n",
      "Test | 128/16 | Loss:0.0659 | MainLoss:0.0659 | SPLoss:0.0077 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [590 | 1000] LR: 0.000881\n",
      "Train | 16/16 | Loss:0.1988 | MainLoss:0.1839 | Alpha:0.4560 | SPLoss:0.0078 | CLSLoss:0.1417 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3913 | MainLoss:0.3913 | SPLoss:0.0078 | CLSLoss:0.1418 | AUROC:0.9266\n",
      "Test | 128/16 | Loss:0.0658 | MainLoss:0.0658 | SPLoss:0.0078 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [591 | 1000] LR: 0.000878\n",
      "Train | 16/16 | Loss:0.2010 | MainLoss:0.1860 | Alpha:0.4550 | SPLoss:0.0079 | CLSLoss:0.1417 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3907 | MainLoss:0.3907 | SPLoss:0.0080 | CLSLoss:0.1417 | AUROC:0.9264\n",
      "Test | 128/16 | Loss:0.0667 | MainLoss:0.0667 | SPLoss:0.0080 | CLSLoss:0.1417 | AUROC:0.9990\n",
      "\n",
      "Epoch: [592 | 1000] LR: 0.000875\n",
      "Train | 16/16 | Loss:0.1759 | MainLoss:0.1610 | Alpha:0.4624 | SPLoss:0.0080 | CLSLoss:0.1417 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3914 | MainLoss:0.3914 | SPLoss:0.0081 | CLSLoss:0.1419 | AUROC:0.9265\n",
      "Test | 128/16 | Loss:0.0661 | MainLoss:0.0661 | SPLoss:0.0081 | CLSLoss:0.1419 | AUROC:0.9990\n",
      "\n",
      "Epoch: [593 | 1000] LR: 0.000872\n",
      "Train | 16/16 | Loss:0.2270 | MainLoss:0.2120 | Alpha:0.4480 | SPLoss:0.0081 | CLSLoss:0.1417 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3910 | MainLoss:0.3910 | SPLoss:0.0082 | CLSLoss:0.1415 | AUROC:0.9263\n",
      "Test | 128/16 | Loss:0.0648 | MainLoss:0.0648 | SPLoss:0.0082 | CLSLoss:0.1415 | AUROC:0.9991\n",
      "\n",
      "Epoch: [594 | 1000] LR: 0.000868\n",
      "Train | 16/16 | Loss:0.1805 | MainLoss:0.1656 | Alpha:0.4589 | SPLoss:0.0082 | CLSLoss:0.1415 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3918 | MainLoss:0.3918 | SPLoss:0.0083 | CLSLoss:0.1416 | AUROC:0.9267\n",
      "Test | 128/16 | Loss:0.0643 | MainLoss:0.0643 | SPLoss:0.0083 | CLSLoss:0.1416 | AUROC:0.9991\n",
      "\n",
      "Epoch: [595 | 1000] LR: 0.000865\n",
      "Train | 16/16 | Loss:0.1959 | MainLoss:0.1809 | Alpha:0.4553 | SPLoss:0.0083 | CLSLoss:0.1416 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3906 | MainLoss:0.3906 | SPLoss:0.0084 | CLSLoss:0.1416 | AUROC:0.9266\n",
      "Test | 128/16 | Loss:0.0660 | MainLoss:0.0660 | SPLoss:0.0084 | CLSLoss:0.1416 | AUROC:0.9991\n",
      "\n",
      "Epoch: [596 | 1000] LR: 0.000862\n",
      "Train | 16/16 | Loss:0.2051 | MainLoss:0.1901 | Alpha:0.4555 | SPLoss:0.0084 | CLSLoss:0.1415 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3903 | MainLoss:0.3903 | SPLoss:0.0085 | CLSLoss:0.1414 | AUROC:0.9266\n",
      "Test | 128/16 | Loss:0.0661 | MainLoss:0.0661 | SPLoss:0.0085 | CLSLoss:0.1414 | AUROC:0.9990\n",
      "\n",
      "Epoch: [597 | 1000] LR: 0.000859\n",
      "Train | 16/16 | Loss:0.1828 | MainLoss:0.1678 | Alpha:0.4583 | SPLoss:0.0086 | CLSLoss:0.1416 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3903 | MainLoss:0.3903 | SPLoss:0.0086 | CLSLoss:0.1416 | AUROC:0.9267\n",
      "Test | 128/16 | Loss:0.0674 | MainLoss:0.0674 | SPLoss:0.0086 | CLSLoss:0.1416 | AUROC:0.9990\n",
      "\n",
      "Epoch: [598 | 1000] LR: 0.000856\n",
      "Train | 16/16 | Loss:0.1852 | MainLoss:0.1702 | Alpha:0.4588 | SPLoss:0.0087 | CLSLoss:0.1416 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3909 | MainLoss:0.3909 | SPLoss:0.0087 | CLSLoss:0.1417 | AUROC:0.9269\n",
      "Test | 128/16 | Loss:0.0657 | MainLoss:0.0657 | SPLoss:0.0087 | CLSLoss:0.1417 | AUROC:0.9990\n",
      "\n",
      "Epoch: [599 | 1000] LR: 0.000853\n",
      "Train | 16/16 | Loss:0.1959 | MainLoss:0.1808 | Alpha:0.4565 | SPLoss:0.0088 | CLSLoss:0.1417 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3909 | MainLoss:0.3909 | SPLoss:0.0089 | CLSLoss:0.1417 | AUROC:0.9267\n",
      "Test | 128/16 | Loss:0.0672 | MainLoss:0.0672 | SPLoss:0.0089 | CLSLoss:0.1417 | AUROC:0.9990\n",
      "\n",
      "Epoch: [600 | 1000] LR: 0.000850\n",
      "Train | 16/16 | Loss:0.1741 | MainLoss:0.1590 | Alpha:0.4607 | SPLoss:0.0089 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3925 | MainLoss:0.3925 | SPLoss:0.0090 | CLSLoss:0.1420 | AUROC:0.9267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 128/16 | Loss:0.0653 | MainLoss:0.0653 | SPLoss:0.0090 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [601 | 1000] LR: 0.000085\n",
      "Train | 16/16 | Loss:0.2064 | MainLoss:0.1922 | Alpha:0.4557 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3924 | MainLoss:0.3924 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9269\n",
      "Test | 128/16 | Loss:0.0656 | MainLoss:0.0656 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [602 | 1000] LR: 0.000084\n",
      "Train | 16/16 | Loss:0.1974 | MainLoss:0.1832 | Alpha:0.4570 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3924 | MainLoss:0.3924 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9268\n",
      "Test | 128/16 | Loss:0.0656 | MainLoss:0.0656 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [603 | 1000] LR: 0.000084\n",
      "Train | 16/16 | Loss:0.1998 | MainLoss:0.1856 | Alpha:0.4578 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3924 | MainLoss:0.3924 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9267\n",
      "Test | 128/16 | Loss:0.0655 | MainLoss:0.0655 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [604 | 1000] LR: 0.000084\n",
      "Train | 16/16 | Loss:0.2003 | MainLoss:0.1861 | Alpha:0.4579 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3924 | MainLoss:0.3924 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9266\n",
      "Test | 128/16 | Loss:0.0655 | MainLoss:0.0655 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9991\n",
      "\n",
      "Epoch: [605 | 1000] LR: 0.000083\n",
      "Train | 16/16 | Loss:0.1995 | MainLoss:0.1853 | Alpha:0.4573 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3924 | MainLoss:0.3924 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9270\n",
      "Test | 128/16 | Loss:0.0655 | MainLoss:0.0655 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [606 | 1000] LR: 0.000083\n",
      "Train | 16/16 | Loss:0.1736 | MainLoss:0.1594 | Alpha:0.4640 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3926 | MainLoss:0.3926 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9267\n",
      "Test | 128/16 | Loss:0.0653 | MainLoss:0.0653 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [607 | 1000] LR: 0.000083\n",
      "Train | 16/16 | Loss:0.1869 | MainLoss:0.1727 | Alpha:0.4606 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3926 | MainLoss:0.3926 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9269\n",
      "Test | 128/16 | Loss:0.0653 | MainLoss:0.0653 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [608 | 1000] LR: 0.000082\n",
      "Train | 16/16 | Loss:0.1933 | MainLoss:0.1791 | Alpha:0.4583 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3926 | MainLoss:0.3926 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9269\n",
      "Test | 128/16 | Loss:0.0653 | MainLoss:0.0653 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [609 | 1000] LR: 0.000082\n",
      "Train | 16/16 | Loss:0.1906 | MainLoss:0.1764 | Alpha:0.4595 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3927 | MainLoss:0.3927 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9267\n",
      "Test | 128/16 | Loss:0.0652 | MainLoss:0.0652 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [610 | 1000] LR: 0.000082\n",
      "Train | 16/16 | Loss:0.1867 | MainLoss:0.1725 | Alpha:0.4597 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3927 | MainLoss:0.3927 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9266\n",
      "Test | 128/16 | Loss:0.0653 | MainLoss:0.0653 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [611 | 1000] LR: 0.000082\n",
      "Train | 16/16 | Loss:0.2003 | MainLoss:0.1861 | Alpha:0.4564 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3927 | MainLoss:0.3927 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9266\n",
      "Test | 128/16 | Loss:0.0651 | MainLoss:0.0651 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [612 | 1000] LR: 0.000081\n",
      "Train | 16/16 | Loss:0.1853 | MainLoss:0.1711 | Alpha:0.4608 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3927 | MainLoss:0.3927 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9267\n",
      "Test | 128/16 | Loss:0.0653 | MainLoss:0.0653 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [613 | 1000] LR: 0.000081\n",
      "Train | 16/16 | Loss:0.1783 | MainLoss:0.1641 | Alpha:0.4612 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3928 | MainLoss:0.3928 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9267\n",
      "Test | 128/16 | Loss:0.0653 | MainLoss:0.0653 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9991\n",
      "\n",
      "Epoch: [614 | 1000] LR: 0.000081\n",
      "Train | 16/16 | Loss:0.1795 | MainLoss:0.1653 | Alpha:0.4630 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3928 | MainLoss:0.3928 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9269\n",
      "Test | 128/16 | Loss:0.0653 | MainLoss:0.0653 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [615 | 1000] LR: 0.000080\n",
      "Train | 16/16 | Loss:0.1894 | MainLoss:0.1752 | Alpha:0.4595 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3928 | MainLoss:0.3928 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9269\n",
      "Test | 128/16 | Loss:0.0653 | MainLoss:0.0653 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [616 | 1000] LR: 0.000080\n",
      "Train | 16/16 | Loss:0.1942 | MainLoss:0.1800 | Alpha:0.4583 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3928 | MainLoss:0.3928 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9266\n",
      "Test | 128/16 | Loss:0.0653 | MainLoss:0.0653 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [617 | 1000] LR: 0.000080\n",
      "Train | 16/16 | Loss:0.2046 | MainLoss:0.1904 | Alpha:0.4563 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3928 | MainLoss:0.3928 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9266\n",
      "Test | 128/16 | Loss:0.0654 | MainLoss:0.0654 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [618 | 1000] LR: 0.000079\n",
      "Train | 16/16 | Loss:0.1813 | MainLoss:0.1671 | Alpha:0.4614 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3927 | MainLoss:0.3927 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9264\n",
      "Test | 128/16 | Loss:0.0656 | MainLoss:0.0656 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [619 | 1000] LR: 0.000079\n",
      "Train | 16/16 | Loss:0.1723 | MainLoss:0.1581 | Alpha:0.4627 | SPLoss:0.0000 | CLSLoss:0.1421 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3929 | MainLoss:0.3929 | SPLoss:0.0000 | CLSLoss:0.1421 | AUROC:0.9266\n",
      "Test | 128/16 | Loss:0.0655 | MainLoss:0.0655 | SPLoss:0.0000 | CLSLoss:0.1421 | AUROC:0.9990\n",
      "\n",
      "Epoch: [620 | 1000] LR: 0.000079\n",
      "Train | 16/16 | Loss:0.1857 | MainLoss:0.1715 | Alpha:0.4614 | SPLoss:0.0000 | CLSLoss:0.1421 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3929 | MainLoss:0.3929 | SPLoss:0.0000 | CLSLoss:0.1421 | AUROC:0.9267\n",
      "Test | 128/16 | Loss:0.0655 | MainLoss:0.0655 | SPLoss:0.0000 | CLSLoss:0.1421 | AUROC:0.9990\n",
      "\n",
      "Epoch: [621 | 1000] LR: 0.000078\n",
      "Train | 16/16 | Loss:0.1980 | MainLoss:0.1838 | Alpha:0.4568 | SPLoss:0.0000 | CLSLoss:0.1421 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3929 | MainLoss:0.3929 | SPLoss:0.0000 | CLSLoss:0.1421 | AUROC:0.9266\n",
      "Test | 128/16 | Loss:0.0655 | MainLoss:0.0655 | SPLoss:0.0000 | CLSLoss:0.1421 | AUROC:0.9990\n",
      "\n",
      "Epoch: [622 | 1000] LR: 0.000078\n",
      "Train | 16/16 | Loss:0.1995 | MainLoss:0.1853 | Alpha:0.4573 | SPLoss:0.0000 | CLSLoss:0.1421 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3929 | MainLoss:0.3929 | SPLoss:0.0000 | CLSLoss:0.1421 | AUROC:0.9269\n",
      "Test | 128/16 | Loss:0.0655 | MainLoss:0.0655 | SPLoss:0.0000 | CLSLoss:0.1421 | AUROC:0.9990\n",
      "\n",
      "Epoch: [623 | 1000] LR: 0.000078\n",
      "Train | 16/16 | Loss:0.2210 | MainLoss:0.2068 | Alpha:0.4526 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3926 | MainLoss:0.3926 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9266\n",
      "Test | 128/16 | Loss:0.0660 | MainLoss:0.0660 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [624 | 1000] LR: 0.000078\n",
      "Train | 16/16 | Loss:0.1802 | MainLoss:0.1660 | Alpha:0.4625 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3927 | MainLoss:0.3927 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9267\n",
      "Test | 128/16 | Loss:0.0658 | MainLoss:0.0658 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [625 | 1000] LR: 0.000077\n",
      "Train | 16/16 | Loss:0.2005 | MainLoss:0.1863 | Alpha:0.4568 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3926 | MainLoss:0.3926 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 128/16 | Loss:0.0659 | MainLoss:0.0659 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [626 | 1000] LR: 0.000077\n",
      "Train | 16/16 | Loss:0.2093 | MainLoss:0.1951 | Alpha:0.4554 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3926 | MainLoss:0.3926 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9267\n",
      "Test | 128/16 | Loss:0.0660 | MainLoss:0.0660 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [627 | 1000] LR: 0.000077\n",
      "Train | 16/16 | Loss:0.1724 | MainLoss:0.1582 | Alpha:0.4632 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3926 | MainLoss:0.3926 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9266\n",
      "Test | 128/16 | Loss:0.0660 | MainLoss:0.0660 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [628 | 1000] LR: 0.000076\n",
      "Train | 16/16 | Loss:0.1822 | MainLoss:0.1680 | Alpha:0.4619 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3926 | MainLoss:0.3926 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9267\n",
      "Test | 128/16 | Loss:0.0660 | MainLoss:0.0660 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [629 | 1000] LR: 0.000076\n",
      "Train | 16/16 | Loss:0.2201 | MainLoss:0.2059 | Alpha:0.4529 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3926 | MainLoss:0.3926 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9266\n",
      "Test | 128/16 | Loss:0.0659 | MainLoss:0.0659 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [630 | 1000] LR: 0.000076\n",
      "Train | 16/16 | Loss:0.1849 | MainLoss:0.1707 | Alpha:0.4593 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3926 | MainLoss:0.3926 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9266\n",
      "Test | 128/16 | Loss:0.0660 | MainLoss:0.0660 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [631 | 1000] LR: 0.000075\n",
      "Train | 16/16 | Loss:0.1894 | MainLoss:0.1752 | Alpha:0.4601 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3927 | MainLoss:0.3927 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9268\n",
      "Test | 128/16 | Loss:0.0658 | MainLoss:0.0658 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9991\n",
      "\n",
      "Epoch: [632 | 1000] LR: 0.000075\n",
      "Train | 16/16 | Loss:0.1997 | MainLoss:0.1855 | Alpha:0.4557 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3928 | MainLoss:0.3928 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9269\n",
      "Test | 128/16 | Loss:0.0656 | MainLoss:0.0656 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [633 | 1000] LR: 0.000075\n",
      "Train | 16/16 | Loss:0.1818 | MainLoss:0.1676 | Alpha:0.4616 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3928 | MainLoss:0.3928 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9266\n",
      "Test | 128/16 | Loss:0.0656 | MainLoss:0.0656 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [634 | 1000] LR: 0.000075\n",
      "Train | 16/16 | Loss:0.1846 | MainLoss:0.1704 | Alpha:0.4611 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3928 | MainLoss:0.3928 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9265\n",
      "Test | 128/16 | Loss:0.0657 | MainLoss:0.0657 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [635 | 1000] LR: 0.000074\n",
      "Train | 16/16 | Loss:0.1937 | MainLoss:0.1795 | Alpha:0.4591 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3928 | MainLoss:0.3928 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9265\n",
      "Test | 128/16 | Loss:0.0658 | MainLoss:0.0658 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9991\n",
      "\n",
      "Epoch: [636 | 1000] LR: 0.000074\n",
      "Train | 16/16 | Loss:0.1890 | MainLoss:0.1748 | Alpha:0.4602 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3928 | MainLoss:0.3928 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9264\n",
      "Test | 128/16 | Loss:0.0658 | MainLoss:0.0658 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [637 | 1000] LR: 0.000074\n",
      "Train | 16/16 | Loss:0.1950 | MainLoss:0.1808 | Alpha:0.4578 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3927 | MainLoss:0.3927 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9262\n",
      "Test | 128/16 | Loss:0.0661 | MainLoss:0.0661 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [638 | 1000] LR: 0.000073\n",
      "Train | 16/16 | Loss:0.1892 | MainLoss:0.1750 | Alpha:0.4590 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3928 | MainLoss:0.3928 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9268\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [639 | 1000] LR: 0.000073\n",
      "Train | 16/16 | Loss:0.1898 | MainLoss:0.1756 | Alpha:0.4596 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3929 | MainLoss:0.3929 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9269\n",
      "Test | 128/16 | Loss:0.0660 | MainLoss:0.0660 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [640 | 1000] LR: 0.000073\n",
      "Train | 16/16 | Loss:0.1981 | MainLoss:0.1839 | Alpha:0.4574 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3929 | MainLoss:0.3929 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9266\n",
      "Test | 128/16 | Loss:0.0659 | MainLoss:0.0659 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [641 | 1000] LR: 0.000072\n",
      "Train | 16/16 | Loss:0.1803 | MainLoss:0.1661 | Alpha:0.4617 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3929 | MainLoss:0.3929 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9265\n",
      "Test | 128/16 | Loss:0.0660 | MainLoss:0.0660 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [642 | 1000] LR: 0.000072\n",
      "Train | 16/16 | Loss:0.1830 | MainLoss:0.1688 | Alpha:0.4606 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3929 | MainLoss:0.3929 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9268\n",
      "Test | 128/16 | Loss:0.0661 | MainLoss:0.0661 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [643 | 1000] LR: 0.000072\n",
      "Train | 16/16 | Loss:0.1835 | MainLoss:0.1693 | Alpha:0.4617 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3929 | MainLoss:0.3929 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9266\n",
      "Test | 128/16 | Loss:0.0660 | MainLoss:0.0660 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [644 | 1000] LR: 0.000071\n",
      "Train | 16/16 | Loss:0.1982 | MainLoss:0.1840 | Alpha:0.4570 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3929 | MainLoss:0.3929 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9267\n",
      "Test | 128/16 | Loss:0.0659 | MainLoss:0.0659 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [645 | 1000] LR: 0.000071\n",
      "Train | 16/16 | Loss:0.1638 | MainLoss:0.1496 | Alpha:0.4656 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1421 | AUROC:0.9265\n",
      "Test | 128/16 | Loss:0.0657 | MainLoss:0.0657 | SPLoss:0.0000 | CLSLoss:0.1421 | AUROC:0.9990\n",
      "\n",
      "Epoch: [646 | 1000] LR: 0.000071\n",
      "Train | 16/16 | Loss:0.1843 | MainLoss:0.1701 | Alpha:0.4603 | SPLoss:0.0000 | CLSLoss:0.1421 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3932 | MainLoss:0.3932 | SPLoss:0.0000 | CLSLoss:0.1421 | AUROC:0.9267\n",
      "Test | 128/16 | Loss:0.0656 | MainLoss:0.0656 | SPLoss:0.0000 | CLSLoss:0.1421 | AUROC:0.9990\n",
      "\n",
      "Epoch: [647 | 1000] LR: 0.000071\n",
      "Train | 16/16 | Loss:0.2076 | MainLoss:0.1934 | Alpha:0.4556 | SPLoss:0.0000 | CLSLoss:0.1421 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9263\n",
      "Test | 128/16 | Loss:0.0658 | MainLoss:0.0658 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [648 | 1000] LR: 0.000070\n",
      "Train | 16/16 | Loss:0.1818 | MainLoss:0.1676 | Alpha:0.4608 | SPLoss:0.0000 | CLSLoss:0.1421 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1421 | AUROC:0.9266\n",
      "Test | 128/16 | Loss:0.0657 | MainLoss:0.0657 | SPLoss:0.0000 | CLSLoss:0.1421 | AUROC:0.9990\n",
      "\n",
      "Epoch: [649 | 1000] LR: 0.000070\n",
      "Train | 16/16 | Loss:0.1893 | MainLoss:0.1751 | Alpha:0.4598 | SPLoss:0.0000 | CLSLoss:0.1421 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1421 | AUROC:0.9267\n",
      "Test | 128/16 | Loss:0.0658 | MainLoss:0.0658 | SPLoss:0.0000 | CLSLoss:0.1421 | AUROC:0.9990\n",
      "\n",
      "Epoch: [650 | 1000] LR: 0.000070\n",
      "Train | 16/16 | Loss:0.1889 | MainLoss:0.1747 | Alpha:0.4602 | SPLoss:0.0000 | CLSLoss:0.1421 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1421 | AUROC:0.9266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 128/16 | Loss:0.0657 | MainLoss:0.0657 | SPLoss:0.0000 | CLSLoss:0.1421 | AUROC:0.9990\n",
      "\n",
      "Epoch: [651 | 1000] LR: 0.000069\n",
      "Train | 16/16 | Loss:0.2069 | MainLoss:0.1927 | Alpha:0.4550 | SPLoss:0.0000 | CLSLoss:0.1421 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3930 | MainLoss:0.3930 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9267\n",
      "Test | 128/16 | Loss:0.0658 | MainLoss:0.0658 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9991\n",
      "\n",
      "Epoch: [652 | 1000] LR: 0.000069\n",
      "Train | 16/16 | Loss:0.1943 | MainLoss:0.1801 | Alpha:0.4584 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3930 | MainLoss:0.3930 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9267\n",
      "Test | 128/16 | Loss:0.0659 | MainLoss:0.0659 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [653 | 1000] LR: 0.000069\n",
      "Train | 16/16 | Loss:0.1906 | MainLoss:0.1764 | Alpha:0.4592 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3930 | MainLoss:0.3930 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9268\n",
      "Test | 128/16 | Loss:0.0660 | MainLoss:0.0660 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [654 | 1000] LR: 0.000069\n",
      "Train | 16/16 | Loss:0.1819 | MainLoss:0.1677 | Alpha:0.4622 | SPLoss:0.0000 | CLSLoss:0.1421 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3930 | MainLoss:0.3930 | SPLoss:0.0000 | CLSLoss:0.1421 | AUROC:0.9267\n",
      "Test | 128/16 | Loss:0.0660 | MainLoss:0.0660 | SPLoss:0.0000 | CLSLoss:0.1421 | AUROC:0.9990\n",
      "\n",
      "Epoch: [655 | 1000] LR: 0.000068\n",
      "Train | 16/16 | Loss:0.1977 | MainLoss:0.1834 | Alpha:0.4567 | SPLoss:0.0000 | CLSLoss:0.1421 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3930 | MainLoss:0.3930 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9269\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [656 | 1000] LR: 0.000068\n",
      "Train | 16/16 | Loss:0.1826 | MainLoss:0.1684 | Alpha:0.4603 | SPLoss:0.0000 | CLSLoss:0.1421 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3930 | MainLoss:0.3930 | SPLoss:0.0000 | CLSLoss:0.1421 | AUROC:0.9268\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1421 | AUROC:0.9990\n",
      "\n",
      "Epoch: [657 | 1000] LR: 0.000068\n",
      "Train | 16/16 | Loss:0.1852 | MainLoss:0.1710 | Alpha:0.4600 | SPLoss:0.0000 | CLSLoss:0.1421 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3930 | MainLoss:0.3930 | SPLoss:0.0000 | CLSLoss:0.1421 | AUROC:0.9271\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1421 | AUROC:0.9990\n",
      "\n",
      "Epoch: [658 | 1000] LR: 0.000067\n",
      "Train | 16/16 | Loss:0.2161 | MainLoss:0.2019 | Alpha:0.4530 | SPLoss:0.0000 | CLSLoss:0.1421 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3930 | MainLoss:0.3930 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9265\n",
      "Test | 128/16 | Loss:0.0661 | MainLoss:0.0661 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [659 | 1000] LR: 0.000067\n",
      "Train | 16/16 | Loss:0.1781 | MainLoss:0.1639 | Alpha:0.4622 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1421 | AUROC:0.9267\n",
      "Test | 128/16 | Loss:0.0661 | MainLoss:0.0661 | SPLoss:0.0000 | CLSLoss:0.1421 | AUROC:0.9990\n",
      "\n",
      "Epoch: [660 | 1000] LR: 0.000067\n",
      "Train | 16/16 | Loss:0.1849 | MainLoss:0.1707 | Alpha:0.4621 | SPLoss:0.0000 | CLSLoss:0.1421 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1421 | AUROC:0.9266\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1421 | AUROC:0.9990\n",
      "\n",
      "Epoch: [661 | 1000] LR: 0.000066\n",
      "Train | 16/16 | Loss:0.1798 | MainLoss:0.1656 | Alpha:0.4610 | SPLoss:0.0000 | CLSLoss:0.1421 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3932 | MainLoss:0.3932 | SPLoss:0.0000 | CLSLoss:0.1421 | AUROC:0.9265\n",
      "Test | 128/16 | Loss:0.0660 | MainLoss:0.0660 | SPLoss:0.0000 | CLSLoss:0.1421 | AUROC:0.9990\n",
      "\n",
      "Epoch: [662 | 1000] LR: 0.000066\n",
      "Train | 16/16 | Loss:0.1945 | MainLoss:0.1803 | Alpha:0.4585 | SPLoss:0.0000 | CLSLoss:0.1421 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1421 | AUROC:0.9263\n",
      "Test | 128/16 | Loss:0.0663 | MainLoss:0.0663 | SPLoss:0.0000 | CLSLoss:0.1421 | AUROC:0.9990\n",
      "\n",
      "Epoch: [663 | 1000] LR: 0.000066\n",
      "Train | 16/16 | Loss:0.1864 | MainLoss:0.1722 | Alpha:0.4608 | SPLoss:0.0000 | CLSLoss:0.1421 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1421 | AUROC:0.9267\n",
      "Test | 128/16 | Loss:0.0664 | MainLoss:0.0664 | SPLoss:0.0000 | CLSLoss:0.1421 | AUROC:0.9990\n",
      "\n",
      "Epoch: [664 | 1000] LR: 0.000066\n",
      "Train | 16/16 | Loss:0.1903 | MainLoss:0.1760 | Alpha:0.4592 | SPLoss:0.0000 | CLSLoss:0.1421 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3932 | MainLoss:0.3932 | SPLoss:0.0000 | CLSLoss:0.1421 | AUROC:0.9268\n",
      "Test | 128/16 | Loss:0.0661 | MainLoss:0.0661 | SPLoss:0.0000 | CLSLoss:0.1421 | AUROC:0.9990\n",
      "\n",
      "Epoch: [665 | 1000] LR: 0.000065\n",
      "Train | 16/16 | Loss:0.1899 | MainLoss:0.1756 | Alpha:0.4600 | SPLoss:0.0000 | CLSLoss:0.1421 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3932 | MainLoss:0.3932 | SPLoss:0.0000 | CLSLoss:0.1421 | AUROC:0.9268\n",
      "Test | 128/16 | Loss:0.0661 | MainLoss:0.0661 | SPLoss:0.0000 | CLSLoss:0.1421 | AUROC:0.9990\n",
      "\n",
      "Epoch: [666 | 1000] LR: 0.000065\n",
      "Train | 16/16 | Loss:0.1957 | MainLoss:0.1814 | Alpha:0.4578 | SPLoss:0.0000 | CLSLoss:0.1421 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1421 | AUROC:0.9265\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1421 | AUROC:0.9990\n",
      "\n",
      "Epoch: [667 | 1000] LR: 0.000065\n",
      "Train | 16/16 | Loss:0.1880 | MainLoss:0.1738 | Alpha:0.4600 | SPLoss:0.0000 | CLSLoss:0.1421 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3932 | MainLoss:0.3932 | SPLoss:0.0000 | CLSLoss:0.1421 | AUROC:0.9267\n",
      "Test | 128/16 | Loss:0.0661 | MainLoss:0.0661 | SPLoss:0.0000 | CLSLoss:0.1421 | AUROC:0.9990\n",
      "\n",
      "Epoch: [668 | 1000] LR: 0.000064\n",
      "Train | 16/16 | Loss:0.1800 | MainLoss:0.1658 | Alpha:0.4617 | SPLoss:0.0000 | CLSLoss:0.1421 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3932 | MainLoss:0.3932 | SPLoss:0.0000 | CLSLoss:0.1421 | AUROC:0.9266\n",
      "Test | 128/16 | Loss:0.0660 | MainLoss:0.0660 | SPLoss:0.0000 | CLSLoss:0.1421 | AUROC:0.9991\n",
      "\n",
      "Epoch: [669 | 1000] LR: 0.000064\n",
      "Train | 16/16 | Loss:0.1856 | MainLoss:0.1714 | Alpha:0.4612 | SPLoss:0.0000 | CLSLoss:0.1421 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3932 | MainLoss:0.3932 | SPLoss:0.0000 | CLSLoss:0.1421 | AUROC:0.9263\n",
      "Test | 128/16 | Loss:0.0661 | MainLoss:0.0661 | SPLoss:0.0000 | CLSLoss:0.1421 | AUROC:0.9990\n",
      "\n",
      "Epoch: [670 | 1000] LR: 0.000064\n",
      "Train | 16/16 | Loss:0.1942 | MainLoss:0.1800 | Alpha:0.4582 | SPLoss:0.0000 | CLSLoss:0.1421 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3933 | MainLoss:0.3933 | SPLoss:0.0000 | CLSLoss:0.1421 | AUROC:0.9268\n",
      "Test | 128/16 | Loss:0.0660 | MainLoss:0.0660 | SPLoss:0.0000 | CLSLoss:0.1421 | AUROC:0.9990\n",
      "\n",
      "Epoch: [671 | 1000] LR: 0.000063\n",
      "Train | 16/16 | Loss:0.2074 | MainLoss:0.1932 | Alpha:0.4542 | SPLoss:0.0000 | CLSLoss:0.1421 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3933 | MainLoss:0.3933 | SPLoss:0.0000 | CLSLoss:0.1421 | AUROC:0.9266\n",
      "Test | 128/16 | Loss:0.0658 | MainLoss:0.0658 | SPLoss:0.0000 | CLSLoss:0.1421 | AUROC:0.9990\n",
      "\n",
      "Epoch: [672 | 1000] LR: 0.000063\n",
      "Train | 16/16 | Loss:0.2116 | MainLoss:0.1974 | Alpha:0.4541 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3933 | MainLoss:0.3933 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9261\n",
      "Test | 128/16 | Loss:0.0658 | MainLoss:0.0658 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9991\n",
      "\n",
      "Epoch: [673 | 1000] LR: 0.000063\n",
      "Train | 16/16 | Loss:0.1906 | MainLoss:0.1764 | Alpha:0.4591 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3933 | MainLoss:0.3933 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9266\n",
      "Test | 128/16 | Loss:0.0658 | MainLoss:0.0658 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9991\n",
      "\n",
      "Epoch: [674 | 1000] LR: 0.000063\n",
      "Train | 16/16 | Loss:0.1985 | MainLoss:0.1843 | Alpha:0.4580 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3933 | MainLoss:0.3933 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9265\n",
      "Test | 128/16 | Loss:0.0658 | MainLoss:0.0658 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [675 | 1000] LR: 0.000062\n",
      "Train | 16/16 | Loss:0.1894 | MainLoss:0.1752 | Alpha:0.4599 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3933 | MainLoss:0.3933 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 128/16 | Loss:0.0659 | MainLoss:0.0659 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [676 | 1000] LR: 0.000062\n",
      "Train | 16/16 | Loss:0.1693 | MainLoss:0.1551 | Alpha:0.4636 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3934 | MainLoss:0.3934 | SPLoss:0.0000 | CLSLoss:0.1421 | AUROC:0.9264\n",
      "Test | 128/16 | Loss:0.0658 | MainLoss:0.0658 | SPLoss:0.0000 | CLSLoss:0.1421 | AUROC:0.9990\n",
      "\n",
      "Epoch: [677 | 1000] LR: 0.000062\n",
      "Train | 16/16 | Loss:0.2006 | MainLoss:0.1864 | Alpha:0.4570 | SPLoss:0.0000 | CLSLoss:0.1421 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3934 | MainLoss:0.3934 | SPLoss:0.0000 | CLSLoss:0.1421 | AUROC:0.9266\n",
      "Test | 128/16 | Loss:0.0658 | MainLoss:0.0658 | SPLoss:0.0000 | CLSLoss:0.1421 | AUROC:0.9990\n",
      "\n",
      "Epoch: [678 | 1000] LR: 0.000061\n",
      "Train | 16/16 | Loss:0.1884 | MainLoss:0.1742 | Alpha:0.4597 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3933 | MainLoss:0.3933 | SPLoss:0.0000 | CLSLoss:0.1421 | AUROC:0.9268\n",
      "Test | 128/16 | Loss:0.0660 | MainLoss:0.0660 | SPLoss:0.0000 | CLSLoss:0.1421 | AUROC:0.9990\n",
      "\n",
      "Epoch: [679 | 1000] LR: 0.000061\n",
      "Train | 16/16 | Loss:0.2003 | MainLoss:0.1861 | Alpha:0.4568 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3933 | MainLoss:0.3933 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9264\n",
      "Test | 128/16 | Loss:0.0660 | MainLoss:0.0660 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [680 | 1000] LR: 0.000061\n",
      "Train | 16/16 | Loss:0.2171 | MainLoss:0.2029 | Alpha:0.4520 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3932 | MainLoss:0.3932 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9263\n",
      "Test | 128/16 | Loss:0.0661 | MainLoss:0.0661 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [681 | 1000] LR: 0.000061\n",
      "Train | 16/16 | Loss:0.1921 | MainLoss:0.1779 | Alpha:0.4585 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3933 | MainLoss:0.3933 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9268\n",
      "Test | 128/16 | Loss:0.0659 | MainLoss:0.0659 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [682 | 1000] LR: 0.000060\n",
      "Train | 16/16 | Loss:0.1958 | MainLoss:0.1815 | Alpha:0.4581 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3933 | MainLoss:0.3933 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9267\n",
      "Test | 128/16 | Loss:0.0660 | MainLoss:0.0660 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [683 | 1000] LR: 0.000060\n",
      "Train | 16/16 | Loss:0.1779 | MainLoss:0.1637 | Alpha:0.4614 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3933 | MainLoss:0.3933 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9267\n",
      "Test | 128/16 | Loss:0.0661 | MainLoss:0.0661 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [684 | 1000] LR: 0.000060\n",
      "Train | 16/16 | Loss:0.1900 | MainLoss:0.1758 | Alpha:0.4590 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3932 | MainLoss:0.3932 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9267\n",
      "Test | 128/16 | Loss:0.0661 | MainLoss:0.0661 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [685 | 1000] LR: 0.000059\n",
      "Train | 16/16 | Loss:0.1889 | MainLoss:0.1747 | Alpha:0.4584 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3933 | MainLoss:0.3933 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9262\n",
      "Test | 128/16 | Loss:0.0660 | MainLoss:0.0660 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [686 | 1000] LR: 0.000059\n",
      "Train | 16/16 | Loss:0.1845 | MainLoss:0.1703 | Alpha:0.4604 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3933 | MainLoss:0.3933 | SPLoss:0.0001 | CLSLoss:0.1420 | AUROC:0.9265\n",
      "Test | 128/16 | Loss:0.0661 | MainLoss:0.0661 | SPLoss:0.0001 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [687 | 1000] LR: 0.000059\n",
      "Train | 16/16 | Loss:0.1914 | MainLoss:0.1772 | Alpha:0.4592 | SPLoss:0.0001 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3932 | MainLoss:0.3932 | SPLoss:0.0001 | CLSLoss:0.1420 | AUROC:0.9264\n",
      "Test | 128/16 | Loss:0.0663 | MainLoss:0.0663 | SPLoss:0.0001 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [688 | 1000] LR: 0.000059\n",
      "Train | 16/16 | Loss:0.1883 | MainLoss:0.1741 | Alpha:0.4591 | SPLoss:0.0001 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3932 | MainLoss:0.3932 | SPLoss:0.0001 | CLSLoss:0.1420 | AUROC:0.9267\n",
      "Test | 128/16 | Loss:0.0661 | MainLoss:0.0661 | SPLoss:0.0001 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [689 | 1000] LR: 0.000058\n",
      "Train | 16/16 | Loss:0.1792 | MainLoss:0.1650 | Alpha:0.4623 | SPLoss:0.0001 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3933 | MainLoss:0.3933 | SPLoss:0.0001 | CLSLoss:0.1420 | AUROC:0.9267\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0001 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [690 | 1000] LR: 0.000058\n",
      "Train | 16/16 | Loss:0.1928 | MainLoss:0.1786 | Alpha:0.4595 | SPLoss:0.0001 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3932 | MainLoss:0.3932 | SPLoss:0.0001 | CLSLoss:0.1420 | AUROC:0.9269\n",
      "Test | 128/16 | Loss:0.0663 | MainLoss:0.0663 | SPLoss:0.0001 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [691 | 1000] LR: 0.000058\n",
      "Train | 16/16 | Loss:0.1899 | MainLoss:0.1757 | Alpha:0.4594 | SPLoss:0.0001 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3932 | MainLoss:0.3932 | SPLoss:0.0001 | CLSLoss:0.1420 | AUROC:0.9269\n",
      "Test | 128/16 | Loss:0.0664 | MainLoss:0.0664 | SPLoss:0.0001 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [692 | 1000] LR: 0.000057\n",
      "Train | 16/16 | Loss:0.1875 | MainLoss:0.1733 | Alpha:0.4601 | SPLoss:0.0001 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3933 | MainLoss:0.3933 | SPLoss:0.0001 | CLSLoss:0.1420 | AUROC:0.9265\n",
      "Test | 128/16 | Loss:0.0663 | MainLoss:0.0663 | SPLoss:0.0001 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [693 | 1000] LR: 0.000057\n",
      "Train | 16/16 | Loss:0.1990 | MainLoss:0.1848 | Alpha:0.4579 | SPLoss:0.0001 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3933 | MainLoss:0.3933 | SPLoss:0.0001 | CLSLoss:0.1420 | AUROC:0.9267\n",
      "Test | 128/16 | Loss:0.0663 | MainLoss:0.0663 | SPLoss:0.0001 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [694 | 1000] LR: 0.000057\n",
      "Train | 16/16 | Loss:0.1935 | MainLoss:0.1793 | Alpha:0.4583 | SPLoss:0.0001 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3933 | MainLoss:0.3933 | SPLoss:0.0001 | CLSLoss:0.1420 | AUROC:0.9266\n",
      "Test | 128/16 | Loss:0.0663 | MainLoss:0.0663 | SPLoss:0.0001 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [695 | 1000] LR: 0.000057\n",
      "Train | 16/16 | Loss:0.1858 | MainLoss:0.1716 | Alpha:0.4616 | SPLoss:0.0001 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3933 | MainLoss:0.3933 | SPLoss:0.0001 | CLSLoss:0.1420 | AUROC:0.9268\n",
      "Test | 128/16 | Loss:0.0663 | MainLoss:0.0663 | SPLoss:0.0001 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [696 | 1000] LR: 0.000056\n",
      "Train | 16/16 | Loss:0.1980 | MainLoss:0.1838 | Alpha:0.4573 | SPLoss:0.0001 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3933 | MainLoss:0.3933 | SPLoss:0.0001 | CLSLoss:0.1420 | AUROC:0.9266\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0001 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [697 | 1000] LR: 0.000056\n",
      "Train | 16/16 | Loss:0.2004 | MainLoss:0.1862 | Alpha:0.4565 | SPLoss:0.0001 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3933 | MainLoss:0.3933 | SPLoss:0.0001 | CLSLoss:0.1420 | AUROC:0.9267\n",
      "Test | 128/16 | Loss:0.0661 | MainLoss:0.0661 | SPLoss:0.0001 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [698 | 1000] LR: 0.000056\n",
      "Train | 16/16 | Loss:0.1851 | MainLoss:0.1709 | Alpha:0.4610 | SPLoss:0.0001 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3933 | MainLoss:0.3933 | SPLoss:0.0001 | CLSLoss:0.1420 | AUROC:0.9263\n",
      "Test | 128/16 | Loss:0.0661 | MainLoss:0.0661 | SPLoss:0.0001 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [699 | 1000] LR: 0.000055\n",
      "Train | 16/16 | Loss:0.1847 | MainLoss:0.1705 | Alpha:0.4609 | SPLoss:0.0001 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3933 | MainLoss:0.3933 | SPLoss:0.0001 | CLSLoss:0.1420 | AUROC:0.9268\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0001 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [700 | 1000] LR: 0.000055\n",
      "Train | 16/16 | Loss:0.1914 | MainLoss:0.1772 | Alpha:0.4598 | SPLoss:0.0001 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3933 | MainLoss:0.3933 | SPLoss:0.0001 | CLSLoss:0.1420 | AUROC:0.9269\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 128/16 | Loss:0.0663 | MainLoss:0.0663 | SPLoss:0.0001 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [701 | 1000] LR: 0.000055\n",
      "Train | 16/16 | Loss:0.1804 | MainLoss:0.1662 | Alpha:0.4618 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3933 | MainLoss:0.3933 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9265\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [702 | 1000] LR: 0.000055\n",
      "Train | 16/16 | Loss:0.1953 | MainLoss:0.1811 | Alpha:0.4595 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3933 | MainLoss:0.3933 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9268\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [703 | 1000] LR: 0.000054\n",
      "Train | 16/16 | Loss:0.1950 | MainLoss:0.1808 | Alpha:0.4576 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3933 | MainLoss:0.3933 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9267\n",
      "Test | 128/16 | Loss:0.0660 | MainLoss:0.0660 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9991\n",
      "\n",
      "Epoch: [704 | 1000] LR: 0.000054\n",
      "Train | 16/16 | Loss:0.2056 | MainLoss:0.1914 | Alpha:0.4552 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3933 | MainLoss:0.3933 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9266\n",
      "Test | 128/16 | Loss:0.0661 | MainLoss:0.0661 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [705 | 1000] LR: 0.000054\n",
      "Train | 16/16 | Loss:0.1842 | MainLoss:0.1700 | Alpha:0.4606 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3933 | MainLoss:0.3933 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9263\n",
      "Test | 128/16 | Loss:0.0661 | MainLoss:0.0661 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [706 | 1000] LR: 0.000053\n",
      "Train | 16/16 | Loss:0.1995 | MainLoss:0.1853 | Alpha:0.4572 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3933 | MainLoss:0.3933 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9269\n",
      "Test | 128/16 | Loss:0.0660 | MainLoss:0.0660 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [707 | 1000] LR: 0.000053\n",
      "Train | 16/16 | Loss:0.1908 | MainLoss:0.1766 | Alpha:0.4587 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3933 | MainLoss:0.3933 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9265\n",
      "Test | 128/16 | Loss:0.0661 | MainLoss:0.0661 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [708 | 1000] LR: 0.000053\n",
      "Train | 16/16 | Loss:0.1983 | MainLoss:0.1841 | Alpha:0.4588 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3932 | MainLoss:0.3932 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9265\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [709 | 1000] LR: 0.000053\n",
      "Train | 16/16 | Loss:0.2039 | MainLoss:0.1897 | Alpha:0.4554 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3933 | MainLoss:0.3933 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9267\n",
      "Test | 128/16 | Loss:0.0661 | MainLoss:0.0661 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [710 | 1000] LR: 0.000052\n",
      "Train | 16/16 | Loss:0.1676 | MainLoss:0.1534 | Alpha:0.4654 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3933 | MainLoss:0.3933 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9264\n",
      "Test | 128/16 | Loss:0.0661 | MainLoss:0.0661 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [711 | 1000] LR: 0.000052\n",
      "Train | 16/16 | Loss:0.2080 | MainLoss:0.1938 | Alpha:0.4547 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3932 | MainLoss:0.3932 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9264\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [712 | 1000] LR: 0.000052\n",
      "Train | 16/16 | Loss:0.1856 | MainLoss:0.1714 | Alpha:0.4618 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3933 | MainLoss:0.3933 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9267\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [713 | 1000] LR: 0.000052\n",
      "Train | 16/16 | Loss:0.1822 | MainLoss:0.1680 | Alpha:0.4612 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3933 | MainLoss:0.3933 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9263\n",
      "Test | 128/16 | Loss:0.0661 | MainLoss:0.0661 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [714 | 1000] LR: 0.000051\n",
      "Train | 16/16 | Loss:0.1805 | MainLoss:0.1663 | Alpha:0.4613 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3933 | MainLoss:0.3933 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9266\n",
      "Test | 128/16 | Loss:0.0661 | MainLoss:0.0661 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [715 | 1000] LR: 0.000051\n",
      "Train | 16/16 | Loss:0.1851 | MainLoss:0.1709 | Alpha:0.4613 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3933 | MainLoss:0.3933 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9265\n",
      "Test | 128/16 | Loss:0.0661 | MainLoss:0.0661 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [716 | 1000] LR: 0.000051\n",
      "Train | 16/16 | Loss:0.2005 | MainLoss:0.1863 | Alpha:0.4580 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3933 | MainLoss:0.3933 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9267\n",
      "Test | 128/16 | Loss:0.0661 | MainLoss:0.0661 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [717 | 1000] LR: 0.000050\n",
      "Train | 16/16 | Loss:0.2129 | MainLoss:0.1987 | Alpha:0.4533 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3932 | MainLoss:0.3932 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9268\n",
      "Test | 128/16 | Loss:0.0661 | MainLoss:0.0661 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [718 | 1000] LR: 0.000050\n",
      "Train | 16/16 | Loss:0.1793 | MainLoss:0.1651 | Alpha:0.4616 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3932 | MainLoss:0.3932 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9269\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [719 | 1000] LR: 0.000050\n",
      "Train | 16/16 | Loss:0.1884 | MainLoss:0.1742 | Alpha:0.4600 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3932 | MainLoss:0.3932 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9266\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [720 | 1000] LR: 0.000050\n",
      "Train | 16/16 | Loss:0.1881 | MainLoss:0.1739 | Alpha:0.4600 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3933 | MainLoss:0.3933 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9265\n",
      "Test | 128/16 | Loss:0.0661 | MainLoss:0.0661 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [721 | 1000] LR: 0.000049\n",
      "Train | 16/16 | Loss:0.1928 | MainLoss:0.1786 | Alpha:0.4583 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3933 | MainLoss:0.3933 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9264\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [722 | 1000] LR: 0.000049\n",
      "Train | 16/16 | Loss:0.1793 | MainLoss:0.1651 | Alpha:0.4618 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3933 | MainLoss:0.3933 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9263\n",
      "Test | 128/16 | Loss:0.0661 | MainLoss:0.0661 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [723 | 1000] LR: 0.000049\n",
      "Train | 16/16 | Loss:0.2170 | MainLoss:0.2028 | Alpha:0.4536 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3933 | MainLoss:0.3933 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9267\n",
      "Test | 128/16 | Loss:0.0661 | MainLoss:0.0661 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [724 | 1000] LR: 0.000049\n",
      "Train | 16/16 | Loss:0.2007 | MainLoss:0.1865 | Alpha:0.4571 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3933 | MainLoss:0.3933 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9265\n",
      "Test | 128/16 | Loss:0.0659 | MainLoss:0.0659 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [725 | 1000] LR: 0.000048\n",
      "Train | 16/16 | Loss:0.1830 | MainLoss:0.1688 | Alpha:0.4607 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3933 | MainLoss:0.3933 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 128/16 | Loss:0.0660 | MainLoss:0.0660 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [726 | 1000] LR: 0.000048\n",
      "Train | 16/16 | Loss:0.1878 | MainLoss:0.1736 | Alpha:0.4609 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3934 | MainLoss:0.3934 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9264\n",
      "Test | 128/16 | Loss:0.0660 | MainLoss:0.0660 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [727 | 1000] LR: 0.000048\n",
      "Train | 16/16 | Loss:0.1678 | MainLoss:0.1536 | Alpha:0.4649 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3934 | MainLoss:0.3934 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9266\n",
      "Test | 128/16 | Loss:0.0661 | MainLoss:0.0661 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [728 | 1000] LR: 0.000047\n",
      "Train | 16/16 | Loss:0.2036 | MainLoss:0.1894 | Alpha:0.4565 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3934 | MainLoss:0.3934 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9267\n",
      "Test | 128/16 | Loss:0.0661 | MainLoss:0.0661 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [729 | 1000] LR: 0.000047\n",
      "Train | 16/16 | Loss:0.1992 | MainLoss:0.1850 | Alpha:0.4565 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3933 | MainLoss:0.3933 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9267\n",
      "Test | 128/16 | Loss:0.0663 | MainLoss:0.0663 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [730 | 1000] LR: 0.000047\n",
      "Train | 16/16 | Loss:0.2035 | MainLoss:0.1893 | Alpha:0.4555 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3933 | MainLoss:0.3933 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9264\n",
      "Test | 128/16 | Loss:0.0663 | MainLoss:0.0663 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [731 | 1000] LR: 0.000047\n",
      "Train | 16/16 | Loss:0.1989 | MainLoss:0.1847 | Alpha:0.4568 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3933 | MainLoss:0.3933 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9265\n",
      "Test | 128/16 | Loss:0.0661 | MainLoss:0.0661 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [732 | 1000] LR: 0.000046\n",
      "Train | 16/16 | Loss:0.1986 | MainLoss:0.1844 | Alpha:0.4578 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3933 | MainLoss:0.3933 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9265\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1420 | AUROC:0.9990\n",
      "\n",
      "Epoch: [733 | 1000] LR: 0.000046\n",
      "Train | 16/16 | Loss:0.2081 | MainLoss:0.1939 | Alpha:0.4550 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3932 | MainLoss:0.3932 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.9268\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.9990\n",
      "\n",
      "Epoch: [734 | 1000] LR: 0.000046\n",
      "Train | 16/16 | Loss:0.1950 | MainLoss:0.1808 | Alpha:0.4581 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3933 | MainLoss:0.3933 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.9269\n",
      "Test | 128/16 | Loss:0.0661 | MainLoss:0.0661 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.9990\n",
      "\n",
      "Epoch: [735 | 1000] LR: 0.000046\n",
      "Train | 16/16 | Loss:0.2283 | MainLoss:0.2141 | Alpha:0.4497 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3932 | MainLoss:0.3932 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.9266\n",
      "Test | 128/16 | Loss:0.0661 | MainLoss:0.0661 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.9990\n",
      "\n",
      "Epoch: [736 | 1000] LR: 0.000045\n",
      "Train | 16/16 | Loss:0.1898 | MainLoss:0.1757 | Alpha:0.4598 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3933 | MainLoss:0.3933 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.9265\n",
      "Test | 128/16 | Loss:0.0660 | MainLoss:0.0660 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.9990\n",
      "\n",
      "Epoch: [737 | 1000] LR: 0.000045\n",
      "Train | 16/16 | Loss:0.1941 | MainLoss:0.1799 | Alpha:0.4577 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3933 | MainLoss:0.3933 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.9262\n",
      "Test | 128/16 | Loss:0.0658 | MainLoss:0.0658 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.9990\n",
      "\n",
      "Epoch: [738 | 1000] LR: 0.000045\n",
      "Train | 16/16 | Loss:0.1908 | MainLoss:0.1766 | Alpha:0.4597 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3933 | MainLoss:0.3933 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.9265\n",
      "Test | 128/16 | Loss:0.0660 | MainLoss:0.0660 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.9991\n",
      "\n",
      "Epoch: [739 | 1000] LR: 0.000045\n",
      "Train | 16/16 | Loss:0.1867 | MainLoss:0.1725 | Alpha:0.4596 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3933 | MainLoss:0.3933 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.9268\n",
      "Test | 128/16 | Loss:0.0660 | MainLoss:0.0660 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.9990\n",
      "\n",
      "Epoch: [740 | 1000] LR: 0.000044\n",
      "Train | 16/16 | Loss:0.1714 | MainLoss:0.1572 | Alpha:0.4643 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3933 | MainLoss:0.3933 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.9268\n",
      "Test | 128/16 | Loss:0.0659 | MainLoss:0.0659 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.9990\n",
      "\n",
      "Epoch: [741 | 1000] LR: 0.000044\n",
      "Train | 16/16 | Loss:0.1807 | MainLoss:0.1665 | Alpha:0.4614 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3934 | MainLoss:0.3934 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.9263\n",
      "Test | 128/16 | Loss:0.0659 | MainLoss:0.0659 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.9991\n",
      "\n",
      "Epoch: [742 | 1000] LR: 0.000044\n",
      "Train | 16/16 | Loss:0.2033 | MainLoss:0.1891 | Alpha:0.4554 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3933 | MainLoss:0.3933 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.9266\n",
      "Test | 128/16 | Loss:0.0659 | MainLoss:0.0659 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.9990\n",
      "\n",
      "Epoch: [743 | 1000] LR: 0.000044\n",
      "Train | 16/16 | Loss:0.1931 | MainLoss:0.1789 | Alpha:0.4578 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3933 | MainLoss:0.3933 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.9262\n",
      "Test | 128/16 | Loss:0.0659 | MainLoss:0.0659 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.9990\n",
      "\n",
      "Epoch: [744 | 1000] LR: 0.000043\n",
      "Train | 16/16 | Loss:0.1879 | MainLoss:0.1737 | Alpha:0.4592 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3933 | MainLoss:0.3933 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.9266\n",
      "Test | 128/16 | Loss:0.0659 | MainLoss:0.0659 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.9991\n",
      "\n",
      "Epoch: [745 | 1000] LR: 0.000043\n",
      "Train | 16/16 | Loss:0.2059 | MainLoss:0.1917 | Alpha:0.4554 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3933 | MainLoss:0.3933 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.9267\n",
      "Test | 128/16 | Loss:0.0659 | MainLoss:0.0659 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.9990\n",
      "\n",
      "Epoch: [746 | 1000] LR: 0.000043\n",
      "Train | 16/16 | Loss:0.2032 | MainLoss:0.1890 | Alpha:0.4560 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3933 | MainLoss:0.3933 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.9267\n",
      "Test | 128/16 | Loss:0.0659 | MainLoss:0.0659 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.9990\n",
      "\n",
      "Epoch: [747 | 1000] LR: 0.000042\n",
      "Train | 16/16 | Loss:0.2195 | MainLoss:0.2053 | Alpha:0.4529 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3933 | MainLoss:0.3933 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.9265\n",
      "Test | 128/16 | Loss:0.0658 | MainLoss:0.0658 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.9990\n",
      "\n",
      "Epoch: [748 | 1000] LR: 0.000042\n",
      "Train | 16/16 | Loss:0.1749 | MainLoss:0.1607 | Alpha:0.4629 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3932 | MainLoss:0.3932 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.9269\n",
      "Test | 128/16 | Loss:0.0659 | MainLoss:0.0659 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.9990\n",
      "\n",
      "Epoch: [749 | 1000] LR: 0.000042\n",
      "Train | 16/16 | Loss:0.1945 | MainLoss:0.1803 | Alpha:0.4579 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3933 | MainLoss:0.3933 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.9267\n",
      "Test | 128/16 | Loss:0.0659 | MainLoss:0.0659 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.9990\n",
      "\n",
      "Epoch: [750 | 1000] LR: 0.000042\n",
      "Train | 16/16 | Loss:0.2065 | MainLoss:0.1924 | Alpha:0.4551 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3932 | MainLoss:0.3932 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.9267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 128/16 | Loss:0.0660 | MainLoss:0.0660 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.9990\n",
      "\n",
      "Epoch: [751 | 1000] LR: 0.000041\n",
      "Train | 16/16 | Loss:0.1939 | MainLoss:0.1797 | Alpha:0.4582 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3932 | MainLoss:0.3932 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.9266\n",
      "Test | 128/16 | Loss:0.0660 | MainLoss:0.0660 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.9990\n",
      "\n",
      "Epoch: [752 | 1000] LR: 0.000041\n",
      "Train | 16/16 | Loss:0.2063 | MainLoss:0.1921 | Alpha:0.4564 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3932 | MainLoss:0.3932 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.9268\n",
      "Test | 128/16 | Loss:0.0660 | MainLoss:0.0660 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.9990\n",
      "\n",
      "Epoch: [753 | 1000] LR: 0.000041\n",
      "Train | 16/16 | Loss:0.1925 | MainLoss:0.1783 | Alpha:0.4586 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3932 | MainLoss:0.3932 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.9268\n",
      "Test | 128/16 | Loss:0.0659 | MainLoss:0.0659 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.9990\n",
      "\n",
      "Epoch: [754 | 1000] LR: 0.000041\n",
      "Train | 16/16 | Loss:0.1790 | MainLoss:0.1648 | Alpha:0.4616 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3932 | MainLoss:0.3932 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.9264\n",
      "Test | 128/16 | Loss:0.0659 | MainLoss:0.0659 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.9990\n",
      "\n",
      "Epoch: [755 | 1000] LR: 0.000040\n",
      "Train | 16/16 | Loss:0.1692 | MainLoss:0.1550 | Alpha:0.4649 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3932 | MainLoss:0.3932 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.9266\n",
      "Test | 128/16 | Loss:0.0659 | MainLoss:0.0659 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.9990\n",
      "\n",
      "Epoch: [756 | 1000] LR: 0.000040\n",
      "Train | 16/16 | Loss:0.1905 | MainLoss:0.1763 | Alpha:0.4594 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3932 | MainLoss:0.3932 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.9266\n",
      "Test | 128/16 | Loss:0.0659 | MainLoss:0.0659 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.9990\n",
      "\n",
      "Epoch: [757 | 1000] LR: 0.000040\n",
      "Train | 16/16 | Loss:0.2091 | MainLoss:0.1949 | Alpha:0.4546 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3932 | MainLoss:0.3932 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.9265\n",
      "Test | 128/16 | Loss:0.0658 | MainLoss:0.0658 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.9990\n",
      "\n",
      "Epoch: [758 | 1000] LR: 0.000040\n",
      "Train | 16/16 | Loss:0.1749 | MainLoss:0.1607 | Alpha:0.4631 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3933 | MainLoss:0.3933 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.9264\n",
      "Test | 128/16 | Loss:0.0658 | MainLoss:0.0658 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.9990\n",
      "\n",
      "Epoch: [759 | 1000] LR: 0.000039\n",
      "Train | 16/16 | Loss:0.2093 | MainLoss:0.1951 | Alpha:0.4557 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3932 | MainLoss:0.3932 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.9268\n",
      "Test | 128/16 | Loss:0.0659 | MainLoss:0.0659 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.9990\n",
      "\n",
      "Epoch: [760 | 1000] LR: 0.000039\n",
      "Train | 16/16 | Loss:0.1947 | MainLoss:0.1805 | Alpha:0.4585 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3932 | MainLoss:0.3932 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.9265\n",
      "Test | 128/16 | Loss:0.0660 | MainLoss:0.0660 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.9990\n",
      "\n",
      "Epoch: [761 | 1000] LR: 0.000039\n",
      "Train | 16/16 | Loss:0.1877 | MainLoss:0.1736 | Alpha:0.4599 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3932 | MainLoss:0.3932 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.9267\n",
      "Test | 128/16 | Loss:0.0660 | MainLoss:0.0660 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.9990\n",
      "\n",
      "Epoch: [762 | 1000] LR: 0.000039\n",
      "Train | 16/16 | Loss:0.1923 | MainLoss:0.1781 | Alpha:0.4593 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3932 | MainLoss:0.3932 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.9265\n",
      "Test | 128/16 | Loss:0.0660 | MainLoss:0.0660 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.9990\n",
      "\n",
      "Epoch: [763 | 1000] LR: 0.000038\n",
      "Train | 16/16 | Loss:0.1982 | MainLoss:0.1840 | Alpha:0.4579 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3932 | MainLoss:0.3932 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.9267\n",
      "Test | 128/16 | Loss:0.0660 | MainLoss:0.0660 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.9990\n",
      "\n",
      "Epoch: [764 | 1000] LR: 0.000038\n",
      "Train | 16/16 | Loss:0.1869 | MainLoss:0.1727 | Alpha:0.4591 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3932 | MainLoss:0.3932 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.9267\n",
      "Test | 128/16 | Loss:0.0661 | MainLoss:0.0661 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.9990\n",
      "\n",
      "Epoch: [765 | 1000] LR: 0.000038\n",
      "Train | 16/16 | Loss:0.1946 | MainLoss:0.1804 | Alpha:0.4586 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3932 | MainLoss:0.3932 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.9268\n",
      "Test | 128/16 | Loss:0.0660 | MainLoss:0.0660 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.9990\n",
      "\n",
      "Epoch: [766 | 1000] LR: 0.000038\n",
      "Train | 16/16 | Loss:0.2145 | MainLoss:0.2004 | Alpha:0.4528 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.9268\n",
      "Test | 128/16 | Loss:0.0661 | MainLoss:0.0661 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.9990\n",
      "\n",
      "Epoch: [767 | 1000] LR: 0.000037\n",
      "Train | 16/16 | Loss:0.1848 | MainLoss:0.1707 | Alpha:0.4609 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.9270\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.9990\n",
      "\n",
      "Epoch: [768 | 1000] LR: 0.000037\n",
      "Train | 16/16 | Loss:0.1884 | MainLoss:0.1742 | Alpha:0.4605 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.9267\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.9990\n",
      "\n",
      "Epoch: [769 | 1000] LR: 0.000037\n",
      "Train | 16/16 | Loss:0.1979 | MainLoss:0.1837 | Alpha:0.4580 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.9268\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.9990\n",
      "\n",
      "Epoch: [770 | 1000] LR: 0.000037\n",
      "Train | 16/16 | Loss:0.2135 | MainLoss:0.1993 | Alpha:0.4536 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9266\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [771 | 1000] LR: 0.000036\n",
      "Train | 16/16 | Loss:0.1860 | MainLoss:0.1718 | Alpha:0.4608 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3932 | MainLoss:0.3932 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.9265\n",
      "Test | 128/16 | Loss:0.0661 | MainLoss:0.0661 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.9990\n",
      "\n",
      "Epoch: [772 | 1000] LR: 0.000036\n",
      "Train | 16/16 | Loss:0.1973 | MainLoss:0.1831 | Alpha:0.4577 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3932 | MainLoss:0.3932 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9266\n",
      "Test | 128/16 | Loss:0.0661 | MainLoss:0.0661 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [773 | 1000] LR: 0.000036\n",
      "Train | 16/16 | Loss:0.2071 | MainLoss:0.1929 | Alpha:0.4552 | SPLoss:0.0000 | CLSLoss:0.1419 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9266\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [774 | 1000] LR: 0.000036\n",
      "Train | 16/16 | Loss:0.2071 | MainLoss:0.1929 | Alpha:0.4550 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9266\n",
      "Test | 128/16 | Loss:0.0663 | MainLoss:0.0663 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [775 | 1000] LR: 0.000036\n",
      "Train | 16/16 | Loss:0.2118 | MainLoss:0.1976 | Alpha:0.4543 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3930 | MainLoss:0.3930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 128/16 | Loss:0.0663 | MainLoss:0.0663 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [776 | 1000] LR: 0.000035\n",
      "Train | 16/16 | Loss:0.1942 | MainLoss:0.1801 | Alpha:0.4578 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3930 | MainLoss:0.3930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9265\n",
      "Test | 128/16 | Loss:0.0663 | MainLoss:0.0663 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [777 | 1000] LR: 0.000035\n",
      "Train | 16/16 | Loss:0.1977 | MainLoss:0.1835 | Alpha:0.4567 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3930 | MainLoss:0.3930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9268\n",
      "Test | 128/16 | Loss:0.0663 | MainLoss:0.0663 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [778 | 1000] LR: 0.000035\n",
      "Train | 16/16 | Loss:0.1882 | MainLoss:0.1741 | Alpha:0.4602 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3930 | MainLoss:0.3930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9264\n",
      "Test | 128/16 | Loss:0.0663 | MainLoss:0.0663 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [779 | 1000] LR: 0.000035\n",
      "Train | 16/16 | Loss:0.1945 | MainLoss:0.1803 | Alpha:0.4577 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3930 | MainLoss:0.3930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9264\n",
      "Test | 128/16 | Loss:0.0663 | MainLoss:0.0663 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [780 | 1000] LR: 0.000034\n",
      "Train | 16/16 | Loss:0.1803 | MainLoss:0.1661 | Alpha:0.4628 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3930 | MainLoss:0.3930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9265\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [781 | 1000] LR: 0.000034\n",
      "Train | 16/16 | Loss:0.2034 | MainLoss:0.1892 | Alpha:0.4556 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3930 | MainLoss:0.3930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9264\n",
      "Test | 128/16 | Loss:0.0663 | MainLoss:0.0663 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [782 | 1000] LR: 0.000034\n",
      "Train | 16/16 | Loss:0.1887 | MainLoss:0.1745 | Alpha:0.4591 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3930 | MainLoss:0.3930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9267\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9989\n",
      "\n",
      "Epoch: [783 | 1000] LR: 0.000034\n",
      "Train | 16/16 | Loss:0.1983 | MainLoss:0.1841 | Alpha:0.4566 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3930 | MainLoss:0.3930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9267\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [784 | 1000] LR: 0.000033\n",
      "Train | 16/16 | Loss:0.1939 | MainLoss:0.1797 | Alpha:0.4588 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3930 | MainLoss:0.3930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9270\n",
      "Test | 128/16 | Loss:0.0661 | MainLoss:0.0661 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [785 | 1000] LR: 0.000033\n",
      "Train | 16/16 | Loss:0.1904 | MainLoss:0.1762 | Alpha:0.4593 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3930 | MainLoss:0.3930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9265\n",
      "Test | 128/16 | Loss:0.0661 | MainLoss:0.0661 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [786 | 1000] LR: 0.000033\n",
      "Train | 16/16 | Loss:0.1886 | MainLoss:0.1744 | Alpha:0.4591 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3930 | MainLoss:0.3930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9267\n",
      "Test | 128/16 | Loss:0.0661 | MainLoss:0.0661 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [787 | 1000] LR: 0.000033\n",
      "Train | 16/16 | Loss:0.2156 | MainLoss:0.2015 | Alpha:0.4533 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3930 | MainLoss:0.3930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9268\n",
      "Test | 128/16 | Loss:0.0661 | MainLoss:0.0661 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [788 | 1000] LR: 0.000032\n",
      "Train | 16/16 | Loss:0.1852 | MainLoss:0.1710 | Alpha:0.4611 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3930 | MainLoss:0.3930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9267\n",
      "Test | 128/16 | Loss:0.0661 | MainLoss:0.0661 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [789 | 1000] LR: 0.000032\n",
      "Train | 16/16 | Loss:0.1963 | MainLoss:0.1821 | Alpha:0.4577 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3930 | MainLoss:0.3930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9265\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [790 | 1000] LR: 0.000032\n",
      "Train | 16/16 | Loss:0.1982 | MainLoss:0.1840 | Alpha:0.4579 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3929 | MainLoss:0.3929 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9267\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [791 | 1000] LR: 0.000032\n",
      "Train | 16/16 | Loss:0.1882 | MainLoss:0.1740 | Alpha:0.4603 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3930 | MainLoss:0.3930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9268\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [792 | 1000] LR: 0.000032\n",
      "Train | 16/16 | Loss:0.1814 | MainLoss:0.1672 | Alpha:0.4610 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3929 | MainLoss:0.3929 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9267\n",
      "Test | 128/16 | Loss:0.0663 | MainLoss:0.0663 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [793 | 1000] LR: 0.000031\n",
      "Train | 16/16 | Loss:0.1948 | MainLoss:0.1806 | Alpha:0.4584 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3930 | MainLoss:0.3930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9263\n",
      "Test | 128/16 | Loss:0.0663 | MainLoss:0.0663 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9991\n",
      "\n",
      "Epoch: [794 | 1000] LR: 0.000031\n",
      "Train | 16/16 | Loss:0.1739 | MainLoss:0.1597 | Alpha:0.4629 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3930 | MainLoss:0.3930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9265\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9989\n",
      "\n",
      "Epoch: [795 | 1000] LR: 0.000031\n",
      "Train | 16/16 | Loss:0.1919 | MainLoss:0.1777 | Alpha:0.4601 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3930 | MainLoss:0.3930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9266\n",
      "Test | 128/16 | Loss:0.0663 | MainLoss:0.0663 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [796 | 1000] LR: 0.000031\n",
      "Train | 16/16 | Loss:0.1956 | MainLoss:0.1814 | Alpha:0.4574 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3930 | MainLoss:0.3930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9263\n",
      "Test | 128/16 | Loss:0.0663 | MainLoss:0.0663 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [797 | 1000] LR: 0.000030\n",
      "Train | 16/16 | Loss:0.1778 | MainLoss:0.1636 | Alpha:0.4634 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3930 | MainLoss:0.3930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9263\n",
      "Test | 128/16 | Loss:0.0663 | MainLoss:0.0663 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [798 | 1000] LR: 0.000030\n",
      "Train | 16/16 | Loss:0.1909 | MainLoss:0.1768 | Alpha:0.4595 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3930 | MainLoss:0.3930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9268\n",
      "Test | 128/16 | Loss:0.0663 | MainLoss:0.0663 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [799 | 1000] LR: 0.000030\n",
      "Train | 16/16 | Loss:0.1800 | MainLoss:0.1658 | Alpha:0.4609 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3930 | MainLoss:0.3930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9264\n",
      "Test | 128/16 | Loss:0.0663 | MainLoss:0.0663 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [800 | 1000] LR: 0.000030\n",
      "Train | 16/16 | Loss:0.1852 | MainLoss:0.1710 | Alpha:0.4606 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3930 | MainLoss:0.3930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 128/16 | Loss:0.0663 | MainLoss:0.0663 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [801 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.1992 | MainLoss:0.1850 | Alpha:0.4570 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3930 | MainLoss:0.3930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9270\n",
      "Test | 128/16 | Loss:0.0663 | MainLoss:0.0663 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [802 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.2002 | MainLoss:0.1860 | Alpha:0.4580 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3930 | MainLoss:0.3930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9268\n",
      "Test | 128/16 | Loss:0.0663 | MainLoss:0.0663 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [803 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.1837 | MainLoss:0.1696 | Alpha:0.4615 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3930 | MainLoss:0.3930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9268\n",
      "Test | 128/16 | Loss:0.0663 | MainLoss:0.0663 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [804 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.1733 | MainLoss:0.1591 | Alpha:0.4646 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3930 | MainLoss:0.3930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9267\n",
      "Test | 128/16 | Loss:0.0663 | MainLoss:0.0663 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9989\n",
      "\n",
      "Epoch: [805 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.1972 | MainLoss:0.1830 | Alpha:0.4570 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3930 | MainLoss:0.3930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9266\n",
      "Test | 128/16 | Loss:0.0663 | MainLoss:0.0663 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [806 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.1933 | MainLoss:0.1791 | Alpha:0.4588 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3930 | MainLoss:0.3930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9268\n",
      "Test | 128/16 | Loss:0.0663 | MainLoss:0.0663 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [807 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.2008 | MainLoss:0.1866 | Alpha:0.4576 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3930 | MainLoss:0.3930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9267\n",
      "Test | 128/16 | Loss:0.0663 | MainLoss:0.0663 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [808 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.1999 | MainLoss:0.1857 | Alpha:0.4573 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3930 | MainLoss:0.3930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9266\n",
      "Test | 128/16 | Loss:0.0663 | MainLoss:0.0663 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [809 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.2092 | MainLoss:0.1950 | Alpha:0.4545 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3930 | MainLoss:0.3930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9264\n",
      "Test | 128/16 | Loss:0.0663 | MainLoss:0.0663 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [810 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.1970 | MainLoss:0.1828 | Alpha:0.4575 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3930 | MainLoss:0.3930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9265\n",
      "Test | 128/16 | Loss:0.0663 | MainLoss:0.0663 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [811 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.1791 | MainLoss:0.1649 | Alpha:0.4613 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3930 | MainLoss:0.3930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9266\n",
      "Test | 128/16 | Loss:0.0663 | MainLoss:0.0663 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [812 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.1826 | MainLoss:0.1684 | Alpha:0.4611 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3930 | MainLoss:0.3930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9264\n",
      "Test | 128/16 | Loss:0.0663 | MainLoss:0.0663 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [813 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.2123 | MainLoss:0.1981 | Alpha:0.4545 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3930 | MainLoss:0.3930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9264\n",
      "Test | 128/16 | Loss:0.0663 | MainLoss:0.0663 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [814 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.1955 | MainLoss:0.1813 | Alpha:0.4585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3930 | MainLoss:0.3930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9264\n",
      "Test | 128/16 | Loss:0.0663 | MainLoss:0.0663 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [815 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.1978 | MainLoss:0.1836 | Alpha:0.4563 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3930 | MainLoss:0.3930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9267\n",
      "Test | 128/16 | Loss:0.0663 | MainLoss:0.0663 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [816 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.1968 | MainLoss:0.1827 | Alpha:0.4581 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3930 | MainLoss:0.3930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9268\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [817 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.2007 | MainLoss:0.1865 | Alpha:0.4565 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3930 | MainLoss:0.3930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9266\n",
      "Test | 128/16 | Loss:0.0663 | MainLoss:0.0663 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [818 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.1899 | MainLoss:0.1757 | Alpha:0.4596 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3930 | MainLoss:0.3930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9264\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [819 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.1903 | MainLoss:0.1762 | Alpha:0.4584 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3930 | MainLoss:0.3930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9265\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9991\n",
      "\n",
      "Epoch: [820 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.1682 | MainLoss:0.1541 | Alpha:0.4645 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3930 | MainLoss:0.3930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9268\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [821 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.2026 | MainLoss:0.1885 | Alpha:0.4568 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3930 | MainLoss:0.3930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9267\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [822 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.2117 | MainLoss:0.1975 | Alpha:0.4545 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3930 | MainLoss:0.3930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9264\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [823 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.1813 | MainLoss:0.1671 | Alpha:0.4612 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3930 | MainLoss:0.3930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9265\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [824 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.2024 | MainLoss:0.1882 | Alpha:0.4552 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3930 | MainLoss:0.3930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9267\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [825 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.1905 | MainLoss:0.1763 | Alpha:0.4593 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3930 | MainLoss:0.3930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9991\n",
      "\n",
      "Epoch: [826 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.1823 | MainLoss:0.1682 | Alpha:0.4623 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3930 | MainLoss:0.3930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9266\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [827 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.1833 | MainLoss:0.1691 | Alpha:0.4617 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3930 | MainLoss:0.3930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9267\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [828 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.1931 | MainLoss:0.1789 | Alpha:0.4583 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3930 | MainLoss:0.3930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9265\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [829 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.1835 | MainLoss:0.1693 | Alpha:0.4616 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3930 | MainLoss:0.3930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9270\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [830 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.2134 | MainLoss:0.1992 | Alpha:0.4548 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3930 | MainLoss:0.3930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9268\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [831 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.2064 | MainLoss:0.1922 | Alpha:0.4553 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3930 | MainLoss:0.3930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9265\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [832 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.1818 | MainLoss:0.1676 | Alpha:0.4613 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3930 | MainLoss:0.3930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9266\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [833 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.1781 | MainLoss:0.1639 | Alpha:0.4624 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3930 | MainLoss:0.3930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9267\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [834 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.1835 | MainLoss:0.1693 | Alpha:0.4614 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3930 | MainLoss:0.3930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9264\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [835 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.1864 | MainLoss:0.1722 | Alpha:0.4606 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3930 | MainLoss:0.3930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9269\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [836 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.1777 | MainLoss:0.1635 | Alpha:0.4625 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3930 | MainLoss:0.3930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9267\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [837 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.1752 | MainLoss:0.1610 | Alpha:0.4625 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3930 | MainLoss:0.3930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9264\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [838 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.1814 | MainLoss:0.1672 | Alpha:0.4625 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3930 | MainLoss:0.3930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9266\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [839 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.1978 | MainLoss:0.1836 | Alpha:0.4582 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3930 | MainLoss:0.3930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9270\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [840 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.1798 | MainLoss:0.1656 | Alpha:0.4620 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3930 | MainLoss:0.3930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9266\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [841 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.1717 | MainLoss:0.1575 | Alpha:0.4630 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3930 | MainLoss:0.3930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9262\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [842 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.1827 | MainLoss:0.1685 | Alpha:0.4617 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3930 | MainLoss:0.3930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9266\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [843 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.1991 | MainLoss:0.1849 | Alpha:0.4567 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3930 | MainLoss:0.3930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9264\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [844 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.1932 | MainLoss:0.1790 | Alpha:0.4582 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3930 | MainLoss:0.3930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9266\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [845 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.1971 | MainLoss:0.1829 | Alpha:0.4581 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3930 | MainLoss:0.3930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9265\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [846 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.1951 | MainLoss:0.1810 | Alpha:0.4572 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3930 | MainLoss:0.3930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9267\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [847 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.1659 | MainLoss:0.1517 | Alpha:0.4657 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3930 | MainLoss:0.3930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9266\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [848 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.1830 | MainLoss:0.1688 | Alpha:0.4604 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3930 | MainLoss:0.3930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9263\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [849 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.1813 | MainLoss:0.1671 | Alpha:0.4617 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3930 | MainLoss:0.3930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9265\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [850 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.1852 | MainLoss:0.1710 | Alpha:0.4610 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [851 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.1957 | MainLoss:0.1815 | Alpha:0.4570 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9265\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [852 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.2030 | MainLoss:0.1889 | Alpha:0.4561 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9266\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [853 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.1914 | MainLoss:0.1772 | Alpha:0.4590 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9267\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [854 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.2074 | MainLoss:0.1932 | Alpha:0.4553 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9266\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [855 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.1861 | MainLoss:0.1719 | Alpha:0.4612 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9264\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [856 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.1822 | MainLoss:0.1680 | Alpha:0.4612 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9265\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [857 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.1996 | MainLoss:0.1855 | Alpha:0.4569 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9266\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [858 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.1905 | MainLoss:0.1763 | Alpha:0.4605 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9267\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [859 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.1823 | MainLoss:0.1681 | Alpha:0.4612 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9266\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9991\n",
      "\n",
      "Epoch: [860 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.1824 | MainLoss:0.1682 | Alpha:0.4603 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9265\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [861 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.1910 | MainLoss:0.1768 | Alpha:0.4603 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9262\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [862 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.1974 | MainLoss:0.1832 | Alpha:0.4561 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9267\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [863 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.1952 | MainLoss:0.1810 | Alpha:0.4586 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9266\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [864 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.1990 | MainLoss:0.1848 | Alpha:0.4566 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9267\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [865 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.1970 | MainLoss:0.1829 | Alpha:0.4582 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9268\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [866 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.1971 | MainLoss:0.1829 | Alpha:0.4589 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9269\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [867 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.1938 | MainLoss:0.1796 | Alpha:0.4583 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9267\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [868 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.1883 | MainLoss:0.1741 | Alpha:0.4596 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9268\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [869 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.1907 | MainLoss:0.1765 | Alpha:0.4600 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9266\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [870 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.1948 | MainLoss:0.1806 | Alpha:0.4585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9267\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [871 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.1813 | MainLoss:0.1671 | Alpha:0.4616 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9264\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [872 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.1822 | MainLoss:0.1680 | Alpha:0.4616 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9265\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9991\n",
      "\n",
      "Epoch: [873 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.1781 | MainLoss:0.1639 | Alpha:0.4617 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9265\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [874 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.2033 | MainLoss:0.1891 | Alpha:0.4558 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9268\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [875 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.2024 | MainLoss:0.1882 | Alpha:0.4565 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [876 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.1880 | MainLoss:0.1738 | Alpha:0.4595 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9265\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [877 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.1976 | MainLoss:0.1834 | Alpha:0.4577 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3930 | MainLoss:0.3930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9267\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [878 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.1807 | MainLoss:0.1665 | Alpha:0.4610 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3930 | MainLoss:0.3930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9264\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [879 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.1914 | MainLoss:0.1772 | Alpha:0.4594 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9264\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [880 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.2011 | MainLoss:0.1870 | Alpha:0.4574 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3930 | MainLoss:0.3930 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9265\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [881 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.1795 | MainLoss:0.1653 | Alpha:0.4614 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9266\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [882 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.1953 | MainLoss:0.1811 | Alpha:0.4583 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9266\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [883 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.1773 | MainLoss:0.1631 | Alpha:0.4625 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9267\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [884 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.1900 | MainLoss:0.1758 | Alpha:0.4585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9265\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [885 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.1985 | MainLoss:0.1844 | Alpha:0.4574 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9266\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9989\n",
      "\n",
      "Epoch: [886 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.1918 | MainLoss:0.1776 | Alpha:0.4594 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9267\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [887 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.2141 | MainLoss:0.1999 | Alpha:0.4529 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9268\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [888 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.1974 | MainLoss:0.1833 | Alpha:0.4572 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9268\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [889 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.1898 | MainLoss:0.1756 | Alpha:0.4602 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9268\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [890 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.1904 | MainLoss:0.1762 | Alpha:0.4581 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9268\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [891 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.1723 | MainLoss:0.1581 | Alpha:0.4633 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9270\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [892 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.2068 | MainLoss:0.1926 | Alpha:0.4553 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9265\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [893 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.2044 | MainLoss:0.1902 | Alpha:0.4565 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9265\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [894 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.2065 | MainLoss:0.1923 | Alpha:0.4557 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9266\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [895 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.1938 | MainLoss:0.1796 | Alpha:0.4593 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9265\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [896 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.1941 | MainLoss:0.1799 | Alpha:0.4596 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9268\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [897 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.1877 | MainLoss:0.1735 | Alpha:0.4601 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9264\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [898 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.2046 | MainLoss:0.1904 | Alpha:0.4564 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9267\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [899 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.2004 | MainLoss:0.1862 | Alpha:0.4573 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9268\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [900 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.1909 | MainLoss:0.1767 | Alpha:0.4590 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [901 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.1920 | MainLoss:0.1778 | Alpha:0.4591 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9266\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9991\n",
      "\n",
      "Epoch: [902 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.1981 | MainLoss:0.1839 | Alpha:0.4582 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9266\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [903 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.1787 | MainLoss:0.1645 | Alpha:0.4617 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9266\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [904 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.1866 | MainLoss:0.1724 | Alpha:0.4602 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9266\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [905 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.1897 | MainLoss:0.1756 | Alpha:0.4605 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9269\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [906 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.1810 | MainLoss:0.1668 | Alpha:0.4627 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9264\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [907 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.1975 | MainLoss:0.1833 | Alpha:0.4575 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9268\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [908 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.2007 | MainLoss:0.1866 | Alpha:0.4568 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9269\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [909 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.2079 | MainLoss:0.1938 | Alpha:0.4549 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9264\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [910 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.1999 | MainLoss:0.1857 | Alpha:0.4562 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9264\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [911 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.1769 | MainLoss:0.1627 | Alpha:0.4619 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9268\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [912 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.1904 | MainLoss:0.1763 | Alpha:0.4592 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9265\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [913 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.1834 | MainLoss:0.1693 | Alpha:0.4612 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9267\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9991\n",
      "\n",
      "Epoch: [914 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.2183 | MainLoss:0.2041 | Alpha:0.4530 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9264\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [915 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.1938 | MainLoss:0.1796 | Alpha:0.4587 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9266\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [916 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.1720 | MainLoss:0.1578 | Alpha:0.4629 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9265\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [917 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.1842 | MainLoss:0.1700 | Alpha:0.4604 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9267\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [918 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.1869 | MainLoss:0.1727 | Alpha:0.4595 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9268\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9991\n",
      "\n",
      "Epoch: [919 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.2055 | MainLoss:0.1913 | Alpha:0.4567 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9266\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [920 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.1972 | MainLoss:0.1831 | Alpha:0.4582 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9265\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [921 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.1825 | MainLoss:0.1683 | Alpha:0.4618 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9269\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [922 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.1794 | MainLoss:0.1652 | Alpha:0.4618 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9267\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [923 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.1831 | MainLoss:0.1689 | Alpha:0.4611 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9264\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [924 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.1871 | MainLoss:0.1729 | Alpha:0.4601 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9268\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [925 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.1982 | MainLoss:0.1841 | Alpha:0.4577 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [926 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.1762 | MainLoss:0.1620 | Alpha:0.4628 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9268\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [927 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.1943 | MainLoss:0.1801 | Alpha:0.4581 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9267\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [928 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.1663 | MainLoss:0.1521 | Alpha:0.4642 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9269\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [929 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.1991 | MainLoss:0.1849 | Alpha:0.4571 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9265\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [930 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.1942 | MainLoss:0.1800 | Alpha:0.4594 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9265\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [931 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.2039 | MainLoss:0.1897 | Alpha:0.4560 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9269\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [932 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.2025 | MainLoss:0.1884 | Alpha:0.4564 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9268\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [933 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.1765 | MainLoss:0.1623 | Alpha:0.4619 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9265\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [934 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.1971 | MainLoss:0.1829 | Alpha:0.4574 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9265\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [935 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.2049 | MainLoss:0.1908 | Alpha:0.4559 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9264\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [936 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.2002 | MainLoss:0.1860 | Alpha:0.4578 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9265\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [937 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.1999 | MainLoss:0.1857 | Alpha:0.4577 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9265\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [938 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.1903 | MainLoss:0.1762 | Alpha:0.4591 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9266\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [939 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.1843 | MainLoss:0.1701 | Alpha:0.4599 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9266\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [940 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.1992 | MainLoss:0.1850 | Alpha:0.4578 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9267\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9991\n",
      "\n",
      "Epoch: [941 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.1983 | MainLoss:0.1841 | Alpha:0.4572 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9268\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [942 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.1934 | MainLoss:0.1792 | Alpha:0.4587 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9262\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [943 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.2025 | MainLoss:0.1883 | Alpha:0.4574 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9266\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [944 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.1835 | MainLoss:0.1693 | Alpha:0.4605 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9264\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [945 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.1970 | MainLoss:0.1829 | Alpha:0.4588 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9268\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [946 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.2067 | MainLoss:0.1925 | Alpha:0.4558 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9266\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [947 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.1964 | MainLoss:0.1822 | Alpha:0.4576 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9266\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [948 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.1732 | MainLoss:0.1591 | Alpha:0.4630 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9267\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [949 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.1996 | MainLoss:0.1854 | Alpha:0.4573 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9267\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [950 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.1964 | MainLoss:0.1823 | Alpha:0.4574 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [951 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.1889 | MainLoss:0.1747 | Alpha:0.4600 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9265\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [952 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.1833 | MainLoss:0.1691 | Alpha:0.4617 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9267\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [953 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.1971 | MainLoss:0.1829 | Alpha:0.4566 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9264\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [954 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.1888 | MainLoss:0.1746 | Alpha:0.4590 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9268\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [955 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.1881 | MainLoss:0.1740 | Alpha:0.4589 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9268\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [956 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.1985 | MainLoss:0.1843 | Alpha:0.4576 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9269\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [957 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.1908 | MainLoss:0.1767 | Alpha:0.4596 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9266\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [958 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.1931 | MainLoss:0.1789 | Alpha:0.4590 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9266\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [959 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.1783 | MainLoss:0.1642 | Alpha:0.4637 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9270\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [960 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.1977 | MainLoss:0.1835 | Alpha:0.4584 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9264\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [961 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.1836 | MainLoss:0.1694 | Alpha:0.4608 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9266\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [962 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.2070 | MainLoss:0.1928 | Alpha:0.4553 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9269\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [963 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.2007 | MainLoss:0.1866 | Alpha:0.4573 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9268\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [964 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.1914 | MainLoss:0.1772 | Alpha:0.4588 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9263\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [965 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.1911 | MainLoss:0.1769 | Alpha:0.4599 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9264\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [966 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.1977 | MainLoss:0.1835 | Alpha:0.4564 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9265\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9991\n",
      "\n",
      "Epoch: [967 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.1935 | MainLoss:0.1794 | Alpha:0.4593 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9264\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [968 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.2047 | MainLoss:0.1905 | Alpha:0.4571 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9267\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [969 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.2050 | MainLoss:0.1908 | Alpha:0.4561 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9267\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [970 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.1866 | MainLoss:0.1724 | Alpha:0.4599 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9264\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [971 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.1993 | MainLoss:0.1851 | Alpha:0.4563 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9266\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [972 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.1892 | MainLoss:0.1750 | Alpha:0.4594 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9265\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [973 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.1903 | MainLoss:0.1761 | Alpha:0.4594 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9268\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [974 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.1984 | MainLoss:0.1842 | Alpha:0.4581 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9266\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [975 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.1871 | MainLoss:0.1729 | Alpha:0.4599 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9269\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [976 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.2026 | MainLoss:0.1884 | Alpha:0.4562 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9268\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [977 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.1794 | MainLoss:0.1652 | Alpha:0.4620 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9269\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [978 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.1762 | MainLoss:0.1620 | Alpha:0.4625 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9266\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [979 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.1939 | MainLoss:0.1798 | Alpha:0.4581 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9267\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [980 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.2059 | MainLoss:0.1917 | Alpha:0.4548 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9265\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [981 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.1761 | MainLoss:0.1620 | Alpha:0.4625 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9270\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [982 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.2160 | MainLoss:0.2018 | Alpha:0.4520 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9266\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [983 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.2118 | MainLoss:0.1976 | Alpha:0.4545 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9267\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [984 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.1778 | MainLoss:0.1636 | Alpha:0.4622 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9263\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [985 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.1913 | MainLoss:0.1772 | Alpha:0.4579 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9268\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9991\n",
      "\n",
      "Epoch: [986 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.1692 | MainLoss:0.1550 | Alpha:0.4650 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9265\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [987 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.1875 | MainLoss:0.1733 | Alpha:0.4610 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9266\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [988 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.1891 | MainLoss:0.1749 | Alpha:0.4587 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9268\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [989 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.1999 | MainLoss:0.1857 | Alpha:0.4569 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9266\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9991\n",
      "\n",
      "Epoch: [990 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.1930 | MainLoss:0.1788 | Alpha:0.4585 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9267\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [991 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.1815 | MainLoss:0.1673 | Alpha:0.4614 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9267\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [992 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.1867 | MainLoss:0.1725 | Alpha:0.4601 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9268\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [993 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.1891 | MainLoss:0.1749 | Alpha:0.4594 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9267\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [994 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.2153 | MainLoss:0.2011 | Alpha:0.4528 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9267\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [995 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.2147 | MainLoss:0.2005 | Alpha:0.4536 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9267\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [996 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.2002 | MainLoss:0.1860 | Alpha:0.4562 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9268\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [997 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.1980 | MainLoss:0.1838 | Alpha:0.4571 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9268\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [998 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.2027 | MainLoss:0.1885 | Alpha:0.4571 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9265\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [999 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.2217 | MainLoss:0.2075 | Alpha:0.4499 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9268\n",
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n",
      "\n",
      "Epoch: [1000 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.1946 | MainLoss:0.1804 | Alpha:0.4583 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.0000\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 128/16 | Loss:0.0662 | MainLoss:0.0662 | SPLoss:0.0000 | CLSLoss:0.1418 | AUROC:0.9990\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(start_epoch, epochs):\n",
    "    state['lr'] = optimizer.state_dict()['param_groups'][0]['lr']\n",
    "\n",
    "    print('\\nEpoch: [%d | %d] LR: %f' % (epoch + 1, epochs, state['lr']))\n",
    "    \n",
    "    train_loss, train_auroc = train(train_loader, teacher_model, student_model, criterion, optimizer, epoch, use_cuda)\n",
    "    test_loss, test_auroc = test(val_target_loader, student_model, criterion, epoch, use_cuda)\n",
    "    source_loss, source_auroc = test(val_source_loader, student_model, criterion, epoch, use_cuda)\n",
    "\n",
    "\n",
    "    logger.append([state['lr'], train_loss, test_loss,  source_loss, train_auroc, test_auroc, source_auroc])\n",
    "    is_best = test_auroc+source_auroc > best_acc\n",
    "    best_acc = max(test_auroc+source_auroc, best_acc)\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'state_dict' : student_model.state_dict(),\n",
    "        'best_acc': best_acc,\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    }, is_best, checkpoint=checkpoint)\n",
    "    scheduler_warmup.step()\n",
    "    scheduler.step()\n",
    "    \n",
    "    if (epoch+1)%100 == 0:\n",
    "        teacher_model.load_state_dict(student_model.state_dict())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
