{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import collections\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "\n",
    "from model_pytorch import EfficientNet\n",
    "from utils import Bar,Logger, AverageMeter, accuracy, mkdir_p, savefig\n",
    "from warmup_scheduler import GradualWarmupScheduler\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "import cv2\n",
    "\n",
    "from PIL import ImageFile, ImageOps\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU device 2: True\n"
     ]
    }
   ],
   "source": [
    "# GPU Device\n",
    "gpu_id = 2\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(\"GPU device %d:\" %(gpu_id), use_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = '/media/data2/dataset/GAN_ImageData/PGGAN_128/'\n",
    "target_dir = '/media/data2/dataset/GAN_ImageData/StyleGAN_256/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained = './log/pggan/128/b0/aug/checkpoint.pth.tar'\n",
    "resume = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model_name = 'efficientnet-b0' # b0-b7 scale\n",
    "\n",
    "# Optimization\n",
    "num_classes = 2\n",
    "epochs = 1000\n",
    "start_epoch = 0\n",
    "train_batch = 250\n",
    "test_batch = 250\n",
    "lr = 0.1\n",
    "momentum = 0.1\n",
    "gamma = 0.1 # LR is multiplied by gamma on schedule\n",
    "\n",
    "# CheckPoint\n",
    "checkpoint = './log/pggan/128/b0/to_style1/2000shot/self2' # dir\n",
    "if not os.path.isdir(checkpoint):\n",
    "    os.makedirs(checkpoint)\n",
    "num_workers = 8\n",
    "\n",
    "# Seed\n",
    "manual_seed = 7\n",
    "random.seed(manual_seed)\n",
    "torch.cuda.manual_seed_all(manual_seed)\n",
    "\n",
    "# Image\n",
    "size = (128, 128)\n",
    "\n",
    "# cutmix\n",
    "cm_prob = 0.5\n",
    "cm_beta = 1.0\n",
    "\n",
    "# augmentation\n",
    "blur_prob = 0.5\n",
    "blog_sig = 0.5\n",
    "jpg_prob = 0.5\n",
    "\n",
    "best_acc = 0\n",
    "\n",
    "# sp\n",
    "sp_alpha = 0.1\n",
    "sp_beta = 0.1\n",
    "fc_name = '_fc.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {}\n",
    "state['num_classes'] = num_classes\n",
    "state['epochs'] = epochs\n",
    "state['start_epoch'] = start_epoch\n",
    "state['train_batch'] = train_batch\n",
    "state['test_batch'] = test_batch\n",
    "state['lr'] = lr\n",
    "state['momentum'] = momentum\n",
    "state['gamma'] = gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_augment(img):\n",
    "    img = np.array(img)\n",
    "\n",
    "    if random.random() < blur_prob:\n",
    "        sig = np.random.uniform(0.0, 3.0)\n",
    "        gaussian_blur(img, sig)\n",
    "\n",
    "    if random.random() < jpg_prob:\n",
    "        qual = np.random.uniform(30.0, 100.0)\n",
    "        img = cv2_jpg(img, qual)\n",
    "\n",
    "    return Image.fromarray(img)\n",
    "\n",
    "\n",
    "def gaussian_blur(img, sigma):\n",
    "    gaussian_filter(img[:,:,0], output=img[:,:,0], sigma=sigma)\n",
    "    gaussian_filter(img[:,:,1], output=img[:,:,1], sigma=sigma)\n",
    "    gaussian_filter(img[:,:,2], output=img[:,:,2], sigma=sigma)\n",
    "\n",
    "\n",
    "def cv2_jpg(img, compress_val):\n",
    "    img_cv2 = img[:,:,::-1]\n",
    "    encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), compress_val]\n",
    "    result, encimg = cv2.imencode('.jpg', img_cv2, encode_param)\n",
    "    decimg = cv2.imdecode(encimg, 1)\n",
    "    return decimg[:,:,::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_bbox(size, lam):\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = np.int(W * cut_rat)\n",
    "    cut_h = np.int(H * cut_rat)\n",
    "\n",
    "    # uniform\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join(source_dir, 'style1/2000_shot')\n",
    "val_target_dir = os.path.join(target_dir, 'validation')\n",
    "val_source_dir = os.path.join(source_dir, 'validation')\n",
    "\n",
    "train_aug = transforms.Compose([\n",
    "    transforms.Lambda(lambda img: data_augment(img)),\n",
    "    transforms.Resize(size),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "val_aug = transforms.Compose([\n",
    "    transforms.Resize(size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# pin_memory : cuda pin memeory use\n",
    "train_loader = DataLoader(datasets.ImageFolder(train_dir, transform=train_aug),\n",
    "                          batch_size=train_batch, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "val_target_loader = DataLoader(datasets.ImageFolder(val_target_dir, val_aug),\n",
    "                       batch_size=test_batch, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "val_source_loader = DataLoader(datasets.ImageFolder(val_source_dir, val_aug),\n",
    "                       batch_size=test_batch, shuffle=True, num_workers=num_workers, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> using pre-trained model './log/pggan/128/b0/aug/checkpoint.pth.tar'\n"
     ]
    }
   ],
   "source": [
    "teacher_model = EfficientNet.from_name(model_name, num_classes=num_classes,\n",
    "                              override_params={'dropout_rate':0.2, 'drop_connect_rate':0.2})\n",
    "student_model = EfficientNet.from_name(model_name, num_classes=num_classes,\n",
    "                              override_params={'dropout_rate':0.2, 'drop_connect_rate':0.2})\n",
    "\n",
    "# Pre-trained\n",
    "if pretrained:\n",
    "    print(\"=> using pre-trained model '{}'\".format(pretrained))\n",
    "    teacher_model.load_state_dict(torch.load(pretrained)['state_dict'])\n",
    "    student_model.load_state_dict(torch.load(pretrained)['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Total params: 4.01M\n"
     ]
    }
   ],
   "source": [
    "teacher_model.to('cuda')\n",
    "student_model.to('cuda')\n",
    "cudnn.benchmark = True\n",
    "print('    Total params: %.2fM' % (sum(p.numel() for p in teacher_model.parameters())/1000000.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = optim.SGD(student_model.parameters(), lr=lr, momentum=momentum)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, 200, gamma=0.1, last_epoch=-1)\n",
    "scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)\n",
    "scheduler_warmup = GradualWarmupScheduler(optimizer, multiplier=2, total_epoch=50, after_scheduler=scheduler_cosine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resume\n",
    "if resume:\n",
    "    print('==> Resuming from checkpoint..')\n",
    "    checkpoint = os.path.dirname(resume)\n",
    "    resume = torch.load(resume)\n",
    "    best_acc = resume['best_acc']\n",
    "    start_epoch = resume['epoch']\n",
    "    student_model.load_state_dict(resume['state_dict'])\n",
    "    optimizer.load_state_dict(resume['optimizer'])\n",
    "    logger = Logger(os.path.join(checkpoint, 'log.txt'), resume=True)\n",
    "else:\n",
    "    logger = Logger(os.path.join(checkpoint, 'log.txt'))\n",
    "    logger.set_names(['Learning Rate', 'Train Loss', 'Valid Loss', 'Source Loss', 'Train AUROC', 'Valid AUROC', 'Source AUROC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EfficientNet(\n",
       "  (_conv_stem): Conv2dStaticSamePadding(\n",
       "    3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
       "    (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "  )\n",
       "  (_gn0): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "  (_blocks): ModuleList(\n",
       "    (0): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        32, 32, kernel_size=(3, 3), stride=[1, 1], groups=32, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        32, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        8, 32, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 16, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (1): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 96, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        96, 96, kernel_size=(3, 3), stride=[2, 2], groups=96, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 96, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        96, 4, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        4, 96, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 24, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (2): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 144, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 144, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 24, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (3): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 144, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        144, 144, kernel_size=(5, 5), stride=[2, 2], groups=144, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 144, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 40, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (4): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 240, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        240, 240, kernel_size=(5, 5), stride=(1, 1), groups=240, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 240, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 40, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (5): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 240, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        240, 240, kernel_size=(3, 3), stride=[2, 2], groups=240, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 240, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 80, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (6): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 480, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 480, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 80, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (7): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 480, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 480, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 80, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (8): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 480, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        480, 480, kernel_size=(5, 5), stride=[1, 1], groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 480, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 112, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (9): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 672, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 672, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 112, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (10): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 672, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 672, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 112, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (11): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 672, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5), stride=[2, 2], groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 672, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 192, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (12): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 1152, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 1152, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 192, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (13): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 1152, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 1152, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 192, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (14): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 1152, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 1152, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 192, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (15): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 1152, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(3, 3), stride=[1, 1], groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 1152, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 320, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "  )\n",
       "  (_conv_head): Conv2dStaticSamePadding(\n",
       "    320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "    (static_padding): Identity()\n",
       "  )\n",
       "  (_gn1): GroupNorm(8, 1280, eps=1e-05, affine=True)\n",
       "  (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n",
       "  (_dropout): Dropout(p=0.2, inplace=False)\n",
       "  (_fc): Linear(in_features=1280, out_features=2, bias=True)\n",
       "  (_swish): MemoryEfficientSwish()\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for param in teacher_model.parameters():\n",
    "    param.requires_grad = False\n",
    "teacher_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_model_weights = {}\n",
    "for name, param in teacher_model.named_parameters():\n",
    "    teacher_model_weights[name] = param.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_cls(model):\n",
    "    l2_cls = torch.tensor(0.).cuda()\n",
    "    for name, param in model.named_parameters():\n",
    "        if name.startswith(fc_name):\n",
    "            l2_cls += 0.5 * torch.norm(param) ** 2\n",
    "    return l2_cls\n",
    "\n",
    "def reg_l2sp(model):\n",
    "    sp_loss = torch.tensor(0.).cuda()\n",
    "    for name, param in model.named_parameters():\n",
    "        if not name.startswith(fc_name):\n",
    "            sp_loss += 0.5 * torch.norm(param - teacher_model_weights[name]) ** 2\n",
    "    return sp_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, teacher_model, student_model, criterion, optimizer, epoch, use_cuda):\n",
    "    teacher_model.eval()\n",
    "    student_model.train()\n",
    "    \n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    arc = AverageMeter()\n",
    "    end = time.time()\n",
    "    cls_losses = AverageMeter()\n",
    "    sp_losses = AverageMeter()\n",
    "    main_losses = AverageMeter()\n",
    "    alpha = AverageMeter()\n",
    "    \n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        batch_size = inputs.size(0)\n",
    "        if batch_size < train_batch:\n",
    "            continue\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            \n",
    "        r = np.random.rand(1)\n",
    "        if cm_beta > 0 and r < cm_prob:\n",
    "            \n",
    "            rand_index = torch.randperm(inputs.size()[0]).cuda()\n",
    "            tt= targets[rand_index]\n",
    "            boolean = targets==tt\n",
    "            rand_index = rand_index[boolean]\n",
    "            lam = np.random.beta(cm_beta, cm_beta)\n",
    "            bbx1, bby1, bbx2, bby2 = rand_bbox(inputs.size(), lam)\n",
    "            inputs[boolean, :, bbx1:bbx2, bby1:bby2] = inputs[rand_index, :, bbx1:bbx2, bby1:bby2]\n",
    "\n",
    "        # compute output\n",
    "        with torch.no_grad():\n",
    "            teacher_outputs = teacher_model(inputs)\n",
    "            teacher_loss = criterion(teacher_outputs, targets)\n",
    "            sp_alpha = 0\n",
    "            sigmoid = nn.Sigmoid()\n",
    "            sp_alpha += sigmoid(-teacher_loss)\n",
    "        \n",
    "        outputs = student_model(inputs)\n",
    "        loss_main = criterion(outputs, targets)\n",
    "        loss_cls = 0\n",
    "        loss_sp = 0\n",
    "        loss_cls = reg_cls(student_model)\n",
    "        loss_sp = reg_l2sp(student_model)\n",
    "        loss =  loss_main + 0.1*loss_sp + 0.1*loss_cls\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        losses.update(loss.data.tolist(), inputs.size(0))\n",
    "        cls_losses.update(loss_cls, inputs.size(0))\n",
    "        sp_losses.update(loss_sp, inputs.size(0))\n",
    "        main_losses.update(loss_main.tolist(), inputs.size(0))\n",
    "        alpha.update(sp_alpha, inputs.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        \n",
    "    print('Train | {batch}/{size} | Loss:{loss:.4f} | MainLoss:{main:.4f} | Alpha:{alp:.4f} | SPLoss:{sp:.4f} | CLSLoss:{cls:.4f} | AUROC:{ac:.4f}'.format(\n",
    "                     batch=batch_idx+1, size=len(train_loader), loss=losses.avg, main=main_losses.avg, alp=alpha.avg, sp=sp_losses.avg, cls=cls_losses.avg, ac=arc.avg))\n",
    "    return (losses.avg, arc.avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(val_loader, model, criterion, epoch, use_cuda):\n",
    "    global best_acc\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    arc = AverageMeter()\n",
    "    cls_losses = AverageMeter()\n",
    "    sp_losses = AverageMeter()\n",
    "    main_losses = AverageMeter()\n",
    "\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(val_loader):\n",
    "            # measure data loading time\n",
    "            data_time.update(time.time() - end)\n",
    "\n",
    "            if use_cuda:\n",
    "                inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "            # compute output\n",
    "            outputs = model(inputs)\n",
    "            loss_main = criterion(outputs, targets)\n",
    "            loss_cls = 0\n",
    "            loss_sp = 0\n",
    "            loss_cls = reg_cls(model)\n",
    "            loss_sp = reg_l2sp(model)\n",
    "            loss = loss_main + 0*loss_sp + 0*loss_cls\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            auroc = roc_auc_score(targets.cpu().detach().numpy(), outputs.cpu().detach().numpy()[:,1])\n",
    "            losses.update(loss.data.tolist(), inputs.size(0))\n",
    "            arc.update(auroc, inputs.size(0))\n",
    "            cls_losses.update(loss_cls, inputs.size(0))\n",
    "            sp_losses.update(loss_sp, inputs.size(0))\n",
    "            main_losses.update(loss_main.tolist(), inputs.size(0))\n",
    "\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "    print('Test | {batch}/{size} | Loss:{loss:.4f} | MainLoss:{main:.4f} | SPLoss:{sp:.4f} | CLSLoss:{cls:.4f} | AUROC:{ac:.4f}'.format(\n",
    "                     batch=batch_idx+1, size=len(train_loader), loss=losses.avg, main=main_losses.avg, sp=sp_losses.avg, cls=cls_losses.avg, ac=arc.avg))\n",
    "    return (losses.avg, arc.avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, checkpoint='checkpoint', filename='checkpoint.pth.tar'):\n",
    "    filepath = os.path.join(checkpoint, filename)\n",
    "    torch.save(state, filepath)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filepath, os.path.join(checkpoint, 'model_best.pth.tar'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [1 | 1000] LR: 0.100000\n",
      "Train | 16/16 | Loss:1.1758 | MainLoss:0.8821 | Alpha:0.0289 | SPLoss:1.6089 | CLSLoss:1.3284 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.6928 | MainLoss:0.6928 | SPLoss:1.4642 | CLSLoss:1.0657 | AUROC:0.5669\n",
      "Test | 128/16 | Loss:0.6687 | MainLoss:0.6687 | SPLoss:1.4642 | CLSLoss:1.0657 | AUROC:1.0000\n",
      "\n",
      "Epoch: [2 | 1000] LR: 0.102000\n",
      "Train | 16/16 | Loss:0.9043 | MainLoss:0.6904 | Alpha:0.0267 | SPLoss:1.2344 | CLSLoss:0.9043 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.6912 | MainLoss:0.6912 | SPLoss:0.9999 | CLSLoss:0.7435 | AUROC:0.5679\n",
      "Test | 128/16 | Loss:0.6231 | MainLoss:0.6231 | SPLoss:0.9999 | CLSLoss:0.7435 | AUROC:1.0000\n",
      "\n",
      "Epoch: [3 | 1000] LR: 0.104000\n",
      "Train | 16/16 | Loss:0.8312 | MainLoss:0.6849 | Alpha:0.0265 | SPLoss:0.8308 | CLSLoss:0.6326 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.6883 | MainLoss:0.6883 | SPLoss:0.6601 | CLSLoss:0.5235 | AUROC:0.5722\n",
      "Test | 128/16 | Loss:0.4933 | MainLoss:0.4933 | SPLoss:0.6601 | CLSLoss:0.5235 | AUROC:1.0000\n",
      "\n",
      "Epoch: [4 | 1000] LR: 0.106000\n",
      "Train | 16/16 | Loss:0.7745 | MainLoss:0.6751 | Alpha:0.0265 | SPLoss:0.5449 | CLSLoss:0.4486 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.6845 | MainLoss:0.6845 | SPLoss:0.4315 | CLSLoss:0.3755 | AUROC:0.5832\n",
      "Test | 128/16 | Loss:0.2720 | MainLoss:0.2720 | SPLoss:0.4315 | CLSLoss:0.3755 | AUROC:1.0000\n",
      "\n",
      "Epoch: [5 | 1000] LR: 0.108000\n",
      "Train | 16/16 | Loss:0.7246 | MainLoss:0.6555 | Alpha:0.0262 | SPLoss:0.3687 | CLSLoss:0.3224 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.7040 | MainLoss:0.7040 | SPLoss:0.3058 | CLSLoss:0.2702 | AUROC:0.6148\n",
      "Test | 128/16 | Loss:0.0888 | MainLoss:0.0888 | SPLoss:0.3058 | CLSLoss:0.2702 | AUROC:1.0000\n",
      "\n",
      "Epoch: [6 | 1000] LR: 0.110000\n",
      "Train | 16/16 | Loss:0.6889 | MainLoss:0.6368 | Alpha:0.0263 | SPLoss:0.2896 | CLSLoss:0.2311 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.6536 | MainLoss:0.6536 | SPLoss:0.2854 | CLSLoss:0.1933 | AUROC:0.6607\n",
      "Test | 128/16 | Loss:0.0867 | MainLoss:0.0867 | SPLoss:0.2854 | CLSLoss:0.1933 | AUROC:1.0000\n",
      "\n",
      "Epoch: [7 | 1000] LR: 0.112000\n",
      "Train | 16/16 | Loss:0.6439 | MainLoss:0.5945 | Alpha:0.0264 | SPLoss:0.3197 | CLSLoss:0.1738 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.6141 | MainLoss:0.6141 | SPLoss:0.3723 | CLSLoss:0.1604 | AUROC:0.7281\n",
      "Test | 128/16 | Loss:0.0730 | MainLoss:0.0730 | SPLoss:0.3723 | CLSLoss:0.1604 | AUROC:1.0000\n",
      "\n",
      "Epoch: [8 | 1000] LR: 0.114000\n",
      "Train | 16/16 | Loss:0.6255 | MainLoss:0.5633 | Alpha:0.0272 | SPLoss:0.4820 | CLSLoss:0.1403 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.5446 | MainLoss:0.5446 | SPLoss:0.5883 | CLSLoss:0.1167 | AUROC:0.8073\n",
      "Test | 128/16 | Loss:0.0930 | MainLoss:0.0930 | SPLoss:0.5883 | CLSLoss:0.1167 | AUROC:1.0000\n",
      "\n",
      "Epoch: [9 | 1000] LR: 0.116000\n",
      "Train | 16/16 | Loss:4.7746 | MainLoss:0.5086 | Alpha:0.0260 | SPLoss:42.5406 | CLSLoss:0.1197 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.5077 | MainLoss:0.5077 | SPLoss:175.3057 | CLSLoss:0.1208 | AUROC:0.8323\n",
      "Test | 128/16 | Loss:0.0984 | MainLoss:0.0984 | SPLoss:175.3059 | CLSLoss:0.1208 | AUROC:1.0000\n",
      "\n",
      "Epoch: [10 | 1000] LR: 0.118000\n",
      "Train | 16/16 | Loss:15.0032 | MainLoss:0.4765 | Alpha:0.0276 | SPLoss:145.1441 | CLSLoss:0.1232 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.4779 | MainLoss:0.4779 | SPLoss:115.4557 | CLSLoss:0.0938 | AUROC:0.8950\n",
      "Test | 128/16 | Loss:0.1460 | MainLoss:0.1460 | SPLoss:115.4558 | CLSLoss:0.0938 | AUROC:0.9998\n",
      "\n",
      "Epoch: [11 | 1000] LR: 0.120000\n",
      "Train | 16/16 | Loss:9.9622 | MainLoss:0.4115 | Alpha:0.0261 | SPLoss:95.3757 | CLSLoss:0.1310 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.3656 | MainLoss:0.3656 | SPLoss:75.7111 | CLSLoss:0.1489 | AUROC:0.9198\n",
      "Test | 128/16 | Loss:0.1342 | MainLoss:0.1342 | SPLoss:75.7111 | CLSLoss:0.1489 | AUROC:0.9993\n",
      "\n",
      "Epoch: [12 | 1000] LR: 0.122000\n",
      "Train | 16/16 | Loss:6.6149 | MainLoss:0.3381 | Alpha:0.0254 | SPLoss:62.6086 | CLSLoss:0.1587 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.3317 | MainLoss:0.3317 | SPLoss:50.0284 | CLSLoss:0.1639 | AUROC:0.9346\n",
      "Test | 128/16 | Loss:0.1220 | MainLoss:0.1220 | SPLoss:50.0285 | CLSLoss:0.1639 | AUROC:0.9997\n",
      "\n",
      "Epoch: [13 | 1000] LR: 0.124000\n",
      "Train | 16/16 | Loss:4.5254 | MainLoss:0.3492 | Alpha:0.0269 | SPLoss:41.6092 | CLSLoss:0.1523 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.4641 | MainLoss:0.4641 | SPLoss:33.0593 | CLSLoss:0.1647 | AUROC:0.9344\n",
      "Test | 128/16 | Loss:0.3865 | MainLoss:0.3865 | SPLoss:33.0593 | CLSLoss:0.1647 | AUROC:0.9977\n",
      "\n",
      "Epoch: [14 | 1000] LR: 0.126000\n",
      "Train | 16/16 | Loss:3.0919 | MainLoss:0.3304 | Alpha:0.0287 | SPLoss:27.4533 | CLSLoss:0.1615 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.3074 | MainLoss:0.3074 | SPLoss:21.9127 | CLSLoss:0.1690 | AUROC:0.9519\n",
      "Test | 128/16 | Loss:0.1673 | MainLoss:0.1673 | SPLoss:21.9127 | CLSLoss:0.1690 | AUROC:0.9964\n",
      "\n",
      "Epoch: [15 | 1000] LR: 0.128000\n",
      "Train | 16/16 | Loss:2.1563 | MainLoss:0.3094 | Alpha:0.0266 | SPLoss:18.3015 | CLSLoss:0.1677 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2679 | MainLoss:0.2679 | SPLoss:14.6878 | CLSLoss:0.1675 | AUROC:0.9608\n",
      "Test | 128/16 | Loss:0.2402 | MainLoss:0.2402 | SPLoss:14.6878 | CLSLoss:0.1675 | AUROC:0.9973\n",
      "\n",
      "Epoch: [16 | 1000] LR: 0.130000\n",
      "Train | 16/16 | Loss:1.5160 | MainLoss:0.2665 | Alpha:0.0260 | SPLoss:12.3147 | CLSLoss:0.1805 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2605 | MainLoss:0.2605 | SPLoss:9.9772 | CLSLoss:0.1820 | AUROC:0.9609\n",
      "Test | 128/16 | Loss:0.1915 | MainLoss:0.1915 | SPLoss:9.9772 | CLSLoss:0.1820 | AUROC:0.9981\n",
      "\n",
      "Epoch: [17 | 1000] LR: 0.132000\n",
      "Train | 16/16 | Loss:1.4109 | MainLoss:0.2874 | Alpha:0.0274 | SPLoss:11.0552 | CLSLoss:0.1794 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2676 | MainLoss:0.2676 | SPLoss:14.2563 | CLSLoss:0.1683 | AUROC:0.9587\n",
      "Test | 128/16 | Loss:0.2838 | MainLoss:0.2838 | SPLoss:14.2563 | CLSLoss:0.1683 | AUROC:0.9949\n",
      "\n",
      "Epoch: [18 | 1000] LR: 0.134000\n",
      "Train | 16/16 | Loss:1.5076 | MainLoss:0.2932 | Alpha:0.0276 | SPLoss:11.9711 | CLSLoss:0.1730 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2558 | MainLoss:0.2558 | SPLoss:9.7549 | CLSLoss:0.1711 | AUROC:0.9626\n",
      "Test | 128/16 | Loss:0.3297 | MainLoss:0.3297 | SPLoss:9.7549 | CLSLoss:0.1711 | AUROC:0.9910\n",
      "\n",
      "Epoch: [19 | 1000] LR: 0.136000\n",
      "Train | 16/16 | Loss:1.3871 | MainLoss:0.3285 | Alpha:0.0269 | SPLoss:10.4206 | CLSLoss:0.1654 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2967 | MainLoss:0.2967 | SPLoss:10.5407 | CLSLoss:0.1617 | AUROC:0.9544\n",
      "Test | 128/16 | Loss:0.2807 | MainLoss:0.2807 | SPLoss:10.5407 | CLSLoss:0.1617 | AUROC:0.9785\n",
      "\n",
      "Epoch: [20 | 1000] LR: 0.138000\n",
      "Train | 16/16 | Loss:16.5064 | MainLoss:0.2964 | Alpha:0.0266 | SPLoss:161.9343 | CLSLoss:0.1653 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2936 | MainLoss:0.2936 | SPLoss:218.3099 | CLSLoss:0.1799 | AUROC:0.9584\n",
      "Test | 128/16 | Loss:0.5337 | MainLoss:0.5337 | SPLoss:218.3100 | CLSLoss:0.1799 | AUROC:0.9737\n",
      "\n",
      "Epoch: [21 | 1000] LR: 0.140000\n",
      "Train | 16/16 | Loss:17.7736 | MainLoss:0.2425 | Alpha:0.0268 | SPLoss:175.1243 | CLSLoss:0.1863 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2795 | MainLoss:0.2795 | SPLoss:133.7362 | CLSLoss:0.1868 | AUROC:0.9683\n",
      "Test | 128/16 | Loss:0.2850 | MainLoss:0.2850 | SPLoss:133.7360 | CLSLoss:0.1868 | AUROC:0.9762\n",
      "\n",
      "Epoch: [22 | 1000] LR: 0.142000\n",
      "Train | 16/16 | Loss:11.2001 | MainLoss:0.3286 | Alpha:0.0260 | SPLoss:108.5505 | CLSLoss:0.1642 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2490 | MainLoss:0.2490 | SPLoss:82.9533 | CLSLoss:0.1797 | AUROC:0.9654\n",
      "Test | 128/16 | Loss:0.2737 | MainLoss:0.2737 | SPLoss:82.9533 | CLSLoss:0.1797 | AUROC:0.9962\n",
      "\n",
      "Epoch: [23 | 1000] LR: 0.144000\n",
      "Train | 16/16 | Loss:6.9596 | MainLoss:0.2851 | Alpha:0.0264 | SPLoss:66.5656 | CLSLoss:0.1794 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2942 | MainLoss:0.2942 | SPLoss:50.7651 | CLSLoss:0.1392 | AUROC:0.9681\n",
      "Test | 128/16 | Loss:0.4543 | MainLoss:0.4543 | SPLoss:50.7651 | CLSLoss:0.1392 | AUROC:0.9841\n",
      "\n",
      "Epoch: [24 | 1000] LR: 0.146000\n",
      "Train | 16/16 | Loss:4.3917 | MainLoss:0.2345 | Alpha:0.0295 | SPLoss:41.3922 | CLSLoss:0.1797 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2794 | MainLoss:0.2794 | SPLoss:32.6035 | CLSLoss:0.1822 | AUROC:0.9686\n",
      "Test | 128/16 | Loss:0.2069 | MainLoss:0.2069 | SPLoss:32.6035 | CLSLoss:0.1822 | AUROC:0.9948\n",
      "\n",
      "Epoch: [25 | 1000] LR: 0.148000\n",
      "Train | 16/16 | Loss:2.8935 | MainLoss:0.2504 | Alpha:0.0251 | SPLoss:26.2507 | CLSLoss:0.1798 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2540 | MainLoss:0.2540 | SPLoss:20.2140 | CLSLoss:0.1815 | AUROC:0.9680\n",
      "Test | 128/16 | Loss:0.2426 | MainLoss:0.2426 | SPLoss:20.2140 | CLSLoss:0.1815 | AUROC:0.9900\n",
      "\n",
      "Epoch: [26 | 1000] LR: 0.150000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 16/16 | Loss:2.0707 | MainLoss:0.2470 | Alpha:0.0257 | SPLoss:18.0584 | CLSLoss:0.1793 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.3145 | MainLoss:0.3145 | SPLoss:15.7135 | CLSLoss:0.1745 | AUROC:0.9729\n",
      "Test | 128/16 | Loss:0.1847 | MainLoss:0.1847 | SPLoss:15.7135 | CLSLoss:0.1745 | AUROC:0.9908\n",
      "\n",
      "Epoch: [27 | 1000] LR: 0.152000\n",
      "Train | 16/16 | Loss:1.6022 | MainLoss:0.2423 | Alpha:0.0269 | SPLoss:13.4198 | CLSLoss:0.1790 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2239 | MainLoss:0.2239 | SPLoss:11.2518 | CLSLoss:0.1849 | AUROC:0.9745\n",
      "Test | 128/16 | Loss:0.2480 | MainLoss:0.2480 | SPLoss:11.2518 | CLSLoss:0.1849 | AUROC:0.9950\n",
      "\n",
      "Epoch: [28 | 1000] LR: 0.154000\n",
      "Train | 16/16 | Loss:3.5135 | MainLoss:0.2782 | Alpha:0.0264 | SPLoss:32.1737 | CLSLoss:0.1798 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2971 | MainLoss:0.2971 | SPLoss:58.7613 | CLSLoss:0.1352 | AUROC:0.9578\n",
      "Test | 128/16 | Loss:0.5158 | MainLoss:0.5158 | SPLoss:58.7614 | CLSLoss:0.1352 | AUROC:0.9849\n",
      "\n",
      "Epoch: [29 | 1000] LR: 0.156000\n",
      "Train | 16/16 | Loss:4.9547 | MainLoss:0.2784 | Alpha:0.0263 | SPLoss:46.6022 | CLSLoss:0.1609 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2884 | MainLoss:0.2884 | SPLoss:35.5677 | CLSLoss:0.1844 | AUROC:0.9631\n",
      "Test | 128/16 | Loss:0.7239 | MainLoss:0.7239 | SPLoss:35.5677 | CLSLoss:0.1844 | AUROC:0.9806\n",
      "\n",
      "Epoch: [30 | 1000] LR: 0.158000\n",
      "Train | 16/16 | Loss:4.6733 | MainLoss:0.2769 | Alpha:0.0266 | SPLoss:43.7922 | CLSLoss:0.1712 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2479 | MainLoss:0.2479 | SPLoss:82.3892 | CLSLoss:0.1733 | AUROC:0.9664\n",
      "Test | 128/16 | Loss:0.4370 | MainLoss:0.4370 | SPLoss:82.3891 | CLSLoss:0.1733 | AUROC:0.9830\n",
      "\n",
      "Epoch: [31 | 1000] LR: 0.160000\n",
      "Train | 16/16 | Loss:6.7482 | MainLoss:0.2910 | Alpha:0.0267 | SPLoss:64.4101 | CLSLoss:0.1619 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.3462 | MainLoss:0.3462 | SPLoss:47.6918 | CLSLoss:0.1466 | AUROC:0.9593\n",
      "Test | 128/16 | Loss:0.6974 | MainLoss:0.6974 | SPLoss:47.6919 | CLSLoss:0.1466 | AUROC:0.9837\n",
      "\n",
      "Epoch: [32 | 1000] LR: 0.162000\n",
      "Train | 16/16 | Loss:4.0391 | MainLoss:0.2813 | Alpha:0.0262 | SPLoss:37.4115 | CLSLoss:0.1664 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.3727 | MainLoss:0.3727 | SPLoss:28.1486 | CLSLoss:0.1334 | AUROC:0.9718\n",
      "Test | 128/16 | Loss:0.3407 | MainLoss:0.3407 | SPLoss:28.1486 | CLSLoss:0.1334 | AUROC:0.9822\n",
      "\n",
      "Epoch: [33 | 1000] LR: 0.164000\n",
      "Train | 16/16 | Loss:3.1608 | MainLoss:0.2812 | Alpha:0.0263 | SPLoss:28.6316 | CLSLoss:0.1643 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2428 | MainLoss:0.2428 | SPLoss:43.7406 | CLSLoss:0.1609 | AUROC:0.9693\n",
      "Test | 128/16 | Loss:0.6085 | MainLoss:0.6085 | SPLoss:43.7405 | CLSLoss:0.1609 | AUROC:0.8881\n",
      "\n",
      "Epoch: [34 | 1000] LR: 0.166000\n",
      "Train | 16/16 | Loss:4.2413 | MainLoss:0.2614 | Alpha:0.0274 | SPLoss:39.6259 | CLSLoss:0.1731 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2184 | MainLoss:0.2184 | SPLoss:36.1296 | CLSLoss:0.1858 | AUROC:0.9738\n",
      "Test | 128/16 | Loss:0.5094 | MainLoss:0.5094 | SPLoss:36.1296 | CLSLoss:0.1858 | AUROC:0.9606\n",
      "\n",
      "Epoch: [35 | 1000] LR: 0.168000\n",
      "Train | 16/16 | Loss:3.2712 | MainLoss:0.2508 | Alpha:0.0265 | SPLoss:30.0266 | CLSLoss:0.1782 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2138 | MainLoss:0.2138 | SPLoss:22.9995 | CLSLoss:0.1874 | AUROC:0.9730\n",
      "Test | 128/16 | Loss:0.4423 | MainLoss:0.4423 | SPLoss:22.9995 | CLSLoss:0.1874 | AUROC:0.9837\n",
      "\n",
      "Epoch: [36 | 1000] LR: 0.170000\n",
      "Train | 16/16 | Loss:3.3256 | MainLoss:0.3020 | Alpha:0.0270 | SPLoss:30.0691 | CLSLoss:0.1668 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2517 | MainLoss:0.2517 | SPLoss:27.1270 | CLSLoss:0.1895 | AUROC:0.9658\n",
      "Test | 128/16 | Loss:0.5112 | MainLoss:0.5112 | SPLoss:27.1270 | CLSLoss:0.1895 | AUROC:0.9755\n",
      "\n",
      "Epoch: [37 | 1000] LR: 0.172000\n",
      "Train | 16/16 | Loss:14.9598 | MainLoss:0.3414 | Alpha:0.0287 | SPLoss:146.0248 | CLSLoss:0.1597 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2506 | MainLoss:0.2506 | SPLoss:126.4135 | CLSLoss:0.1495 | AUROC:0.9681\n",
      "Test | 128/16 | Loss:0.6024 | MainLoss:0.6024 | SPLoss:126.4137 | CLSLoss:0.1495 | AUROC:0.9614\n",
      "\n",
      "Epoch: [38 | 1000] LR: 0.174000\n",
      "Train | 16/16 | Loss:15.2338 | MainLoss:0.3790 | Alpha:0.0275 | SPLoss:148.4036 | CLSLoss:0.1439 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2538 | MainLoss:0.2538 | SPLoss:171.5888 | CLSLoss:0.1709 | AUROC:0.9650\n",
      "Test | 128/16 | Loss:0.6008 | MainLoss:0.6008 | SPLoss:171.5887 | CLSLoss:0.1709 | AUROC:0.9318\n",
      "\n",
      "Epoch: [39 | 1000] LR: 0.176000\n",
      "Train | 16/16 | Loss:13.3264 | MainLoss:0.2945 | Alpha:0.0268 | SPLoss:130.1388 | CLSLoss:0.1803 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2234 | MainLoss:0.2234 | SPLoss:92.1167 | CLSLoss:0.1806 | AUROC:0.9743\n",
      "Test | 128/16 | Loss:0.6038 | MainLoss:0.6038 | SPLoss:92.1167 | CLSLoss:0.1806 | AUROC:0.9085\n",
      "\n",
      "Epoch: [40 | 1000] LR: 0.178000\n",
      "Train | 16/16 | Loss:7.2916 | MainLoss:0.2729 | Alpha:0.0268 | SPLoss:70.0104 | CLSLoss:0.1762 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2108 | MainLoss:0.2108 | SPLoss:49.6551 | CLSLoss:0.1930 | AUROC:0.9749\n",
      "Test | 128/16 | Loss:0.6531 | MainLoss:0.6531 | SPLoss:49.6550 | CLSLoss:0.1930 | AUROC:0.9344\n",
      "\n",
      "Epoch: [41 | 1000] LR: 0.180000\n",
      "Train | 16/16 | Loss:5.5542 | MainLoss:0.3233 | Alpha:0.0269 | SPLoss:52.1394 | CLSLoss:0.1694 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.3398 | MainLoss:0.3398 | SPLoss:44.6961 | CLSLoss:0.1565 | AUROC:0.9722\n",
      "Test | 128/16 | Loss:0.4898 | MainLoss:0.4898 | SPLoss:44.6960 | CLSLoss:0.1565 | AUROC:0.8745\n",
      "\n",
      "Epoch: [42 | 1000] LR: 0.182000\n",
      "Train | 16/16 | Loss:3.7315 | MainLoss:0.2915 | Alpha:0.0248 | SPLoss:34.2366 | CLSLoss:0.1635 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2330 | MainLoss:0.2330 | SPLoss:24.4100 | CLSLoss:0.1756 | AUROC:0.9741\n",
      "Test | 128/16 | Loss:0.6220 | MainLoss:0.6220 | SPLoss:24.4100 | CLSLoss:0.1756 | AUROC:0.9208\n",
      "\n",
      "Epoch: [43 | 1000] LR: 0.184000\n",
      "Train | 16/16 | Loss:2.2009 | MainLoss:0.2770 | Alpha:0.0251 | SPLoss:19.0690 | CLSLoss:0.1700 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2393 | MainLoss:0.2393 | SPLoss:14.0760 | CLSLoss:0.1587 | AUROC:0.9739\n",
      "Test | 128/16 | Loss:0.6778 | MainLoss:0.6778 | SPLoss:14.0760 | CLSLoss:0.1587 | AUROC:0.9614\n",
      "\n",
      "Epoch: [44 | 1000] LR: 0.186000\n",
      "Train | 16/16 | Loss:2.8563 | MainLoss:0.2772 | Alpha:0.0265 | SPLoss:25.6209 | CLSLoss:0.1703 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2503 | MainLoss:0.2503 | SPLoss:22.0946 | CLSLoss:0.1544 | AUROC:0.9695\n",
      "Test | 128/16 | Loss:0.8128 | MainLoss:0.8128 | SPLoss:22.0946 | CLSLoss:0.1544 | AUROC:0.9068\n",
      "\n",
      "Epoch: [45 | 1000] LR: 0.188000\n",
      "Train | 16/16 | Loss:1.9962 | MainLoss:0.2678 | Alpha:0.0250 | SPLoss:17.1108 | CLSLoss:0.1726 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2465 | MainLoss:0.2465 | SPLoss:12.6409 | CLSLoss:0.1760 | AUROC:0.9707\n",
      "Test | 128/16 | Loss:0.5762 | MainLoss:0.5762 | SPLoss:12.6409 | CLSLoss:0.1760 | AUROC:0.9221\n",
      "\n",
      "Epoch: [46 | 1000] LR: 0.190000\n",
      "Train | 16/16 | Loss:1.3653 | MainLoss:0.2474 | Alpha:0.0265 | SPLoss:11.0053 | CLSLoss:0.1739 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2392 | MainLoss:0.2392 | SPLoss:12.7160 | CLSLoss:0.1817 | AUROC:0.9666\n",
      "Test | 128/16 | Loss:0.5790 | MainLoss:0.5790 | SPLoss:12.7160 | CLSLoss:0.1817 | AUROC:0.9529\n",
      "\n",
      "Epoch: [47 | 1000] LR: 0.192000\n",
      "Train | 16/16 | Loss:1.5061 | MainLoss:0.3012 | Alpha:0.0278 | SPLoss:11.8889 | CLSLoss:0.1601 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2663 | MainLoss:0.2663 | SPLoss:9.1324 | CLSLoss:0.1556 | AUROC:0.9731\n",
      "Test | 128/16 | Loss:0.4242 | MainLoss:0.4242 | SPLoss:9.1324 | CLSLoss:0.1556 | AUROC:0.9580\n",
      "\n",
      "Epoch: [48 | 1000] LR: 0.194000\n",
      "Train | 16/16 | Loss:2.4294 | MainLoss:0.2928 | Alpha:0.0260 | SPLoss:21.1994 | CLSLoss:0.1659 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.3432 | MainLoss:0.3432 | SPLoss:36.0033 | CLSLoss:0.1735 | AUROC:0.9707\n",
      "Test | 128/16 | Loss:0.4361 | MainLoss:0.4361 | SPLoss:36.0033 | CLSLoss:0.1735 | AUROC:0.9157\n",
      "\n",
      "Epoch: [49 | 1000] LR: 0.196000\n",
      "Train | 16/16 | Loss:9.0360 | MainLoss:0.2923 | Alpha:0.0280 | SPLoss:87.2743 | CLSLoss:0.1629 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2213 | MainLoss:0.2213 | SPLoss:90.2013 | CLSLoss:0.1692 | AUROC:0.9714\n",
      "Test | 128/16 | Loss:0.5791 | MainLoss:0.5791 | SPLoss:90.2013 | CLSLoss:0.1692 | AUROC:0.9582\n",
      "\n",
      "Epoch: [50 | 1000] LR: 0.198000\n",
      "Train | 16/16 | Loss:7.5726 | MainLoss:0.3506 | Alpha:0.0263 | SPLoss:72.0580 | CLSLoss:0.1622 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2309 | MainLoss:0.2309 | SPLoss:72.4994 | CLSLoss:0.2098 | AUROC:0.9691\n",
      "Test | 128/16 | Loss:0.5757 | MainLoss:0.5757 | SPLoss:72.4994 | CLSLoss:0.2098 | AUROC:0.9353\n",
      "\n",
      "Epoch: [51 | 1000] LR: 0.200000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 16/16 | Loss:7.7671 | MainLoss:0.3578 | Alpha:0.0293 | SPLoss:73.9192 | CLSLoss:0.1732 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2960 | MainLoss:0.2960 | SPLoss:54.0839 | CLSLoss:0.1700 | AUROC:0.9622\n",
      "Test | 128/16 | Loss:0.4655 | MainLoss:0.4655 | SPLoss:54.0840 | CLSLoss:0.1700 | AUROC:0.9224\n",
      "\n",
      "Epoch: [52 | 1000] LR: 0.200000\n",
      "Train | 16/16 | Loss:5.9670 | MainLoss:0.3535 | Alpha:0.0286 | SPLoss:55.9825 | CLSLoss:0.1526 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2935 | MainLoss:0.2935 | SPLoss:56.3392 | CLSLoss:0.1525 | AUROC:0.9604\n",
      "Test | 128/16 | Loss:0.5577 | MainLoss:0.5577 | SPLoss:56.3391 | CLSLoss:0.1525 | AUROC:0.8879\n",
      "\n",
      "Epoch: [53 | 1000] LR: 0.200000\n",
      "Train | 16/16 | Loss:4.5900 | MainLoss:0.3059 | Alpha:0.0268 | SPLoss:42.6734 | CLSLoss:0.1684 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2503 | MainLoss:0.2503 | SPLoss:31.2286 | CLSLoss:0.1404 | AUROC:0.9740\n",
      "Test | 128/16 | Loss:0.6380 | MainLoss:0.6380 | SPLoss:31.2287 | CLSLoss:0.1404 | AUROC:0.8561\n",
      "\n",
      "Epoch: [54 | 1000] LR: 0.199998\n",
      "Train | 16/16 | Loss:3.2505 | MainLoss:0.2894 | Alpha:0.0274 | SPLoss:29.4491 | CLSLoss:0.1628 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.3546 | MainLoss:0.3546 | SPLoss:91.1084 | CLSLoss:0.1317 | AUROC:0.9410\n",
      "Test | 128/16 | Loss:0.5367 | MainLoss:0.5367 | SPLoss:91.1083 | CLSLoss:0.1317 | AUROC:0.9556\n",
      "\n",
      "Epoch: [55 | 1000] LR: 0.199996\n",
      "Train | 16/16 | Loss:13.7959 | MainLoss:0.3529 | Alpha:0.0266 | SPLoss:134.2873 | CLSLoss:0.1425 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.3831 | MainLoss:0.3831 | SPLoss:96.1413 | CLSLoss:0.1113 | AUROC:0.9674\n",
      "Test | 128/16 | Loss:0.4913 | MainLoss:0.4913 | SPLoss:96.1413 | CLSLoss:0.1113 | AUROC:0.8942\n",
      "\n",
      "Epoch: [56 | 1000] LR: 0.199992\n",
      "Train | 16/16 | Loss:7.5228 | MainLoss:0.2948 | Alpha:0.0264 | SPLoss:72.1103 | CLSLoss:0.1698 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2649 | MainLoss:0.2649 | SPLoss:53.4199 | CLSLoss:0.1641 | AUROC:0.9625\n",
      "Test | 128/16 | Loss:0.6348 | MainLoss:0.6348 | SPLoss:53.4200 | CLSLoss:0.1641 | AUROC:0.9431\n",
      "\n",
      "Epoch: [57 | 1000] LR: 0.199988\n",
      "Train | 16/16 | Loss:4.2946 | MainLoss:0.2893 | Alpha:0.0263 | SPLoss:39.8865 | CLSLoss:0.1665 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2198 | MainLoss:0.2198 | SPLoss:27.7596 | CLSLoss:0.1603 | AUROC:0.9746\n",
      "Test | 128/16 | Loss:0.5353 | MainLoss:0.5353 | SPLoss:27.7597 | CLSLoss:0.1603 | AUROC:0.9618\n",
      "\n",
      "Epoch: [58 | 1000] LR: 0.199982\n",
      "Train | 16/16 | Loss:4.0784 | MainLoss:0.2505 | Alpha:0.0267 | SPLoss:38.1041 | CLSLoss:0.1750 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2628 | MainLoss:0.2628 | SPLoss:47.6396 | CLSLoss:0.1765 | AUROC:0.9734\n",
      "Test | 128/16 | Loss:0.4728 | MainLoss:0.4728 | SPLoss:47.6396 | CLSLoss:0.1765 | AUROC:0.9384\n",
      "\n",
      "Epoch: [59 | 1000] LR: 0.199976\n",
      "Train | 16/16 | Loss:3.8951 | MainLoss:0.2709 | Alpha:0.0268 | SPLoss:36.0728 | CLSLoss:0.1694 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2690 | MainLoss:0.2690 | SPLoss:26.3506 | CLSLoss:0.1863 | AUROC:0.9735\n",
      "Test | 128/16 | Loss:0.4560 | MainLoss:0.4560 | SPLoss:26.3506 | CLSLoss:0.1863 | AUROC:0.9405\n",
      "\n",
      "Epoch: [60 | 1000] LR: 0.199968\n",
      "Train | 16/16 | Loss:2.3030 | MainLoss:0.2686 | Alpha:0.0268 | SPLoss:20.1651 | CLSLoss:0.1790 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.3200 | MainLoss:0.3200 | SPLoss:14.8181 | CLSLoss:0.1042 | AUROC:0.9739\n",
      "Test | 128/16 | Loss:0.5188 | MainLoss:0.5188 | SPLoss:14.8181 | CLSLoss:0.1042 | AUROC:0.9103\n",
      "\n",
      "Epoch: [61 | 1000] LR: 0.199960\n",
      "Train | 16/16 | Loss:1.4237 | MainLoss:0.2674 | Alpha:0.0277 | SPLoss:11.3984 | CLSLoss:0.1646 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.3963 | MainLoss:0.3963 | SPLoss:13.5650 | CLSLoss:0.1645 | AUROC:0.9697\n",
      "Test | 128/16 | Loss:0.2657 | MainLoss:0.2657 | SPLoss:13.5650 | CLSLoss:0.1645 | AUROC:0.9764\n",
      "\n",
      "Epoch: [62 | 1000] LR: 0.199951\n",
      "Train | 16/16 | Loss:1.4895 | MainLoss:0.3271 | Alpha:0.0300 | SPLoss:11.4698 | CLSLoss:0.1536 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2233 | MainLoss:0.2233 | SPLoss:8.5211 | CLSLoss:0.1454 | AUROC:0.9738\n",
      "Test | 128/16 | Loss:0.6843 | MainLoss:0.6843 | SPLoss:8.5211 | CLSLoss:0.1454 | AUROC:0.9198\n",
      "\n",
      "Epoch: [63 | 1000] LR: 0.199940\n",
      "Train | 16/16 | Loss:12.5550 | MainLoss:0.3096 | Alpha:0.0262 | SPLoss:122.2994 | CLSLoss:0.1541 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2457 | MainLoss:0.2457 | SPLoss:179.1035 | CLSLoss:0.1889 | AUROC:0.9673\n",
      "Test | 128/16 | Loss:0.5838 | MainLoss:0.5838 | SPLoss:179.1038 | CLSLoss:0.1889 | AUROC:0.9470\n",
      "\n",
      "Epoch: [64 | 1000] LR: 0.199929\n",
      "Train | 16/16 | Loss:13.4605 | MainLoss:0.2441 | Alpha:0.0272 | SPLoss:131.9704 | CLSLoss:0.1931 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.3802 | MainLoss:0.3802 | SPLoss:89.6419 | CLSLoss:0.1715 | AUROC:0.9543\n",
      "Test | 128/16 | Loss:0.9142 | MainLoss:0.9142 | SPLoss:89.6420 | CLSLoss:0.1715 | AUROC:0.9323\n",
      "\n",
      "Epoch: [65 | 1000] LR: 0.199917\n",
      "Train | 16/16 | Loss:12.0311 | MainLoss:0.3347 | Alpha:0.0255 | SPLoss:116.8025 | CLSLoss:0.1619 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2912 | MainLoss:0.2912 | SPLoss:92.3827 | CLSLoss:0.1327 | AUROC:0.9651\n",
      "Test | 128/16 | Loss:0.5689 | MainLoss:0.5689 | SPLoss:92.3829 | CLSLoss:0.1327 | AUROC:0.8981\n",
      "\n",
      "Epoch: [66 | 1000] LR: 0.199903\n",
      "Train | 16/16 | Loss:9.1156 | MainLoss:0.3252 | Alpha:0.0284 | SPLoss:87.7560 | CLSLoss:0.1481 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2442 | MainLoss:0.2442 | SPLoss:85.6976 | CLSLoss:0.1385 | AUROC:0.9694\n",
      "Test | 128/16 | Loss:0.6918 | MainLoss:0.6918 | SPLoss:85.6976 | CLSLoss:0.1385 | AUROC:0.8908\n",
      "\n",
      "Epoch: [67 | 1000] LR: 0.199889\n",
      "Train | 16/16 | Loss:7.5090 | MainLoss:0.2783 | Alpha:0.0272 | SPLoss:72.1440 | CLSLoss:0.1630 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2393 | MainLoss:0.2393 | SPLoss:51.9154 | CLSLoss:0.1670 | AUROC:0.9689\n",
      "Test | 128/16 | Loss:0.6663 | MainLoss:0.6663 | SPLoss:51.9155 | CLSLoss:0.1670 | AUROC:0.9359\n",
      "\n",
      "Epoch: [68 | 1000] LR: 0.199874\n",
      "Train | 16/16 | Loss:4.9969 | MainLoss:0.3088 | Alpha:0.0260 | SPLoss:46.7216 | CLSLoss:0.1595 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2775 | MainLoss:0.2775 | SPLoss:36.8191 | CLSLoss:0.1401 | AUROC:0.9622\n",
      "Test | 128/16 | Loss:0.5077 | MainLoss:0.5077 | SPLoss:36.8190 | CLSLoss:0.1401 | AUROC:0.9422\n",
      "\n",
      "Epoch: [69 | 1000] LR: 0.199857\n",
      "Train | 16/16 | Loss:5.0423 | MainLoss:0.2893 | Alpha:0.0273 | SPLoss:47.3712 | CLSLoss:0.1589 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2529 | MainLoss:0.2529 | SPLoss:43.5816 | CLSLoss:0.1695 | AUROC:0.9667\n",
      "Test | 128/16 | Loss:0.8388 | MainLoss:0.8388 | SPLoss:43.5816 | CLSLoss:0.1695 | AUROC:0.9429\n",
      "\n",
      "Epoch: [70 | 1000] LR: 0.199840\n",
      "Train | 16/16 | Loss:6.1995 | MainLoss:0.3013 | Alpha:0.0268 | SPLoss:58.8162 | CLSLoss:0.1657 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2578 | MainLoss:0.2578 | SPLoss:53.4370 | CLSLoss:0.1604 | AUROC:0.9639\n",
      "Test | 128/16 | Loss:0.6548 | MainLoss:0.6548 | SPLoss:53.4370 | CLSLoss:0.1604 | AUROC:0.9334\n",
      "\n",
      "Epoch: [71 | 1000] LR: 0.199822\n",
      "Train | 16/16 | Loss:4.4381 | MainLoss:0.3070 | Alpha:0.0274 | SPLoss:41.1452 | CLSLoss:0.1657 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2377 | MainLoss:0.2377 | SPLoss:28.7008 | CLSLoss:0.1489 | AUROC:0.9690\n",
      "Test | 128/16 | Loss:0.6935 | MainLoss:0.6935 | SPLoss:28.7008 | CLSLoss:0.1489 | AUROC:0.9053\n",
      "\n",
      "Epoch: [72 | 1000] LR: 0.199803\n",
      "Train | 16/16 | Loss:3.2372 | MainLoss:0.2933 | Alpha:0.0278 | SPLoss:29.2824 | CLSLoss:0.1571 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.3218 | MainLoss:0.3218 | SPLoss:28.1371 | CLSLoss:0.1513 | AUROC:0.9646\n",
      "Test | 128/16 | Loss:0.4112 | MainLoss:0.4112 | SPLoss:28.1371 | CLSLoss:0.1513 | AUROC:0.9425\n",
      "\n",
      "Epoch: [73 | 1000] LR: 0.199782\n",
      "Train | 16/16 | Loss:7.8319 | MainLoss:0.3272 | Alpha:0.0268 | SPLoss:74.8945 | CLSLoss:0.1521 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.5349 | MainLoss:0.5349 | SPLoss:59.3310 | CLSLoss:0.1331 | AUROC:0.9677\n",
      "Test | 128/16 | Loss:0.2941 | MainLoss:0.2941 | SPLoss:59.3310 | CLSLoss:0.1331 | AUROC:0.9613\n",
      "\n",
      "Epoch: [74 | 1000] LR: 0.199761\n",
      "Train | 16/16 | Loss:4.7820 | MainLoss:0.2942 | Alpha:0.0268 | SPLoss:44.7182 | CLSLoss:0.1607 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2308 | MainLoss:0.2308 | SPLoss:34.5055 | CLSLoss:0.1821 | AUROC:0.9698\n",
      "Test | 128/16 | Loss:0.6278 | MainLoss:0.6278 | SPLoss:34.5055 | CLSLoss:0.1821 | AUROC:0.9525\n",
      "\n",
      "Epoch: [75 | 1000] LR: 0.199739\n",
      "Train | 16/16 | Loss:3.4807 | MainLoss:0.2770 | Alpha:0.0268 | SPLoss:31.8652 | CLSLoss:0.1716 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2442 | MainLoss:0.2442 | SPLoss:25.5371 | CLSLoss:0.1771 | AUROC:0.9690\n",
      "Test | 128/16 | Loss:0.5437 | MainLoss:0.5437 | SPLoss:25.5371 | CLSLoss:0.1771 | AUROC:0.9621\n",
      "\n",
      "Epoch: [76 | 1000] LR: 0.199716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 16/16 | Loss:2.2021 | MainLoss:0.2675 | Alpha:0.0262 | SPLoss:19.1717 | CLSLoss:0.1749 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.3285 | MainLoss:0.3285 | SPLoss:13.5812 | CLSLoss:0.1544 | AUROC:0.9662\n",
      "Test | 128/16 | Loss:0.3981 | MainLoss:0.3981 | SPLoss:13.5812 | CLSLoss:0.1544 | AUROC:0.9285\n",
      "\n",
      "Epoch: [77 | 1000] LR: 0.199692\n",
      "Train | 16/16 | Loss:1.8043 | MainLoss:0.2898 | Alpha:0.0270 | SPLoss:14.9852 | CLSLoss:0.1599 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.4684 | MainLoss:0.4684 | SPLoss:33.4177 | CLSLoss:0.1354 | AUROC:0.9555\n",
      "Test | 128/16 | Loss:1.0943 | MainLoss:1.0943 | SPLoss:33.4177 | CLSLoss:0.1354 | AUROC:0.8717\n",
      "\n",
      "Epoch: [78 | 1000] LR: 0.199667\n",
      "Train | 16/16 | Loss:2.9469 | MainLoss:0.2843 | Alpha:0.0278 | SPLoss:26.4666 | CLSLoss:0.1596 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.3410 | MainLoss:0.3410 | SPLoss:19.7371 | CLSLoss:0.1604 | AUROC:0.9669\n",
      "Test | 128/16 | Loss:0.9937 | MainLoss:0.9937 | SPLoss:19.7371 | CLSLoss:0.1604 | AUROC:0.9337\n",
      "\n",
      "Epoch: [79 | 1000] LR: 0.199640\n",
      "Train | 16/16 | Loss:1.8149 | MainLoss:0.2923 | Alpha:0.0281 | SPLoss:15.0631 | CLSLoss:0.1627 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2388 | MainLoss:0.2388 | SPLoss:11.0210 | CLSLoss:0.1576 | AUROC:0.9735\n",
      "Test | 128/16 | Loss:0.5960 | MainLoss:0.5960 | SPLoss:11.0210 | CLSLoss:0.1576 | AUROC:0.9120\n",
      "\n",
      "Epoch: [80 | 1000] LR: 0.199613\n",
      "Train | 16/16 | Loss:1.7976 | MainLoss:0.2695 | Alpha:0.0265 | SPLoss:15.1086 | CLSLoss:0.1718 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2402 | MainLoss:0.2402 | SPLoss:15.1415 | CLSLoss:0.1784 | AUROC:0.9716\n",
      "Test | 128/16 | Loss:0.7588 | MainLoss:0.7588 | SPLoss:15.1415 | CLSLoss:0.1784 | AUROC:0.9475\n",
      "\n",
      "Epoch: [81 | 1000] LR: 0.199585\n",
      "Train | 16/16 | Loss:2.1217 | MainLoss:0.2635 | Alpha:0.0278 | SPLoss:18.4058 | CLSLoss:0.1763 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2251 | MainLoss:0.2251 | SPLoss:21.7194 | CLSLoss:0.1580 | AUROC:0.9743\n",
      "Test | 128/16 | Loss:0.6254 | MainLoss:0.6254 | SPLoss:21.7195 | CLSLoss:0.1580 | AUROC:0.9572\n",
      "\n",
      "Epoch: [82 | 1000] LR: 0.199556\n",
      "Train | 16/16 | Loss:2.3061 | MainLoss:0.2660 | Alpha:0.0266 | SPLoss:20.2273 | CLSLoss:0.1731 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2389 | MainLoss:0.2389 | SPLoss:15.4064 | CLSLoss:0.1871 | AUROC:0.9691\n",
      "Test | 128/16 | Loss:0.7525 | MainLoss:0.7525 | SPLoss:15.4064 | CLSLoss:0.1871 | AUROC:0.9444\n",
      "\n",
      "Epoch: [83 | 1000] LR: 0.199526\n",
      "Train | 16/16 | Loss:1.4663 | MainLoss:0.2591 | Alpha:0.0272 | SPLoss:11.8922 | CLSLoss:0.1794 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2427 | MainLoss:0.2427 | SPLoss:8.7717 | CLSLoss:0.1720 | AUROC:0.9744\n",
      "Test | 128/16 | Loss:0.4419 | MainLoss:0.4419 | SPLoss:8.7717 | CLSLoss:0.1720 | AUROC:0.9651\n",
      "\n",
      "Epoch: [84 | 1000] LR: 0.199495\n",
      "Train | 16/16 | Loss:1.0268 | MainLoss:0.2888 | Alpha:0.0257 | SPLoss:7.2116 | CLSLoss:0.1681 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2460 | MainLoss:0.2460 | SPLoss:5.8936 | CLSLoss:0.1715 | AUROC:0.9684\n",
      "Test | 128/16 | Loss:0.4952 | MainLoss:0.4952 | SPLoss:5.8936 | CLSLoss:0.1715 | AUROC:0.9603\n",
      "\n",
      "Epoch: [85 | 1000] LR: 0.199463\n",
      "Train | 16/16 | Loss:1.5266 | MainLoss:0.3688 | Alpha:0.0259 | SPLoss:11.4306 | CLSLoss:0.1473 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.5398 | MainLoss:0.5398 | SPLoss:115.7658 | CLSLoss:0.1351 | AUROC:0.8830\n",
      "Test | 128/16 | Loss:0.6453 | MainLoss:0.6453 | SPLoss:115.7659 | CLSLoss:0.1351 | AUROC:0.9752\n",
      "\n",
      "Epoch: [86 | 1000] LR: 0.199430\n",
      "Train | 16/16 | Loss:12.5905 | MainLoss:0.3554 | Alpha:0.0260 | SPLoss:122.1994 | CLSLoss:0.1510 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2971 | MainLoss:0.2971 | SPLoss:1046.1495 | CLSLoss:0.1429 | AUROC:0.9601\n",
      "Test | 128/16 | Loss:0.5441 | MainLoss:0.5441 | SPLoss:1046.1503 | CLSLoss:0.1429 | AUROC:0.9410\n",
      "\n",
      "Epoch: [87 | 1000] LR: 0.199396\n",
      "Train | 16/16 | Loss:91.1960 | MainLoss:0.3576 | Alpha:0.0275 | SPLoss:908.2300 | CLSLoss:0.1546 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2710 | MainLoss:0.2710 | SPLoss:617.8470 | CLSLoss:0.1883 | AUROC:0.9615\n",
      "Test | 128/16 | Loss:0.8971 | MainLoss:0.8971 | SPLoss:617.8478 | CLSLoss:0.1883 | AUROC:0.9042\n",
      "\n",
      "Epoch: [88 | 1000] LR: 0.199361\n",
      "Train | 16/16 | Loss:45.4829 | MainLoss:0.2845 | Alpha:0.0277 | SPLoss:451.8050 | CLSLoss:0.1791 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.3138 | MainLoss:0.3138 | SPLoss:302.6750 | CLSLoss:0.1766 | AUROC:0.9658\n",
      "Test | 128/16 | Loss:0.4379 | MainLoss:0.4379 | SPLoss:302.6755 | CLSLoss:0.1766 | AUROC:0.9552\n",
      "\n",
      "Epoch: [89 | 1000] LR: 0.199325\n",
      "Train | 16/16 | Loss:22.4773 | MainLoss:0.2887 | Alpha:0.0261 | SPLoss:221.7161 | CLSLoss:0.1698 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.3574 | MainLoss:0.3574 | SPLoss:150.4105 | CLSLoss:0.1541 | AUROC:0.9542\n",
      "Test | 128/16 | Loss:0.7912 | MainLoss:0.7912 | SPLoss:150.4102 | CLSLoss:0.1541 | AUROC:0.9597\n",
      "\n",
      "Epoch: [90 | 1000] LR: 0.199288\n",
      "Train | 16/16 | Loss:11.7595 | MainLoss:0.3163 | Alpha:0.0262 | SPLoss:114.2704 | CLSLoss:0.1609 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2333 | MainLoss:0.2333 | SPLoss:77.9204 | CLSLoss:0.1660 | AUROC:0.9681\n",
      "Test | 128/16 | Loss:0.8002 | MainLoss:0.8002 | SPLoss:77.9204 | CLSLoss:0.1660 | AUROC:0.8451\n",
      "\n",
      "Epoch: [91 | 1000] LR: 0.199250\n",
      "Train | 16/16 | Loss:18.7091 | MainLoss:0.3248 | Alpha:0.0263 | SPLoss:183.6872 | CLSLoss:0.1555 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2516 | MainLoss:0.2516 | SPLoss:210.2526 | CLSLoss:0.1691 | AUROC:0.9647\n",
      "Test | 128/16 | Loss:0.6510 | MainLoss:0.6510 | SPLoss:210.2525 | CLSLoss:0.1691 | AUROC:0.8788\n",
      "\n",
      "Epoch: [92 | 1000] LR: 0.199211\n",
      "Train | 16/16 | Loss:15.6995 | MainLoss:0.2779 | Alpha:0.0285 | SPLoss:154.0429 | CLSLoss:0.1722 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.3494 | MainLoss:0.3494 | SPLoss:103.9254 | CLSLoss:0.1524 | AUROC:0.9633\n",
      "Test | 128/16 | Loss:0.5122 | MainLoss:0.5122 | SPLoss:103.9253 | CLSLoss:0.1524 | AUROC:0.8781\n",
      "\n",
      "Epoch: [93 | 1000] LR: 0.199172\n",
      "Train | 16/16 | Loss:8.1457 | MainLoss:0.2892 | Alpha:0.0275 | SPLoss:78.3999 | CLSLoss:0.1646 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2391 | MainLoss:0.2391 | SPLoss:59.3461 | CLSLoss:0.1837 | AUROC:0.9667\n",
      "Test | 128/16 | Loss:0.7132 | MainLoss:0.7132 | SPLoss:59.3460 | CLSLoss:0.1837 | AUROC:0.8871\n",
      "\n",
      "Epoch: [94 | 1000] LR: 0.199131\n",
      "Train | 16/16 | Loss:4.8294 | MainLoss:0.2936 | Alpha:0.0280 | SPLoss:45.1863 | CLSLoss:0.1717 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2707 | MainLoss:0.2707 | SPLoss:32.5611 | CLSLoss:0.1716 | AUROC:0.9606\n",
      "Test | 128/16 | Loss:0.6615 | MainLoss:0.6615 | SPLoss:32.5611 | CLSLoss:0.1716 | AUROC:0.8788\n",
      "\n",
      "Epoch: [95 | 1000] LR: 0.199089\n",
      "Train | 16/16 | Loss:3.0737 | MainLoss:0.2869 | Alpha:0.0261 | SPLoss:27.7005 | CLSLoss:0.1673 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2237 | MainLoss:0.2237 | SPLoss:22.9150 | CLSLoss:0.1754 | AUROC:0.9701\n",
      "Test | 128/16 | Loss:0.8062 | MainLoss:0.8062 | SPLoss:22.9150 | CLSLoss:0.1754 | AUROC:0.8588\n",
      "\n",
      "Epoch: [96 | 1000] LR: 0.199046\n",
      "Train | 16/16 | Loss:2.1112 | MainLoss:0.2514 | Alpha:0.0272 | SPLoss:18.4207 | CLSLoss:0.1776 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.3490 | MainLoss:0.3490 | SPLoss:14.1041 | CLSLoss:0.1582 | AUROC:0.9530\n",
      "Test | 128/16 | Loss:0.7971 | MainLoss:0.7971 | SPLoss:14.1041 | CLSLoss:0.1582 | AUROC:0.9271\n",
      "\n",
      "Epoch: [97 | 1000] LR: 0.199002\n",
      "Train | 16/16 | Loss:2.0275 | MainLoss:0.3024 | Alpha:0.0279 | SPLoss:17.0913 | CLSLoss:0.1598 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2429 | MainLoss:0.2429 | SPLoss:18.9010 | CLSLoss:0.1755 | AUROC:0.9659\n",
      "Test | 128/16 | Loss:0.5713 | MainLoss:0.5713 | SPLoss:18.9010 | CLSLoss:0.1755 | AUROC:0.9465\n",
      "\n",
      "Epoch: [98 | 1000] LR: 0.198958\n",
      "Train | 16/16 | Loss:1.8806 | MainLoss:0.3046 | Alpha:0.0265 | SPLoss:15.5950 | CLSLoss:0.1651 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2941 | MainLoss:0.2941 | SPLoss:24.9789 | CLSLoss:0.1502 | AUROC:0.9546\n",
      "Test | 128/16 | Loss:0.8250 | MainLoss:0.8250 | SPLoss:24.9790 | CLSLoss:0.1502 | AUROC:0.8989\n",
      "\n",
      "Epoch: [99 | 1000] LR: 0.198912\n",
      "Train | 16/16 | Loss:2.2678 | MainLoss:0.3168 | Alpha:0.0269 | SPLoss:19.3563 | CLSLoss:0.1546 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2112 | MainLoss:0.2112 | SPLoss:13.7594 | CLSLoss:0.1823 | AUROC:0.9737\n",
      "Test | 128/16 | Loss:0.8235 | MainLoss:0.8235 | SPLoss:13.7594 | CLSLoss:0.1823 | AUROC:0.8819\n",
      "\n",
      "Epoch: [100 | 1000] LR: 0.198865\n",
      "Train | 16/16 | Loss:33.3341 | MainLoss:0.3437 | Alpha:0.0280 | SPLoss:329.7425 | CLSLoss:0.1613 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2607 | MainLoss:0.2607 | SPLoss:374.9331 | CLSLoss:0.1849 | AUROC:0.9718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 128/16 | Loss:0.6348 | MainLoss:0.6348 | SPLoss:374.9330 | CLSLoss:0.1849 | AUROC:0.8784\n",
      "\n",
      "Epoch: [101 | 1000] LR: 0.198817\n",
      "Train | 16/16 | Loss:0.4304 | MainLoss:0.2599 | Alpha:0.4405 | SPLoss:1.5230 | CLSLoss:0.1817 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2077 | MainLoss:0.2077 | SPLoss:1.5129 | CLSLoss:0.1757 | AUROC:0.9777\n",
      "Test | 128/16 | Loss:0.7890 | MainLoss:0.7890 | SPLoss:1.5129 | CLSLoss:0.1757 | AUROC:0.8783\n",
      "\n",
      "Epoch: [102 | 1000] LR: 0.198769\n",
      "Train | 16/16 | Loss:0.3628 | MainLoss:0.2126 | Alpha:0.4407 | SPLoss:1.3235 | CLSLoss:0.1787 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1757 | MainLoss:0.1757 | SPLoss:1.1560 | CLSLoss:0.1732 | AUROC:0.9826\n",
      "Test | 128/16 | Loss:0.9384 | MainLoss:0.9384 | SPLoss:1.1560 | CLSLoss:0.1732 | AUROC:0.8485\n",
      "\n",
      "Epoch: [103 | 1000] LR: 0.198719\n",
      "Train | 16/16 | Loss:0.3240 | MainLoss:0.2012 | Alpha:0.4389 | SPLoss:1.0537 | CLSLoss:0.1734 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1896 | MainLoss:0.1896 | SPLoss:1.0016 | CLSLoss:0.1700 | AUROC:0.9866\n",
      "Test | 128/16 | Loss:0.7019 | MainLoss:0.7019 | SPLoss:1.0016 | CLSLoss:0.1700 | AUROC:0.8768\n",
      "\n",
      "Epoch: [104 | 1000] LR: 0.198669\n",
      "Train | 16/16 | Loss:0.4666 | MainLoss:0.1880 | Alpha:0.4398 | SPLoss:2.6132 | CLSLoss:0.1727 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1935 | MainLoss:0.1935 | SPLoss:3.3470 | CLSLoss:0.1623 | AUROC:0.9842\n",
      "Test | 128/16 | Loss:0.7320 | MainLoss:0.7320 | SPLoss:3.3470 | CLSLoss:0.1623 | AUROC:0.8541\n",
      "\n",
      "Epoch: [105 | 1000] LR: 0.198617\n",
      "Train | 16/16 | Loss:0.4819 | MainLoss:0.1955 | Alpha:0.4401 | SPLoss:2.7008 | CLSLoss:0.1628 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1701 | MainLoss:0.1701 | SPLoss:2.0854 | CLSLoss:0.1676 | AUROC:0.9864\n",
      "Test | 128/16 | Loss:0.7735 | MainLoss:0.7735 | SPLoss:2.0854 | CLSLoss:0.1676 | AUROC:0.8693\n",
      "\n",
      "Epoch: [106 | 1000] LR: 0.198564\n",
      "Train | 16/16 | Loss:0.3499 | MainLoss:0.1574 | Alpha:0.4417 | SPLoss:1.7456 | CLSLoss:0.1794 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1691 | MainLoss:0.1691 | SPLoss:1.4719 | CLSLoss:0.1811 | AUROC:0.9859\n",
      "Test | 128/16 | Loss:1.1515 | MainLoss:1.1515 | SPLoss:1.4719 | CLSLoss:0.1811 | AUROC:0.8460\n",
      "\n",
      "Epoch: [107 | 1000] LR: 0.198511\n",
      "Train | 16/16 | Loss:0.3147 | MainLoss:0.1667 | Alpha:0.4435 | SPLoss:1.3034 | CLSLoss:0.1771 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1662 | MainLoss:0.1662 | SPLoss:1.1901 | CLSLoss:0.1768 | AUROC:0.9852\n",
      "Test | 128/16 | Loss:1.0793 | MainLoss:1.0793 | SPLoss:1.1901 | CLSLoss:0.1768 | AUROC:0.8890\n",
      "\n",
      "Epoch: [108 | 1000] LR: 0.198456\n",
      "Train | 16/16 | Loss:0.3217 | MainLoss:0.1841 | Alpha:0.4412 | SPLoss:1.2119 | CLSLoss:0.1639 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1718 | MainLoss:0.1718 | SPLoss:1.1363 | CLSLoss:0.1612 | AUROC:0.9838\n",
      "Test | 128/16 | Loss:0.7352 | MainLoss:0.7352 | SPLoss:1.1363 | CLSLoss:0.1612 | AUROC:0.9112\n",
      "\n",
      "Epoch: [109 | 1000] LR: 0.198401\n",
      "Train | 16/16 | Loss:0.2974 | MainLoss:0.1730 | Alpha:0.4393 | SPLoss:1.0767 | CLSLoss:0.1681 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1697 | MainLoss:0.1697 | SPLoss:0.9984 | CLSLoss:0.1686 | AUROC:0.9854\n",
      "Test | 128/16 | Loss:0.7879 | MainLoss:0.7879 | SPLoss:0.9984 | CLSLoss:0.1686 | AUROC:0.8961\n",
      "\n",
      "Epoch: [110 | 1000] LR: 0.198345\n",
      "Train | 16/16 | Loss:0.2962 | MainLoss:0.1646 | Alpha:0.4414 | SPLoss:1.1435 | CLSLoss:0.1720 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1761 | MainLoss:0.1761 | SPLoss:1.0935 | CLSLoss:0.1563 | AUROC:0.9861\n",
      "Test | 128/16 | Loss:0.6774 | MainLoss:0.6774 | SPLoss:1.0935 | CLSLoss:0.1563 | AUROC:0.9005\n",
      "\n",
      "Epoch: [111 | 1000] LR: 0.198287\n",
      "Train | 16/16 | Loss:0.2976 | MainLoss:0.1710 | Alpha:0.4406 | SPLoss:1.1028 | CLSLoss:0.1632 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1571 | MainLoss:0.1571 | SPLoss:1.0149 | CLSLoss:0.1803 | AUROC:0.9868\n",
      "Test | 128/16 | Loss:0.9478 | MainLoss:0.9478 | SPLoss:1.0149 | CLSLoss:0.1803 | AUROC:0.8551\n",
      "\n",
      "Epoch: [112 | 1000] LR: 0.198229\n",
      "Train | 16/16 | Loss:0.2753 | MainLoss:0.1595 | Alpha:0.4392 | SPLoss:0.9852 | CLSLoss:0.1725 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1716 | MainLoss:0.1716 | SPLoss:0.9809 | CLSLoss:0.1705 | AUROC:0.9840\n",
      "Test | 128/16 | Loss:0.8583 | MainLoss:0.8583 | SPLoss:0.9809 | CLSLoss:0.1705 | AUROC:0.8844\n",
      "\n",
      "Epoch: [113 | 1000] LR: 0.198169\n",
      "Train | 16/16 | Loss:0.2863 | MainLoss:0.1735 | Alpha:0.4419 | SPLoss:0.9594 | CLSLoss:0.1687 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1579 | MainLoss:0.1579 | SPLoss:0.9485 | CLSLoss:0.1785 | AUROC:0.9845\n",
      "Test | 128/16 | Loss:1.0724 | MainLoss:1.0724 | SPLoss:0.9485 | CLSLoss:0.1785 | AUROC:0.8594\n",
      "\n",
      "Epoch: [114 | 1000] LR: 0.198109\n",
      "Train | 16/16 | Loss:0.2831 | MainLoss:0.1720 | Alpha:0.4406 | SPLoss:0.9375 | CLSLoss:0.1735 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1607 | MainLoss:0.1607 | SPLoss:0.8930 | CLSLoss:0.1765 | AUROC:0.9862\n",
      "Test | 128/16 | Loss:0.9272 | MainLoss:0.9272 | SPLoss:0.8930 | CLSLoss:0.1765 | AUROC:0.8578\n",
      "\n",
      "Epoch: [115 | 1000] LR: 0.198048\n",
      "Train | 16/16 | Loss:0.2680 | MainLoss:0.1605 | Alpha:0.4408 | SPLoss:0.9016 | CLSLoss:0.1739 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1589 | MainLoss:0.1589 | SPLoss:0.8881 | CLSLoss:0.1825 | AUROC:0.9850\n",
      "Test | 128/16 | Loss:0.9539 | MainLoss:0.9539 | SPLoss:0.8881 | CLSLoss:0.1825 | AUROC:0.9001\n",
      "\n",
      "Epoch: [116 | 1000] LR: 0.197986\n",
      "Train | 16/16 | Loss:0.3654 | MainLoss:0.1799 | Alpha:0.4398 | SPLoss:1.6886 | CLSLoss:0.1665 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1682 | MainLoss:0.1682 | SPLoss:4.1338 | CLSLoss:0.1723 | AUROC:0.9828\n",
      "Test | 128/16 | Loss:1.0487 | MainLoss:1.0487 | SPLoss:4.1338 | CLSLoss:0.1723 | AUROC:0.8909\n",
      "\n",
      "Epoch: [117 | 1000] LR: 0.197922\n",
      "Train | 16/16 | Loss:0.5472 | MainLoss:0.1674 | Alpha:0.4402 | SPLoss:3.6284 | CLSLoss:0.1691 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1769 | MainLoss:0.1769 | SPLoss:2.9288 | CLSLoss:0.1571 | AUROC:0.9819\n",
      "Test | 128/16 | Loss:1.0818 | MainLoss:1.0818 | SPLoss:2.9288 | CLSLoss:0.1571 | AUROC:0.8726\n",
      "\n",
      "Epoch: [118 | 1000] LR: 0.197858\n",
      "Train | 16/16 | Loss:0.4549 | MainLoss:0.1844 | Alpha:0.4392 | SPLoss:2.5484 | CLSLoss:0.1569 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1783 | MainLoss:0.1783 | SPLoss:2.1638 | CLSLoss:0.1644 | AUROC:0.9862\n",
      "Test | 128/16 | Loss:0.8735 | MainLoss:0.8735 | SPLoss:2.1638 | CLSLoss:0.1644 | AUROC:0.8213\n",
      "\n",
      "Epoch: [119 | 1000] LR: 0.197793\n",
      "Train | 16/16 | Loss:0.3833 | MainLoss:0.1853 | Alpha:0.4398 | SPLoss:1.8159 | CLSLoss:0.1649 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1841 | MainLoss:0.1841 | SPLoss:1.5388 | CLSLoss:0.1633 | AUROC:0.9857\n",
      "Test | 128/16 | Loss:0.7666 | MainLoss:0.7666 | SPLoss:1.5388 | CLSLoss:0.1633 | AUROC:0.8372\n",
      "\n",
      "Epoch: [120 | 1000] LR: 0.197727\n",
      "Train | 16/16 | Loss:0.3283 | MainLoss:0.1725 | Alpha:0.4371 | SPLoss:1.3892 | CLSLoss:0.1687 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1523 | MainLoss:0.1523 | SPLoss:1.2080 | CLSLoss:0.1635 | AUROC:0.9873\n",
      "Test | 128/16 | Loss:1.0000 | MainLoss:1.0000 | SPLoss:1.2080 | CLSLoss:0.1635 | AUROC:0.8530\n",
      "\n",
      "Epoch: [121 | 1000] LR: 0.197660\n",
      "Train | 16/16 | Loss:0.3811 | MainLoss:0.1869 | Alpha:0.4387 | SPLoss:1.7792 | CLSLoss:0.1633 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2151 | MainLoss:0.2151 | SPLoss:2.4085 | CLSLoss:0.1468 | AUROC:0.9837\n",
      "Test | 128/16 | Loss:1.1137 | MainLoss:1.1137 | SPLoss:2.4085 | CLSLoss:0.1468 | AUROC:0.8604\n",
      "\n",
      "Epoch: [122 | 1000] LR: 0.197592\n",
      "Train | 16/16 | Loss:0.3981 | MainLoss:0.1814 | Alpha:0.4396 | SPLoss:2.0020 | CLSLoss:0.1650 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1840 | MainLoss:0.1840 | SPLoss:1.6314 | CLSLoss:0.1632 | AUROC:0.9853\n",
      "Test | 128/16 | Loss:0.7350 | MainLoss:0.7350 | SPLoss:1.6314 | CLSLoss:0.1632 | AUROC:0.8782\n",
      "\n",
      "Epoch: [123 | 1000] LR: 0.197523\n",
      "Train | 16/16 | Loss:0.3329 | MainLoss:0.1721 | Alpha:0.4380 | SPLoss:1.4388 | CLSLoss:0.1692 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1784 | MainLoss:0.1784 | SPLoss:1.2658 | CLSLoss:0.1706 | AUROC:0.9863\n",
      "Test | 128/16 | Loss:0.7455 | MainLoss:0.7455 | SPLoss:1.2658 | CLSLoss:0.1706 | AUROC:0.8874\n",
      "\n",
      "Epoch: [124 | 1000] LR: 0.197453\n",
      "Train | 16/16 | Loss:0.3197 | MainLoss:0.1819 | Alpha:0.4387 | SPLoss:1.2086 | CLSLoss:0.1685 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1750 | MainLoss:0.1750 | SPLoss:1.1486 | CLSLoss:0.1732 | AUROC:0.9841\n",
      "Test | 128/16 | Loss:0.8511 | MainLoss:0.8511 | SPLoss:1.1486 | CLSLoss:0.1732 | AUROC:0.8476\n",
      "\n",
      "Epoch: [125 | 1000] LR: 0.197382\n",
      "Train | 16/16 | Loss:0.2891 | MainLoss:0.1653 | Alpha:0.4404 | SPLoss:1.0651 | CLSLoss:0.1735 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1610 | MainLoss:0.1610 | SPLoss:0.9623 | CLSLoss:0.1565 | AUROC:0.9857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 128/16 | Loss:0.9747 | MainLoss:0.9747 | SPLoss:0.9623 | CLSLoss:0.1565 | AUROC:0.8174\n",
      "\n",
      "Epoch: [126 | 1000] LR: 0.197310\n",
      "Train | 16/16 | Loss:0.3440 | MainLoss:0.1622 | Alpha:0.4401 | SPLoss:1.6524 | CLSLoss:0.1650 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1664 | MainLoss:0.1664 | SPLoss:2.5095 | CLSLoss:0.1720 | AUROC:0.9848\n",
      "Test | 128/16 | Loss:0.8949 | MainLoss:0.8949 | SPLoss:2.5095 | CLSLoss:0.1720 | AUROC:0.8842\n",
      "\n",
      "Epoch: [127 | 1000] LR: 0.197237\n",
      "Train | 16/16 | Loss:0.4050 | MainLoss:0.1796 | Alpha:0.4400 | SPLoss:2.0917 | CLSLoss:0.1629 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2015 | MainLoss:0.2015 | SPLoss:1.6677 | CLSLoss:0.1769 | AUROC:0.9868\n",
      "Test | 128/16 | Loss:0.8416 | MainLoss:0.8416 | SPLoss:1.6677 | CLSLoss:0.1769 | AUROC:0.8512\n",
      "\n",
      "Epoch: [128 | 1000] LR: 0.197163\n",
      "Train | 16/16 | Loss:0.3408 | MainLoss:0.1709 | Alpha:0.4405 | SPLoss:1.5296 | CLSLoss:0.1691 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1593 | MainLoss:0.1593 | SPLoss:1.3994 | CLSLoss:0.1676 | AUROC:0.9854\n",
      "Test | 128/16 | Loss:1.0329 | MainLoss:1.0329 | SPLoss:1.3994 | CLSLoss:0.1676 | AUROC:0.8330\n",
      "\n",
      "Epoch: [129 | 1000] LR: 0.197088\n",
      "Train | 16/16 | Loss:0.3268 | MainLoss:0.1681 | Alpha:0.4395 | SPLoss:1.4197 | CLSLoss:0.1677 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1775 | MainLoss:0.1775 | SPLoss:1.5601 | CLSLoss:0.1576 | AUROC:0.9860\n",
      "Test | 128/16 | Loss:0.7281 | MainLoss:0.7281 | SPLoss:1.5601 | CLSLoss:0.1576 | AUROC:0.8875\n",
      "\n",
      "Epoch: [130 | 1000] LR: 0.197013\n",
      "Train | 16/16 | Loss:0.3242 | MainLoss:0.1699 | Alpha:0.4407 | SPLoss:1.3772 | CLSLoss:0.1651 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1627 | MainLoss:0.1627 | SPLoss:1.2010 | CLSLoss:0.1639 | AUROC:0.9848\n",
      "Test | 128/16 | Loss:1.1520 | MainLoss:1.1520 | SPLoss:1.2010 | CLSLoss:0.1639 | AUROC:0.8494\n",
      "\n",
      "Epoch: [131 | 1000] LR: 0.196936\n",
      "Train | 16/16 | Loss:0.2988 | MainLoss:0.1702 | Alpha:0.4403 | SPLoss:1.1176 | CLSLoss:0.1683 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2233 | MainLoss:0.2233 | SPLoss:1.0757 | CLSLoss:0.1391 | AUROC:0.9842\n",
      "Test | 128/16 | Loss:0.5913 | MainLoss:0.5913 | SPLoss:1.0757 | CLSLoss:0.1391 | AUROC:0.8848\n",
      "\n",
      "Epoch: [132 | 1000] LR: 0.196858\n",
      "Train | 16/16 | Loss:0.2946 | MainLoss:0.1750 | Alpha:0.4404 | SPLoss:1.0357 | CLSLoss:0.1605 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1655 | MainLoss:0.1655 | SPLoss:0.9937 | CLSLoss:0.1700 | AUROC:0.9861\n",
      "Test | 128/16 | Loss:0.8765 | MainLoss:0.8765 | SPLoss:0.9937 | CLSLoss:0.1700 | AUROC:0.8671\n",
      "\n",
      "Epoch: [133 | 1000] LR: 0.196780\n",
      "Train | 16/16 | Loss:0.2893 | MainLoss:0.1742 | Alpha:0.4385 | SPLoss:0.9840 | CLSLoss:0.1671 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1559 | MainLoss:0.1559 | SPLoss:0.9723 | CLSLoss:0.1770 | AUROC:0.9866\n",
      "Test | 128/16 | Loss:0.8878 | MainLoss:0.8878 | SPLoss:0.9723 | CLSLoss:0.1770 | AUROC:0.8779\n",
      "\n",
      "Epoch: [134 | 1000] LR: 0.196700\n",
      "Train | 16/16 | Loss:0.2780 | MainLoss:0.1646 | Alpha:0.4408 | SPLoss:0.9619 | CLSLoss:0.1719 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1643 | MainLoss:0.1643 | SPLoss:0.9601 | CLSLoss:0.1727 | AUROC:0.9843\n",
      "Test | 128/16 | Loss:0.9201 | MainLoss:0.9201 | SPLoss:0.9601 | CLSLoss:0.1727 | AUROC:0.8921\n",
      "\n",
      "Epoch: [135 | 1000] LR: 0.196620\n",
      "Train | 16/16 | Loss:0.2751 | MainLoss:0.1610 | Alpha:0.4407 | SPLoss:0.9697 | CLSLoss:0.1710 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1682 | MainLoss:0.1682 | SPLoss:0.9893 | CLSLoss:0.1827 | AUROC:0.9838\n",
      "Test | 128/16 | Loss:0.8997 | MainLoss:0.8997 | SPLoss:0.9893 | CLSLoss:0.1827 | AUROC:0.8814\n",
      "\n",
      "Epoch: [136 | 1000] LR: 0.196538\n",
      "Train | 16/16 | Loss:0.2968 | MainLoss:0.1798 | Alpha:0.4388 | SPLoss:0.9974 | CLSLoss:0.1723 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2560 | MainLoss:0.2560 | SPLoss:0.9885 | CLSLoss:0.1366 | AUROC:0.9855\n",
      "Test | 128/16 | Loss:0.5421 | MainLoss:0.5421 | SPLoss:0.9885 | CLSLoss:0.1366 | AUROC:0.8536\n",
      "\n",
      "Epoch: [137 | 1000] LR: 0.196456\n",
      "Train | 16/16 | Loss:0.2828 | MainLoss:0.1717 | Alpha:0.4397 | SPLoss:0.9465 | CLSLoss:0.1642 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1740 | MainLoss:0.1740 | SPLoss:0.9165 | CLSLoss:0.1647 | AUROC:0.9880\n",
      "Test | 128/16 | Loss:0.7980 | MainLoss:0.7980 | SPLoss:0.9165 | CLSLoss:0.1647 | AUROC:0.8663\n",
      "\n",
      "Epoch: [138 | 1000] LR: 0.196372\n",
      "Train | 16/16 | Loss:0.3009 | MainLoss:0.1914 | Alpha:0.4391 | SPLoss:0.9278 | CLSLoss:0.1671 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2134 | MainLoss:0.2134 | SPLoss:0.9720 | CLSLoss:0.1259 | AUROC:0.9846\n",
      "Test | 128/16 | Loss:0.5873 | MainLoss:0.5873 | SPLoss:0.9720 | CLSLoss:0.1259 | AUROC:0.8661\n",
      "\n",
      "Epoch: [139 | 1000] LR: 0.196288\n",
      "Train | 16/16 | Loss:0.2639 | MainLoss:0.1549 | Alpha:0.4412 | SPLoss:0.9195 | CLSLoss:0.1699 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1580 | MainLoss:0.1580 | SPLoss:0.8936 | CLSLoss:0.1678 | AUROC:0.9847\n",
      "Test | 128/16 | Loss:0.9158 | MainLoss:0.9158 | SPLoss:0.8936 | CLSLoss:0.1678 | AUROC:0.8595\n",
      "\n",
      "Epoch: [140 | 1000] LR: 0.196203\n",
      "Train | 16/16 | Loss:0.3158 | MainLoss:0.1827 | Alpha:0.4394 | SPLoss:1.1633 | CLSLoss:0.1680 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1732 | MainLoss:0.1732 | SPLoss:1.1553 | CLSLoss:0.1682 | AUROC:0.9851\n",
      "Test | 128/16 | Loss:0.6373 | MainLoss:0.6373 | SPLoss:1.1553 | CLSLoss:0.1682 | AUROC:0.9178\n",
      "\n",
      "Epoch: [141 | 1000] LR: 0.196117\n",
      "Train | 16/16 | Loss:0.3797 | MainLoss:0.1906 | Alpha:0.4369 | SPLoss:1.7321 | CLSLoss:0.1591 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1837 | MainLoss:0.1837 | SPLoss:5.6081 | CLSLoss:0.1686 | AUROC:0.9807\n",
      "Test | 128/16 | Loss:0.8577 | MainLoss:0.8577 | SPLoss:5.6081 | CLSLoss:0.1686 | AUROC:0.8567\n",
      "\n",
      "Epoch: [142 | 1000] LR: 0.196029\n",
      "Train | 16/16 | Loss:0.6820 | MainLoss:0.1904 | Alpha:0.4395 | SPLoss:4.7526 | CLSLoss:0.1632 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2438 | MainLoss:0.2438 | SPLoss:6.3625 | CLSLoss:0.1544 | AUROC:0.9861\n",
      "Test | 128/16 | Loss:0.5383 | MainLoss:0.5383 | SPLoss:6.3625 | CLSLoss:0.1544 | AUROC:0.8917\n",
      "\n",
      "Epoch: [143 | 1000] LR: 0.195941\n",
      "Train | 16/16 | Loss:0.6985 | MainLoss:0.1732 | Alpha:0.4394 | SPLoss:5.0847 | CLSLoss:0.1681 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2084 | MainLoss:0.2084 | SPLoss:3.7220 | CLSLoss:0.1650 | AUROC:0.9853\n",
      "Test | 128/16 | Loss:0.5487 | MainLoss:0.5487 | SPLoss:3.7220 | CLSLoss:0.1650 | AUROC:0.9215\n",
      "\n",
      "Epoch: [144 | 1000] LR: 0.195852\n",
      "Train | 16/16 | Loss:0.5335 | MainLoss:0.2170 | Alpha:0.4387 | SPLoss:3.0099 | CLSLoss:0.1558 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1743 | MainLoss:0.1743 | SPLoss:2.3456 | CLSLoss:0.1552 | AUROC:0.9844\n",
      "Test | 128/16 | Loss:0.8784 | MainLoss:0.8784 | SPLoss:2.3456 | CLSLoss:0.1552 | AUROC:0.8218\n",
      "\n",
      "Epoch: [145 | 1000] LR: 0.195762\n",
      "Train | 16/16 | Loss:0.3812 | MainLoss:0.1706 | Alpha:0.4380 | SPLoss:1.9330 | CLSLoss:0.1736 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1569 | MainLoss:0.1569 | SPLoss:1.5869 | CLSLoss:0.1691 | AUROC:0.9851\n",
      "Test | 128/16 | Loss:0.8692 | MainLoss:0.8692 | SPLoss:1.5869 | CLSLoss:0.1691 | AUROC:0.9180\n",
      "\n",
      "Epoch: [146 | 1000] LR: 0.195671\n",
      "Train | 16/16 | Loss:0.3494 | MainLoss:0.1717 | Alpha:0.4382 | SPLoss:1.6060 | CLSLoss:0.1710 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1613 | MainLoss:0.1613 | SPLoss:1.5310 | CLSLoss:0.1805 | AUROC:0.9852\n",
      "Test | 128/16 | Loss:0.9101 | MainLoss:0.9101 | SPLoss:1.5310 | CLSLoss:0.1805 | AUROC:0.8807\n",
      "\n",
      "Epoch: [147 | 1000] LR: 0.195579\n",
      "Train | 16/16 | Loss:0.4308 | MainLoss:0.1773 | Alpha:0.4394 | SPLoss:2.3614 | CLSLoss:0.1737 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1707 | MainLoss:0.1707 | SPLoss:6.3266 | CLSLoss:0.1658 | AUROC:0.9830\n",
      "Test | 128/16 | Loss:1.1506 | MainLoss:1.1506 | SPLoss:6.3266 | CLSLoss:0.1658 | AUROC:0.8361\n",
      "\n",
      "Epoch: [148 | 1000] LR: 0.195486\n",
      "Train | 16/16 | Loss:0.7081 | MainLoss:0.1987 | Alpha:0.4415 | SPLoss:4.9358 | CLSLoss:0.1580 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1826 | MainLoss:0.1826 | SPLoss:3.6202 | CLSLoss:0.1601 | AUROC:0.9800\n",
      "Test | 128/16 | Loss:1.0821 | MainLoss:1.0821 | SPLoss:3.6202 | CLSLoss:0.1601 | AUROC:0.7985\n",
      "\n",
      "Epoch: [149 | 1000] LR: 0.195393\n",
      "Train | 16/16 | Loss:0.5889 | MainLoss:0.1830 | Alpha:0.4408 | SPLoss:3.8940 | CLSLoss:0.1651 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1745 | MainLoss:0.1745 | SPLoss:9.1657 | CLSLoss:0.1629 | AUROC:0.9819\n",
      "Test | 128/16 | Loss:1.0211 | MainLoss:1.0211 | SPLoss:9.1657 | CLSLoss:0.1629 | AUROC:0.8260\n",
      "\n",
      "Epoch: [150 | 1000] LR: 0.195298\n",
      "Train | 16/16 | Loss:0.8929 | MainLoss:0.1801 | Alpha:0.4418 | SPLoss:6.9608 | CLSLoss:0.1672 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1591 | MainLoss:0.1591 | SPLoss:4.9683 | CLSLoss:0.1685 | AUROC:0.9855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 128/16 | Loss:0.9882 | MainLoss:0.9882 | SPLoss:4.9683 | CLSLoss:0.1685 | AUROC:0.8386\n",
      "\n",
      "Epoch: [151 | 1000] LR: 0.195202\n",
      "Train | 16/16 | Loss:0.5790 | MainLoss:0.1701 | Alpha:0.4389 | SPLoss:3.9173 | CLSLoss:0.1725 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1727 | MainLoss:0.1727 | SPLoss:2.9848 | CLSLoss:0.1763 | AUROC:0.9854\n",
      "Test | 128/16 | Loss:0.8342 | MainLoss:0.8342 | SPLoss:2.9848 | CLSLoss:0.1763 | AUROC:0.8616\n",
      "\n",
      "Epoch: [152 | 1000] LR: 0.195106\n",
      "Train | 16/16 | Loss:0.4518 | MainLoss:0.1868 | Alpha:0.4395 | SPLoss:2.4845 | CLSLoss:0.1659 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1567 | MainLoss:0.1567 | SPLoss:1.9666 | CLSLoss:0.1740 | AUROC:0.9855\n",
      "Test | 128/16 | Loss:0.9523 | MainLoss:0.9523 | SPLoss:1.9666 | CLSLoss:0.1740 | AUROC:0.8508\n",
      "\n",
      "Epoch: [153 | 1000] LR: 0.195008\n",
      "Train | 16/16 | Loss:1.0562 | MainLoss:0.1752 | Alpha:0.4418 | SPLoss:8.6406 | CLSLoss:0.1694 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1745 | MainLoss:0.1745 | SPLoss:27.9890 | CLSLoss:0.1599 | AUROC:0.9822\n",
      "Test | 128/16 | Loss:0.9244 | MainLoss:0.9244 | SPLoss:27.9890 | CLSLoss:0.1599 | AUROC:0.8194\n",
      "\n",
      "Epoch: [154 | 1000] LR: 0.194910\n",
      "Train | 16/16 | Loss:2.2817 | MainLoss:0.1817 | Alpha:0.4412 | SPLoss:20.8371 | CLSLoss:0.1633 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1927 | MainLoss:0.1927 | SPLoss:14.3520 | CLSLoss:0.1692 | AUROC:0.9834\n",
      "Test | 128/16 | Loss:0.7002 | MainLoss:0.7002 | SPLoss:14.3520 | CLSLoss:0.1692 | AUROC:0.8582\n",
      "\n",
      "Epoch: [155 | 1000] LR: 0.194810\n",
      "Train | 16/16 | Loss:1.2774 | MainLoss:0.1733 | Alpha:0.4404 | SPLoss:10.8731 | CLSLoss:0.1683 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1661 | MainLoss:0.1661 | SPLoss:7.6891 | CLSLoss:0.1738 | AUROC:0.9850\n",
      "Test | 128/16 | Loss:0.9548 | MainLoss:0.9548 | SPLoss:7.6891 | CLSLoss:0.1738 | AUROC:0.8400\n",
      "\n",
      "Epoch: [156 | 1000] LR: 0.194710\n",
      "Train | 16/16 | Loss:0.7907 | MainLoss:0.1718 | Alpha:0.4414 | SPLoss:6.0184 | CLSLoss:0.1708 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1707 | MainLoss:0.1707 | SPLoss:4.4384 | CLSLoss:0.1673 | AUROC:0.9845\n",
      "Test | 128/16 | Loss:0.9030 | MainLoss:0.9030 | SPLoss:4.4384 | CLSLoss:0.1673 | AUROC:0.8656\n",
      "\n",
      "Epoch: [157 | 1000] LR: 0.194609\n",
      "Train | 16/16 | Loss:0.5397 | MainLoss:0.1563 | Alpha:0.4416 | SPLoss:3.6604 | CLSLoss:0.1733 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1835 | MainLoss:0.1835 | SPLoss:2.8494 | CLSLoss:0.1808 | AUROC:0.9856\n",
      "Test | 128/16 | Loss:0.9273 | MainLoss:0.9273 | SPLoss:2.8494 | CLSLoss:0.1808 | AUROC:0.8413\n",
      "\n",
      "Epoch: [158 | 1000] LR: 0.194506\n",
      "Train | 16/16 | Loss:0.4415 | MainLoss:0.1911 | Alpha:0.4399 | SPLoss:2.3428 | CLSLoss:0.1614 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1985 | MainLoss:0.1985 | SPLoss:1.8688 | CLSLoss:0.1626 | AUROC:0.9844\n",
      "Test | 128/16 | Loss:0.6667 | MainLoss:0.6667 | SPLoss:1.8688 | CLSLoss:0.1626 | AUROC:0.8737\n",
      "\n",
      "Epoch: [159 | 1000] LR: 0.194403\n",
      "Train | 16/16 | Loss:0.3457 | MainLoss:0.1662 | Alpha:0.4405 | SPLoss:1.6256 | CLSLoss:0.1700 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1874 | MainLoss:0.1874 | SPLoss:1.4752 | CLSLoss:0.1687 | AUROC:0.9826\n",
      "Test | 128/16 | Loss:0.7432 | MainLoss:0.7432 | SPLoss:1.4752 | CLSLoss:0.1687 | AUROC:0.8483\n",
      "\n",
      "Epoch: [160 | 1000] LR: 0.194299\n",
      "Train | 16/16 | Loss:0.3145 | MainLoss:0.1608 | Alpha:0.4414 | SPLoss:1.3645 | CLSLoss:0.1723 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2112 | MainLoss:0.2112 | SPLoss:1.2085 | CLSLoss:0.1767 | AUROC:0.9808\n",
      "Test | 128/16 | Loss:1.1943 | MainLoss:1.1943 | SPLoss:1.2085 | CLSLoss:0.1767 | AUROC:0.8753\n",
      "\n",
      "Epoch: [161 | 1000] LR: 0.194194\n",
      "Train | 16/16 | Loss:0.3120 | MainLoss:0.1836 | Alpha:0.4378 | SPLoss:1.1227 | CLSLoss:0.1615 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1600 | MainLoss:0.1600 | SPLoss:1.0168 | CLSLoss:0.1560 | AUROC:0.9854\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:1.0168 | CLSLoss:0.1560 | AUROC:0.8985\n",
      "\n",
      "Epoch: [162 | 1000] LR: 0.194088\n",
      "Train | 16/16 | Loss:0.2792 | MainLoss:0.1555 | Alpha:0.4424 | SPLoss:1.0647 | CLSLoss:0.1715 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1656 | MainLoss:0.1656 | SPLoss:1.5707 | CLSLoss:0.1734 | AUROC:0.9837\n",
      "Test | 128/16 | Loss:0.9873 | MainLoss:0.9873 | SPLoss:1.5707 | CLSLoss:0.1734 | AUROC:0.8629\n",
      "\n",
      "Epoch: [163 | 1000] LR: 0.193981\n",
      "Train | 16/16 | Loss:0.3713 | MainLoss:0.1700 | Alpha:0.4382 | SPLoss:1.8382 | CLSLoss:0.1741 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2765 | MainLoss:0.2765 | SPLoss:1.7912 | CLSLoss:0.1547 | AUROC:0.9821\n",
      "Test | 128/16 | Loss:1.2411 | MainLoss:1.2411 | SPLoss:1.7912 | CLSLoss:0.1547 | AUROC:0.8182\n",
      "\n",
      "Epoch: [164 | 1000] LR: 0.193873\n",
      "Train | 16/16 | Loss:0.3870 | MainLoss:0.2190 | Alpha:0.4395 | SPLoss:1.5206 | CLSLoss:0.1590 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1851 | MainLoss:0.1851 | SPLoss:1.3426 | CLSLoss:0.1399 | AUROC:0.9853\n",
      "Test | 128/16 | Loss:0.7521 | MainLoss:0.7521 | SPLoss:1.3426 | CLSLoss:0.1399 | AUROC:0.8311\n",
      "\n",
      "Epoch: [165 | 1000] LR: 0.193765\n",
      "Train | 16/16 | Loss:0.2974 | MainLoss:0.1623 | Alpha:0.4408 | SPLoss:1.1816 | CLSLoss:0.1688 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1642 | MainLoss:0.1642 | SPLoss:1.0718 | CLSLoss:0.1649 | AUROC:0.9857\n",
      "Test | 128/16 | Loss:0.8149 | MainLoss:0.8149 | SPLoss:1.0718 | CLSLoss:0.1649 | AUROC:0.8700\n",
      "\n",
      "Epoch: [166 | 1000] LR: 0.193655\n",
      "Train | 16/16 | Loss:0.3291 | MainLoss:0.2027 | Alpha:0.4370 | SPLoss:1.1017 | CLSLoss:0.1627 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1984 | MainLoss:0.1984 | SPLoss:1.0943 | CLSLoss:0.1591 | AUROC:0.9854\n",
      "Test | 128/16 | Loss:0.6197 | MainLoss:0.6197 | SPLoss:1.0943 | CLSLoss:0.1591 | AUROC:0.8926\n",
      "\n",
      "Epoch: [167 | 1000] LR: 0.193544\n",
      "Train | 16/16 | Loss:0.2822 | MainLoss:0.1602 | Alpha:0.4417 | SPLoss:1.0443 | CLSLoss:0.1761 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1985 | MainLoss:0.1985 | SPLoss:0.9912 | CLSLoss:0.1684 | AUROC:0.9836\n",
      "Test | 128/16 | Loss:0.6379 | MainLoss:0.6379 | SPLoss:0.9912 | CLSLoss:0.1684 | AUROC:0.9093\n",
      "\n",
      "Epoch: [168 | 1000] LR: 0.193433\n",
      "Train | 16/16 | Loss:0.3376 | MainLoss:0.1780 | Alpha:0.4389 | SPLoss:1.4251 | CLSLoss:0.1707 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1684 | MainLoss:0.1684 | SPLoss:1.6506 | CLSLoss:0.1589 | AUROC:0.9847\n",
      "Test | 128/16 | Loss:0.7667 | MainLoss:0.7667 | SPLoss:1.6506 | CLSLoss:0.1589 | AUROC:0.8804\n",
      "\n",
      "Epoch: [169 | 1000] LR: 0.193320\n",
      "Train | 16/16 | Loss:0.3260 | MainLoss:0.1656 | Alpha:0.4410 | SPLoss:1.4350 | CLSLoss:0.1696 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2479 | MainLoss:0.2479 | SPLoss:1.2670 | CLSLoss:0.1751 | AUROC:0.9847\n",
      "Test | 128/16 | Loss:0.6553 | MainLoss:0.6553 | SPLoss:1.2670 | CLSLoss:0.1751 | AUROC:0.8876\n",
      "\n",
      "Epoch: [170 | 1000] LR: 0.193207\n",
      "Train | 16/16 | Loss:0.3099 | MainLoss:0.1712 | Alpha:0.4431 | SPLoss:1.2166 | CLSLoss:0.1703 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1726 | MainLoss:0.1726 | SPLoss:1.0761 | CLSLoss:0.1764 | AUROC:0.9857\n",
      "Test | 128/16 | Loss:0.8154 | MainLoss:0.8154 | SPLoss:1.0761 | CLSLoss:0.1764 | AUROC:0.8932\n",
      "\n",
      "Epoch: [171 | 1000] LR: 0.193093\n",
      "Train | 16/16 | Loss:0.2837 | MainLoss:0.1648 | Alpha:0.4425 | SPLoss:1.0174 | CLSLoss:0.1716 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2013 | MainLoss:0.2013 | SPLoss:0.9861 | CLSLoss:0.1599 | AUROC:0.9862\n",
      "Test | 128/16 | Loss:0.8307 | MainLoss:0.8307 | SPLoss:0.9861 | CLSLoss:0.1599 | AUROC:0.8352\n",
      "\n",
      "Epoch: [172 | 1000] LR: 0.192978\n",
      "Train | 16/16 | Loss:0.2845 | MainLoss:0.1680 | Alpha:0.4401 | SPLoss:0.9993 | CLSLoss:0.1661 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1579 | MainLoss:0.1579 | SPLoss:0.9775 | CLSLoss:0.1678 | AUROC:0.9860\n",
      "Test | 128/16 | Loss:0.9102 | MainLoss:0.9102 | SPLoss:0.9775 | CLSLoss:0.1678 | AUROC:0.8661\n",
      "\n",
      "Epoch: [173 | 1000] LR: 0.192862\n",
      "Train | 16/16 | Loss:0.2850 | MainLoss:0.1730 | Alpha:0.4385 | SPLoss:0.9500 | CLSLoss:0.1700 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1554 | MainLoss:0.1554 | SPLoss:0.8913 | CLSLoss:0.1712 | AUROC:0.9854\n",
      "Test | 128/16 | Loss:0.9321 | MainLoss:0.9321 | SPLoss:0.8913 | CLSLoss:0.1712 | AUROC:0.8687\n",
      "\n",
      "Epoch: [174 | 1000] LR: 0.192745\n",
      "Train | 16/16 | Loss:0.3430 | MainLoss:0.1939 | Alpha:0.4386 | SPLoss:1.3317 | CLSLoss:0.1594 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1727 | MainLoss:0.1727 | SPLoss:1.4485 | CLSLoss:0.1610 | AUROC:0.9818\n",
      "Test | 128/16 | Loss:0.8968 | MainLoss:0.8968 | SPLoss:1.4485 | CLSLoss:0.1610 | AUROC:0.9220\n",
      "\n",
      "Epoch: [175 | 1000] LR: 0.192627\n",
      "Train | 16/16 | Loss:0.3480 | MainLoss:0.1856 | Alpha:0.4394 | SPLoss:1.4615 | CLSLoss:0.1622 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1717 | MainLoss:0.1717 | SPLoss:2.1179 | CLSLoss:0.1552 | AUROC:0.9857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 128/16 | Loss:0.8460 | MainLoss:0.8460 | SPLoss:2.1179 | CLSLoss:0.1552 | AUROC:0.8482\n",
      "\n",
      "Epoch: [176 | 1000] LR: 0.192508\n",
      "Train | 16/16 | Loss:0.3891 | MainLoss:0.1919 | Alpha:0.4399 | SPLoss:1.8090 | CLSLoss:0.1631 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1678 | MainLoss:0.1678 | SPLoss:1.5211 | CLSLoss:0.1572 | AUROC:0.9838\n",
      "Test | 128/16 | Loss:0.9640 | MainLoss:0.9640 | SPLoss:1.5211 | CLSLoss:0.1572 | AUROC:0.8364\n",
      "\n",
      "Epoch: [177 | 1000] LR: 0.192388\n",
      "Train | 16/16 | Loss:0.3267 | MainLoss:0.1628 | Alpha:0.4421 | SPLoss:1.4677 | CLSLoss:0.1718 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2098 | MainLoss:0.2098 | SPLoss:1.3615 | CLSLoss:0.1644 | AUROC:0.9790\n",
      "Test | 128/16 | Loss:1.2999 | MainLoss:1.2999 | SPLoss:1.3615 | CLSLoss:0.1644 | AUROC:0.8278\n",
      "\n",
      "Epoch: [178 | 1000] LR: 0.192267\n",
      "Train | 16/16 | Loss:0.4554 | MainLoss:0.1639 | Alpha:0.4425 | SPLoss:2.7515 | CLSLoss:0.1631 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2408 | MainLoss:0.2408 | SPLoss:4.3515 | CLSLoss:0.1666 | AUROC:0.9815\n",
      "Test | 128/16 | Loss:0.6356 | MainLoss:0.6356 | SPLoss:4.3516 | CLSLoss:0.1666 | AUROC:0.9040\n",
      "\n",
      "Epoch: [179 | 1000] LR: 0.192146\n",
      "Train | 16/16 | Loss:0.5233 | MainLoss:0.1623 | Alpha:0.4425 | SPLoss:3.4472 | CLSLoss:0.1628 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1621 | MainLoss:0.1621 | SPLoss:2.6543 | CLSLoss:0.1657 | AUROC:0.9845\n",
      "Test | 128/16 | Loss:1.2124 | MainLoss:1.2124 | SPLoss:2.6543 | CLSLoss:0.1657 | AUROC:0.7852\n",
      "\n",
      "Epoch: [180 | 1000] LR: 0.192023\n",
      "Train | 16/16 | Loss:0.4236 | MainLoss:0.1698 | Alpha:0.4425 | SPLoss:2.3762 | CLSLoss:0.1615 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2170 | MainLoss:0.2170 | SPLoss:2.1762 | CLSLoss:0.1590 | AUROC:0.9843\n",
      "Test | 128/16 | Loss:0.8011 | MainLoss:0.8011 | SPLoss:2.1762 | CLSLoss:0.1590 | AUROC:0.8266\n",
      "\n",
      "Epoch: [181 | 1000] LR: 0.191900\n",
      "Train | 16/16 | Loss:0.3784 | MainLoss:0.1792 | Alpha:0.4381 | SPLoss:1.8321 | CLSLoss:0.1599 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1888 | MainLoss:0.1888 | SPLoss:1.5470 | CLSLoss:0.1550 | AUROC:0.9840\n",
      "Test | 128/16 | Loss:0.7831 | MainLoss:0.7831 | SPLoss:1.5470 | CLSLoss:0.1550 | AUROC:0.8677\n",
      "\n",
      "Epoch: [182 | 1000] LR: 0.191775\n",
      "Train | 16/16 | Loss:0.3829 | MainLoss:0.1910 | Alpha:0.4426 | SPLoss:1.7578 | CLSLoss:0.1614 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1784 | MainLoss:0.1784 | SPLoss:2.0263 | CLSLoss:0.1691 | AUROC:0.9827\n",
      "Test | 128/16 | Loss:0.9790 | MainLoss:0.9790 | SPLoss:2.0263 | CLSLoss:0.1691 | AUROC:0.8638\n",
      "\n",
      "Epoch: [183 | 1000] LR: 0.191650\n",
      "Train | 16/16 | Loss:0.3862 | MainLoss:0.1822 | Alpha:0.4381 | SPLoss:1.8779 | CLSLoss:0.1626 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.3511 | MainLoss:0.3511 | SPLoss:2.1337 | CLSLoss:0.1592 | AUROC:0.9835\n",
      "Test | 128/16 | Loss:0.5307 | MainLoss:0.5307 | SPLoss:2.1337 | CLSLoss:0.1592 | AUROC:0.8770\n",
      "\n",
      "Epoch: [184 | 1000] LR: 0.191524\n",
      "Train | 16/16 | Loss:0.4114 | MainLoss:0.2008 | Alpha:0.4404 | SPLoss:1.9498 | CLSLoss:0.1559 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1762 | MainLoss:0.1762 | SPLoss:1.7644 | CLSLoss:0.1546 | AUROC:0.9840\n",
      "Test | 128/16 | Loss:0.7785 | MainLoss:0.7785 | SPLoss:1.7644 | CLSLoss:0.1546 | AUROC:0.8593\n",
      "\n",
      "Epoch: [185 | 1000] LR: 0.191397\n",
      "Train | 16/16 | Loss:0.3507 | MainLoss:0.1780 | Alpha:0.4399 | SPLoss:1.5603 | CLSLoss:0.1663 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1927 | MainLoss:0.1927 | SPLoss:1.3863 | CLSLoss:0.1532 | AUROC:0.9856\n",
      "Test | 128/16 | Loss:0.6874 | MainLoss:0.6874 | SPLoss:1.3863 | CLSLoss:0.1532 | AUROC:0.8534\n",
      "\n",
      "Epoch: [186 | 1000] LR: 0.191269\n",
      "Train | 16/16 | Loss:0.3303 | MainLoss:0.1834 | Alpha:0.4390 | SPLoss:1.3038 | CLSLoss:0.1650 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1955 | MainLoss:0.1955 | SPLoss:1.2166 | CLSLoss:0.1791 | AUROC:0.9854\n",
      "Test | 128/16 | Loss:0.7705 | MainLoss:0.7705 | SPLoss:1.2166 | CLSLoss:0.1791 | AUROC:0.8754\n",
      "\n",
      "Epoch: [187 | 1000] LR: 0.191140\n",
      "Train | 16/16 | Loss:0.7255 | MainLoss:0.1895 | Alpha:0.4390 | SPLoss:5.1940 | CLSLoss:0.1657 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1619 | MainLoss:0.1619 | SPLoss:6.5864 | CLSLoss:0.1770 | AUROC:0.9863\n",
      "Test | 128/16 | Loss:0.7983 | MainLoss:0.7983 | SPLoss:6.5864 | CLSLoss:0.1770 | AUROC:0.8997\n",
      "\n",
      "Epoch: [188 | 1000] LR: 0.191011\n",
      "Train | 16/16 | Loss:0.7192 | MainLoss:0.1882 | Alpha:0.4400 | SPLoss:5.1453 | CLSLoss:0.1649 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2075 | MainLoss:0.2075 | SPLoss:3.9220 | CLSLoss:0.1435 | AUROC:0.9817\n",
      "Test | 128/16 | Loss:0.9480 | MainLoss:0.9480 | SPLoss:3.9219 | CLSLoss:0.1435 | AUROC:0.8532\n",
      "\n",
      "Epoch: [189 | 1000] LR: 0.190880\n",
      "Train | 16/16 | Loss:0.5175 | MainLoss:0.1863 | Alpha:0.4377 | SPLoss:3.1519 | CLSLoss:0.1602 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1621 | MainLoss:0.1621 | SPLoss:2.5522 | CLSLoss:0.1652 | AUROC:0.9844\n",
      "Test | 128/16 | Loss:0.8459 | MainLoss:0.8459 | SPLoss:2.5522 | CLSLoss:0.1652 | AUROC:0.8635\n",
      "\n",
      "Epoch: [190 | 1000] LR: 0.190748\n",
      "Train | 16/16 | Loss:0.4056 | MainLoss:0.1644 | Alpha:0.4404 | SPLoss:2.2404 | CLSLoss:0.1714 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1886 | MainLoss:0.1886 | SPLoss:1.8853 | CLSLoss:0.1682 | AUROC:0.9859\n",
      "Test | 128/16 | Loss:0.6365 | MainLoss:0.6365 | SPLoss:1.8853 | CLSLoss:0.1682 | AUROC:0.8887\n",
      "\n",
      "Epoch: [191 | 1000] LR: 0.190616\n",
      "Train | 16/16 | Loss:0.3483 | MainLoss:0.1702 | Alpha:0.4414 | SPLoss:1.6116 | CLSLoss:0.1692 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1627 | MainLoss:0.1627 | SPLoss:1.3420 | CLSLoss:0.1650 | AUROC:0.9856\n",
      "Test | 128/16 | Loss:0.8011 | MainLoss:0.8011 | SPLoss:1.3420 | CLSLoss:0.1650 | AUROC:0.8598\n",
      "\n",
      "Epoch: [192 | 1000] LR: 0.190483\n",
      "Train | 16/16 | Loss:0.3289 | MainLoss:0.1862 | Alpha:0.4392 | SPLoss:1.2643 | CLSLoss:0.1629 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1492 | MainLoss:0.1492 | SPLoss:1.1604 | CLSLoss:0.1696 | AUROC:0.9873\n",
      "Test | 128/16 | Loss:0.8484 | MainLoss:0.8484 | SPLoss:1.1604 | CLSLoss:0.1696 | AUROC:0.8632\n",
      "\n",
      "Epoch: [193 | 1000] LR: 0.190348\n",
      "Train | 16/16 | Loss:0.3340 | MainLoss:0.1624 | Alpha:0.4385 | SPLoss:1.5435 | CLSLoss:0.1726 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1850 | MainLoss:0.1850 | SPLoss:3.1004 | CLSLoss:0.1729 | AUROC:0.9829\n",
      "Test | 128/16 | Loss:0.7800 | MainLoss:0.7800 | SPLoss:3.1004 | CLSLoss:0.1729 | AUROC:0.8536\n",
      "\n",
      "Epoch: [194 | 1000] LR: 0.190213\n",
      "Train | 16/16 | Loss:0.5031 | MainLoss:0.1972 | Alpha:0.4397 | SPLoss:2.8945 | CLSLoss:0.1647 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1994 | MainLoss:0.1994 | SPLoss:2.6390 | CLSLoss:0.1536 | AUROC:0.9865\n",
      "Test | 128/16 | Loss:0.6943 | MainLoss:0.6943 | SPLoss:2.6390 | CLSLoss:0.1536 | AUROC:0.8542\n",
      "\n",
      "Epoch: [195 | 1000] LR: 0.190077\n",
      "Train | 16/16 | Loss:0.4084 | MainLoss:0.1569 | Alpha:0.4408 | SPLoss:2.3455 | CLSLoss:0.1698 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1843 | MainLoss:0.1843 | SPLoss:1.9612 | CLSLoss:0.1782 | AUROC:0.9840\n",
      "Test | 128/16 | Loss:1.1056 | MainLoss:1.1056 | SPLoss:1.9612 | CLSLoss:0.1782 | AUROC:0.8900\n",
      "\n",
      "Epoch: [196 | 1000] LR: 0.189941\n",
      "Train | 16/16 | Loss:0.3569 | MainLoss:0.1715 | Alpha:0.4402 | SPLoss:1.6864 | CLSLoss:0.1678 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1760 | MainLoss:0.1760 | SPLoss:1.4322 | CLSLoss:0.1662 | AUROC:0.9854\n",
      "Test | 128/16 | Loss:0.5812 | MainLoss:0.5812 | SPLoss:1.4322 | CLSLoss:0.1662 | AUROC:0.9287\n",
      "\n",
      "Epoch: [197 | 1000] LR: 0.189803\n",
      "Train | 16/16 | Loss:0.3080 | MainLoss:0.1591 | Alpha:0.4404 | SPLoss:1.3120 | CLSLoss:0.1769 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1858 | MainLoss:0.1858 | SPLoss:1.2543 | CLSLoss:0.1626 | AUROC:0.9816\n",
      "Test | 128/16 | Loss:1.1258 | MainLoss:1.1258 | SPLoss:1.2543 | CLSLoss:0.1626 | AUROC:0.8421\n",
      "\n",
      "Epoch: [198 | 1000] LR: 0.189664\n",
      "Train | 16/16 | Loss:0.3824 | MainLoss:0.1767 | Alpha:0.4381 | SPLoss:1.8979 | CLSLoss:0.1597 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1636 | MainLoss:0.1636 | SPLoss:4.0781 | CLSLoss:0.1632 | AUROC:0.9842\n",
      "Test | 128/16 | Loss:0.9671 | MainLoss:0.9671 | SPLoss:4.0781 | CLSLoss:0.1632 | AUROC:0.8777\n",
      "\n",
      "Epoch: [199 | 1000] LR: 0.189525\n",
      "Train | 16/16 | Loss:0.5074 | MainLoss:0.1663 | Alpha:0.4397 | SPLoss:3.2431 | CLSLoss:0.1680 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1869 | MainLoss:0.1869 | SPLoss:2.4768 | CLSLoss:0.1652 | AUROC:0.9843\n",
      "Test | 128/16 | Loss:0.8038 | MainLoss:0.8038 | SPLoss:2.4768 | CLSLoss:0.1652 | AUROC:0.8923\n",
      "\n",
      "Epoch: [200 | 1000] LR: 0.189384\n",
      "Train | 16/16 | Loss:0.3913 | MainLoss:0.1669 | Alpha:0.4395 | SPLoss:2.0728 | CLSLoss:0.1711 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1657 | MainLoss:0.1657 | SPLoss:1.7081 | CLSLoss:0.1521 | AUROC:0.9853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 128/16 | Loss:0.8672 | MainLoss:0.8672 | SPLoss:1.7081 | CLSLoss:0.1521 | AUROC:0.8700\n",
      "\n",
      "Epoch: [201 | 1000] LR: 0.018924\n",
      "Train | 16/16 | Loss:0.1618 | MainLoss:0.1458 | Alpha:0.4629 | SPLoss:0.0021 | CLSLoss:0.1575 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1638 | MainLoss:0.1638 | SPLoss:0.0051 | CLSLoss:0.1621 | AUROC:0.9867\n",
      "Test | 128/16 | Loss:0.8392 | MainLoss:0.8392 | SPLoss:0.0051 | CLSLoss:0.1621 | AUROC:0.8910\n",
      "\n",
      "Epoch: [202 | 1000] LR: 0.018910\n",
      "Train | 16/16 | Loss:0.1416 | MainLoss:0.1242 | Alpha:0.4662 | SPLoss:0.0079 | CLSLoss:0.1664 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:0.0115 | CLSLoss:0.1701 | AUROC:0.9865\n",
      "Test | 128/16 | Loss:0.8323 | MainLoss:0.8323 | SPLoss:0.0115 | CLSLoss:0.1701 | AUROC:0.9028\n",
      "\n",
      "Epoch: [203 | 1000] LR: 0.018896\n",
      "Train | 16/16 | Loss:0.1409 | MainLoss:0.1220 | Alpha:0.4657 | SPLoss:0.0153 | CLSLoss:0.1730 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1567 | MainLoss:0.1567 | SPLoss:0.0197 | CLSLoss:0.1736 | AUROC:0.9879\n",
      "Test | 128/16 | Loss:0.8819 | MainLoss:0.8819 | SPLoss:0.0197 | CLSLoss:0.1736 | AUROC:0.9018\n",
      "\n",
      "Epoch: [204 | 1000] LR: 0.018881\n",
      "Train | 16/16 | Loss:0.1387 | MainLoss:0.1187 | Alpha:0.4644 | SPLoss:0.0240 | CLSLoss:0.1760 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1609 | MainLoss:0.1609 | SPLoss:0.0286 | CLSLoss:0.1766 | AUROC:0.9884\n",
      "Test | 128/16 | Loss:0.8582 | MainLoss:0.8582 | SPLoss:0.0286 | CLSLoss:0.1766 | AUROC:0.9006\n",
      "\n",
      "Epoch: [205 | 1000] LR: 0.018867\n",
      "Train | 16/16 | Loss:0.1333 | MainLoss:0.1123 | Alpha:0.4643 | SPLoss:0.0328 | CLSLoss:0.1776 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1526 | MainLoss:0.1526 | SPLoss:0.0377 | CLSLoss:0.1791 | AUROC:0.9884\n",
      "Test | 128/16 | Loss:0.8899 | MainLoss:0.8899 | SPLoss:0.0377 | CLSLoss:0.1791 | AUROC:0.9095\n",
      "\n",
      "Epoch: [206 | 1000] LR: 0.018852\n",
      "Train | 16/16 | Loss:0.1349 | MainLoss:0.1127 | Alpha:0.4644 | SPLoss:0.0426 | CLSLoss:0.1788 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1452 | MainLoss:0.1452 | SPLoss:0.0468 | CLSLoss:0.1794 | AUROC:0.9887\n",
      "Test | 128/16 | Loss:0.9104 | MainLoss:0.9104 | SPLoss:0.0468 | CLSLoss:0.1794 | AUROC:0.9124\n",
      "\n",
      "Epoch: [207 | 1000] LR: 0.018838\n",
      "Train | 16/16 | Loss:0.1334 | MainLoss:0.1105 | Alpha:0.4641 | SPLoss:0.0500 | CLSLoss:0.1791 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1458 | MainLoss:0.1458 | SPLoss:0.0550 | CLSLoss:0.1795 | AUROC:0.9889\n",
      "Test | 128/16 | Loss:0.8893 | MainLoss:0.8893 | SPLoss:0.0550 | CLSLoss:0.1795 | AUROC:0.9172\n",
      "\n",
      "Epoch: [208 | 1000] LR: 0.018823\n",
      "Train | 16/16 | Loss:0.1422 | MainLoss:0.1185 | Alpha:0.4622 | SPLoss:0.0584 | CLSLoss:0.1782 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1526 | MainLoss:0.1526 | SPLoss:0.0624 | CLSLoss:0.1774 | AUROC:0.9890\n",
      "Test | 128/16 | Loss:0.8066 | MainLoss:0.8066 | SPLoss:0.0624 | CLSLoss:0.1774 | AUROC:0.9223\n",
      "\n",
      "Epoch: [209 | 1000] LR: 0.018808\n",
      "Train | 16/16 | Loss:0.1218 | MainLoss:0.0974 | Alpha:0.4655 | SPLoss:0.0654 | CLSLoss:0.1783 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1460 | MainLoss:0.1460 | SPLoss:0.0695 | CLSLoss:0.1800 | AUROC:0.9893\n",
      "Test | 128/16 | Loss:0.8833 | MainLoss:0.8833 | SPLoss:0.0695 | CLSLoss:0.1800 | AUROC:0.9240\n",
      "\n",
      "Epoch: [210 | 1000] LR: 0.018793\n",
      "Train | 16/16 | Loss:0.1162 | MainLoss:0.0909 | Alpha:0.4677 | SPLoss:0.0721 | CLSLoss:0.1810 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1514 | MainLoss:0.1514 | SPLoss:0.0756 | CLSLoss:0.1811 | AUROC:0.9889\n",
      "Test | 128/16 | Loss:0.8454 | MainLoss:0.8454 | SPLoss:0.0756 | CLSLoss:0.1811 | AUROC:0.9252\n",
      "\n",
      "Epoch: [211 | 1000] LR: 0.018778\n",
      "Train | 16/16 | Loss:0.1203 | MainLoss:0.0942 | Alpha:0.4642 | SPLoss:0.0793 | CLSLoss:0.1814 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1515 | MainLoss:0.1515 | SPLoss:0.0842 | CLSLoss:0.1812 | AUROC:0.9887\n",
      "Test | 128/16 | Loss:0.8518 | MainLoss:0.8518 | SPLoss:0.0842 | CLSLoss:0.1812 | AUROC:0.9261\n",
      "\n",
      "Epoch: [212 | 1000] LR: 0.018763\n",
      "Train | 16/16 | Loss:0.1181 | MainLoss:0.0911 | Alpha:0.4654 | SPLoss:0.0881 | CLSLoss:0.1816 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1509 | MainLoss:0.1509 | SPLoss:0.0914 | CLSLoss:0.1818 | AUROC:0.9890\n",
      "Test | 128/16 | Loss:0.8545 | MainLoss:0.8545 | SPLoss:0.0914 | CLSLoss:0.1818 | AUROC:0.9239\n",
      "\n",
      "Epoch: [213 | 1000] LR: 0.018748\n",
      "Train | 16/16 | Loss:0.1159 | MainLoss:0.0882 | Alpha:0.4653 | SPLoss:0.0947 | CLSLoss:0.1822 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1513 | MainLoss:0.1513 | SPLoss:0.0990 | CLSLoss:0.1824 | AUROC:0.9890\n",
      "Test | 128/16 | Loss:0.8322 | MainLoss:0.8322 | SPLoss:0.0990 | CLSLoss:0.1824 | AUROC:0.9269\n",
      "\n",
      "Epoch: [214 | 1000] LR: 0.018733\n",
      "Train | 16/16 | Loss:0.1169 | MainLoss:0.0883 | Alpha:0.4645 | SPLoss:0.1031 | CLSLoss:0.1826 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1504 | MainLoss:0.1504 | SPLoss:0.1067 | CLSLoss:0.1830 | AUROC:0.9889\n",
      "Test | 128/16 | Loss:0.8359 | MainLoss:0.8359 | SPLoss:0.1067 | CLSLoss:0.1830 | AUROC:0.9318\n",
      "\n",
      "Epoch: [215 | 1000] LR: 0.018717\n",
      "Train | 16/16 | Loss:0.1294 | MainLoss:0.1003 | Alpha:0.4633 | SPLoss:0.1094 | CLSLoss:0.1815 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1526 | MainLoss:0.1526 | SPLoss:0.1117 | CLSLoss:0.1800 | AUROC:0.9892\n",
      "Test | 128/16 | Loss:0.8007 | MainLoss:0.8007 | SPLoss:0.1117 | CLSLoss:0.1800 | AUROC:0.9333\n",
      "\n",
      "Epoch: [216 | 1000] LR: 0.018702\n",
      "Train | 16/16 | Loss:0.1200 | MainLoss:0.0907 | Alpha:0.4649 | SPLoss:0.1139 | CLSLoss:0.1793 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1459 | MainLoss:0.1459 | SPLoss:0.1168 | CLSLoss:0.1804 | AUROC:0.9893\n",
      "Test | 128/16 | Loss:0.8755 | MainLoss:0.8755 | SPLoss:0.1168 | CLSLoss:0.1804 | AUROC:0.9268\n",
      "\n",
      "Epoch: [217 | 1000] LR: 0.018686\n",
      "Train | 16/16 | Loss:0.1190 | MainLoss:0.0889 | Alpha:0.4638 | SPLoss:0.1209 | CLSLoss:0.1800 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1523 | MainLoss:0.1523 | SPLoss:0.1251 | CLSLoss:0.1804 | AUROC:0.9891\n",
      "Test | 128/16 | Loss:0.8005 | MainLoss:0.8005 | SPLoss:0.1251 | CLSLoss:0.1804 | AUROC:0.9349\n",
      "\n",
      "Epoch: [218 | 1000] LR: 0.018671\n",
      "Train | 16/16 | Loss:0.1190 | MainLoss:0.0881 | Alpha:0.4634 | SPLoss:0.1295 | CLSLoss:0.1799 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1509 | MainLoss:0.1509 | SPLoss:0.1324 | CLSLoss:0.1800 | AUROC:0.9894\n",
      "Test | 128/16 | Loss:0.8160 | MainLoss:0.8160 | SPLoss:0.1324 | CLSLoss:0.1800 | AUROC:0.9316\n",
      "\n",
      "Epoch: [219 | 1000] LR: 0.018655\n",
      "Train | 16/16 | Loss:0.1402 | MainLoss:0.1089 | Alpha:0.4602 | SPLoss:0.1362 | CLSLoss:0.1767 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1459 | MainLoss:0.1459 | SPLoss:0.1393 | CLSLoss:0.1748 | AUROC:0.9894\n",
      "Test | 128/16 | Loss:0.8298 | MainLoss:0.8298 | SPLoss:0.1393 | CLSLoss:0.1748 | AUROC:0.9283\n",
      "\n",
      "Epoch: [220 | 1000] LR: 0.018639\n",
      "Train | 16/16 | Loss:0.1249 | MainLoss:0.0931 | Alpha:0.4630 | SPLoss:0.1429 | CLSLoss:0.1752 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1509 | MainLoss:0.1509 | SPLoss:0.1465 | CLSLoss:0.1744 | AUROC:0.9895\n",
      "Test | 128/16 | Loss:0.7858 | MainLoss:0.7858 | SPLoss:0.1465 | CLSLoss:0.1744 | AUROC:0.9300\n",
      "\n",
      "Epoch: [221 | 1000] LR: 0.018623\n",
      "Train | 16/16 | Loss:0.1158 | MainLoss:0.0836 | Alpha:0.4658 | SPLoss:0.1477 | CLSLoss:0.1744 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1504 | MainLoss:0.1504 | SPLoss:0.1505 | CLSLoss:0.1755 | AUROC:0.9899\n",
      "Test | 128/16 | Loss:0.7924 | MainLoss:0.7924 | SPLoss:0.1505 | CLSLoss:0.1755 | AUROC:0.9298\n",
      "\n",
      "Epoch: [222 | 1000] LR: 0.018607\n",
      "Train | 16/16 | Loss:0.1191 | MainLoss:0.0863 | Alpha:0.4641 | SPLoss:0.1527 | CLSLoss:0.1757 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1420 | MainLoss:0.1420 | SPLoss:0.1548 | CLSLoss:0.1759 | AUROC:0.9894\n",
      "Test | 128/16 | Loss:0.8615 | MainLoss:0.8615 | SPLoss:0.1548 | CLSLoss:0.1759 | AUROC:0.9318\n",
      "\n",
      "Epoch: [223 | 1000] LR: 0.018591\n",
      "Train | 16/16 | Loss:0.1233 | MainLoss:0.0898 | Alpha:0.4628 | SPLoss:0.1595 | CLSLoss:0.1759 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1480 | MainLoss:0.1480 | SPLoss:0.1633 | CLSLoss:0.1759 | AUROC:0.9892\n",
      "Test | 128/16 | Loss:0.7999 | MainLoss:0.7999 | SPLoss:0.1633 | CLSLoss:0.1759 | AUROC:0.9353\n",
      "\n",
      "Epoch: [224 | 1000] LR: 0.018575\n",
      "Train | 16/16 | Loss:0.1119 | MainLoss:0.0777 | Alpha:0.4644 | SPLoss:0.1646 | CLSLoss:0.1771 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1539 | MainLoss:0.1539 | SPLoss:0.1691 | CLSLoss:0.1773 | AUROC:0.9894\n",
      "Test | 128/16 | Loss:0.7397 | MainLoss:0.7397 | SPLoss:0.1691 | CLSLoss:0.1773 | AUROC:0.9404\n",
      "\n",
      "Epoch: [225 | 1000] LR: 0.018559\n",
      "Train | 16/16 | Loss:0.1215 | MainLoss:0.0867 | Alpha:0.4633 | SPLoss:0.1707 | CLSLoss:0.1766 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1429 | MainLoss:0.1429 | SPLoss:0.1726 | CLSLoss:0.1763 | AUROC:0.9893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 128/16 | Loss:0.8354 | MainLoss:0.8354 | SPLoss:0.1726 | CLSLoss:0.1763 | AUROC:0.9370\n",
      "\n",
      "Epoch: [226 | 1000] LR: 0.018543\n",
      "Train | 16/16 | Loss:0.1152 | MainLoss:0.0801 | Alpha:0.4652 | SPLoss:0.1751 | CLSLoss:0.1766 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1489 | MainLoss:0.1489 | SPLoss:0.1764 | CLSLoss:0.1766 | AUROC:0.9896\n",
      "Test | 128/16 | Loss:0.8019 | MainLoss:0.8019 | SPLoss:0.1764 | CLSLoss:0.1766 | AUROC:0.9387\n",
      "\n",
      "Epoch: [227 | 1000] LR: 0.018526\n",
      "Train | 16/16 | Loss:0.1132 | MainLoss:0.0777 | Alpha:0.4652 | SPLoss:0.1783 | CLSLoss:0.1769 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1503 | MainLoss:0.1503 | SPLoss:0.1796 | CLSLoss:0.1765 | AUROC:0.9897\n",
      "Test | 128/16 | Loss:0.7960 | MainLoss:0.7960 | SPLoss:0.1796 | CLSLoss:0.1765 | AUROC:0.9399\n",
      "\n",
      "Epoch: [228 | 1000] LR: 0.018510\n",
      "Train | 16/16 | Loss:0.1132 | MainLoss:0.0774 | Alpha:0.4650 | SPLoss:0.1816 | CLSLoss:0.1764 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1448 | MainLoss:0.1448 | SPLoss:0.1833 | CLSLoss:0.1759 | AUROC:0.9900\n",
      "Test | 128/16 | Loss:0.8165 | MainLoss:0.8165 | SPLoss:0.1833 | CLSLoss:0.1759 | AUROC:0.9374\n",
      "\n",
      "Epoch: [229 | 1000] LR: 0.018493\n",
      "Train | 16/16 | Loss:0.1165 | MainLoss:0.0802 | Alpha:0.4647 | SPLoss:0.1871 | CLSLoss:0.1762 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1462 | MainLoss:0.1462 | SPLoss:0.1888 | CLSLoss:0.1754 | AUROC:0.9900\n",
      "Test | 128/16 | Loss:0.8166 | MainLoss:0.8166 | SPLoss:0.1888 | CLSLoss:0.1754 | AUROC:0.9363\n",
      "\n",
      "Epoch: [230 | 1000] LR: 0.018477\n",
      "Train | 16/16 | Loss:0.1223 | MainLoss:0.0859 | Alpha:0.4630 | SPLoss:0.1898 | CLSLoss:0.1749 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1458 | MainLoss:0.1458 | SPLoss:0.1919 | CLSLoss:0.1734 | AUROC:0.9901\n",
      "Test | 128/16 | Loss:0.7703 | MainLoss:0.7703 | SPLoss:0.1919 | CLSLoss:0.1734 | AUROC:0.9396\n",
      "\n",
      "Epoch: [231 | 1000] LR: 0.018460\n",
      "Train | 16/16 | Loss:0.1114 | MainLoss:0.0745 | Alpha:0.4643 | SPLoss:0.1941 | CLSLoss:0.1749 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1435 | MainLoss:0.1435 | SPLoss:0.1955 | CLSLoss:0.1749 | AUROC:0.9900\n",
      "Test | 128/16 | Loss:0.8079 | MainLoss:0.8079 | SPLoss:0.1955 | CLSLoss:0.1749 | AUROC:0.9368\n",
      "\n",
      "Epoch: [232 | 1000] LR: 0.018443\n",
      "Train | 16/16 | Loss:0.1228 | MainLoss:0.0855 | Alpha:0.4637 | SPLoss:0.1978 | CLSLoss:0.1747 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1433 | MainLoss:0.1433 | SPLoss:0.1998 | CLSLoss:0.1731 | AUROC:0.9897\n",
      "Test | 128/16 | Loss:0.8107 | MainLoss:0.8107 | SPLoss:0.1998 | CLSLoss:0.1731 | AUROC:0.9360\n",
      "\n",
      "Epoch: [233 | 1000] LR: 0.018426\n",
      "Train | 16/16 | Loss:0.1072 | MainLoss:0.0697 | Alpha:0.4654 | SPLoss:0.2009 | CLSLoss:0.1736 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1476 | MainLoss:0.1476 | SPLoss:0.2022 | CLSLoss:0.1751 | AUROC:0.9899\n",
      "Test | 128/16 | Loss:0.8107 | MainLoss:0.8107 | SPLoss:0.2022 | CLSLoss:0.1751 | AUROC:0.9369\n",
      "\n",
      "Epoch: [234 | 1000] LR: 0.018409\n",
      "Train | 16/16 | Loss:0.1161 | MainLoss:0.0782 | Alpha:0.4637 | SPLoss:0.2044 | CLSLoss:0.1748 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1511 | MainLoss:0.1511 | SPLoss:0.2066 | CLSLoss:0.1754 | AUROC:0.9899\n",
      "Test | 128/16 | Loss:0.7774 | MainLoss:0.7774 | SPLoss:0.2066 | CLSLoss:0.1754 | AUROC:0.9397\n",
      "\n",
      "Epoch: [235 | 1000] LR: 0.018392\n",
      "Train | 16/16 | Loss:0.1113 | MainLoss:0.0729 | Alpha:0.4647 | SPLoss:0.2086 | CLSLoss:0.1753 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1510 | MainLoss:0.1510 | SPLoss:0.2097 | CLSLoss:0.1761 | AUROC:0.9897\n",
      "Test | 128/16 | Loss:0.7771 | MainLoss:0.7771 | SPLoss:0.2097 | CLSLoss:0.1761 | AUROC:0.9437\n",
      "\n",
      "Epoch: [236 | 1000] LR: 0.018375\n",
      "Train | 16/16 | Loss:0.1256 | MainLoss:0.0869 | Alpha:0.4625 | SPLoss:0.2122 | CLSLoss:0.1749 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1439 | MainLoss:0.1439 | SPLoss:0.2130 | CLSLoss:0.1735 | AUROC:0.9898\n",
      "Test | 128/16 | Loss:0.7921 | MainLoss:0.7921 | SPLoss:0.2130 | CLSLoss:0.1735 | AUROC:0.9494\n",
      "\n",
      "Epoch: [237 | 1000] LR: 0.018358\n",
      "Train | 16/16 | Loss:0.1066 | MainLoss:0.0676 | Alpha:0.4650 | SPLoss:0.2155 | CLSLoss:0.1747 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1504 | MainLoss:0.1504 | SPLoss:0.2166 | CLSLoss:0.1760 | AUROC:0.9898\n",
      "Test | 128/16 | Loss:0.7634 | MainLoss:0.7634 | SPLoss:0.2166 | CLSLoss:0.1760 | AUROC:0.9541\n",
      "\n",
      "Epoch: [238 | 1000] LR: 0.018341\n",
      "Train | 16/16 | Loss:0.1131 | MainLoss:0.0738 | Alpha:0.4660 | SPLoss:0.2170 | CLSLoss:0.1759 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1467 | MainLoss:0.1467 | SPLoss:0.2162 | CLSLoss:0.1752 | AUROC:0.9897\n",
      "Test | 128/16 | Loss:0.8177 | MainLoss:0.8177 | SPLoss:0.2162 | CLSLoss:0.1752 | AUROC:0.9466\n",
      "\n",
      "Epoch: [239 | 1000] LR: 0.018323\n",
      "Train | 16/16 | Loss:0.1188 | MainLoss:0.0796 | Alpha:0.4628 | SPLoss:0.2177 | CLSLoss:0.1743 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1443 | MainLoss:0.1443 | SPLoss:0.2193 | CLSLoss:0.1741 | AUROC:0.9901\n",
      "Test | 128/16 | Loss:0.7993 | MainLoss:0.7993 | SPLoss:0.2193 | CLSLoss:0.1741 | AUROC:0.9474\n",
      "\n",
      "Epoch: [240 | 1000] LR: 0.018306\n",
      "Train | 16/16 | Loss:0.1092 | MainLoss:0.0697 | Alpha:0.4667 | SPLoss:0.2200 | CLSLoss:0.1750 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1480 | MainLoss:0.1480 | SPLoss:0.2180 | CLSLoss:0.1745 | AUROC:0.9897\n",
      "Test | 128/16 | Loss:0.7868 | MainLoss:0.7868 | SPLoss:0.2180 | CLSLoss:0.1745 | AUROC:0.9433\n",
      "\n",
      "Epoch: [241 | 1000] LR: 0.018288\n",
      "Train | 16/16 | Loss:0.1219 | MainLoss:0.0828 | Alpha:0.4635 | SPLoss:0.2179 | CLSLoss:0.1730 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1507 | MainLoss:0.1507 | SPLoss:0.2197 | CLSLoss:0.1723 | AUROC:0.9896\n",
      "Test | 128/16 | Loss:0.7608 | MainLoss:0.7608 | SPLoss:0.2197 | CLSLoss:0.1723 | AUROC:0.9462\n",
      "\n",
      "Epoch: [242 | 1000] LR: 0.018271\n",
      "Train | 16/16 | Loss:0.1108 | MainLoss:0.0715 | Alpha:0.4660 | SPLoss:0.2202 | CLSLoss:0.1724 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1500 | MainLoss:0.1500 | SPLoss:0.2215 | CLSLoss:0.1734 | AUROC:0.9901\n",
      "Test | 128/16 | Loss:0.7679 | MainLoss:0.7679 | SPLoss:0.2215 | CLSLoss:0.1734 | AUROC:0.9453\n",
      "\n",
      "Epoch: [243 | 1000] LR: 0.018253\n",
      "Train | 16/16 | Loss:0.1150 | MainLoss:0.0755 | Alpha:0.4647 | SPLoss:0.2218 | CLSLoss:0.1724 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1442 | MainLoss:0.1442 | SPLoss:0.2232 | CLSLoss:0.1727 | AUROC:0.9899\n",
      "Test | 128/16 | Loss:0.8387 | MainLoss:0.8387 | SPLoss:0.2232 | CLSLoss:0.1727 | AUROC:0.9335\n",
      "\n",
      "Epoch: [244 | 1000] LR: 0.018235\n",
      "Train | 16/16 | Loss:0.1288 | MainLoss:0.0893 | Alpha:0.4612 | SPLoss:0.2230 | CLSLoss:0.1720 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.2241 | CLSLoss:0.1696 | AUROC:0.9902\n",
      "Test | 128/16 | Loss:0.8256 | MainLoss:0.8256 | SPLoss:0.2241 | CLSLoss:0.1696 | AUROC:0.9339\n",
      "\n",
      "Epoch: [245 | 1000] LR: 0.018217\n",
      "Train | 16/16 | Loss:0.1147 | MainLoss:0.0751 | Alpha:0.4642 | SPLoss:0.2263 | CLSLoss:0.1699 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1413 | MainLoss:0.1413 | SPLoss:0.2271 | CLSLoss:0.1704 | AUROC:0.9898\n",
      "Test | 128/16 | Loss:0.8643 | MainLoss:0.8643 | SPLoss:0.2271 | CLSLoss:0.1704 | AUROC:0.9365\n",
      "\n",
      "Epoch: [246 | 1000] LR: 0.018200\n",
      "Train | 16/16 | Loss:0.1164 | MainLoss:0.0764 | Alpha:0.4640 | SPLoss:0.2293 | CLSLoss:0.1705 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1476 | MainLoss:0.1476 | SPLoss:0.2301 | CLSLoss:0.1710 | AUROC:0.9899\n",
      "Test | 128/16 | Loss:0.7680 | MainLoss:0.7680 | SPLoss:0.2301 | CLSLoss:0.1710 | AUROC:0.9440\n",
      "\n",
      "Epoch: [247 | 1000] LR: 0.018181\n",
      "Train | 16/16 | Loss:0.1155 | MainLoss:0.0751 | Alpha:0.4644 | SPLoss:0.2316 | CLSLoss:0.1721 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1459 | MainLoss:0.1459 | SPLoss:0.2330 | CLSLoss:0.1709 | AUROC:0.9897\n",
      "Test | 128/16 | Loss:0.7720 | MainLoss:0.7720 | SPLoss:0.2330 | CLSLoss:0.1709 | AUROC:0.9488\n",
      "\n",
      "Epoch: [248 | 1000] LR: 0.018163\n",
      "Train | 16/16 | Loss:0.1094 | MainLoss:0.0688 | Alpha:0.4671 | SPLoss:0.2344 | CLSLoss:0.1715 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1467 | MainLoss:0.1467 | SPLoss:0.2347 | CLSLoss:0.1715 | AUROC:0.9898\n",
      "Test | 128/16 | Loss:0.7765 | MainLoss:0.7765 | SPLoss:0.2347 | CLSLoss:0.1715 | AUROC:0.9469\n",
      "\n",
      "Epoch: [249 | 1000] LR: 0.018145\n",
      "Train | 16/16 | Loss:0.1144 | MainLoss:0.0738 | Alpha:0.4638 | SPLoss:0.2351 | CLSLoss:0.1715 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1473 | MainLoss:0.1473 | SPLoss:0.2373 | CLSLoss:0.1720 | AUROC:0.9901\n",
      "Test | 128/16 | Loss:0.7494 | MainLoss:0.7494 | SPLoss:0.2373 | CLSLoss:0.1720 | AUROC:0.9483\n",
      "\n",
      "Epoch: [250 | 1000] LR: 0.018127\n",
      "Train | 16/16 | Loss:0.1074 | MainLoss:0.0664 | Alpha:0.4663 | SPLoss:0.2369 | CLSLoss:0.1728 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1442 | MainLoss:0.1442 | SPLoss:0.2348 | CLSLoss:0.1730 | AUROC:0.9899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 128/16 | Loss:0.8313 | MainLoss:0.8313 | SPLoss:0.2348 | CLSLoss:0.1730 | AUROC:0.9390\n",
      "\n",
      "Epoch: [251 | 1000] LR: 0.018109\n",
      "Train | 16/16 | Loss:0.1195 | MainLoss:0.0787 | Alpha:0.4643 | SPLoss:0.2358 | CLSLoss:0.1721 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1466 | MainLoss:0.1466 | SPLoss:0.2352 | CLSLoss:0.1714 | AUROC:0.9898\n",
      "Test | 128/16 | Loss:0.8110 | MainLoss:0.8110 | SPLoss:0.2352 | CLSLoss:0.1714 | AUROC:0.9370\n",
      "\n",
      "Epoch: [252 | 1000] LR: 0.018090\n",
      "Train | 16/16 | Loss:0.1122 | MainLoss:0.0715 | Alpha:0.4643 | SPLoss:0.2357 | CLSLoss:0.1714 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1450 | MainLoss:0.1450 | SPLoss:0.2360 | CLSLoss:0.1714 | AUROC:0.9902\n",
      "Test | 128/16 | Loss:0.8010 | MainLoss:0.8010 | SPLoss:0.2360 | CLSLoss:0.1714 | AUROC:0.9387\n",
      "\n",
      "Epoch: [253 | 1000] LR: 0.018072\n",
      "Train | 16/16 | Loss:0.1043 | MainLoss:0.0635 | Alpha:0.4663 | SPLoss:0.2362 | CLSLoss:0.1720 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1458 | MainLoss:0.1458 | SPLoss:0.2364 | CLSLoss:0.1727 | AUROC:0.9897\n",
      "Test | 128/16 | Loss:0.8163 | MainLoss:0.8163 | SPLoss:0.2364 | CLSLoss:0.1727 | AUROC:0.9374\n",
      "\n",
      "Epoch: [254 | 1000] LR: 0.018053\n",
      "Train | 16/16 | Loss:0.1139 | MainLoss:0.0729 | Alpha:0.4645 | SPLoss:0.2392 | CLSLoss:0.1715 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1409 | MainLoss:0.1409 | SPLoss:0.2407 | CLSLoss:0.1716 | AUROC:0.9899\n",
      "Test | 128/16 | Loss:0.8345 | MainLoss:0.8345 | SPLoss:0.2407 | CLSLoss:0.1716 | AUROC:0.9399\n",
      "\n",
      "Epoch: [255 | 1000] LR: 0.018034\n",
      "Train | 16/16 | Loss:0.1042 | MainLoss:0.0628 | Alpha:0.4656 | SPLoss:0.2411 | CLSLoss:0.1725 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1470 | MainLoss:0.1470 | SPLoss:0.2443 | CLSLoss:0.1734 | AUROC:0.9899\n",
      "Test | 128/16 | Loss:0.7846 | MainLoss:0.7846 | SPLoss:0.2443 | CLSLoss:0.1734 | AUROC:0.9453\n",
      "\n",
      "Epoch: [256 | 1000] LR: 0.018016\n",
      "Train | 16/16 | Loss:0.1147 | MainLoss:0.0731 | Alpha:0.4645 | SPLoss:0.2447 | CLSLoss:0.1721 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1418 | MainLoss:0.1418 | SPLoss:0.2452 | CLSLoss:0.1716 | AUROC:0.9900\n",
      "Test | 128/16 | Loss:0.8676 | MainLoss:0.8676 | SPLoss:0.2452 | CLSLoss:0.1716 | AUROC:0.9406\n",
      "\n",
      "Epoch: [257 | 1000] LR: 0.017997\n",
      "Train | 16/16 | Loss:0.1090 | MainLoss:0.0672 | Alpha:0.4647 | SPLoss:0.2459 | CLSLoss:0.1716 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1532 | MainLoss:0.1532 | SPLoss:0.2463 | CLSLoss:0.1722 | AUROC:0.9894\n",
      "Test | 128/16 | Loss:0.7616 | MainLoss:0.7616 | SPLoss:0.2463 | CLSLoss:0.1722 | AUROC:0.9473\n",
      "\n",
      "Epoch: [258 | 1000] LR: 0.017978\n",
      "Train | 16/16 | Loss:0.1223 | MainLoss:0.0805 | Alpha:0.4626 | SPLoss:0.2469 | CLSLoss:0.1709 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1508 | MainLoss:0.1508 | SPLoss:0.2473 | CLSLoss:0.1705 | AUROC:0.9901\n",
      "Test | 128/16 | Loss:0.8120 | MainLoss:0.8120 | SPLoss:0.2473 | CLSLoss:0.1705 | AUROC:0.9358\n",
      "\n",
      "Epoch: [259 | 1000] LR: 0.017959\n",
      "Train | 16/16 | Loss:0.1144 | MainLoss:0.0728 | Alpha:0.4658 | SPLoss:0.2466 | CLSLoss:0.1697 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1484 | MainLoss:0.1484 | SPLoss:0.2463 | CLSLoss:0.1698 | AUROC:0.9903\n",
      "Test | 128/16 | Loss:0.8055 | MainLoss:0.8055 | SPLoss:0.2463 | CLSLoss:0.1698 | AUROC:0.9381\n",
      "\n",
      "Epoch: [260 | 1000] LR: 0.017940\n",
      "Train | 16/16 | Loss:0.1173 | MainLoss:0.0756 | Alpha:0.4638 | SPLoss:0.2472 | CLSLoss:0.1696 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1495 | MainLoss:0.1495 | SPLoss:0.2480 | CLSLoss:0.1692 | AUROC:0.9900\n",
      "Test | 128/16 | Loss:0.7972 | MainLoss:0.7972 | SPLoss:0.2480 | CLSLoss:0.1692 | AUROC:0.9370\n",
      "\n",
      "Epoch: [261 | 1000] LR: 0.017921\n",
      "Train | 16/16 | Loss:0.1214 | MainLoss:0.0798 | Alpha:0.4626 | SPLoss:0.2491 | CLSLoss:0.1678 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1427 | MainLoss:0.1427 | SPLoss:0.2497 | CLSLoss:0.1678 | AUROC:0.9899\n",
      "Test | 128/16 | Loss:0.8251 | MainLoss:0.8251 | SPLoss:0.2497 | CLSLoss:0.1678 | AUROC:0.9384\n",
      "\n",
      "Epoch: [262 | 1000] LR: 0.017902\n",
      "Train | 16/16 | Loss:0.1023 | MainLoss:0.0603 | Alpha:0.4654 | SPLoss:0.2503 | CLSLoss:0.1694 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1467 | MainLoss:0.1467 | SPLoss:0.2526 | CLSLoss:0.1713 | AUROC:0.9902\n",
      "Test | 128/16 | Loss:0.7964 | MainLoss:0.7964 | SPLoss:0.2526 | CLSLoss:0.1713 | AUROC:0.9430\n",
      "\n",
      "Epoch: [263 | 1000] LR: 0.017882\n",
      "Train | 16/16 | Loss:0.1179 | MainLoss:0.0756 | Alpha:0.4638 | SPLoss:0.2536 | CLSLoss:0.1698 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1540 | MainLoss:0.1540 | SPLoss:0.2541 | CLSLoss:0.1693 | AUROC:0.9904\n",
      "Test | 128/16 | Loss:0.7325 | MainLoss:0.7325 | SPLoss:0.2541 | CLSLoss:0.1693 | AUROC:0.9483\n",
      "\n",
      "Epoch: [264 | 1000] LR: 0.017863\n",
      "Train | 16/16 | Loss:0.1086 | MainLoss:0.0663 | Alpha:0.4654 | SPLoss:0.2527 | CLSLoss:0.1703 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1539 | MainLoss:0.1539 | SPLoss:0.2539 | CLSLoss:0.1704 | AUROC:0.9898\n",
      "Test | 128/16 | Loss:0.7344 | MainLoss:0.7344 | SPLoss:0.2539 | CLSLoss:0.1704 | AUROC:0.9508\n",
      "\n",
      "Epoch: [265 | 1000] LR: 0.017843\n",
      "Train | 16/16 | Loss:0.1176 | MainLoss:0.0753 | Alpha:0.4640 | SPLoss:0.2541 | CLSLoss:0.1689 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1462 | MainLoss:0.1462 | SPLoss:0.2533 | CLSLoss:0.1694 | AUROC:0.9900\n",
      "Test | 128/16 | Loss:0.7798 | MainLoss:0.7798 | SPLoss:0.2533 | CLSLoss:0.1694 | AUROC:0.9492\n",
      "\n",
      "Epoch: [266 | 1000] LR: 0.017824\n",
      "Train | 16/16 | Loss:0.1058 | MainLoss:0.0634 | Alpha:0.4649 | SPLoss:0.2545 | CLSLoss:0.1696 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1480 | MainLoss:0.1480 | SPLoss:0.2556 | CLSLoss:0.1715 | AUROC:0.9898\n",
      "Test | 128/16 | Loss:0.8158 | MainLoss:0.8158 | SPLoss:0.2556 | CLSLoss:0.1715 | AUROC:0.9449\n",
      "\n",
      "Epoch: [267 | 1000] LR: 0.017804\n",
      "Train | 16/16 | Loss:0.1259 | MainLoss:0.0831 | Alpha:0.4627 | SPLoss:0.2568 | CLSLoss:0.1708 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1478 | MainLoss:0.1478 | SPLoss:0.2573 | CLSLoss:0.1677 | AUROC:0.9903\n",
      "Test | 128/16 | Loss:0.7602 | MainLoss:0.7602 | SPLoss:0.2573 | CLSLoss:0.1677 | AUROC:0.9436\n",
      "\n",
      "Epoch: [268 | 1000] LR: 0.017785\n",
      "Train | 16/16 | Loss:0.1202 | MainLoss:0.0776 | Alpha:0.4634 | SPLoss:0.2586 | CLSLoss:0.1671 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1468 | MainLoss:0.1468 | SPLoss:0.2595 | CLSLoss:0.1680 | AUROC:0.9900\n",
      "Test | 128/16 | Loss:0.8075 | MainLoss:0.8075 | SPLoss:0.2595 | CLSLoss:0.1680 | AUROC:0.9398\n",
      "\n",
      "Epoch: [269 | 1000] LR: 0.017765\n",
      "Train | 16/16 | Loss:0.1050 | MainLoss:0.0621 | Alpha:0.4652 | SPLoss:0.2603 | CLSLoss:0.1691 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1476 | MainLoss:0.1476 | SPLoss:0.2607 | CLSLoss:0.1711 | AUROC:0.9901\n",
      "Test | 128/16 | Loss:0.8044 | MainLoss:0.8044 | SPLoss:0.2607 | CLSLoss:0.1711 | AUROC:0.9459\n",
      "\n",
      "Epoch: [270 | 1000] LR: 0.017745\n",
      "Train | 16/16 | Loss:0.1149 | MainLoss:0.0717 | Alpha:0.4641 | SPLoss:0.2627 | CLSLoss:0.1699 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1538 | MainLoss:0.1538 | SPLoss:0.2628 | CLSLoss:0.1702 | AUROC:0.9899\n",
      "Test | 128/16 | Loss:0.7419 | MainLoss:0.7419 | SPLoss:0.2628 | CLSLoss:0.1702 | AUROC:0.9500\n",
      "\n",
      "Epoch: [271 | 1000] LR: 0.017725\n",
      "Train | 16/16 | Loss:0.1242 | MainLoss:0.0808 | Alpha:0.4618 | SPLoss:0.2642 | CLSLoss:0.1697 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1521 | MainLoss:0.1521 | SPLoss:0.2669 | CLSLoss:0.1674 | AUROC:0.9898\n",
      "Test | 128/16 | Loss:0.7091 | MainLoss:0.7091 | SPLoss:0.2669 | CLSLoss:0.1674 | AUROC:0.9524\n",
      "\n",
      "Epoch: [272 | 1000] LR: 0.017705\n",
      "Train | 16/16 | Loss:0.1304 | MainLoss:0.0873 | Alpha:0.4634 | SPLoss:0.2662 | CLSLoss:0.1656 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1483 | MainLoss:0.1483 | SPLoss:0.2654 | CLSLoss:0.1647 | AUROC:0.9903\n",
      "Test | 128/16 | Loss:0.7191 | MainLoss:0.7191 | SPLoss:0.2654 | CLSLoss:0.1647 | AUROC:0.9478\n",
      "\n",
      "Epoch: [273 | 1000] LR: 0.017685\n",
      "Train | 16/16 | Loss:0.1201 | MainLoss:0.0771 | Alpha:0.4633 | SPLoss:0.2650 | CLSLoss:0.1647 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1443 | MainLoss:0.1443 | SPLoss:0.2649 | CLSLoss:0.1652 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:0.7738 | MainLoss:0.7738 | SPLoss:0.2649 | CLSLoss:0.1652 | AUROC:0.9449\n",
      "\n",
      "Epoch: [274 | 1000] LR: 0.017665\n",
      "Train | 16/16 | Loss:0.1038 | MainLoss:0.0604 | Alpha:0.4661 | SPLoss:0.2663 | CLSLoss:0.1673 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1546 | MainLoss:0.1546 | SPLoss:0.2657 | CLSLoss:0.1685 | AUROC:0.9900\n",
      "Test | 128/16 | Loss:0.7255 | MainLoss:0.7255 | SPLoss:0.2657 | CLSLoss:0.1685 | AUROC:0.9516\n",
      "\n",
      "Epoch: [275 | 1000] LR: 0.017645\n",
      "Train | 16/16 | Loss:0.1192 | MainLoss:0.0757 | Alpha:0.4632 | SPLoss:0.2664 | CLSLoss:0.1686 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1475 | MainLoss:0.1475 | SPLoss:0.2663 | CLSLoss:0.1674 | AUROC:0.9902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 128/16 | Loss:0.7624 | MainLoss:0.7624 | SPLoss:0.2663 | CLSLoss:0.1674 | AUROC:0.9518\n",
      "\n",
      "Epoch: [276 | 1000] LR: 0.017624\n",
      "Train | 16/16 | Loss:0.1072 | MainLoss:0.0638 | Alpha:0.4660 | SPLoss:0.2657 | CLSLoss:0.1682 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1443 | MainLoss:0.1443 | SPLoss:0.2651 | CLSLoss:0.1694 | AUROC:0.9903\n",
      "Test | 128/16 | Loss:0.8126 | MainLoss:0.8126 | SPLoss:0.2651 | CLSLoss:0.1694 | AUROC:0.9493\n",
      "\n",
      "Epoch: [277 | 1000] LR: 0.017604\n",
      "Train | 16/16 | Loss:0.1047 | MainLoss:0.0611 | Alpha:0.4646 | SPLoss:0.2659 | CLSLoss:0.1705 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1485 | MainLoss:0.1485 | SPLoss:0.2667 | CLSLoss:0.1715 | AUROC:0.9901\n",
      "Test | 128/16 | Loss:0.7687 | MainLoss:0.7687 | SPLoss:0.2667 | CLSLoss:0.1715 | AUROC:0.9521\n",
      "\n",
      "Epoch: [278 | 1000] LR: 0.017584\n",
      "Train | 16/16 | Loss:0.1055 | MainLoss:0.0616 | Alpha:0.4650 | SPLoss:0.2670 | CLSLoss:0.1718 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1577 | MainLoss:0.1577 | SPLoss:0.2681 | CLSLoss:0.1725 | AUROC:0.9898\n",
      "Test | 128/16 | Loss:0.6977 | MainLoss:0.6977 | SPLoss:0.2681 | CLSLoss:0.1725 | AUROC:0.9573\n",
      "\n",
      "Epoch: [279 | 1000] LR: 0.017563\n",
      "Train | 16/16 | Loss:0.1123 | MainLoss:0.0685 | Alpha:0.4650 | SPLoss:0.2670 | CLSLoss:0.1705 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1566 | MainLoss:0.1566 | SPLoss:0.2661 | CLSLoss:0.1715 | AUROC:0.9900\n",
      "Test | 128/16 | Loss:0.7240 | MainLoss:0.7240 | SPLoss:0.2661 | CLSLoss:0.1715 | AUROC:0.9540\n",
      "\n",
      "Epoch: [280 | 1000] LR: 0.017543\n",
      "Train | 16/16 | Loss:0.1210 | MainLoss:0.0775 | Alpha:0.4635 | SPLoss:0.2652 | CLSLoss:0.1695 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1421 | MainLoss:0.1421 | SPLoss:0.2652 | CLSLoss:0.1677 | AUROC:0.9900\n",
      "Test | 128/16 | Loss:0.7891 | MainLoss:0.7891 | SPLoss:0.2652 | CLSLoss:0.1677 | AUROC:0.9533\n",
      "\n",
      "Epoch: [281 | 1000] LR: 0.017522\n",
      "Train | 16/16 | Loss:0.1122 | MainLoss:0.0688 | Alpha:0.4653 | SPLoss:0.2663 | CLSLoss:0.1676 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1452 | MainLoss:0.1452 | SPLoss:0.2662 | CLSLoss:0.1683 | AUROC:0.9904\n",
      "Test | 128/16 | Loss:0.7512 | MainLoss:0.7512 | SPLoss:0.2662 | CLSLoss:0.1683 | AUROC:0.9519\n",
      "\n",
      "Epoch: [282 | 1000] LR: 0.017501\n",
      "Train | 16/16 | Loss:0.1062 | MainLoss:0.0627 | Alpha:0.4648 | SPLoss:0.2662 | CLSLoss:0.1688 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1444 | MainLoss:0.1444 | SPLoss:0.2670 | CLSLoss:0.1699 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:0.7997 | MainLoss:0.7997 | SPLoss:0.2670 | CLSLoss:0.1699 | AUROC:0.9473\n",
      "\n",
      "Epoch: [283 | 1000] LR: 0.017480\n",
      "Train | 16/16 | Loss:0.1057 | MainLoss:0.0619 | Alpha:0.4639 | SPLoss:0.2674 | CLSLoss:0.1701 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1479 | MainLoss:0.1479 | SPLoss:0.2683 | CLSLoss:0.1704 | AUROC:0.9902\n",
      "Test | 128/16 | Loss:0.7863 | MainLoss:0.7863 | SPLoss:0.2683 | CLSLoss:0.1704 | AUROC:0.9494\n",
      "\n",
      "Epoch: [284 | 1000] LR: 0.017459\n",
      "Train | 16/16 | Loss:0.1166 | MainLoss:0.0728 | Alpha:0.4647 | SPLoss:0.2678 | CLSLoss:0.1699 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1500 | MainLoss:0.1500 | SPLoss:0.2681 | CLSLoss:0.1689 | AUROC:0.9903\n",
      "Test | 128/16 | Loss:0.7647 | MainLoss:0.7647 | SPLoss:0.2681 | CLSLoss:0.1689 | AUROC:0.9484\n",
      "\n",
      "Epoch: [285 | 1000] LR: 0.017438\n",
      "Train | 16/16 | Loss:0.1153 | MainLoss:0.0718 | Alpha:0.4656 | SPLoss:0.2674 | CLSLoss:0.1679 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1432 | MainLoss:0.1432 | SPLoss:0.2652 | CLSLoss:0.1677 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:0.8010 | MainLoss:0.8010 | SPLoss:0.2652 | CLSLoss:0.1677 | AUROC:0.9444\n",
      "\n",
      "Epoch: [286 | 1000] LR: 0.017417\n",
      "Train | 16/16 | Loss:0.1122 | MainLoss:0.0688 | Alpha:0.4638 | SPLoss:0.2659 | CLSLoss:0.1680 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1370 | MainLoss:0.1370 | SPLoss:0.2663 | CLSLoss:0.1677 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:0.8562 | MainLoss:0.8562 | SPLoss:0.2663 | CLSLoss:0.1677 | AUROC:0.9419\n",
      "\n",
      "Epoch: [287 | 1000] LR: 0.017396\n",
      "Train | 16/16 | Loss:0.1193 | MainLoss:0.0761 | Alpha:0.4656 | SPLoss:0.2654 | CLSLoss:0.1670 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1486 | MainLoss:0.1486 | SPLoss:0.2651 | CLSLoss:0.1662 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:0.7612 | MainLoss:0.7612 | SPLoss:0.2651 | CLSLoss:0.1662 | AUROC:0.9437\n",
      "\n",
      "Epoch: [288 | 1000] LR: 0.017375\n",
      "Train | 16/16 | Loss:0.1199 | MainLoss:0.0768 | Alpha:0.4648 | SPLoss:0.2653 | CLSLoss:0.1656 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1405 | MainLoss:0.1405 | SPLoss:0.2654 | CLSLoss:0.1659 | AUROC:0.9901\n",
      "Test | 128/16 | Loss:0.8226 | MainLoss:0.8226 | SPLoss:0.2654 | CLSLoss:0.1659 | AUROC:0.9455\n",
      "\n",
      "Epoch: [289 | 1000] LR: 0.017354\n",
      "Train | 16/16 | Loss:0.1088 | MainLoss:0.0655 | Alpha:0.4646 | SPLoss:0.2661 | CLSLoss:0.1674 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1604 | MainLoss:0.1604 | SPLoss:0.2655 | CLSLoss:0.1681 | AUROC:0.9902\n",
      "Test | 128/16 | Loss:0.7101 | MainLoss:0.7101 | SPLoss:0.2655 | CLSLoss:0.1681 | AUROC:0.9496\n",
      "\n",
      "Epoch: [290 | 1000] LR: 0.017333\n",
      "Train | 16/16 | Loss:0.1095 | MainLoss:0.0660 | Alpha:0.4635 | SPLoss:0.2659 | CLSLoss:0.1689 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1495 | MainLoss:0.1495 | SPLoss:0.2665 | CLSLoss:0.1683 | AUROC:0.9903\n",
      "Test | 128/16 | Loss:0.7510 | MainLoss:0.7510 | SPLoss:0.2665 | CLSLoss:0.1683 | AUROC:0.9511\n",
      "\n",
      "Epoch: [291 | 1000] LR: 0.017311\n",
      "Train | 16/16 | Loss:0.1189 | MainLoss:0.0754 | Alpha:0.4637 | SPLoss:0.2672 | CLSLoss:0.1679 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1432 | MainLoss:0.1432 | SPLoss:0.2659 | CLSLoss:0.1672 | AUROC:0.9898\n",
      "Test | 128/16 | Loss:0.7870 | MainLoss:0.7870 | SPLoss:0.2659 | CLSLoss:0.1672 | AUROC:0.9529\n",
      "\n",
      "Epoch: [292 | 1000] LR: 0.017290\n",
      "Train | 16/16 | Loss:0.1143 | MainLoss:0.0709 | Alpha:0.4649 | SPLoss:0.2663 | CLSLoss:0.1675 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1395 | MainLoss:0.1395 | SPLoss:0.2672 | CLSLoss:0.1672 | AUROC:0.9901\n",
      "Test | 128/16 | Loss:0.8294 | MainLoss:0.8294 | SPLoss:0.2672 | CLSLoss:0.1672 | AUROC:0.9509\n",
      "\n",
      "Epoch: [293 | 1000] LR: 0.017268\n",
      "Train | 16/16 | Loss:0.1062 | MainLoss:0.0626 | Alpha:0.4643 | SPLoss:0.2686 | CLSLoss:0.1680 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1426 | MainLoss:0.1426 | SPLoss:0.2699 | CLSLoss:0.1694 | AUROC:0.9898\n",
      "Test | 128/16 | Loss:0.8171 | MainLoss:0.8171 | SPLoss:0.2699 | CLSLoss:0.1694 | AUROC:0.9531\n",
      "\n",
      "Epoch: [294 | 1000] LR: 0.017247\n",
      "Train | 16/16 | Loss:0.1050 | MainLoss:0.0610 | Alpha:0.4657 | SPLoss:0.2705 | CLSLoss:0.1696 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1420 | MainLoss:0.1420 | SPLoss:0.2698 | CLSLoss:0.1705 | AUROC:0.9902\n",
      "Test | 128/16 | Loss:0.8472 | MainLoss:0.8472 | SPLoss:0.2698 | CLSLoss:0.1705 | AUROC:0.9508\n",
      "\n",
      "Epoch: [295 | 1000] LR: 0.017225\n",
      "Train | 16/16 | Loss:0.1117 | MainLoss:0.0676 | Alpha:0.4644 | SPLoss:0.2715 | CLSLoss:0.1695 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1467 | MainLoss:0.1467 | SPLoss:0.2720 | CLSLoss:0.1700 | AUROC:0.9902\n",
      "Test | 128/16 | Loss:0.8182 | MainLoss:0.8182 | SPLoss:0.2720 | CLSLoss:0.1700 | AUROC:0.9520\n",
      "\n",
      "Epoch: [296 | 1000] LR: 0.017203\n",
      "Train | 16/16 | Loss:0.1200 | MainLoss:0.0760 | Alpha:0.4633 | SPLoss:0.2711 | CLSLoss:0.1691 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1503 | MainLoss:0.1503 | SPLoss:0.2675 | CLSLoss:0.1676 | AUROC:0.9897\n",
      "Test | 128/16 | Loss:0.7372 | MainLoss:0.7372 | SPLoss:0.2675 | CLSLoss:0.1676 | AUROC:0.9542\n",
      "\n",
      "Epoch: [297 | 1000] LR: 0.017181\n",
      "Train | 16/16 | Loss:0.1019 | MainLoss:0.0584 | Alpha:0.4671 | SPLoss:0.2665 | CLSLoss:0.1687 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1476 | MainLoss:0.1476 | SPLoss:0.2666 | CLSLoss:0.1700 | AUROC:0.9901\n",
      "Test | 128/16 | Loss:0.7858 | MainLoss:0.7858 | SPLoss:0.2666 | CLSLoss:0.1700 | AUROC:0.9483\n",
      "\n",
      "Epoch: [298 | 1000] LR: 0.017159\n",
      "Train | 16/16 | Loss:0.1069 | MainLoss:0.0633 | Alpha:0.4662 | SPLoss:0.2658 | CLSLoss:0.1708 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1531 | MainLoss:0.1531 | SPLoss:0.2660 | CLSLoss:0.1696 | AUROC:0.9899\n",
      "Test | 128/16 | Loss:0.7503 | MainLoss:0.7503 | SPLoss:0.2660 | CLSLoss:0.1696 | AUROC:0.9539\n",
      "\n",
      "Epoch: [299 | 1000] LR: 0.017137\n",
      "Train | 16/16 | Loss:0.1211 | MainLoss:0.0775 | Alpha:0.4629 | SPLoss:0.2667 | CLSLoss:0.1689 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1529 | MainLoss:0.1529 | SPLoss:0.2680 | CLSLoss:0.1669 | AUROC:0.9901\n",
      "Test | 128/16 | Loss:0.7467 | MainLoss:0.7467 | SPLoss:0.2680 | CLSLoss:0.1669 | AUROC:0.9520\n",
      "\n",
      "Epoch: [300 | 1000] LR: 0.017115\n",
      "Train | 16/16 | Loss:0.1116 | MainLoss:0.0683 | Alpha:0.4667 | SPLoss:0.2666 | CLSLoss:0.1667 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1579 | MainLoss:0.1579 | SPLoss:0.2671 | CLSLoss:0.1674 | AUROC:0.9905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 128/16 | Loss:0.7494 | MainLoss:0.7494 | SPLoss:0.2671 | CLSLoss:0.1674 | AUROC:0.9413\n",
      "\n",
      "Epoch: [301 | 1000] LR: 0.017093\n",
      "Train | 16/16 | Loss:0.0968 | MainLoss:0.0800 | Alpha:0.4818 | SPLoss:0.0019 | CLSLoss:0.1668 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1454 | MainLoss:0.1454 | SPLoss:0.0041 | CLSLoss:0.1659 | AUROC:0.9903\n",
      "Test | 128/16 | Loss:0.7951 | MainLoss:0.7951 | SPLoss:0.0041 | CLSLoss:0.1659 | AUROC:0.9422\n",
      "\n",
      "Epoch: [302 | 1000] LR: 0.017071\n",
      "Train | 16/16 | Loss:0.0809 | MainLoss:0.0635 | Alpha:0.4839 | SPLoss:0.0065 | CLSLoss:0.1669 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1428 | MainLoss:0.1428 | SPLoss:0.0097 | CLSLoss:0.1678 | AUROC:0.9900\n",
      "Test | 128/16 | Loss:0.8328 | MainLoss:0.8328 | SPLoss:0.0097 | CLSLoss:0.1678 | AUROC:0.9413\n",
      "\n",
      "Epoch: [303 | 1000] LR: 0.017049\n",
      "Train | 16/16 | Loss:0.0997 | MainLoss:0.0820 | Alpha:0.4820 | SPLoss:0.0114 | CLSLoss:0.1663 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1439 | MainLoss:0.1439 | SPLoss:0.0135 | CLSLoss:0.1639 | AUROC:0.9902\n",
      "Test | 128/16 | Loss:0.7819 | MainLoss:0.7819 | SPLoss:0.0135 | CLSLoss:0.1639 | AUROC:0.9461\n",
      "\n",
      "Epoch: [304 | 1000] LR: 0.017026\n",
      "Train | 16/16 | Loss:0.0815 | MainLoss:0.0635 | Alpha:0.4842 | SPLoss:0.0152 | CLSLoss:0.1647 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1465 | MainLoss:0.1465 | SPLoss:0.0171 | CLSLoss:0.1648 | AUROC:0.9901\n",
      "Test | 128/16 | Loss:0.7637 | MainLoss:0.7637 | SPLoss:0.0171 | CLSLoss:0.1648 | AUROC:0.9523\n",
      "\n",
      "Epoch: [305 | 1000] LR: 0.017004\n",
      "Train | 16/16 | Loss:0.0798 | MainLoss:0.0616 | Alpha:0.4854 | SPLoss:0.0184 | CLSLoss:0.1642 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1506 | MainLoss:0.1506 | SPLoss:0.0198 | CLSLoss:0.1653 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:0.7393 | MainLoss:0.7393 | SPLoss:0.0198 | CLSLoss:0.1653 | AUROC:0.9540\n",
      "\n",
      "Epoch: [306 | 1000] LR: 0.016982\n",
      "Train | 16/16 | Loss:0.0782 | MainLoss:0.0595 | Alpha:0.4854 | SPLoss:0.0220 | CLSLoss:0.1654 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1480 | MainLoss:0.1480 | SPLoss:0.0237 | CLSLoss:0.1664 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:0.8141 | MainLoss:0.8141 | SPLoss:0.0237 | CLSLoss:0.1664 | AUROC:0.9495\n",
      "\n",
      "Epoch: [307 | 1000] LR: 0.016959\n",
      "Train | 16/16 | Loss:0.0925 | MainLoss:0.0735 | Alpha:0.4806 | SPLoss:0.0259 | CLSLoss:0.1644 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1493 | MainLoss:0.1493 | SPLoss:0.0286 | CLSLoss:0.1642 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:0.7486 | MainLoss:0.7486 | SPLoss:0.0286 | CLSLoss:0.1642 | AUROC:0.9591\n",
      "\n",
      "Epoch: [308 | 1000] LR: 0.016937\n",
      "Train | 16/16 | Loss:0.0805 | MainLoss:0.0610 | Alpha:0.4846 | SPLoss:0.0313 | CLSLoss:0.1638 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1546 | MainLoss:0.1546 | SPLoss:0.0326 | CLSLoss:0.1643 | AUROC:0.9899\n",
      "Test | 128/16 | Loss:0.7341 | MainLoss:0.7341 | SPLoss:0.0326 | CLSLoss:0.1643 | AUROC:0.9577\n",
      "\n",
      "Epoch: [309 | 1000] LR: 0.016914\n",
      "Train | 16/16 | Loss:0.0912 | MainLoss:0.0715 | Alpha:0.4818 | SPLoss:0.0346 | CLSLoss:0.1629 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1486 | MainLoss:0.1486 | SPLoss:0.0370 | CLSLoss:0.1619 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:0.7543 | MainLoss:0.7543 | SPLoss:0.0370 | CLSLoss:0.1619 | AUROC:0.9556\n",
      "\n",
      "Epoch: [310 | 1000] LR: 0.016891\n",
      "Train | 16/16 | Loss:0.0901 | MainLoss:0.0701 | Alpha:0.4813 | SPLoss:0.0390 | CLSLoss:0.1614 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1510 | MainLoss:0.1510 | SPLoss:0.0412 | CLSLoss:0.1609 | AUROC:0.9901\n",
      "Test | 128/16 | Loss:0.7137 | MainLoss:0.7137 | SPLoss:0.0412 | CLSLoss:0.1609 | AUROC:0.9614\n",
      "\n",
      "Epoch: [311 | 1000] LR: 0.016868\n",
      "Train | 16/16 | Loss:0.0869 | MainLoss:0.0666 | Alpha:0.4840 | SPLoss:0.0419 | CLSLoss:0.1604 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1439 | MainLoss:0.1439 | SPLoss:0.0427 | CLSLoss:0.1600 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:0.7883 | MainLoss:0.7883 | SPLoss:0.0427 | CLSLoss:0.1600 | AUROC:0.9549\n",
      "\n",
      "Epoch: [312 | 1000] LR: 0.016845\n",
      "Train | 16/16 | Loss:0.0827 | MainLoss:0.0623 | Alpha:0.4844 | SPLoss:0.0442 | CLSLoss:0.1602 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1454 | MainLoss:0.1454 | SPLoss:0.0458 | CLSLoss:0.1604 | AUROC:0.9911\n",
      "Test | 128/16 | Loss:0.7958 | MainLoss:0.7958 | SPLoss:0.0458 | CLSLoss:0.1604 | AUROC:0.9501\n",
      "\n",
      "Epoch: [313 | 1000] LR: 0.016823\n",
      "Train | 16/16 | Loss:0.0867 | MainLoss:0.0660 | Alpha:0.4825 | SPLoss:0.0469 | CLSLoss:0.1600 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1455 | MainLoss:0.1455 | SPLoss:0.0482 | CLSLoss:0.1592 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:0.7581 | MainLoss:0.7581 | SPLoss:0.0482 | CLSLoss:0.1592 | AUROC:0.9525\n",
      "\n",
      "Epoch: [314 | 1000] LR: 0.016800\n",
      "Train | 16/16 | Loss:0.0756 | MainLoss:0.0547 | Alpha:0.4849 | SPLoss:0.0496 | CLSLoss:0.1601 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1487 | MainLoss:0.1487 | SPLoss:0.0510 | CLSLoss:0.1610 | AUROC:0.9905\n",
      "Test | 128/16 | Loss:0.7463 | MainLoss:0.7463 | SPLoss:0.0510 | CLSLoss:0.1610 | AUROC:0.9563\n",
      "\n",
      "Epoch: [315 | 1000] LR: 0.016776\n",
      "Train | 16/16 | Loss:0.0749 | MainLoss:0.0536 | Alpha:0.4867 | SPLoss:0.0519 | CLSLoss:0.1605 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1477 | MainLoss:0.1477 | SPLoss:0.0529 | CLSLoss:0.1612 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:0.7714 | MainLoss:0.7714 | SPLoss:0.0529 | CLSLoss:0.1612 | AUROC:0.9568\n",
      "\n",
      "Epoch: [316 | 1000] LR: 0.016753\n",
      "Train | 16/16 | Loss:0.0902 | MainLoss:0.0687 | Alpha:0.4831 | SPLoss:0.0559 | CLSLoss:0.1594 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1510 | MainLoss:0.1510 | SPLoss:0.0573 | CLSLoss:0.1583 | AUROC:0.9911\n",
      "Test | 128/16 | Loss:0.6977 | MainLoss:0.6977 | SPLoss:0.0573 | CLSLoss:0.1583 | AUROC:0.9603\n",
      "\n",
      "Epoch: [317 | 1000] LR: 0.016730\n",
      "Train | 16/16 | Loss:0.0879 | MainLoss:0.0663 | Alpha:0.4815 | SPLoss:0.0591 | CLSLoss:0.1574 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1391 | MainLoss:0.1391 | SPLoss:0.0599 | CLSLoss:0.1576 | AUROC:0.9909\n",
      "Test | 128/16 | Loss:0.8067 | MainLoss:0.8067 | SPLoss:0.0599 | CLSLoss:0.1576 | AUROC:0.9554\n",
      "\n",
      "Epoch: [318 | 1000] LR: 0.016707\n",
      "Train | 16/16 | Loss:0.0751 | MainLoss:0.0532 | Alpha:0.4858 | SPLoss:0.0608 | CLSLoss:0.1580 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1431 | MainLoss:0.1431 | SPLoss:0.0615 | CLSLoss:0.1592 | AUROC:0.9914\n",
      "Test | 128/16 | Loss:0.7860 | MainLoss:0.7860 | SPLoss:0.0615 | CLSLoss:0.1592 | AUROC:0.9559\n",
      "\n",
      "Epoch: [319 | 1000] LR: 0.016684\n",
      "Train | 16/16 | Loss:0.0724 | MainLoss:0.0502 | Alpha:0.4847 | SPLoss:0.0629 | CLSLoss:0.1596 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1445 | MainLoss:0.1445 | SPLoss:0.0643 | CLSLoss:0.1602 | AUROC:0.9917\n",
      "Test | 128/16 | Loss:0.7894 | MainLoss:0.7894 | SPLoss:0.0643 | CLSLoss:0.1602 | AUROC:0.9568\n",
      "\n",
      "Epoch: [320 | 1000] LR: 0.016660\n",
      "Train | 16/16 | Loss:0.0749 | MainLoss:0.0524 | Alpha:0.4850 | SPLoss:0.0647 | CLSLoss:0.1599 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1438 | MainLoss:0.1438 | SPLoss:0.0655 | CLSLoss:0.1596 | AUROC:0.9912\n",
      "Test | 128/16 | Loss:0.8120 | MainLoss:0.8120 | SPLoss:0.0655 | CLSLoss:0.1596 | AUROC:0.9557\n",
      "\n",
      "Epoch: [321 | 1000] LR: 0.016637\n",
      "Train | 16/16 | Loss:0.0787 | MainLoss:0.0560 | Alpha:0.4857 | SPLoss:0.0666 | CLSLoss:0.1602 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1428 | MainLoss:0.1428 | SPLoss:0.0675 | CLSLoss:0.1587 | AUROC:0.9913\n",
      "Test | 128/16 | Loss:0.8223 | MainLoss:0.8223 | SPLoss:0.0675 | CLSLoss:0.1587 | AUROC:0.9522\n",
      "\n",
      "Epoch: [322 | 1000] LR: 0.016613\n",
      "Train | 16/16 | Loss:0.0691 | MainLoss:0.0463 | Alpha:0.4865 | SPLoss:0.0679 | CLSLoss:0.1598 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1396 | MainLoss:0.1396 | SPLoss:0.0687 | CLSLoss:0.1599 | AUROC:0.9909\n",
      "Test | 128/16 | Loss:0.9118 | MainLoss:0.9118 | SPLoss:0.0687 | CLSLoss:0.1599 | AUROC:0.9475\n",
      "\n",
      "Epoch: [323 | 1000] LR: 0.016590\n",
      "Train | 16/16 | Loss:0.0905 | MainLoss:0.0677 | Alpha:0.4817 | SPLoss:0.0693 | CLSLoss:0.1588 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1435 | MainLoss:0.1435 | SPLoss:0.0709 | CLSLoss:0.1561 | AUROC:0.9909\n",
      "Test | 128/16 | Loss:0.8174 | MainLoss:0.8174 | SPLoss:0.0709 | CLSLoss:0.1561 | AUROC:0.9514\n",
      "\n",
      "Epoch: [324 | 1000] LR: 0.016566\n",
      "Train | 16/16 | Loss:0.0787 | MainLoss:0.0560 | Alpha:0.4848 | SPLoss:0.0712 | CLSLoss:0.1564 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1458 | MainLoss:0.1458 | SPLoss:0.0725 | CLSLoss:0.1567 | AUROC:0.9909\n",
      "Test | 128/16 | Loss:0.8091 | MainLoss:0.8091 | SPLoss:0.0725 | CLSLoss:0.1567 | AUROC:0.9526\n",
      "\n",
      "Epoch: [325 | 1000] LR: 0.016542\n",
      "Train | 16/16 | Loss:0.0749 | MainLoss:0.0521 | Alpha:0.4856 | SPLoss:0.0728 | CLSLoss:0.1560 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1444 | MainLoss:0.1444 | SPLoss:0.0735 | CLSLoss:0.1570 | AUROC:0.9911\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 128/16 | Loss:0.8025 | MainLoss:0.8025 | SPLoss:0.0735 | CLSLoss:0.1570 | AUROC:0.9540\n",
      "\n",
      "Epoch: [326 | 1000] LR: 0.016518\n",
      "Train | 16/16 | Loss:0.0847 | MainLoss:0.0618 | Alpha:0.4826 | SPLoss:0.0738 | CLSLoss:0.1554 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1433 | MainLoss:0.1433 | SPLoss:0.0748 | CLSLoss:0.1544 | AUROC:0.9911\n",
      "Test | 128/16 | Loss:0.7687 | MainLoss:0.7687 | SPLoss:0.0748 | CLSLoss:0.1544 | AUROC:0.9575\n",
      "\n",
      "Epoch: [327 | 1000] LR: 0.016494\n",
      "Train | 16/16 | Loss:0.0826 | MainLoss:0.0596 | Alpha:0.4832 | SPLoss:0.0762 | CLSLoss:0.1542 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1495 | MainLoss:0.1495 | SPLoss:0.0769 | CLSLoss:0.1538 | AUROC:0.9908\n",
      "Test | 128/16 | Loss:0.7186 | MainLoss:0.7186 | SPLoss:0.0769 | CLSLoss:0.1538 | AUROC:0.9593\n",
      "\n",
      "Epoch: [328 | 1000] LR: 0.016471\n",
      "Train | 16/16 | Loss:0.0807 | MainLoss:0.0576 | Alpha:0.4836 | SPLoss:0.0773 | CLSLoss:0.1541 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1439 | MainLoss:0.1439 | SPLoss:0.0784 | CLSLoss:0.1531 | AUROC:0.9909\n",
      "Test | 128/16 | Loss:0.7735 | MainLoss:0.7735 | SPLoss:0.0784 | CLSLoss:0.1531 | AUROC:0.9572\n",
      "\n",
      "Epoch: [329 | 1000] LR: 0.016447\n",
      "Train | 16/16 | Loss:0.0814 | MainLoss:0.0581 | Alpha:0.4831 | SPLoss:0.0789 | CLSLoss:0.1533 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1427 | MainLoss:0.1427 | SPLoss:0.0802 | CLSLoss:0.1526 | AUROC:0.9912\n",
      "Test | 128/16 | Loss:0.7697 | MainLoss:0.7697 | SPLoss:0.0802 | CLSLoss:0.1526 | AUROC:0.9590\n",
      "\n",
      "Epoch: [330 | 1000] LR: 0.016423\n",
      "Train | 16/16 | Loss:0.0841 | MainLoss:0.0608 | Alpha:0.4816 | SPLoss:0.0805 | CLSLoss:0.1527 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1423 | MainLoss:0.1423 | SPLoss:0.0810 | CLSLoss:0.1520 | AUROC:0.9910\n",
      "Test | 128/16 | Loss:0.7625 | MainLoss:0.7625 | SPLoss:0.0810 | CLSLoss:0.1520 | AUROC:0.9597\n",
      "\n",
      "Epoch: [331 | 1000] LR: 0.016398\n",
      "Train | 16/16 | Loss:0.0692 | MainLoss:0.0458 | Alpha:0.4863 | SPLoss:0.0810 | CLSLoss:0.1530 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1463 | MainLoss:0.1463 | SPLoss:0.0812 | CLSLoss:0.1544 | AUROC:0.9909\n",
      "Test | 128/16 | Loss:0.7601 | MainLoss:0.7601 | SPLoss:0.0812 | CLSLoss:0.1544 | AUROC:0.9586\n",
      "\n",
      "Epoch: [332 | 1000] LR: 0.016374\n",
      "Train | 16/16 | Loss:0.0799 | MainLoss:0.0563 | Alpha:0.4842 | SPLoss:0.0814 | CLSLoss:0.1544 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1521 | MainLoss:0.1521 | SPLoss:0.0814 | CLSLoss:0.1541 | AUROC:0.9912\n",
      "Test | 128/16 | Loss:0.7574 | MainLoss:0.7574 | SPLoss:0.0814 | CLSLoss:0.1541 | AUROC:0.9542\n",
      "\n",
      "Epoch: [333 | 1000] LR: 0.016350\n",
      "Train | 16/16 | Loss:0.0814 | MainLoss:0.0578 | Alpha:0.4833 | SPLoss:0.0820 | CLSLoss:0.1539 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1561 | MainLoss:0.1561 | SPLoss:0.0820 | CLSLoss:0.1523 | AUROC:0.9916\n",
      "Test | 128/16 | Loss:0.7496 | MainLoss:0.7496 | SPLoss:0.0820 | CLSLoss:0.1523 | AUROC:0.9519\n",
      "\n",
      "Epoch: [334 | 1000] LR: 0.016326\n",
      "Train | 16/16 | Loss:0.0748 | MainLoss:0.0513 | Alpha:0.4849 | SPLoss:0.0828 | CLSLoss:0.1527 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1480 | MainLoss:0.1480 | SPLoss:0.0831 | CLSLoss:0.1527 | AUROC:0.9914\n",
      "Test | 128/16 | Loss:0.7935 | MainLoss:0.7935 | SPLoss:0.0831 | CLSLoss:0.1527 | AUROC:0.9524\n",
      "\n",
      "Epoch: [335 | 1000] LR: 0.016301\n",
      "Train | 16/16 | Loss:0.0734 | MainLoss:0.0496 | Alpha:0.4842 | SPLoss:0.0846 | CLSLoss:0.1538 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1607 | MainLoss:0.1607 | SPLoss:0.0861 | CLSLoss:0.1538 | AUROC:0.9913\n",
      "Test | 128/16 | Loss:0.7432 | MainLoss:0.7432 | SPLoss:0.0861 | CLSLoss:0.1538 | AUROC:0.9548\n",
      "\n",
      "Epoch: [336 | 1000] LR: 0.016277\n",
      "Train | 16/16 | Loss:0.0740 | MainLoss:0.0500 | Alpha:0.4852 | SPLoss:0.0869 | CLSLoss:0.1534 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1532 | MainLoss:0.1532 | SPLoss:0.0879 | CLSLoss:0.1540 | AUROC:0.9914\n",
      "Test | 128/16 | Loss:0.7814 | MainLoss:0.7814 | SPLoss:0.0879 | CLSLoss:0.1540 | AUROC:0.9542\n",
      "\n",
      "Epoch: [337 | 1000] LR: 0.016252\n",
      "Train | 16/16 | Loss:0.0798 | MainLoss:0.0555 | Alpha:0.4826 | SPLoss:0.0906 | CLSLoss:0.1532 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1507 | MainLoss:0.1507 | SPLoss:0.0923 | CLSLoss:0.1531 | AUROC:0.9912\n",
      "Test | 128/16 | Loss:0.7547 | MainLoss:0.7547 | SPLoss:0.0923 | CLSLoss:0.1531 | AUROC:0.9570\n",
      "\n",
      "Epoch: [338 | 1000] LR: 0.016228\n",
      "Train | 16/16 | Loss:0.0715 | MainLoss:0.0469 | Alpha:0.4846 | SPLoss:0.0927 | CLSLoss:0.1529 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1443 | MainLoss:0.1443 | SPLoss:0.0931 | CLSLoss:0.1536 | AUROC:0.9910\n",
      "Test | 128/16 | Loss:0.7918 | MainLoss:0.7918 | SPLoss:0.0931 | CLSLoss:0.1536 | AUROC:0.9561\n",
      "\n",
      "Epoch: [339 | 1000] LR: 0.016203\n",
      "Train | 16/16 | Loss:0.0707 | MainLoss:0.0459 | Alpha:0.4854 | SPLoss:0.0939 | CLSLoss:0.1540 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1536 | MainLoss:0.1536 | SPLoss:0.0942 | CLSLoss:0.1540 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:0.7419 | MainLoss:0.7419 | SPLoss:0.0942 | CLSLoss:0.1540 | AUROC:0.9562\n",
      "\n",
      "Epoch: [340 | 1000] LR: 0.016179\n",
      "Train | 16/16 | Loss:0.0773 | MainLoss:0.0525 | Alpha:0.4850 | SPLoss:0.0941 | CLSLoss:0.1542 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1489 | MainLoss:0.1489 | SPLoss:0.0946 | CLSLoss:0.1526 | AUROC:0.9911\n",
      "Test | 128/16 | Loss:0.7552 | MainLoss:0.7552 | SPLoss:0.0946 | CLSLoss:0.1526 | AUROC:0.9553\n",
      "\n",
      "Epoch: [341 | 1000] LR: 0.016154\n",
      "Train | 16/16 | Loss:0.0753 | MainLoss:0.0506 | Alpha:0.4856 | SPLoss:0.0945 | CLSLoss:0.1522 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1425 | MainLoss:0.1425 | SPLoss:0.0950 | CLSLoss:0.1526 | AUROC:0.9910\n",
      "Test | 128/16 | Loss:0.8785 | MainLoss:0.8785 | SPLoss:0.0950 | CLSLoss:0.1526 | AUROC:0.9509\n",
      "\n",
      "Epoch: [342 | 1000] LR: 0.016129\n",
      "Train | 16/16 | Loss:0.0733 | MainLoss:0.0485 | Alpha:0.4852 | SPLoss:0.0951 | CLSLoss:0.1532 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1585 | MainLoss:0.1585 | SPLoss:0.0958 | CLSLoss:0.1521 | AUROC:0.9912\n",
      "Test | 128/16 | Loss:0.7473 | MainLoss:0.7473 | SPLoss:0.0958 | CLSLoss:0.1521 | AUROC:0.9550\n",
      "\n",
      "Epoch: [343 | 1000] LR: 0.016104\n",
      "Train | 16/16 | Loss:0.0677 | MainLoss:0.0428 | Alpha:0.4860 | SPLoss:0.0966 | CLSLoss:0.1523 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1576 | MainLoss:0.1576 | SPLoss:0.0969 | CLSLoss:0.1533 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:0.7893 | MainLoss:0.7893 | SPLoss:0.0969 | CLSLoss:0.1533 | AUROC:0.9539\n",
      "\n",
      "Epoch: [344 | 1000] LR: 0.016079\n",
      "Train | 16/16 | Loss:0.0744 | MainLoss:0.0493 | Alpha:0.4843 | SPLoss:0.0978 | CLSLoss:0.1530 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1509 | MainLoss:0.1509 | SPLoss:0.0982 | CLSLoss:0.1529 | AUROC:0.9908\n",
      "Test | 128/16 | Loss:0.8080 | MainLoss:0.8080 | SPLoss:0.0982 | CLSLoss:0.1529 | AUROC:0.9543\n",
      "\n",
      "Epoch: [345 | 1000] LR: 0.016054\n",
      "Train | 16/16 | Loss:0.0771 | MainLoss:0.0521 | Alpha:0.4843 | SPLoss:0.0986 | CLSLoss:0.1515 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1509 | MainLoss:0.1509 | SPLoss:0.0986 | CLSLoss:0.1508 | AUROC:0.9907\n",
      "Test | 128/16 | Loss:0.8051 | MainLoss:0.8051 | SPLoss:0.0986 | CLSLoss:0.1508 | AUROC:0.9519\n",
      "\n",
      "Epoch: [346 | 1000] LR: 0.016029\n",
      "Train | 16/16 | Loss:0.0723 | MainLoss:0.0473 | Alpha:0.4848 | SPLoss:0.0987 | CLSLoss:0.1515 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1517 | MainLoss:0.1517 | SPLoss:0.0987 | CLSLoss:0.1511 | AUROC:0.9906\n",
      "Test | 128/16 | Loss:0.8062 | MainLoss:0.8062 | SPLoss:0.0987 | CLSLoss:0.1511 | AUROC:0.9518\n",
      "\n",
      "Epoch: [347 | 1000] LR: 0.016004\n",
      "Train | 16/16 | Loss:0.0896 | MainLoss:0.0647 | Alpha:0.4822 | SPLoss:0.0989 | CLSLoss:0.1496 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1607 | MainLoss:0.1607 | SPLoss:0.0991 | CLSLoss:0.1489 | AUROC:0.9912\n",
      "Test | 128/16 | Loss:0.7016 | MainLoss:0.7016 | SPLoss:0.0991 | CLSLoss:0.1489 | AUROC:0.9540\n",
      "\n",
      "Epoch: [348 | 1000] LR: 0.015979\n",
      "Train | 16/16 | Loss:0.0676 | MainLoss:0.0426 | Alpha:0.4856 | SPLoss:0.0996 | CLSLoss:0.1497 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1576 | MainLoss:0.1576 | SPLoss:0.0998 | CLSLoss:0.1505 | AUROC:0.9908\n",
      "Test | 128/16 | Loss:0.7154 | MainLoss:0.7154 | SPLoss:0.0998 | CLSLoss:0.1505 | AUROC:0.9558\n",
      "\n",
      "Epoch: [349 | 1000] LR: 0.015954\n",
      "Train | 16/16 | Loss:0.0748 | MainLoss:0.0497 | Alpha:0.4851 | SPLoss:0.1002 | CLSLoss:0.1506 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1512 | MainLoss:0.1512 | SPLoss:0.1002 | CLSLoss:0.1501 | AUROC:0.9911\n",
      "Test | 128/16 | Loss:0.7417 | MainLoss:0.7417 | SPLoss:0.1002 | CLSLoss:0.1501 | AUROC:0.9535\n",
      "\n",
      "Epoch: [350 | 1000] LR: 0.015929\n",
      "Train | 16/16 | Loss:0.0775 | MainLoss:0.0526 | Alpha:0.4850 | SPLoss:0.1004 | CLSLoss:0.1494 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1561 | MainLoss:0.1561 | SPLoss:0.1005 | CLSLoss:0.1489 | AUROC:0.9912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 128/16 | Loss:0.6885 | MainLoss:0.6885 | SPLoss:0.1005 | CLSLoss:0.1489 | AUROC:0.9587\n",
      "\n",
      "Epoch: [351 | 1000] LR: 0.015903\n",
      "Train | 16/16 | Loss:0.0804 | MainLoss:0.0554 | Alpha:0.4838 | SPLoss:0.1014 | CLSLoss:0.1484 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1534 | MainLoss:0.1534 | SPLoss:0.1024 | CLSLoss:0.1486 | AUROC:0.9912\n",
      "Test | 128/16 | Loss:0.7071 | MainLoss:0.7071 | SPLoss:0.1024 | CLSLoss:0.1486 | AUROC:0.9577\n",
      "\n",
      "Epoch: [352 | 1000] LR: 0.015878\n",
      "Train | 16/16 | Loss:0.0827 | MainLoss:0.0576 | Alpha:0.4837 | SPLoss:0.1024 | CLSLoss:0.1479 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1520 | MainLoss:0.1520 | SPLoss:0.1027 | CLSLoss:0.1474 | AUROC:0.9911\n",
      "Test | 128/16 | Loss:0.7313 | MainLoss:0.7313 | SPLoss:0.1027 | CLSLoss:0.1474 | AUROC:0.9559\n",
      "\n",
      "Epoch: [353 | 1000] LR: 0.015852\n",
      "Train | 16/16 | Loss:0.0817 | MainLoss:0.0565 | Alpha:0.4828 | SPLoss:0.1037 | CLSLoss:0.1476 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1515 | MainLoss:0.1515 | SPLoss:0.1041 | CLSLoss:0.1478 | AUROC:0.9911\n",
      "Test | 128/16 | Loss:0.7450 | MainLoss:0.7450 | SPLoss:0.1041 | CLSLoss:0.1478 | AUROC:0.9576\n",
      "\n",
      "Epoch: [354 | 1000] LR: 0.015827\n",
      "Train | 16/16 | Loss:0.0733 | MainLoss:0.0480 | Alpha:0.4847 | SPLoss:0.1047 | CLSLoss:0.1483 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1475 | MainLoss:0.1475 | SPLoss:0.1065 | CLSLoss:0.1484 | AUROC:0.9913\n",
      "Test | 128/16 | Loss:0.7809 | MainLoss:0.7809 | SPLoss:0.1065 | CLSLoss:0.1484 | AUROC:0.9605\n",
      "\n",
      "Epoch: [355 | 1000] LR: 0.015801\n",
      "Train | 16/16 | Loss:0.0773 | MainLoss:0.0516 | Alpha:0.4830 | SPLoss:0.1074 | CLSLoss:0.1488 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1461 | MainLoss:0.1461 | SPLoss:0.1087 | CLSLoss:0.1486 | AUROC:0.9912\n",
      "Test | 128/16 | Loss:0.8472 | MainLoss:0.8472 | SPLoss:0.1087 | CLSLoss:0.1486 | AUROC:0.9561\n",
      "\n",
      "Epoch: [356 | 1000] LR: 0.015776\n",
      "Train | 16/16 | Loss:0.0743 | MainLoss:0.0485 | Alpha:0.4842 | SPLoss:0.1093 | CLSLoss:0.1492 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1462 | MainLoss:0.1462 | SPLoss:0.1093 | CLSLoss:0.1491 | AUROC:0.9912\n",
      "Test | 128/16 | Loss:0.8110 | MainLoss:0.8110 | SPLoss:0.1093 | CLSLoss:0.1491 | AUROC:0.9596\n",
      "\n",
      "Epoch: [357 | 1000] LR: 0.015750\n",
      "Train | 16/16 | Loss:0.0861 | MainLoss:0.0602 | Alpha:0.4812 | SPLoss:0.1106 | CLSLoss:0.1486 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1435 | MainLoss:0.1435 | SPLoss:0.1113 | CLSLoss:0.1476 | AUROC:0.9909\n",
      "Test | 128/16 | Loss:0.7870 | MainLoss:0.7870 | SPLoss:0.1113 | CLSLoss:0.1476 | AUROC:0.9626\n",
      "\n",
      "Epoch: [358 | 1000] LR: 0.015724\n",
      "Train | 16/16 | Loss:0.0759 | MainLoss:0.0500 | Alpha:0.4830 | SPLoss:0.1114 | CLSLoss:0.1479 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1427 | MainLoss:0.1427 | SPLoss:0.1127 | CLSLoss:0.1484 | AUROC:0.9913\n",
      "Test | 128/16 | Loss:0.8015 | MainLoss:0.8015 | SPLoss:0.1127 | CLSLoss:0.1484 | AUROC:0.9631\n",
      "\n",
      "Epoch: [359 | 1000] LR: 0.015699\n",
      "Train | 16/16 | Loss:0.0731 | MainLoss:0.0470 | Alpha:0.4857 | SPLoss:0.1125 | CLSLoss:0.1486 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1435 | MainLoss:0.1435 | SPLoss:0.1124 | CLSLoss:0.1494 | AUROC:0.9910\n",
      "Test | 128/16 | Loss:0.8245 | MainLoss:0.8245 | SPLoss:0.1124 | CLSLoss:0.1494 | AUROC:0.9622\n",
      "\n",
      "Epoch: [360 | 1000] LR: 0.015673\n",
      "Train | 16/16 | Loss:0.0915 | MainLoss:0.0655 | Alpha:0.4814 | SPLoss:0.1120 | CLSLoss:0.1477 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1503 | MainLoss:0.1503 | SPLoss:0.1129 | CLSLoss:0.1463 | AUROC:0.9911\n",
      "Test | 128/16 | Loss:0.7407 | MainLoss:0.7407 | SPLoss:0.1129 | CLSLoss:0.1463 | AUROC:0.9621\n",
      "\n",
      "Epoch: [361 | 1000] LR: 0.015647\n",
      "Train | 16/16 | Loss:0.0729 | MainLoss:0.0467 | Alpha:0.4857 | SPLoss:0.1136 | CLSLoss:0.1474 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1526 | MainLoss:0.1526 | SPLoss:0.1137 | CLSLoss:0.1480 | AUROC:0.9912\n",
      "Test | 128/16 | Loss:0.7441 | MainLoss:0.7441 | SPLoss:0.1137 | CLSLoss:0.1480 | AUROC:0.9634\n",
      "\n",
      "Epoch: [362 | 1000] LR: 0.015621\n",
      "Train | 16/16 | Loss:0.0796 | MainLoss:0.0534 | Alpha:0.4839 | SPLoss:0.1144 | CLSLoss:0.1481 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1496 | MainLoss:0.1496 | SPLoss:0.1146 | CLSLoss:0.1483 | AUROC:0.9913\n",
      "Test | 128/16 | Loss:0.7742 | MainLoss:0.7742 | SPLoss:0.1146 | CLSLoss:0.1483 | AUROC:0.9607\n",
      "\n",
      "Epoch: [363 | 1000] LR: 0.015595\n",
      "Train | 16/16 | Loss:0.0826 | MainLoss:0.0563 | Alpha:0.4827 | SPLoss:0.1152 | CLSLoss:0.1480 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1422 | MainLoss:0.1422 | SPLoss:0.1158 | CLSLoss:0.1474 | AUROC:0.9911\n",
      "Test | 128/16 | Loss:0.8571 | MainLoss:0.8571 | SPLoss:0.1158 | CLSLoss:0.1474 | AUROC:0.9574\n",
      "\n",
      "Epoch: [364 | 1000] LR: 0.015569\n",
      "Train | 16/16 | Loss:0.0659 | MainLoss:0.0395 | Alpha:0.4864 | SPLoss:0.1162 | CLSLoss:0.1484 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1465 | MainLoss:0.1465 | SPLoss:0.1158 | CLSLoss:0.1495 | AUROC:0.9913\n",
      "Test | 128/16 | Loss:0.8128 | MainLoss:0.8128 | SPLoss:0.1158 | CLSLoss:0.1495 | AUROC:0.9577\n",
      "\n",
      "Epoch: [365 | 1000] LR: 0.015543\n",
      "Train | 16/16 | Loss:0.0723 | MainLoss:0.0457 | Alpha:0.4841 | SPLoss:0.1169 | CLSLoss:0.1492 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1492 | MainLoss:0.1492 | SPLoss:0.1170 | CLSLoss:0.1502 | AUROC:0.9908\n",
      "Test | 128/16 | Loss:0.8071 | MainLoss:0.8071 | SPLoss:0.1170 | CLSLoss:0.1502 | AUROC:0.9598\n",
      "\n",
      "Epoch: [366 | 1000] LR: 0.015516\n",
      "Train | 16/16 | Loss:0.0740 | MainLoss:0.0475 | Alpha:0.4857 | SPLoss:0.1164 | CLSLoss:0.1494 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1463 | MainLoss:0.1463 | SPLoss:0.1158 | CLSLoss:0.1498 | AUROC:0.9912\n",
      "Test | 128/16 | Loss:0.8179 | MainLoss:0.8179 | SPLoss:0.1158 | CLSLoss:0.1498 | AUROC:0.9582\n",
      "\n",
      "Epoch: [367 | 1000] LR: 0.015490\n",
      "Train | 16/16 | Loss:0.0762 | MainLoss:0.0497 | Alpha:0.4846 | SPLoss:0.1157 | CLSLoss:0.1497 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1463 | MainLoss:0.1463 | SPLoss:0.1147 | CLSLoss:0.1491 | AUROC:0.9909\n",
      "Test | 128/16 | Loss:0.8098 | MainLoss:0.8098 | SPLoss:0.1147 | CLSLoss:0.1491 | AUROC:0.9581\n",
      "\n",
      "Epoch: [368 | 1000] LR: 0.015464\n",
      "Train | 16/16 | Loss:0.0769 | MainLoss:0.0505 | Alpha:0.4841 | SPLoss:0.1156 | CLSLoss:0.1486 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1475 | MainLoss:0.1475 | SPLoss:0.1153 | CLSLoss:0.1486 | AUROC:0.9912\n",
      "Test | 128/16 | Loss:0.8034 | MainLoss:0.8034 | SPLoss:0.1153 | CLSLoss:0.1486 | AUROC:0.9580\n",
      "\n",
      "Epoch: [369 | 1000] LR: 0.015438\n",
      "Train | 16/16 | Loss:0.0820 | MainLoss:0.0557 | Alpha:0.4830 | SPLoss:0.1157 | CLSLoss:0.1474 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1519 | MainLoss:0.1519 | SPLoss:0.1158 | CLSLoss:0.1473 | AUROC:0.9912\n",
      "Test | 128/16 | Loss:0.7521 | MainLoss:0.7521 | SPLoss:0.1158 | CLSLoss:0.1473 | AUROC:0.9592\n",
      "\n",
      "Epoch: [370 | 1000] LR: 0.015411\n",
      "Train | 16/16 | Loss:0.0714 | MainLoss:0.0450 | Alpha:0.4852 | SPLoss:0.1161 | CLSLoss:0.1478 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1492 | MainLoss:0.1492 | SPLoss:0.1158 | CLSLoss:0.1488 | AUROC:0.9911\n",
      "Test | 128/16 | Loss:0.8005 | MainLoss:0.8005 | SPLoss:0.1158 | CLSLoss:0.1488 | AUROC:0.9551\n",
      "\n",
      "Epoch: [371 | 1000] LR: 0.015385\n",
      "Train | 16/16 | Loss:0.0915 | MainLoss:0.0650 | Alpha:0.4798 | SPLoss:0.1176 | CLSLoss:0.1467 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1446 | MainLoss:0.1446 | SPLoss:0.1178 | CLSLoss:0.1458 | AUROC:0.9916\n",
      "Test | 128/16 | Loss:0.7723 | MainLoss:0.7723 | SPLoss:0.1178 | CLSLoss:0.1458 | AUROC:0.9576\n",
      "\n",
      "Epoch: [372 | 1000] LR: 0.015358\n",
      "Train | 16/16 | Loss:0.0702 | MainLoss:0.0437 | Alpha:0.4860 | SPLoss:0.1179 | CLSLoss:0.1470 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1424 | MainLoss:0.1424 | SPLoss:0.1176 | CLSLoss:0.1479 | AUROC:0.9914\n",
      "Test | 128/16 | Loss:0.8100 | MainLoss:0.8100 | SPLoss:0.1176 | CLSLoss:0.1479 | AUROC:0.9573\n",
      "\n",
      "Epoch: [373 | 1000] LR: 0.015332\n",
      "Train | 16/16 | Loss:0.0724 | MainLoss:0.0459 | Alpha:0.4850 | SPLoss:0.1173 | CLSLoss:0.1476 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1463 | MainLoss:0.1463 | SPLoss:0.1164 | CLSLoss:0.1488 | AUROC:0.9915\n",
      "Test | 128/16 | Loss:0.8084 | MainLoss:0.8084 | SPLoss:0.1164 | CLSLoss:0.1488 | AUROC:0.9554\n",
      "\n",
      "Epoch: [374 | 1000] LR: 0.015305\n",
      "Train | 16/16 | Loss:0.0830 | MainLoss:0.0565 | Alpha:0.4834 | SPLoss:0.1163 | CLSLoss:0.1479 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1463 | MainLoss:0.1463 | SPLoss:0.1169 | CLSLoss:0.1467 | AUROC:0.9913\n",
      "Test | 128/16 | Loss:0.7618 | MainLoss:0.7618 | SPLoss:0.1169 | CLSLoss:0.1467 | AUROC:0.9571\n",
      "\n",
      "Epoch: [375 | 1000] LR: 0.015278\n",
      "Train | 16/16 | Loss:0.0855 | MainLoss:0.0591 | Alpha:0.4817 | SPLoss:0.1172 | CLSLoss:0.1460 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1425 | MainLoss:0.1425 | SPLoss:0.1173 | CLSLoss:0.1454 | AUROC:0.9913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 128/16 | Loss:0.7561 | MainLoss:0.7561 | SPLoss:0.1173 | CLSLoss:0.1454 | AUROC:0.9618\n",
      "\n",
      "Epoch: [376 | 1000] LR: 0.015252\n",
      "Train | 16/16 | Loss:0.0784 | MainLoss:0.0521 | Alpha:0.4839 | SPLoss:0.1176 | CLSLoss:0.1459 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1432 | MainLoss:0.1432 | SPLoss:0.1182 | CLSLoss:0.1461 | AUROC:0.9909\n",
      "Test | 128/16 | Loss:0.7826 | MainLoss:0.7826 | SPLoss:0.1182 | CLSLoss:0.1461 | AUROC:0.9597\n",
      "\n",
      "Epoch: [377 | 1000] LR: 0.015225\n",
      "Train | 16/16 | Loss:0.0865 | MainLoss:0.0601 | Alpha:0.4830 | SPLoss:0.1186 | CLSLoss:0.1458 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1559 | MainLoss:0.1559 | SPLoss:0.1184 | CLSLoss:0.1447 | AUROC:0.9912\n",
      "Test | 128/16 | Loss:0.6716 | MainLoss:0.6716 | SPLoss:0.1184 | CLSLoss:0.1447 | AUROC:0.9627\n",
      "\n",
      "Epoch: [378 | 1000] LR: 0.015198\n",
      "Train | 16/16 | Loss:0.0774 | MainLoss:0.0511 | Alpha:0.4839 | SPLoss:0.1180 | CLSLoss:0.1446 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1490 | MainLoss:0.1490 | SPLoss:0.1179 | CLSLoss:0.1455 | AUROC:0.9908\n",
      "Test | 128/16 | Loss:0.7440 | MainLoss:0.7440 | SPLoss:0.1179 | CLSLoss:0.1455 | AUROC:0.9606\n",
      "\n",
      "Epoch: [379 | 1000] LR: 0.015171\n",
      "Train | 16/16 | Loss:0.0658 | MainLoss:0.0392 | Alpha:0.4855 | SPLoss:0.1185 | CLSLoss:0.1470 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1481 | MainLoss:0.1481 | SPLoss:0.1194 | CLSLoss:0.1489 | AUROC:0.9912\n",
      "Test | 128/16 | Loss:0.7898 | MainLoss:0.7898 | SPLoss:0.1194 | CLSLoss:0.1489 | AUROC:0.9590\n",
      "\n",
      "Epoch: [380 | 1000] LR: 0.015144\n",
      "Train | 16/16 | Loss:0.0810 | MainLoss:0.0541 | Alpha:0.4826 | SPLoss:0.1208 | CLSLoss:0.1481 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1481 | MainLoss:0.1481 | SPLoss:0.1218 | CLSLoss:0.1485 | AUROC:0.9912\n",
      "Test | 128/16 | Loss:0.7446 | MainLoss:0.7446 | SPLoss:0.1218 | CLSLoss:0.1485 | AUROC:0.9627\n",
      "\n",
      "Epoch: [381 | 1000] LR: 0.015117\n",
      "Train | 16/16 | Loss:0.0816 | MainLoss:0.0547 | Alpha:0.4835 | SPLoss:0.1213 | CLSLoss:0.1477 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1546 | MainLoss:0.1546 | SPLoss:0.1207 | CLSLoss:0.1474 | AUROC:0.9911\n",
      "Test | 128/16 | Loss:0.7164 | MainLoss:0.7164 | SPLoss:0.1207 | CLSLoss:0.1474 | AUROC:0.9593\n",
      "\n",
      "Epoch: [382 | 1000] LR: 0.015090\n",
      "Train | 16/16 | Loss:0.0755 | MainLoss:0.0485 | Alpha:0.4850 | SPLoss:0.1214 | CLSLoss:0.1481 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1545 | MainLoss:0.1545 | SPLoss:0.1220 | CLSLoss:0.1488 | AUROC:0.9912\n",
      "Test | 128/16 | Loss:0.7682 | MainLoss:0.7682 | SPLoss:0.1220 | CLSLoss:0.1488 | AUROC:0.9531\n",
      "\n",
      "Epoch: [383 | 1000] LR: 0.015063\n",
      "Train | 16/16 | Loss:0.0741 | MainLoss:0.0470 | Alpha:0.4853 | SPLoss:0.1217 | CLSLoss:0.1491 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1470 | MainLoss:0.1470 | SPLoss:0.1214 | CLSLoss:0.1492 | AUROC:0.9910\n",
      "Test | 128/16 | Loss:0.8132 | MainLoss:0.8132 | SPLoss:0.1214 | CLSLoss:0.1492 | AUROC:0.9539\n",
      "\n",
      "Epoch: [384 | 1000] LR: 0.015036\n",
      "Train | 16/16 | Loss:0.0868 | MainLoss:0.0599 | Alpha:0.4816 | SPLoss:0.1229 | CLSLoss:0.1471 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1450 | MainLoss:0.1450 | SPLoss:0.1238 | CLSLoss:0.1471 | AUROC:0.9915\n",
      "Test | 128/16 | Loss:0.7767 | MainLoss:0.7767 | SPLoss:0.1238 | CLSLoss:0.1471 | AUROC:0.9609\n",
      "\n",
      "Epoch: [385 | 1000] LR: 0.015009\n",
      "Train | 16/16 | Loss:0.0879 | MainLoss:0.0609 | Alpha:0.4808 | SPLoss:0.1238 | CLSLoss:0.1459 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1477 | MainLoss:0.1477 | SPLoss:0.1231 | CLSLoss:0.1456 | AUROC:0.9915\n",
      "Test | 128/16 | Loss:0.7293 | MainLoss:0.7293 | SPLoss:0.1231 | CLSLoss:0.1456 | AUROC:0.9598\n",
      "\n",
      "Epoch: [386 | 1000] LR: 0.014982\n",
      "Train | 16/16 | Loss:0.0719 | MainLoss:0.0450 | Alpha:0.4852 | SPLoss:0.1231 | CLSLoss:0.1465 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1476 | MainLoss:0.1476 | SPLoss:0.1228 | CLSLoss:0.1467 | AUROC:0.9912\n",
      "Test | 128/16 | Loss:0.7362 | MainLoss:0.7362 | SPLoss:0.1228 | CLSLoss:0.1467 | AUROC:0.9621\n",
      "\n",
      "Epoch: [387 | 1000] LR: 0.014955\n",
      "Train | 16/16 | Loss:0.0737 | MainLoss:0.0468 | Alpha:0.4850 | SPLoss:0.1222 | CLSLoss:0.1472 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1514 | MainLoss:0.1514 | SPLoss:0.1209 | CLSLoss:0.1476 | AUROC:0.9913\n",
      "Test | 128/16 | Loss:0.7263 | MainLoss:0.7263 | SPLoss:0.1209 | CLSLoss:0.1476 | AUROC:0.9602\n",
      "\n",
      "Epoch: [388 | 1000] LR: 0.014927\n",
      "Train | 16/16 | Loss:0.0759 | MainLoss:0.0491 | Alpha:0.4847 | SPLoss:0.1201 | CLSLoss:0.1479 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1488 | MainLoss:0.1488 | SPLoss:0.1203 | CLSLoss:0.1473 | AUROC:0.9915\n",
      "Test | 128/16 | Loss:0.7533 | MainLoss:0.7533 | SPLoss:0.1203 | CLSLoss:0.1473 | AUROC:0.9581\n",
      "\n",
      "Epoch: [389 | 1000] LR: 0.014900\n",
      "Train | 16/16 | Loss:0.0729 | MainLoss:0.0461 | Alpha:0.4848 | SPLoss:0.1204 | CLSLoss:0.1476 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1465 | MainLoss:0.1465 | SPLoss:0.1205 | CLSLoss:0.1477 | AUROC:0.9915\n",
      "Test | 128/16 | Loss:0.7677 | MainLoss:0.7677 | SPLoss:0.1205 | CLSLoss:0.1477 | AUROC:0.9546\n",
      "\n",
      "Epoch: [390 | 1000] LR: 0.014873\n",
      "Train | 16/16 | Loss:0.0831 | MainLoss:0.0564 | Alpha:0.4823 | SPLoss:0.1205 | CLSLoss:0.1473 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1496 | MainLoss:0.1496 | SPLoss:0.1203 | CLSLoss:0.1463 | AUROC:0.9918\n",
      "Test | 128/16 | Loss:0.7558 | MainLoss:0.7558 | SPLoss:0.1203 | CLSLoss:0.1463 | AUROC:0.9550\n",
      "\n",
      "Epoch: [391 | 1000] LR: 0.014845\n",
      "Train | 16/16 | Loss:0.0849 | MainLoss:0.0584 | Alpha:0.4821 | SPLoss:0.1197 | CLSLoss:0.1454 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1438 | MainLoss:0.1438 | SPLoss:0.1201 | CLSLoss:0.1448 | AUROC:0.9913\n",
      "Test | 128/16 | Loss:0.7920 | MainLoss:0.7920 | SPLoss:0.1201 | CLSLoss:0.1448 | AUROC:0.9523\n",
      "\n",
      "Epoch: [392 | 1000] LR: 0.014818\n",
      "Train | 16/16 | Loss:0.0727 | MainLoss:0.0462 | Alpha:0.4865 | SPLoss:0.1198 | CLSLoss:0.1451 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1414 | MainLoss:0.1414 | SPLoss:0.1198 | CLSLoss:0.1458 | AUROC:0.9916\n",
      "Test | 128/16 | Loss:0.7737 | MainLoss:0.7737 | SPLoss:0.1198 | CLSLoss:0.1458 | AUROC:0.9554\n",
      "\n",
      "Epoch: [393 | 1000] LR: 0.014790\n",
      "Train | 16/16 | Loss:0.0793 | MainLoss:0.0527 | Alpha:0.4834 | SPLoss:0.1206 | CLSLoss:0.1453 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1416 | MainLoss:0.1416 | SPLoss:0.1210 | CLSLoss:0.1454 | AUROC:0.9916\n",
      "Test | 128/16 | Loss:0.7495 | MainLoss:0.7495 | SPLoss:0.1210 | CLSLoss:0.1454 | AUROC:0.9576\n",
      "\n",
      "Epoch: [394 | 1000] LR: 0.014762\n",
      "Train | 16/16 | Loss:0.0739 | MainLoss:0.0473 | Alpha:0.4852 | SPLoss:0.1207 | CLSLoss:0.1462 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1429 | MainLoss:0.1429 | SPLoss:0.1204 | CLSLoss:0.1460 | AUROC:0.9916\n",
      "Test | 128/16 | Loss:0.7492 | MainLoss:0.7492 | SPLoss:0.1204 | CLSLoss:0.1460 | AUROC:0.9569\n",
      "\n",
      "Epoch: [395 | 1000] LR: 0.014735\n",
      "Train | 16/16 | Loss:0.0767 | MainLoss:0.0500 | Alpha:0.4834 | SPLoss:0.1209 | CLSLoss:0.1461 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1463 | MainLoss:0.1463 | SPLoss:0.1210 | CLSLoss:0.1464 | AUROC:0.9917\n",
      "Test | 128/16 | Loss:0.7176 | MainLoss:0.7176 | SPLoss:0.1210 | CLSLoss:0.1464 | AUROC:0.9610\n",
      "\n",
      "Epoch: [396 | 1000] LR: 0.014707\n",
      "Train | 16/16 | Loss:0.0766 | MainLoss:0.0499 | Alpha:0.4838 | SPLoss:0.1209 | CLSLoss:0.1465 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1518 | MainLoss:0.1518 | SPLoss:0.1204 | CLSLoss:0.1463 | AUROC:0.9910\n",
      "Test | 128/16 | Loss:0.6896 | MainLoss:0.6896 | SPLoss:0.1204 | CLSLoss:0.1463 | AUROC:0.9615\n",
      "\n",
      "Epoch: [397 | 1000] LR: 0.014679\n",
      "Train | 16/16 | Loss:0.0790 | MainLoss:0.0525 | Alpha:0.4830 | SPLoss:0.1198 | CLSLoss:0.1459 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1507 | MainLoss:0.1507 | SPLoss:0.1195 | CLSLoss:0.1458 | AUROC:0.9914\n",
      "Test | 128/16 | Loss:0.7104 | MainLoss:0.7104 | SPLoss:0.1195 | CLSLoss:0.1458 | AUROC:0.9587\n",
      "\n",
      "Epoch: [398 | 1000] LR: 0.014652\n",
      "Train | 16/16 | Loss:0.0693 | MainLoss:0.0427 | Alpha:0.4866 | SPLoss:0.1194 | CLSLoss:0.1465 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1558 | MainLoss:0.1558 | SPLoss:0.1190 | CLSLoss:0.1476 | AUROC:0.9912\n",
      "Test | 128/16 | Loss:0.7190 | MainLoss:0.7190 | SPLoss:0.1190 | CLSLoss:0.1476 | AUROC:0.9586\n",
      "\n",
      "Epoch: [399 | 1000] LR: 0.014624\n",
      "Train | 16/16 | Loss:0.0759 | MainLoss:0.0492 | Alpha:0.4854 | SPLoss:0.1195 | CLSLoss:0.1476 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1538 | MainLoss:0.1538 | SPLoss:0.1198 | CLSLoss:0.1473 | AUROC:0.9912\n",
      "Test | 128/16 | Loss:0.7357 | MainLoss:0.7357 | SPLoss:0.1198 | CLSLoss:0.1473 | AUROC:0.9553\n",
      "\n",
      "Epoch: [400 | 1000] LR: 0.014596\n",
      "Train | 16/16 | Loss:0.0881 | MainLoss:0.0613 | Alpha:0.4799 | SPLoss:0.1210 | CLSLoss:0.1463 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1389 | MainLoss:0.1389 | SPLoss:0.1213 | CLSLoss:0.1448 | AUROC:0.9912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 128/16 | Loss:0.8255 | MainLoss:0.8255 | SPLoss:0.1213 | CLSLoss:0.1448 | AUROC:0.9505\n",
      "\n",
      "Epoch: [401 | 1000] LR: 0.001457\n",
      "Train | 16/16 | Loss:0.0586 | MainLoss:0.0441 | Alpha:0.4900 | SPLoss:0.0000 | CLSLoss:0.1449 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1402 | MainLoss:0.1402 | SPLoss:0.0000 | CLSLoss:0.1450 | AUROC:0.9912\n",
      "Test | 128/16 | Loss:0.8119 | MainLoss:0.8119 | SPLoss:0.0000 | CLSLoss:0.1450 | AUROC:0.9511\n",
      "\n",
      "Epoch: [402 | 1000] LR: 0.001454\n",
      "Train | 16/16 | Loss:0.0653 | MainLoss:0.0508 | Alpha:0.4887 | SPLoss:0.0000 | CLSLoss:0.1450 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1412 | MainLoss:0.1412 | SPLoss:0.0001 | CLSLoss:0.1450 | AUROC:0.9916\n",
      "Test | 128/16 | Loss:0.8002 | MainLoss:0.8002 | SPLoss:0.0001 | CLSLoss:0.1450 | AUROC:0.9518\n",
      "\n",
      "Epoch: [403 | 1000] LR: 0.001451\n",
      "Train | 16/16 | Loss:0.0561 | MainLoss:0.0416 | Alpha:0.4910 | SPLoss:0.0001 | CLSLoss:0.1451 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1428 | MainLoss:0.1428 | SPLoss:0.0001 | CLSLoss:0.1452 | AUROC:0.9911\n",
      "Test | 128/16 | Loss:0.7855 | MainLoss:0.7855 | SPLoss:0.0001 | CLSLoss:0.1452 | AUROC:0.9528\n",
      "\n",
      "Epoch: [404 | 1000] LR: 0.001448\n",
      "Train | 16/16 | Loss:0.0593 | MainLoss:0.0447 | Alpha:0.4902 | SPLoss:0.0001 | CLSLoss:0.1453 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1439 | MainLoss:0.1439 | SPLoss:0.0002 | CLSLoss:0.1453 | AUROC:0.9913\n",
      "Test | 128/16 | Loss:0.7750 | MainLoss:0.7750 | SPLoss:0.0002 | CLSLoss:0.1453 | AUROC:0.9533\n",
      "\n",
      "Epoch: [405 | 1000] LR: 0.001446\n",
      "Train | 16/16 | Loss:0.0634 | MainLoss:0.0489 | Alpha:0.4889 | SPLoss:0.0002 | CLSLoss:0.1453 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1443 | MainLoss:0.1443 | SPLoss:0.0002 | CLSLoss:0.1453 | AUROC:0.9915\n",
      "Test | 128/16 | Loss:0.7721 | MainLoss:0.7721 | SPLoss:0.0002 | CLSLoss:0.1453 | AUROC:0.9536\n",
      "\n",
      "Epoch: [406 | 1000] LR: 0.001443\n",
      "Train | 16/16 | Loss:0.0640 | MainLoss:0.0494 | Alpha:0.4891 | SPLoss:0.0002 | CLSLoss:0.1455 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1430 | MainLoss:0.1430 | SPLoss:0.0002 | CLSLoss:0.1454 | AUROC:0.9914\n",
      "Test | 128/16 | Loss:0.7839 | MainLoss:0.7839 | SPLoss:0.0002 | CLSLoss:0.1454 | AUROC:0.9538\n",
      "\n",
      "Epoch: [407 | 1000] LR: 0.001440\n",
      "Train | 16/16 | Loss:0.0715 | MainLoss:0.0570 | Alpha:0.4878 | SPLoss:0.0002 | CLSLoss:0.1454 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1430 | MainLoss:0.1430 | SPLoss:0.0003 | CLSLoss:0.1453 | AUROC:0.9913\n",
      "Test | 128/16 | Loss:0.7794 | MainLoss:0.7794 | SPLoss:0.0003 | CLSLoss:0.1453 | AUROC:0.9535\n",
      "\n",
      "Epoch: [408 | 1000] LR: 0.001437\n",
      "Train | 16/16 | Loss:0.0643 | MainLoss:0.0497 | Alpha:0.4888 | SPLoss:0.0003 | CLSLoss:0.1454 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1441 | MainLoss:0.1441 | SPLoss:0.0003 | CLSLoss:0.1453 | AUROC:0.9914\n",
      "Test | 128/16 | Loss:0.7671 | MainLoss:0.7671 | SPLoss:0.0003 | CLSLoss:0.1453 | AUROC:0.9543\n",
      "\n",
      "Epoch: [409 | 1000] LR: 0.001434\n",
      "Train | 16/16 | Loss:0.0567 | MainLoss:0.0422 | Alpha:0.4907 | SPLoss:0.0003 | CLSLoss:0.1454 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1438 | MainLoss:0.1438 | SPLoss:0.0003 | CLSLoss:0.1455 | AUROC:0.9912\n",
      "Test | 128/16 | Loss:0.7749 | MainLoss:0.7749 | SPLoss:0.0003 | CLSLoss:0.1455 | AUROC:0.9541\n",
      "\n",
      "Epoch: [410 | 1000] LR: 0.001431\n",
      "Train | 16/16 | Loss:0.0632 | MainLoss:0.0486 | Alpha:0.4897 | SPLoss:0.0004 | CLSLoss:0.1456 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1437 | MainLoss:0.1437 | SPLoss:0.0004 | CLSLoss:0.1456 | AUROC:0.9912\n",
      "Test | 128/16 | Loss:0.7763 | MainLoss:0.7763 | SPLoss:0.0004 | CLSLoss:0.1456 | AUROC:0.9539\n",
      "\n",
      "Epoch: [411 | 1000] LR: 0.001429\n",
      "Train | 16/16 | Loss:0.0658 | MainLoss:0.0512 | Alpha:0.4881 | SPLoss:0.0004 | CLSLoss:0.1456 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1465 | MainLoss:0.1465 | SPLoss:0.0005 | CLSLoss:0.1457 | AUROC:0.9913\n",
      "Test | 128/16 | Loss:0.7562 | MainLoss:0.7562 | SPLoss:0.0005 | CLSLoss:0.1457 | AUROC:0.9547\n",
      "\n",
      "Epoch: [412 | 1000] LR: 0.001426\n",
      "Train | 16/16 | Loss:0.0595 | MainLoss:0.0449 | Alpha:0.4893 | SPLoss:0.0005 | CLSLoss:0.1457 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1472 | MainLoss:0.1472 | SPLoss:0.0006 | CLSLoss:0.1458 | AUROC:0.9912\n",
      "Test | 128/16 | Loss:0.7535 | MainLoss:0.7535 | SPLoss:0.0006 | CLSLoss:0.1458 | AUROC:0.9551\n",
      "\n",
      "Epoch: [413 | 1000] LR: 0.001423\n",
      "Train | 16/16 | Loss:0.0606 | MainLoss:0.0460 | Alpha:0.4896 | SPLoss:0.0006 | CLSLoss:0.1459 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1468 | MainLoss:0.1468 | SPLoss:0.0006 | CLSLoss:0.1459 | AUROC:0.9911\n",
      "Test | 128/16 | Loss:0.7602 | MainLoss:0.7602 | SPLoss:0.0006 | CLSLoss:0.1459 | AUROC:0.9545\n",
      "\n",
      "Epoch: [414 | 1000] LR: 0.001420\n",
      "Train | 16/16 | Loss:0.0549 | MainLoss:0.0402 | Alpha:0.4910 | SPLoss:0.0006 | CLSLoss:0.1460 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1462 | MainLoss:0.1462 | SPLoss:0.0006 | CLSLoss:0.1461 | AUROC:0.9913\n",
      "Test | 128/16 | Loss:0.7673 | MainLoss:0.7673 | SPLoss:0.0006 | CLSLoss:0.1461 | AUROC:0.9547\n",
      "\n",
      "Epoch: [415 | 1000] LR: 0.001417\n",
      "Train | 16/16 | Loss:0.0613 | MainLoss:0.0466 | Alpha:0.4898 | SPLoss:0.0007 | CLSLoss:0.1462 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1468 | MainLoss:0.1468 | SPLoss:0.0007 | CLSLoss:0.1463 | AUROC:0.9914\n",
      "Test | 128/16 | Loss:0.7653 | MainLoss:0.7653 | SPLoss:0.0007 | CLSLoss:0.1463 | AUROC:0.9545\n",
      "\n",
      "Epoch: [416 | 1000] LR: 0.001414\n",
      "Train | 16/16 | Loss:0.0694 | MainLoss:0.0547 | Alpha:0.4881 | SPLoss:0.0007 | CLSLoss:0.1461 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1473 | MainLoss:0.1473 | SPLoss:0.0008 | CLSLoss:0.1462 | AUROC:0.9916\n",
      "Test | 128/16 | Loss:0.7622 | MainLoss:0.7622 | SPLoss:0.0008 | CLSLoss:0.1462 | AUROC:0.9548\n",
      "\n",
      "Epoch: [417 | 1000] LR: 0.001412\n",
      "Train | 16/16 | Loss:0.0581 | MainLoss:0.0434 | Alpha:0.4905 | SPLoss:0.0008 | CLSLoss:0.1462 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1478 | MainLoss:0.1478 | SPLoss:0.0008 | CLSLoss:0.1463 | AUROC:0.9914\n",
      "Test | 128/16 | Loss:0.7607 | MainLoss:0.7607 | SPLoss:0.0008 | CLSLoss:0.1463 | AUROC:0.9546\n",
      "\n",
      "Epoch: [418 | 1000] LR: 0.001409\n",
      "Train | 16/16 | Loss:0.0613 | MainLoss:0.0466 | Alpha:0.4894 | SPLoss:0.0009 | CLSLoss:0.1463 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1479 | MainLoss:0.1479 | SPLoss:0.0009 | CLSLoss:0.1464 | AUROC:0.9914\n",
      "Test | 128/16 | Loss:0.7595 | MainLoss:0.7595 | SPLoss:0.0009 | CLSLoss:0.1464 | AUROC:0.9549\n",
      "\n",
      "Epoch: [419 | 1000] LR: 0.001406\n",
      "Train | 16/16 | Loss:0.0656 | MainLoss:0.0509 | Alpha:0.4884 | SPLoss:0.0009 | CLSLoss:0.1464 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1470 | MainLoss:0.1470 | SPLoss:0.0009 | CLSLoss:0.1464 | AUROC:0.9915\n",
      "Test | 128/16 | Loss:0.7672 | MainLoss:0.7672 | SPLoss:0.0009 | CLSLoss:0.1464 | AUROC:0.9550\n",
      "\n",
      "Epoch: [420 | 1000] LR: 0.001403\n",
      "Train | 16/16 | Loss:0.0566 | MainLoss:0.0418 | Alpha:0.4900 | SPLoss:0.0009 | CLSLoss:0.1465 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1473 | MainLoss:0.1473 | SPLoss:0.0010 | CLSLoss:0.1466 | AUROC:0.9915\n",
      "Test | 128/16 | Loss:0.7675 | MainLoss:0.7675 | SPLoss:0.0010 | CLSLoss:0.1466 | AUROC:0.9552\n",
      "\n",
      "Epoch: [421 | 1000] LR: 0.001400\n",
      "Train | 16/16 | Loss:0.0655 | MainLoss:0.0508 | Alpha:0.4886 | SPLoss:0.0010 | CLSLoss:0.1465 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1465 | MainLoss:0.1465 | SPLoss:0.0010 | CLSLoss:0.1465 | AUROC:0.9915\n",
      "Test | 128/16 | Loss:0.7731 | MainLoss:0.7731 | SPLoss:0.0010 | CLSLoss:0.1465 | AUROC:0.9546\n",
      "\n",
      "Epoch: [422 | 1000] LR: 0.001397\n",
      "Train | 16/16 | Loss:0.0686 | MainLoss:0.0539 | Alpha:0.4874 | SPLoss:0.0010 | CLSLoss:0.1464 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1470 | MainLoss:0.1470 | SPLoss:0.0011 | CLSLoss:0.1464 | AUROC:0.9914\n",
      "Test | 128/16 | Loss:0.7650 | MainLoss:0.7650 | SPLoss:0.0011 | CLSLoss:0.1464 | AUROC:0.9553\n",
      "\n",
      "Epoch: [423 | 1000] LR: 0.001394\n",
      "Train | 16/16 | Loss:0.0594 | MainLoss:0.0446 | Alpha:0.4904 | SPLoss:0.0011 | CLSLoss:0.1465 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1456 | MainLoss:0.1456 | SPLoss:0.0011 | CLSLoss:0.1465 | AUROC:0.9916\n",
      "Test | 128/16 | Loss:0.7737 | MainLoss:0.7737 | SPLoss:0.0011 | CLSLoss:0.1465 | AUROC:0.9556\n",
      "\n",
      "Epoch: [424 | 1000] LR: 0.001391\n",
      "Train | 16/16 | Loss:0.0505 | MainLoss:0.0357 | Alpha:0.4922 | SPLoss:0.0011 | CLSLoss:0.1466 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1455 | MainLoss:0.1455 | SPLoss:0.0012 | CLSLoss:0.1468 | AUROC:0.9916\n",
      "Test | 128/16 | Loss:0.7782 | MainLoss:0.7782 | SPLoss:0.0012 | CLSLoss:0.1468 | AUROC:0.9555\n",
      "\n",
      "Epoch: [425 | 1000] LR: 0.001388\n",
      "Train | 16/16 | Loss:0.0623 | MainLoss:0.0475 | Alpha:0.4887 | SPLoss:0.0012 | CLSLoss:0.1468 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1451 | MainLoss:0.1451 | SPLoss:0.0012 | CLSLoss:0.1468 | AUROC:0.9913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 128/16 | Loss:0.7841 | MainLoss:0.7841 | SPLoss:0.0012 | CLSLoss:0.1468 | AUROC:0.9555\n",
      "\n",
      "Epoch: [426 | 1000] LR: 0.001386\n",
      "Train | 16/16 | Loss:0.0612 | MainLoss:0.0464 | Alpha:0.4897 | SPLoss:0.0012 | CLSLoss:0.1468 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1437 | MainLoss:0.1437 | SPLoss:0.0012 | CLSLoss:0.1469 | AUROC:0.9914\n",
      "Test | 128/16 | Loss:0.7955 | MainLoss:0.7955 | SPLoss:0.0012 | CLSLoss:0.1469 | AUROC:0.9553\n",
      "\n",
      "Epoch: [427 | 1000] LR: 0.001383\n",
      "Train | 16/16 | Loss:0.0590 | MainLoss:0.0441 | Alpha:0.4899 | SPLoss:0.0013 | CLSLoss:0.1469 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1447 | MainLoss:0.1447 | SPLoss:0.0013 | CLSLoss:0.1469 | AUROC:0.9915\n",
      "Test | 128/16 | Loss:0.7884 | MainLoss:0.7884 | SPLoss:0.0013 | CLSLoss:0.1469 | AUROC:0.9558\n",
      "\n",
      "Epoch: [428 | 1000] LR: 0.001380\n",
      "Train | 16/16 | Loss:0.0708 | MainLoss:0.0560 | Alpha:0.4870 | SPLoss:0.0013 | CLSLoss:0.1468 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1445 | MainLoss:0.1445 | SPLoss:0.0013 | CLSLoss:0.1467 | AUROC:0.9914\n",
      "Test | 128/16 | Loss:0.7877 | MainLoss:0.7877 | SPLoss:0.0013 | CLSLoss:0.1467 | AUROC:0.9559\n",
      "\n",
      "Epoch: [429 | 1000] LR: 0.001377\n",
      "Train | 16/16 | Loss:0.0582 | MainLoss:0.0434 | Alpha:0.4901 | SPLoss:0.0014 | CLSLoss:0.1468 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1455 | MainLoss:0.1455 | SPLoss:0.0014 | CLSLoss:0.1468 | AUROC:0.9914\n",
      "Test | 128/16 | Loss:0.7811 | MainLoss:0.7811 | SPLoss:0.0014 | CLSLoss:0.1468 | AUROC:0.9562\n",
      "\n",
      "Epoch: [430 | 1000] LR: 0.001374\n",
      "Train | 16/16 | Loss:0.0633 | MainLoss:0.0484 | Alpha:0.4882 | SPLoss:0.0014 | CLSLoss:0.1468 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1458 | MainLoss:0.1458 | SPLoss:0.0015 | CLSLoss:0.1468 | AUROC:0.9914\n",
      "Test | 128/16 | Loss:0.7799 | MainLoss:0.7799 | SPLoss:0.0015 | CLSLoss:0.1468 | AUROC:0.9561\n",
      "\n",
      "Epoch: [431 | 1000] LR: 0.001371\n",
      "Train | 16/16 | Loss:0.0651 | MainLoss:0.0503 | Alpha:0.4880 | SPLoss:0.0015 | CLSLoss:0.1468 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1457 | MainLoss:0.1457 | SPLoss:0.0015 | CLSLoss:0.1467 | AUROC:0.9916\n",
      "Test | 128/16 | Loss:0.7829 | MainLoss:0.7829 | SPLoss:0.0015 | CLSLoss:0.1467 | AUROC:0.9558\n",
      "\n",
      "Epoch: [432 | 1000] LR: 0.001368\n",
      "Train | 16/16 | Loss:0.0672 | MainLoss:0.0524 | Alpha:0.4882 | SPLoss:0.0015 | CLSLoss:0.1467 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1457 | MainLoss:0.1457 | SPLoss:0.0016 | CLSLoss:0.1466 | AUROC:0.9914\n",
      "Test | 128/16 | Loss:0.7802 | MainLoss:0.7802 | SPLoss:0.0016 | CLSLoss:0.1466 | AUROC:0.9561\n",
      "\n",
      "Epoch: [433 | 1000] LR: 0.001365\n",
      "Train | 16/16 | Loss:0.0674 | MainLoss:0.0525 | Alpha:0.4881 | SPLoss:0.0017 | CLSLoss:0.1465 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1463 | MainLoss:0.1463 | SPLoss:0.0017 | CLSLoss:0.1465 | AUROC:0.9915\n",
      "Test | 128/16 | Loss:0.7724 | MainLoss:0.7724 | SPLoss:0.0017 | CLSLoss:0.1465 | AUROC:0.9565\n",
      "\n",
      "Epoch: [434 | 1000] LR: 0.001362\n",
      "Train | 16/16 | Loss:0.0596 | MainLoss:0.0448 | Alpha:0.4893 | SPLoss:0.0017 | CLSLoss:0.1466 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1461 | MainLoss:0.1461 | SPLoss:0.0017 | CLSLoss:0.1466 | AUROC:0.9914\n",
      "Test | 128/16 | Loss:0.7758 | MainLoss:0.7758 | SPLoss:0.0017 | CLSLoss:0.1466 | AUROC:0.9565\n",
      "\n",
      "Epoch: [435 | 1000] LR: 0.001359\n",
      "Train | 16/16 | Loss:0.0566 | MainLoss:0.0418 | Alpha:0.4907 | SPLoss:0.0017 | CLSLoss:0.1466 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1454 | MainLoss:0.1454 | SPLoss:0.0018 | CLSLoss:0.1466 | AUROC:0.9914\n",
      "Test | 128/16 | Loss:0.7836 | MainLoss:0.7836 | SPLoss:0.0018 | CLSLoss:0.1466 | AUROC:0.9558\n",
      "\n",
      "Epoch: [436 | 1000] LR: 0.001356\n",
      "Train | 16/16 | Loss:0.0683 | MainLoss:0.0535 | Alpha:0.4878 | SPLoss:0.0018 | CLSLoss:0.1465 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1453 | MainLoss:0.1453 | SPLoss:0.0018 | CLSLoss:0.1465 | AUROC:0.9916\n",
      "Test | 128/16 | Loss:0.7825 | MainLoss:0.7825 | SPLoss:0.0018 | CLSLoss:0.1465 | AUROC:0.9563\n",
      "\n",
      "Epoch: [437 | 1000] LR: 0.001353\n",
      "Train | 16/16 | Loss:0.0578 | MainLoss:0.0430 | Alpha:0.4908 | SPLoss:0.0019 | CLSLoss:0.1465 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1455 | MainLoss:0.1455 | SPLoss:0.0019 | CLSLoss:0.1465 | AUROC:0.9915\n",
      "Test | 128/16 | Loss:0.7810 | MainLoss:0.7810 | SPLoss:0.0019 | CLSLoss:0.1465 | AUROC:0.9567\n",
      "\n",
      "Epoch: [438 | 1000] LR: 0.001351\n",
      "Train | 16/16 | Loss:0.0638 | MainLoss:0.0489 | Alpha:0.4885 | SPLoss:0.0019 | CLSLoss:0.1466 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1456 | MainLoss:0.1456 | SPLoss:0.0020 | CLSLoss:0.1465 | AUROC:0.9914\n",
      "Test | 128/16 | Loss:0.7786 | MainLoss:0.7786 | SPLoss:0.0020 | CLSLoss:0.1465 | AUROC:0.9569\n",
      "\n",
      "Epoch: [439 | 1000] LR: 0.001348\n",
      "Train | 16/16 | Loss:0.0571 | MainLoss:0.0423 | Alpha:0.4901 | SPLoss:0.0020 | CLSLoss:0.1466 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1466 | MainLoss:0.1466 | SPLoss:0.0020 | CLSLoss:0.1467 | AUROC:0.9914\n",
      "Test | 128/16 | Loss:0.7714 | MainLoss:0.7714 | SPLoss:0.0020 | CLSLoss:0.1467 | AUROC:0.9570\n",
      "\n",
      "Epoch: [440 | 1000] LR: 0.001345\n",
      "Train | 16/16 | Loss:0.0586 | MainLoss:0.0437 | Alpha:0.4901 | SPLoss:0.0021 | CLSLoss:0.1467 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1467 | MainLoss:0.1467 | SPLoss:0.0021 | CLSLoss:0.1467 | AUROC:0.9915\n",
      "Test | 128/16 | Loss:0.7730 | MainLoss:0.7730 | SPLoss:0.0021 | CLSLoss:0.1467 | AUROC:0.9573\n",
      "\n",
      "Epoch: [441 | 1000] LR: 0.001342\n",
      "Train | 16/16 | Loss:0.0610 | MainLoss:0.0461 | Alpha:0.4883 | SPLoss:0.0021 | CLSLoss:0.1468 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1456 | MainLoss:0.1456 | SPLoss:0.0022 | CLSLoss:0.1468 | AUROC:0.9916\n",
      "Test | 128/16 | Loss:0.7872 | MainLoss:0.7872 | SPLoss:0.0022 | CLSLoss:0.1468 | AUROC:0.9565\n",
      "\n",
      "Epoch: [442 | 1000] LR: 0.001339\n",
      "Train | 16/16 | Loss:0.0723 | MainLoss:0.0574 | Alpha:0.4868 | SPLoss:0.0022 | CLSLoss:0.1467 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1463 | MainLoss:0.1463 | SPLoss:0.0023 | CLSLoss:0.1466 | AUROC:0.9913\n",
      "Test | 128/16 | Loss:0.7771 | MainLoss:0.7771 | SPLoss:0.0023 | CLSLoss:0.1466 | AUROC:0.9571\n",
      "\n",
      "Epoch: [443 | 1000] LR: 0.001336\n",
      "Train | 16/16 | Loss:0.0702 | MainLoss:0.0553 | Alpha:0.4868 | SPLoss:0.0023 | CLSLoss:0.1466 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1468 | MainLoss:0.1468 | SPLoss:0.0024 | CLSLoss:0.1464 | AUROC:0.9916\n",
      "Test | 128/16 | Loss:0.7699 | MainLoss:0.7699 | SPLoss:0.0024 | CLSLoss:0.1464 | AUROC:0.9574\n",
      "\n",
      "Epoch: [444 | 1000] LR: 0.001333\n",
      "Train | 16/16 | Loss:0.0718 | MainLoss:0.0570 | Alpha:0.4857 | SPLoss:0.0024 | CLSLoss:0.1464 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1469 | MainLoss:0.1469 | SPLoss:0.0024 | CLSLoss:0.1463 | AUROC:0.9913\n",
      "Test | 128/16 | Loss:0.7686 | MainLoss:0.7686 | SPLoss:0.0024 | CLSLoss:0.1463 | AUROC:0.9574\n",
      "\n",
      "Epoch: [445 | 1000] LR: 0.001330\n",
      "Train | 16/16 | Loss:0.0594 | MainLoss:0.0445 | Alpha:0.4903 | SPLoss:0.0025 | CLSLoss:0.1463 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1464 | MainLoss:0.1464 | SPLoss:0.0025 | CLSLoss:0.1463 | AUROC:0.9914\n",
      "Test | 128/16 | Loss:0.7737 | MainLoss:0.7737 | SPLoss:0.0025 | CLSLoss:0.1463 | AUROC:0.9572\n",
      "\n",
      "Epoch: [446 | 1000] LR: 0.001327\n",
      "Train | 16/16 | Loss:0.0681 | MainLoss:0.0532 | Alpha:0.4876 | SPLoss:0.0025 | CLSLoss:0.1462 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1450 | MainLoss:0.1450 | SPLoss:0.0025 | CLSLoss:0.1461 | AUROC:0.9915\n",
      "Test | 128/16 | Loss:0.7847 | MainLoss:0.7847 | SPLoss:0.0025 | CLSLoss:0.1461 | AUROC:0.9569\n",
      "\n",
      "Epoch: [447 | 1000] LR: 0.001324\n",
      "Train | 16/16 | Loss:0.0654 | MainLoss:0.0505 | Alpha:0.4883 | SPLoss:0.0025 | CLSLoss:0.1460 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1449 | MainLoss:0.1449 | SPLoss:0.0026 | CLSLoss:0.1460 | AUROC:0.9915\n",
      "Test | 128/16 | Loss:0.7825 | MainLoss:0.7825 | SPLoss:0.0026 | CLSLoss:0.1460 | AUROC:0.9571\n",
      "\n",
      "Epoch: [448 | 1000] LR: 0.001321\n",
      "Train | 16/16 | Loss:0.0557 | MainLoss:0.0408 | Alpha:0.4906 | SPLoss:0.0026 | CLSLoss:0.1461 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1452 | MainLoss:0.1452 | SPLoss:0.0027 | CLSLoss:0.1461 | AUROC:0.9913\n",
      "Test | 128/16 | Loss:0.7827 | MainLoss:0.7827 | SPLoss:0.0027 | CLSLoss:0.1461 | AUROC:0.9571\n",
      "\n",
      "Epoch: [449 | 1000] LR: 0.001318\n",
      "Train | 16/16 | Loss:0.0574 | MainLoss:0.0425 | Alpha:0.4900 | SPLoss:0.0027 | CLSLoss:0.1462 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1462 | MainLoss:0.1462 | SPLoss:0.0028 | CLSLoss:0.1462 | AUROC:0.9915\n",
      "Test | 128/16 | Loss:0.7728 | MainLoss:0.7728 | SPLoss:0.0028 | CLSLoss:0.1462 | AUROC:0.9575\n",
      "\n",
      "Epoch: [450 | 1000] LR: 0.001315\n",
      "Train | 16/16 | Loss:0.0676 | MainLoss:0.0527 | Alpha:0.4871 | SPLoss:0.0028 | CLSLoss:0.1461 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1458 | MainLoss:0.1458 | SPLoss:0.0028 | CLSLoss:0.1460 | AUROC:0.9913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 128/16 | Loss:0.7745 | MainLoss:0.7745 | SPLoss:0.0028 | CLSLoss:0.1460 | AUROC:0.9572\n",
      "\n",
      "Epoch: [451 | 1000] LR: 0.001312\n",
      "Train | 16/16 | Loss:0.0557 | MainLoss:0.0408 | Alpha:0.4898 | SPLoss:0.0029 | CLSLoss:0.1461 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1451 | MainLoss:0.1451 | SPLoss:0.0029 | CLSLoss:0.1461 | AUROC:0.9916\n",
      "Test | 128/16 | Loss:0.7786 | MainLoss:0.7786 | SPLoss:0.0029 | CLSLoss:0.1461 | AUROC:0.9576\n",
      "\n",
      "Epoch: [452 | 1000] LR: 0.001309\n",
      "Train | 16/16 | Loss:0.0632 | MainLoss:0.0483 | Alpha:0.4883 | SPLoss:0.0029 | CLSLoss:0.1461 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1456 | MainLoss:0.1456 | SPLoss:0.0030 | CLSLoss:0.1461 | AUROC:0.9914\n",
      "Test | 128/16 | Loss:0.7738 | MainLoss:0.7738 | SPLoss:0.0030 | CLSLoss:0.1461 | AUROC:0.9579\n",
      "\n",
      "Epoch: [453 | 1000] LR: 0.001306\n",
      "Train | 16/16 | Loss:0.0557 | MainLoss:0.0408 | Alpha:0.4901 | SPLoss:0.0030 | CLSLoss:0.1462 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1449 | MainLoss:0.1449 | SPLoss:0.0030 | CLSLoss:0.1463 | AUROC:0.9916\n",
      "Test | 128/16 | Loss:0.7817 | MainLoss:0.7817 | SPLoss:0.0030 | CLSLoss:0.1463 | AUROC:0.9579\n",
      "\n",
      "Epoch: [454 | 1000] LR: 0.001303\n",
      "Train | 16/16 | Loss:0.0612 | MainLoss:0.0462 | Alpha:0.4893 | SPLoss:0.0031 | CLSLoss:0.1463 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1453 | MainLoss:0.1453 | SPLoss:0.0031 | CLSLoss:0.1463 | AUROC:0.9915\n",
      "Test | 128/16 | Loss:0.7808 | MainLoss:0.7808 | SPLoss:0.0031 | CLSLoss:0.1463 | AUROC:0.9580\n",
      "\n",
      "Epoch: [455 | 1000] LR: 0.001300\n",
      "Train | 16/16 | Loss:0.0536 | MainLoss:0.0386 | Alpha:0.4903 | SPLoss:0.0031 | CLSLoss:0.1463 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1450 | MainLoss:0.1450 | SPLoss:0.0032 | CLSLoss:0.1464 | AUROC:0.9914\n",
      "Test | 128/16 | Loss:0.7870 | MainLoss:0.7870 | SPLoss:0.0032 | CLSLoss:0.1464 | AUROC:0.9578\n",
      "\n",
      "Epoch: [456 | 1000] LR: 0.001297\n",
      "Train | 16/16 | Loss:0.0628 | MainLoss:0.0479 | Alpha:0.4887 | SPLoss:0.0032 | CLSLoss:0.1464 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1455 | MainLoss:0.1455 | SPLoss:0.0033 | CLSLoss:0.1463 | AUROC:0.9917\n",
      "Test | 128/16 | Loss:0.7806 | MainLoss:0.7806 | SPLoss:0.0033 | CLSLoss:0.1463 | AUROC:0.9580\n",
      "\n",
      "Epoch: [457 | 1000] LR: 0.001294\n",
      "Train | 16/16 | Loss:0.0552 | MainLoss:0.0402 | Alpha:0.4905 | SPLoss:0.0033 | CLSLoss:0.1463 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1467 | MainLoss:0.1467 | SPLoss:0.0034 | CLSLoss:0.1464 | AUROC:0.9914\n",
      "Test | 128/16 | Loss:0.7716 | MainLoss:0.7716 | SPLoss:0.0034 | CLSLoss:0.1464 | AUROC:0.9582\n",
      "\n",
      "Epoch: [458 | 1000] LR: 0.001291\n",
      "Train | 16/16 | Loss:0.0629 | MainLoss:0.0479 | Alpha:0.4883 | SPLoss:0.0034 | CLSLoss:0.1463 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1466 | MainLoss:0.1466 | SPLoss:0.0034 | CLSLoss:0.1464 | AUROC:0.9912\n",
      "Test | 128/16 | Loss:0.7708 | MainLoss:0.7708 | SPLoss:0.0034 | CLSLoss:0.1464 | AUROC:0.9582\n",
      "\n",
      "Epoch: [459 | 1000] LR: 0.001288\n",
      "Train | 16/16 | Loss:0.0509 | MainLoss:0.0360 | Alpha:0.4908 | SPLoss:0.0035 | CLSLoss:0.1465 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1482 | MainLoss:0.1482 | SPLoss:0.0035 | CLSLoss:0.1465 | AUROC:0.9913\n",
      "Test | 128/16 | Loss:0.7633 | MainLoss:0.7633 | SPLoss:0.0035 | CLSLoss:0.1465 | AUROC:0.9584\n",
      "\n",
      "Epoch: [460 | 1000] LR: 0.001285\n",
      "Train | 16/16 | Loss:0.0634 | MainLoss:0.0484 | Alpha:0.4884 | SPLoss:0.0036 | CLSLoss:0.1465 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1485 | MainLoss:0.1485 | SPLoss:0.0036 | CLSLoss:0.1465 | AUROC:0.9914\n",
      "Test | 128/16 | Loss:0.7604 | MainLoss:0.7604 | SPLoss:0.0036 | CLSLoss:0.1465 | AUROC:0.9584\n",
      "\n",
      "Epoch: [461 | 1000] LR: 0.001282\n",
      "Train | 16/16 | Loss:0.0573 | MainLoss:0.0423 | Alpha:0.4890 | SPLoss:0.0036 | CLSLoss:0.1466 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1487 | MainLoss:0.1487 | SPLoss:0.0037 | CLSLoss:0.1466 | AUROC:0.9914\n",
      "Test | 128/16 | Loss:0.7601 | MainLoss:0.7601 | SPLoss:0.0037 | CLSLoss:0.1466 | AUROC:0.9588\n",
      "\n",
      "Epoch: [462 | 1000] LR: 0.001279\n",
      "Train | 16/16 | Loss:0.0645 | MainLoss:0.0494 | Alpha:0.4887 | SPLoss:0.0037 | CLSLoss:0.1465 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1492 | MainLoss:0.1492 | SPLoss:0.0038 | CLSLoss:0.1464 | AUROC:0.9916\n",
      "Test | 128/16 | Loss:0.7539 | MainLoss:0.7539 | SPLoss:0.0038 | CLSLoss:0.1464 | AUROC:0.9589\n",
      "\n",
      "Epoch: [463 | 1000] LR: 0.001276\n",
      "Train | 16/16 | Loss:0.0564 | MainLoss:0.0413 | Alpha:0.4897 | SPLoss:0.0038 | CLSLoss:0.1464 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1487 | MainLoss:0.1487 | SPLoss:0.0038 | CLSLoss:0.1465 | AUROC:0.9913\n",
      "Test | 128/16 | Loss:0.7584 | MainLoss:0.7584 | SPLoss:0.0038 | CLSLoss:0.1465 | AUROC:0.9585\n",
      "\n",
      "Epoch: [464 | 1000] LR: 0.001273\n",
      "Train | 16/16 | Loss:0.0661 | MainLoss:0.0511 | Alpha:0.4873 | SPLoss:0.0038 | CLSLoss:0.1463 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1476 | MainLoss:0.1476 | SPLoss:0.0039 | CLSLoss:0.1464 | AUROC:0.9914\n",
      "Test | 128/16 | Loss:0.7642 | MainLoss:0.7642 | SPLoss:0.0039 | CLSLoss:0.1464 | AUROC:0.9587\n",
      "\n",
      "Epoch: [465 | 1000] LR: 0.001270\n",
      "Train | 16/16 | Loss:0.0658 | MainLoss:0.0508 | Alpha:0.4872 | SPLoss:0.0039 | CLSLoss:0.1463 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1475 | MainLoss:0.1475 | SPLoss:0.0039 | CLSLoss:0.1462 | AUROC:0.9914\n",
      "Test | 128/16 | Loss:0.7655 | MainLoss:0.7655 | SPLoss:0.0039 | CLSLoss:0.1462 | AUROC:0.9585\n",
      "\n",
      "Epoch: [466 | 1000] LR: 0.001267\n",
      "Train | 16/16 | Loss:0.0607 | MainLoss:0.0457 | Alpha:0.4888 | SPLoss:0.0040 | CLSLoss:0.1462 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1486 | MainLoss:0.1486 | SPLoss:0.0040 | CLSLoss:0.1462 | AUROC:0.9916\n",
      "Test | 128/16 | Loss:0.7582 | MainLoss:0.7582 | SPLoss:0.0040 | CLSLoss:0.1462 | AUROC:0.9583\n",
      "\n",
      "Epoch: [467 | 1000] LR: 0.001264\n",
      "Train | 16/16 | Loss:0.0712 | MainLoss:0.0562 | Alpha:0.4868 | SPLoss:0.0041 | CLSLoss:0.1462 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1475 | MainLoss:0.1475 | SPLoss:0.0041 | CLSLoss:0.1460 | AUROC:0.9915\n",
      "Test | 128/16 | Loss:0.7638 | MainLoss:0.7638 | SPLoss:0.0041 | CLSLoss:0.1460 | AUROC:0.9586\n",
      "\n",
      "Epoch: [468 | 1000] LR: 0.001261\n",
      "Train | 16/16 | Loss:0.0526 | MainLoss:0.0375 | Alpha:0.4911 | SPLoss:0.0041 | CLSLoss:0.1461 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1464 | MainLoss:0.1464 | SPLoss:0.0041 | CLSLoss:0.1462 | AUROC:0.9915\n",
      "Test | 128/16 | Loss:0.7749 | MainLoss:0.7749 | SPLoss:0.0041 | CLSLoss:0.1462 | AUROC:0.9585\n",
      "\n",
      "Epoch: [469 | 1000] LR: 0.001258\n",
      "Train | 16/16 | Loss:0.0620 | MainLoss:0.0470 | Alpha:0.4886 | SPLoss:0.0042 | CLSLoss:0.1461 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1458 | MainLoss:0.1458 | SPLoss:0.0042 | CLSLoss:0.1461 | AUROC:0.9916\n",
      "Test | 128/16 | Loss:0.7800 | MainLoss:0.7800 | SPLoss:0.0042 | CLSLoss:0.1461 | AUROC:0.9581\n",
      "\n",
      "Epoch: [470 | 1000] LR: 0.001255\n",
      "Train | 16/16 | Loss:0.0534 | MainLoss:0.0384 | Alpha:0.4902 | SPLoss:0.0043 | CLSLoss:0.1462 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1468 | MainLoss:0.1468 | SPLoss:0.0043 | CLSLoss:0.1462 | AUROC:0.9917\n",
      "Test | 128/16 | Loss:0.7721 | MainLoss:0.7721 | SPLoss:0.0043 | CLSLoss:0.1462 | AUROC:0.9583\n",
      "\n",
      "Epoch: [471 | 1000] LR: 0.001252\n",
      "Train | 16/16 | Loss:0.0568 | MainLoss:0.0418 | Alpha:0.4896 | SPLoss:0.0044 | CLSLoss:0.1462 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1474 | MainLoss:0.1474 | SPLoss:0.0044 | CLSLoss:0.1463 | AUROC:0.9916\n",
      "Test | 128/16 | Loss:0.7675 | MainLoss:0.7675 | SPLoss:0.0044 | CLSLoss:0.1463 | AUROC:0.9587\n",
      "\n",
      "Epoch: [472 | 1000] LR: 0.001249\n",
      "Train | 16/16 | Loss:0.0600 | MainLoss:0.0449 | Alpha:0.4894 | SPLoss:0.0044 | CLSLoss:0.1463 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1454 | MainLoss:0.1454 | SPLoss:0.0044 | CLSLoss:0.1463 | AUROC:0.9915\n",
      "Test | 128/16 | Loss:0.7836 | MainLoss:0.7836 | SPLoss:0.0044 | CLSLoss:0.1463 | AUROC:0.9583\n",
      "\n",
      "Epoch: [473 | 1000] LR: 0.001246\n",
      "Train | 16/16 | Loss:0.0596 | MainLoss:0.0445 | Alpha:0.4899 | SPLoss:0.0045 | CLSLoss:0.1463 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1455 | MainLoss:0.1455 | SPLoss:0.0045 | CLSLoss:0.1463 | AUROC:0.9915\n",
      "Test | 128/16 | Loss:0.7828 | MainLoss:0.7828 | SPLoss:0.0045 | CLSLoss:0.1463 | AUROC:0.9587\n",
      "\n",
      "Epoch: [474 | 1000] LR: 0.001243\n",
      "Train | 16/16 | Loss:0.0602 | MainLoss:0.0451 | Alpha:0.4896 | SPLoss:0.0045 | CLSLoss:0.1463 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1441 | MainLoss:0.1441 | SPLoss:0.0046 | CLSLoss:0.1462 | AUROC:0.9916\n",
      "Test | 128/16 | Loss:0.7946 | MainLoss:0.7946 | SPLoss:0.0046 | CLSLoss:0.1462 | AUROC:0.9586\n",
      "\n",
      "Epoch: [475 | 1000] LR: 0.001240\n",
      "Train | 16/16 | Loss:0.0564 | MainLoss:0.0413 | Alpha:0.4904 | SPLoss:0.0046 | CLSLoss:0.1462 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1444 | MainLoss:0.1444 | SPLoss:0.0046 | CLSLoss:0.1463 | AUROC:0.9916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 128/16 | Loss:0.7925 | MainLoss:0.7925 | SPLoss:0.0046 | CLSLoss:0.1463 | AUROC:0.9585\n",
      "\n",
      "Epoch: [476 | 1000] LR: 0.001236\n",
      "Train | 16/16 | Loss:0.0620 | MainLoss:0.0469 | Alpha:0.4888 | SPLoss:0.0047 | CLSLoss:0.1462 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1449 | MainLoss:0.1449 | SPLoss:0.0047 | CLSLoss:0.1462 | AUROC:0.9914\n",
      "Test | 128/16 | Loss:0.7849 | MainLoss:0.7849 | SPLoss:0.0047 | CLSLoss:0.1462 | AUROC:0.9585\n",
      "\n",
      "Epoch: [477 | 1000] LR: 0.001233\n",
      "Train | 16/16 | Loss:0.0537 | MainLoss:0.0386 | Alpha:0.4910 | SPLoss:0.0047 | CLSLoss:0.1462 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1456 | MainLoss:0.1456 | SPLoss:0.0048 | CLSLoss:0.1463 | AUROC:0.9916\n",
      "Test | 128/16 | Loss:0.7795 | MainLoss:0.7795 | SPLoss:0.0048 | CLSLoss:0.1463 | AUROC:0.9587\n",
      "\n",
      "Epoch: [478 | 1000] LR: 0.001230\n",
      "Train | 16/16 | Loss:0.0571 | MainLoss:0.0420 | Alpha:0.4895 | SPLoss:0.0048 | CLSLoss:0.1463 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1448 | MainLoss:0.1448 | SPLoss:0.0048 | CLSLoss:0.1463 | AUROC:0.9915\n",
      "Test | 128/16 | Loss:0.7862 | MainLoss:0.7862 | SPLoss:0.0048 | CLSLoss:0.1463 | AUROC:0.9587\n",
      "\n",
      "Epoch: [479 | 1000] LR: 0.001227\n",
      "Train | 16/16 | Loss:0.0538 | MainLoss:0.0387 | Alpha:0.4908 | SPLoss:0.0049 | CLSLoss:0.1464 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1442 | MainLoss:0.1442 | SPLoss:0.0049 | CLSLoss:0.1464 | AUROC:0.9917\n",
      "Test | 128/16 | Loss:0.7931 | MainLoss:0.7931 | SPLoss:0.0049 | CLSLoss:0.1464 | AUROC:0.9583\n",
      "\n",
      "Epoch: [480 | 1000] LR: 0.001224\n",
      "Train | 16/16 | Loss:0.0609 | MainLoss:0.0458 | Alpha:0.4893 | SPLoss:0.0049 | CLSLoss:0.1464 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1438 | MainLoss:0.1438 | SPLoss:0.0049 | CLSLoss:0.1463 | AUROC:0.9917\n",
      "Test | 128/16 | Loss:0.7968 | MainLoss:0.7968 | SPLoss:0.0049 | CLSLoss:0.1463 | AUROC:0.9580\n",
      "\n",
      "Epoch: [481 | 1000] LR: 0.001221\n",
      "Train | 16/16 | Loss:0.0603 | MainLoss:0.0452 | Alpha:0.4894 | SPLoss:0.0050 | CLSLoss:0.1463 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1450 | MainLoss:0.1450 | SPLoss:0.0050 | CLSLoss:0.1462 | AUROC:0.9918\n",
      "Test | 128/16 | Loss:0.7863 | MainLoss:0.7863 | SPLoss:0.0050 | CLSLoss:0.1462 | AUROC:0.9583\n",
      "\n",
      "Epoch: [482 | 1000] LR: 0.001218\n",
      "Train | 16/16 | Loss:0.0638 | MainLoss:0.0487 | Alpha:0.4892 | SPLoss:0.0051 | CLSLoss:0.1463 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1461 | MainLoss:0.1461 | SPLoss:0.0051 | CLSLoss:0.1461 | AUROC:0.9917\n",
      "Test | 128/16 | Loss:0.7789 | MainLoss:0.7789 | SPLoss:0.0051 | CLSLoss:0.1461 | AUROC:0.9581\n",
      "\n",
      "Epoch: [483 | 1000] LR: 0.001215\n",
      "Train | 16/16 | Loss:0.0594 | MainLoss:0.0443 | Alpha:0.4902 | SPLoss:0.0051 | CLSLoss:0.1461 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1458 | MainLoss:0.1458 | SPLoss:0.0052 | CLSLoss:0.1461 | AUROC:0.9918\n",
      "Test | 128/16 | Loss:0.7825 | MainLoss:0.7825 | SPLoss:0.0052 | CLSLoss:0.1461 | AUROC:0.9582\n",
      "\n",
      "Epoch: [484 | 1000] LR: 0.001212\n",
      "Train | 16/16 | Loss:0.0563 | MainLoss:0.0412 | Alpha:0.4906 | SPLoss:0.0052 | CLSLoss:0.1462 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1458 | MainLoss:0.1458 | SPLoss:0.0052 | CLSLoss:0.1462 | AUROC:0.9914\n",
      "Test | 128/16 | Loss:0.7826 | MainLoss:0.7826 | SPLoss:0.0052 | CLSLoss:0.1462 | AUROC:0.9580\n",
      "\n",
      "Epoch: [485 | 1000] LR: 0.001209\n",
      "Train | 16/16 | Loss:0.0644 | MainLoss:0.0493 | Alpha:0.4875 | SPLoss:0.0053 | CLSLoss:0.1461 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1462 | MainLoss:0.1462 | SPLoss:0.0053 | CLSLoss:0.1461 | AUROC:0.9917\n",
      "Test | 128/16 | Loss:0.7769 | MainLoss:0.7769 | SPLoss:0.0053 | CLSLoss:0.1461 | AUROC:0.9581\n",
      "\n",
      "Epoch: [486 | 1000] LR: 0.001206\n",
      "Train | 16/16 | Loss:0.0568 | MainLoss:0.0416 | Alpha:0.4899 | SPLoss:0.0054 | CLSLoss:0.1461 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1459 | MainLoss:0.1459 | SPLoss:0.0054 | CLSLoss:0.1461 | AUROC:0.9918\n",
      "Test | 128/16 | Loss:0.7801 | MainLoss:0.7801 | SPLoss:0.0054 | CLSLoss:0.1461 | AUROC:0.9582\n",
      "\n",
      "Epoch: [487 | 1000] LR: 0.001203\n",
      "Train | 16/16 | Loss:0.0783 | MainLoss:0.0631 | Alpha:0.4845 | SPLoss:0.0054 | CLSLoss:0.1460 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1467 | MainLoss:0.1467 | SPLoss:0.0055 | CLSLoss:0.1458 | AUROC:0.9917\n",
      "Test | 128/16 | Loss:0.7691 | MainLoss:0.7691 | SPLoss:0.0055 | CLSLoss:0.1458 | AUROC:0.9583\n",
      "\n",
      "Epoch: [488 | 1000] LR: 0.001200\n",
      "Train | 16/16 | Loss:0.0552 | MainLoss:0.0401 | Alpha:0.4897 | SPLoss:0.0055 | CLSLoss:0.1458 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1465 | MainLoss:0.1465 | SPLoss:0.0056 | CLSLoss:0.1458 | AUROC:0.9915\n",
      "Test | 128/16 | Loss:0.7698 | MainLoss:0.7698 | SPLoss:0.0056 | CLSLoss:0.1458 | AUROC:0.9586\n",
      "\n",
      "Epoch: [489 | 1000] LR: 0.001197\n",
      "Train | 16/16 | Loss:0.0560 | MainLoss:0.0409 | Alpha:0.4890 | SPLoss:0.0056 | CLSLoss:0.1458 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1465 | MainLoss:0.1465 | SPLoss:0.0056 | CLSLoss:0.1459 | AUROC:0.9916\n",
      "Test | 128/16 | Loss:0.7699 | MainLoss:0.7699 | SPLoss:0.0056 | CLSLoss:0.1459 | AUROC:0.9584\n",
      "\n",
      "Epoch: [490 | 1000] LR: 0.001194\n",
      "Train | 16/16 | Loss:0.0736 | MainLoss:0.0585 | Alpha:0.4864 | SPLoss:0.0057 | CLSLoss:0.1457 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1453 | MainLoss:0.1453 | SPLoss:0.0056 | CLSLoss:0.1456 | AUROC:0.9916\n",
      "Test | 128/16 | Loss:0.7777 | MainLoss:0.7777 | SPLoss:0.0056 | CLSLoss:0.1456 | AUROC:0.9581\n",
      "\n",
      "Epoch: [491 | 1000] LR: 0.001190\n",
      "Train | 16/16 | Loss:0.0507 | MainLoss:0.0356 | Alpha:0.4900 | SPLoss:0.0057 | CLSLoss:0.1457 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1473 | MainLoss:0.1473 | SPLoss:0.0058 | CLSLoss:0.1457 | AUROC:0.9917\n",
      "Test | 128/16 | Loss:0.7628 | MainLoss:0.7628 | SPLoss:0.0058 | CLSLoss:0.1457 | AUROC:0.9586\n",
      "\n",
      "Epoch: [492 | 1000] LR: 0.001187\n",
      "Train | 16/16 | Loss:0.0561 | MainLoss:0.0410 | Alpha:0.4901 | SPLoss:0.0058 | CLSLoss:0.1457 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1463 | MainLoss:0.1463 | SPLoss:0.0059 | CLSLoss:0.1458 | AUROC:0.9917\n",
      "Test | 128/16 | Loss:0.7732 | MainLoss:0.7732 | SPLoss:0.0059 | CLSLoss:0.1458 | AUROC:0.9584\n",
      "\n",
      "Epoch: [493 | 1000] LR: 0.001184\n",
      "Train | 16/16 | Loss:0.0594 | MainLoss:0.0442 | Alpha:0.4887 | SPLoss:0.0059 | CLSLoss:0.1458 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1462 | MainLoss:0.1462 | SPLoss:0.0059 | CLSLoss:0.1458 | AUROC:0.9916\n",
      "Test | 128/16 | Loss:0.7738 | MainLoss:0.7738 | SPLoss:0.0059 | CLSLoss:0.1458 | AUROC:0.9584\n",
      "\n",
      "Epoch: [494 | 1000] LR: 0.001181\n",
      "Train | 16/16 | Loss:0.0518 | MainLoss:0.0366 | Alpha:0.4909 | SPLoss:0.0060 | CLSLoss:0.1458 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1468 | MainLoss:0.1468 | SPLoss:0.0060 | CLSLoss:0.1459 | AUROC:0.9916\n",
      "Test | 128/16 | Loss:0.7695 | MainLoss:0.7695 | SPLoss:0.0060 | CLSLoss:0.1459 | AUROC:0.9588\n",
      "\n",
      "Epoch: [495 | 1000] LR: 0.001178\n",
      "Train | 16/16 | Loss:0.0566 | MainLoss:0.0414 | Alpha:0.4897 | SPLoss:0.0061 | CLSLoss:0.1458 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1467 | MainLoss:0.1467 | SPLoss:0.0061 | CLSLoss:0.1459 | AUROC:0.9918\n",
      "Test | 128/16 | Loss:0.7701 | MainLoss:0.7701 | SPLoss:0.0061 | CLSLoss:0.1459 | AUROC:0.9590\n",
      "\n",
      "Epoch: [496 | 1000] LR: 0.001175\n",
      "Train | 16/16 | Loss:0.0535 | MainLoss:0.0383 | Alpha:0.4906 | SPLoss:0.0061 | CLSLoss:0.1459 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1455 | MainLoss:0.1455 | SPLoss:0.0061 | CLSLoss:0.1460 | AUROC:0.9917\n",
      "Test | 128/16 | Loss:0.7853 | MainLoss:0.7853 | SPLoss:0.0061 | CLSLoss:0.1460 | AUROC:0.9581\n",
      "\n",
      "Epoch: [497 | 1000] LR: 0.001172\n",
      "Train | 16/16 | Loss:0.0558 | MainLoss:0.0406 | Alpha:0.4903 | SPLoss:0.0062 | CLSLoss:0.1460 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1459 | MainLoss:0.1459 | SPLoss:0.0062 | CLSLoss:0.1460 | AUROC:0.9917\n",
      "Test | 128/16 | Loss:0.7835 | MainLoss:0.7835 | SPLoss:0.0062 | CLSLoss:0.1460 | AUROC:0.9580\n",
      "\n",
      "Epoch: [498 | 1000] LR: 0.001169\n",
      "Train | 16/16 | Loss:0.0547 | MainLoss:0.0395 | Alpha:0.4899 | SPLoss:0.0063 | CLSLoss:0.1460 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1464 | MainLoss:0.1464 | SPLoss:0.0063 | CLSLoss:0.1461 | AUROC:0.9916\n",
      "Test | 128/16 | Loss:0.7791 | MainLoss:0.7791 | SPLoss:0.0063 | CLSLoss:0.1461 | AUROC:0.9581\n",
      "\n",
      "Epoch: [499 | 1000] LR: 0.001166\n",
      "Train | 16/16 | Loss:0.0628 | MainLoss:0.0476 | Alpha:0.4884 | SPLoss:0.0063 | CLSLoss:0.1460 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1459 | MainLoss:0.1459 | SPLoss:0.0064 | CLSLoss:0.1459 | AUROC:0.9916\n",
      "Test | 128/16 | Loss:0.7772 | MainLoss:0.7772 | SPLoss:0.0064 | CLSLoss:0.1459 | AUROC:0.9584\n",
      "\n",
      "Epoch: [500 | 1000] LR: 0.001163\n",
      "Train | 16/16 | Loss:0.0629 | MainLoss:0.0477 | Alpha:0.4875 | SPLoss:0.0064 | CLSLoss:0.1459 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1449 | MainLoss:0.1449 | SPLoss:0.0065 | CLSLoss:0.1459 | AUROC:0.9917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 128/16 | Loss:0.7866 | MainLoss:0.7866 | SPLoss:0.0065 | CLSLoss:0.1459 | AUROC:0.9582\n",
      "\n",
      "Epoch: [501 | 1000] LR: 0.001160\n",
      "Train | 16/16 | Loss:0.0616 | MainLoss:0.0470 | Alpha:0.4904 | SPLoss:0.0000 | CLSLoss:0.1458 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1460 | MainLoss:0.1460 | SPLoss:0.0000 | CLSLoss:0.1457 | AUROC:0.9918\n",
      "Test | 128/16 | Loss:0.7763 | MainLoss:0.7763 | SPLoss:0.0000 | CLSLoss:0.1457 | AUROC:0.9583\n",
      "\n",
      "Epoch: [502 | 1000] LR: 0.001156\n",
      "Train | 16/16 | Loss:0.0571 | MainLoss:0.0425 | Alpha:0.4913 | SPLoss:0.0000 | CLSLoss:0.1457 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1459 | MainLoss:0.1459 | SPLoss:0.0000 | CLSLoss:0.1457 | AUROC:0.9917\n",
      "Test | 128/16 | Loss:0.7770 | MainLoss:0.7770 | SPLoss:0.0000 | CLSLoss:0.1457 | AUROC:0.9584\n",
      "\n",
      "Epoch: [503 | 1000] LR: 0.001153\n",
      "Train | 16/16 | Loss:0.0631 | MainLoss:0.0485 | Alpha:0.4884 | SPLoss:0.0000 | CLSLoss:0.1457 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1460 | MainLoss:0.1460 | SPLoss:0.0001 | CLSLoss:0.1455 | AUROC:0.9915\n",
      "Test | 128/16 | Loss:0.7721 | MainLoss:0.7721 | SPLoss:0.0001 | CLSLoss:0.1455 | AUROC:0.9586\n",
      "\n",
      "Epoch: [504 | 1000] LR: 0.001150\n",
      "Train | 16/16 | Loss:0.0556 | MainLoss:0.0410 | Alpha:0.4913 | SPLoss:0.0001 | CLSLoss:0.1456 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1456 | MainLoss:0.1456 | SPLoss:0.0001 | CLSLoss:0.1455 | AUROC:0.9917\n",
      "Test | 128/16 | Loss:0.7752 | MainLoss:0.7752 | SPLoss:0.0001 | CLSLoss:0.1455 | AUROC:0.9586\n",
      "\n",
      "Epoch: [505 | 1000] LR: 0.001147\n",
      "Train | 16/16 | Loss:0.0523 | MainLoss:0.0377 | Alpha:0.4917 | SPLoss:0.0001 | CLSLoss:0.1455 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1464 | MainLoss:0.1464 | SPLoss:0.0001 | CLSLoss:0.1456 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7693 | MainLoss:0.7693 | SPLoss:0.0001 | CLSLoss:0.1456 | AUROC:0.9589\n",
      "\n",
      "Epoch: [506 | 1000] LR: 0.001144\n",
      "Train | 16/16 | Loss:0.0650 | MainLoss:0.0505 | Alpha:0.4892 | SPLoss:0.0001 | CLSLoss:0.1455 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1438 | MainLoss:0.1438 | SPLoss:0.0001 | CLSLoss:0.1455 | AUROC:0.9918\n",
      "Test | 128/16 | Loss:0.7930 | MainLoss:0.7930 | SPLoss:0.0001 | CLSLoss:0.1455 | AUROC:0.9581\n",
      "\n",
      "Epoch: [507 | 1000] LR: 0.001141\n",
      "Train | 16/16 | Loss:0.0589 | MainLoss:0.0444 | Alpha:0.4911 | SPLoss:0.0001 | CLSLoss:0.1454 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1452 | MainLoss:0.1452 | SPLoss:0.0001 | CLSLoss:0.1454 | AUROC:0.9917\n",
      "Test | 128/16 | Loss:0.7757 | MainLoss:0.7757 | SPLoss:0.0001 | CLSLoss:0.1454 | AUROC:0.9586\n",
      "\n",
      "Epoch: [508 | 1000] LR: 0.001138\n",
      "Train | 16/16 | Loss:0.0592 | MainLoss:0.0447 | Alpha:0.4909 | SPLoss:0.0001 | CLSLoss:0.1454 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1452 | MainLoss:0.1452 | SPLoss:0.0001 | CLSLoss:0.1454 | AUROC:0.9917\n",
      "Test | 128/16 | Loss:0.7771 | MainLoss:0.7771 | SPLoss:0.0001 | CLSLoss:0.1454 | AUROC:0.9587\n",
      "\n",
      "Epoch: [509 | 1000] LR: 0.001135\n",
      "Train | 16/16 | Loss:0.0618 | MainLoss:0.0472 | Alpha:0.4901 | SPLoss:0.0002 | CLSLoss:0.1454 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1454 | MainLoss:0.1454 | SPLoss:0.0002 | CLSLoss:0.1453 | AUROC:0.9915\n",
      "Test | 128/16 | Loss:0.7733 | MainLoss:0.7733 | SPLoss:0.0002 | CLSLoss:0.1453 | AUROC:0.9589\n",
      "\n",
      "Epoch: [510 | 1000] LR: 0.001132\n",
      "Train | 16/16 | Loss:0.0605 | MainLoss:0.0459 | Alpha:0.4896 | SPLoss:0.0002 | CLSLoss:0.1453 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1454 | MainLoss:0.1454 | SPLoss:0.0002 | CLSLoss:0.1453 | AUROC:0.9917\n",
      "Test | 128/16 | Loss:0.7734 | MainLoss:0.7734 | SPLoss:0.0002 | CLSLoss:0.1453 | AUROC:0.9591\n",
      "\n",
      "Epoch: [511 | 1000] LR: 0.001128\n",
      "Train | 16/16 | Loss:0.0644 | MainLoss:0.0499 | Alpha:0.4883 | SPLoss:0.0002 | CLSLoss:0.1452 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1457 | MainLoss:0.1457 | SPLoss:0.0002 | CLSLoss:0.1452 | AUROC:0.9918\n",
      "Test | 128/16 | Loss:0.7687 | MainLoss:0.7687 | SPLoss:0.0002 | CLSLoss:0.1452 | AUROC:0.9592\n",
      "\n",
      "Epoch: [512 | 1000] LR: 0.001125\n",
      "Train | 16/16 | Loss:0.0556 | MainLoss:0.0410 | Alpha:0.4911 | SPLoss:0.0002 | CLSLoss:0.1452 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1443 | MainLoss:0.1443 | SPLoss:0.0002 | CLSLoss:0.1452 | AUROC:0.9916\n",
      "Test | 128/16 | Loss:0.7792 | MainLoss:0.7792 | SPLoss:0.0002 | CLSLoss:0.1452 | AUROC:0.9589\n",
      "\n",
      "Epoch: [513 | 1000] LR: 0.001122\n",
      "Train | 16/16 | Loss:0.0575 | MainLoss:0.0430 | Alpha:0.4911 | SPLoss:0.0002 | CLSLoss:0.1452 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1441 | MainLoss:0.1441 | SPLoss:0.0003 | CLSLoss:0.1452 | AUROC:0.9917\n",
      "Test | 128/16 | Loss:0.7815 | MainLoss:0.7815 | SPLoss:0.0003 | CLSLoss:0.1452 | AUROC:0.9588\n",
      "\n",
      "Epoch: [514 | 1000] LR: 0.001119\n",
      "Train | 16/16 | Loss:0.0609 | MainLoss:0.0463 | Alpha:0.4897 | SPLoss:0.0003 | CLSLoss:0.1452 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1426 | MainLoss:0.1426 | SPLoss:0.0003 | CLSLoss:0.1451 | AUROC:0.9915\n",
      "Test | 128/16 | Loss:0.7961 | MainLoss:0.7961 | SPLoss:0.0003 | CLSLoss:0.1451 | AUROC:0.9582\n",
      "\n",
      "Epoch: [515 | 1000] LR: 0.001116\n",
      "Train | 16/16 | Loss:0.0717 | MainLoss:0.0571 | Alpha:0.4880 | SPLoss:0.0003 | CLSLoss:0.1450 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1437 | MainLoss:0.1437 | SPLoss:0.0003 | CLSLoss:0.1449 | AUROC:0.9917\n",
      "Test | 128/16 | Loss:0.7856 | MainLoss:0.7856 | SPLoss:0.0003 | CLSLoss:0.1449 | AUROC:0.9584\n",
      "\n",
      "Epoch: [516 | 1000] LR: 0.001113\n",
      "Train | 16/16 | Loss:0.0553 | MainLoss:0.0408 | Alpha:0.4917 | SPLoss:0.0003 | CLSLoss:0.1449 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1439 | MainLoss:0.1439 | SPLoss:0.0003 | CLSLoss:0.1449 | AUROC:0.9921\n",
      "Test | 128/16 | Loss:0.7843 | MainLoss:0.7843 | SPLoss:0.0003 | CLSLoss:0.1449 | AUROC:0.9588\n",
      "\n",
      "Epoch: [517 | 1000] LR: 0.001110\n",
      "Train | 16/16 | Loss:0.0543 | MainLoss:0.0398 | Alpha:0.4923 | SPLoss:0.0003 | CLSLoss:0.1449 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1441 | MainLoss:0.1441 | SPLoss:0.0004 | CLSLoss:0.1449 | AUROC:0.9918\n",
      "Test | 128/16 | Loss:0.7816 | MainLoss:0.7816 | SPLoss:0.0004 | CLSLoss:0.1449 | AUROC:0.9583\n",
      "\n",
      "Epoch: [518 | 1000] LR: 0.001107\n",
      "Train | 16/16 | Loss:0.0559 | MainLoss:0.0414 | Alpha:0.4912 | SPLoss:0.0004 | CLSLoss:0.1450 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1441 | MainLoss:0.1441 | SPLoss:0.0004 | CLSLoss:0.1449 | AUROC:0.9918\n",
      "Test | 128/16 | Loss:0.7808 | MainLoss:0.7808 | SPLoss:0.0004 | CLSLoss:0.1449 | AUROC:0.9584\n",
      "\n",
      "Epoch: [519 | 1000] LR: 0.001103\n",
      "Train | 16/16 | Loss:0.0587 | MainLoss:0.0442 | Alpha:0.4902 | SPLoss:0.0004 | CLSLoss:0.1450 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1440 | MainLoss:0.1440 | SPLoss:0.0004 | CLSLoss:0.1449 | AUROC:0.9918\n",
      "Test | 128/16 | Loss:0.7826 | MainLoss:0.7826 | SPLoss:0.0004 | CLSLoss:0.1449 | AUROC:0.9589\n",
      "\n",
      "Epoch: [520 | 1000] LR: 0.001100\n",
      "Train | 16/16 | Loss:0.0532 | MainLoss:0.0387 | Alpha:0.4914 | SPLoss:0.0004 | CLSLoss:0.1450 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1440 | MainLoss:0.1440 | SPLoss:0.0004 | CLSLoss:0.1450 | AUROC:0.9916\n",
      "Test | 128/16 | Loss:0.7855 | MainLoss:0.7855 | SPLoss:0.0004 | CLSLoss:0.1450 | AUROC:0.9585\n",
      "\n",
      "Epoch: [521 | 1000] LR: 0.001097\n",
      "Train | 16/16 | Loss:0.0570 | MainLoss:0.0425 | Alpha:0.4909 | SPLoss:0.0004 | CLSLoss:0.1450 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1436 | MainLoss:0.1436 | SPLoss:0.0004 | CLSLoss:0.1450 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7875 | MainLoss:0.7875 | SPLoss:0.0004 | CLSLoss:0.1450 | AUROC:0.9587\n",
      "\n",
      "Epoch: [522 | 1000] LR: 0.001094\n",
      "Train | 16/16 | Loss:0.0580 | MainLoss:0.0435 | Alpha:0.4904 | SPLoss:0.0005 | CLSLoss:0.1450 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1433 | MainLoss:0.1433 | SPLoss:0.0005 | CLSLoss:0.1450 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7904 | MainLoss:0.7904 | SPLoss:0.0005 | CLSLoss:0.1450 | AUROC:0.9586\n",
      "\n",
      "Epoch: [523 | 1000] LR: 0.001091\n",
      "Train | 16/16 | Loss:0.0508 | MainLoss:0.0362 | Alpha:0.4925 | SPLoss:0.0005 | CLSLoss:0.1450 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1433 | MainLoss:0.1433 | SPLoss:0.0005 | CLSLoss:0.1451 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7922 | MainLoss:0.7922 | SPLoss:0.0005 | CLSLoss:0.1451 | AUROC:0.9586\n",
      "\n",
      "Epoch: [524 | 1000] LR: 0.001088\n",
      "Train | 16/16 | Loss:0.0646 | MainLoss:0.0501 | Alpha:0.4889 | SPLoss:0.0005 | CLSLoss:0.1450 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1432 | MainLoss:0.1432 | SPLoss:0.0005 | CLSLoss:0.1449 | AUROC:0.9918\n",
      "Test | 128/16 | Loss:0.7892 | MainLoss:0.7892 | SPLoss:0.0005 | CLSLoss:0.1449 | AUROC:0.9588\n",
      "\n",
      "Epoch: [525 | 1000] LR: 0.001085\n",
      "Train | 16/16 | Loss:0.0573 | MainLoss:0.0427 | Alpha:0.4899 | SPLoss:0.0005 | CLSLoss:0.1449 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1435 | MainLoss:0.1435 | SPLoss:0.0005 | CLSLoss:0.1449 | AUROC:0.9916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 128/16 | Loss:0.7867 | MainLoss:0.7867 | SPLoss:0.0005 | CLSLoss:0.1449 | AUROC:0.9592\n",
      "\n",
      "Epoch: [526 | 1000] LR: 0.001082\n",
      "Train | 16/16 | Loss:0.0668 | MainLoss:0.0523 | Alpha:0.4888 | SPLoss:0.0006 | CLSLoss:0.1449 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1436 | MainLoss:0.1436 | SPLoss:0.0006 | CLSLoss:0.1447 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7780 | MainLoss:0.7780 | SPLoss:0.0006 | CLSLoss:0.1447 | AUROC:0.9596\n",
      "\n",
      "Epoch: [527 | 1000] LR: 0.001078\n",
      "Train | 16/16 | Loss:0.0599 | MainLoss:0.0454 | Alpha:0.4904 | SPLoss:0.0006 | CLSLoss:0.1446 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1444 | MainLoss:0.1444 | SPLoss:0.0006 | CLSLoss:0.1447 | AUROC:0.9918\n",
      "Test | 128/16 | Loss:0.7695 | MainLoss:0.7695 | SPLoss:0.0006 | CLSLoss:0.1447 | AUROC:0.9597\n",
      "\n",
      "Epoch: [528 | 1000] LR: 0.001075\n",
      "Train | 16/16 | Loss:0.0589 | MainLoss:0.0444 | Alpha:0.4906 | SPLoss:0.0006 | CLSLoss:0.1447 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1443 | MainLoss:0.1443 | SPLoss:0.0006 | CLSLoss:0.1446 | AUROC:0.9918\n",
      "Test | 128/16 | Loss:0.7712 | MainLoss:0.7712 | SPLoss:0.0006 | CLSLoss:0.1446 | AUROC:0.9597\n",
      "\n",
      "Epoch: [529 | 1000] LR: 0.001072\n",
      "Train | 16/16 | Loss:0.0677 | MainLoss:0.0532 | Alpha:0.4887 | SPLoss:0.0006 | CLSLoss:0.1446 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1438 | MainLoss:0.1438 | SPLoss:0.0007 | CLSLoss:0.1445 | AUROC:0.9918\n",
      "Test | 128/16 | Loss:0.7732 | MainLoss:0.7732 | SPLoss:0.0007 | CLSLoss:0.1445 | AUROC:0.9594\n",
      "\n",
      "Epoch: [530 | 1000] LR: 0.001069\n",
      "Train | 16/16 | Loss:0.0564 | MainLoss:0.0419 | Alpha:0.4903 | SPLoss:0.0007 | CLSLoss:0.1445 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1447 | MainLoss:0.1447 | SPLoss:0.0007 | CLSLoss:0.1445 | AUROC:0.9918\n",
      "Test | 128/16 | Loss:0.7662 | MainLoss:0.7662 | SPLoss:0.0007 | CLSLoss:0.1445 | AUROC:0.9597\n",
      "\n",
      "Epoch: [531 | 1000] LR: 0.001066\n",
      "Train | 16/16 | Loss:0.0671 | MainLoss:0.0526 | Alpha:0.4888 | SPLoss:0.0007 | CLSLoss:0.1444 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1435 | MainLoss:0.1435 | SPLoss:0.0007 | CLSLoss:0.1444 | AUROC:0.9918\n",
      "Test | 128/16 | Loss:0.7755 | MainLoss:0.7755 | SPLoss:0.0007 | CLSLoss:0.1444 | AUROC:0.9598\n",
      "\n",
      "Epoch: [532 | 1000] LR: 0.001063\n",
      "Train | 16/16 | Loss:0.0613 | MainLoss:0.0468 | Alpha:0.4895 | SPLoss:0.0007 | CLSLoss:0.1444 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1441 | MainLoss:0.1441 | SPLoss:0.0008 | CLSLoss:0.1443 | AUROC:0.9918\n",
      "Test | 128/16 | Loss:0.7702 | MainLoss:0.7702 | SPLoss:0.0008 | CLSLoss:0.1443 | AUROC:0.9595\n",
      "\n",
      "Epoch: [533 | 1000] LR: 0.001060\n",
      "Train | 16/16 | Loss:0.0596 | MainLoss:0.0451 | Alpha:0.4902 | SPLoss:0.0008 | CLSLoss:0.1443 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1443 | MainLoss:0.1443 | SPLoss:0.0008 | CLSLoss:0.1443 | AUROC:0.9918\n",
      "Test | 128/16 | Loss:0.7676 | MainLoss:0.7676 | SPLoss:0.0008 | CLSLoss:0.1443 | AUROC:0.9599\n",
      "\n",
      "Epoch: [534 | 1000] LR: 0.001057\n",
      "Train | 16/16 | Loss:0.0541 | MainLoss:0.0396 | Alpha:0.4911 | SPLoss:0.0008 | CLSLoss:0.1444 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1442 | MainLoss:0.1442 | SPLoss:0.0008 | CLSLoss:0.1444 | AUROC:0.9918\n",
      "Test | 128/16 | Loss:0.7709 | MainLoss:0.7709 | SPLoss:0.0008 | CLSLoss:0.1444 | AUROC:0.9599\n",
      "\n",
      "Epoch: [535 | 1000] LR: 0.001053\n",
      "Train | 16/16 | Loss:0.0500 | MainLoss:0.0355 | Alpha:0.4922 | SPLoss:0.0008 | CLSLoss:0.1444 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1448 | MainLoss:0.1448 | SPLoss:0.0008 | CLSLoss:0.1445 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7676 | MainLoss:0.7676 | SPLoss:0.0008 | CLSLoss:0.1445 | AUROC:0.9601\n",
      "\n",
      "Epoch: [536 | 1000] LR: 0.001050\n",
      "Train | 16/16 | Loss:0.0606 | MainLoss:0.0461 | Alpha:0.4898 | SPLoss:0.0009 | CLSLoss:0.1445 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1438 | MainLoss:0.1438 | SPLoss:0.0009 | CLSLoss:0.1444 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7746 | MainLoss:0.7746 | SPLoss:0.0009 | CLSLoss:0.1444 | AUROC:0.9600\n",
      "\n",
      "Epoch: [537 | 1000] LR: 0.001047\n",
      "Train | 16/16 | Loss:0.0597 | MainLoss:0.0452 | Alpha:0.4900 | SPLoss:0.0009 | CLSLoss:0.1444 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1438 | MainLoss:0.1438 | SPLoss:0.0009 | CLSLoss:0.1443 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7718 | MainLoss:0.7718 | SPLoss:0.0009 | CLSLoss:0.1443 | AUROC:0.9601\n",
      "\n",
      "Epoch: [538 | 1000] LR: 0.001044\n",
      "Train | 16/16 | Loss:0.0557 | MainLoss:0.0412 | Alpha:0.4907 | SPLoss:0.0009 | CLSLoss:0.1443 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1443 | MainLoss:0.1443 | SPLoss:0.0009 | CLSLoss:0.1443 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7691 | MainLoss:0.7691 | SPLoss:0.0009 | CLSLoss:0.1443 | AUROC:0.9599\n",
      "\n",
      "Epoch: [539 | 1000] LR: 0.001041\n",
      "Train | 16/16 | Loss:0.0478 | MainLoss:0.0333 | Alpha:0.4931 | SPLoss:0.0009 | CLSLoss:0.1444 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1453 | MainLoss:0.1453 | SPLoss:0.0009 | CLSLoss:0.1445 | AUROC:0.9918\n",
      "Test | 128/16 | Loss:0.7609 | MainLoss:0.7609 | SPLoss:0.0009 | CLSLoss:0.1445 | AUROC:0.9608\n",
      "\n",
      "Epoch: [540 | 1000] LR: 0.001038\n",
      "Train | 16/16 | Loss:0.0639 | MainLoss:0.0493 | Alpha:0.4896 | SPLoss:0.0010 | CLSLoss:0.1444 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1451 | MainLoss:0.1451 | SPLoss:0.0010 | CLSLoss:0.1443 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7572 | MainLoss:0.7572 | SPLoss:0.0010 | CLSLoss:0.1443 | AUROC:0.9608\n",
      "\n",
      "Epoch: [541 | 1000] LR: 0.001035\n",
      "Train | 16/16 | Loss:0.0455 | MainLoss:0.0309 | Alpha:0.4935 | SPLoss:0.0010 | CLSLoss:0.1444 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1453 | MainLoss:0.1453 | SPLoss:0.0010 | CLSLoss:0.1445 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7599 | MainLoss:0.7599 | SPLoss:0.0010 | CLSLoss:0.1445 | AUROC:0.9607\n",
      "\n",
      "Epoch: [542 | 1000] LR: 0.001031\n",
      "Train | 16/16 | Loss:0.0695 | MainLoss:0.0549 | Alpha:0.4873 | SPLoss:0.0010 | CLSLoss:0.1444 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1450 | MainLoss:0.1450 | SPLoss:0.0010 | CLSLoss:0.1443 | AUROC:0.9918\n",
      "Test | 128/16 | Loss:0.7597 | MainLoss:0.7597 | SPLoss:0.0010 | CLSLoss:0.1443 | AUROC:0.9606\n",
      "\n",
      "Epoch: [543 | 1000] LR: 0.001028\n",
      "Train | 16/16 | Loss:0.0622 | MainLoss:0.0477 | Alpha:0.4889 | SPLoss:0.0011 | CLSLoss:0.1442 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1459 | MainLoss:0.1459 | SPLoss:0.0011 | CLSLoss:0.1442 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7527 | MainLoss:0.7527 | SPLoss:0.0011 | CLSLoss:0.1442 | AUROC:0.9608\n",
      "\n",
      "Epoch: [544 | 1000] LR: 0.001025\n",
      "Train | 16/16 | Loss:0.0519 | MainLoss:0.0373 | Alpha:0.4920 | SPLoss:0.0011 | CLSLoss:0.1443 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1446 | MainLoss:0.1446 | SPLoss:0.0011 | CLSLoss:0.1443 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7662 | MainLoss:0.7662 | SPLoss:0.0011 | CLSLoss:0.1443 | AUROC:0.9605\n",
      "\n",
      "Epoch: [545 | 1000] LR: 0.001022\n",
      "Train | 16/16 | Loss:0.0610 | MainLoss:0.0465 | Alpha:0.4902 | SPLoss:0.0011 | CLSLoss:0.1443 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1448 | MainLoss:0.1448 | SPLoss:0.0011 | CLSLoss:0.1442 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7634 | MainLoss:0.7634 | SPLoss:0.0011 | CLSLoss:0.1442 | AUROC:0.9603\n",
      "\n",
      "Epoch: [546 | 1000] LR: 0.001019\n",
      "Train | 16/16 | Loss:0.0588 | MainLoss:0.0443 | Alpha:0.4901 | SPLoss:0.0011 | CLSLoss:0.1443 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1446 | MainLoss:0.1446 | SPLoss:0.0011 | CLSLoss:0.1442 | AUROC:0.9918\n",
      "Test | 128/16 | Loss:0.7646 | MainLoss:0.7646 | SPLoss:0.0011 | CLSLoss:0.1442 | AUROC:0.9601\n",
      "\n",
      "Epoch: [547 | 1000] LR: 0.001016\n",
      "Train | 16/16 | Loss:0.0567 | MainLoss:0.0421 | Alpha:0.4909 | SPLoss:0.0012 | CLSLoss:0.1443 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1448 | MainLoss:0.1448 | SPLoss:0.0012 | CLSLoss:0.1442 | AUROC:0.9918\n",
      "Test | 128/16 | Loss:0.7632 | MainLoss:0.7632 | SPLoss:0.0012 | CLSLoss:0.1442 | AUROC:0.9600\n",
      "\n",
      "Epoch: [548 | 1000] LR: 0.001013\n",
      "Train | 16/16 | Loss:0.0593 | MainLoss:0.0447 | Alpha:0.4900 | SPLoss:0.0012 | CLSLoss:0.1442 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1444 | MainLoss:0.1444 | SPLoss:0.0012 | CLSLoss:0.1442 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7665 | MainLoss:0.7665 | SPLoss:0.0012 | CLSLoss:0.1442 | AUROC:0.9601\n",
      "\n",
      "Epoch: [549 | 1000] LR: 0.001009\n",
      "Train | 16/16 | Loss:0.0605 | MainLoss:0.0459 | Alpha:0.4896 | SPLoss:0.0012 | CLSLoss:0.1442 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1451 | MainLoss:0.1451 | SPLoss:0.0012 | CLSLoss:0.1442 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7603 | MainLoss:0.7603 | SPLoss:0.0012 | CLSLoss:0.1442 | AUROC:0.9604\n",
      "\n",
      "Epoch: [550 | 1000] LR: 0.001006\n",
      "Train | 16/16 | Loss:0.0630 | MainLoss:0.0484 | Alpha:0.4888 | SPLoss:0.0012 | CLSLoss:0.1442 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1445 | MainLoss:0.1445 | SPLoss:0.0013 | CLSLoss:0.1441 | AUROC:0.9918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 128/16 | Loss:0.7641 | MainLoss:0.7641 | SPLoss:0.0013 | CLSLoss:0.1441 | AUROC:0.9602\n",
      "\n",
      "Epoch: [551 | 1000] LR: 0.001003\n",
      "Train | 16/16 | Loss:0.0656 | MainLoss:0.0510 | Alpha:0.4886 | SPLoss:0.0013 | CLSLoss:0.1441 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1447 | MainLoss:0.1447 | SPLoss:0.0013 | CLSLoss:0.1440 | AUROC:0.9915\n",
      "Test | 128/16 | Loss:0.7629 | MainLoss:0.7629 | SPLoss:0.0013 | CLSLoss:0.1440 | AUROC:0.9597\n",
      "\n",
      "Epoch: [552 | 1000] LR: 0.001000\n",
      "Train | 16/16 | Loss:0.0590 | MainLoss:0.0444 | Alpha:0.4896 | SPLoss:0.0013 | CLSLoss:0.1440 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1448 | MainLoss:0.1448 | SPLoss:0.0013 | CLSLoss:0.1440 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7636 | MainLoss:0.7636 | SPLoss:0.0013 | CLSLoss:0.1440 | AUROC:0.9598\n",
      "\n",
      "Epoch: [553 | 1000] LR: 0.000997\n",
      "Train | 16/16 | Loss:0.0473 | MainLoss:0.0328 | Alpha:0.4932 | SPLoss:0.0013 | CLSLoss:0.1441 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1446 | MainLoss:0.1446 | SPLoss:0.0014 | CLSLoss:0.1442 | AUROC:0.9918\n",
      "Test | 128/16 | Loss:0.7687 | MainLoss:0.7687 | SPLoss:0.0014 | CLSLoss:0.1442 | AUROC:0.9598\n",
      "\n",
      "Epoch: [554 | 1000] LR: 0.000994\n",
      "Train | 16/16 | Loss:0.0536 | MainLoss:0.0390 | Alpha:0.4915 | SPLoss:0.0014 | CLSLoss:0.1442 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1458 | MainLoss:0.1458 | SPLoss:0.0014 | CLSLoss:0.1442 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7589 | MainLoss:0.7589 | SPLoss:0.0014 | CLSLoss:0.1442 | AUROC:0.9600\n",
      "\n",
      "Epoch: [555 | 1000] LR: 0.000991\n",
      "Train | 16/16 | Loss:0.0599 | MainLoss:0.0454 | Alpha:0.4899 | SPLoss:0.0014 | CLSLoss:0.1441 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1458 | MainLoss:0.1458 | SPLoss:0.0014 | CLSLoss:0.1440 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7580 | MainLoss:0.7580 | SPLoss:0.0014 | CLSLoss:0.1440 | AUROC:0.9604\n",
      "\n",
      "Epoch: [556 | 1000] LR: 0.000987\n",
      "Train | 16/16 | Loss:0.0541 | MainLoss:0.0395 | Alpha:0.4923 | SPLoss:0.0014 | CLSLoss:0.1440 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1465 | MainLoss:0.1465 | SPLoss:0.0015 | CLSLoss:0.1441 | AUROC:0.9918\n",
      "Test | 128/16 | Loss:0.7525 | MainLoss:0.7525 | SPLoss:0.0015 | CLSLoss:0.1441 | AUROC:0.9606\n",
      "\n",
      "Epoch: [557 | 1000] LR: 0.000984\n",
      "Train | 16/16 | Loss:0.0438 | MainLoss:0.0292 | Alpha:0.4937 | SPLoss:0.0015 | CLSLoss:0.1441 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1462 | MainLoss:0.1462 | SPLoss:0.0015 | CLSLoss:0.1442 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7584 | MainLoss:0.7584 | SPLoss:0.0015 | CLSLoss:0.1442 | AUROC:0.9602\n",
      "\n",
      "Epoch: [558 | 1000] LR: 0.000981\n",
      "Train | 16/16 | Loss:0.0620 | MainLoss:0.0474 | Alpha:0.4896 | SPLoss:0.0015 | CLSLoss:0.1442 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1457 | MainLoss:0.1457 | SPLoss:0.0015 | CLSLoss:0.1442 | AUROC:0.9918\n",
      "Test | 128/16 | Loss:0.7629 | MainLoss:0.7629 | SPLoss:0.0015 | CLSLoss:0.1442 | AUROC:0.9600\n",
      "\n",
      "Epoch: [559 | 1000] LR: 0.000978\n",
      "Train | 16/16 | Loss:0.0542 | MainLoss:0.0396 | Alpha:0.4917 | SPLoss:0.0015 | CLSLoss:0.1442 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1458 | MainLoss:0.1458 | SPLoss:0.0015 | CLSLoss:0.1442 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7640 | MainLoss:0.7640 | SPLoss:0.0015 | CLSLoss:0.1442 | AUROC:0.9599\n",
      "\n",
      "Epoch: [560 | 1000] LR: 0.000975\n",
      "Train | 16/16 | Loss:0.0603 | MainLoss:0.0458 | Alpha:0.4896 | SPLoss:0.0016 | CLSLoss:0.1442 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1449 | MainLoss:0.1449 | SPLoss:0.0016 | CLSLoss:0.1442 | AUROC:0.9915\n",
      "Test | 128/16 | Loss:0.7708 | MainLoss:0.7708 | SPLoss:0.0016 | CLSLoss:0.1442 | AUROC:0.9595\n",
      "\n",
      "Epoch: [561 | 1000] LR: 0.000972\n",
      "Train | 16/16 | Loss:0.0508 | MainLoss:0.0362 | Alpha:0.4920 | SPLoss:0.0016 | CLSLoss:0.1442 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1450 | MainLoss:0.1450 | SPLoss:0.0016 | CLSLoss:0.1443 | AUROC:0.9918\n",
      "Test | 128/16 | Loss:0.7734 | MainLoss:0.7734 | SPLoss:0.0016 | CLSLoss:0.1443 | AUROC:0.9591\n",
      "\n",
      "Epoch: [562 | 1000] LR: 0.000969\n",
      "Train | 16/16 | Loss:0.0562 | MainLoss:0.0416 | Alpha:0.4904 | SPLoss:0.0016 | CLSLoss:0.1443 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1450 | MainLoss:0.1450 | SPLoss:0.0016 | CLSLoss:0.1443 | AUROC:0.9918\n",
      "Test | 128/16 | Loss:0.7733 | MainLoss:0.7733 | SPLoss:0.0016 | CLSLoss:0.1443 | AUROC:0.9594\n",
      "\n",
      "Epoch: [563 | 1000] LR: 0.000965\n",
      "Train | 16/16 | Loss:0.0538 | MainLoss:0.0392 | Alpha:0.4918 | SPLoss:0.0016 | CLSLoss:0.1443 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1446 | MainLoss:0.1446 | SPLoss:0.0017 | CLSLoss:0.1443 | AUROC:0.9918\n",
      "Test | 128/16 | Loss:0.7776 | MainLoss:0.7776 | SPLoss:0.0017 | CLSLoss:0.1443 | AUROC:0.9593\n",
      "\n",
      "Epoch: [564 | 1000] LR: 0.000962\n",
      "Train | 16/16 | Loss:0.0494 | MainLoss:0.0348 | Alpha:0.4925 | SPLoss:0.0017 | CLSLoss:0.1443 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1451 | MainLoss:0.1451 | SPLoss:0.0017 | CLSLoss:0.1444 | AUROC:0.9918\n",
      "Test | 128/16 | Loss:0.7745 | MainLoss:0.7745 | SPLoss:0.0017 | CLSLoss:0.1444 | AUROC:0.9597\n",
      "\n",
      "Epoch: [565 | 1000] LR: 0.000959\n",
      "Train | 16/16 | Loss:0.0604 | MainLoss:0.0458 | Alpha:0.4899 | SPLoss:0.0017 | CLSLoss:0.1444 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1454 | MainLoss:0.1454 | SPLoss:0.0017 | CLSLoss:0.1443 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7719 | MainLoss:0.7719 | SPLoss:0.0017 | CLSLoss:0.1443 | AUROC:0.9595\n",
      "\n",
      "Epoch: [566 | 1000] LR: 0.000956\n",
      "Train | 16/16 | Loss:0.0510 | MainLoss:0.0364 | Alpha:0.4917 | SPLoss:0.0017 | CLSLoss:0.1444 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1458 | MainLoss:0.1458 | SPLoss:0.0017 | CLSLoss:0.1444 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7702 | MainLoss:0.7702 | SPLoss:0.0017 | CLSLoss:0.1444 | AUROC:0.9594\n",
      "\n",
      "Epoch: [567 | 1000] LR: 0.000953\n",
      "Train | 16/16 | Loss:0.0535 | MainLoss:0.0389 | Alpha:0.4912 | SPLoss:0.0018 | CLSLoss:0.1444 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1455 | MainLoss:0.1455 | SPLoss:0.0018 | CLSLoss:0.1444 | AUROC:0.9922\n",
      "Test | 128/16 | Loss:0.7736 | MainLoss:0.7736 | SPLoss:0.0018 | CLSLoss:0.1444 | AUROC:0.9592\n",
      "\n",
      "Epoch: [568 | 1000] LR: 0.000950\n",
      "Train | 16/16 | Loss:0.0519 | MainLoss:0.0373 | Alpha:0.4922 | SPLoss:0.0018 | CLSLoss:0.1445 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1445 | MainLoss:0.1445 | SPLoss:0.0018 | CLSLoss:0.1445 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7840 | MainLoss:0.7840 | SPLoss:0.0018 | CLSLoss:0.1445 | AUROC:0.9590\n",
      "\n",
      "Epoch: [569 | 1000] LR: 0.000947\n",
      "Train | 16/16 | Loss:0.0553 | MainLoss:0.0406 | Alpha:0.4905 | SPLoss:0.0018 | CLSLoss:0.1445 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1450 | MainLoss:0.1450 | SPLoss:0.0018 | CLSLoss:0.1445 | AUROC:0.9921\n",
      "Test | 128/16 | Loss:0.7795 | MainLoss:0.7795 | SPLoss:0.0018 | CLSLoss:0.1445 | AUROC:0.9591\n",
      "\n",
      "Epoch: [570 | 1000] LR: 0.000943\n",
      "Train | 16/16 | Loss:0.0537 | MainLoss:0.0391 | Alpha:0.4904 | SPLoss:0.0019 | CLSLoss:0.1445 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1453 | MainLoss:0.1453 | SPLoss:0.0019 | CLSLoss:0.1445 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7746 | MainLoss:0.7746 | SPLoss:0.0019 | CLSLoss:0.1445 | AUROC:0.9595\n",
      "\n",
      "Epoch: [571 | 1000] LR: 0.000940\n",
      "Train | 16/16 | Loss:0.0599 | MainLoss:0.0453 | Alpha:0.4902 | SPLoss:0.0019 | CLSLoss:0.1445 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1451 | MainLoss:0.1451 | SPLoss:0.0019 | CLSLoss:0.1445 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7762 | MainLoss:0.7762 | SPLoss:0.0019 | CLSLoss:0.1445 | AUROC:0.9593\n",
      "\n",
      "Epoch: [572 | 1000] LR: 0.000937\n",
      "Train | 16/16 | Loss:0.0562 | MainLoss:0.0416 | Alpha:0.4903 | SPLoss:0.0019 | CLSLoss:0.1445 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1450 | MainLoss:0.1450 | SPLoss:0.0019 | CLSLoss:0.1445 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7764 | MainLoss:0.7764 | SPLoss:0.0019 | CLSLoss:0.1445 | AUROC:0.9597\n",
      "\n",
      "Epoch: [573 | 1000] LR: 0.000934\n",
      "Train | 16/16 | Loss:0.0582 | MainLoss:0.0436 | Alpha:0.4902 | SPLoss:0.0020 | CLSLoss:0.1445 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1448 | MainLoss:0.1448 | SPLoss:0.0020 | CLSLoss:0.1445 | AUROC:0.9918\n",
      "Test | 128/16 | Loss:0.7752 | MainLoss:0.7752 | SPLoss:0.0020 | CLSLoss:0.1445 | AUROC:0.9597\n",
      "\n",
      "Epoch: [574 | 1000] LR: 0.000931\n",
      "Train | 16/16 | Loss:0.0674 | MainLoss:0.0528 | Alpha:0.4888 | SPLoss:0.0020 | CLSLoss:0.1444 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1444 | MainLoss:0.1444 | SPLoss:0.0020 | CLSLoss:0.1443 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7740 | MainLoss:0.7740 | SPLoss:0.0020 | CLSLoss:0.1443 | AUROC:0.9597\n",
      "\n",
      "Epoch: [575 | 1000] LR: 0.000928\n",
      "Train | 16/16 | Loss:0.0553 | MainLoss:0.0407 | Alpha:0.4917 | SPLoss:0.0020 | CLSLoss:0.1443 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1441 | MainLoss:0.1441 | SPLoss:0.0020 | CLSLoss:0.1443 | AUROC:0.9921\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 128/16 | Loss:0.7763 | MainLoss:0.7763 | SPLoss:0.0020 | CLSLoss:0.1443 | AUROC:0.9597\n",
      "\n",
      "Epoch: [576 | 1000] LR: 0.000925\n",
      "Train | 16/16 | Loss:0.0531 | MainLoss:0.0384 | Alpha:0.4908 | SPLoss:0.0021 | CLSLoss:0.1444 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1437 | MainLoss:0.1437 | SPLoss:0.0021 | CLSLoss:0.1444 | AUROC:0.9918\n",
      "Test | 128/16 | Loss:0.7809 | MainLoss:0.7809 | SPLoss:0.0021 | CLSLoss:0.1444 | AUROC:0.9595\n",
      "\n",
      "Epoch: [577 | 1000] LR: 0.000922\n",
      "Train | 16/16 | Loss:0.0598 | MainLoss:0.0451 | Alpha:0.4899 | SPLoss:0.0021 | CLSLoss:0.1444 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0021 | CLSLoss:0.1443 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7831 | MainLoss:0.7831 | SPLoss:0.0021 | CLSLoss:0.1443 | AUROC:0.9593\n",
      "\n",
      "Epoch: [578 | 1000] LR: 0.000918\n",
      "Train | 16/16 | Loss:0.0688 | MainLoss:0.0542 | Alpha:0.4876 | SPLoss:0.0021 | CLSLoss:0.1443 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1430 | MainLoss:0.1430 | SPLoss:0.0022 | CLSLoss:0.1441 | AUROC:0.9918\n",
      "Test | 128/16 | Loss:0.7807 | MainLoss:0.7807 | SPLoss:0.0022 | CLSLoss:0.1441 | AUROC:0.9599\n",
      "\n",
      "Epoch: [579 | 1000] LR: 0.000915\n",
      "Train | 16/16 | Loss:0.0685 | MainLoss:0.0538 | Alpha:0.4883 | SPLoss:0.0022 | CLSLoss:0.1440 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1431 | MainLoss:0.1431 | SPLoss:0.0022 | CLSLoss:0.1440 | AUROC:0.9921\n",
      "Test | 128/16 | Loss:0.7766 | MainLoss:0.7766 | SPLoss:0.0022 | CLSLoss:0.1440 | AUROC:0.9599\n",
      "\n",
      "Epoch: [580 | 1000] LR: 0.000912\n",
      "Train | 16/16 | Loss:0.0680 | MainLoss:0.0534 | Alpha:0.4873 | SPLoss:0.0022 | CLSLoss:0.1439 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1432 | MainLoss:0.1432 | SPLoss:0.0023 | CLSLoss:0.1438 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7754 | MainLoss:0.7754 | SPLoss:0.0023 | CLSLoss:0.1438 | AUROC:0.9598\n",
      "\n",
      "Epoch: [581 | 1000] LR: 0.000909\n",
      "Train | 16/16 | Loss:0.0497 | MainLoss:0.0351 | Alpha:0.4924 | SPLoss:0.0023 | CLSLoss:0.1439 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1432 | MainLoss:0.1432 | SPLoss:0.0023 | CLSLoss:0.1439 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7785 | MainLoss:0.7785 | SPLoss:0.0023 | CLSLoss:0.1439 | AUROC:0.9598\n",
      "\n",
      "Epoch: [582 | 1000] LR: 0.000906\n",
      "Train | 16/16 | Loss:0.0565 | MainLoss:0.0419 | Alpha:0.4905 | SPLoss:0.0023 | CLSLoss:0.1440 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1429 | MainLoss:0.1429 | SPLoss:0.0023 | CLSLoss:0.1439 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7819 | MainLoss:0.7819 | SPLoss:0.0023 | CLSLoss:0.1439 | AUROC:0.9599\n",
      "\n",
      "Epoch: [583 | 1000] LR: 0.000903\n",
      "Train | 16/16 | Loss:0.0663 | MainLoss:0.0516 | Alpha:0.4881 | SPLoss:0.0023 | CLSLoss:0.1439 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1432 | MainLoss:0.1432 | SPLoss:0.0024 | CLSLoss:0.1438 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7797 | MainLoss:0.7797 | SPLoss:0.0024 | CLSLoss:0.1438 | AUROC:0.9600\n",
      "\n",
      "Epoch: [584 | 1000] LR: 0.000900\n",
      "Train | 16/16 | Loss:0.0527 | MainLoss:0.0381 | Alpha:0.4916 | SPLoss:0.0024 | CLSLoss:0.1438 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1437 | MainLoss:0.1437 | SPLoss:0.0024 | CLSLoss:0.1438 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7768 | MainLoss:0.7768 | SPLoss:0.0024 | CLSLoss:0.1438 | AUROC:0.9600\n",
      "\n",
      "Epoch: [585 | 1000] LR: 0.000897\n",
      "Train | 16/16 | Loss:0.0621 | MainLoss:0.0475 | Alpha:0.4895 | SPLoss:0.0024 | CLSLoss:0.1438 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1433 | MainLoss:0.1433 | SPLoss:0.0024 | CLSLoss:0.1437 | AUROC:0.9921\n",
      "Test | 128/16 | Loss:0.7793 | MainLoss:0.7793 | SPLoss:0.0024 | CLSLoss:0.1437 | AUROC:0.9601\n",
      "\n",
      "Epoch: [586 | 1000] LR: 0.000893\n",
      "Train | 16/16 | Loss:0.0554 | MainLoss:0.0408 | Alpha:0.4906 | SPLoss:0.0024 | CLSLoss:0.1438 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1437 | MainLoss:0.1437 | SPLoss:0.0025 | CLSLoss:0.1438 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7766 | MainLoss:0.7766 | SPLoss:0.0025 | CLSLoss:0.1438 | AUROC:0.9603\n",
      "\n",
      "Epoch: [587 | 1000] LR: 0.000890\n",
      "Train | 16/16 | Loss:0.0629 | MainLoss:0.0482 | Alpha:0.4896 | SPLoss:0.0025 | CLSLoss:0.1438 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1427 | MainLoss:0.1427 | SPLoss:0.0025 | CLSLoss:0.1437 | AUROC:0.9922\n",
      "Test | 128/16 | Loss:0.7845 | MainLoss:0.7845 | SPLoss:0.0025 | CLSLoss:0.1437 | AUROC:0.9598\n",
      "\n",
      "Epoch: [588 | 1000] LR: 0.000887\n",
      "Train | 16/16 | Loss:0.0547 | MainLoss:0.0400 | Alpha:0.4902 | SPLoss:0.0025 | CLSLoss:0.1437 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1424 | MainLoss:0.1424 | SPLoss:0.0025 | CLSLoss:0.1437 | AUROC:0.9918\n",
      "Test | 128/16 | Loss:0.7877 | MainLoss:0.7877 | SPLoss:0.0025 | CLSLoss:0.1437 | AUROC:0.9593\n",
      "\n",
      "Epoch: [589 | 1000] LR: 0.000884\n",
      "Train | 16/16 | Loss:0.0730 | MainLoss:0.0584 | Alpha:0.4873 | SPLoss:0.0025 | CLSLoss:0.1436 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1427 | MainLoss:0.1427 | SPLoss:0.0026 | CLSLoss:0.1435 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7810 | MainLoss:0.7810 | SPLoss:0.0026 | CLSLoss:0.1435 | AUROC:0.9601\n",
      "\n",
      "Epoch: [590 | 1000] LR: 0.000881\n",
      "Train | 16/16 | Loss:0.0579 | MainLoss:0.0433 | Alpha:0.4914 | SPLoss:0.0026 | CLSLoss:0.1435 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1429 | MainLoss:0.1429 | SPLoss:0.0026 | CLSLoss:0.1434 | AUROC:0.9917\n",
      "Test | 128/16 | Loss:0.7793 | MainLoss:0.7793 | SPLoss:0.0026 | CLSLoss:0.1434 | AUROC:0.9602\n",
      "\n",
      "Epoch: [591 | 1000] LR: 0.000878\n",
      "Train | 16/16 | Loss:0.0664 | MainLoss:0.0518 | Alpha:0.4885 | SPLoss:0.0026 | CLSLoss:0.1434 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0026 | CLSLoss:0.1433 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7742 | MainLoss:0.7742 | SPLoss:0.0026 | CLSLoss:0.1433 | AUROC:0.9602\n",
      "\n",
      "Epoch: [592 | 1000] LR: 0.000875\n",
      "Train | 16/16 | Loss:0.0563 | MainLoss:0.0417 | Alpha:0.4904 | SPLoss:0.0026 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0026 | CLSLoss:0.1433 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7747 | MainLoss:0.7747 | SPLoss:0.0026 | CLSLoss:0.1433 | AUROC:0.9600\n",
      "\n",
      "Epoch: [593 | 1000] LR: 0.000872\n",
      "Train | 16/16 | Loss:0.0523 | MainLoss:0.0377 | Alpha:0.4916 | SPLoss:0.0027 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1433 | MainLoss:0.1433 | SPLoss:0.0027 | CLSLoss:0.1434 | AUROC:0.9921\n",
      "Test | 128/16 | Loss:0.7773 | MainLoss:0.7773 | SPLoss:0.0027 | CLSLoss:0.1434 | AUROC:0.9600\n",
      "\n",
      "Epoch: [594 | 1000] LR: 0.000868\n",
      "Train | 16/16 | Loss:0.0556 | MainLoss:0.0410 | Alpha:0.4900 | SPLoss:0.0027 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1441 | MainLoss:0.1441 | SPLoss:0.0027 | CLSLoss:0.1434 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7715 | MainLoss:0.7715 | SPLoss:0.0027 | CLSLoss:0.1434 | AUROC:0.9603\n",
      "\n",
      "Epoch: [595 | 1000] LR: 0.000865\n",
      "Train | 16/16 | Loss:0.0482 | MainLoss:0.0336 | Alpha:0.4926 | SPLoss:0.0027 | CLSLoss:0.1434 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1446 | MainLoss:0.1446 | SPLoss:0.0027 | CLSLoss:0.1435 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7686 | MainLoss:0.7686 | SPLoss:0.0027 | CLSLoss:0.1435 | AUROC:0.9602\n",
      "\n",
      "Epoch: [596 | 1000] LR: 0.000862\n",
      "Train | 16/16 | Loss:0.0517 | MainLoss:0.0370 | Alpha:0.4917 | SPLoss:0.0028 | CLSLoss:0.1435 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1437 | MainLoss:0.1437 | SPLoss:0.0028 | CLSLoss:0.1435 | AUROC:0.9921\n",
      "Test | 128/16 | Loss:0.7757 | MainLoss:0.7757 | SPLoss:0.0028 | CLSLoss:0.1435 | AUROC:0.9602\n",
      "\n",
      "Epoch: [597 | 1000] LR: 0.000859\n",
      "Train | 16/16 | Loss:0.0538 | MainLoss:0.0392 | Alpha:0.4918 | SPLoss:0.0028 | CLSLoss:0.1435 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1428 | MainLoss:0.1428 | SPLoss:0.0028 | CLSLoss:0.1436 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7847 | MainLoss:0.7847 | SPLoss:0.0028 | CLSLoss:0.1436 | AUROC:0.9597\n",
      "\n",
      "Epoch: [598 | 1000] LR: 0.000856\n",
      "Train | 16/16 | Loss:0.0621 | MainLoss:0.0475 | Alpha:0.4891 | SPLoss:0.0028 | CLSLoss:0.1435 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1418 | MainLoss:0.1418 | SPLoss:0.0028 | CLSLoss:0.1435 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7925 | MainLoss:0.7925 | SPLoss:0.0028 | CLSLoss:0.1435 | AUROC:0.9598\n",
      "\n",
      "Epoch: [599 | 1000] LR: 0.000853\n",
      "Train | 16/16 | Loss:0.0527 | MainLoss:0.0380 | Alpha:0.4915 | SPLoss:0.0028 | CLSLoss:0.1435 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1422 | MainLoss:0.1422 | SPLoss:0.0029 | CLSLoss:0.1436 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7922 | MainLoss:0.7922 | SPLoss:0.0029 | CLSLoss:0.1436 | AUROC:0.9599\n",
      "\n",
      "Epoch: [600 | 1000] LR: 0.000850\n",
      "Train | 16/16 | Loss:0.0603 | MainLoss:0.0456 | Alpha:0.4904 | SPLoss:0.0029 | CLSLoss:0.1435 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1422 | MainLoss:0.1422 | SPLoss:0.0029 | CLSLoss:0.1435 | AUROC:0.9919\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 128/16 | Loss:0.7910 | MainLoss:0.7910 | SPLoss:0.0029 | CLSLoss:0.1435 | AUROC:0.9596\n",
      "\n",
      "Epoch: [601 | 1000] LR: 0.000085\n",
      "Train | 16/16 | Loss:0.0693 | MainLoss:0.0549 | Alpha:0.4880 | SPLoss:0.0000 | CLSLoss:0.1435 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1422 | MainLoss:0.1422 | SPLoss:0.0000 | CLSLoss:0.1435 | AUROC:0.9922\n",
      "Test | 128/16 | Loss:0.7909 | MainLoss:0.7909 | SPLoss:0.0000 | CLSLoss:0.1435 | AUROC:0.9597\n",
      "\n",
      "Epoch: [602 | 1000] LR: 0.000084\n",
      "Train | 16/16 | Loss:0.0642 | MainLoss:0.0499 | Alpha:0.4892 | SPLoss:0.0000 | CLSLoss:0.1435 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1422 | MainLoss:0.1422 | SPLoss:0.0000 | CLSLoss:0.1435 | AUROC:0.9917\n",
      "Test | 128/16 | Loss:0.7912 | MainLoss:0.7912 | SPLoss:0.0000 | CLSLoss:0.1435 | AUROC:0.9598\n",
      "\n",
      "Epoch: [603 | 1000] LR: 0.000084\n",
      "Train | 16/16 | Loss:0.0669 | MainLoss:0.0525 | Alpha:0.4885 | SPLoss:0.0000 | CLSLoss:0.1435 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1422 | MainLoss:0.1422 | SPLoss:0.0000 | CLSLoss:0.1434 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7907 | MainLoss:0.7907 | SPLoss:0.0000 | CLSLoss:0.1434 | AUROC:0.9599\n",
      "\n",
      "Epoch: [604 | 1000] LR: 0.000084\n",
      "Train | 16/16 | Loss:0.0672 | MainLoss:0.0528 | Alpha:0.4881 | SPLoss:0.0000 | CLSLoss:0.1434 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1422 | MainLoss:0.1422 | SPLoss:0.0000 | CLSLoss:0.1434 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7904 | MainLoss:0.7904 | SPLoss:0.0000 | CLSLoss:0.1434 | AUROC:0.9599\n",
      "\n",
      "Epoch: [605 | 1000] LR: 0.000083\n",
      "Train | 16/16 | Loss:0.0572 | MainLoss:0.0428 | Alpha:0.4908 | SPLoss:0.0000 | CLSLoss:0.1434 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1421 | MainLoss:0.1421 | SPLoss:0.0000 | CLSLoss:0.1434 | AUROC:0.9921\n",
      "Test | 128/16 | Loss:0.7907 | MainLoss:0.7907 | SPLoss:0.0000 | CLSLoss:0.1434 | AUROC:0.9598\n",
      "\n",
      "Epoch: [606 | 1000] LR: 0.000083\n",
      "Train | 16/16 | Loss:0.0584 | MainLoss:0.0441 | Alpha:0.4904 | SPLoss:0.0000 | CLSLoss:0.1434 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1422 | MainLoss:0.1422 | SPLoss:0.0000 | CLSLoss:0.1434 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7899 | MainLoss:0.7899 | SPLoss:0.0000 | CLSLoss:0.1434 | AUROC:0.9598\n",
      "\n",
      "Epoch: [607 | 1000] LR: 0.000083\n",
      "Train | 16/16 | Loss:0.0502 | MainLoss:0.0358 | Alpha:0.4926 | SPLoss:0.0000 | CLSLoss:0.1434 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1423 | MainLoss:0.1423 | SPLoss:0.0000 | CLSLoss:0.1434 | AUROC:0.9921\n",
      "Test | 128/16 | Loss:0.7896 | MainLoss:0.7896 | SPLoss:0.0000 | CLSLoss:0.1434 | AUROC:0.9599\n",
      "\n",
      "Epoch: [608 | 1000] LR: 0.000082\n",
      "Train | 16/16 | Loss:0.0586 | MainLoss:0.0442 | Alpha:0.4911 | SPLoss:0.0000 | CLSLoss:0.1434 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1423 | MainLoss:0.1423 | SPLoss:0.0000 | CLSLoss:0.1434 | AUROC:0.9918\n",
      "Test | 128/16 | Loss:0.7892 | MainLoss:0.7892 | SPLoss:0.0000 | CLSLoss:0.1434 | AUROC:0.9599\n",
      "\n",
      "Epoch: [609 | 1000] LR: 0.000082\n",
      "Train | 16/16 | Loss:0.0558 | MainLoss:0.0415 | Alpha:0.4915 | SPLoss:0.0000 | CLSLoss:0.1434 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1423 | MainLoss:0.1423 | SPLoss:0.0000 | CLSLoss:0.1434 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7886 | MainLoss:0.7886 | SPLoss:0.0000 | CLSLoss:0.1434 | AUROC:0.9601\n",
      "\n",
      "Epoch: [610 | 1000] LR: 0.000082\n",
      "Train | 16/16 | Loss:0.0568 | MainLoss:0.0425 | Alpha:0.4916 | SPLoss:0.0000 | CLSLoss:0.1434 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1423 | MainLoss:0.1423 | SPLoss:0.0000 | CLSLoss:0.1434 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7887 | MainLoss:0.7887 | SPLoss:0.0000 | CLSLoss:0.1434 | AUROC:0.9598\n",
      "\n",
      "Epoch: [611 | 1000] LR: 0.000082\n",
      "Train | 16/16 | Loss:0.0789 | MainLoss:0.0646 | Alpha:0.4851 | SPLoss:0.0000 | CLSLoss:0.1434 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1424 | MainLoss:0.1424 | SPLoss:0.0000 | CLSLoss:0.1434 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7878 | MainLoss:0.7878 | SPLoss:0.0000 | CLSLoss:0.1434 | AUROC:0.9598\n",
      "\n",
      "Epoch: [612 | 1000] LR: 0.000081\n",
      "Train | 16/16 | Loss:0.0608 | MainLoss:0.0465 | Alpha:0.4895 | SPLoss:0.0000 | CLSLoss:0.1434 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1424 | MainLoss:0.1424 | SPLoss:0.0000 | CLSLoss:0.1434 | AUROC:0.9921\n",
      "Test | 128/16 | Loss:0.7870 | MainLoss:0.7870 | SPLoss:0.0000 | CLSLoss:0.1434 | AUROC:0.9598\n",
      "\n",
      "Epoch: [613 | 1000] LR: 0.000081\n",
      "Train | 16/16 | Loss:0.0564 | MainLoss:0.0420 | Alpha:0.4914 | SPLoss:0.0000 | CLSLoss:0.1434 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1424 | MainLoss:0.1424 | SPLoss:0.0000 | CLSLoss:0.1434 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7868 | MainLoss:0.7868 | SPLoss:0.0000 | CLSLoss:0.1434 | AUROC:0.9601\n",
      "\n",
      "Epoch: [614 | 1000] LR: 0.000081\n",
      "Train | 16/16 | Loss:0.0750 | MainLoss:0.0607 | Alpha:0.4863 | SPLoss:0.0000 | CLSLoss:0.1434 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1425 | MainLoss:0.1425 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7861 | MainLoss:0.7861 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9601\n",
      "\n",
      "Epoch: [615 | 1000] LR: 0.000080\n",
      "Train | 16/16 | Loss:0.0493 | MainLoss:0.0350 | Alpha:0.4928 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1425 | MainLoss:0.1425 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7856 | MainLoss:0.7856 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9598\n",
      "\n",
      "Epoch: [616 | 1000] LR: 0.000080\n",
      "Train | 16/16 | Loss:0.0553 | MainLoss:0.0410 | Alpha:0.4919 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1426 | MainLoss:0.1426 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7851 | MainLoss:0.7851 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9598\n",
      "\n",
      "Epoch: [617 | 1000] LR: 0.000080\n",
      "Train | 16/16 | Loss:0.0523 | MainLoss:0.0379 | Alpha:0.4921 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1427 | MainLoss:0.1427 | SPLoss:0.0000 | CLSLoss:0.1434 | AUROC:0.9921\n",
      "Test | 128/16 | Loss:0.7846 | MainLoss:0.7846 | SPLoss:0.0000 | CLSLoss:0.1434 | AUROC:0.9599\n",
      "\n",
      "Epoch: [618 | 1000] LR: 0.000079\n",
      "Train | 16/16 | Loss:0.0562 | MainLoss:0.0418 | Alpha:0.4910 | SPLoss:0.0000 | CLSLoss:0.1434 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1426 | MainLoss:0.1426 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7851 | MainLoss:0.7851 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9598\n",
      "\n",
      "Epoch: [619 | 1000] LR: 0.000079\n",
      "Train | 16/16 | Loss:0.0643 | MainLoss:0.0499 | Alpha:0.4892 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1426 | MainLoss:0.1426 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7852 | MainLoss:0.7852 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9601\n",
      "\n",
      "Epoch: [620 | 1000] LR: 0.000079\n",
      "Train | 16/16 | Loss:0.0583 | MainLoss:0.0439 | Alpha:0.4907 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1426 | MainLoss:0.1426 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7854 | MainLoss:0.7854 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9599\n",
      "\n",
      "Epoch: [621 | 1000] LR: 0.000078\n",
      "Train | 16/16 | Loss:0.0491 | MainLoss:0.0348 | Alpha:0.4931 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1426 | MainLoss:0.1426 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9922\n",
      "Test | 128/16 | Loss:0.7852 | MainLoss:0.7852 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9598\n",
      "\n",
      "Epoch: [622 | 1000] LR: 0.000078\n",
      "Train | 16/16 | Loss:0.0501 | MainLoss:0.0357 | Alpha:0.4926 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1427 | MainLoss:0.1427 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7849 | MainLoss:0.7849 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9599\n",
      "\n",
      "Epoch: [623 | 1000] LR: 0.000078\n",
      "Train | 16/16 | Loss:0.0620 | MainLoss:0.0476 | Alpha:0.4890 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1427 | MainLoss:0.1427 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9922\n",
      "Test | 128/16 | Loss:0.7849 | MainLoss:0.7849 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9599\n",
      "\n",
      "Epoch: [624 | 1000] LR: 0.000078\n",
      "Train | 16/16 | Loss:0.0516 | MainLoss:0.0373 | Alpha:0.4921 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1426 | MainLoss:0.1426 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9921\n",
      "Test | 128/16 | Loss:0.7854 | MainLoss:0.7854 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9598\n",
      "\n",
      "Epoch: [625 | 1000] LR: 0.000077\n",
      "Train | 16/16 | Loss:0.0601 | MainLoss:0.0457 | Alpha:0.4904 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1427 | MainLoss:0.1427 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 128/16 | Loss:0.7851 | MainLoss:0.7851 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9600\n",
      "\n",
      "Epoch: [626 | 1000] LR: 0.000077\n",
      "Train | 16/16 | Loss:0.0592 | MainLoss:0.0449 | Alpha:0.4901 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1427 | MainLoss:0.1427 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7847 | MainLoss:0.7847 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9600\n",
      "\n",
      "Epoch: [627 | 1000] LR: 0.000077\n",
      "Train | 16/16 | Loss:0.0640 | MainLoss:0.0497 | Alpha:0.4892 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1427 | MainLoss:0.1427 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7849 | MainLoss:0.7849 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9599\n",
      "\n",
      "Epoch: [628 | 1000] LR: 0.000076\n",
      "Train | 16/16 | Loss:0.0497 | MainLoss:0.0354 | Alpha:0.4928 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1428 | MainLoss:0.1428 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7842 | MainLoss:0.7842 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9600\n",
      "\n",
      "Epoch: [629 | 1000] LR: 0.000076\n",
      "Train | 16/16 | Loss:0.0515 | MainLoss:0.0372 | Alpha:0.4923 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1428 | MainLoss:0.1428 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9921\n",
      "Test | 128/16 | Loss:0.7842 | MainLoss:0.7842 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9599\n",
      "\n",
      "Epoch: [630 | 1000] LR: 0.000076\n",
      "Train | 16/16 | Loss:0.0514 | MainLoss:0.0371 | Alpha:0.4918 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1429 | MainLoss:0.1429 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7832 | MainLoss:0.7832 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9599\n",
      "\n",
      "Epoch: [631 | 1000] LR: 0.000075\n",
      "Train | 16/16 | Loss:0.0621 | MainLoss:0.0478 | Alpha:0.4899 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1428 | MainLoss:0.1428 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7841 | MainLoss:0.7841 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9602\n",
      "\n",
      "Epoch: [632 | 1000] LR: 0.000075\n",
      "Train | 16/16 | Loss:0.0546 | MainLoss:0.0403 | Alpha:0.4913 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1428 | MainLoss:0.1428 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9922\n",
      "Test | 128/16 | Loss:0.7836 | MainLoss:0.7836 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9603\n",
      "\n",
      "Epoch: [633 | 1000] LR: 0.000075\n",
      "Train | 16/16 | Loss:0.0543 | MainLoss:0.0400 | Alpha:0.4916 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1429 | MainLoss:0.1429 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7831 | MainLoss:0.7831 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9599\n",
      "\n",
      "Epoch: [634 | 1000] LR: 0.000075\n",
      "Train | 16/16 | Loss:0.0644 | MainLoss:0.0500 | Alpha:0.4896 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1429 | MainLoss:0.1429 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9921\n",
      "Test | 128/16 | Loss:0.7831 | MainLoss:0.7831 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9600\n",
      "\n",
      "Epoch: [635 | 1000] LR: 0.000074\n",
      "Train | 16/16 | Loss:0.0580 | MainLoss:0.0437 | Alpha:0.4907 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1429 | MainLoss:0.1429 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7832 | MainLoss:0.7832 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9602\n",
      "\n",
      "Epoch: [636 | 1000] LR: 0.000074\n",
      "Train | 16/16 | Loss:0.0606 | MainLoss:0.0463 | Alpha:0.4901 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1429 | MainLoss:0.1429 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7827 | MainLoss:0.7827 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9600\n",
      "\n",
      "Epoch: [637 | 1000] LR: 0.000074\n",
      "Train | 16/16 | Loss:0.0575 | MainLoss:0.0432 | Alpha:0.4907 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1429 | MainLoss:0.1429 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9918\n",
      "Test | 128/16 | Loss:0.7823 | MainLoss:0.7823 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9599\n",
      "\n",
      "Epoch: [638 | 1000] LR: 0.000073\n",
      "Train | 16/16 | Loss:0.0527 | MainLoss:0.0384 | Alpha:0.4921 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1430 | MainLoss:0.1430 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9921\n",
      "Test | 128/16 | Loss:0.7823 | MainLoss:0.7823 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9598\n",
      "\n",
      "Epoch: [639 | 1000] LR: 0.000073\n",
      "Train | 16/16 | Loss:0.0537 | MainLoss:0.0394 | Alpha:0.4915 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1429 | MainLoss:0.1429 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7832 | MainLoss:0.7832 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9599\n",
      "\n",
      "Epoch: [640 | 1000] LR: 0.000073\n",
      "Train | 16/16 | Loss:0.0576 | MainLoss:0.0432 | Alpha:0.4901 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1428 | MainLoss:0.1428 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7831 | MainLoss:0.7831 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9599\n",
      "\n",
      "Epoch: [641 | 1000] LR: 0.000072\n",
      "Train | 16/16 | Loss:0.0543 | MainLoss:0.0399 | Alpha:0.4916 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1428 | MainLoss:0.1428 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7834 | MainLoss:0.7834 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9600\n",
      "\n",
      "Epoch: [642 | 1000] LR: 0.000072\n",
      "Train | 16/16 | Loss:0.0525 | MainLoss:0.0382 | Alpha:0.4915 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1429 | MainLoss:0.1429 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7832 | MainLoss:0.7832 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9599\n",
      "\n",
      "Epoch: [643 | 1000] LR: 0.000072\n",
      "Train | 16/16 | Loss:0.0545 | MainLoss:0.0401 | Alpha:0.4917 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1429 | MainLoss:0.1429 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9921\n",
      "Test | 128/16 | Loss:0.7825 | MainLoss:0.7825 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9597\n",
      "\n",
      "Epoch: [644 | 1000] LR: 0.000071\n",
      "Train | 16/16 | Loss:0.0504 | MainLoss:0.0360 | Alpha:0.4928 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1430 | MainLoss:0.1430 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7822 | MainLoss:0.7822 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9600\n",
      "\n",
      "Epoch: [645 | 1000] LR: 0.000071\n",
      "Train | 16/16 | Loss:0.0565 | MainLoss:0.0421 | Alpha:0.4905 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1430 | MainLoss:0.1430 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7821 | MainLoss:0.7821 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9599\n",
      "\n",
      "Epoch: [646 | 1000] LR: 0.000071\n",
      "Train | 16/16 | Loss:0.0586 | MainLoss:0.0443 | Alpha:0.4911 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1430 | MainLoss:0.1430 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7824 | MainLoss:0.7824 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9599\n",
      "\n",
      "Epoch: [647 | 1000] LR: 0.000071\n",
      "Train | 16/16 | Loss:0.0600 | MainLoss:0.0457 | Alpha:0.4908 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1431 | MainLoss:0.1431 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7812 | MainLoss:0.7812 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9601\n",
      "\n",
      "Epoch: [648 | 1000] LR: 0.000070\n",
      "Train | 16/16 | Loss:0.0548 | MainLoss:0.0404 | Alpha:0.4915 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1431 | MainLoss:0.1431 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7809 | MainLoss:0.7809 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9598\n",
      "\n",
      "Epoch: [649 | 1000] LR: 0.000070\n",
      "Train | 16/16 | Loss:0.0697 | MainLoss:0.0553 | Alpha:0.4889 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1431 | MainLoss:0.1431 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9922\n",
      "Test | 128/16 | Loss:0.7802 | MainLoss:0.7802 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9600\n",
      "\n",
      "Epoch: [650 | 1000] LR: 0.000070\n",
      "Train | 16/16 | Loss:0.0477 | MainLoss:0.0334 | Alpha:0.4929 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1431 | MainLoss:0.1431 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9919\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 128/16 | Loss:0.7804 | MainLoss:0.7804 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9599\n",
      "\n",
      "Epoch: [651 | 1000] LR: 0.000069\n",
      "Train | 16/16 | Loss:0.0546 | MainLoss:0.0403 | Alpha:0.4918 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1431 | MainLoss:0.1431 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7805 | MainLoss:0.7805 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9601\n",
      "\n",
      "Epoch: [652 | 1000] LR: 0.000069\n",
      "Train | 16/16 | Loss:0.0612 | MainLoss:0.0469 | Alpha:0.4901 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1432 | MainLoss:0.1432 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7798 | MainLoss:0.7798 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9602\n",
      "\n",
      "Epoch: [653 | 1000] LR: 0.000069\n",
      "Train | 16/16 | Loss:0.0570 | MainLoss:0.0426 | Alpha:0.4913 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1431 | MainLoss:0.1431 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7802 | MainLoss:0.7802 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9603\n",
      "\n",
      "Epoch: [654 | 1000] LR: 0.000069\n",
      "Train | 16/16 | Loss:0.0543 | MainLoss:0.0400 | Alpha:0.4920 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1431 | MainLoss:0.1431 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9918\n",
      "Test | 128/16 | Loss:0.7802 | MainLoss:0.7802 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9603\n",
      "\n",
      "Epoch: [655 | 1000] LR: 0.000068\n",
      "Train | 16/16 | Loss:0.0675 | MainLoss:0.0531 | Alpha:0.4892 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1431 | MainLoss:0.1431 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9918\n",
      "Test | 128/16 | Loss:0.7805 | MainLoss:0.7805 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9602\n",
      "\n",
      "Epoch: [656 | 1000] LR: 0.000068\n",
      "Train | 16/16 | Loss:0.0665 | MainLoss:0.0522 | Alpha:0.4890 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1430 | MainLoss:0.1430 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7806 | MainLoss:0.7806 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9602\n",
      "\n",
      "Epoch: [657 | 1000] LR: 0.000068\n",
      "Train | 16/16 | Loss:0.0714 | MainLoss:0.0571 | Alpha:0.4879 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1431 | MainLoss:0.1431 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7791 | MainLoss:0.7791 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9602\n",
      "\n",
      "Epoch: [658 | 1000] LR: 0.000067\n",
      "Train | 16/16 | Loss:0.0557 | MainLoss:0.0413 | Alpha:0.4911 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1431 | MainLoss:0.1431 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7793 | MainLoss:0.7793 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9599\n",
      "\n",
      "Epoch: [659 | 1000] LR: 0.000067\n",
      "Train | 16/16 | Loss:0.0566 | MainLoss:0.0422 | Alpha:0.4911 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1432 | MainLoss:0.1432 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7786 | MainLoss:0.7786 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9601\n",
      "\n",
      "Epoch: [660 | 1000] LR: 0.000067\n",
      "Train | 16/16 | Loss:0.0526 | MainLoss:0.0383 | Alpha:0.4911 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1432 | MainLoss:0.1432 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7785 | MainLoss:0.7785 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9601\n",
      "\n",
      "Epoch: [661 | 1000] LR: 0.000066\n",
      "Train | 16/16 | Loss:0.0578 | MainLoss:0.0435 | Alpha:0.4902 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1433 | MainLoss:0.1433 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7776 | MainLoss:0.7776 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9604\n",
      "\n",
      "Epoch: [662 | 1000] LR: 0.000066\n",
      "Train | 16/16 | Loss:0.0572 | MainLoss:0.0429 | Alpha:0.4908 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1433 | MainLoss:0.1433 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9918\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9602\n",
      "\n",
      "Epoch: [663 | 1000] LR: 0.000066\n",
      "Train | 16/16 | Loss:0.0633 | MainLoss:0.0490 | Alpha:0.4892 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1433 | MainLoss:0.1433 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9921\n",
      "Test | 128/16 | Loss:0.7773 | MainLoss:0.7773 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9600\n",
      "\n",
      "Epoch: [664 | 1000] LR: 0.000066\n",
      "Train | 16/16 | Loss:0.0552 | MainLoss:0.0409 | Alpha:0.4906 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7769 | MainLoss:0.7769 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9603\n",
      "\n",
      "Epoch: [665 | 1000] LR: 0.000065\n",
      "Train | 16/16 | Loss:0.0559 | MainLoss:0.0415 | Alpha:0.4909 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7767 | MainLoss:0.7767 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9603\n",
      "\n",
      "Epoch: [666 | 1000] LR: 0.000065\n",
      "Train | 16/16 | Loss:0.0505 | MainLoss:0.0362 | Alpha:0.4930 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7770 | MainLoss:0.7770 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9603\n",
      "\n",
      "Epoch: [667 | 1000] LR: 0.000065\n",
      "Train | 16/16 | Loss:0.0550 | MainLoss:0.0407 | Alpha:0.4910 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1433 | MainLoss:0.1433 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9921\n",
      "Test | 128/16 | Loss:0.7772 | MainLoss:0.7772 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9603\n",
      "\n",
      "Epoch: [668 | 1000] LR: 0.000064\n",
      "Train | 16/16 | Loss:0.0523 | MainLoss:0.0380 | Alpha:0.4917 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7771 | MainLoss:0.7771 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9602\n",
      "\n",
      "Epoch: [669 | 1000] LR: 0.000064\n",
      "Train | 16/16 | Loss:0.0447 | MainLoss:0.0304 | Alpha:0.4938 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7768 | MainLoss:0.7768 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9604\n",
      "\n",
      "Epoch: [670 | 1000] LR: 0.000064\n",
      "Train | 16/16 | Loss:0.0695 | MainLoss:0.0552 | Alpha:0.4884 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9922\n",
      "Test | 128/16 | Loss:0.7767 | MainLoss:0.7767 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9600\n",
      "\n",
      "Epoch: [671 | 1000] LR: 0.000063\n",
      "Train | 16/16 | Loss:0.0511 | MainLoss:0.0368 | Alpha:0.4922 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7769 | MainLoss:0.7769 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9602\n",
      "\n",
      "Epoch: [672 | 1000] LR: 0.000063\n",
      "Train | 16/16 | Loss:0.0572 | MainLoss:0.0429 | Alpha:0.4906 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1435 | MainLoss:0.1435 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7761 | MainLoss:0.7761 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9603\n",
      "\n",
      "Epoch: [673 | 1000] LR: 0.000063\n",
      "Train | 16/16 | Loss:0.0594 | MainLoss:0.0451 | Alpha:0.4904 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1435 | MainLoss:0.1435 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7763 | MainLoss:0.7763 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9603\n",
      "\n",
      "Epoch: [674 | 1000] LR: 0.000063\n",
      "Train | 16/16 | Loss:0.0491 | MainLoss:0.0347 | Alpha:0.4922 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1435 | MainLoss:0.1435 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9922\n",
      "Test | 128/16 | Loss:0.7762 | MainLoss:0.7762 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9602\n",
      "\n",
      "Epoch: [675 | 1000] LR: 0.000062\n",
      "Train | 16/16 | Loss:0.0624 | MainLoss:0.0481 | Alpha:0.4895 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1435 | MainLoss:0.1435 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 128/16 | Loss:0.7764 | MainLoss:0.7764 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9602\n",
      "\n",
      "Epoch: [676 | 1000] LR: 0.000062\n",
      "Train | 16/16 | Loss:0.0576 | MainLoss:0.0433 | Alpha:0.4902 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7770 | MainLoss:0.7770 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9601\n",
      "\n",
      "Epoch: [677 | 1000] LR: 0.000062\n",
      "Train | 16/16 | Loss:0.0501 | MainLoss:0.0358 | Alpha:0.4925 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7770 | MainLoss:0.7770 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9601\n",
      "\n",
      "Epoch: [678 | 1000] LR: 0.000061\n",
      "Train | 16/16 | Loss:0.0537 | MainLoss:0.0394 | Alpha:0.4919 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9922\n",
      "Test | 128/16 | Loss:0.7770 | MainLoss:0.7770 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9603\n",
      "\n",
      "Epoch: [679 | 1000] LR: 0.000061\n",
      "Train | 16/16 | Loss:0.0492 | MainLoss:0.0349 | Alpha:0.4932 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7772 | MainLoss:0.7772 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9603\n",
      "\n",
      "Epoch: [680 | 1000] LR: 0.000061\n",
      "Train | 16/16 | Loss:0.0499 | MainLoss:0.0356 | Alpha:0.4921 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9918\n",
      "Test | 128/16 | Loss:0.7777 | MainLoss:0.7777 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9602\n",
      "\n",
      "Epoch: [681 | 1000] LR: 0.000061\n",
      "Train | 16/16 | Loss:0.0504 | MainLoss:0.0360 | Alpha:0.4920 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7779 | MainLoss:0.7779 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9602\n",
      "\n",
      "Epoch: [682 | 1000] LR: 0.000060\n",
      "Train | 16/16 | Loss:0.0637 | MainLoss:0.0494 | Alpha:0.4890 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7779 | MainLoss:0.7779 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9601\n",
      "\n",
      "Epoch: [683 | 1000] LR: 0.000060\n",
      "Train | 16/16 | Loss:0.0532 | MainLoss:0.0389 | Alpha:0.4918 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7777 | MainLoss:0.7777 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9601\n",
      "\n",
      "Epoch: [684 | 1000] LR: 0.000060\n",
      "Train | 16/16 | Loss:0.0538 | MainLoss:0.0395 | Alpha:0.4916 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9922\n",
      "Test | 128/16 | Loss:0.7778 | MainLoss:0.7778 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9602\n",
      "\n",
      "Epoch: [685 | 1000] LR: 0.000059\n",
      "Train | 16/16 | Loss:0.0483 | MainLoss:0.0340 | Alpha:0.4926 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1435 | MainLoss:0.1435 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7776 | MainLoss:0.7776 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9602\n",
      "\n",
      "Epoch: [686 | 1000] LR: 0.000059\n",
      "Train | 16/16 | Loss:0.0587 | MainLoss:0.0444 | Alpha:0.4909 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7782 | MainLoss:0.7782 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9598\n",
      "\n",
      "Epoch: [687 | 1000] LR: 0.000059\n",
      "Train | 16/16 | Loss:0.0625 | MainLoss:0.0481 | Alpha:0.4911 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9921\n",
      "Test | 128/16 | Loss:0.7778 | MainLoss:0.7778 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9602\n",
      "\n",
      "Epoch: [688 | 1000] LR: 0.000059\n",
      "Train | 16/16 | Loss:0.0658 | MainLoss:0.0515 | Alpha:0.4888 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9602\n",
      "\n",
      "Epoch: [689 | 1000] LR: 0.000058\n",
      "Train | 16/16 | Loss:0.0470 | MainLoss:0.0326 | Alpha:0.4931 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9918\n",
      "Test | 128/16 | Loss:0.7777 | MainLoss:0.7777 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9602\n",
      "\n",
      "Epoch: [690 | 1000] LR: 0.000058\n",
      "Train | 16/16 | Loss:0.0558 | MainLoss:0.0414 | Alpha:0.4912 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9921\n",
      "Test | 128/16 | Loss:0.7778 | MainLoss:0.7778 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9603\n",
      "\n",
      "Epoch: [691 | 1000] LR: 0.000058\n",
      "Train | 16/16 | Loss:0.0435 | MainLoss:0.0292 | Alpha:0.4938 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1435 | MainLoss:0.1435 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9603\n",
      "\n",
      "Epoch: [692 | 1000] LR: 0.000057\n",
      "Train | 16/16 | Loss:0.0572 | MainLoss:0.0429 | Alpha:0.4910 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7778 | MainLoss:0.7778 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9602\n",
      "\n",
      "Epoch: [693 | 1000] LR: 0.000057\n",
      "Train | 16/16 | Loss:0.0603 | MainLoss:0.0460 | Alpha:0.4904 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9922\n",
      "Test | 128/16 | Loss:0.7777 | MainLoss:0.7777 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9600\n",
      "\n",
      "Epoch: [694 | 1000] LR: 0.000057\n",
      "Train | 16/16 | Loss:0.0562 | MainLoss:0.0418 | Alpha:0.4908 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7779 | MainLoss:0.7779 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9603\n",
      "\n",
      "Epoch: [695 | 1000] LR: 0.000057\n",
      "Train | 16/16 | Loss:0.0577 | MainLoss:0.0433 | Alpha:0.4897 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7783 | MainLoss:0.7783 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9602\n",
      "\n",
      "Epoch: [696 | 1000] LR: 0.000056\n",
      "Train | 16/16 | Loss:0.0584 | MainLoss:0.0441 | Alpha:0.4903 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7778 | MainLoss:0.7778 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9602\n",
      "\n",
      "Epoch: [697 | 1000] LR: 0.000056\n",
      "Train | 16/16 | Loss:0.0585 | MainLoss:0.0442 | Alpha:0.4905 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7781 | MainLoss:0.7781 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9601\n",
      "\n",
      "Epoch: [698 | 1000] LR: 0.000056\n",
      "Train | 16/16 | Loss:0.0490 | MainLoss:0.0347 | Alpha:0.4932 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7783 | MainLoss:0.7783 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9601\n",
      "\n",
      "Epoch: [699 | 1000] LR: 0.000055\n",
      "Train | 16/16 | Loss:0.0568 | MainLoss:0.0425 | Alpha:0.4910 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7783 | MainLoss:0.7783 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9601\n",
      "\n",
      "Epoch: [700 | 1000] LR: 0.000055\n",
      "Train | 16/16 | Loss:0.0478 | MainLoss:0.0335 | Alpha:0.4937 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9919\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 128/16 | Loss:0.7785 | MainLoss:0.7785 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9603\n",
      "\n",
      "Epoch: [701 | 1000] LR: 0.000055\n",
      "Train | 16/16 | Loss:0.0436 | MainLoss:0.0292 | Alpha:0.4932 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7782 | MainLoss:0.7782 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9601\n",
      "\n",
      "Epoch: [702 | 1000] LR: 0.000055\n",
      "Train | 16/16 | Loss:0.0539 | MainLoss:0.0396 | Alpha:0.4912 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9917\n",
      "Test | 128/16 | Loss:0.7782 | MainLoss:0.7782 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9601\n",
      "\n",
      "Epoch: [703 | 1000] LR: 0.000054\n",
      "Train | 16/16 | Loss:0.0628 | MainLoss:0.0485 | Alpha:0.4891 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9917\n",
      "Test | 128/16 | Loss:0.7784 | MainLoss:0.7784 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9600\n",
      "\n",
      "Epoch: [704 | 1000] LR: 0.000054\n",
      "Train | 16/16 | Loss:0.0548 | MainLoss:0.0405 | Alpha:0.4902 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9921\n",
      "Test | 128/16 | Loss:0.7780 | MainLoss:0.7780 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9602\n",
      "\n",
      "Epoch: [705 | 1000] LR: 0.000054\n",
      "Train | 16/16 | Loss:0.0632 | MainLoss:0.0489 | Alpha:0.4888 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1433 | MainLoss:0.1433 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9921\n",
      "Test | 128/16 | Loss:0.7786 | MainLoss:0.7786 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9603\n",
      "\n",
      "Epoch: [706 | 1000] LR: 0.000053\n",
      "Train | 16/16 | Loss:0.0579 | MainLoss:0.0436 | Alpha:0.4906 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1433 | MainLoss:0.1433 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7789 | MainLoss:0.7789 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9604\n",
      "\n",
      "Epoch: [707 | 1000] LR: 0.000053\n",
      "Train | 16/16 | Loss:0.0612 | MainLoss:0.0469 | Alpha:0.4899 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1433 | MainLoss:0.1433 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9921\n",
      "Test | 128/16 | Loss:0.7788 | MainLoss:0.7788 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9601\n",
      "\n",
      "Epoch: [708 | 1000] LR: 0.000053\n",
      "Train | 16/16 | Loss:0.0494 | MainLoss:0.0351 | Alpha:0.4929 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1433 | MainLoss:0.1433 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9921\n",
      "Test | 128/16 | Loss:0.7787 | MainLoss:0.7787 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9601\n",
      "\n",
      "Epoch: [709 | 1000] LR: 0.000053\n",
      "Train | 16/16 | Loss:0.0501 | MainLoss:0.0358 | Alpha:0.4925 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1433 | MainLoss:0.1433 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9917\n",
      "Test | 128/16 | Loss:0.7792 | MainLoss:0.7792 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9602\n",
      "\n",
      "Epoch: [710 | 1000] LR: 0.000052\n",
      "Train | 16/16 | Loss:0.0525 | MainLoss:0.0382 | Alpha:0.4914 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1433 | MainLoss:0.1433 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9921\n",
      "Test | 128/16 | Loss:0.7790 | MainLoss:0.7790 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9602\n",
      "\n",
      "Epoch: [711 | 1000] LR: 0.000052\n",
      "Train | 16/16 | Loss:0.0609 | MainLoss:0.0465 | Alpha:0.4898 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1433 | MainLoss:0.1433 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7790 | MainLoss:0.7790 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9601\n",
      "\n",
      "Epoch: [712 | 1000] LR: 0.000052\n",
      "Train | 16/16 | Loss:0.0429 | MainLoss:0.0286 | Alpha:0.4947 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1433 | MainLoss:0.1433 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9917\n",
      "Test | 128/16 | Loss:0.7791 | MainLoss:0.7791 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9600\n",
      "\n",
      "Epoch: [713 | 1000] LR: 0.000052\n",
      "Train | 16/16 | Loss:0.0471 | MainLoss:0.0328 | Alpha:0.4936 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1433 | MainLoss:0.1433 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7794 | MainLoss:0.7794 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9602\n",
      "\n",
      "Epoch: [714 | 1000] LR: 0.000051\n",
      "Train | 16/16 | Loss:0.0581 | MainLoss:0.0438 | Alpha:0.4909 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1433 | MainLoss:0.1433 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9918\n",
      "Test | 128/16 | Loss:0.7794 | MainLoss:0.7794 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9602\n",
      "\n",
      "Epoch: [715 | 1000] LR: 0.000051\n",
      "Train | 16/16 | Loss:0.0512 | MainLoss:0.0369 | Alpha:0.4928 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1433 | MainLoss:0.1433 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9918\n",
      "Test | 128/16 | Loss:0.7793 | MainLoss:0.7793 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9602\n",
      "\n",
      "Epoch: [716 | 1000] LR: 0.000051\n",
      "Train | 16/16 | Loss:0.0498 | MainLoss:0.0355 | Alpha:0.4929 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1433 | MainLoss:0.1433 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7793 | MainLoss:0.7793 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9599\n",
      "\n",
      "Epoch: [717 | 1000] LR: 0.000050\n",
      "Train | 16/16 | Loss:0.0589 | MainLoss:0.0446 | Alpha:0.4902 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1433 | MainLoss:0.1433 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9922\n",
      "Test | 128/16 | Loss:0.7796 | MainLoss:0.7796 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9604\n",
      "\n",
      "Epoch: [718 | 1000] LR: 0.000050\n",
      "Train | 16/16 | Loss:0.0678 | MainLoss:0.0535 | Alpha:0.4885 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1433 | MainLoss:0.1433 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7793 | MainLoss:0.7793 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9603\n",
      "\n",
      "Epoch: [719 | 1000] LR: 0.000050\n",
      "Train | 16/16 | Loss:0.0568 | MainLoss:0.0425 | Alpha:0.4916 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1433 | MainLoss:0.1433 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9918\n",
      "Test | 128/16 | Loss:0.7793 | MainLoss:0.7793 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9604\n",
      "\n",
      "Epoch: [720 | 1000] LR: 0.000050\n",
      "Train | 16/16 | Loss:0.0547 | MainLoss:0.0404 | Alpha:0.4912 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1433 | MainLoss:0.1433 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7793 | MainLoss:0.7793 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9601\n",
      "\n",
      "Epoch: [721 | 1000] LR: 0.000049\n",
      "Train | 16/16 | Loss:0.0623 | MainLoss:0.0480 | Alpha:0.4889 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1433 | MainLoss:0.1433 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9922\n",
      "Test | 128/16 | Loss:0.7792 | MainLoss:0.7792 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9601\n",
      "\n",
      "Epoch: [722 | 1000] LR: 0.000049\n",
      "Train | 16/16 | Loss:0.0611 | MainLoss:0.0468 | Alpha:0.4901 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1433 | MainLoss:0.1433 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7794 | MainLoss:0.7794 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9602\n",
      "\n",
      "Epoch: [723 | 1000] LR: 0.000049\n",
      "Train | 16/16 | Loss:0.0497 | MainLoss:0.0354 | Alpha:0.4931 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1433 | MainLoss:0.1433 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9921\n",
      "Test | 128/16 | Loss:0.7792 | MainLoss:0.7792 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9602\n",
      "\n",
      "Epoch: [724 | 1000] LR: 0.000049\n",
      "Train | 16/16 | Loss:0.0586 | MainLoss:0.0442 | Alpha:0.4909 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1433 | MainLoss:0.1433 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7795 | MainLoss:0.7795 | SPLoss:0.0000 | CLSLoss:0.1433 | AUROC:0.9603\n",
      "\n",
      "Epoch: [725 | 1000] LR: 0.000048\n",
      "Train | 16/16 | Loss:0.0715 | MainLoss:0.0572 | Alpha:0.4871 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1432 | MainLoss:0.1432 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9921\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 128/16 | Loss:0.7793 | MainLoss:0.7793 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9604\n",
      "\n",
      "Epoch: [726 | 1000] LR: 0.000048\n",
      "Train | 16/16 | Loss:0.0572 | MainLoss:0.0428 | Alpha:0.4909 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1432 | MainLoss:0.1432 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7793 | MainLoss:0.7793 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9603\n",
      "\n",
      "Epoch: [727 | 1000] LR: 0.000048\n",
      "Train | 16/16 | Loss:0.0649 | MainLoss:0.0506 | Alpha:0.4888 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1432 | MainLoss:0.1432 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7791 | MainLoss:0.7791 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9601\n",
      "\n",
      "Epoch: [728 | 1000] LR: 0.000047\n",
      "Train | 16/16 | Loss:0.0523 | MainLoss:0.0380 | Alpha:0.4920 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1432 | MainLoss:0.1432 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7796 | MainLoss:0.7796 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9602\n",
      "\n",
      "Epoch: [729 | 1000] LR: 0.000047\n",
      "Train | 16/16 | Loss:0.0603 | MainLoss:0.0460 | Alpha:0.4903 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1432 | MainLoss:0.1432 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9921\n",
      "Test | 128/16 | Loss:0.7796 | MainLoss:0.7796 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9601\n",
      "\n",
      "Epoch: [730 | 1000] LR: 0.000047\n",
      "Train | 16/16 | Loss:0.0573 | MainLoss:0.0430 | Alpha:0.4913 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1432 | MainLoss:0.1432 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7798 | MainLoss:0.7798 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9604\n",
      "\n",
      "Epoch: [731 | 1000] LR: 0.000047\n",
      "Train | 16/16 | Loss:0.0463 | MainLoss:0.0319 | Alpha:0.4932 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1432 | MainLoss:0.1432 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9921\n",
      "Test | 128/16 | Loss:0.7799 | MainLoss:0.7799 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9600\n",
      "\n",
      "Epoch: [732 | 1000] LR: 0.000046\n",
      "Train | 16/16 | Loss:0.0555 | MainLoss:0.0412 | Alpha:0.4916 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1432 | MainLoss:0.1432 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7798 | MainLoss:0.7798 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9602\n",
      "\n",
      "Epoch: [733 | 1000] LR: 0.000046\n",
      "Train | 16/16 | Loss:0.0517 | MainLoss:0.0374 | Alpha:0.4926 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1432 | MainLoss:0.1432 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9923\n",
      "Test | 128/16 | Loss:0.7796 | MainLoss:0.7796 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9603\n",
      "\n",
      "Epoch: [734 | 1000] LR: 0.000046\n",
      "Train | 16/16 | Loss:0.0558 | MainLoss:0.0415 | Alpha:0.4916 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1432 | MainLoss:0.1432 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9921\n",
      "Test | 128/16 | Loss:0.7796 | MainLoss:0.7796 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9600\n",
      "\n",
      "Epoch: [735 | 1000] LR: 0.000046\n",
      "Train | 16/16 | Loss:0.0568 | MainLoss:0.0425 | Alpha:0.4908 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1432 | MainLoss:0.1432 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9918\n",
      "Test | 128/16 | Loss:0.7797 | MainLoss:0.7797 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9602\n",
      "\n",
      "Epoch: [736 | 1000] LR: 0.000045\n",
      "Train | 16/16 | Loss:0.0623 | MainLoss:0.0480 | Alpha:0.4902 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1432 | MainLoss:0.1432 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7797 | MainLoss:0.7797 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9603\n",
      "\n",
      "Epoch: [737 | 1000] LR: 0.000045\n",
      "Train | 16/16 | Loss:0.0632 | MainLoss:0.0489 | Alpha:0.4893 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1432 | MainLoss:0.1432 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7796 | MainLoss:0.7796 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9601\n",
      "\n",
      "Epoch: [738 | 1000] LR: 0.000045\n",
      "Train | 16/16 | Loss:0.0542 | MainLoss:0.0399 | Alpha:0.4917 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1432 | MainLoss:0.1432 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7799 | MainLoss:0.7799 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9600\n",
      "\n",
      "Epoch: [739 | 1000] LR: 0.000045\n",
      "Train | 16/16 | Loss:0.0584 | MainLoss:0.0440 | Alpha:0.4906 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1432 | MainLoss:0.1432 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9921\n",
      "Test | 128/16 | Loss:0.7800 | MainLoss:0.7800 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9602\n",
      "\n",
      "Epoch: [740 | 1000] LR: 0.000044\n",
      "Train | 16/16 | Loss:0.0593 | MainLoss:0.0450 | Alpha:0.4903 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1432 | MainLoss:0.1432 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9923\n",
      "Test | 128/16 | Loss:0.7797 | MainLoss:0.7797 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9604\n",
      "\n",
      "Epoch: [741 | 1000] LR: 0.000044\n",
      "Train | 16/16 | Loss:0.0551 | MainLoss:0.0408 | Alpha:0.4915 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1432 | MainLoss:0.1432 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7799 | MainLoss:0.7799 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9602\n",
      "\n",
      "Epoch: [742 | 1000] LR: 0.000044\n",
      "Train | 16/16 | Loss:0.0494 | MainLoss:0.0351 | Alpha:0.4922 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1432 | MainLoss:0.1432 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7801 | MainLoss:0.7801 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9601\n",
      "\n",
      "Epoch: [743 | 1000] LR: 0.000044\n",
      "Train | 16/16 | Loss:0.0491 | MainLoss:0.0348 | Alpha:0.4929 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1432 | MainLoss:0.1432 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7802 | MainLoss:0.7802 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9604\n",
      "\n",
      "Epoch: [744 | 1000] LR: 0.000043\n",
      "Train | 16/16 | Loss:0.0663 | MainLoss:0.0520 | Alpha:0.4883 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1432 | MainLoss:0.1432 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7798 | MainLoss:0.7798 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9602\n",
      "\n",
      "Epoch: [745 | 1000] LR: 0.000043\n",
      "Train | 16/16 | Loss:0.0536 | MainLoss:0.0393 | Alpha:0.4924 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1432 | MainLoss:0.1432 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9924\n",
      "Test | 128/16 | Loss:0.7796 | MainLoss:0.7796 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9601\n",
      "\n",
      "Epoch: [746 | 1000] LR: 0.000043\n",
      "Train | 16/16 | Loss:0.0610 | MainLoss:0.0466 | Alpha:0.4896 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1432 | MainLoss:0.1432 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7794 | MainLoss:0.7794 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9603\n",
      "\n",
      "Epoch: [747 | 1000] LR: 0.000042\n",
      "Train | 16/16 | Loss:0.0624 | MainLoss:0.0481 | Alpha:0.4902 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1432 | MainLoss:0.1432 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7795 | MainLoss:0.7795 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9603\n",
      "\n",
      "Epoch: [748 | 1000] LR: 0.000042\n",
      "Train | 16/16 | Loss:0.0640 | MainLoss:0.0497 | Alpha:0.4900 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1432 | MainLoss:0.1432 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9918\n",
      "Test | 128/16 | Loss:0.7794 | MainLoss:0.7794 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9603\n",
      "\n",
      "Epoch: [749 | 1000] LR: 0.000042\n",
      "Train | 16/16 | Loss:0.0516 | MainLoss:0.0373 | Alpha:0.4926 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1433 | MainLoss:0.1433 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9918\n",
      "Test | 128/16 | Loss:0.7792 | MainLoss:0.7792 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9600\n",
      "\n",
      "Epoch: [750 | 1000] LR: 0.000042\n",
      "Train | 16/16 | Loss:0.0505 | MainLoss:0.0361 | Alpha:0.4925 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1433 | MainLoss:0.1433 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9919\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 128/16 | Loss:0.7789 | MainLoss:0.7789 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9604\n",
      "\n",
      "Epoch: [751 | 1000] LR: 0.000041\n",
      "Train | 16/16 | Loss:0.0596 | MainLoss:0.0453 | Alpha:0.4903 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1433 | MainLoss:0.1433 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9918\n",
      "Test | 128/16 | Loss:0.7788 | MainLoss:0.7788 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9603\n",
      "\n",
      "Epoch: [752 | 1000] LR: 0.000041\n",
      "Train | 16/16 | Loss:0.0525 | MainLoss:0.0382 | Alpha:0.4912 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1433 | MainLoss:0.1433 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9922\n",
      "Test | 128/16 | Loss:0.7785 | MainLoss:0.7785 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9602\n",
      "\n",
      "Epoch: [753 | 1000] LR: 0.000041\n",
      "Train | 16/16 | Loss:0.0578 | MainLoss:0.0435 | Alpha:0.4908 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7783 | MainLoss:0.7783 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9602\n",
      "\n",
      "Epoch: [754 | 1000] LR: 0.000041\n",
      "Train | 16/16 | Loss:0.0522 | MainLoss:0.0379 | Alpha:0.4916 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9921\n",
      "Test | 128/16 | Loss:0.7783 | MainLoss:0.7783 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9604\n",
      "\n",
      "Epoch: [755 | 1000] LR: 0.000040\n",
      "Train | 16/16 | Loss:0.0504 | MainLoss:0.0360 | Alpha:0.4921 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9921\n",
      "Test | 128/16 | Loss:0.7781 | MainLoss:0.7781 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9601\n",
      "\n",
      "Epoch: [756 | 1000] LR: 0.000040\n",
      "Train | 16/16 | Loss:0.0670 | MainLoss:0.0526 | Alpha:0.4888 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7781 | MainLoss:0.7781 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9602\n",
      "\n",
      "Epoch: [757 | 1000] LR: 0.000040\n",
      "Train | 16/16 | Loss:0.0567 | MainLoss:0.0424 | Alpha:0.4915 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7776 | MainLoss:0.7776 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9602\n",
      "\n",
      "Epoch: [758 | 1000] LR: 0.000040\n",
      "Train | 16/16 | Loss:0.0738 | MainLoss:0.0594 | Alpha:0.4870 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9917\n",
      "Test | 128/16 | Loss:0.7773 | MainLoss:0.7773 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9603\n",
      "\n",
      "Epoch: [759 | 1000] LR: 0.000039\n",
      "Train | 16/16 | Loss:0.0525 | MainLoss:0.0382 | Alpha:0.4917 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7774 | MainLoss:0.7774 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9604\n",
      "\n",
      "Epoch: [760 | 1000] LR: 0.000039\n",
      "Train | 16/16 | Loss:0.0587 | MainLoss:0.0444 | Alpha:0.4902 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9602\n",
      "\n",
      "Epoch: [761 | 1000] LR: 0.000039\n",
      "Train | 16/16 | Loss:0.0558 | MainLoss:0.0415 | Alpha:0.4910 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7774 | MainLoss:0.7774 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9604\n",
      "\n",
      "Epoch: [762 | 1000] LR: 0.000039\n",
      "Train | 16/16 | Loss:0.0507 | MainLoss:0.0364 | Alpha:0.4923 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1435 | MainLoss:0.1435 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9921\n",
      "Test | 128/16 | Loss:0.7772 | MainLoss:0.7772 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9603\n",
      "\n",
      "Epoch: [763 | 1000] LR: 0.000038\n",
      "Train | 16/16 | Loss:0.0554 | MainLoss:0.0411 | Alpha:0.4913 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1435 | MainLoss:0.1435 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7770 | MainLoss:0.7770 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9601\n",
      "\n",
      "Epoch: [764 | 1000] LR: 0.000038\n",
      "Train | 16/16 | Loss:0.0533 | MainLoss:0.0390 | Alpha:0.4916 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1435 | MainLoss:0.1435 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9922\n",
      "Test | 128/16 | Loss:0.7770 | MainLoss:0.7770 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9601\n",
      "\n",
      "Epoch: [765 | 1000] LR: 0.000038\n",
      "Train | 16/16 | Loss:0.0563 | MainLoss:0.0419 | Alpha:0.4910 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9604\n",
      "\n",
      "Epoch: [766 | 1000] LR: 0.000038\n",
      "Train | 16/16 | Loss:0.0565 | MainLoss:0.0422 | Alpha:0.4906 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9922\n",
      "Test | 128/16 | Loss:0.7773 | MainLoss:0.7773 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9604\n",
      "\n",
      "Epoch: [767 | 1000] LR: 0.000037\n",
      "Train | 16/16 | Loss:0.0617 | MainLoss:0.0474 | Alpha:0.4896 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7772 | MainLoss:0.7772 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9604\n",
      "\n",
      "Epoch: [768 | 1000] LR: 0.000037\n",
      "Train | 16/16 | Loss:0.0568 | MainLoss:0.0425 | Alpha:0.4909 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9921\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9601\n",
      "\n",
      "Epoch: [769 | 1000] LR: 0.000037\n",
      "Train | 16/16 | Loss:0.0570 | MainLoss:0.0427 | Alpha:0.4918 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9921\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9601\n",
      "\n",
      "Epoch: [770 | 1000] LR: 0.000037\n",
      "Train | 16/16 | Loss:0.0512 | MainLoss:0.0369 | Alpha:0.4920 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9605\n",
      "\n",
      "Epoch: [771 | 1000] LR: 0.000036\n",
      "Train | 16/16 | Loss:0.0570 | MainLoss:0.0427 | Alpha:0.4906 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9922\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9602\n",
      "\n",
      "Epoch: [772 | 1000] LR: 0.000036\n",
      "Train | 16/16 | Loss:0.0517 | MainLoss:0.0373 | Alpha:0.4920 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1435 | MainLoss:0.1435 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7773 | MainLoss:0.7773 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9603\n",
      "\n",
      "Epoch: [773 | 1000] LR: 0.000036\n",
      "Train | 16/16 | Loss:0.0586 | MainLoss:0.0443 | Alpha:0.4895 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1435 | MainLoss:0.1435 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9922\n",
      "Test | 128/16 | Loss:0.7773 | MainLoss:0.7773 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9603\n",
      "\n",
      "Epoch: [774 | 1000] LR: 0.000036\n",
      "Train | 16/16 | Loss:0.0634 | MainLoss:0.0490 | Alpha:0.4891 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1435 | MainLoss:0.1435 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7770 | MainLoss:0.7770 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9604\n",
      "\n",
      "Epoch: [775 | 1000] LR: 0.000036\n",
      "Train | 16/16 | Loss:0.0563 | MainLoss:0.0420 | Alpha:0.4912 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1435 | MainLoss:0.1435 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9919\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 128/16 | Loss:0.7771 | MainLoss:0.7771 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9603\n",
      "\n",
      "Epoch: [776 | 1000] LR: 0.000035\n",
      "Train | 16/16 | Loss:0.0588 | MainLoss:0.0444 | Alpha:0.4900 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1435 | MainLoss:0.1435 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9917\n",
      "Test | 128/16 | Loss:0.7766 | MainLoss:0.7766 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9605\n",
      "\n",
      "Epoch: [777 | 1000] LR: 0.000035\n",
      "Train | 16/16 | Loss:0.0626 | MainLoss:0.0482 | Alpha:0.4897 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1436 | MainLoss:0.1436 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7763 | MainLoss:0.7763 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9602\n",
      "\n",
      "Epoch: [778 | 1000] LR: 0.000035\n",
      "Train | 16/16 | Loss:0.0614 | MainLoss:0.0471 | Alpha:0.4899 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1435 | MainLoss:0.1435 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9922\n",
      "Test | 128/16 | Loss:0.7765 | MainLoss:0.7765 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9601\n",
      "\n",
      "Epoch: [779 | 1000] LR: 0.000035\n",
      "Train | 16/16 | Loss:0.0619 | MainLoss:0.0476 | Alpha:0.4898 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1436 | MainLoss:0.1436 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7762 | MainLoss:0.7762 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9605\n",
      "\n",
      "Epoch: [780 | 1000] LR: 0.000034\n",
      "Train | 16/16 | Loss:0.0680 | MainLoss:0.0537 | Alpha:0.4886 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1435 | MainLoss:0.1435 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7766 | MainLoss:0.7766 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9604\n",
      "\n",
      "Epoch: [781 | 1000] LR: 0.000034\n",
      "Train | 16/16 | Loss:0.0535 | MainLoss:0.0392 | Alpha:0.4915 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1435 | MainLoss:0.1435 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7769 | MainLoss:0.7769 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9604\n",
      "\n",
      "Epoch: [782 | 1000] LR: 0.000034\n",
      "Train | 16/16 | Loss:0.0520 | MainLoss:0.0377 | Alpha:0.4920 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1435 | MainLoss:0.1435 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7770 | MainLoss:0.7770 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9601\n",
      "\n",
      "Epoch: [783 | 1000] LR: 0.000034\n",
      "Train | 16/16 | Loss:0.0564 | MainLoss:0.0421 | Alpha:0.4906 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1435 | MainLoss:0.1435 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9921\n",
      "Test | 128/16 | Loss:0.7768 | MainLoss:0.7768 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9605\n",
      "\n",
      "Epoch: [784 | 1000] LR: 0.000033\n",
      "Train | 16/16 | Loss:0.0622 | MainLoss:0.0479 | Alpha:0.4898 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7772 | MainLoss:0.7772 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9606\n",
      "\n",
      "Epoch: [785 | 1000] LR: 0.000033\n",
      "Train | 16/16 | Loss:0.0492 | MainLoss:0.0349 | Alpha:0.4922 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9918\n",
      "Test | 128/16 | Loss:0.7774 | MainLoss:0.7774 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9603\n",
      "\n",
      "Epoch: [786 | 1000] LR: 0.000033\n",
      "Train | 16/16 | Loss:0.0537 | MainLoss:0.0394 | Alpha:0.4917 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9918\n",
      "Test | 128/16 | Loss:0.7773 | MainLoss:0.7773 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9605\n",
      "\n",
      "Epoch: [787 | 1000] LR: 0.000033\n",
      "Train | 16/16 | Loss:0.0567 | MainLoss:0.0423 | Alpha:0.4909 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7773 | MainLoss:0.7773 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9602\n",
      "\n",
      "Epoch: [788 | 1000] LR: 0.000032\n",
      "Train | 16/16 | Loss:0.0552 | MainLoss:0.0409 | Alpha:0.4910 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1435 | MainLoss:0.1435 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9921\n",
      "Test | 128/16 | Loss:0.7771 | MainLoss:0.7771 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9602\n",
      "\n",
      "Epoch: [789 | 1000] LR: 0.000032\n",
      "Train | 16/16 | Loss:0.0539 | MainLoss:0.0396 | Alpha:0.4916 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1435 | MainLoss:0.1435 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9921\n",
      "Test | 128/16 | Loss:0.7771 | MainLoss:0.7771 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9605\n",
      "\n",
      "Epoch: [790 | 1000] LR: 0.000032\n",
      "Train | 16/16 | Loss:0.0584 | MainLoss:0.0441 | Alpha:0.4911 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1435 | MainLoss:0.1435 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7771 | MainLoss:0.7771 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9604\n",
      "\n",
      "Epoch: [791 | 1000] LR: 0.000032\n",
      "Train | 16/16 | Loss:0.0556 | MainLoss:0.0413 | Alpha:0.4910 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7772 | MainLoss:0.7772 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9603\n",
      "\n",
      "Epoch: [792 | 1000] LR: 0.000032\n",
      "Train | 16/16 | Loss:0.0478 | MainLoss:0.0335 | Alpha:0.4924 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1435 | MainLoss:0.1435 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9922\n",
      "Test | 128/16 | Loss:0.7771 | MainLoss:0.7771 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9603\n",
      "\n",
      "Epoch: [793 | 1000] LR: 0.000031\n",
      "Train | 16/16 | Loss:0.0572 | MainLoss:0.0429 | Alpha:0.4912 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1435 | MainLoss:0.1435 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9917\n",
      "Test | 128/16 | Loss:0.7772 | MainLoss:0.7772 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9606\n",
      "\n",
      "Epoch: [794 | 1000] LR: 0.000031\n",
      "Train | 16/16 | Loss:0.0603 | MainLoss:0.0460 | Alpha:0.4903 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1435 | MainLoss:0.1435 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7769 | MainLoss:0.7769 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9601\n",
      "\n",
      "Epoch: [795 | 1000] LR: 0.000031\n",
      "Train | 16/16 | Loss:0.0573 | MainLoss:0.0430 | Alpha:0.4903 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1435 | MainLoss:0.1435 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9922\n",
      "Test | 128/16 | Loss:0.7770 | MainLoss:0.7770 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9601\n",
      "\n",
      "Epoch: [796 | 1000] LR: 0.000031\n",
      "Train | 16/16 | Loss:0.0570 | MainLoss:0.0427 | Alpha:0.4907 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1435 | MainLoss:0.1435 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7771 | MainLoss:0.7771 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9603\n",
      "\n",
      "Epoch: [797 | 1000] LR: 0.000030\n",
      "Train | 16/16 | Loss:0.0678 | MainLoss:0.0534 | Alpha:0.4882 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1435 | MainLoss:0.1435 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7771 | MainLoss:0.7771 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9602\n",
      "\n",
      "Epoch: [798 | 1000] LR: 0.000030\n",
      "Train | 16/16 | Loss:0.0545 | MainLoss:0.0402 | Alpha:0.4916 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1435 | MainLoss:0.1435 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9922\n",
      "Test | 128/16 | Loss:0.7768 | MainLoss:0.7768 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9605\n",
      "\n",
      "Epoch: [799 | 1000] LR: 0.000030\n",
      "Train | 16/16 | Loss:0.0573 | MainLoss:0.0430 | Alpha:0.4909 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1435 | MainLoss:0.1435 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9923\n",
      "Test | 128/16 | Loss:0.7770 | MainLoss:0.7770 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9605\n",
      "\n",
      "Epoch: [800 | 1000] LR: 0.000030\n",
      "Train | 16/16 | Loss:0.0508 | MainLoss:0.0365 | Alpha:0.4926 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9919\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 128/16 | Loss:0.7773 | MainLoss:0.7773 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9606\n",
      "\n",
      "Epoch: [801 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.0656 | MainLoss:0.0513 | Alpha:0.4894 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7773 | MainLoss:0.7773 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9603\n",
      "\n",
      "Epoch: [802 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.0586 | MainLoss:0.0442 | Alpha:0.4905 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7772 | MainLoss:0.7772 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9604\n",
      "\n",
      "Epoch: [803 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.0545 | MainLoss:0.0402 | Alpha:0.4915 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7773 | MainLoss:0.7773 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9602\n",
      "\n",
      "Epoch: [804 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.0498 | MainLoss:0.0354 | Alpha:0.4927 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9921\n",
      "Test | 128/16 | Loss:0.7773 | MainLoss:0.7773 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9604\n",
      "\n",
      "Epoch: [805 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.0619 | MainLoss:0.0475 | Alpha:0.4900 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9921\n",
      "Test | 128/16 | Loss:0.7773 | MainLoss:0.7773 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9604\n",
      "\n",
      "Epoch: [806 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.0520 | MainLoss:0.0377 | Alpha:0.4922 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9922\n",
      "Test | 128/16 | Loss:0.7773 | MainLoss:0.7773 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9603\n",
      "\n",
      "Epoch: [807 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.0537 | MainLoss:0.0394 | Alpha:0.4911 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7773 | MainLoss:0.7773 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9604\n",
      "\n",
      "Epoch: [808 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.0512 | MainLoss:0.0369 | Alpha:0.4920 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9921\n",
      "Test | 128/16 | Loss:0.7773 | MainLoss:0.7773 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9603\n",
      "\n",
      "Epoch: [809 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.0538 | MainLoss:0.0394 | Alpha:0.4918 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9918\n",
      "Test | 128/16 | Loss:0.7773 | MainLoss:0.7773 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9605\n",
      "\n",
      "Epoch: [810 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.0518 | MainLoss:0.0375 | Alpha:0.4923 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7773 | MainLoss:0.7773 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9604\n",
      "\n",
      "Epoch: [811 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.0687 | MainLoss:0.0543 | Alpha:0.4878 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9921\n",
      "Test | 128/16 | Loss:0.7773 | MainLoss:0.7773 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9604\n",
      "\n",
      "Epoch: [812 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.0518 | MainLoss:0.0375 | Alpha:0.4924 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7773 | MainLoss:0.7773 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9604\n",
      "\n",
      "Epoch: [813 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.0721 | MainLoss:0.0578 | Alpha:0.4875 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9921\n",
      "Test | 128/16 | Loss:0.7773 | MainLoss:0.7773 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9604\n",
      "\n",
      "Epoch: [814 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.0590 | MainLoss:0.0447 | Alpha:0.4900 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7773 | MainLoss:0.7773 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9603\n",
      "\n",
      "Epoch: [815 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.0623 | MainLoss:0.0480 | Alpha:0.4899 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7773 | MainLoss:0.7773 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9604\n",
      "\n",
      "Epoch: [816 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.0550 | MainLoss:0.0407 | Alpha:0.4910 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9924\n",
      "Test | 128/16 | Loss:0.7773 | MainLoss:0.7773 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9605\n",
      "\n",
      "Epoch: [817 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.0613 | MainLoss:0.0470 | Alpha:0.4905 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7773 | MainLoss:0.7773 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9602\n",
      "\n",
      "Epoch: [818 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.0576 | MainLoss:0.0432 | Alpha:0.4911 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7773 | MainLoss:0.7773 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9605\n",
      "\n",
      "Epoch: [819 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.0603 | MainLoss:0.0460 | Alpha:0.4903 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7773 | MainLoss:0.7773 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9605\n",
      "\n",
      "Epoch: [820 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.0550 | MainLoss:0.0407 | Alpha:0.4909 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9922\n",
      "Test | 128/16 | Loss:0.7773 | MainLoss:0.7773 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9604\n",
      "\n",
      "Epoch: [821 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.0493 | MainLoss:0.0350 | Alpha:0.4923 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9921\n",
      "Test | 128/16 | Loss:0.7773 | MainLoss:0.7773 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9602\n",
      "\n",
      "Epoch: [822 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0630 | MainLoss:0.0486 | Alpha:0.4895 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7773 | MainLoss:0.7773 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9605\n",
      "\n",
      "Epoch: [823 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0526 | MainLoss:0.0383 | Alpha:0.4916 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7774 | MainLoss:0.7774 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9605\n",
      "\n",
      "Epoch: [824 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0515 | MainLoss:0.0372 | Alpha:0.4924 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7774 | MainLoss:0.7774 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9605\n",
      "\n",
      "Epoch: [825 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0542 | MainLoss:0.0398 | Alpha:0.4915 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 128/16 | Loss:0.7774 | MainLoss:0.7774 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9602\n",
      "\n",
      "Epoch: [826 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0549 | MainLoss:0.0406 | Alpha:0.4916 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9922\n",
      "Test | 128/16 | Loss:0.7774 | MainLoss:0.7774 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9603\n",
      "\n",
      "Epoch: [827 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0494 | MainLoss:0.0350 | Alpha:0.4923 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7774 | MainLoss:0.7774 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9604\n",
      "\n",
      "Epoch: [828 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0677 | MainLoss:0.0534 | Alpha:0.4885 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7774 | MainLoss:0.7774 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9604\n",
      "\n",
      "Epoch: [829 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0502 | MainLoss:0.0358 | Alpha:0.4927 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7774 | MainLoss:0.7774 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9604\n",
      "\n",
      "Epoch: [830 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0527 | MainLoss:0.0384 | Alpha:0.4919 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7774 | MainLoss:0.7774 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9605\n",
      "\n",
      "Epoch: [831 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0571 | MainLoss:0.0428 | Alpha:0.4902 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7774 | MainLoss:0.7774 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9603\n",
      "\n",
      "Epoch: [832 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0525 | MainLoss:0.0382 | Alpha:0.4921 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7774 | MainLoss:0.7774 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9605\n",
      "\n",
      "Epoch: [833 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0506 | MainLoss:0.0363 | Alpha:0.4922 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7774 | MainLoss:0.7774 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9606\n",
      "\n",
      "Epoch: [834 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0617 | MainLoss:0.0474 | Alpha:0.4892 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7774 | MainLoss:0.7774 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9606\n",
      "\n",
      "Epoch: [835 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0640 | MainLoss:0.0497 | Alpha:0.4892 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9918\n",
      "Test | 128/16 | Loss:0.7774 | MainLoss:0.7774 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9604\n",
      "\n",
      "Epoch: [836 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0571 | MainLoss:0.0428 | Alpha:0.4917 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9922\n",
      "Test | 128/16 | Loss:0.7774 | MainLoss:0.7774 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9601\n",
      "\n",
      "Epoch: [837 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0549 | MainLoss:0.0406 | Alpha:0.4913 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9924\n",
      "Test | 128/16 | Loss:0.7774 | MainLoss:0.7774 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9603\n",
      "\n",
      "Epoch: [838 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0602 | MainLoss:0.0459 | Alpha:0.4902 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9917\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9605\n",
      "\n",
      "Epoch: [839 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0520 | MainLoss:0.0377 | Alpha:0.4923 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9921\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9604\n",
      "\n",
      "Epoch: [840 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0599 | MainLoss:0.0455 | Alpha:0.4894 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9921\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9602\n",
      "\n",
      "Epoch: [841 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0625 | MainLoss:0.0482 | Alpha:0.4898 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9921\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9605\n",
      "\n",
      "Epoch: [842 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0468 | MainLoss:0.0324 | Alpha:0.4938 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9604\n",
      "\n",
      "Epoch: [843 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0506 | MainLoss:0.0363 | Alpha:0.4917 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9603\n",
      "\n",
      "Epoch: [844 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0488 | MainLoss:0.0345 | Alpha:0.4929 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9921\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9601\n",
      "\n",
      "Epoch: [845 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0652 | MainLoss:0.0509 | Alpha:0.4891 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9605\n",
      "\n",
      "Epoch: [846 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0634 | MainLoss:0.0491 | Alpha:0.4899 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9605\n",
      "\n",
      "Epoch: [847 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0534 | MainLoss:0.0391 | Alpha:0.4915 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9603\n",
      "\n",
      "Epoch: [848 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0604 | MainLoss:0.0460 | Alpha:0.4905 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9604\n",
      "\n",
      "Epoch: [849 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0539 | MainLoss:0.0396 | Alpha:0.4922 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9602\n",
      "\n",
      "Epoch: [850 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0624 | MainLoss:0.0481 | Alpha:0.4900 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9603\n",
      "\n",
      "Epoch: [851 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0554 | MainLoss:0.0411 | Alpha:0.4911 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9602\n",
      "\n",
      "Epoch: [852 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0511 | MainLoss:0.0368 | Alpha:0.4925 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9922\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9604\n",
      "\n",
      "Epoch: [853 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0574 | MainLoss:0.0431 | Alpha:0.4914 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9603\n",
      "\n",
      "Epoch: [854 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0426 | MainLoss:0.0282 | Alpha:0.4945 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9921\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9605\n",
      "\n",
      "Epoch: [855 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0511 | MainLoss:0.0368 | Alpha:0.4922 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9922\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9605\n",
      "\n",
      "Epoch: [856 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0496 | MainLoss:0.0353 | Alpha:0.4930 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9922\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9603\n",
      "\n",
      "Epoch: [857 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0523 | MainLoss:0.0379 | Alpha:0.4922 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9921\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9604\n",
      "\n",
      "Epoch: [858 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0473 | MainLoss:0.0329 | Alpha:0.4935 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9604\n",
      "\n",
      "Epoch: [859 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0519 | MainLoss:0.0376 | Alpha:0.4922 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9922\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9603\n",
      "\n",
      "Epoch: [860 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0660 | MainLoss:0.0517 | Alpha:0.4886 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9921\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9604\n",
      "\n",
      "Epoch: [861 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0591 | MainLoss:0.0448 | Alpha:0.4901 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9922\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9602\n",
      "\n",
      "Epoch: [862 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0581 | MainLoss:0.0438 | Alpha:0.4910 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9921\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9603\n",
      "\n",
      "Epoch: [863 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0599 | MainLoss:0.0456 | Alpha:0.4905 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9921\n",
      "Test | 128/16 | Loss:0.7776 | MainLoss:0.7776 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9604\n",
      "\n",
      "Epoch: [864 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0701 | MainLoss:0.0558 | Alpha:0.4883 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9918\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9602\n",
      "\n",
      "Epoch: [865 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0535 | MainLoss:0.0392 | Alpha:0.4917 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9601\n",
      "\n",
      "Epoch: [866 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0679 | MainLoss:0.0536 | Alpha:0.4878 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9921\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9601\n",
      "\n",
      "Epoch: [867 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0528 | MainLoss:0.0384 | Alpha:0.4921 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9918\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9603\n",
      "\n",
      "Epoch: [868 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0535 | MainLoss:0.0392 | Alpha:0.4913 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9603\n",
      "\n",
      "Epoch: [869 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0591 | MainLoss:0.0447 | Alpha:0.4908 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9602\n",
      "\n",
      "Epoch: [870 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0574 | MainLoss:0.0430 | Alpha:0.4915 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9918\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9606\n",
      "\n",
      "Epoch: [871 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0526 | MainLoss:0.0383 | Alpha:0.4916 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9604\n",
      "\n",
      "Epoch: [872 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0530 | MainLoss:0.0387 | Alpha:0.4916 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9603\n",
      "\n",
      "Epoch: [873 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0528 | MainLoss:0.0385 | Alpha:0.4923 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9603\n",
      "\n",
      "Epoch: [874 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0612 | MainLoss:0.0469 | Alpha:0.4903 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9603\n",
      "\n",
      "Epoch: [875 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0635 | MainLoss:0.0492 | Alpha:0.4896 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9921\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9604\n",
      "\n",
      "Epoch: [876 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0679 | MainLoss:0.0535 | Alpha:0.4886 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9604\n",
      "\n",
      "Epoch: [877 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0505 | MainLoss:0.0362 | Alpha:0.4920 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9604\n",
      "\n",
      "Epoch: [878 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0617 | MainLoss:0.0474 | Alpha:0.4901 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9601\n",
      "\n",
      "Epoch: [879 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0566 | MainLoss:0.0423 | Alpha:0.4904 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9604\n",
      "\n",
      "Epoch: [880 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0585 | MainLoss:0.0442 | Alpha:0.4904 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9605\n",
      "\n",
      "Epoch: [881 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0482 | MainLoss:0.0339 | Alpha:0.4927 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9603\n",
      "\n",
      "Epoch: [882 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0568 | MainLoss:0.0425 | Alpha:0.4905 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9918\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9603\n",
      "\n",
      "Epoch: [883 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0528 | MainLoss:0.0385 | Alpha:0.4923 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9602\n",
      "\n",
      "Epoch: [884 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0567 | MainLoss:0.0424 | Alpha:0.4909 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9604\n",
      "\n",
      "Epoch: [885 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0576 | MainLoss:0.0432 | Alpha:0.4914 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9921\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9604\n",
      "\n",
      "Epoch: [886 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0695 | MainLoss:0.0552 | Alpha:0.4869 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9605\n",
      "\n",
      "Epoch: [887 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0532 | MainLoss:0.0389 | Alpha:0.4917 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9921\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9604\n",
      "\n",
      "Epoch: [888 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0579 | MainLoss:0.0436 | Alpha:0.4906 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9922\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9604\n",
      "\n",
      "Epoch: [889 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0633 | MainLoss:0.0490 | Alpha:0.4898 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9918\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9605\n",
      "\n",
      "Epoch: [890 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0565 | MainLoss:0.0422 | Alpha:0.4910 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9921\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9604\n",
      "\n",
      "Epoch: [891 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0545 | MainLoss:0.0402 | Alpha:0.4923 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9921\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9603\n",
      "\n",
      "Epoch: [892 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0474 | MainLoss:0.0331 | Alpha:0.4933 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9922\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9604\n",
      "\n",
      "Epoch: [893 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0549 | MainLoss:0.0406 | Alpha:0.4914 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9922\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9604\n",
      "\n",
      "Epoch: [894 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0566 | MainLoss:0.0423 | Alpha:0.4901 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9603\n",
      "\n",
      "Epoch: [895 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0511 | MainLoss:0.0368 | Alpha:0.4920 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9603\n",
      "\n",
      "Epoch: [896 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0525 | MainLoss:0.0382 | Alpha:0.4915 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9918\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9603\n",
      "\n",
      "Epoch: [897 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0507 | MainLoss:0.0364 | Alpha:0.4924 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9921\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9603\n",
      "\n",
      "Epoch: [898 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0616 | MainLoss:0.0473 | Alpha:0.4896 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9602\n",
      "\n",
      "Epoch: [899 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0513 | MainLoss:0.0370 | Alpha:0.4913 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9604\n",
      "\n",
      "Epoch: [900 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0600 | MainLoss:0.0457 | Alpha:0.4896 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9921\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9604\n",
      "\n",
      "Epoch: [901 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0455 | MainLoss:0.0312 | Alpha:0.4933 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9604\n",
      "\n",
      "Epoch: [902 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0537 | MainLoss:0.0394 | Alpha:0.4919 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9604\n",
      "\n",
      "Epoch: [903 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0571 | MainLoss:0.0428 | Alpha:0.4909 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9602\n",
      "\n",
      "Epoch: [904 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0514 | MainLoss:0.0370 | Alpha:0.4922 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9603\n",
      "\n",
      "Epoch: [905 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0634 | MainLoss:0.0490 | Alpha:0.4902 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9921\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9603\n",
      "\n",
      "Epoch: [906 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0656 | MainLoss:0.0513 | Alpha:0.4892 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9603\n",
      "\n",
      "Epoch: [907 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0563 | MainLoss:0.0420 | Alpha:0.4908 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9605\n",
      "\n",
      "Epoch: [908 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0558 | MainLoss:0.0415 | Alpha:0.4910 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9921\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9606\n",
      "\n",
      "Epoch: [909 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0641 | MainLoss:0.0498 | Alpha:0.4900 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9921\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9603\n",
      "\n",
      "Epoch: [910 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0588 | MainLoss:0.0445 | Alpha:0.4905 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9603\n",
      "\n",
      "Epoch: [911 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0512 | MainLoss:0.0369 | Alpha:0.4922 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9918\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9604\n",
      "\n",
      "Epoch: [912 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0593 | MainLoss:0.0450 | Alpha:0.4909 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9921\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9605\n",
      "\n",
      "Epoch: [913 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0668 | MainLoss:0.0525 | Alpha:0.4886 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9921\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9604\n",
      "\n",
      "Epoch: [914 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0484 | MainLoss:0.0341 | Alpha:0.4935 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9917\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9603\n",
      "\n",
      "Epoch: [915 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0490 | MainLoss:0.0347 | Alpha:0.4925 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9607\n",
      "\n",
      "Epoch: [916 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0510 | MainLoss:0.0366 | Alpha:0.4920 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9603\n",
      "\n",
      "Epoch: [917 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0582 | MainLoss:0.0439 | Alpha:0.4908 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9918\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9603\n",
      "\n",
      "Epoch: [918 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0518 | MainLoss:0.0375 | Alpha:0.4918 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9921\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9604\n",
      "\n",
      "Epoch: [919 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0691 | MainLoss:0.0548 | Alpha:0.4884 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9601\n",
      "\n",
      "Epoch: [920 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0562 | MainLoss:0.0419 | Alpha:0.4904 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9917\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9604\n",
      "\n",
      "Epoch: [921 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0560 | MainLoss:0.0417 | Alpha:0.4921 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9921\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9605\n",
      "\n",
      "Epoch: [922 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0517 | MainLoss:0.0374 | Alpha:0.4917 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9921\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9604\n",
      "\n",
      "Epoch: [923 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0542 | MainLoss:0.0398 | Alpha:0.4919 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9604\n",
      "\n",
      "Epoch: [924 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0560 | MainLoss:0.0417 | Alpha:0.4908 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9605\n",
      "\n",
      "Epoch: [925 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0593 | MainLoss:0.0450 | Alpha:0.4911 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9604\n",
      "\n",
      "Epoch: [926 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0598 | MainLoss:0.0455 | Alpha:0.4898 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9604\n",
      "\n",
      "Epoch: [927 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0647 | MainLoss:0.0504 | Alpha:0.4888 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9602\n",
      "\n",
      "Epoch: [928 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0699 | MainLoss:0.0555 | Alpha:0.4875 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9604\n",
      "\n",
      "Epoch: [929 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0499 | MainLoss:0.0356 | Alpha:0.4928 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9921\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9604\n",
      "\n",
      "Epoch: [930 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0594 | MainLoss:0.0451 | Alpha:0.4900 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9603\n",
      "\n",
      "Epoch: [931 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0558 | MainLoss:0.0415 | Alpha:0.4904 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9603\n",
      "\n",
      "Epoch: [932 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0586 | MainLoss:0.0443 | Alpha:0.4909 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9921\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9605\n",
      "\n",
      "Epoch: [933 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0556 | MainLoss:0.0413 | Alpha:0.4916 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9601\n",
      "\n",
      "Epoch: [934 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0545 | MainLoss:0.0402 | Alpha:0.4910 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9918\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9601\n",
      "\n",
      "Epoch: [935 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0522 | MainLoss:0.0379 | Alpha:0.4926 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9921\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9601\n",
      "\n",
      "Epoch: [936 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0612 | MainLoss:0.0469 | Alpha:0.4900 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9605\n",
      "\n",
      "Epoch: [937 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0531 | MainLoss:0.0388 | Alpha:0.4919 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9603\n",
      "\n",
      "Epoch: [938 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0517 | MainLoss:0.0374 | Alpha:0.4917 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9605\n",
      "\n",
      "Epoch: [939 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0511 | MainLoss:0.0368 | Alpha:0.4922 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9604\n",
      "\n",
      "Epoch: [940 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0562 | MainLoss:0.0419 | Alpha:0.4911 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9923\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9602\n",
      "\n",
      "Epoch: [941 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0548 | MainLoss:0.0404 | Alpha:0.4912 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9918\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9604\n",
      "\n",
      "Epoch: [942 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0505 | MainLoss:0.0362 | Alpha:0.4922 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9602\n",
      "\n",
      "Epoch: [943 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0652 | MainLoss:0.0509 | Alpha:0.4897 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9918\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9603\n",
      "\n",
      "Epoch: [944 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0598 | MainLoss:0.0454 | Alpha:0.4899 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9921\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9605\n",
      "\n",
      "Epoch: [945 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0535 | MainLoss:0.0392 | Alpha:0.4914 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9604\n",
      "\n",
      "Epoch: [946 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0664 | MainLoss:0.0521 | Alpha:0.4891 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9921\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9603\n",
      "\n",
      "Epoch: [947 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0472 | MainLoss:0.0329 | Alpha:0.4935 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9603\n",
      "\n",
      "Epoch: [948 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0730 | MainLoss:0.0587 | Alpha:0.4875 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9605\n",
      "\n",
      "Epoch: [949 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0482 | MainLoss:0.0339 | Alpha:0.4932 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9922\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9604\n",
      "\n",
      "Epoch: [950 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0613 | MainLoss:0.0469 | Alpha:0.4904 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9603\n",
      "\n",
      "Epoch: [951 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0521 | MainLoss:0.0377 | Alpha:0.4928 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9604\n",
      "\n",
      "Epoch: [952 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0583 | MainLoss:0.0440 | Alpha:0.4904 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9921\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9603\n",
      "\n",
      "Epoch: [953 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0539 | MainLoss:0.0396 | Alpha:0.4909 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9922\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9604\n",
      "\n",
      "Epoch: [954 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0501 | MainLoss:0.0358 | Alpha:0.4921 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9918\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9603\n",
      "\n",
      "Epoch: [955 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0551 | MainLoss:0.0408 | Alpha:0.4918 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9602\n",
      "\n",
      "Epoch: [956 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0500 | MainLoss:0.0357 | Alpha:0.4923 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9604\n",
      "\n",
      "Epoch: [957 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0643 | MainLoss:0.0500 | Alpha:0.4891 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9602\n",
      "\n",
      "Epoch: [958 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0609 | MainLoss:0.0466 | Alpha:0.4905 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9605\n",
      "\n",
      "Epoch: [959 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0490 | MainLoss:0.0347 | Alpha:0.4926 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9917\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9603\n",
      "\n",
      "Epoch: [960 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0588 | MainLoss:0.0445 | Alpha:0.4908 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9921\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9603\n",
      "\n",
      "Epoch: [961 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0623 | MainLoss:0.0480 | Alpha:0.4899 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9922\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9603\n",
      "\n",
      "Epoch: [962 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0628 | MainLoss:0.0485 | Alpha:0.4897 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9604\n",
      "\n",
      "Epoch: [963 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0580 | MainLoss:0.0437 | Alpha:0.4907 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9921\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9603\n",
      "\n",
      "Epoch: [964 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0565 | MainLoss:0.0422 | Alpha:0.4915 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9922\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9602\n",
      "\n",
      "Epoch: [965 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0579 | MainLoss:0.0436 | Alpha:0.4898 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9601\n",
      "\n",
      "Epoch: [966 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0507 | MainLoss:0.0364 | Alpha:0.4924 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9603\n",
      "\n",
      "Epoch: [967 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0560 | MainLoss:0.0417 | Alpha:0.4911 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9603\n",
      "\n",
      "Epoch: [968 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0631 | MainLoss:0.0487 | Alpha:0.4901 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9921\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9604\n",
      "\n",
      "Epoch: [969 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0487 | MainLoss:0.0344 | Alpha:0.4929 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9603\n",
      "\n",
      "Epoch: [970 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0602 | MainLoss:0.0459 | Alpha:0.4902 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9604\n",
      "\n",
      "Epoch: [971 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0731 | MainLoss:0.0588 | Alpha:0.4873 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9922\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9604\n",
      "\n",
      "Epoch: [972 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0495 | MainLoss:0.0352 | Alpha:0.4928 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9917\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9603\n",
      "\n",
      "Epoch: [973 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0546 | MainLoss:0.0403 | Alpha:0.4914 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9603\n",
      "\n",
      "Epoch: [974 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0684 | MainLoss:0.0541 | Alpha:0.4873 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9921\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9604\n",
      "\n",
      "Epoch: [975 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0617 | MainLoss:0.0474 | Alpha:0.4896 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9919\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9604\n",
      "\n",
      "Epoch: [976 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0505 | MainLoss:0.0362 | Alpha:0.4926 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9603\n",
      "\n",
      "Epoch: [977 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0515 | MainLoss:0.0371 | Alpha:0.4918 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9605\n",
      "\n",
      "Epoch: [978 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0572 | MainLoss:0.0429 | Alpha:0.4906 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9606\n",
      "\n",
      "Epoch: [979 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0534 | MainLoss:0.0390 | Alpha:0.4917 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9607\n",
      "\n",
      "Epoch: [980 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0640 | MainLoss:0.0497 | Alpha:0.4888 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9921\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9603\n",
      "\n",
      "Epoch: [981 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0615 | MainLoss:0.0472 | Alpha:0.4899 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9603\n",
      "\n",
      "Epoch: [982 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0637 | MainLoss:0.0494 | Alpha:0.4896 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9922\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9602\n",
      "\n",
      "Epoch: [983 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0613 | MainLoss:0.0470 | Alpha:0.4901 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9918\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9604\n",
      "\n",
      "Epoch: [984 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0575 | MainLoss:0.0431 | Alpha:0.4907 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9603\n",
      "\n",
      "Epoch: [985 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0510 | MainLoss:0.0366 | Alpha:0.4924 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9921\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9605\n",
      "\n",
      "Epoch: [986 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0543 | MainLoss:0.0400 | Alpha:0.4922 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9603\n",
      "\n",
      "Epoch: [987 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0558 | MainLoss:0.0414 | Alpha:0.4917 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9921\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9604\n",
      "\n",
      "Epoch: [988 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0573 | MainLoss:0.0430 | Alpha:0.4905 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9921\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9604\n",
      "\n",
      "Epoch: [989 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0481 | MainLoss:0.0338 | Alpha:0.4930 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9922\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9602\n",
      "\n",
      "Epoch: [990 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0504 | MainLoss:0.0361 | Alpha:0.4926 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9922\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9603\n",
      "\n",
      "Epoch: [991 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0549 | MainLoss:0.0406 | Alpha:0.4910 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9605\n",
      "\n",
      "Epoch: [992 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0624 | MainLoss:0.0481 | Alpha:0.4894 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9604\n",
      "\n",
      "Epoch: [993 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0574 | MainLoss:0.0431 | Alpha:0.4916 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9606\n",
      "\n",
      "Epoch: [994 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0546 | MainLoss:0.0403 | Alpha:0.4919 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9918\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9602\n",
      "\n",
      "Epoch: [995 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0643 | MainLoss:0.0500 | Alpha:0.4891 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9602\n",
      "\n",
      "Epoch: [996 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0636 | MainLoss:0.0492 | Alpha:0.4891 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9604\n",
      "\n",
      "Epoch: [997 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0619 | MainLoss:0.0476 | Alpha:0.4905 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9604\n",
      "\n",
      "Epoch: [998 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0540 | MainLoss:0.0397 | Alpha:0.4921 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9920\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9603\n",
      "\n",
      "Epoch: [999 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0583 | MainLoss:0.0440 | Alpha:0.4903 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9919\n",
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9604\n",
      "\n",
      "Epoch: [1000 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0599 | MainLoss:0.0455 | Alpha:0.4897 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9919\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 128/16 | Loss:0.7775 | MainLoss:0.7775 | SPLoss:0.0000 | CLSLoss:0.1432 | AUROC:0.9604\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(start_epoch, epochs):\n",
    "    state['lr'] = optimizer.state_dict()['param_groups'][0]['lr']\n",
    "#     adjust_learning_rate(optimizer, epoch)\n",
    "    print('\\nEpoch: [%d | %d] LR: %f' % (epoch + 1, epochs, state['lr']))\n",
    "    \n",
    "    train_loss, train_auroc = train(train_loader, teacher_model, student_model, criterion, optimizer, epoch, use_cuda)\n",
    "    test_loss, test_auroc = test(val_target_loader, student_model, criterion, epoch, use_cuda)\n",
    "    source_loss, source_auroc = test(val_source_loader, student_model, criterion, epoch, use_cuda)\n",
    "\n",
    "\n",
    "    logger.append([state['lr'], train_loss, test_loss,  source_loss, train_auroc, test_auroc, source_auroc])\n",
    "    is_best = test_auroc+source_auroc > best_acc\n",
    "    best_acc = max(test_auroc+source_auroc, best_acc)\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'state_dict' : student_model.state_dict(),\n",
    "        'best_acc': best_acc,\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    }, is_best, checkpoint=checkpoint)\n",
    "    scheduler_warmup.step()\n",
    "    scheduler.step()\n",
    "    \n",
    "    if (epoch+1)%100 == 0:\n",
    "        teacher_model.load_state_dict(student_model.state_dict())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
