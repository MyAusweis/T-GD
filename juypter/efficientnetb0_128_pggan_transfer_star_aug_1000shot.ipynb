{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import collections\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "\n",
    "from model_pytorch import EfficientNet\n",
    "from utils import Bar,Logger, AverageMeter, accuracy, mkdir_p, savefig\n",
    "from warmup_scheduler import GradualWarmupScheduler\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "import cv2\n",
    "\n",
    "from PIL import ImageFile, ImageOps\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU device 3: True\n"
     ]
    }
   ],
   "source": [
    "# GPU Device\n",
    "gpu_id = 3\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(\"GPU device %d:\" %(gpu_id), use_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = '/media/data2/dataset/GAN_ImageData/PGGAN_128/'\n",
    "target_dir = '/media/data2/dataset/GAN_ImageData/StarGAN_128/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained = './log/pggan/128/b0/aug/checkpoint.pth.tar'\n",
    "resume = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model_name = 'efficientnet-b0' # b0-b7 scale\n",
    "\n",
    "# Optimization\n",
    "num_classes = 2\n",
    "epochs = 1000\n",
    "start_epoch = 0\n",
    "train_batch = 200\n",
    "test_batch = 200\n",
    "lr = 0.1\n",
    "schedule = [50, 250, 500, 750]\n",
    "momentum = 0.1\n",
    "gamma = 0.1 # LR is multiplied by gamma on schedule\n",
    "\n",
    "# CheckPoint\n",
    "checkpoint = './log/pggan/128/b0/to_star/1000shot' # dir\n",
    "if not os.path.isdir(checkpoint):\n",
    "    os.makedirs(checkpoint)\n",
    "num_workers = 8\n",
    "\n",
    "# Seed\n",
    "manual_seed = 7\n",
    "random.seed(manual_seed)\n",
    "torch.cuda.manual_seed_all(manual_seed)\n",
    "\n",
    "# Image\n",
    "size = (128, 128)\n",
    "\n",
    "# cutmix\n",
    "cm_prob = 0.5\n",
    "cm_beta = 1.0\n",
    "\n",
    "# augmentation\n",
    "blur_prob = 0.2\n",
    "blog_sig = 0.5\n",
    "jpg_prob = 0.2\n",
    "\n",
    "best_acc = 0\n",
    "\n",
    "# sp\n",
    "sp_alpha = 0.1\n",
    "sp_beta = 0.01\n",
    "fc_name = '_fc.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {}\n",
    "state['num_classes'] = num_classes\n",
    "state['epochs'] = epochs\n",
    "state['start_epoch'] = start_epoch\n",
    "state['train_batch'] = train_batch\n",
    "state['test_batch'] = test_batch\n",
    "state['lr'] = lr\n",
    "state['schedule'] = schedule\n",
    "state['momentum'] = momentum\n",
    "state['gamma'] = gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_augment(img):\n",
    "    img = np.array(img)\n",
    "\n",
    "    if random.random() < blur_prob:\n",
    "        sig = np.random.uniform(0.0, 3.0)\n",
    "        gaussian_blur(img, sig)\n",
    "\n",
    "    if random.random() < jpg_prob:\n",
    "        qual = np.random.uniform(30.0, 100.0)\n",
    "        img = cv2_jpg(img, qual)\n",
    "\n",
    "    return Image.fromarray(img)\n",
    "\n",
    "\n",
    "def gaussian_blur(img, sigma):\n",
    "    gaussian_filter(img[:,:,0], output=img[:,:,0], sigma=sigma)\n",
    "    gaussian_filter(img[:,:,1], output=img[:,:,1], sigma=sigma)\n",
    "    gaussian_filter(img[:,:,2], output=img[:,:,2], sigma=sigma)\n",
    "\n",
    "\n",
    "def cv2_jpg(img, compress_val):\n",
    "    img_cv2 = img[:,:,::-1]\n",
    "    encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), compress_val]\n",
    "    result, encimg = cv2.imencode('.jpg', img_cv2, encode_param)\n",
    "    decimg = cv2.imdecode(encimg, 1)\n",
    "    return decimg[:,:,::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_bbox(size, lam):\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = np.int(W * cut_rat)\n",
    "    cut_h = np.int(H * cut_rat)\n",
    "\n",
    "    # uniform\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join(source_dir, 'star/1000_shot_only')\n",
    "val_target_dir = os.path.join(target_dir, 'validation')\n",
    "val_source_dir = os.path.join(source_dir, 'validation')\n",
    "\n",
    "train_aug = transforms.Compose([\n",
    "    transforms.Lambda(lambda img: data_augment(img)),\n",
    "    transforms.Resize(size),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "#     transforms.RandomErasing(p=0.3, scale=(0.02, 0.10), ratio=(0.3, 3.3), value=0, inplace=True),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "val_aug = transforms.Compose([\n",
    "    transforms.Resize(size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# pin_memory : cuda pin memeory use\n",
    "train_loader = DataLoader(datasets.ImageFolder(train_dir, transform=train_aug),\n",
    "                          batch_size=train_batch, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "val_target_loader = DataLoader(datasets.ImageFolder(val_target_dir, val_aug),\n",
    "                       batch_size=test_batch, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "val_source_loader = DataLoader(datasets.ImageFolder(val_source_dir, val_aug),\n",
    "                       batch_size=test_batch, shuffle=True, num_workers=num_workers, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> using pre-trained model './log/pggan/128/b0/aug/checkpoint.pth.tar'\n"
     ]
    }
   ],
   "source": [
    "teacher_model = EfficientNet.from_name(model_name, num_classes=num_classes,\n",
    "                              override_params={'dropout_rate':0.2, 'drop_connect_rate':0.2})\n",
    "student_model = EfficientNet.from_name(model_name, num_classes=num_classes,\n",
    "                              override_params={'dropout_rate':0.2, 'drop_connect_rate':0.2})\n",
    "\n",
    "# Pre-trained\n",
    "if pretrained:\n",
    "    print(\"=> using pre-trained model '{}'\".format(pretrained))\n",
    "    teacher_model.load_state_dict(torch.load(pretrained)['state_dict'])\n",
    "    student_model.load_state_dict(torch.load(pretrained)['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Total params: 4.01M\n"
     ]
    }
   ],
   "source": [
    "teacher_model.to('cuda')\n",
    "student_model.to('cuda')\n",
    "cudnn.benchmark = True\n",
    "print('    Total params: %.2fM' % (sum(p.numel() for p in teacher_model.parameters())/1000000.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = optim.SGD(student_model.parameters(), lr=lr, momentum=momentum)\n",
    "# optimizer = optim.Adam(student_model.parameters())\n",
    "scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)\n",
    "scheduler_warmup = GradualWarmupScheduler(optimizer, multiplier=4, total_epoch=10, after_scheduler=scheduler_cosine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resume\n",
    "if resume:\n",
    "    print('==> Resuming from checkpoint..')\n",
    "    checkpoint = os.path.dirname(resume)\n",
    "#     checkpoint = torch.load(resume)\n",
    "    resume = torch.load(resume)\n",
    "    best_acc = resume['best_acc']\n",
    "    start_epoch = resume['epoch']\n",
    "    student_model.load_state_dict(resume['state_dict'])\n",
    "    optimizer.load_state_dict(resume['optimizer'])\n",
    "    logger = Logger(os.path.join(checkpoint, 'log.txt'), resume=True)\n",
    "else:\n",
    "    logger = Logger(os.path.join(checkpoint, 'log.txt'))\n",
    "    logger.set_names(['Learning Rate', 'Train Loss', 'Valid Loss', 'Source Loss', 'Train Acc.', 'Valid Acc.', 'Source ACC.', 'Train AUROC', 'Valid AUROC', 'Source AUROC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EfficientNet(\n",
       "  (_conv_stem): Conv2dStaticSamePadding(\n",
       "    3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
       "    (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "  )\n",
       "  (_gn0): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "  (_blocks): ModuleList(\n",
       "    (0): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        32, 32, kernel_size=(3, 3), stride=[1, 1], groups=32, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        32, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        8, 32, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 16, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (1): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 96, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        96, 96, kernel_size=(3, 3), stride=[2, 2], groups=96, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 96, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        96, 4, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        4, 96, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 24, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (2): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 144, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 144, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 24, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (3): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 144, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        144, 144, kernel_size=(5, 5), stride=[2, 2], groups=144, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 144, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 40, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (4): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 240, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        240, 240, kernel_size=(5, 5), stride=(1, 1), groups=240, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 240, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 40, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (5): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 240, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        240, 240, kernel_size=(3, 3), stride=[2, 2], groups=240, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 240, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 80, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (6): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 480, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 480, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 80, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (7): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 480, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 480, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 80, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (8): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 480, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        480, 480, kernel_size=(5, 5), stride=[1, 1], groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 480, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 112, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (9): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 672, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 672, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 112, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (10): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 672, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 672, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 112, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (11): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 672, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5), stride=[2, 2], groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 672, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 192, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (12): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 1152, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 1152, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 192, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (13): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 1152, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 1152, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 192, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (14): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 1152, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 1152, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 192, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (15): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 1152, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(3, 3), stride=[1, 1], groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 1152, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 320, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "  )\n",
       "  (_conv_head): Conv2dStaticSamePadding(\n",
       "    320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "    (static_padding): Identity()\n",
       "  )\n",
       "  (_gn1): GroupNorm(8, 1280, eps=1e-05, affine=True)\n",
       "  (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n",
       "  (_dropout): Dropout(p=0.2, inplace=False)\n",
       "  (_fc): Linear(in_features=1280, out_features=2, bias=True)\n",
       "  (_swish): MemoryEfficientSwish()\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for param in teacher_model.parameters():\n",
    "    param.requires_grad = False\n",
    "teacher_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_model_weights = {}\n",
    "for name, param in teacher_model.named_parameters():\n",
    "    teacher_model_weights[name] = param.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_cls(model):\n",
    "    l2_cls = torch.tensor(0.).cuda()\n",
    "    for name, param in model.named_parameters():\n",
    "        if name.startswith(fc_name):\n",
    "            l2_cls += 0.5 * torch.norm(param) ** 2\n",
    "    return l2_cls\n",
    "\n",
    "def reg_l2sp(model):\n",
    "    sp_loss = torch.tensor(0.).cuda()\n",
    "    for name, param in model.named_parameters():\n",
    "        if not name.startswith(fc_name):\n",
    "            sp_loss += 0.5 * torch.norm(param - teacher_model_weights[name]) ** 2\n",
    "    return sp_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch, use_cuda):\n",
    "    model.train()\n",
    "    \n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    arc = AverageMeter()\n",
    "    end = time.time()\n",
    "    cls_losses = AverageMeter()\n",
    "    sp_losses = AverageMeter()\n",
    "    main_losses = AverageMeter()\n",
    "    \n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        batch_size = inputs.size(0)\n",
    "        if batch_size < train_batch:\n",
    "            continue\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            \n",
    "        r = np.random.rand(1)\n",
    "        if cm_beta > 0 and r < cm_prob:\n",
    "            \n",
    "            rand_index = torch.randperm(inputs.size()[0]).cuda()\n",
    "            tt= targets[rand_index]\n",
    "            boolean = targets==tt\n",
    "            rand_index = rand_index[boolean]\n",
    "            lam = np.random.beta(cm_beta, cm_beta)\n",
    "            bbx1, bby1, bbx2, bby2 = rand_bbox(inputs.size(), lam)\n",
    "            inputs[boolean, :, bbx1:bbx2, bby1:bby2] = inputs[rand_index, :, bbx1:bbx2, bby1:bby2]\n",
    "\n",
    "        # compute output\n",
    "        outputs = model(inputs)\n",
    "        loss_main = criterion(outputs, targets)\n",
    "        loss_cls = 0\n",
    "        loss_sp = 0\n",
    "        loss_cls = reg_cls(model)\n",
    "        loss_sp = reg_l2sp(model)\n",
    "        loss =  loss_main + sp_alpha*loss_sp + sp_beta*loss_cls\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1 = accuracy(outputs.data, targets.data)\n",
    "#         auroc = roc_auc_score(targets.cpu().detach().numpy(), outputs.cpu().detach().numpy()[:,1])\n",
    "        losses.update(loss.data.tolist(), inputs.size(0))\n",
    "        top1.update(prec1[0], inputs.size(0))\n",
    "#         arc.update(auroc, inputs.size(0))\n",
    "        cls_losses.update(loss_cls, inputs.size(0))\n",
    "        sp_losses.update(loss_sp, inputs.size(0))\n",
    "        main_losses.update(loss_main.tolist(), inputs.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        \n",
    "#         if batch_idx % 100 == 0:\n",
    "#             print('{batch}/{size} | Loss:{loss:.4f} | MainLoss:{main:.4f} | SPLoss:{sp:.4f} | CLSLoss:{cls:.4f} | top1:{tp1:.4f} | AUROC:{ac:.4f}'.format(\n",
    "#                      batch=batch_idx+1, size=len(train_loader), loss=losses.avg, main=main_losses.avg, sp=sp_losses.avg, cls=cls_losses.avg, tp1=top1.avg, ac=arc.avg))\n",
    "    print('Train | {batch}/{size} | Loss:{loss:.4f} | MainLoss:{main:.4f} | SPLoss:{sp:.4f} | CLSLoss:{cls:.4f} | top1:{tp1:.4f} | AUROC:{ac:.4f}'.format(\n",
    "                     batch=batch_idx+1, size=len(train_loader), loss=losses.avg, main=main_losses.avg, sp=sp_losses.avg, cls=cls_losses.avg, tp1=top1.avg, ac=arc.avg))\n",
    "    return (losses.avg, top1.avg, arc.avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(val_loader, model, criterion, epoch, use_cuda):\n",
    "    global best_acc\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    arc = AverageMeter()\n",
    "    cls_losses = AverageMeter()\n",
    "    sp_losses = AverageMeter()\n",
    "    main_losses = AverageMeter()\n",
    "\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(val_loader):\n",
    "            # measure data loading time\n",
    "            data_time.update(time.time() - end)\n",
    "\n",
    "            if use_cuda:\n",
    "                inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "            # compute output\n",
    "            outputs = model(inputs)\n",
    "            loss_main = criterion(outputs, targets)\n",
    "            loss_cls = 0\n",
    "            loss_sp = 0\n",
    "            loss_cls = reg_cls(model)\n",
    "            loss_sp = reg_l2sp(model)\n",
    "            loss = loss_main + sp_alpha*loss_sp + sp_beta*loss_cls\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            prec1 = accuracy(outputs.data, targets.data)\n",
    "            auroc = roc_auc_score(targets.cpu().detach().numpy(), outputs.cpu().detach().numpy()[:,1])\n",
    "            losses.update(loss.data.tolist(), inputs.size(0))\n",
    "            top1.update(prec1[0], inputs.size(0))\n",
    "            arc.update(auroc, inputs.size(0))\n",
    "            cls_losses.update(loss_cls, inputs.size(0))\n",
    "            sp_losses.update(loss_sp, inputs.size(0))\n",
    "            main_losses.update(loss_main.tolist(), inputs.size(0))\n",
    "\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "    print('Test | {batch}/{size} | Loss:{loss:.4f} | MainLoss:{main:.4f} | SPLoss:{sp:.4f} | CLSLoss:{cls:.4f} | top1:{tp1:.4f} | AUROC:{ac:.4f}'.format(\n",
    "                     batch=batch_idx+1, size=len(train_loader), loss=losses.avg, main=main_losses.avg, sp=sp_losses.avg, cls=cls_losses.avg, tp1=top1.avg, ac=arc.avg))\n",
    "    return (losses.avg, top1.avg, arc.avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, checkpoint='checkpoint', filename='checkpoint.pth.tar'):\n",
    "    filepath = os.path.join(checkpoint, filename)\n",
    "    torch.save(state, filepath)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filepath, os.path.join(checkpoint, 'model_best.pth.tar'))\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    global state\n",
    "    lr_set = [1, 1e-1, 1e-2, 1e-3, 1e-4, 1e-5]\n",
    "    lr_list = schedule.copy()\n",
    "    lr_list.append(epoch)\n",
    "    lr_list.sort()\n",
    "    idx = lr_list.index(epoch)\n",
    "    state['lr'] *= lr_set[idx]\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = state['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [1 | 1000] LR: 0.100000\n",
      "Train | 10/10 | Loss:1.2365 | MainLoss:0.9881 | SPLoss:2.3269 | CLSLoss:1.5727 | top1:49.1000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9478 | MainLoss:0.6933 | SPLoss:2.3949 | CLSLoss:1.5036 | top1:50.0098 | AUROC:0.4951\n",
      "Test | 161/10 | Loss:0.9393 | MainLoss:0.6848 | SPLoss:2.3949 | CLSLoss:1.5036 | top1:83.9034 | AUROC:0.9824\n",
      "\n",
      "Epoch: [2 | 1000] LR: 0.130000\n",
      "Train | 10/10 | Loss:0.9190 | MainLoss:0.6933 | SPLoss:2.1088 | CLSLoss:1.4840 | top1:50.6000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.8870 | MainLoss:0.6932 | SPLoss:1.7923 | CLSLoss:1.4602 | top1:50.0262 | AUROC:0.5006\n",
      "Test | 161/10 | Loss:0.8687 | MainLoss:0.6748 | SPLoss:1.7923 | CLSLoss:1.4602 | top1:87.3551 | AUROC:0.9942\n",
      "\n",
      "Epoch: [3 | 1000] LR: 0.160000\n",
      "Train | 10/10 | Loss:0.8613 | MainLoss:0.6935 | SPLoss:1.5346 | CLSLoss:1.4365 | top1:50.0000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.8343 | MainLoss:0.6952 | SPLoss:1.2501 | CLSLoss:1.4075 | top1:50.0262 | AUROC:0.5107\n",
      "Test | 161/10 | Loss:0.7850 | MainLoss:0.6459 | SPLoss:1.2501 | CLSLoss:1.4075 | top1:87.1900 | AUROC:0.9985\n",
      "\n",
      "Epoch: [4 | 1000] LR: 0.190000\n",
      "Train | 10/10 | Loss:0.8133 | MainLoss:0.6943 | SPLoss:1.0514 | CLSLoss:1.3784 | top1:50.7000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.7905 | MainLoss:0.6944 | SPLoss:0.8270 | CLSLoss:1.3434 | top1:50.4784 | AUROC:0.5335\n",
      "Test | 161/10 | Loss:0.6831 | MainLoss:0.5870 | SPLoss:0.8270 | CLSLoss:1.3434 | top1:99.0717 | AUROC:0.9997\n",
      "\n",
      "Epoch: [5 | 1000] LR: 0.220000\n",
      "Train | 10/10 | Loss:0.7763 | MainLoss:0.6943 | SPLoss:0.6899 | CLSLoss:1.3063 | top1:51.6500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.7522 | MainLoss:0.6868 | SPLoss:0.5280 | CLSLoss:1.2659 | top1:54.8624 | AUROC:0.5775\n",
      "Test | 161/10 | Loss:0.5698 | MainLoss:0.5043 | SPLoss:0.5280 | CLSLoss:1.2659 | top1:98.2555 | AUROC:0.9999\n",
      "\n",
      "Epoch: [6 | 1000] LR: 0.250000\n",
      "Train | 10/10 | Loss:0.7947 | MainLoss:0.7074 | SPLoss:0.7543 | CLSLoss:1.1883 | top1:52.3500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.7830 | MainLoss:0.6940 | SPLoss:0.7782 | CLSLoss:1.1124 | top1:50.0000 | AUROC:0.6289\n",
      "Test | 161/10 | Loss:0.7724 | MainLoss:0.6835 | SPLoss:0.7782 | CLSLoss:1.1124 | top1:50.0000 | AUROC:0.9999\n",
      "\n",
      "Epoch: [7 | 1000] LR: 0.280000\n",
      "Train | 10/10 | Loss:0.7609 | MainLoss:0.6912 | SPLoss:0.5891 | CLSLoss:1.0820 | top1:52.4500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.7402 | MainLoss:0.6899 | SPLoss:0.3992 | CLSLoss:1.0458 | top1:55.3866 | AUROC:0.6317\n",
      "Test | 161/10 | Loss:0.6736 | MainLoss:0.6232 | SPLoss:0.3992 | CLSLoss:1.0458 | top1:99.7913 | AUROC:1.0000\n",
      "\n",
      "Epoch: [8 | 1000] LR: 0.310000\n",
      "Train | 10/10 | Loss:0.7246 | MainLoss:0.6863 | SPLoss:0.2809 | CLSLoss:1.0169 | top1:54.4000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.6992 | MainLoss:0.6709 | SPLoss:0.1849 | CLSLoss:0.9822 | top1:56.7890 | AUROC:0.6637\n",
      "Test | 161/10 | Loss:0.2521 | MainLoss:0.2237 | SPLoss:0.1849 | CLSLoss:0.9822 | top1:99.7383 | AUROC:1.0000\n",
      "\n",
      "Epoch: [9 | 1000] LR: 0.340000\n",
      "Train | 10/10 | Loss:0.7166 | MainLoss:0.6817 | SPLoss:0.2579 | CLSLoss:0.9102 | top1:57.2000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.6507 | MainLoss:0.6219 | SPLoss:0.2010 | CLSLoss:0.8687 | top1:64.9410 | AUROC:0.7187\n",
      "Test | 161/10 | Loss:0.1249 | MainLoss:0.0961 | SPLoss:0.2010 | CLSLoss:0.8687 | top1:99.7103 | AUROC:1.0000\n",
      "\n",
      "Epoch: [10 | 1000] LR: 0.370000\n",
      "Train | 10/10 | Loss:0.7827 | MainLoss:0.6946 | SPLoss:0.8060 | CLSLoss:0.7524 | top1:51.5500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.7720 | MainLoss:0.6940 | SPLoss:0.7113 | CLSLoss:0.6811 | top1:50.0000 | AUROC:0.6132\n",
      "Test | 161/10 | Loss:0.7550 | MainLoss:0.6771 | SPLoss:0.7113 | CLSLoss:0.6811 | top1:50.0000 | AUROC:0.9999\n",
      "\n",
      "Epoch: [11 | 1000] LR: 0.400000\n",
      "Train | 10/10 | Loss:0.7444 | MainLoss:0.6903 | SPLoss:0.4752 | CLSLoss:0.6553 | top1:53.6500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.7139 | MainLoss:0.6828 | SPLoss:0.2481 | CLSLoss:0.6302 | top1:53.7615 | AUROC:0.6405\n",
      "Test | 161/10 | Loss:0.4241 | MainLoss:0.3930 | SPLoss:0.2481 | CLSLoss:0.6302 | top1:99.8411 | AUROC:1.0000\n",
      "\n",
      "Epoch: [12 | 1000] LR: 0.400000\n",
      "Train | 10/10 | Loss:1.1720 | MainLoss:0.8440 | SPLoss:3.2363 | CLSLoss:0.4346 | top1:54.5500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.3501 | MainLoss:0.6934 | SPLoss:6.5537 | CLSLoss:0.1344 | top1:50.0000 | AUROC:0.5818\n",
      "Test | 161/10 | Loss:1.3500 | MainLoss:0.6932 | SPLoss:6.5537 | CLSLoss:0.1344 | top1:50.0000 | AUROC:0.8905\n",
      "\n",
      "Epoch: [13 | 1000] LR: 0.399999\n",
      "Train | 10/10 | Loss:1.1446 | MainLoss:0.6938 | SPLoss:4.4952 | CLSLoss:0.1281 | top1:49.1500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9569 | MainLoss:0.6931 | SPLoss:2.6263 | CLSLoss:0.1208 | top1:50.0000 | AUROC:0.5960\n",
      "Test | 161/10 | Loss:0.9537 | MainLoss:0.6899 | SPLoss:2.6263 | CLSLoss:0.1208 | top1:50.0000 | AUROC:0.9983\n",
      "\n",
      "Epoch: [14 | 1000] LR: 0.399996\n",
      "Train | 10/10 | Loss:0.8744 | MainLoss:0.6933 | SPLoss:1.7995 | CLSLoss:0.1163 | top1:49.3500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.7980 | MainLoss:0.6918 | SPLoss:1.0510 | CLSLoss:0.1105 | top1:56.7267 | AUROC:0.5974\n",
      "Test | 161/10 | Loss:0.7661 | MainLoss:0.6599 | SPLoss:1.0510 | CLSLoss:0.1105 | top1:99.2928 | AUROC:0.9999\n",
      "\n",
      "Epoch: [15 | 1000] LR: 0.399991\n",
      "Train | 10/10 | Loss:0.7625 | MainLoss:0.6899 | SPLoss:0.7157 | CLSLoss:0.1097 | top1:52.3000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.7277 | MainLoss:0.6851 | SPLoss:0.4152 | CLSLoss:0.1088 | top1:54.4627 | AUROC:0.6167\n",
      "Test | 161/10 | Loss:0.5270 | MainLoss:0.4844 | SPLoss:0.4152 | CLSLoss:0.1088 | top1:99.4424 | AUROC:1.0000\n",
      "\n",
      "Epoch: [16 | 1000] LR: 0.399984\n",
      "Train | 10/10 | Loss:0.7186 | MainLoss:0.6867 | SPLoss:0.3087 | CLSLoss:0.1043 | top1:55.0500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.6908 | MainLoss:0.6670 | SPLoss:0.2268 | CLSLoss:0.1109 | top1:61.0256 | AUROC:0.6629\n",
      "Test | 161/10 | Loss:0.3703 | MainLoss:0.3465 | SPLoss:0.2268 | CLSLoss:0.1109 | top1:99.8567 | AUROC:1.0000\n",
      "\n",
      "Epoch: [17 | 1000] LR: 0.399975\n",
      "Train | 10/10 | Loss:7.9880 | MainLoss:0.7003 | SPLoss:72.8694 | CLSLoss:0.0683 | top1:51.6000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:6.8336 | MainLoss:0.6910 | SPLoss:61.4211 | CLSLoss:0.0520 | top1:50.0197 | AUROC:0.6461\n",
      "Test | 161/10 | Loss:6.8130 | MainLoss:0.6704 | SPLoss:61.4211 | CLSLoss:0.0520 | top1:61.3178 | AUROC:0.9938\n",
      "\n",
      "Epoch: [18 | 1000] LR: 0.399964\n",
      "Train | 10/10 | Loss:4.8937 | MainLoss:0.6753 | SPLoss:42.1771 | CLSLoss:0.0661 | top1:58.3000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:3.1793 | MainLoss:0.6434 | SPLoss:25.3478 | CLSLoss:0.1082 | top1:63.0144 | AUROC:0.6981\n",
      "Test | 161/10 | Loss:2.9828 | MainLoss:0.4469 | SPLoss:25.3478 | CLSLoss:0.1082 | top1:84.9938 | AUROC:0.9758\n",
      "\n",
      "Epoch: [19 | 1000] LR: 0.399952\n",
      "Train | 10/10 | Loss:2.4731 | MainLoss:0.6631 | SPLoss:18.0902 | CLSLoss:0.1019 | top1:63.2000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.8140 | MainLoss:0.7031 | SPLoss:11.1027 | CLSLoss:0.0555 | top1:50.0885 | AUROC:0.5213\n",
      "Test | 161/10 | Loss:1.7507 | MainLoss:0.6399 | SPLoss:11.1027 | CLSLoss:0.0555 | top1:71.2305 | AUROC:0.8990\n",
      "\n",
      "Epoch: [20 | 1000] LR: 0.399937\n",
      "Train | 10/10 | Loss:2.0208 | MainLoss:0.6730 | SPLoss:13.4725 | CLSLoss:0.0632 | top1:59.5000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:3.5882 | MainLoss:0.6388 | SPLoss:29.4853 | CLSLoss:0.0917 | top1:64.3709 | AUROC:0.7009\n",
      "Test | 161/10 | Loss:3.5073 | MainLoss:0.5579 | SPLoss:29.4853 | CLSLoss:0.0917 | top1:70.8847 | AUROC:0.9123\n",
      "\n",
      "Epoch: [21 | 1000] LR: 0.399920\n",
      "Train | 10/10 | Loss:5.7489 | MainLoss:0.6711 | SPLoss:50.7705 | CLSLoss:0.0752 | top1:58.2000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:5.6752 | MainLoss:0.6711 | SPLoss:50.0358 | CLSLoss:0.0522 | top1:64.9083 | AUROC:0.7217\n",
      "Test | 161/10 | Loss:5.6612 | MainLoss:0.6571 | SPLoss:50.0358 | CLSLoss:0.0522 | top1:66.2835 | AUROC:0.8674\n",
      "\n",
      "Epoch: [22 | 1000] LR: 0.399901\n",
      "Train | 10/10 | Loss:6.9592 | MainLoss:0.6723 | SPLoss:62.8569 | CLSLoss:0.1142 | top1:63.4500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:8.8261 | MainLoss:0.6891 | SPLoss:81.3563 | CLSLoss:0.1401 | top1:50.0000 | AUROC:0.7020\n",
      "Test | 161/10 | Loss:8.8283 | MainLoss:0.6913 | SPLoss:81.3563 | CLSLoss:0.1401 | top1:50.0000 | AUROC:0.7202\n",
      "\n",
      "Epoch: [23 | 1000] LR: 0.399881\n",
      "Train | 10/10 | Loss:6.3153 | MainLoss:0.6628 | SPLoss:56.5085 | CLSLoss:0.1658 | top1:61.4500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:18.2048 | MainLoss:0.6533 | SPLoss:175.4974 | CLSLoss:0.1702 | top1:60.9633 | AUROC:0.6856\n",
      "Test | 161/10 | Loss:18.2215 | MainLoss:0.6701 | SPLoss:175.4974 | CLSLoss:0.1702 | top1:58.1495 | AUROC:0.6208\n",
      "\n",
      "Epoch: [24 | 1000] LR: 0.399858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 10/10 | Loss:15.3249 | MainLoss:0.6379 | SPLoss:146.8515 | CLSLoss:0.1885 | top1:66.0000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:9.8671 | MainLoss:0.6517 | SPLoss:92.1400 | CLSLoss:0.1424 | top1:66.6219 | AUROC:0.7374\n",
      "Test | 161/10 | Loss:9.8928 | MainLoss:0.6774 | SPLoss:92.1400 | CLSLoss:0.1424 | top1:58.0062 | AUROC:0.6140\n",
      "\n",
      "Epoch: [25 | 1000] LR: 0.399833\n",
      "Train | 10/10 | Loss:7.0993 | MainLoss:0.6719 | SPLoss:64.2577 | CLSLoss:0.1604 | top1:65.6000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:4.5175 | MainLoss:0.6474 | SPLoss:38.6847 | CLSLoss:0.1575 | top1:65.9273 | AUROC:0.7213\n",
      "Test | 161/10 | Loss:4.5537 | MainLoss:0.6837 | SPLoss:38.6847 | CLSLoss:0.1575 | top1:54.2866 | AUROC:0.5863\n",
      "\n",
      "Epoch: [26 | 1000] LR: 0.399807\n",
      "Train | 10/10 | Loss:3.4770 | MainLoss:0.6476 | SPLoss:28.2743 | CLSLoss:0.1947 | top1:65.4000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:2.6392 | MainLoss:0.6146 | SPLoss:20.2255 | CLSLoss:0.1974 | top1:66.7595 | AUROC:0.7654\n",
      "Test | 161/10 | Loss:2.6902 | MainLoss:0.6657 | SPLoss:20.2255 | CLSLoss:0.1974 | top1:58.9408 | AUROC:0.6888\n",
      "\n",
      "Epoch: [27 | 1000] LR: 0.399778\n",
      "Train | 10/10 | Loss:2.1061 | MainLoss:0.6425 | SPLoss:14.6155 | CLSLoss:0.2010 | top1:63.5500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.5596 | MainLoss:0.6330 | SPLoss:9.2509 | CLSLoss:0.1446 | top1:68.7353 | AUROC:0.7531\n",
      "Test | 161/10 | Loss:1.6334 | MainLoss:0.7068 | SPLoss:9.2509 | CLSLoss:0.1446 | top1:50.8505 | AUROC:0.4754\n",
      "\n",
      "Epoch: [28 | 1000] LR: 0.399747\n",
      "Train | 10/10 | Loss:2.7377 | MainLoss:0.6329 | SPLoss:21.0280 | CLSLoss:0.2012 | top1:65.9500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:5.2031 | MainLoss:0.6412 | SPLoss:45.6038 | CLSLoss:0.1522 | top1:67.8670 | AUROC:0.7453\n",
      "Test | 161/10 | Loss:5.2329 | MainLoss:0.6710 | SPLoss:45.6038 | CLSLoss:0.1522 | top1:57.9657 | AUROC:0.6595\n",
      "\n",
      "Epoch: [29 | 1000] LR: 0.399715\n",
      "Train | 10/10 | Loss:11.3864 | MainLoss:0.6296 | SPLoss:107.5481 | CLSLoss:0.1972 | top1:66.7000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:7.9677 | MainLoss:0.6190 | SPLoss:73.4718 | CLSLoss:0.1466 | top1:68.9253 | AUROC:0.7623\n",
      "Test | 161/10 | Loss:8.0909 | MainLoss:0.7423 | SPLoss:73.4718 | CLSLoss:0.1466 | top1:48.2741 | AUROC:0.4412\n",
      "\n",
      "Epoch: [30 | 1000] LR: 0.399680\n",
      "Train | 10/10 | Loss:6.1063 | MainLoss:0.6303 | SPLoss:54.7426 | CLSLoss:0.1729 | top1:65.9500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:4.5020 | MainLoss:0.7288 | SPLoss:37.7113 | CLSLoss:0.2011 | top1:61.0321 | AUROC:0.7296\n",
      "Test | 161/10 | Loss:4.5988 | MainLoss:0.8257 | SPLoss:37.7113 | CLSLoss:0.2011 | top1:54.9346 | AUROC:0.7261\n",
      "\n",
      "Epoch: [31 | 1000] LR: 0.399644\n",
      "Train | 10/10 | Loss:3.8754 | MainLoss:0.6362 | SPLoss:32.3773 | CLSLoss:0.1554 | top1:64.9500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:4.8100 | MainLoss:0.6310 | SPLoss:41.7681 | CLSLoss:0.2177 | top1:64.8395 | AUROC:0.7678\n",
      "Test | 161/10 | Loss:4.8580 | MainLoss:0.6790 | SPLoss:41.7681 | CLSLoss:0.2177 | top1:60.3146 | AUROC:0.6439\n",
      "\n",
      "Epoch: [32 | 1000] LR: 0.399605\n",
      "Train | 10/10 | Loss:3.6711 | MainLoss:0.7250 | SPLoss:29.4457 | CLSLoss:0.1483 | top1:52.8500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:2.4230 | MainLoss:0.6832 | SPLoss:17.3853 | CLSLoss:0.1259 | top1:61.4515 | AUROC:0.6581\n",
      "Test | 161/10 | Loss:2.4243 | MainLoss:0.6845 | SPLoss:17.3853 | CLSLoss:0.1259 | top1:56.7508 | AUROC:0.6529\n",
      "\n",
      "Epoch: [33 | 1000] LR: 0.399565\n",
      "Train | 10/10 | Loss:1.9486 | MainLoss:0.6658 | SPLoss:12.8127 | CLSLoss:0.1574 | top1:62.6000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.7117 | MainLoss:0.6940 | SPLoss:10.1643 | CLSLoss:0.1192 | top1:50.0557 | AUROC:0.6271\n",
      "Test | 161/10 | Loss:1.7113 | MainLoss:0.6937 | SPLoss:10.1643 | CLSLoss:0.1192 | top1:50.0125 | AUROC:0.6771\n",
      "\n",
      "Epoch: [34 | 1000] LR: 0.399523\n",
      "Train | 10/10 | Loss:1.3668 | MainLoss:0.6595 | SPLoss:7.0581 | CLSLoss:0.1483 | top1:61.5500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.1697 | MainLoss:0.7003 | SPLoss:4.6769 | CLSLoss:0.1715 | top1:54.9836 | AUROC:0.6867\n",
      "Test | 161/10 | Loss:1.0725 | MainLoss:0.6031 | SPLoss:4.6769 | CLSLoss:0.1715 | top1:71.8100 | AUROC:0.8366\n",
      "\n",
      "Epoch: [35 | 1000] LR: 0.399478\n",
      "Train | 10/10 | Loss:1.0655 | MainLoss:0.6365 | SPLoss:4.2722 | CLSLoss:0.1786 | top1:64.7500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:4.0328 | MainLoss:0.7900 | SPLoss:32.4087 | CLSLoss:0.1859 | top1:51.8218 | AUROC:0.6861\n",
      "Test | 161/10 | Loss:3.9297 | MainLoss:0.6870 | SPLoss:32.4087 | CLSLoss:0.1859 | top1:59.2617 | AUROC:0.6972\n",
      "\n",
      "Epoch: [36 | 1000] LR: 0.399432\n",
      "Train | 10/10 | Loss:4.2893 | MainLoss:0.6621 | SPLoss:36.2565 | CLSLoss:0.1580 | top1:61.8500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:2.9329 | MainLoss:0.5827 | SPLoss:23.4842 | CLSLoss:0.1773 | top1:70.8060 | AUROC:0.7770\n",
      "Test | 161/10 | Loss:3.0079 | MainLoss:0.6577 | SPLoss:23.4842 | CLSLoss:0.1773 | top1:60.7819 | AUROC:0.6781\n",
      "\n",
      "Epoch: [37 | 1000] LR: 0.399383\n",
      "Train | 10/10 | Loss:4.0797 | MainLoss:0.6830 | SPLoss:33.9496 | CLSLoss:0.1743 | top1:62.5500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:3.2721 | MainLoss:0.6531 | SPLoss:26.1731 | CLSLoss:0.1661 | top1:63.4862 | AUROC:0.7129\n",
      "Test | 161/10 | Loss:3.2739 | MainLoss:0.6549 | SPLoss:26.1731 | CLSLoss:0.1661 | top1:63.7508 | AUROC:0.6843\n",
      "\n",
      "Epoch: [38 | 1000] LR: 0.399333\n",
      "Train | 10/10 | Loss:2.5243 | MainLoss:0.6388 | SPLoss:18.8360 | CLSLoss:0.1943 | top1:64.8500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.8126 | MainLoss:0.6185 | SPLoss:11.9193 | CLSLoss:0.2195 | top1:67.0380 | AUROC:0.7445\n",
      "Test | 161/10 | Loss:1.9539 | MainLoss:0.7598 | SPLoss:11.9193 | CLSLoss:0.2195 | top1:52.0903 | AUROC:0.5260\n",
      "\n",
      "Epoch: [39 | 1000] LR: 0.399281\n",
      "Train | 10/10 | Loss:3.0748 | MainLoss:0.6547 | SPLoss:24.1810 | CLSLoss:0.2052 | top1:62.6500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:6.3946 | MainLoss:0.6667 | SPLoss:57.2630 | CLSLoss:0.1580 | top1:61.6645 | AUROC:0.6776\n",
      "Test | 161/10 | Loss:6.3263 | MainLoss:0.5984 | SPLoss:57.2630 | CLSLoss:0.1580 | top1:85.3614 | AUROC:0.9379\n",
      "\n",
      "Epoch: [40 | 1000] LR: 0.399227\n",
      "Train | 10/10 | Loss:4.7362 | MainLoss:0.6431 | SPLoss:40.9114 | CLSLoss:0.1918 | top1:63.9000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:3.2407 | MainLoss:0.7016 | SPLoss:25.3712 | CLSLoss:0.1984 | top1:54.6298 | AUROC:0.7198\n",
      "Test | 161/10 | Loss:3.1450 | MainLoss:0.6059 | SPLoss:25.3712 | CLSLoss:0.1984 | top1:70.1464 | AUROC:0.8036\n",
      "\n",
      "Epoch: [41 | 1000] LR: 0.399171\n",
      "Train | 10/10 | Loss:2.4000 | MainLoss:0.6271 | SPLoss:17.7079 | CLSLoss:0.2067 | top1:65.1000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.7040 | MainLoss:0.6253 | SPLoss:10.7645 | CLSLoss:0.2243 | top1:65.6422 | AUROC:0.7238\n",
      "Test | 161/10 | Loss:1.7555 | MainLoss:0.6768 | SPLoss:10.7645 | CLSLoss:0.2243 | top1:58.1682 | AUROC:0.6861\n",
      "\n",
      "Epoch: [42 | 1000] LR: 0.399112\n",
      "Train | 10/10 | Loss:1.4930 | MainLoss:0.6231 | SPLoss:8.6784 | CLSLoss:0.2079 | top1:65.6500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.2884 | MainLoss:0.5964 | SPLoss:6.8983 | CLSLoss:0.2114 | top1:68.1324 | AUROC:0.7540\n",
      "Test | 161/10 | Loss:1.3242 | MainLoss:0.6323 | SPLoss:6.8983 | CLSLoss:0.2114 | top1:62.9065 | AUROC:0.7735\n",
      "\n",
      "Epoch: [43 | 1000] LR: 0.399052\n",
      "Train | 10/10 | Loss:15.5780 | MainLoss:0.6697 | SPLoss:149.0671 | CLSLoss:0.1572 | top1:59.0000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:13.5354 | MainLoss:0.6695 | SPLoss:128.6475 | CLSLoss:0.1173 | top1:61.2156 | AUROC:0.6716\n",
      "Test | 161/10 | Loss:13.4984 | MainLoss:0.6325 | SPLoss:128.6475 | CLSLoss:0.1173 | top1:76.6324 | AUROC:0.8782\n",
      "\n",
      "Epoch: [44 | 1000] LR: 0.398990\n",
      "Train | 10/10 | Loss:19.2832 | MainLoss:0.6586 | SPLoss:186.2312 | CLSLoss:0.1470 | top1:63.7000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:21.0682 | MainLoss:0.6041 | SPLoss:204.6242 | CLSLoss:0.1765 | top1:67.7294 | AUROC:0.7435\n",
      "Test | 161/10 | Loss:21.0290 | MainLoss:0.5649 | SPLoss:204.6242 | CLSLoss:0.1765 | top1:69.3209 | AUROC:0.8998\n",
      "\n",
      "Epoch: [45 | 1000] LR: 0.398926\n",
      "Train | 10/10 | Loss:20.8348 | MainLoss:0.6345 | SPLoss:201.9856 | CLSLoss:0.1719 | top1:63.6000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:14.4862 | MainLoss:0.7934 | SPLoss:136.9088 | CLSLoss:0.1904 | top1:56.5269 | AUROC:0.5903\n",
      "Test | 161/10 | Loss:14.3457 | MainLoss:0.6529 | SPLoss:136.9088 | CLSLoss:0.1904 | top1:61.7009 | AUROC:0.6980\n",
      "\n",
      "Epoch: [46 | 1000] LR: 0.398860\n",
      "Train | 10/10 | Loss:10.1651 | MainLoss:0.7039 | SPLoss:94.6014 | CLSLoss:0.1048 | top1:56.0500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:6.2399 | MainLoss:0.6819 | SPLoss:55.5702 | CLSLoss:0.0995 | top1:57.7064 | AUROC:0.6068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 161/10 | Loss:6.1944 | MainLoss:0.6364 | SPLoss:55.5702 | CLSLoss:0.0995 | top1:73.3770 | AUROC:0.9130\n",
      "\n",
      "Epoch: [47 | 1000] LR: 0.398792\n",
      "Train | 10/10 | Loss:4.4975 | MainLoss:0.6697 | SPLoss:38.2659 | CLSLoss:0.1205 | top1:59.7500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:2.9554 | MainLoss:0.6688 | SPLoss:22.8533 | CLSLoss:0.1331 | top1:58.9515 | AUROC:0.7029\n",
      "Test | 161/10 | Loss:2.9426 | MainLoss:0.6559 | SPLoss:22.8534 | CLSLoss:0.1331 | top1:59.6293 | AUROC:0.7834\n",
      "\n",
      "Epoch: [48 | 1000] LR: 0.398722\n",
      "Train | 10/10 | Loss:3.0870 | MainLoss:0.6560 | SPLoss:24.2968 | CLSLoss:0.1351 | top1:61.9500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:4.8969 | MainLoss:0.6493 | SPLoss:42.4668 | CLSLoss:0.0948 | top1:64.7870 | AUROC:0.7232\n",
      "Test | 161/10 | Loss:4.8960 | MainLoss:0.6484 | SPLoss:42.4668 | CLSLoss:0.0948 | top1:61.4050 | AUROC:0.7780\n",
      "\n",
      "Epoch: [49 | 1000] LR: 0.398650\n",
      "Train | 10/10 | Loss:3.5969 | MainLoss:0.6505 | SPLoss:29.4516 | CLSLoss:0.1179 | top1:62.6500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:2.3876 | MainLoss:0.6048 | SPLoss:17.8100 | CLSLoss:0.1753 | top1:66.9627 | AUROC:0.7468\n",
      "Test | 161/10 | Loss:2.4011 | MainLoss:0.6183 | SPLoss:17.8100 | CLSLoss:0.1753 | top1:62.7819 | AUROC:0.8505\n",
      "\n",
      "Epoch: [50 | 1000] LR: 0.398577\n",
      "Train | 10/10 | Loss:1.9543 | MainLoss:0.6491 | SPLoss:13.0369 | CLSLoss:0.1498 | top1:63.1000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.5488 | MainLoss:0.6525 | SPLoss:8.9499 | CLSLoss:0.1298 | top1:61.9004 | AUROC:0.7103\n",
      "Test | 161/10 | Loss:1.4750 | MainLoss:0.5787 | SPLoss:8.9499 | CLSLoss:0.1298 | top1:75.9813 | AUROC:0.8448\n",
      "\n",
      "Epoch: [51 | 1000] LR: 0.398501\n",
      "Train | 10/10 | Loss:13.4126 | MainLoss:0.6670 | SPLoss:127.4432 | CLSLoss:0.1335 | top1:59.5500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:20.4951 | MainLoss:0.6776 | SPLoss:198.1643 | CLSLoss:0.1067 | top1:62.2051 | AUROC:0.6691\n",
      "Test | 161/10 | Loss:20.4665 | MainLoss:0.6490 | SPLoss:198.1643 | CLSLoss:0.1067 | top1:77.0966 | AUROC:0.9313\n",
      "\n",
      "Epoch: [52 | 1000] LR: 0.039842\n",
      "Train | 10/10 | Loss:19.7164 | MainLoss:0.6693 | SPLoss:190.4592 | CLSLoss:0.1103 | top1:64.4000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:18.8035 | MainLoss:0.6699 | SPLoss:181.3250 | CLSLoss:0.1150 | top1:61.9856 | AUROC:0.6776\n",
      "Test | 161/10 | Loss:18.7647 | MainLoss:0.6310 | SPLoss:181.3250 | CLSLoss:0.1150 | top1:74.2866 | AUROC:0.9363\n",
      "\n",
      "Epoch: [53 | 1000] LR: 0.039834\n",
      "Train | 10/10 | Loss:18.0910 | MainLoss:0.6613 | SPLoss:174.2847 | CLSLoss:0.1199 | top1:63.2500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:17.2532 | MainLoss:0.6589 | SPLoss:165.9310 | CLSLoss:0.1252 | top1:62.8637 | AUROC:0.6895\n",
      "Test | 161/10 | Loss:17.2032 | MainLoss:0.6089 | SPLoss:165.9309 | CLSLoss:0.1252 | top1:74.0935 | AUROC:0.9405\n",
      "\n",
      "Epoch: [54 | 1000] LR: 0.039826\n",
      "Train | 10/10 | Loss:16.5918 | MainLoss:0.6412 | SPLoss:159.4925 | CLSLoss:0.1312 | top1:66.6000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:15.8270 | MainLoss:0.6403 | SPLoss:151.8534 | CLSLoss:0.1414 | top1:64.7248 | AUROC:0.7099\n",
      "Test | 161/10 | Loss:15.7639 | MainLoss:0.5771 | SPLoss:151.8534 | CLSLoss:0.1414 | top1:75.1713 | AUROC:0.9436\n",
      "\n",
      "Epoch: [55 | 1000] LR: 0.039818\n",
      "Train | 10/10 | Loss:15.2158 | MainLoss:0.6174 | SPLoss:145.9688 | CLSLoss:0.1511 | top1:67.7500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:14.5162 | MainLoss:0.6157 | SPLoss:138.9888 | CLSLoss:0.1614 | top1:66.9758 | AUROC:0.7355\n",
      "Test | 161/10 | Loss:14.4417 | MainLoss:0.5412 | SPLoss:138.9889 | CLSLoss:0.1614 | top1:76.7134 | AUROC:0.9457\n",
      "\n",
      "Epoch: [56 | 1000] LR: 0.039809\n",
      "Train | 10/10 | Loss:13.9679 | MainLoss:0.6021 | SPLoss:133.6403 | CLSLoss:0.1694 | top1:67.7500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:13.3307 | MainLoss:0.5955 | SPLoss:127.3347 | CLSLoss:0.1787 | top1:68.2634 | AUROC:0.7537\n",
      "Test | 161/10 | Loss:13.2675 | MainLoss:0.5323 | SPLoss:127.3347 | CLSLoss:0.1787 | top1:75.0249 | AUROC:0.9271\n",
      "\n",
      "Epoch: [57 | 1000] LR: 0.039800\n",
      "Train | 10/10 | Loss:12.8130 | MainLoss:0.5701 | SPLoss:122.4106 | CLSLoss:0.1885 | top1:70.0000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:12.2397 | MainLoss:0.5810 | SPLoss:116.5675 | CLSLoss:0.1976 | top1:69.4266 | AUROC:0.7663\n",
      "Test | 161/10 | Loss:12.1862 | MainLoss:0.5275 | SPLoss:116.5675 | CLSLoss:0.1976 | top1:73.5826 | AUROC:0.9138\n",
      "\n",
      "Epoch: [58 | 1000] LR: 0.039792\n",
      "Train | 10/10 | Loss:11.7717 | MainLoss:0.5630 | SPLoss:112.0667 | CLSLoss:0.2057 | top1:70.7000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:11.2517 | MainLoss:0.5768 | SPLoss:106.7284 | CLSLoss:0.2116 | top1:69.3775 | AUROC:0.7698\n",
      "Test | 161/10 | Loss:11.2340 | MainLoss:0.5590 | SPLoss:106.7284 | CLSLoss:0.2116 | top1:69.0374 | AUROC:0.9273\n",
      "\n",
      "Epoch: [59 | 1000] LR: 0.039782\n",
      "Train | 10/10 | Loss:10.8015 | MainLoss:0.5380 | SPLoss:102.6129 | CLSLoss:0.2178 | top1:72.5000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:10.3362 | MainLoss:0.5610 | SPLoss:97.7289 | CLSLoss:0.2282 | top1:70.8290 | AUROC:0.7852\n",
      "Test | 161/10 | Loss:10.3320 | MainLoss:0.5568 | SPLoss:97.7289 | CLSLoss:0.2282 | top1:69.3209 | AUROC:0.9119\n",
      "\n",
      "Epoch: [60 | 1000] LR: 0.039773\n",
      "Train | 10/10 | Loss:9.9261 | MainLoss:0.5272 | SPLoss:93.9662 | CLSLoss:0.2309 | top1:73.5000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:9.5084 | MainLoss:0.5560 | SPLoss:89.5001 | CLSLoss:0.2387 | top1:71.2123 | AUROC:0.7919\n",
      "Test | 161/10 | Loss:9.5352 | MainLoss:0.5827 | SPLoss:89.5001 | CLSLoss:0.2387 | top1:67.4112 | AUROC:0.9013\n",
      "\n",
      "Epoch: [61 | 1000] LR: 0.039763\n",
      "Train | 10/10 | Loss:9.1018 | MainLoss:0.4935 | SPLoss:86.0585 | CLSLoss:0.2463 | top1:76.0000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:8.7602 | MainLoss:0.5606 | SPLoss:81.9708 | CLSLoss:0.2520 | top1:71.7497 | AUROC:0.7964\n",
      "Test | 161/10 | Loss:8.7322 | MainLoss:0.5326 | SPLoss:81.9709 | CLSLoss:0.2520 | top1:71.4486 | AUROC:0.9040\n",
      "\n",
      "Epoch: [62 | 1000] LR: 0.039754\n",
      "Train | 10/10 | Loss:8.3999 | MainLoss:0.5160 | SPLoss:78.8138 | CLSLoss:0.2520 | top1:74.9500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:8.0714 | MainLoss:0.5627 | SPLoss:75.0613 | CLSLoss:0.2516 | top1:70.5799 | AUROC:0.7951\n",
      "Test | 161/10 | Loss:8.0999 | MainLoss:0.5912 | SPLoss:75.0613 | CLSLoss:0.2516 | top1:66.5452 | AUROC:0.9122\n",
      "\n",
      "Epoch: [63 | 1000] LR: 0.039744\n",
      "Train | 10/10 | Loss:7.7141 | MainLoss:0.4932 | SPLoss:72.1840 | CLSLoss:0.2580 | top1:77.0000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:7.4371 | MainLoss:0.5572 | SPLoss:68.7730 | CLSLoss:0.2597 | top1:71.2254 | AUROC:0.8004\n",
      "Test | 161/10 | Loss:7.4962 | MainLoss:0.6163 | SPLoss:68.7729 | CLSLoss:0.2597 | top1:65.1277 | AUROC:0.9068\n",
      "\n",
      "Epoch: [64 | 1000] LR: 0.039734\n",
      "Train | 10/10 | Loss:7.0900 | MainLoss:0.4701 | SPLoss:66.1728 | CLSLoss:0.2659 | top1:78.2000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:6.8531 | MainLoss:0.5444 | SPLoss:63.0592 | CLSLoss:0.2727 | top1:73.0668 | AUROC:0.8074\n",
      "Test | 161/10 | Loss:6.8600 | MainLoss:0.5513 | SPLoss:63.0592 | CLSLoss:0.2727 | top1:70.4268 | AUROC:0.9012\n",
      "\n",
      "Epoch: [65 | 1000] LR: 0.039723\n",
      "Train | 10/10 | Loss:6.5604 | MainLoss:0.4931 | SPLoss:60.6454 | CLSLoss:0.2728 | top1:75.9500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:6.3291 | MainLoss:0.5401 | SPLoss:57.8633 | CLSLoss:0.2725 | top1:72.7687 | AUROC:0.8094\n",
      "Test | 161/10 | Loss:6.3110 | MainLoss:0.5219 | SPLoss:57.8633 | CLSLoss:0.2725 | top1:72.0997 | AUROC:0.9169\n",
      "\n",
      "Epoch: [66 | 1000] LR: 0.039713\n",
      "Train | 10/10 | Loss:6.0403 | MainLoss:0.4700 | SPLoss:55.6759 | CLSLoss:0.2778 | top1:78.0000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:5.8413 | MainLoss:0.5324 | SPLoss:53.0611 | CLSLoss:0.2776 | top1:73.2372 | AUROC:0.8142\n",
      "Test | 161/10 | Loss:5.8812 | MainLoss:0.5723 | SPLoss:53.0611 | CLSLoss:0.2776 | top1:68.9657 | AUROC:0.9050\n",
      "\n",
      "Epoch: [67 | 1000] LR: 0.039702\n",
      "Train | 10/10 | Loss:5.5554 | MainLoss:0.4479 | SPLoss:51.0466 | CLSLoss:0.2849 | top1:79.4000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:5.4374 | MainLoss:0.5688 | SPLoss:48.6571 | CLSLoss:0.2900 | top1:71.0157 | AUROC:0.8168\n",
      "Test | 161/10 | Loss:5.5652 | MainLoss:0.6966 | SPLoss:48.6571 | CLSLoss:0.2900 | top1:62.1589 | AUROC:0.8789\n",
      "\n",
      "Epoch: [68 | 1000] LR: 0.039691\n",
      "Train | 10/10 | Loss:5.1450 | MainLoss:0.4608 | SPLoss:46.8126 | CLSLoss:0.2928 | top1:78.8500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:4.9896 | MainLoss:0.5245 | SPLoss:44.6217 | CLSLoss:0.2927 | top1:74.0858 | AUROC:0.8214\n",
      "Test | 161/10 | Loss:5.0498 | MainLoss:0.5847 | SPLoss:44.6217 | CLSLoss:0.2927 | top1:68.6698 | AUROC:0.9004\n",
      "\n",
      "Epoch: [69 | 1000] LR: 0.039680\n",
      "Train | 10/10 | Loss:4.7315 | MainLoss:0.4354 | SPLoss:42.9308 | CLSLoss:0.2997 | top1:80.9000 | AUROC:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 153/10 | Loss:4.6230 | MainLoss:0.5273 | SPLoss:40.9278 | CLSLoss:0.3007 | top1:74.1415 | AUROC:0.8216\n",
      "Test | 161/10 | Loss:4.6469 | MainLoss:0.5511 | SPLoss:40.9277 | CLSLoss:0.3007 | top1:70.7944 | AUROC:0.9122\n",
      "\n",
      "Epoch: [70 | 1000] LR: 0.039669\n",
      "Train | 10/10 | Loss:4.3599 | MainLoss:0.4187 | SPLoss:39.3815 | CLSLoss:0.3084 | top1:81.6000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:4.2834 | MainLoss:0.5255 | SPLoss:37.5485 | CLSLoss:0.3107 | top1:74.2497 | AUROC:0.8233\n",
      "Test | 161/10 | Loss:4.3376 | MainLoss:0.5797 | SPLoss:37.5485 | CLSLoss:0.3107 | top1:69.4424 | AUROC:0.9053\n",
      "\n",
      "Epoch: [71 | 1000] LR: 0.039657\n",
      "Train | 10/10 | Loss:4.0499 | MainLoss:0.4329 | SPLoss:36.1388 | CLSLoss:0.3145 | top1:79.5500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:3.9805 | MainLoss:0.5305 | SPLoss:34.4681 | CLSLoss:0.3129 | top1:73.8139 | AUROC:0.8233\n",
      "Test | 161/10 | Loss:4.0748 | MainLoss:0.6248 | SPLoss:34.4681 | CLSLoss:0.3129 | top1:66.8536 | AUROC:0.8989\n",
      "\n",
      "Epoch: [72 | 1000] LR: 0.039646\n",
      "Train | 10/10 | Loss:3.7498 | MainLoss:0.4291 | SPLoss:33.1749 | CLSLoss:0.3177 | top1:80.1000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:3.6974 | MainLoss:0.5298 | SPLoss:31.6444 | CLSLoss:0.3181 | top1:74.4332 | AUROC:0.8251\n",
      "Test | 161/10 | Loss:3.7054 | MainLoss:0.5378 | SPLoss:31.6444 | CLSLoss:0.3181 | top1:72.0561 | AUROC:0.9057\n",
      "\n",
      "Epoch: [73 | 1000] LR: 0.039634\n",
      "Train | 10/10 | Loss:3.4333 | MainLoss:0.3830 | SPLoss:30.4701 | CLSLoss:0.3275 | top1:82.4000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:3.4641 | MainLoss:0.5537 | SPLoss:29.0706 | CLSLoss:0.3353 | top1:74.4070 | AUROC:0.8311\n",
      "Test | 161/10 | Loss:3.4177 | MainLoss:0.5073 | SPLoss:29.0706 | CLSLoss:0.3353 | top1:74.5639 | AUROC:0.9084\n",
      "\n",
      "Epoch: [74 | 1000] LR: 0.039622\n",
      "Train | 10/10 | Loss:3.2064 | MainLoss:0.4038 | SPLoss:27.9924 | CLSLoss:0.3376 | top1:82.4000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:3.3513 | MainLoss:0.6753 | SPLoss:26.7260 | CLSLoss:0.3369 | top1:67.1298 | AUROC:0.8210\n",
      "Test | 161/10 | Loss:3.5625 | MainLoss:0.8865 | SPLoss:26.7260 | CLSLoss:0.3369 | top1:57.3863 | AUROC:0.8477\n",
      "\n",
      "Epoch: [75 | 1000] LR: 0.039610\n",
      "Train | 10/10 | Loss:2.9928 | MainLoss:0.4146 | SPLoss:25.7488 | CLSLoss:0.3325 | top1:81.7000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:2.9816 | MainLoss:0.5215 | SPLoss:24.5665 | CLSLoss:0.3428 | top1:75.4358 | AUROC:0.8351\n",
      "Test | 161/10 | Loss:3.0988 | MainLoss:0.6388 | SPLoss:24.5665 | CLSLoss:0.3428 | top1:67.9003 | AUROC:0.8812\n",
      "\n",
      "Epoch: [76 | 1000] LR: 0.039597\n",
      "Train | 10/10 | Loss:2.7528 | MainLoss:0.3831 | SPLoss:23.6629 | CLSLoss:0.3468 | top1:82.9500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:2.7973 | MainLoss:0.5346 | SPLoss:22.5927 | CLSLoss:0.3468 | top1:74.8919 | AUROC:0.8331\n",
      "Test | 161/10 | Loss:2.8212 | MainLoss:0.5585 | SPLoss:22.5927 | CLSLoss:0.3468 | top1:71.1277 | AUROC:0.8997\n",
      "\n",
      "Epoch: [77 | 1000] LR: 0.039584\n",
      "Train | 10/10 | Loss:2.5620 | MainLoss:0.3803 | SPLoss:21.7818 | CLSLoss:0.3534 | top1:83.6500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:2.6542 | MainLoss:0.5696 | SPLoss:20.8103 | CLSLoss:0.3551 | top1:73.4240 | AUROC:0.8293\n",
      "Test | 161/10 | Loss:2.6120 | MainLoss:0.5274 | SPLoss:20.8103 | CLSLoss:0.3551 | top1:73.2025 | AUROC:0.9128\n",
      "\n",
      "Epoch: [78 | 1000] LR: 0.039572\n",
      "Train | 10/10 | Loss:2.3993 | MainLoss:0.3894 | SPLoss:20.0640 | CLSLoss:0.3545 | top1:83.1000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:2.4530 | MainLoss:0.5327 | SPLoss:19.1662 | CLSLoss:0.3625 | top1:75.3604 | AUROC:0.8380\n",
      "Test | 161/10 | Loss:2.5172 | MainLoss:0.5969 | SPLoss:19.1662 | CLSLoss:0.3625 | top1:70.3707 | AUROC:0.8880\n",
      "\n",
      "Epoch: [79 | 1000] LR: 0.039559\n",
      "Train | 10/10 | Loss:2.2781 | MainLoss:0.4263 | SPLoss:18.4818 | CLSLoss:0.3570 | top1:80.2500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:2.2858 | MainLoss:0.5160 | SPLoss:17.6620 | CLSLoss:0.3558 | top1:75.0229 | AUROC:0.8332\n",
      "Test | 161/10 | Loss:2.4114 | MainLoss:0.6417 | SPLoss:17.6620 | CLSLoss:0.3558 | top1:66.9844 | AUROC:0.8907\n",
      "\n",
      "Epoch: [80 | 1000] LR: 0.039545\n",
      "Train | 10/10 | Loss:2.0737 | MainLoss:0.3666 | SPLoss:17.0346 | CLSLoss:0.3617 | top1:84.7000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:2.1638 | MainLoss:0.5312 | SPLoss:16.2883 | CLSLoss:0.3669 | top1:75.4358 | AUROC:0.8351\n",
      "Test | 161/10 | Loss:2.2511 | MainLoss:0.6186 | SPLoss:16.2883 | CLSLoss:0.3669 | top1:69.3988 | AUROC:0.9002\n",
      "\n",
      "Epoch: [81 | 1000] LR: 0.039532\n",
      "Train | 10/10 | Loss:1.9775 | MainLoss:0.4018 | SPLoss:15.7204 | CLSLoss:0.3648 | top1:82.1500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:2.0276 | MainLoss:0.5200 | SPLoss:15.0397 | CLSLoss:0.3621 | top1:75.4686 | AUROC:0.8370\n",
      "Test | 161/10 | Loss:2.0818 | MainLoss:0.5742 | SPLoss:15.0397 | CLSLoss:0.3621 | top1:70.9969 | AUROC:0.8951\n",
      "\n",
      "Epoch: [82 | 1000] LR: 0.039518\n",
      "Train | 10/10 | Loss:1.8301 | MainLoss:0.3755 | SPLoss:14.5101 | CLSLoss:0.3668 | top1:83.9500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.9213 | MainLoss:0.5291 | SPLoss:13.8847 | CLSLoss:0.3670 | top1:74.9672 | AUROC:0.8324\n",
      "Test | 161/10 | Loss:1.9790 | MainLoss:0.5869 | SPLoss:13.8847 | CLSLoss:0.3670 | top1:70.4984 | AUROC:0.9121\n",
      "\n",
      "Epoch: [83 | 1000] LR: 0.039505\n",
      "Train | 10/10 | Loss:1.6715 | MainLoss:0.3285 | SPLoss:13.3921 | CLSLoss:0.3761 | top1:87.2000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.9196 | MainLoss:0.6323 | SPLoss:12.8348 | CLSLoss:0.3816 | top1:72.6802 | AUROC:0.8264\n",
      "Test | 161/10 | Loss:1.7442 | MainLoss:0.4569 | SPLoss:12.8348 | CLSLoss:0.3816 | top1:77.7290 | AUROC:0.9529\n",
      "\n",
      "Epoch: [84 | 1000] LR: 0.039491\n",
      "Train | 10/10 | Loss:1.6539 | MainLoss:0.4088 | SPLoss:12.4133 | CLSLoss:0.3787 | top1:81.5000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.7140 | MainLoss:0.5182 | SPLoss:11.9215 | CLSLoss:0.3660 | top1:75.0491 | AUROC:0.8312\n",
      "Test | 161/10 | Loss:1.8073 | MainLoss:0.6115 | SPLoss:11.9215 | CLSLoss:0.3660 | top1:68.7913 | AUROC:0.9023\n",
      "\n",
      "Epoch: [85 | 1000] LR: 0.039476\n",
      "Train | 10/10 | Loss:1.5461 | MainLoss:0.3916 | SPLoss:11.5081 | CLSLoss:0.3693 | top1:82.9000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.6249 | MainLoss:0.5188 | SPLoss:11.0244 | CLSLoss:0.3688 | top1:75.1081 | AUROC:0.8341\n",
      "Test | 161/10 | Loss:1.7795 | MainLoss:0.6734 | SPLoss:11.0244 | CLSLoss:0.3688 | top1:66.3302 | AUROC:0.8906\n",
      "\n",
      "Epoch: [86 | 1000] LR: 0.039462\n",
      "Train | 10/10 | Loss:1.4377 | MainLoss:0.3684 | SPLoss:10.6553 | CLSLoss:0.3741 | top1:83.7000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.5563 | MainLoss:0.5312 | SPLoss:10.2130 | CLSLoss:0.3786 | top1:75.4718 | AUROC:0.8371\n",
      "Test | 161/10 | Loss:1.6484 | MainLoss:0.6233 | SPLoss:10.2130 | CLSLoss:0.3786 | top1:69.5234 | AUROC:0.8804\n",
      "\n",
      "Epoch: [87 | 1000] LR: 0.039447\n",
      "Train | 10/10 | Loss:1.3294 | MainLoss:0.3373 | SPLoss:9.8823 | CLSLoss:0.3870 | top1:85.6500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.5347 | MainLoss:0.5807 | SPLoss:9.5010 | CLSLoss:0.3844 | top1:72.7425 | AUROC:0.8268\n",
      "Test | 161/10 | Loss:1.7614 | MainLoss:0.8074 | SPLoss:9.5010 | CLSLoss:0.3844 | top1:62.3738 | AUROC:0.8827\n",
      "\n",
      "Epoch: [88 | 1000] LR: 0.039433\n",
      "Train | 10/10 | Loss:2.4941 | MainLoss:0.3950 | SPLoss:20.9537 | CLSLoss:0.3718 | top1:82.4000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:2.8648 | MainLoss:0.5289 | SPLoss:23.3219 | CLSLoss:0.3770 | top1:75.6225 | AUROC:0.8364\n",
      "Test | 161/10 | Loss:2.9501 | MainLoss:0.6141 | SPLoss:23.3219 | CLSLoss:0.3770 | top1:70.1620 | AUROC:0.8938\n",
      "\n",
      "Epoch: [89 | 1000] LR: 0.039418\n",
      "Train | 10/10 | Loss:2.6102 | MainLoss:0.3590 | SPLoss:22.4744 | CLSLoss:0.3752 | top1:84.4000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:2.6871 | MainLoss:0.5359 | SPLoss:21.4741 | CLSLoss:0.3814 | top1:75.3735 | AUROC:0.8395\n",
      "Test | 161/10 | Loss:2.8667 | MainLoss:0.7155 | SPLoss:21.4741 | CLSLoss:0.3814 | top1:66.4361 | AUROC:0.8864\n",
      "\n",
      "Epoch: [90 | 1000] LR: 0.039403\n",
      "Train | 10/10 | Loss:2.4408 | MainLoss:0.3677 | SPLoss:20.6920 | CLSLoss:0.3829 | top1:83.5000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:2.5060 | MainLoss:0.5243 | SPLoss:19.7792 | CLSLoss:0.3797 | top1:75.4161 | AUROC:0.8367\n",
      "Test | 161/10 | Loss:2.5824 | MainLoss:0.6007 | SPLoss:19.7792 | CLSLoss:0.3797 | top1:70.8037 | AUROC:0.9128\n",
      "\n",
      "Epoch: [91 | 1000] LR: 0.039387\n",
      "Train | 10/10 | Loss:2.2664 | MainLoss:0.3553 | SPLoss:19.0727 | CLSLoss:0.3842 | top1:84.3500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:2.3583 | MainLoss:0.5306 | SPLoss:18.2381 | CLSLoss:0.3825 | top1:75.1442 | AUROC:0.8340\n",
      "Test | 161/10 | Loss:2.4992 | MainLoss:0.6715 | SPLoss:18.2381 | CLSLoss:0.3825 | top1:67.8411 | AUROC:0.8925\n",
      "\n",
      "Epoch: [92 | 1000] LR: 0.039372\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 10/10 | Loss:2.1086 | MainLoss:0.3453 | SPLoss:17.5934 | CLSLoss:0.3877 | top1:85.3500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:2.3661 | MainLoss:0.6784 | SPLoss:16.8383 | CLSLoss:0.3854 | top1:70.2359 | AUROC:0.8289\n",
      "Test | 161/10 | Loss:2.1682 | MainLoss:0.4805 | SPLoss:16.8383 | CLSLoss:0.3854 | top1:76.8879 | AUROC:0.9067\n",
      "\n",
      "Epoch: [93 | 1000] LR: 0.039356\n",
      "Train | 10/10 | Loss:2.0160 | MainLoss:0.3873 | SPLoss:16.2488 | CLSLoss:0.3831 | top1:83.4500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:2.1169 | MainLoss:0.5581 | SPLoss:15.5507 | CLSLoss:0.3792 | top1:73.2634 | AUROC:0.8373\n",
      "Test | 161/10 | Loss:2.3382 | MainLoss:0.7793 | SPLoss:15.5507 | CLSLoss:0.3792 | top1:62.9720 | AUROC:0.8786\n",
      "\n",
      "Epoch: [94 | 1000] LR: 0.039340\n",
      "Train | 10/10 | Loss:1.8913 | MainLoss:0.3871 | SPLoss:15.0034 | CLSLoss:0.3808 | top1:82.6500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.9855 | MainLoss:0.5463 | SPLoss:14.3541 | CLSLoss:0.3825 | top1:74.2005 | AUROC:0.8318\n",
      "Test | 161/10 | Loss:2.1913 | MainLoss:0.7520 | SPLoss:14.3541 | CLSLoss:0.3825 | top1:64.4112 | AUROC:0.8694\n",
      "\n",
      "Epoch: [95 | 1000] LR: 0.039324\n",
      "Train | 10/10 | Loss:1.7628 | MainLoss:0.3727 | SPLoss:13.8620 | CLSLoss:0.3828 | top1:83.4000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.9086 | MainLoss:0.5777 | SPLoss:13.2709 | CLSLoss:0.3874 | top1:72.9391 | AUROC:0.8395\n",
      "Test | 161/10 | Loss:2.1599 | MainLoss:0.8290 | SPLoss:13.2709 | CLSLoss:0.3874 | top1:62.4081 | AUROC:0.8737\n",
      "\n",
      "Epoch: [96 | 1000] LR: 0.039308\n",
      "Train | 10/10 | Loss:1.6098 | MainLoss:0.3126 | SPLoss:12.9321 | CLSLoss:0.3941 | top1:86.7000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.7971 | MainLoss:0.5521 | SPLoss:12.4102 | CLSLoss:0.4032 | top1:75.7241 | AUROC:0.8403\n",
      "Test | 161/10 | Loss:1.9172 | MainLoss:0.6722 | SPLoss:12.4102 | CLSLoss:0.4032 | top1:69.2461 | AUROC:0.8859\n",
      "\n",
      "Epoch: [97 | 1000] LR: 0.039291\n",
      "Train | 10/10 | Loss:1.5807 | MainLoss:0.3762 | SPLoss:12.0048 | CLSLoss:0.3960 | top1:83.2500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.6840 | MainLoss:0.5288 | SPLoss:11.5122 | CLSLoss:0.3955 | top1:75.5472 | AUROC:0.8381\n",
      "Test | 161/10 | Loss:1.8559 | MainLoss:0.7007 | SPLoss:11.5122 | CLSLoss:0.3955 | top1:66.7726 | AUROC:0.8981\n",
      "\n",
      "Epoch: [98 | 1000] LR: 0.039274\n",
      "Train | 10/10 | Loss:1.4744 | MainLoss:0.3514 | SPLoss:11.1906 | CLSLoss:0.4000 | top1:84.0000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.6013 | MainLoss:0.5171 | SPLoss:10.8027 | CLSLoss:0.3955 | top1:75.6815 | AUROC:0.8389\n",
      "Test | 161/10 | Loss:1.7490 | MainLoss:0.6647 | SPLoss:10.8027 | CLSLoss:0.3955 | top1:67.8723 | AUROC:0.8928\n",
      "\n",
      "Epoch: [99 | 1000] LR: 0.039258\n",
      "Train | 10/10 | Loss:1.3329 | MainLoss:0.2845 | SPLoss:10.4439 | CLSLoss:0.4060 | top1:88.0500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.5631 | MainLoss:0.5569 | SPLoss:10.0203 | CLSLoss:0.4199 | top1:75.7798 | AUROC:0.8410\n",
      "Test | 161/10 | Loss:1.7924 | MainLoss:0.7862 | SPLoss:10.0203 | CLSLoss:0.4199 | top1:66.5296 | AUROC:0.8822\n",
      "\n",
      "Epoch: [100 | 1000] LR: 0.039241\n",
      "Train | 10/10 | Loss:1.3283 | MainLoss:0.3511 | SPLoss:9.7308 | CLSLoss:0.4151 | top1:84.4500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.4696 | MainLoss:0.5291 | SPLoss:9.3643 | CLSLoss:0.4081 | top1:75.6291 | AUROC:0.8379\n",
      "Test | 161/10 | Loss:1.6454 | MainLoss:0.7049 | SPLoss:9.3643 | CLSLoss:0.4081 | top1:67.4268 | AUROC:0.8927\n",
      "\n",
      "Epoch: [101 | 1000] LR: 0.039223\n",
      "Train | 10/10 | Loss:1.2157 | MainLoss:0.3054 | SPLoss:9.0611 | CLSLoss:0.4157 | top1:87.2500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.4541 | MainLoss:0.5793 | SPLoss:8.7059 | CLSLoss:0.4182 | top1:74.6822 | AUROC:0.8352\n",
      "Test | 161/10 | Loss:1.4593 | MainLoss:0.5845 | SPLoss:8.7059 | CLSLoss:0.4182 | top1:72.8785 | AUROC:0.9086\n",
      "\n",
      "Epoch: [102 | 1000] LR: 0.039206\n",
      "Train | 10/10 | Loss:1.1732 | MainLoss:0.3240 | SPLoss:8.4506 | CLSLoss:0.4177 | top1:87.1000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.3588 | MainLoss:0.5419 | SPLoss:8.1277 | CLSLoss:0.4186 | top1:75.9928 | AUROC:0.8398\n",
      "Test | 161/10 | Loss:1.5655 | MainLoss:0.7485 | SPLoss:8.1277 | CLSLoss:0.4186 | top1:67.3925 | AUROC:0.8912\n",
      "\n",
      "Epoch: [103 | 1000] LR: 0.039188\n",
      "Train | 10/10 | Loss:1.1113 | MainLoss:0.3181 | SPLoss:7.8896 | CLSLoss:0.4184 | top1:86.7500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.3250 | MainLoss:0.5623 | SPLoss:7.5851 | CLSLoss:0.4245 | top1:75.4686 | AUROC:0.8380\n",
      "Test | 161/10 | Loss:1.4179 | MainLoss:0.6551 | SPLoss:7.5851 | CLSLoss:0.4245 | top1:71.1589 | AUROC:0.8941\n",
      "\n",
      "Epoch: [104 | 1000] LR: 0.039170\n",
      "Train | 10/10 | Loss:1.0611 | MainLoss:0.3215 | SPLoss:7.3536 | CLSLoss:0.4228 | top1:86.1000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.2898 | MainLoss:0.5779 | SPLoss:7.0769 | CLSLoss:0.4235 | top1:74.1579 | AUROC:0.8292\n",
      "Test | 161/10 | Loss:1.5207 | MainLoss:0.8087 | SPLoss:7.0769 | CLSLoss:0.4235 | top1:65.3427 | AUROC:0.8722\n",
      "\n",
      "Epoch: [105 | 1000] LR: 0.039152\n",
      "Train | 10/10 | Loss:1.0143 | MainLoss:0.3216 | SPLoss:6.8843 | CLSLoss:0.4236 | top1:86.1500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.2568 | MainLoss:0.5779 | SPLoss:6.7459 | CLSLoss:0.4272 | top1:74.5052 | AUROC:0.8372\n",
      "Test | 161/10 | Loss:1.5605 | MainLoss:0.8817 | SPLoss:6.7459 | CLSLoss:0.4272 | top1:63.8411 | AUROC:0.8592\n",
      "\n",
      "Epoch: [106 | 1000] LR: 0.039134\n",
      "Train | 10/10 | Loss:0.9751 | MainLoss:0.3124 | SPLoss:6.5850 | CLSLoss:0.4294 | top1:87.1000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.3305 | MainLoss:0.6892 | SPLoss:6.3706 | CLSLoss:0.4229 | top1:69.6887 | AUROC:0.8291\n",
      "Test | 161/10 | Loss:1.6552 | MainLoss:1.0139 | SPLoss:6.3706 | CLSLoss:0.4229 | top1:59.0062 | AUROC:0.8347\n",
      "\n",
      "Epoch: [107 | 1000] LR: 0.039116\n",
      "Train | 10/10 | Loss:0.9719 | MainLoss:0.3486 | SPLoss:6.1916 | CLSLoss:0.4210 | top1:85.2500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.1488 | MainLoss:0.5455 | SPLoss:5.9918 | CLSLoss:0.4183 | top1:74.7477 | AUROC:0.8271\n",
      "Test | 161/10 | Loss:1.3238 | MainLoss:0.7204 | SPLoss:5.9918 | CLSLoss:0.4183 | top1:67.0903 | AUROC:0.8758\n",
      "\n",
      "Epoch: [108 | 1000] LR: 0.039097\n",
      "Train | 10/10 | Loss:0.8891 | MainLoss:0.3020 | SPLoss:5.8285 | CLSLoss:0.4235 | top1:87.7500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.1229 | MainLoss:0.5565 | SPLoss:5.6209 | CLSLoss:0.4318 | top1:75.7045 | AUROC:0.8380\n",
      "Test | 161/10 | Loss:1.3577 | MainLoss:0.7913 | SPLoss:5.6209 | CLSLoss:0.4318 | top1:66.9190 | AUROC:0.8489\n",
      "\n",
      "Epoch: [109 | 1000] LR: 0.039079\n",
      "Train | 10/10 | Loss:0.8942 | MainLoss:0.3405 | SPLoss:5.4941 | CLSLoss:0.4265 | top1:85.5000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.0918 | MainLoss:0.5553 | SPLoss:5.3222 | CLSLoss:0.4287 | top1:75.4161 | AUROC:0.8419\n",
      "Test | 161/10 | Loss:1.2590 | MainLoss:0.7225 | SPLoss:5.3222 | CLSLoss:0.4287 | top1:68.5389 | AUROC:0.8508\n",
      "\n",
      "Epoch: [110 | 1000] LR: 0.039060\n",
      "Train | 10/10 | Loss:1.1266 | MainLoss:0.3223 | SPLoss:7.9997 | CLSLoss:0.4303 | top1:86.0500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.4089 | MainLoss:0.5515 | SPLoss:8.5305 | CLSLoss:0.4315 | top1:75.7536 | AUROC:0.8375\n",
      "Test | 161/10 | Loss:1.6700 | MainLoss:0.8127 | SPLoss:8.5305 | CLSLoss:0.4315 | top1:66.6231 | AUROC:0.8317\n",
      "\n",
      "Epoch: [111 | 1000] LR: 0.039040\n",
      "Train | 10/10 | Loss:1.1415 | MainLoss:0.3087 | SPLoss:8.2840 | CLSLoss:0.4326 | top1:86.5000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.3928 | MainLoss:0.5901 | SPLoss:7.9834 | CLSLoss:0.4348 | top1:74.5741 | AUROC:0.8361\n",
      "Test | 161/10 | Loss:1.6493 | MainLoss:0.8466 | SPLoss:7.9834 | CLSLoss:0.4348 | top1:66.0125 | AUROC:0.8429\n",
      "\n",
      "Epoch: [112 | 1000] LR: 0.039021\n",
      "Train | 10/10 | Loss:1.0462 | MainLoss:0.2683 | SPLoss:7.7343 | CLSLoss:0.4393 | top1:89.2500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.3757 | MainLoss:0.6251 | SPLoss:7.4616 | CLSLoss:0.4438 | top1:74.1055 | AUROC:0.8362\n",
      "Test | 161/10 | Loss:1.3418 | MainLoss:0.5912 | SPLoss:7.4616 | CLSLoss:0.4438 | top1:74.8037 | AUROC:0.8811\n",
      "\n",
      "Epoch: [113 | 1000] LR: 0.039002\n",
      "Train | 10/10 | Loss:1.0401 | MainLoss:0.3114 | SPLoss:7.2430 | CLSLoss:0.4407 | top1:87.0000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.2705 | MainLoss:0.5668 | SPLoss:6.9924 | CLSLoss:0.4403 | top1:74.9410 | AUROC:0.8333\n",
      "Test | 161/10 | Loss:1.3078 | MainLoss:0.6042 | SPLoss:6.9924 | CLSLoss:0.4403 | top1:73.5763 | AUROC:0.8967\n",
      "\n",
      "Epoch: [114 | 1000] LR: 0.038982\n",
      "Train | 10/10 | Loss:0.9746 | MainLoss:0.2911 | SPLoss:6.7908 | CLSLoss:0.4438 | top1:88.3500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.2813 | MainLoss:0.6214 | SPLoss:6.5540 | CLSLoss:0.4476 | top1:74.8526 | AUROC:0.8408\n",
      "Test | 161/10 | Loss:1.5443 | MainLoss:0.8844 | SPLoss:6.5540 | CLSLoss:0.4476 | top1:66.1308 | AUROC:0.8431\n",
      "\n",
      "Epoch: [115 | 1000] LR: 0.038962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 10/10 | Loss:0.9478 | MainLoss:0.3054 | SPLoss:6.3801 | CLSLoss:0.4451 | top1:87.3000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.1910 | MainLoss:0.5707 | SPLoss:6.1583 | CLSLoss:0.4486 | top1:75.2785 | AUROC:0.8352\n",
      "Test | 161/10 | Loss:1.3917 | MainLoss:0.7714 | SPLoss:6.1583 | CLSLoss:0.4486 | top1:68.3925 | AUROC:0.8550\n",
      "\n",
      "Epoch: [116 | 1000] LR: 0.038942\n",
      "Train | 10/10 | Loss:0.8747 | MainLoss:0.2721 | SPLoss:5.9819 | CLSLoss:0.4505 | top1:89.5500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.1737 | MainLoss:0.5927 | SPLoss:5.7640 | CLSLoss:0.4542 | top1:75.1540 | AUROC:0.8362\n",
      "Test | 161/10 | Loss:1.2523 | MainLoss:0.6714 | SPLoss:5.7640 | CLSLoss:0.4542 | top1:72.6604 | AUROC:0.8868\n",
      "\n",
      "Epoch: [117 | 1000] LR: 0.038922\n",
      "Train | 10/10 | Loss:0.8618 | MainLoss:0.2951 | SPLoss:5.6217 | CLSLoss:0.4492 | top1:88.6500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.1335 | MainLoss:0.5854 | SPLoss:5.4359 | CLSLoss:0.4548 | top1:75.6979 | AUROC:0.8386\n",
      "Test | 161/10 | Loss:1.2713 | MainLoss:0.7231 | SPLoss:5.4359 | CLSLoss:0.4548 | top1:71.1246 | AUROC:0.8862\n",
      "\n",
      "Epoch: [118 | 1000] LR: 0.038901\n",
      "Train | 10/10 | Loss:1.7034 | MainLoss:0.4126 | SPLoss:12.8634 | CLSLoss:0.4463 | top1:82.9000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:4.8250 | MainLoss:0.5897 | SPLoss:42.3116 | CLSLoss:0.4149 | top1:70.5636 | AUROC:0.7916\n",
      "Test | 161/10 | Loss:4.9706 | MainLoss:0.7353 | SPLoss:42.3116 | CLSLoss:0.4149 | top1:64.7757 | AUROC:0.8396\n",
      "\n",
      "Epoch: [119 | 1000] LR: 0.038881\n",
      "Train | 10/10 | Loss:4.4820 | MainLoss:0.3954 | SPLoss:40.8241 | CLSLoss:0.4191 | top1:82.2000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:4.4304 | MainLoss:0.5271 | SPLoss:38.9908 | CLSLoss:0.4212 | top1:75.4587 | AUROC:0.8336\n",
      "Test | 161/10 | Loss:4.6052 | MainLoss:0.7019 | SPLoss:38.9908 | CLSLoss:0.4212 | top1:68.1807 | AUROC:0.8634\n",
      "\n",
      "Epoch: [120 | 1000] LR: 0.038860\n",
      "Train | 10/10 | Loss:4.0939 | MainLoss:0.3336 | SPLoss:37.5604 | CLSLoss:0.4257 | top1:85.1500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:4.1385 | MainLoss:0.5476 | SPLoss:35.8662 | CLSLoss:0.4287 | top1:75.2195 | AUROC:0.8342\n",
      "Test | 161/10 | Loss:4.2980 | MainLoss:0.7071 | SPLoss:35.8662 | CLSLoss:0.4287 | top1:69.0499 | AUROC:0.8488\n",
      "\n",
      "Epoch: [121 | 1000] LR: 0.038839\n",
      "Train | 10/10 | Loss:3.8278 | MainLoss:0.3660 | SPLoss:34.5759 | CLSLoss:0.4245 | top1:84.0000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:3.8869 | MainLoss:0.5797 | SPLoss:33.0303 | CLSLoss:0.4254 | top1:73.7877 | AUROC:0.8344\n",
      "Test | 161/10 | Loss:3.9390 | MainLoss:0.6317 | SPLoss:33.0303 | CLSLoss:0.4254 | top1:71.3863 | AUROC:0.8463\n",
      "\n",
      "Epoch: [122 | 1000] LR: 0.038818\n",
      "Train | 10/10 | Loss:3.5249 | MainLoss:0.3377 | SPLoss:31.8295 | CLSLoss:0.4261 | top1:85.3500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:3.5850 | MainLoss:0.5386 | SPLoss:30.4227 | CLSLoss:0.4211 | top1:74.6396 | AUROC:0.8362\n",
      "Test | 161/10 | Loss:3.6734 | MainLoss:0.6269 | SPLoss:30.4227 | CLSLoss:0.4211 | top1:70.7539 | AUROC:0.8524\n",
      "\n",
      "Epoch: [123 | 1000] LR: 0.038796\n",
      "Train | 10/10 | Loss:3.2713 | MainLoss:0.3338 | SPLoss:29.3325 | CLSLoss:0.4246 | top1:85.5000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:3.3493 | MainLoss:0.5401 | SPLoss:28.0488 | CLSLoss:0.4260 | top1:75.2228 | AUROC:0.8369\n",
      "Test | 161/10 | Loss:3.4349 | MainLoss:0.6258 | SPLoss:28.0488 | CLSLoss:0.4260 | top1:72.1277 | AUROC:0.8727\n",
      "\n",
      "Epoch: [124 | 1000] LR: 0.038775\n",
      "Train | 10/10 | Loss:3.0207 | MainLoss:0.3121 | SPLoss:27.0425 | CLSLoss:0.4315 | top1:87.3500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:3.2315 | MainLoss:0.6412 | SPLoss:25.8603 | CLSLoss:0.4254 | top1:71.5367 | AUROC:0.8352\n",
      "Test | 161/10 | Loss:3.0892 | MainLoss:0.4989 | SPLoss:25.8603 | CLSLoss:0.4254 | top1:77.3458 | AUROC:0.8854\n",
      "\n",
      "Epoch: [125 | 1000] LR: 0.038753\n",
      "Train | 10/10 | Loss:2.8731 | MainLoss:0.3746 | SPLoss:24.9424 | CLSLoss:0.4213 | top1:82.8500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:2.9345 | MainLoss:0.5451 | SPLoss:23.8515 | CLSLoss:0.4205 | top1:74.5249 | AUROC:0.8363\n",
      "Test | 161/10 | Loss:2.9911 | MainLoss:0.6018 | SPLoss:23.8515 | CLSLoss:0.4205 | top1:72.2430 | AUROC:0.8634\n",
      "\n",
      "Epoch: [126 | 1000] LR: 0.038731\n",
      "Train | 10/10 | Loss:2.6183 | MainLoss:0.3136 | SPLoss:23.0053 | CLSLoss:0.4249 | top1:86.5000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:2.8240 | MainLoss:0.6195 | SPLoss:22.0025 | CLSLoss:0.4288 | top1:73.2241 | AUROC:0.8350\n",
      "Test | 161/10 | Loss:2.8098 | MainLoss:0.6053 | SPLoss:22.0025 | CLSLoss:0.4288 | top1:72.5888 | AUROC:0.8437\n",
      "\n",
      "Epoch: [127 | 1000] LR: 0.038709\n",
      "Train | 10/10 | Loss:2.4376 | MainLoss:0.3110 | SPLoss:21.2228 | CLSLoss:0.4301 | top1:86.5500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:2.6405 | MainLoss:0.6053 | SPLoss:20.3091 | CLSLoss:0.4334 | top1:73.7451 | AUROC:0.8350\n",
      "Test | 161/10 | Loss:2.9324 | MainLoss:0.8972 | SPLoss:20.3091 | CLSLoss:0.4334 | top1:63.6449 | AUROC:0.8207\n",
      "\n",
      "Epoch: [128 | 1000] LR: 0.038687\n",
      "Train | 10/10 | Loss:2.3033 | MainLoss:0.3386 | SPLoss:19.6043 | CLSLoss:0.4326 | top1:85.7500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:2.4468 | MainLoss:0.5655 | SPLoss:18.7700 | CLSLoss:0.4310 | top1:74.3971 | AUROC:0.8353\n",
      "Test | 161/10 | Loss:2.7137 | MainLoss:0.8324 | SPLoss:18.7700 | CLSLoss:0.4310 | top1:64.7850 | AUROC:0.8338\n",
      "\n",
      "Epoch: [129 | 1000] LR: 0.038664\n",
      "Train | 10/10 | Loss:2.1441 | MainLoss:0.3277 | SPLoss:18.1211 | CLSLoss:0.4339 | top1:86.4000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:2.3389 | MainLoss:0.5975 | SPLoss:17.3707 | CLSLoss:0.4320 | top1:73.6796 | AUROC:0.8333\n",
      "Test | 161/10 | Loss:2.3190 | MainLoss:0.5776 | SPLoss:17.3707 | CLSLoss:0.4320 | top1:73.9003 | AUROC:0.8611\n",
      "\n",
      "Epoch: [130 | 1000] LR: 0.038641\n",
      "Train | 10/10 | Loss:2.0134 | MainLoss:0.3294 | SPLoss:16.7973 | CLSLoss:0.4284 | top1:85.7500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:2.1965 | MainLoss:0.5834 | SPLoss:16.0879 | CLSLoss:0.4387 | top1:75.4128 | AUROC:0.8394\n",
      "Test | 161/10 | Loss:2.3479 | MainLoss:0.7347 | SPLoss:16.0879 | CLSLoss:0.4387 | top1:69.5358 | AUROC:0.8166\n",
      "\n",
      "Epoch: [131 | 1000] LR: 0.038619\n",
      "Train | 10/10 | Loss:1.8791 | MainLoss:0.3206 | SPLoss:15.5418 | CLSLoss:0.4348 | top1:86.9500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:2.1253 | MainLoss:0.6308 | SPLoss:14.9023 | CLSLoss:0.4332 | top1:72.5983 | AUROC:0.8330\n",
      "Test | 161/10 | Loss:2.4882 | MainLoss:0.9936 | SPLoss:14.9023 | CLSLoss:0.4332 | top1:61.3053 | AUROC:0.7897\n",
      "\n",
      "Epoch: [132 | 1000] LR: 0.038596\n",
      "Train | 10/10 | Loss:1.7220 | MainLoss:0.2773 | SPLoss:14.4031 | CLSLoss:0.4383 | top1:88.5500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.9666 | MainLoss:0.5800 | SPLoss:13.8223 | CLSLoss:0.4417 | top1:74.9771 | AUROC:0.8366\n",
      "Test | 161/10 | Loss:2.1244 | MainLoss:0.7377 | SPLoss:13.8223 | CLSLoss:0.4417 | top1:69.4860 | AUROC:0.8395\n",
      "\n",
      "Epoch: [133 | 1000] LR: 0.038572\n",
      "Train | 10/10 | Loss:1.6427 | MainLoss:0.3025 | SPLoss:13.3580 | CLSLoss:0.4434 | top1:87.5500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.9760 | MainLoss:0.6892 | SPLoss:12.8244 | CLSLoss:0.4367 | top1:70.3703 | AUROC:0.8278\n",
      "Test | 161/10 | Loss:1.8036 | MainLoss:0.5168 | SPLoss:12.8244 | CLSLoss:0.4367 | top1:76.7882 | AUROC:0.8821\n",
      "\n",
      "Epoch: [134 | 1000] LR: 0.038549\n",
      "Train | 10/10 | Loss:1.5508 | MainLoss:0.3052 | SPLoss:12.4115 | CLSLoss:0.4375 | top1:87.1000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.7735 | MainLoss:0.5787 | SPLoss:11.9035 | CLSLoss:0.4431 | top1:74.8231 | AUROC:0.8336\n",
      "Test | 161/10 | Loss:1.9081 | MainLoss:0.7133 | SPLoss:11.9035 | CLSLoss:0.4431 | top1:70.2586 | AUROC:0.8368\n",
      "\n",
      "Epoch: [135 | 1000] LR: 0.038525\n",
      "Train | 10/10 | Loss:1.4767 | MainLoss:0.3200 | SPLoss:11.5235 | CLSLoss:0.4436 | top1:86.2000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.7824 | MainLoss:0.6702 | SPLoss:11.0784 | CLSLoss:0.4375 | top1:71.2025 | AUROC:0.8331\n",
      "Test | 161/10 | Loss:2.1107 | MainLoss:0.9985 | SPLoss:11.0784 | CLSLoss:0.4375 | top1:60.9502 | AUROC:0.8192\n",
      "\n",
      "Epoch: [136 | 1000] LR: 0.038502\n",
      "Train | 10/10 | Loss:1.3888 | MainLoss:0.3005 | SPLoss:10.8390 | CLSLoss:0.4422 | top1:87.5000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.6921 | MainLoss:0.5929 | SPLoss:10.9476 | CLSLoss:0.4430 | top1:73.7025 | AUROC:0.8341\n",
      "Test | 161/10 | Loss:1.7465 | MainLoss:0.6473 | SPLoss:10.9476 | CLSLoss:0.4430 | top1:71.6885 | AUROC:0.8453\n",
      "\n",
      "Epoch: [137 | 1000] LR: 0.038478\n",
      "Train | 10/10 | Loss:1.3787 | MainLoss:0.3136 | SPLoss:10.6069 | CLSLoss:0.4442 | top1:86.5500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.6458 | MainLoss:0.6212 | SPLoss:10.2021 | CLSLoss:0.4423 | top1:73.2536 | AUROC:0.8344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 161/10 | Loss:1.9202 | MainLoss:0.8955 | SPLoss:10.2021 | CLSLoss:0.4423 | top1:63.9564 | AUROC:0.8239\n",
      "\n",
      "Epoch: [138 | 1000] LR: 0.038453\n",
      "Train | 10/10 | Loss:1.2861 | MainLoss:0.2937 | SPLoss:9.8792 | CLSLoss:0.4433 | top1:87.9000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.6497 | MainLoss:0.6951 | SPLoss:9.5016 | CLSLoss:0.4463 | top1:71.5007 | AUROC:0.8345\n",
      "Test | 161/10 | Loss:1.5153 | MainLoss:0.5607 | SPLoss:9.5016 | CLSLoss:0.4463 | top1:75.9813 | AUROC:0.8599\n",
      "\n",
      "Epoch: [139 | 1000] LR: 0.038429\n",
      "Train | 10/10 | Loss:1.2715 | MainLoss:0.3395 | SPLoss:9.2766 | CLSLoss:0.4375 | top1:86.5000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.5232 | MainLoss:0.5750 | SPLoss:9.4376 | CLSLoss:0.4391 | top1:75.1999 | AUROC:0.8365\n",
      "Test | 161/10 | Loss:1.6084 | MainLoss:0.6602 | SPLoss:9.4376 | CLSLoss:0.4391 | top1:72.3801 | AUROC:0.8486\n",
      "\n",
      "Epoch: [140 | 1000] LR: 0.038405\n",
      "Train | 10/10 | Loss:1.1647 | MainLoss:0.2412 | SPLoss:9.1905 | CLSLoss:0.4463 | top1:90.4500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.5112 | MainLoss:0.6221 | SPLoss:8.8459 | CLSLoss:0.4513 | top1:74.4463 | AUROC:0.8335\n",
      "Test | 161/10 | Loss:1.5634 | MainLoss:0.6743 | SPLoss:8.8459 | CLSLoss:0.4513 | top1:72.9844 | AUROC:0.8618\n",
      "\n",
      "Epoch: [141 | 1000] LR: 0.038380\n",
      "Train | 10/10 | Loss:1.1638 | MainLoss:0.2999 | SPLoss:8.5936 | CLSLoss:0.4484 | top1:87.4500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.4134 | MainLoss:0.5810 | SPLoss:8.2796 | CLSLoss:0.4454 | top1:75.1147 | AUROC:0.8348\n",
      "Test | 161/10 | Loss:1.7229 | MainLoss:0.8905 | SPLoss:8.2796 | CLSLoss:0.4454 | top1:65.2773 | AUROC:0.8308\n",
      "\n",
      "Epoch: [142 | 1000] LR: 0.038355\n",
      "Train | 10/10 | Loss:1.1108 | MainLoss:0.3024 | SPLoss:8.0394 | CLSLoss:0.4450 | top1:86.4500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.3693 | MainLoss:0.5911 | SPLoss:7.7360 | CLSLoss:0.4530 | top1:75.0426 | AUROC:0.8333\n",
      "Test | 161/10 | Loss:1.7585 | MainLoss:0.9804 | SPLoss:7.7360 | CLSLoss:0.4530 | top1:64.2337 | AUROC:0.7994\n",
      "\n",
      "Epoch: [143 | 1000] LR: 0.038330\n",
      "Train | 10/10 | Loss:1.0210 | MainLoss:0.2667 | SPLoss:7.4976 | CLSLoss:0.4572 | top1:89.6000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.6843 | MainLoss:0.9557 | SPLoss:7.2405 | CLSLoss:0.4493 | top1:64.1121 | AUROC:0.8205\n",
      "Test | 161/10 | Loss:2.0146 | MainLoss:1.2860 | SPLoss:7.2405 | CLSLoss:0.4493 | top1:57.0561 | AUROC:0.7541\n",
      "\n",
      "Epoch: [144 | 1000] LR: 0.038305\n",
      "Train | 10/10 | Loss:1.0195 | MainLoss:0.3101 | SPLoss:7.0486 | CLSLoss:0.4476 | top1:87.1500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.2568 | MainLoss:0.5661 | SPLoss:6.8616 | CLSLoss:0.4538 | top1:75.8388 | AUROC:0.8388\n",
      "Test | 161/10 | Loss:1.5008 | MainLoss:0.8101 | SPLoss:6.8616 | CLSLoss:0.4538 | top1:68.0748 | AUROC:0.8276\n",
      "\n",
      "Epoch: [145 | 1000] LR: 0.038279\n",
      "Train | 10/10 | Loss:1.0047 | MainLoss:0.3325 | SPLoss:6.6779 | CLSLoss:0.4499 | top1:86.4000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.1975 | MainLoss:0.5468 | SPLoss:6.4619 | CLSLoss:0.4437 | top1:75.4128 | AUROC:0.8336\n",
      "Test | 161/10 | Loss:1.3863 | MainLoss:0.7357 | SPLoss:6.4619 | CLSLoss:0.4437 | top1:68.9284 | AUROC:0.8397\n",
      "\n",
      "Epoch: [146 | 1000] LR: 0.038254\n",
      "Train | 10/10 | Loss:0.8809 | MainLoss:0.2487 | SPLoss:6.2770 | CLSLoss:0.4526 | top1:90.4000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.2130 | MainLoss:0.6037 | SPLoss:6.0462 | CLSLoss:0.4606 | top1:75.1049 | AUROC:0.8326\n",
      "Test | 161/10 | Loss:1.4494 | MainLoss:0.8402 | SPLoss:6.0462 | CLSLoss:0.4606 | top1:68.8224 | AUROC:0.8386\n",
      "\n",
      "Epoch: [147 | 1000] LR: 0.038228\n",
      "Train | 10/10 | Loss:0.8994 | MainLoss:0.3053 | SPLoss:5.8951 | CLSLoss:0.4587 | top1:87.9000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.1250 | MainLoss:0.5490 | SPLoss:5.7156 | CLSLoss:0.4464 | top1:74.6822 | AUROC:0.8271\n",
      "Test | 161/10 | Loss:1.2863 | MainLoss:0.7102 | SPLoss:5.7156 | CLSLoss:0.4464 | top1:69.6075 | AUROC:0.8528\n",
      "\n",
      "Epoch: [148 | 1000] LR: 0.038202\n",
      "Train | 10/10 | Loss:0.8575 | MainLoss:0.2960 | SPLoss:5.5694 | CLSLoss:0.4516 | top1:87.3000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.1847 | MainLoss:0.6402 | SPLoss:5.4000 | CLSLoss:0.4465 | top1:71.4974 | AUROC:0.8216\n",
      "Test | 161/10 | Loss:1.1063 | MainLoss:0.5618 | SPLoss:5.4000 | CLSLoss:0.4465 | top1:75.0966 | AUROC:0.8590\n",
      "\n",
      "Epoch: [149 | 1000] LR: 0.038176\n",
      "Train | 10/10 | Loss:0.8325 | MainLoss:0.3017 | SPLoss:5.2634 | CLSLoss:0.4500 | top1:87.1000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.5090 | MainLoss:0.9926 | SPLoss:5.1198 | CLSLoss:0.4469 | top1:62.9620 | AUROC:0.8189\n",
      "Test | 161/10 | Loss:1.0174 | MainLoss:0.5010 | SPLoss:5.1198 | CLSLoss:0.4469 | top1:77.6012 | AUROC:0.8586\n",
      "\n",
      "Epoch: [150 | 1000] LR: 0.038150\n",
      "Train | 10/10 | Loss:0.8292 | MainLoss:0.3244 | SPLoss:5.0044 | CLSLoss:0.4399 | top1:86.8000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.0589 | MainLoss:0.5706 | SPLoss:4.8391 | CLSLoss:0.4488 | top1:75.5931 | AUROC:0.8402\n",
      "Test | 161/10 | Loss:1.2444 | MainLoss:0.7560 | SPLoss:4.8391 | CLSLoss:0.4488 | top1:69.7134 | AUROC:0.8039\n",
      "\n",
      "Epoch: [151 | 1000] LR: 0.038123\n",
      "Train | 10/10 | Loss:0.7375 | MainLoss:0.2617 | SPLoss:4.7130 | CLSLoss:0.4526 | top1:89.1500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.0906 | MainLoss:0.6286 | SPLoss:4.5750 | CLSLoss:0.4523 | top1:73.8204 | AUROC:0.8339\n",
      "Test | 161/10 | Loss:1.3565 | MainLoss:0.8945 | SPLoss:4.5750 | CLSLoss:0.4523 | top1:66.2835 | AUROC:0.8363\n",
      "\n",
      "Epoch: [152 | 1000] LR: 0.038097\n",
      "Train | 10/10 | Loss:0.8167 | MainLoss:0.3625 | SPLoss:4.4972 | CLSLoss:0.4478 | top1:83.7500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:139.8424 | MainLoss:0.5495 | SPLoss:1392.8861 | CLSLoss:0.4390 | top1:73.3814 | AUROC:0.8137\n",
      "Test | 161/10 | Loss:139.9185 | MainLoss:0.6255 | SPLoss:1392.8856 | CLSLoss:0.4390 | top1:70.8879 | AUROC:0.8964\n",
      "\n",
      "Epoch: [153 | 1000] LR: 0.038070\n",
      "Train | 10/10 | Loss:164.1274 | MainLoss:0.5045 | SPLoss:1636.1858 | CLSLoss:0.4262 | top1:75.5000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:160.3761 | MainLoss:0.5401 | SPLoss:1598.3196 | CLSLoss:0.4232 | top1:72.8146 | AUROC:0.8074\n",
      "Test | 161/10 | Loss:160.4856 | MainLoss:0.6496 | SPLoss:1598.3196 | CLSLoss:0.4232 | top1:67.8505 | AUROC:0.8270\n",
      "\n",
      "Epoch: [154 | 1000] LR: 0.038043\n",
      "Train | 10/10 | Loss:154.3264 | MainLoss:0.4212 | SPLoss:1539.0093 | CLSLoss:0.4266 | top1:81.0000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:147.4645 | MainLoss:0.6058 | SPLoss:1468.5419 | CLSLoss:0.4251 | top1:71.1566 | AUROC:0.8106\n",
      "Test | 161/10 | Loss:147.7227 | MainLoss:0.8641 | SPLoss:1468.5419 | CLSLoss:0.4251 | top1:61.1994 | AUROC:0.8209\n",
      "\n",
      "Epoch: [155 | 1000] LR: 0.038015\n",
      "Train | 10/10 | Loss:141.9164 | MainLoss:0.4241 | SPLoss:1414.8807 | CLSLoss:0.4246 | top1:80.4000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:135.6948 | MainLoss:0.5449 | SPLoss:1351.4584 | CLSLoss:0.4229 | top1:73.7058 | AUROC:0.8154\n",
      "Test | 161/10 | Loss:135.7841 | MainLoss:0.6342 | SPLoss:1351.4584 | CLSLoss:0.4229 | top1:69.7259 | AUROC:0.9065\n",
      "\n",
      "Epoch: [156 | 1000] LR: 0.037988\n",
      "Train | 10/10 | Loss:130.5391 | MainLoss:0.3955 | SPLoss:1301.3932 | CLSLoss:0.4237 | top1:81.7000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:124.7760 | MainLoss:0.5819 | SPLoss:1241.8995 | CLSLoss:0.4250 | top1:73.3814 | AUROC:0.8235\n",
      "Test | 161/10 | Loss:125.0121 | MainLoss:0.8180 | SPLoss:1241.8995 | CLSLoss:0.4250 | top1:64.6137 | AUROC:0.8767\n",
      "\n",
      "Epoch: [157 | 1000] LR: 0.037961\n",
      "Train | 10/10 | Loss:119.9930 | MainLoss:0.3948 | SPLoss:1195.9402 | CLSLoss:0.4223 | top1:82.1500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:114.6760 | MainLoss:0.5394 | SPLoss:1141.3225 | CLSLoss:0.4198 | top1:74.4594 | AUROC:0.8234\n",
      "Test | 161/10 | Loss:114.9535 | MainLoss:0.8168 | SPLoss:1141.3223 | CLSLoss:0.4198 | top1:63.3240 | AUROC:0.8469\n",
      "\n",
      "Epoch: [158 | 1000] LR: 0.037933\n",
      "Train | 10/10 | Loss:110.3473 | MainLoss:0.4309 | SPLoss:1099.1227 | CLSLoss:0.4167 | top1:80.0000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:105.4227 | MainLoss:0.5208 | SPLoss:1048.9794 | CLSLoss:0.4095 | top1:74.8788 | AUROC:0.8280\n",
      "Test | 161/10 | Loss:105.6161 | MainLoss:0.7142 | SPLoss:1048.9794 | CLSLoss:0.4095 | top1:65.9097 | AUROC:0.8589\n",
      "\n",
      "Epoch: [159 | 1000] LR: 0.037905\n",
      "Train | 10/10 | Loss:101.4136 | MainLoss:0.3883 | SPLoss:1010.2113 | CLSLoss:0.4168 | top1:82.0000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:96.9729 | MainLoss:0.5509 | SPLoss:964.1800 | CLSLoss:0.4044 | top1:73.0799 | AUROC:0.8242\n",
      "Test | 161/10 | Loss:97.2339 | MainLoss:0.8119 | SPLoss:964.1800 | CLSLoss:0.4044 | top1:61.1589 | AUROC:0.8326\n",
      "\n",
      "Epoch: [160 | 1000] LR: 0.037877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 10/10 | Loss:93.2362 | MainLoss:0.3703 | SPLoss:928.6183 | CLSLoss:0.4119 | top1:82.7000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:89.2237 | MainLoss:0.5354 | SPLoss:886.8408 | CLSLoss:0.4166 | top1:75.1180 | AUROC:0.8299\n",
      "Test | 161/10 | Loss:89.4758 | MainLoss:0.7875 | SPLoss:886.8407 | CLSLoss:0.4166 | top1:65.6075 | AUROC:0.8198\n",
      "\n",
      "Epoch: [161 | 1000] LR: 0.037849\n",
      "Train | 10/10 | Loss:85.7426 | MainLoss:0.3251 | SPLoss:854.1321 | CLSLoss:0.4224 | top1:85.8500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:82.1393 | MainLoss:0.6094 | SPLoss:815.2567 | CLSLoss:0.4246 | top1:72.7097 | AUROC:0.8290\n",
      "Test | 161/10 | Loss:82.2469 | MainLoss:0.7171 | SPLoss:815.2569 | CLSLoss:0.4246 | top1:69.1963 | AUROC:0.8467\n",
      "\n",
      "Epoch: [162 | 1000] LR: 0.037820\n",
      "Train | 10/10 | Loss:78.8932 | MainLoss:0.3667 | SPLoss:785.2231 | CLSLoss:0.4221 | top1:83.7500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:75.4919 | MainLoss:0.5350 | SPLoss:749.5273 | CLSLoss:0.4171 | top1:74.8493 | AUROC:0.8310\n",
      "Test | 161/10 | Loss:75.7438 | MainLoss:0.7869 | SPLoss:749.5274 | CLSLoss:0.4171 | top1:65.0156 | AUROC:0.8175\n",
      "\n",
      "Epoch: [163 | 1000] LR: 0.037792\n",
      "Train | 10/10 | Loss:72.5828 | MainLoss:0.3853 | SPLoss:721.9341 | CLSLoss:0.4122 | top1:83.3500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:69.4896 | MainLoss:0.5720 | SPLoss:689.1338 | CLSLoss:0.4103 | top1:74.3381 | AUROC:0.8229\n",
      "Test | 161/10 | Loss:69.8791 | MainLoss:0.9616 | SPLoss:689.1336 | CLSLoss:0.4103 | top1:61.6729 | AUROC:0.8099\n",
      "\n",
      "Epoch: [164 | 1000] LR: 0.037763\n",
      "Train | 10/10 | Loss:66.7076 | MainLoss:0.3246 | SPLoss:663.7894 | CLSLoss:0.4115 | top1:86.5500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:63.9611 | MainLoss:0.5877 | SPLoss:633.6911 | CLSLoss:0.4192 | top1:74.7248 | AUROC:0.8270\n",
      "Test | 161/10 | Loss:64.3000 | MainLoss:0.9266 | SPLoss:633.6910 | CLSLoss:0.4192 | top1:64.3583 | AUROC:0.8307\n",
      "\n",
      "Epoch: [165 | 1000] LR: 0.037734\n",
      "Train | 10/10 | Loss:61.3658 | MainLoss:0.3191 | SPLoss:610.4250 | CLSLoss:0.4181 | top1:86.3000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:58.8522 | MainLoss:0.5727 | SPLoss:582.7538 | CLSLoss:0.4187 | top1:74.6232 | AUROC:0.8302\n",
      "Test | 161/10 | Loss:59.1389 | MainLoss:0.8594 | SPLoss:582.7537 | CLSLoss:0.4187 | top1:65.8941 | AUROC:0.7981\n",
      "\n",
      "Epoch: [166 | 1000] LR: 0.037705\n",
      "Train | 10/10 | Loss:56.5078 | MainLoss:0.3663 | SPLoss:561.3744 | CLSLoss:0.4118 | top1:84.1500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:54.2495 | MainLoss:0.6501 | SPLoss:535.9537 | CLSLoss:0.4130 | top1:72.0904 | AUROC:0.8274\n",
      "Test | 161/10 | Loss:54.6928 | MainLoss:1.0934 | SPLoss:535.9537 | CLSLoss:0.4130 | top1:59.4081 | AUROC:0.7846\n",
      "\n",
      "Epoch: [167 | 1000] LR: 0.037675\n",
      "Train | 10/10 | Loss:51.9947 | MainLoss:0.3601 | SPLoss:516.3055 | CLSLoss:0.4101 | top1:84.2000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:49.8879 | MainLoss:0.5889 | SPLoss:492.9497 | CLSLoss:0.4093 | top1:73.2765 | AUROC:0.8294\n",
      "Test | 161/10 | Loss:50.0010 | MainLoss:0.7020 | SPLoss:492.9497 | CLSLoss:0.4093 | top1:69.2337 | AUROC:0.8279\n",
      "\n",
      "Epoch: [168 | 1000] LR: 0.037646\n",
      "Train | 10/10 | Loss:47.8733 | MainLoss:0.3765 | SPLoss:474.9275 | CLSLoss:0.4017 | top1:83.4000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:45.9957 | MainLoss:0.5783 | SPLoss:454.1346 | CLSLoss:0.4030 | top1:73.6828 | AUROC:0.8267\n",
      "Test | 161/10 | Loss:46.1357 | MainLoss:0.7183 | SPLoss:454.1346 | CLSLoss:0.4030 | top1:68.6604 | AUROC:0.8134\n",
      "\n",
      "Epoch: [169 | 1000] LR: 0.037616\n",
      "Train | 10/10 | Loss:44.3220 | MainLoss:0.4053 | SPLoss:439.1271 | CLSLoss:0.3931 | top1:80.6500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:42.5535 | MainLoss:0.5428 | SPLoss:420.0666 | CLSLoss:0.3964 | top1:75.0754 | AUROC:0.8330\n",
      "Test | 161/10 | Loss:42.9121 | MainLoss:0.9015 | SPLoss:420.0665 | CLSLoss:0.3964 | top1:63.2679 | AUROC:0.8606\n",
      "\n",
      "Epoch: [170 | 1000] LR: 0.037586\n",
      "Train | 10/10 | Loss:40.7838 | MainLoss:0.3053 | SPLoss:404.7448 | CLSLoss:0.4019 | top1:86.7500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:39.2759 | MainLoss:0.6220 | SPLoss:386.4986 | CLSLoss:0.4083 | top1:73.7025 | AUROC:0.8301\n",
      "Test | 161/10 | Loss:39.7954 | MainLoss:1.1415 | SPLoss:386.4987 | CLSLoss:0.4083 | top1:59.4704 | AUROC:0.7957\n",
      "\n",
      "Epoch: [171 | 1000] LR: 0.037556\n",
      "Train | 10/10 | Loss:37.5929 | MainLoss:0.3490 | SPLoss:372.3990 | CLSLoss:0.3996 | top1:84.9500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:36.1362 | MainLoss:0.5713 | SPLoss:355.6096 | CLSLoss:0.4065 | top1:74.7149 | AUROC:0.8286\n",
      "Test | 161/10 | Loss:36.5173 | MainLoss:0.9524 | SPLoss:355.6097 | CLSLoss:0.4065 | top1:63.2523 | AUROC:0.8301\n",
      "\n",
      "Epoch: [172 | 1000] LR: 0.037526\n",
      "Train | 10/10 | Loss:34.6339 | MainLoss:0.3651 | SPLoss:342.6483 | CLSLoss:0.4027 | top1:83.1000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:33.2643 | MainLoss:0.5365 | SPLoss:327.2381 | CLSLoss:0.3937 | top1:74.3218 | AUROC:0.8298\n",
      "Test | 161/10 | Loss:33.5112 | MainLoss:0.7834 | SPLoss:327.2381 | CLSLoss:0.3937 | top1:65.8006 | AUROC:0.8665\n",
      "\n",
      "Epoch: [173 | 1000] LR: 0.037496\n",
      "Train | 10/10 | Loss:31.8521 | MainLoss:0.3168 | SPLoss:315.3138 | CLSLoss:0.3996 | top1:86.1500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:30.6899 | MainLoss:0.5715 | SPLoss:301.1433 | CLSLoss:0.4053 | top1:74.6461 | AUROC:0.8268\n",
      "Test | 161/10 | Loss:31.1041 | MainLoss:0.9857 | SPLoss:301.1433 | CLSLoss:0.4053 | top1:62.0779 | AUROC:0.8382\n",
      "\n",
      "Epoch: [174 | 1000] LR: 0.037465\n",
      "Train | 10/10 | Loss:29.3769 | MainLoss:0.3475 | SPLoss:290.2539 | CLSLoss:0.3994 | top1:84.8000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:28.2975 | MainLoss:0.5644 | SPLoss:277.2919 | CLSLoss:0.4014 | top1:74.5708 | AUROC:0.8275\n",
      "Test | 161/10 | Loss:28.6543 | MainLoss:0.9211 | SPLoss:277.2918 | CLSLoss:0.4014 | top1:62.6947 | AUROC:0.8388\n",
      "\n",
      "Epoch: [175 | 1000] LR: 0.037435\n",
      "Train | 10/10 | Loss:27.0571 | MainLoss:0.3308 | SPLoss:267.2220 | CLSLoss:0.4030 | top1:85.6000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:26.0936 | MainLoss:0.5636 | SPLoss:255.2595 | CLSLoss:0.3996 | top1:73.7484 | AUROC:0.8229\n",
      "Test | 161/10 | Loss:26.3022 | MainLoss:0.7723 | SPLoss:255.2595 | CLSLoss:0.3996 | top1:66.0561 | AUROC:0.8433\n",
      "\n",
      "Epoch: [176 | 1000] LR: 0.037404\n",
      "Train | 10/10 | Loss:24.8849 | MainLoss:0.2817 | SPLoss:245.9909 | CLSLoss:0.4090 | top1:88.5500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:24.0874 | MainLoss:0.5844 | SPLoss:234.9893 | CLSLoss:0.4110 | top1:74.4889 | AUROC:0.8244\n",
      "Test | 161/10 | Loss:24.5426 | MainLoss:1.0396 | SPLoss:234.9893 | CLSLoss:0.4110 | top1:61.4984 | AUROC:0.7867\n",
      "\n",
      "Epoch: [177 | 1000] LR: 0.037373\n",
      "Train | 10/10 | Loss:23.0090 | MainLoss:0.3559 | SPLoss:226.4906 | CLSLoss:0.4051 | top1:83.6500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:22.3105 | MainLoss:0.6697 | SPLoss:216.3675 | CLSLoss:0.4061 | top1:71.9037 | AUROC:0.8265\n",
      "Test | 161/10 | Loss:22.8905 | MainLoss:1.2497 | SPLoss:216.3674 | CLSLoss:0.4061 | top1:56.5203 | AUROC:0.7576\n",
      "\n",
      "Epoch: [178 | 1000] LR: 0.037341\n",
      "Train | 10/10 | Loss:21.2165 | MainLoss:0.3565 | SPLoss:208.5595 | CLSLoss:0.4015 | top1:84.6000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:20.5001 | MainLoss:0.5729 | SPLoss:199.2317 | CLSLoss:0.4071 | top1:74.7215 | AUROC:0.8272\n",
      "Test | 161/10 | Loss:20.8244 | MainLoss:0.8972 | SPLoss:199.2317 | CLSLoss:0.4071 | top1:65.0654 | AUROC:0.8076\n",
      "\n",
      "Epoch: [179 | 1000] LR: 0.037310\n",
      "Train | 10/10 | Loss:19.4966 | MainLoss:0.2897 | SPLoss:192.0269 | CLSLoss:0.4128 | top1:87.8500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:18.9932 | MainLoss:0.6419 | SPLoss:183.4718 | CLSLoss:0.4082 | top1:72.6704 | AUROC:0.8203\n",
      "Test | 161/10 | Loss:19.5413 | MainLoss:1.1901 | SPLoss:183.4718 | CLSLoss:0.4082 | top1:58.2368 | AUROC:0.8014\n",
      "\n",
      "Epoch: [180 | 1000] LR: 0.037278\n",
      "Train | 10/10 | Loss:17.9996 | MainLoss:0.3096 | SPLoss:176.8592 | CLSLoss:0.4108 | top1:86.5500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:17.5392 | MainLoss:0.6332 | SPLoss:169.0185 | CLSLoss:0.4086 | top1:72.1363 | AUROC:0.8270\n",
      "Test | 161/10 | Loss:17.6296 | MainLoss:0.7237 | SPLoss:169.0184 | CLSLoss:0.4086 | top1:69.2866 | AUROC:0.8560\n",
      "\n",
      "Epoch: [181 | 1000] LR: 0.037247\n",
      "Train | 10/10 | Loss:16.5606 | MainLoss:0.2634 | SPLoss:162.9301 | CLSLoss:0.4152 | top1:88.8500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:16.3701 | MainLoss:0.7969 | SPLoss:155.6898 | CLSLoss:0.4219 | top1:69.1055 | AUROC:0.8151\n",
      "Test | 161/10 | Loss:16.9424 | MainLoss:1.3692 | SPLoss:155.6898 | CLSLoss:0.4219 | top1:56.1745 | AUROC:0.7779\n",
      "\n",
      "Epoch: [182 | 1000] LR: 0.037215\n",
      "Train | 10/10 | Loss:15.3559 | MainLoss:0.3382 | SPLoss:150.1364 | CLSLoss:0.4093 | top1:85.9500 | AUROC:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 153/10 | Loss:14.9449 | MainLoss:0.5921 | SPLoss:143.4862 | CLSLoss:0.4157 | top1:74.7739 | AUROC:0.8300\n",
      "Test | 161/10 | Loss:15.3181 | MainLoss:0.9653 | SPLoss:143.4861 | CLSLoss:0.4157 | top1:63.7477 | AUROC:0.8110\n",
      "\n",
      "Epoch: [183 | 1000] LR: 0.037183\n",
      "Train | 10/10 | Loss:14.1498 | MainLoss:0.3126 | SPLoss:138.3302 | CLSLoss:0.4196 | top1:86.9000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:13.9679 | MainLoss:0.7392 | SPLoss:132.2465 | CLSLoss:0.4068 | top1:68.6107 | AUROC:0.7963\n",
      "Test | 161/10 | Loss:14.2849 | MainLoss:1.0562 | SPLoss:132.2465 | CLSLoss:0.4068 | top1:59.8100 | AUROC:0.9125\n",
      "\n",
      "Epoch: [184 | 1000] LR: 0.037151\n",
      "Train | 10/10 | Loss:13.1222 | MainLoss:0.3664 | SPLoss:127.5185 | CLSLoss:0.4024 | top1:83.4500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:12.7708 | MainLoss:0.5794 | SPLoss:121.8728 | CLSLoss:0.4096 | top1:74.0531 | AUROC:0.8204\n",
      "Test | 161/10 | Loss:12.9717 | MainLoss:0.7803 | SPLoss:121.8728 | CLSLoss:0.4096 | top1:67.5794 | AUROC:0.8880\n",
      "\n",
      "Epoch: [185 | 1000] LR: 0.037118\n",
      "Train | 10/10 | Loss:12.0963 | MainLoss:0.3403 | SPLoss:117.5182 | CLSLoss:0.4109 | top1:84.9500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:11.8518 | MainLoss:0.6116 | SPLoss:112.3612 | CLSLoss:0.4075 | top1:72.5786 | AUROC:0.8147\n",
      "Test | 161/10 | Loss:12.2160 | MainLoss:0.9758 | SPLoss:112.3612 | CLSLoss:0.4075 | top1:61.2586 | AUROC:0.8607\n",
      "\n",
      "Epoch: [186 | 1000] LR: 0.037086\n",
      "Train | 10/10 | Loss:11.1726 | MainLoss:0.3327 | SPLoss:108.3582 | CLSLoss:0.4076 | top1:85.5500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:10.9457 | MainLoss:0.5827 | SPLoss:103.5892 | CLSLoss:0.4106 | top1:74.0695 | AUROC:0.8195\n",
      "Test | 161/10 | Loss:11.2589 | MainLoss:0.8959 | SPLoss:103.5891 | CLSLoss:0.4106 | top1:64.8660 | AUROC:0.8579\n",
      "\n",
      "Epoch: [187 | 1000] LR: 0.037053\n",
      "Train | 10/10 | Loss:10.3399 | MainLoss:0.3446 | SPLoss:99.9122 | CLSLoss:0.4056 | top1:84.7500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:10.1308 | MainLoss:0.5743 | SPLoss:95.5246 | CLSLoss:0.4079 | top1:74.0629 | AUROC:0.8223\n",
      "Test | 161/10 | Loss:10.3915 | MainLoss:0.8350 | SPLoss:95.5246 | CLSLoss:0.4079 | top1:66.1308 | AUROC:0.8579\n",
      "\n",
      "Epoch: [188 | 1000] LR: 0.037020\n",
      "Train | 10/10 | Loss:9.5662 | MainLoss:0.3477 | SPLoss:92.1440 | CLSLoss:0.4067 | top1:84.5500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:9.3813 | MainLoss:0.5655 | SPLoss:88.1171 | CLSLoss:0.4030 | top1:74.5249 | AUROC:0.8243\n",
      "Test | 161/10 | Loss:9.7616 | MainLoss:0.9458 | SPLoss:88.1171 | CLSLoss:0.4030 | top1:62.5732 | AUROC:0.8482\n",
      "\n",
      "Epoch: [189 | 1000] LR: 0.036987\n",
      "Train | 10/10 | Loss:8.8997 | MainLoss:0.3936 | SPLoss:85.0207 | CLSLoss:0.4021 | top1:82.6000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:8.7336 | MainLoss:0.5822 | SPLoss:81.4763 | CLSLoss:0.3827 | top1:70.1737 | AUROC:0.7732\n",
      "Test | 161/10 | Loss:8.9821 | MainLoss:0.8306 | SPLoss:81.4763 | CLSLoss:0.3827 | top1:60.6324 | AUROC:0.8022\n",
      "\n",
      "Epoch: [190 | 1000] LR: 0.036954\n",
      "Train | 10/10 | Loss:8.2481 | MainLoss:0.3837 | SPLoss:78.6051 | CLSLoss:0.3905 | top1:83.0500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:8.1351 | MainLoss:0.6131 | SPLoss:75.1812 | CLSLoss:0.3914 | top1:71.3532 | AUROC:0.8019\n",
      "Test | 161/10 | Loss:8.5581 | MainLoss:1.0360 | SPLoss:75.1812 | CLSLoss:0.3914 | top1:58.3053 | AUROC:0.7366\n",
      "\n",
      "Epoch: [191 | 1000] LR: 0.036920\n",
      "Train | 10/10 | Loss:7.6294 | MainLoss:0.3724 | SPLoss:72.5307 | CLSLoss:0.3953 | top1:83.6500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:7.5106 | MainLoss:0.5664 | SPLoss:69.4025 | CLSLoss:0.3844 | top1:72.1298 | AUROC:0.8023\n",
      "Test | 161/10 | Loss:7.7862 | MainLoss:0.8421 | SPLoss:69.4025 | CLSLoss:0.3844 | top1:61.3458 | AUROC:0.7456\n",
      "\n",
      "Epoch: [192 | 1000] LR: 0.036887\n",
      "Train | 10/10 | Loss:7.0292 | MainLoss:0.3257 | SPLoss:66.9952 | CLSLoss:0.3918 | top1:85.7000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:6.9990 | MainLoss:0.5830 | SPLoss:64.1206 | CLSLoss:0.3990 | top1:73.7779 | AUROC:0.8161\n",
      "Test | 161/10 | Loss:7.3896 | MainLoss:0.9736 | SPLoss:64.1206 | CLSLoss:0.3990 | top1:61.3614 | AUROC:0.7746\n",
      "\n",
      "Epoch: [193 | 1000] LR: 0.036853\n",
      "Train | 10/10 | Loss:6.4973 | MainLoss:0.3059 | SPLoss:61.8739 | CLSLoss:0.4037 | top1:87.2000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:6.7880 | MainLoss:0.6508 | SPLoss:61.3319 | CLSLoss:0.4048 | top1:72.2281 | AUROC:0.8183\n",
      "Test | 161/10 | Loss:6.9468 | MainLoss:0.8096 | SPLoss:61.3319 | CLSLoss:0.4048 | top1:66.2181 | AUROC:0.8170\n",
      "\n",
      "Epoch: [194 | 1000] LR: 0.036819\n",
      "Train | 10/10 | Loss:6.3525 | MainLoss:0.3771 | SPLoss:59.7140 | CLSLoss:0.3970 | top1:83.0000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:6.2992 | MainLoss:0.5749 | SPLoss:57.2023 | CLSLoss:0.4005 | top1:74.2726 | AUROC:0.8241\n",
      "Test | 161/10 | Loss:6.6433 | MainLoss:0.9190 | SPLoss:57.2023 | CLSLoss:0.4005 | top1:62.2617 | AUROC:0.7868\n",
      "\n",
      "Epoch: [195 | 1000] LR: 0.036785\n",
      "Train | 10/10 | Loss:5.8610 | MainLoss:0.3373 | SPLoss:55.1968 | CLSLoss:0.4037 | top1:85.1500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:5.9701 | MainLoss:0.6848 | SPLoss:52.8131 | CLSLoss:0.3971 | top1:69.3906 | AUROC:0.8154\n",
      "Test | 161/10 | Loss:6.0804 | MainLoss:0.7951 | SPLoss:52.8131 | CLSLoss:0.3971 | top1:64.0405 | AUROC:0.7773\n",
      "\n",
      "Epoch: [196 | 1000] LR: 0.036751\n",
      "Train | 10/10 | Loss:5.4186 | MainLoss:0.3157 | SPLoss:50.9884 | CLSLoss:0.4005 | top1:86.5000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:5.4994 | MainLoss:0.6141 | SPLoss:48.8127 | CLSLoss:0.4049 | top1:72.8211 | AUROC:0.8251\n",
      "Test | 161/10 | Loss:5.7390 | MainLoss:0.8537 | SPLoss:48.8127 | CLSLoss:0.4049 | top1:64.2555 | AUROC:0.8034\n",
      "\n",
      "Epoch: [197 | 1000] LR: 0.036716\n",
      "Train | 10/10 | Loss:5.0336 | MainLoss:0.3163 | SPLoss:47.1319 | CLSLoss:0.4064 | top1:86.5000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:5.1128 | MainLoss:0.5961 | SPLoss:45.1256 | CLSLoss:0.4095 | top1:74.0105 | AUROC:0.8227\n",
      "Test | 161/10 | Loss:5.4707 | MainLoss:0.9541 | SPLoss:45.1256 | CLSLoss:0.4095 | top1:61.9502 | AUROC:0.7805\n",
      "\n",
      "Epoch: [198 | 1000] LR: 0.036682\n",
      "Train | 10/10 | Loss:4.7390 | MainLoss:0.3774 | SPLoss:43.5763 | CLSLoss:0.4029 | top1:82.8500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:4.7334 | MainLoss:0.5579 | SPLoss:41.7147 | CLSLoss:0.3984 | top1:73.7516 | AUROC:0.8183\n",
      "Test | 161/10 | Loss:5.0495 | MainLoss:0.8740 | SPLoss:41.7148 | CLSLoss:0.3984 | top1:62.4798 | AUROC:0.7853\n",
      "\n",
      "Epoch: [199 | 1000] LR: 0.036647\n",
      "Train | 10/10 | Loss:4.3537 | MainLoss:0.3206 | SPLoss:40.2906 | CLSLoss:0.4036 | top1:86.5000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:4.4432 | MainLoss:0.5803 | SPLoss:38.5883 | CLSLoss:0.4033 | top1:73.5256 | AUROC:0.8180\n",
      "Test | 161/10 | Loss:4.7421 | MainLoss:0.8792 | SPLoss:38.5883 | CLSLoss:0.4033 | top1:63.3271 | AUROC:0.7934\n",
      "\n",
      "Epoch: [200 | 1000] LR: 0.036612\n",
      "Train | 10/10 | Loss:4.0634 | MainLoss:0.3318 | SPLoss:37.2748 | CLSLoss:0.4045 | top1:85.2000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:4.2393 | MainLoss:0.6645 | SPLoss:35.7076 | CLSLoss:0.4066 | top1:70.7339 | AUROC:0.8080\n",
      "Test | 161/10 | Loss:4.3950 | MainLoss:0.8202 | SPLoss:35.7076 | CLSLoss:0.4066 | top1:64.8006 | AUROC:0.7879\n",
      "\n",
      "Epoch: [201 | 1000] LR: 0.036577\n",
      "Train | 10/10 | Loss:3.8042 | MainLoss:0.3497 | SPLoss:34.5046 | CLSLoss:0.4044 | top1:84.7500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:3.8843 | MainLoss:0.5731 | SPLoss:33.0721 | CLSLoss:0.4016 | top1:73.4633 | AUROC:0.8231\n",
      "Test | 161/10 | Loss:4.0695 | MainLoss:0.7583 | SPLoss:33.0721 | CLSLoss:0.4016 | top1:66.8006 | AUROC:0.8379\n",
      "\n",
      "Epoch: [202 | 1000] LR: 0.036542\n",
      "Train | 10/10 | Loss:3.4809 | MainLoss:0.2831 | SPLoss:31.9370 | CLSLoss:0.4096 | top1:88.5000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:3.6569 | MainLoss:0.5933 | SPLoss:30.5947 | CLSLoss:0.4137 | top1:74.0203 | AUROC:0.8175\n",
      "Test | 161/10 | Loss:4.0320 | MainLoss:0.9684 | SPLoss:30.5947 | CLSLoss:0.4137 | top1:62.2648 | AUROC:0.8082\n",
      "\n",
      "Epoch: [203 | 1000] LR: 0.036506\n",
      "Train | 10/10 | Loss:3.2881 | MainLoss:0.3258 | SPLoss:29.5818 | CLSLoss:0.4102 | top1:86.3000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:3.4281 | MainLoss:0.5878 | SPLoss:28.3616 | CLSLoss:0.4139 | top1:74.2792 | AUROC:0.8241\n",
      "Test | 161/10 | Loss:3.8124 | MainLoss:0.9721 | SPLoss:28.3616 | CLSLoss:0.4139 | top1:62.2928 | AUROC:0.7667\n",
      "\n",
      "Epoch: [204 | 1000] LR: 0.036471\n",
      "Train | 10/10 | Loss:3.0197 | MainLoss:0.2728 | SPLoss:27.4273 | CLSLoss:0.4181 | top1:88.5000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:3.3108 | MainLoss:0.6754 | SPLoss:26.3110 | CLSLoss:0.4243 | top1:72.7752 | AUROC:0.8241\n",
      "Test | 161/10 | Loss:3.9709 | MainLoss:1.3355 | SPLoss:26.3110 | CLSLoss:0.4243 | top1:56.4143 | AUROC:0.7397\n",
      "\n",
      "Epoch: [205 | 1000] LR: 0.036435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 10/10 | Loss:2.8778 | MainLoss:0.3271 | SPLoss:25.4657 | CLSLoss:0.4173 | top1:86.1000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:3.0366 | MainLoss:0.5899 | SPLoss:24.4253 | CLSLoss:0.4191 | top1:74.4921 | AUROC:0.8254\n",
      "Test | 161/10 | Loss:3.5993 | MainLoss:1.1526 | SPLoss:24.4253 | CLSLoss:0.4191 | top1:58.7165 | AUROC:0.7729\n",
      "\n",
      "Epoch: [206 | 1000] LR: 0.036399\n",
      "Train | 10/10 | Loss:2.8038 | MainLoss:0.3726 | SPLoss:24.2715 | CLSLoss:0.4140 | top1:83.4000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:2.9310 | MainLoss:0.5343 | SPLoss:23.9266 | CLSLoss:0.4007 | top1:74.0039 | AUROC:0.8200\n",
      "Test | 161/10 | Loss:3.3215 | MainLoss:0.9249 | SPLoss:23.9266 | CLSLoss:0.4007 | top1:59.1776 | AUROC:0.7404\n",
      "\n",
      "Epoch: [207 | 1000] LR: 0.036363\n",
      "Train | 10/10 | Loss:2.5798 | MainLoss:0.2636 | SPLoss:23.1207 | CLSLoss:0.4136 | top1:90.2000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:2.8215 | MainLoss:0.5994 | SPLoss:22.1791 | CLSLoss:0.4219 | top1:74.8231 | AUROC:0.8268\n",
      "Test | 161/10 | Loss:3.3793 | MainLoss:1.1572 | SPLoss:22.1791 | CLSLoss:0.4219 | top1:58.8910 | AUROC:0.7216\n",
      "\n",
      "Epoch: [208 | 1000] LR: 0.036327\n",
      "Train | 10/10 | Loss:2.4971 | MainLoss:0.3450 | SPLoss:21.4793 | CLSLoss:0.4147 | top1:85.6000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:2.7425 | MainLoss:0.6741 | SPLoss:20.6431 | CLSLoss:0.4071 | top1:70.7634 | AUROC:0.8212\n",
      "Test | 161/10 | Loss:2.9144 | MainLoss:0.8460 | SPLoss:20.6431 | CLSLoss:0.4071 | top1:63.7819 | AUROC:0.7368\n",
      "\n",
      "Epoch: [209 | 1000] LR: 0.036290\n",
      "Train | 10/10 | Loss:2.2861 | MainLoss:0.2817 | SPLoss:20.0019 | CLSLoss:0.4130 | top1:88.7500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:2.6607 | MainLoss:0.7344 | SPLoss:19.2213 | CLSLoss:0.4163 | top1:69.5773 | AUROC:0.8152\n",
      "Test | 161/10 | Loss:2.7483 | MainLoss:0.8220 | SPLoss:19.2213 | CLSLoss:0.4163 | top1:66.0623 | AUROC:0.7611\n",
      "\n",
      "Epoch: [210 | 1000] LR: 0.036254\n",
      "Train | 10/10 | Loss:2.1734 | MainLoss:0.3087 | SPLoss:18.6047 | CLSLoss:0.4143 | top1:86.6000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:2.5150 | MainLoss:0.7242 | SPLoss:17.8662 | CLSLoss:0.4171 | top1:69.7182 | AUROC:0.8075\n",
      "Test | 161/10 | Loss:2.6184 | MainLoss:0.8276 | SPLoss:17.8662 | CLSLoss:0.4171 | top1:66.4361 | AUROC:0.7917\n",
      "\n",
      "Epoch: [211 | 1000] LR: 0.036217\n",
      "Train | 10/10 | Loss:2.0932 | MainLoss:0.3497 | SPLoss:17.3930 | CLSLoss:0.4163 | top1:85.0500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:2.3972 | MainLoss:0.6869 | SPLoss:17.0631 | CLSLoss:0.3985 | top1:66.9037 | AUROC:0.7850\n",
      "Test | 161/10 | Loss:2.3655 | MainLoss:0.6552 | SPLoss:17.0631 | CLSLoss:0.3985 | top1:68.4548 | AUROC:0.7813\n",
      "\n",
      "Epoch: [212 | 1000] LR: 0.036180\n",
      "Train | 10/10 | Loss:2.0231 | MainLoss:0.3670 | SPLoss:16.5219 | CLSLoss:0.3997 | top1:83.5500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:2.1811 | MainLoss:0.5899 | SPLoss:15.8722 | CLSLoss:0.4040 | top1:72.9423 | AUROC:0.8075\n",
      "Test | 161/10 | Loss:2.5377 | MainLoss:0.9465 | SPLoss:15.8722 | CLSLoss:0.4040 | top1:62.0966 | AUROC:0.7597\n",
      "\n",
      "Epoch: [213 | 1000] LR: 0.036143\n",
      "Train | 10/10 | Loss:1.8976 | MainLoss:0.3553 | SPLoss:15.3825 | CLSLoss:0.4037 | top1:83.7500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:2.0784 | MainLoss:0.5943 | SPLoss:14.8003 | CLSLoss:0.4042 | top1:73.0996 | AUROC:0.8157\n",
      "Test | 161/10 | Loss:2.5909 | MainLoss:1.1069 | SPLoss:14.8003 | CLSLoss:0.4042 | top1:58.8380 | AUROC:0.7691\n",
      "\n",
      "Epoch: [214 | 1000] LR: 0.036106\n",
      "Train | 10/10 | Loss:1.7745 | MainLoss:0.3361 | SPLoss:14.3430 | CLSLoss:0.4067 | top1:84.9500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.9888 | MainLoss:0.6054 | SPLoss:13.7931 | CLSLoss:0.4078 | top1:73.3454 | AUROC:0.8192\n",
      "Test | 161/10 | Loss:2.5668 | MainLoss:1.1834 | SPLoss:13.7931 | CLSLoss:0.4078 | top1:58.0062 | AUROC:0.7571\n",
      "\n",
      "Epoch: [215 | 1000] LR: 0.036069\n",
      "Train | 10/10 | Loss:1.6950 | MainLoss:0.3318 | SPLoss:13.5911 | CLSLoss:0.4085 | top1:85.8000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.9244 | MainLoss:0.5773 | SPLoss:13.4308 | CLSLoss:0.4083 | top1:73.9777 | AUROC:0.8211\n",
      "Test | 161/10 | Loss:2.4484 | MainLoss:1.1013 | SPLoss:13.4308 | CLSLoss:0.4083 | top1:59.0156 | AUROC:0.7806\n",
      "\n",
      "Epoch: [216 | 1000] LR: 0.036031\n",
      "Train | 10/10 | Loss:1.7186 | MainLoss:0.4061 | SPLoss:13.0845 | CLSLoss:0.4089 | top1:81.7000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:2.1489 | MainLoss:0.6751 | SPLoss:14.7002 | CLSLoss:0.3812 | top1:64.3807 | AUROC:0.7869\n",
      "Test | 161/10 | Loss:2.0223 | MainLoss:0.5484 | SPLoss:14.7002 | CLSLoss:0.3812 | top1:72.2025 | AUROC:0.8316\n",
      "\n",
      "Epoch: [217 | 1000] LR: 0.035994\n",
      "Train | 10/10 | Loss:1.8480 | MainLoss:0.3918 | SPLoss:14.5233 | CLSLoss:0.3863 | top1:81.6500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.9651 | MainLoss:0.5624 | SPLoss:13.9867 | CLSLoss:0.3978 | top1:73.8467 | AUROC:0.8179\n",
      "Test | 161/10 | Loss:2.2796 | MainLoss:0.8769 | SPLoss:13.9867 | CLSLoss:0.3978 | top1:63.3551 | AUROC:0.8078\n",
      "\n",
      "Epoch: [218 | 1000] LR: 0.035956\n",
      "Train | 10/10 | Loss:1.7076 | MainLoss:0.3485 | SPLoss:13.5502 | CLSLoss:0.4015 | top1:85.3500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.9826 | MainLoss:0.6737 | SPLoss:13.0498 | CLSLoss:0.3945 | top1:69.3971 | AUROC:0.8027\n",
      "Test | 161/10 | Loss:2.0555 | MainLoss:0.7466 | SPLoss:13.0498 | CLSLoss:0.3945 | top1:66.1838 | AUROC:0.7879\n",
      "\n",
      "Epoch: [219 | 1000] LR: 0.035918\n",
      "Train | 10/10 | Loss:1.5961 | MainLoss:0.3269 | SPLoss:12.6523 | CLSLoss:0.3988 | top1:86.1000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.7892 | MainLoss:0.5669 | SPLoss:12.1827 | CLSLoss:0.3994 | top1:73.9417 | AUROC:0.8228\n",
      "Test | 161/10 | Loss:2.2553 | MainLoss:1.0331 | SPLoss:12.1827 | CLSLoss:0.3994 | top1:60.4517 | AUROC:0.7688\n",
      "\n",
      "Epoch: [220 | 1000] LR: 0.035880\n",
      "Train | 10/10 | Loss:1.5221 | MainLoss:0.3358 | SPLoss:11.8235 | CLSLoss:0.4025 | top1:85.7000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.7013 | MainLoss:0.5568 | SPLoss:11.4053 | CLSLoss:0.3956 | top1:73.6271 | AUROC:0.8169\n",
      "Test | 161/10 | Loss:2.0056 | MainLoss:0.8612 | SPLoss:11.4053 | CLSLoss:0.3956 | top1:63.3365 | AUROC:0.7752\n",
      "\n",
      "Epoch: [221 | 1000] LR: 0.035842\n",
      "Train | 10/10 | Loss:1.4071 | MainLoss:0.2974 | SPLoss:11.0568 | CLSLoss:0.4048 | top1:88.1500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.7942 | MainLoss:0.7244 | SPLoss:10.6572 | CLSLoss:0.4098 | top1:69.9509 | AUROC:0.8210\n",
      "Test | 161/10 | Loss:1.8734 | MainLoss:0.8035 | SPLoss:10.6572 | CLSLoss:0.4098 | top1:66.6168 | AUROC:0.7862\n",
      "\n",
      "Epoch: [222 | 1000] LR: 0.035803\n",
      "Train | 10/10 | Loss:1.3818 | MainLoss:0.3416 | SPLoss:10.3608 | CLSLoss:0.4056 | top1:85.3000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.6042 | MainLoss:0.6018 | SPLoss:9.9827 | CLSLoss:0.4058 | top1:72.9915 | AUROC:0.8270\n",
      "Test | 161/10 | Loss:2.1536 | MainLoss:1.1513 | SPLoss:9.9827 | CLSLoss:0.4058 | top1:57.7227 | AUROC:0.7503\n",
      "\n",
      "Epoch: [223 | 1000] LR: 0.035765\n",
      "Train | 10/10 | Loss:1.2851 | MainLoss:0.3110 | SPLoss:9.7005 | CLSLoss:0.4091 | top1:86.6500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.5089 | MainLoss:0.5685 | SPLoss:9.3629 | CLSLoss:0.4096 | top1:74.8755 | AUROC:0.8317\n",
      "Test | 161/10 | Loss:1.9926 | MainLoss:1.0522 | SPLoss:9.3629 | CLSLoss:0.4096 | top1:60.8349 | AUROC:0.7650\n",
      "\n",
      "Epoch: [224 | 1000] LR: 0.035726\n",
      "Train | 10/10 | Loss:1.2725 | MainLoss:0.3567 | SPLoss:9.1167 | CLSLoss:0.4031 | top1:83.9000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.4517 | MainLoss:0.5683 | SPLoss:8.7931 | CLSLoss:0.4076 | top1:74.4037 | AUROC:0.8267\n",
      "Test | 161/10 | Loss:1.9177 | MainLoss:1.0343 | SPLoss:8.7931 | CLSLoss:0.4076 | top1:60.6106 | AUROC:0.7878\n",
      "\n",
      "Epoch: [225 | 1000] LR: 0.035687\n",
      "Train | 10/10 | Loss:1.1274 | MainLoss:0.2680 | SPLoss:8.5524 | CLSLoss:0.4135 | top1:89.1000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.4206 | MainLoss:0.5902 | SPLoss:8.2628 | CLSLoss:0.4180 | top1:74.5249 | AUROC:0.8232\n",
      "Test | 161/10 | Loss:1.9486 | MainLoss:1.1181 | SPLoss:8.2628 | CLSLoss:0.4180 | top1:59.9034 | AUROC:0.7437\n",
      "\n",
      "Epoch: [226 | 1000] LR: 0.035648\n",
      "Train | 10/10 | Loss:1.1594 | MainLoss:0.3508 | SPLoss:8.0443 | CLSLoss:0.4193 | top1:84.8500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.4465 | MainLoss:0.6589 | SPLoss:7.8370 | CLSLoss:0.3932 | top1:68.1848 | AUROC:0.8069\n",
      "Test | 161/10 | Loss:1.8692 | MainLoss:1.0816 | SPLoss:7.8370 | CLSLoss:0.3932 | top1:55.6012 | AUROC:0.6921\n",
      "\n",
      "Epoch: [227 | 1000] LR: 0.035609\n",
      "Train | 10/10 | Loss:1.0659 | MainLoss:0.3009 | SPLoss:7.6095 | CLSLoss:0.4031 | top1:88.0500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.3143 | MainLoss:0.5764 | SPLoss:7.3373 | CLSLoss:0.4129 | top1:74.9771 | AUROC:0.8312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 161/10 | Loss:1.8624 | MainLoss:1.1246 | SPLoss:7.3373 | CLSLoss:0.4129 | top1:60.2679 | AUROC:0.7267\n",
      "\n",
      "Epoch: [228 | 1000] LR: 0.035569\n",
      "Train | 10/10 | Loss:0.9898 | MainLoss:0.2713 | SPLoss:7.1434 | CLSLoss:0.4193 | top1:88.9500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.4002 | MainLoss:0.7033 | SPLoss:6.9266 | CLSLoss:0.4173 | top1:70.8421 | AUROC:0.8212\n",
      "Test | 161/10 | Loss:1.5735 | MainLoss:0.8766 | SPLoss:6.9266 | CLSLoss:0.4173 | top1:65.5950 | AUROC:0.7529\n",
      "\n",
      "Epoch: [229 | 1000] LR: 0.035530\n",
      "Train | 10/10 | Loss:0.9937 | MainLoss:0.3136 | SPLoss:6.7593 | CLSLoss:0.4137 | top1:87.3500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.2352 | MainLoss:0.5759 | SPLoss:6.5517 | CLSLoss:0.4167 | top1:74.6429 | AUROC:0.8299\n",
      "Test | 161/10 | Loss:1.6212 | MainLoss:0.9618 | SPLoss:6.5517 | CLSLoss:0.4167 | top1:63.4299 | AUROC:0.7591\n",
      "\n",
      "Epoch: [230 | 1000] LR: 0.035490\n",
      "Train | 10/10 | Loss:0.9350 | MainLoss:0.2916 | SPLoss:6.3922 | CLSLoss:0.4161 | top1:87.5000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.2300 | MainLoss:0.6074 | SPLoss:6.1837 | CLSLoss:0.4217 | top1:74.3676 | AUROC:0.8250\n",
      "Test | 161/10 | Loss:1.7815 | MainLoss:1.1590 | SPLoss:6.1837 | CLSLoss:0.4217 | top1:60.8660 | AUROC:0.7475\n",
      "\n",
      "Epoch: [231 | 1000] LR: 0.035450\n",
      "Train | 10/10 | Loss:0.9143 | MainLoss:0.3002 | SPLoss:6.0990 | CLSLoss:0.4199 | top1:87.4000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.2010 | MainLoss:0.5882 | SPLoss:6.0856 | CLSLoss:0.4194 | top1:74.4561 | AUROC:0.8232\n",
      "Test | 161/10 | Loss:1.6370 | MainLoss:1.0242 | SPLoss:6.0856 | CLSLoss:0.4194 | top1:62.4891 | AUROC:0.7619\n",
      "\n",
      "Epoch: [232 | 1000] LR: 0.035410\n",
      "Train | 10/10 | Loss:0.9391 | MainLoss:0.3395 | SPLoss:5.9541 | CLSLoss:0.4118 | top1:86.1000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.1727 | MainLoss:0.5912 | SPLoss:5.7740 | CLSLoss:0.4137 | top1:73.9777 | AUROC:0.8220\n",
      "Test | 161/10 | Loss:1.5547 | MainLoss:0.9731 | SPLoss:5.7740 | CLSLoss:0.4137 | top1:63.6636 | AUROC:0.7800\n",
      "\n",
      "Epoch: [233 | 1000] LR: 0.035370\n",
      "Train | 10/10 | Loss:0.8280 | MainLoss:0.2604 | SPLoss:5.6340 | CLSLoss:0.4216 | top1:89.9000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.3822 | MainLoss:0.8300 | SPLoss:5.4803 | CLSLoss:0.4198 | top1:67.9620 | AUROC:0.8070\n",
      "Test | 161/10 | Loss:1.9396 | MainLoss:1.3874 | SPLoss:5.4803 | CLSLoss:0.4198 | top1:56.8505 | AUROC:0.7451\n",
      "\n",
      "Epoch: [234 | 1000] LR: 0.035330\n",
      "Train | 10/10 | Loss:0.8401 | MainLoss:0.2986 | SPLoss:5.3739 | CLSLoss:0.4165 | top1:87.6000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.2115 | MainLoss:0.6844 | SPLoss:5.2291 | CLSLoss:0.4213 | top1:73.1553 | AUROC:0.8333\n",
      "Test | 161/10 | Loss:1.7977 | MainLoss:1.2705 | SPLoss:5.2291 | CLSLoss:0.4213 | top1:59.2617 | AUROC:0.7679\n",
      "\n",
      "Epoch: [235 | 1000] LR: 0.035289\n",
      "Train | 10/10 | Loss:1.0311 | MainLoss:0.3507 | SPLoss:6.7623 | CLSLoss:0.4157 | top1:85.6000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.2700 | MainLoss:0.5687 | SPLoss:6.9721 | CLSLoss:0.4027 | top1:73.7418 | AUROC:0.8207\n",
      "Test | 161/10 | Loss:1.7185 | MainLoss:1.0172 | SPLoss:6.9721 | CLSLoss:0.4027 | top1:59.9315 | AUROC:0.7583\n",
      "\n",
      "Epoch: [236 | 1000] LR: 0.035249\n",
      "Train | 10/10 | Loss:0.9812 | MainLoss:0.2941 | SPLoss:6.8295 | CLSLoss:0.4110 | top1:89.0500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.3406 | MainLoss:0.6548 | SPLoss:6.8179 | CLSLoss:0.4076 | top1:72.1298 | AUROC:0.8263\n",
      "Test | 161/10 | Loss:1.8794 | MainLoss:1.1936 | SPLoss:6.8179 | CLSLoss:0.4076 | top1:58.3894 | AUROC:0.7482\n",
      "\n",
      "Epoch: [237 | 1000] LR: 0.035208\n",
      "Train | 10/10 | Loss:0.9683 | MainLoss:0.2975 | SPLoss:6.6671 | CLSLoss:0.4077 | top1:87.7500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.2976 | MainLoss:0.5973 | SPLoss:6.9624 | CLSLoss:0.4112 | top1:74.1776 | AUROC:0.8279\n",
      "Test | 161/10 | Loss:1.6714 | MainLoss:0.9710 | SPLoss:6.9624 | CLSLoss:0.4112 | top1:62.8287 | AUROC:0.7385\n",
      "\n",
      "Epoch: [238 | 1000] LR: 0.035167\n",
      "Train | 10/10 | Loss:1.0471 | MainLoss:0.3534 | SPLoss:6.8970 | CLSLoss:0.4056 | top1:84.4000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.2784 | MainLoss:0.6043 | SPLoss:6.7009 | CLSLoss:0.4004 | top1:71.9528 | AUROC:0.8223\n",
      "Test | 161/10 | Loss:1.5062 | MainLoss:0.8322 | SPLoss:6.7009 | CLSLoss:0.4004 | top1:64.0093 | AUROC:0.7393\n",
      "\n",
      "Epoch: [239 | 1000] LR: 0.035126\n",
      "Train | 10/10 | Loss:0.9693 | MainLoss:0.3113 | SPLoss:6.5394 | CLSLoss:0.4054 | top1:86.9000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.2008 | MainLoss:0.5609 | SPLoss:6.3585 | CLSLoss:0.4054 | top1:74.5773 | AUROC:0.8291\n",
      "Test | 161/10 | Loss:1.6423 | MainLoss:1.0024 | SPLoss:6.3585 | CLSLoss:0.4054 | top1:60.4486 | AUROC:0.6982\n",
      "\n",
      "Epoch: [240 | 1000] LR: 0.035085\n",
      "Train | 10/10 | Loss:0.8666 | MainLoss:0.2428 | SPLoss:6.1961 | CLSLoss:0.4144 | top1:90.3000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.2810 | MainLoss:0.6758 | SPLoss:6.0100 | CLSLoss:0.4236 | top1:72.4869 | AUROC:0.8295\n",
      "Test | 161/10 | Loss:1.9221 | MainLoss:1.3168 | SPLoss:6.0100 | CLSLoss:0.4236 | top1:58.0093 | AUROC:0.7254\n",
      "\n",
      "Epoch: [241 | 1000] LR: 0.035044\n",
      "Train | 10/10 | Loss:0.9001 | MainLoss:0.3093 | SPLoss:5.8660 | CLSLoss:0.4218 | top1:87.3500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.1494 | MainLoss:0.5753 | SPLoss:5.6995 | CLSLoss:0.4145 | top1:74.5151 | AUROC:0.8272\n",
      "Test | 161/10 | Loss:1.5597 | MainLoss:0.9856 | SPLoss:5.6995 | CLSLoss:0.4145 | top1:63.0779 | AUROC:0.7713\n",
      "\n",
      "Epoch: [242 | 1000] LR: 0.035002\n",
      "Train | 10/10 | Loss:0.8602 | MainLoss:0.2957 | SPLoss:5.6036 | CLSLoss:0.4160 | top1:87.5500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.1407 | MainLoss:0.5873 | SPLoss:5.4922 | CLSLoss:0.4173 | top1:74.3545 | AUROC:0.8266\n",
      "Test | 161/10 | Loss:1.6704 | MainLoss:1.1170 | SPLoss:5.4922 | CLSLoss:0.4173 | top1:60.3146 | AUROC:0.7213\n",
      "\n",
      "Epoch: [243 | 1000] LR: 0.034961\n",
      "Train | 10/10 | Loss:0.8233 | MainLoss:0.2824 | SPLoss:5.3671 | CLSLoss:0.4201 | top1:88.5000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.1261 | MainLoss:0.5994 | SPLoss:5.2255 | CLSLoss:0.4158 | top1:73.4338 | AUROC:0.8191\n",
      "Test | 161/10 | Loss:1.6623 | MainLoss:1.1356 | SPLoss:5.2255 | CLSLoss:0.4158 | top1:59.7041 | AUROC:0.7318\n",
      "\n",
      "Epoch: [244 | 1000] LR: 0.034919\n",
      "Train | 10/10 | Loss:0.8276 | MainLoss:0.3111 | SPLoss:5.1231 | CLSLoss:0.4159 | top1:87.2000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.0914 | MainLoss:0.5869 | SPLoss:5.0029 | CLSLoss:0.4122 | top1:74.3414 | AUROC:0.8299\n",
      "Test | 161/10 | Loss:1.4519 | MainLoss:0.9475 | SPLoss:5.0029 | CLSLoss:0.4122 | top1:63.1776 | AUROC:0.7455\n",
      "\n",
      "Epoch: [245 | 1000] LR: 0.034877\n",
      "Train | 10/10 | Loss:0.7498 | MainLoss:0.2571 | SPLoss:4.8855 | CLSLoss:0.4199 | top1:89.2000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.3822 | MainLoss:0.9026 | SPLoss:4.7542 | CLSLoss:0.4198 | top1:65.6488 | AUROC:0.8147\n",
      "Test | 161/10 | Loss:2.0392 | MainLoss:1.5596 | SPLoss:4.7542 | CLSLoss:0.4198 | top1:54.1963 | AUROC:0.6978\n",
      "\n",
      "Epoch: [246 | 1000] LR: 0.034835\n",
      "Train | 10/10 | Loss:0.7844 | MainLoss:0.3105 | SPLoss:4.6975 | CLSLoss:0.4126 | top1:87.7000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.0585 | MainLoss:0.5968 | SPLoss:4.5750 | CLSLoss:0.4200 | top1:74.8788 | AUROC:0.8292\n",
      "Test | 161/10 | Loss:1.5590 | MainLoss:1.0973 | SPLoss:4.5750 | CLSLoss:0.4200 | top1:61.1215 | AUROC:0.7253\n",
      "\n",
      "Epoch: [247 | 1000] LR: 0.034793\n",
      "Train | 10/10 | Loss:0.6896 | MainLoss:0.2383 | SPLoss:4.4707 | CLSLoss:0.4227 | top1:90.5500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.0765 | MainLoss:0.6362 | SPLoss:4.3596 | CLSLoss:0.4279 | top1:73.9646 | AUROC:0.8225\n",
      "Test | 161/10 | Loss:1.5029 | MainLoss:1.0627 | SPLoss:4.3596 | CLSLoss:0.4279 | top1:62.3863 | AUROC:0.7192\n",
      "\n",
      "Epoch: [248 | 1000] LR: 0.034750\n",
      "Train | 10/10 | Loss:0.7571 | MainLoss:0.3237 | SPLoss:4.2910 | CLSLoss:0.4220 | top1:86.8500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9928 | MainLoss:0.5683 | SPLoss:4.2032 | CLSLoss:0.4154 | top1:74.8100 | AUROC:0.8279\n",
      "Test | 161/10 | Loss:1.4578 | MainLoss:1.0333 | SPLoss:4.2032 | CLSLoss:0.4154 | top1:61.0187 | AUROC:0.6949\n",
      "\n",
      "Epoch: [249 | 1000] LR: 0.034708\n",
      "Train | 10/10 | Loss:0.6985 | MainLoss:0.2706 | SPLoss:4.2376 | CLSLoss:0.4197 | top1:89.0500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.0393 | MainLoss:0.6082 | SPLoss:4.2689 | CLSLoss:0.4227 | top1:74.2988 | AUROC:0.8224\n",
      "Test | 161/10 | Loss:1.6498 | MainLoss:1.2187 | SPLoss:4.2689 | CLSLoss:0.4227 | top1:57.8816 | AUROC:0.6273\n",
      "\n",
      "Epoch: [250 | 1000] LR: 0.034665\n",
      "Train | 10/10 | Loss:0.7519 | MainLoss:0.3228 | SPLoss:4.2495 | CLSLoss:0.4158 | top1:86.7500 | AUROC:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 153/10 | Loss:1.0140 | MainLoss:0.5941 | SPLoss:4.1575 | CLSLoss:0.4153 | top1:74.6199 | AUROC:0.8268\n",
      "Test | 161/10 | Loss:1.5527 | MainLoss:1.1328 | SPLoss:4.1575 | CLSLoss:0.4153 | top1:58.6324 | AUROC:0.6500\n",
      "\n",
      "Epoch: [251 | 1000] LR: 0.034622\n",
      "Train | 10/10 | Loss:0.6591 | MainLoss:0.2471 | SPLoss:4.0779 | CLSLoss:0.4198 | top1:90.4500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.0313 | MainLoss:0.6285 | SPLoss:3.9856 | CLSLoss:0.4231 | top1:74.2890 | AUROC:0.8258\n",
      "Test | 161/10 | Loss:1.4803 | MainLoss:1.0775 | SPLoss:3.9856 | CLSLoss:0.4231 | top1:61.0810 | AUROC:0.6963\n",
      "\n",
      "Epoch: [252 | 1000] LR: 0.003458\n",
      "Train | 10/10 | Loss:0.6188 | MainLoss:0.2171 | SPLoss:3.9750 | CLSLoss:0.4235 | top1:91.4000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.0111 | MainLoss:0.6106 | SPLoss:3.9630 | CLSLoss:0.4243 | top1:74.7805 | AUROC:0.8273\n",
      "Test | 161/10 | Loss:1.5669 | MainLoss:1.1663 | SPLoss:3.9630 | CLSLoss:0.4243 | top1:59.4517 | AUROC:0.6833\n",
      "\n",
      "Epoch: [253 | 1000] LR: 0.003454\n",
      "Train | 10/10 | Loss:0.6530 | MainLoss:0.2534 | SPLoss:3.9532 | CLSLoss:0.4247 | top1:89.5500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.0099 | MainLoss:0.6115 | SPLoss:3.9413 | CLSLoss:0.4243 | top1:74.7739 | AUROC:0.8271\n",
      "Test | 161/10 | Loss:1.5787 | MainLoss:1.1803 | SPLoss:3.9413 | CLSLoss:0.4243 | top1:59.3115 | AUROC:0.6826\n",
      "\n",
      "Epoch: [254 | 1000] LR: 0.003449\n",
      "Train | 10/10 | Loss:0.6345 | MainLoss:0.2371 | SPLoss:3.9314 | CLSLoss:0.4248 | top1:90.3000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.0114 | MainLoss:0.6152 | SPLoss:3.9192 | CLSLoss:0.4247 | top1:74.7117 | AUROC:0.8263\n",
      "Test | 161/10 | Loss:1.5260 | MainLoss:1.1298 | SPLoss:3.9192 | CLSLoss:0.4247 | top1:60.2523 | AUROC:0.6901\n",
      "\n",
      "Epoch: [255 | 1000] LR: 0.003445\n",
      "Train | 10/10 | Loss:0.6096 | MainLoss:0.2143 | SPLoss:3.9099 | CLSLoss:0.4252 | top1:91.5000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.0108 | MainLoss:0.6167 | SPLoss:3.8985 | CLSLoss:0.4259 | top1:74.6855 | AUROC:0.8261\n",
      "Test | 161/10 | Loss:1.5647 | MainLoss:1.1706 | SPLoss:3.8985 | CLSLoss:0.4259 | top1:59.5078 | AUROC:0.6846\n",
      "\n",
      "Epoch: [256 | 1000] LR: 0.003441\n",
      "Train | 10/10 | Loss:0.6165 | MainLoss:0.2232 | SPLoss:3.8898 | CLSLoss:0.4265 | top1:91.3500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.0106 | MainLoss:0.6185 | SPLoss:3.8784 | CLSLoss:0.4270 | top1:74.6986 | AUROC:0.8265\n",
      "Test | 161/10 | Loss:1.5771 | MainLoss:1.1850 | SPLoss:3.8784 | CLSLoss:0.4270 | top1:59.2960 | AUROC:0.6767\n",
      "\n",
      "Epoch: [257 | 1000] LR: 0.003436\n",
      "Train | 10/10 | Loss:0.6118 | MainLoss:0.2205 | SPLoss:3.8698 | CLSLoss:0.4272 | top1:91.6500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.0114 | MainLoss:0.6211 | SPLoss:3.8596 | CLSLoss:0.4278 | top1:74.7870 | AUROC:0.8275\n",
      "Test | 161/10 | Loss:1.5612 | MainLoss:1.1710 | SPLoss:3.8596 | CLSLoss:0.4278 | top1:59.6729 | AUROC:0.6812\n",
      "\n",
      "Epoch: [258 | 1000] LR: 0.003432\n",
      "Train | 10/10 | Loss:0.6180 | MainLoss:0.2287 | SPLoss:3.8508 | CLSLoss:0.4281 | top1:90.9000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.0075 | MainLoss:0.6191 | SPLoss:3.8408 | CLSLoss:0.4283 | top1:74.8952 | AUROC:0.8290\n",
      "Test | 161/10 | Loss:1.5995 | MainLoss:1.2111 | SPLoss:3.8408 | CLSLoss:0.4283 | top1:59.2586 | AUROC:0.6806\n",
      "\n",
      "Epoch: [259 | 1000] LR: 0.003427\n",
      "Train | 10/10 | Loss:0.5739 | MainLoss:0.1863 | SPLoss:3.8328 | CLSLoss:0.4291 | top1:92.7000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.0090 | MainLoss:0.6225 | SPLoss:3.8221 | CLSLoss:0.4299 | top1:74.8952 | AUROC:0.8287\n",
      "Test | 161/10 | Loss:1.5893 | MainLoss:1.2027 | SPLoss:3.8221 | CLSLoss:0.4299 | top1:59.4611 | AUROC:0.6824\n",
      "\n",
      "Epoch: [260 | 1000] LR: 0.003423\n",
      "Train | 10/10 | Loss:0.6008 | MainLoss:0.2150 | SPLoss:3.8147 | CLSLoss:0.4302 | top1:91.2000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.0072 | MainLoss:0.6224 | SPLoss:3.8052 | CLSLoss:0.4307 | top1:74.8853 | AUROC:0.8290\n",
      "Test | 161/10 | Loss:1.5905 | MainLoss:1.2057 | SPLoss:3.8052 | CLSLoss:0.4307 | top1:59.3956 | AUROC:0.6834\n",
      "\n",
      "Epoch: [261 | 1000] LR: 0.003419\n",
      "Train | 10/10 | Loss:0.5703 | MainLoss:0.1864 | SPLoss:3.7960 | CLSLoss:0.4313 | top1:93.0500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.0084 | MainLoss:0.6256 | SPLoss:3.7850 | CLSLoss:0.4321 | top1:74.9443 | AUROC:0.8292\n",
      "Test | 161/10 | Loss:1.6021 | MainLoss:1.2193 | SPLoss:3.7850 | CLSLoss:0.4321 | top1:59.3583 | AUROC:0.6845\n",
      "\n",
      "Epoch: [262 | 1000] LR: 0.003414\n",
      "Train | 10/10 | Loss:0.5703 | MainLoss:0.1883 | SPLoss:3.7772 | CLSLoss:0.4329 | top1:92.9000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.0125 | MainLoss:0.6314 | SPLoss:3.7675 | CLSLoss:0.4338 | top1:74.8722 | AUROC:0.8284\n",
      "Test | 161/10 | Loss:1.5961 | MainLoss:1.2150 | SPLoss:3.7675 | CLSLoss:0.4338 | top1:59.5545 | AUROC:0.6840\n",
      "\n",
      "Epoch: [263 | 1000] LR: 0.003410\n",
      "Train | 10/10 | Loss:0.6154 | MainLoss:0.2351 | SPLoss:3.7596 | CLSLoss:0.4338 | top1:90.8500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.0093 | MainLoss:0.6301 | SPLoss:3.7483 | CLSLoss:0.4336 | top1:74.8263 | AUROC:0.8276\n",
      "Test | 161/10 | Loss:1.5857 | MainLoss:1.2065 | SPLoss:3.7483 | CLSLoss:0.4336 | top1:59.6885 | AUROC:0.6869\n",
      "\n",
      "Epoch: [264 | 1000] LR: 0.003405\n",
      "Train | 10/10 | Loss:0.6089 | MainLoss:0.2306 | SPLoss:3.7396 | CLSLoss:0.4338 | top1:91.4000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.0071 | MainLoss:0.6298 | SPLoss:3.7300 | CLSLoss:0.4335 | top1:74.7936 | AUROC:0.8276\n",
      "Test | 161/10 | Loss:1.5655 | MainLoss:1.1881 | SPLoss:3.7300 | CLSLoss:0.4335 | top1:60.0031 | AUROC:0.6919\n",
      "\n",
      "Epoch: [265 | 1000] LR: 0.003401\n",
      "Train | 10/10 | Loss:0.5979 | MainLoss:0.2213 | SPLoss:3.7222 | CLSLoss:0.4337 | top1:91.7000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.0062 | MainLoss:0.6305 | SPLoss:3.7132 | CLSLoss:0.4340 | top1:74.8689 | AUROC:0.8277\n",
      "Test | 161/10 | Loss:1.5772 | MainLoss:1.2015 | SPLoss:3.7132 | CLSLoss:0.4340 | top1:59.8069 | AUROC:0.6874\n",
      "\n",
      "Epoch: [266 | 1000] LR: 0.003396\n",
      "Train | 10/10 | Loss:0.5806 | MainLoss:0.2058 | SPLoss:3.7049 | CLSLoss:0.4342 | top1:91.7500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.0037 | MainLoss:0.6298 | SPLoss:3.6956 | CLSLoss:0.4347 | top1:74.9607 | AUROC:0.8290\n",
      "Test | 161/10 | Loss:1.5865 | MainLoss:1.2126 | SPLoss:3.6956 | CLSLoss:0.4347 | top1:59.7601 | AUROC:0.6882\n",
      "\n",
      "Epoch: [267 | 1000] LR: 0.003392\n",
      "Train | 10/10 | Loss:0.6029 | MainLoss:0.2297 | SPLoss:3.6880 | CLSLoss:0.4345 | top1:91.2000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.0015 | MainLoss:0.6292 | SPLoss:3.6798 | CLSLoss:0.4348 | top1:75.0983 | AUROC:0.8294\n",
      "Test | 161/10 | Loss:1.5690 | MainLoss:1.1967 | SPLoss:3.6798 | CLSLoss:0.4348 | top1:59.9907 | AUROC:0.6907\n",
      "\n",
      "Epoch: [268 | 1000] LR: 0.003387\n",
      "Train | 10/10 | Loss:0.5944 | MainLoss:0.2229 | SPLoss:3.6717 | CLSLoss:0.4348 | top1:91.8000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:1.0001 | MainLoss:0.6295 | SPLoss:3.6626 | CLSLoss:0.4350 | top1:75.1278 | AUROC:0.8305\n",
      "Test | 161/10 | Loss:1.5907 | MainLoss:1.2201 | SPLoss:3.6626 | CLSLoss:0.4350 | top1:59.6044 | AUROC:0.6841\n",
      "\n",
      "Epoch: [269 | 1000] LR: 0.003383\n",
      "Train | 10/10 | Loss:0.6079 | MainLoss:0.2380 | SPLoss:3.6558 | CLSLoss:0.4347 | top1:91.1500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9962 | MainLoss:0.6271 | SPLoss:3.6475 | CLSLoss:0.4347 | top1:75.2261 | AUROC:0.8311\n",
      "Test | 161/10 | Loss:1.5683 | MainLoss:1.1993 | SPLoss:3.6475 | CLSLoss:0.4347 | top1:59.9190 | AUROC:0.6861\n",
      "\n",
      "Epoch: [270 | 1000] LR: 0.003378\n",
      "Train | 10/10 | Loss:0.5899 | MainLoss:0.2216 | SPLoss:3.6401 | CLSLoss:0.4348 | top1:92.0500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9929 | MainLoss:0.6255 | SPLoss:3.6309 | CLSLoss:0.4348 | top1:75.1900 | AUROC:0.8305\n",
      "Test | 161/10 | Loss:1.5777 | MainLoss:1.2102 | SPLoss:3.6309 | CLSLoss:0.4348 | top1:59.7321 | AUROC:0.6874\n",
      "\n",
      "Epoch: [271 | 1000] LR: 0.003374\n",
      "Train | 10/10 | Loss:0.6209 | MainLoss:0.2542 | SPLoss:3.6238 | CLSLoss:0.4343 | top1:90.5000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9898 | MainLoss:0.6239 | SPLoss:3.6160 | CLSLoss:0.4345 | top1:75.1245 | AUROC:0.8306\n",
      "Test | 161/10 | Loss:1.5957 | MainLoss:1.2297 | SPLoss:3.6160 | CLSLoss:0.4345 | top1:59.4143 | AUROC:0.6837\n",
      "\n",
      "Epoch: [272 | 1000] LR: 0.003369\n",
      "Train | 10/10 | Loss:0.5454 | MainLoss:0.1802 | SPLoss:3.6082 | CLSLoss:0.4354 | top1:93.5000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9937 | MainLoss:0.6295 | SPLoss:3.5984 | CLSLoss:0.4362 | top1:75.1016 | AUROC:0.8304\n",
      "Test | 161/10 | Loss:1.5952 | MainLoss:1.2310 | SPLoss:3.5984 | CLSLoss:0.4362 | top1:59.5483 | AUROC:0.6862\n",
      "\n",
      "Epoch: [273 | 1000] LR: 0.003365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 10/10 | Loss:0.5695 | MainLoss:0.2061 | SPLoss:3.5906 | CLSLoss:0.4366 | top1:92.7500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9939 | MainLoss:0.6314 | SPLoss:3.5815 | CLSLoss:0.4369 | top1:74.9115 | AUROC:0.8276\n",
      "Test | 161/10 | Loss:1.6103 | MainLoss:1.2478 | SPLoss:3.5815 | CLSLoss:0.4369 | top1:59.2617 | AUROC:0.6832\n",
      "\n",
      "Epoch: [274 | 1000] LR: 0.003360\n",
      "Train | 10/10 | Loss:0.5782 | MainLoss:0.2165 | SPLoss:3.5735 | CLSLoss:0.4375 | top1:91.7000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9985 | MainLoss:0.6377 | SPLoss:3.5645 | CLSLoss:0.4376 | top1:74.6461 | AUROC:0.8256\n",
      "Test | 161/10 | Loss:1.6125 | MainLoss:1.2517 | SPLoss:3.5645 | CLSLoss:0.4376 | top1:59.2336 | AUROC:0.6823\n",
      "\n",
      "Epoch: [275 | 1000] LR: 0.003355\n",
      "Train | 10/10 | Loss:0.5602 | MainLoss:0.2000 | SPLoss:3.5578 | CLSLoss:0.4382 | top1:92.9500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9985 | MainLoss:0.6391 | SPLoss:3.5505 | CLSLoss:0.4385 | top1:74.7772 | AUROC:0.8275\n",
      "Test | 161/10 | Loss:1.6525 | MainLoss:1.2931 | SPLoss:3.5505 | CLSLoss:0.4385 | top1:58.8567 | AUROC:0.6797\n",
      "\n",
      "Epoch: [276 | 1000] LR: 0.003351\n",
      "Train | 10/10 | Loss:0.5592 | MainLoss:0.2004 | SPLoss:3.5445 | CLSLoss:0.4390 | top1:92.4000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9958 | MainLoss:0.6377 | SPLoss:3.5370 | CLSLoss:0.4393 | top1:74.9738 | AUROC:0.8286\n",
      "Test | 161/10 | Loss:1.6193 | MainLoss:1.2612 | SPLoss:3.5370 | CLSLoss:0.4393 | top1:59.3801 | AUROC:0.6830\n",
      "\n",
      "Epoch: [277 | 1000] LR: 0.003346\n",
      "Train | 10/10 | Loss:0.5525 | MainLoss:0.1952 | SPLoss:3.5294 | CLSLoss:0.4398 | top1:92.7500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9961 | MainLoss:0.6397 | SPLoss:3.5205 | CLSLoss:0.4401 | top1:75.0295 | AUROC:0.8285\n",
      "Test | 161/10 | Loss:1.6013 | MainLoss:1.2449 | SPLoss:3.5205 | CLSLoss:0.4401 | top1:59.7321 | AUROC:0.6838\n",
      "\n",
      "Epoch: [278 | 1000] LR: 0.003341\n",
      "Train | 10/10 | Loss:0.5735 | MainLoss:0.2178 | SPLoss:3.5134 | CLSLoss:0.4405 | top1:92.3000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9931 | MainLoss:0.6383 | SPLoss:3.5043 | CLSLoss:0.4402 | top1:75.0885 | AUROC:0.8307\n",
      "Test | 161/10 | Loss:1.6297 | MainLoss:1.2749 | SPLoss:3.5043 | CLSLoss:0.4402 | top1:59.3115 | AUROC:0.6777\n",
      "\n",
      "Epoch: [279 | 1000] LR: 0.003337\n",
      "Train | 10/10 | Loss:0.5802 | MainLoss:0.2261 | SPLoss:3.4971 | CLSLoss:0.4401 | top1:91.2000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9894 | MainLoss:0.6362 | SPLoss:3.4879 | CLSLoss:0.4399 | top1:75.1212 | AUROC:0.8297\n",
      "Test | 161/10 | Loss:1.6095 | MainLoss:1.2563 | SPLoss:3.4879 | CLSLoss:0.4399 | top1:59.5327 | AUROC:0.6809\n",
      "\n",
      "Epoch: [280 | 1000] LR: 0.003332\n",
      "Train | 10/10 | Loss:0.5768 | MainLoss:0.2242 | SPLoss:3.4820 | CLSLoss:0.4396 | top1:91.5500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9842 | MainLoss:0.6324 | SPLoss:3.4744 | CLSLoss:0.4399 | top1:75.2326 | AUROC:0.8317\n",
      "Test | 161/10 | Loss:1.6128 | MainLoss:1.2609 | SPLoss:3.4744 | CLSLoss:0.4399 | top1:59.3707 | AUROC:0.6802\n",
      "\n",
      "Epoch: [281 | 1000] LR: 0.003327\n",
      "Train | 10/10 | Loss:0.5625 | MainLoss:0.2114 | SPLoss:3.4668 | CLSLoss:0.4401 | top1:92.0000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9836 | MainLoss:0.6334 | SPLoss:3.4583 | CLSLoss:0.4401 | top1:75.2195 | AUROC:0.8322\n",
      "Test | 161/10 | Loss:1.6202 | MainLoss:1.2700 | SPLoss:3.4583 | CLSLoss:0.4401 | top1:59.3801 | AUROC:0.6820\n",
      "\n",
      "Epoch: [282 | 1000] LR: 0.003323\n",
      "Train | 10/10 | Loss:0.5429 | MainLoss:0.1934 | SPLoss:3.4507 | CLSLoss:0.4402 | top1:93.3000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9844 | MainLoss:0.6358 | SPLoss:3.4418 | CLSLoss:0.4407 | top1:75.1704 | AUROC:0.8308\n",
      "Test | 161/10 | Loss:1.6065 | MainLoss:1.2579 | SPLoss:3.4418 | CLSLoss:0.4407 | top1:59.5327 | AUROC:0.6814\n",
      "\n",
      "Epoch: [283 | 1000] LR: 0.003318\n",
      "Train | 10/10 | Loss:0.5329 | MainLoss:0.1851 | SPLoss:3.4340 | CLSLoss:0.4414 | top1:93.6000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9875 | MainLoss:0.6405 | SPLoss:3.4254 | CLSLoss:0.4417 | top1:75.1966 | AUROC:0.8310\n",
      "Test | 161/10 | Loss:1.6250 | MainLoss:1.2780 | SPLoss:3.4254 | CLSLoss:0.4417 | top1:59.5016 | AUROC:0.6854\n",
      "\n",
      "Epoch: [284 | 1000] LR: 0.003313\n",
      "Train | 10/10 | Loss:0.5175 | MainLoss:0.1711 | SPLoss:3.4194 | CLSLoss:0.4425 | top1:93.3500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9908 | MainLoss:0.6451 | SPLoss:3.4122 | CLSLoss:0.4431 | top1:75.1835 | AUROC:0.8301\n",
      "Test | 161/10 | Loss:1.6202 | MainLoss:1.2745 | SPLoss:3.4122 | CLSLoss:0.4431 | top1:59.6262 | AUROC:0.6839\n",
      "\n",
      "Epoch: [285 | 1000] LR: 0.003308\n",
      "Train | 10/10 | Loss:0.5433 | MainLoss:0.1984 | SPLoss:3.4047 | CLSLoss:0.4434 | top1:92.7500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9960 | MainLoss:0.6518 | SPLoss:3.3977 | CLSLoss:0.4434 | top1:74.9967 | AUROC:0.8293\n",
      "Test | 161/10 | Loss:1.5796 | MainLoss:1.2354 | SPLoss:3.3977 | CLSLoss:0.4434 | top1:60.3209 | AUROC:0.6911\n",
      "\n",
      "Epoch: [286 | 1000] LR: 0.003304\n",
      "Train | 10/10 | Loss:0.5378 | MainLoss:0.1940 | SPLoss:3.3933 | CLSLoss:0.4438 | top1:92.8000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9940 | MainLoss:0.6508 | SPLoss:3.3878 | CLSLoss:0.4440 | top1:75.0819 | AUROC:0.8291\n",
      "Test | 161/10 | Loss:1.5868 | MainLoss:1.2436 | SPLoss:3.3878 | CLSLoss:0.4440 | top1:60.1153 | AUROC:0.6860\n",
      "\n",
      "Epoch: [287 | 1000] LR: 0.003299\n",
      "Train | 10/10 | Loss:0.5432 | MainLoss:0.2007 | SPLoss:3.3814 | CLSLoss:0.4440 | top1:92.5500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9876 | MainLoss:0.6457 | SPLoss:3.3741 | CLSLoss:0.4443 | top1:75.0918 | AUROC:0.8295\n",
      "Test | 161/10 | Loss:1.6372 | MainLoss:1.2953 | SPLoss:3.3741 | CLSLoss:0.4443 | top1:59.3489 | AUROC:0.6792\n",
      "\n",
      "Epoch: [288 | 1000] LR: 0.003294\n",
      "Train | 10/10 | Loss:0.5579 | MainLoss:0.2166 | SPLoss:3.3693 | CLSLoss:0.4439 | top1:91.9500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9860 | MainLoss:0.6453 | SPLoss:3.3625 | CLSLoss:0.4443 | top1:75.0918 | AUROC:0.8300\n",
      "Test | 161/10 | Loss:1.6234 | MainLoss:1.2827 | SPLoss:3.3625 | CLSLoss:0.4443 | top1:59.5919 | AUROC:0.6829\n",
      "\n",
      "Epoch: [289 | 1000] LR: 0.003289\n",
      "Train | 10/10 | Loss:0.5680 | MainLoss:0.2279 | SPLoss:3.3572 | CLSLoss:0.4441 | top1:90.9000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9805 | MainLoss:0.6409 | SPLoss:3.3515 | CLSLoss:0.4438 | top1:75.0819 | AUROC:0.8300\n",
      "Test | 161/10 | Loss:1.6228 | MainLoss:1.2833 | SPLoss:3.3515 | CLSLoss:0.4438 | top1:59.3240 | AUROC:0.6794\n",
      "\n",
      "Epoch: [290 | 1000] LR: 0.003285\n",
      "Train | 10/10 | Loss:0.5372 | MainLoss:0.1982 | SPLoss:3.3449 | CLSLoss:0.4440 | top1:93.1000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9812 | MainLoss:0.6430 | SPLoss:3.3370 | CLSLoss:0.4443 | top1:75.1671 | AUROC:0.8295\n",
      "Test | 161/10 | Loss:1.6124 | MainLoss:1.2743 | SPLoss:3.3370 | CLSLoss:0.4443 | top1:59.4704 | AUROC:0.6834\n",
      "\n",
      "Epoch: [291 | 1000] LR: 0.003280\n",
      "Train | 10/10 | Loss:0.5407 | MainLoss:0.2032 | SPLoss:3.3302 | CLSLoss:0.4444 | top1:92.4000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9823 | MainLoss:0.6456 | SPLoss:3.3230 | CLSLoss:0.4448 | top1:74.9607 | AUROC:0.8291\n",
      "Test | 161/10 | Loss:1.6148 | MainLoss:1.2781 | SPLoss:3.3230 | CLSLoss:0.4448 | top1:59.5545 | AUROC:0.6842\n",
      "\n",
      "Epoch: [292 | 1000] LR: 0.003275\n",
      "Train | 10/10 | Loss:0.5642 | MainLoss:0.2281 | SPLoss:3.3171 | CLSLoss:0.4449 | top1:91.1500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9754 | MainLoss:0.6399 | SPLoss:3.3103 | CLSLoss:0.4443 | top1:75.0819 | AUROC:0.8307\n",
      "Test | 161/10 | Loss:1.6070 | MainLoss:1.2716 | SPLoss:3.3103 | CLSLoss:0.4443 | top1:59.6791 | AUROC:0.6900\n",
      "\n",
      "Epoch: [293 | 1000] LR: 0.003270\n",
      "Train | 10/10 | Loss:0.5421 | MainLoss:0.2073 | SPLoss:3.3038 | CLSLoss:0.4444 | top1:92.8500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9758 | MainLoss:0.6418 | SPLoss:3.2954 | CLSLoss:0.4446 | top1:74.9541 | AUROC:0.8300\n",
      "Test | 161/10 | Loss:1.6151 | MainLoss:1.2811 | SPLoss:3.2954 | CLSLoss:0.4446 | top1:59.4361 | AUROC:0.6883\n",
      "\n",
      "Epoch: [294 | 1000] LR: 0.003265\n",
      "Train | 10/10 | Loss:0.4996 | MainLoss:0.1661 | SPLoss:3.2906 | CLSLoss:0.4453 | top1:94.1000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9801 | MainLoss:0.6472 | SPLoss:3.2843 | CLSLoss:0.4461 | top1:75.0590 | AUROC:0.8287\n",
      "Test | 161/10 | Loss:1.6001 | MainLoss:1.2672 | SPLoss:3.2843 | CLSLoss:0.4461 | top1:59.7601 | AUROC:0.6890\n",
      "\n",
      "Epoch: [295 | 1000] LR: 0.003260\n",
      "Train | 10/10 | Loss:0.5254 | MainLoss:0.1931 | SPLoss:3.2781 | CLSLoss:0.4464 | top1:92.7500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9798 | MainLoss:0.6482 | SPLoss:3.2711 | CLSLoss:0.4468 | top1:75.0033 | AUROC:0.8291\n",
      "Test | 161/10 | Loss:1.6250 | MainLoss:1.2934 | SPLoss:3.2711 | CLSLoss:0.4468 | top1:59.4611 | AUROC:0.6854\n",
      "\n",
      "Epoch: [296 | 1000] LR: 0.003255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 10/10 | Loss:0.5190 | MainLoss:0.1879 | SPLoss:3.2659 | CLSLoss:0.4473 | top1:92.9500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9836 | MainLoss:0.6532 | SPLoss:3.2594 | CLSLoss:0.4475 | top1:75.0491 | AUROC:0.8289\n",
      "Test | 161/10 | Loss:1.6055 | MainLoss:1.2751 | SPLoss:3.2594 | CLSLoss:0.4475 | top1:59.7601 | AUROC:0.6865\n",
      "\n",
      "Epoch: [297 | 1000] LR: 0.003250\n",
      "Train | 10/10 | Loss:0.5121 | MainLoss:0.1823 | SPLoss:3.2530 | CLSLoss:0.4479 | top1:93.3000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9841 | MainLoss:0.6552 | SPLoss:3.2451 | CLSLoss:0.4482 | top1:75.0262 | AUROC:0.8293\n",
      "Test | 161/10 | Loss:1.6143 | MainLoss:1.2853 | SPLoss:3.2451 | CLSLoss:0.4482 | top1:59.7414 | AUROC:0.6866\n",
      "\n",
      "Epoch: [298 | 1000] LR: 0.003246\n",
      "Train | 10/10 | Loss:0.5463 | MainLoss:0.2178 | SPLoss:3.2402 | CLSLoss:0.4482 | top1:91.7000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9814 | MainLoss:0.6535 | SPLoss:3.2339 | CLSLoss:0.4479 | top1:74.9869 | AUROC:0.8293\n",
      "Test | 161/10 | Loss:1.6578 | MainLoss:1.3300 | SPLoss:3.2339 | CLSLoss:0.4479 | top1:59.1090 | AUROC:0.6802\n",
      "\n",
      "Epoch: [299 | 1000] LR: 0.003241\n",
      "Train | 10/10 | Loss:0.5133 | MainLoss:0.1860 | SPLoss:3.2279 | CLSLoss:0.4485 | top1:93.0500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9783 | MainLoss:0.6516 | SPLoss:3.2217 | CLSLoss:0.4487 | top1:75.1081 | AUROC:0.8301\n",
      "Test | 161/10 | Loss:1.6149 | MainLoss:1.2882 | SPLoss:3.2217 | CLSLoss:0.4487 | top1:59.7975 | AUROC:0.6900\n",
      "\n",
      "Epoch: [300 | 1000] LR: 0.003236\n",
      "Train | 10/10 | Loss:0.5359 | MainLoss:0.2099 | SPLoss:3.2155 | CLSLoss:0.4489 | top1:92.0000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9786 | MainLoss:0.6534 | SPLoss:3.2072 | CLSLoss:0.4485 | top1:75.0557 | AUROC:0.8286\n",
      "Test | 161/10 | Loss:1.6186 | MainLoss:1.2934 | SPLoss:3.2072 | CLSLoss:0.4485 | top1:59.5950 | AUROC:0.6868\n",
      "\n",
      "Epoch: [301 | 1000] LR: 0.003231\n",
      "Train | 10/10 | Loss:0.5142 | MainLoss:0.1895 | SPLoss:3.2015 | CLSLoss:0.4488 | top1:92.6000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9844 | MainLoss:0.6604 | SPLoss:3.1944 | CLSLoss:0.4493 | top1:74.8689 | AUROC:0.8280\n",
      "Test | 161/10 | Loss:1.5907 | MainLoss:1.2667 | SPLoss:3.1944 | CLSLoss:0.4493 | top1:59.9813 | AUROC:0.6856\n",
      "\n",
      "Epoch: [302 | 1000] LR: 0.003226\n",
      "Train | 10/10 | Loss:0.5356 | MainLoss:0.2122 | SPLoss:3.1888 | CLSLoss:0.4491 | top1:92.5500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9805 | MainLoss:0.6579 | SPLoss:3.1817 | CLSLoss:0.4490 | top1:74.9640 | AUROC:0.8281\n",
      "Test | 161/10 | Loss:1.5905 | MainLoss:1.2678 | SPLoss:3.1817 | CLSLoss:0.4490 | top1:60.0592 | AUROC:0.6915\n",
      "\n",
      "Epoch: [303 | 1000] LR: 0.003221\n",
      "Train | 10/10 | Loss:0.5457 | MainLoss:0.2236 | SPLoss:3.1768 | CLSLoss:0.4485 | top1:91.1000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9768 | MainLoss:0.6552 | SPLoss:3.1709 | CLSLoss:0.4486 | top1:74.9214 | AUROC:0.8277\n",
      "Test | 161/10 | Loss:1.5770 | MainLoss:1.2555 | SPLoss:3.1709 | CLSLoss:0.4486 | top1:60.0779 | AUROC:0.6913\n",
      "\n",
      "Epoch: [304 | 1000] LR: 0.003216\n",
      "Train | 10/10 | Loss:0.5155 | MainLoss:0.1944 | SPLoss:3.1654 | CLSLoss:0.4488 | top1:93.1000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9743 | MainLoss:0.6539 | SPLoss:3.1590 | CLSLoss:0.4491 | top1:74.9705 | AUROC:0.8281\n",
      "Test | 161/10 | Loss:1.5989 | MainLoss:1.2785 | SPLoss:3.1590 | CLSLoss:0.4491 | top1:59.8193 | AUROC:0.6893\n",
      "\n",
      "Epoch: [305 | 1000] LR: 0.003211\n",
      "Train | 10/10 | Loss:0.5467 | MainLoss:0.2267 | SPLoss:3.1550 | CLSLoss:0.4489 | top1:91.1000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9728 | MainLoss:0.6534 | SPLoss:3.1491 | CLSLoss:0.4488 | top1:75.1507 | AUROC:0.8296\n",
      "Test | 161/10 | Loss:1.5832 | MainLoss:1.2638 | SPLoss:3.1491 | CLSLoss:0.4488 | top1:60.1589 | AUROC:0.6924\n",
      "\n",
      "Epoch: [306 | 1000] LR: 0.003206\n",
      "Train | 10/10 | Loss:0.5246 | MainLoss:0.2056 | SPLoss:3.1447 | CLSLoss:0.4489 | top1:93.0000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9694 | MainLoss:0.6511 | SPLoss:3.1385 | CLSLoss:0.4488 | top1:75.1835 | AUROC:0.8292\n",
      "Test | 161/10 | Loss:1.5998 | MainLoss:1.2814 | SPLoss:3.1385 | CLSLoss:0.4488 | top1:59.8972 | AUROC:0.6945\n",
      "\n",
      "Epoch: [307 | 1000] LR: 0.003201\n",
      "Train | 10/10 | Loss:0.4951 | MainLoss:0.1773 | SPLoss:3.1327 | CLSLoss:0.4492 | top1:94.0500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9734 | MainLoss:0.6563 | SPLoss:3.1259 | CLSLoss:0.4497 | top1:75.0885 | AUROC:0.8283\n",
      "Test | 161/10 | Loss:1.6046 | MainLoss:1.2875 | SPLoss:3.1259 | CLSLoss:0.4497 | top1:59.7975 | AUROC:0.6916\n",
      "\n",
      "Epoch: [308 | 1000] LR: 0.003196\n",
      "Train | 10/10 | Loss:0.4984 | MainLoss:0.1818 | SPLoss:3.1210 | CLSLoss:0.4503 | top1:93.2500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9761 | MainLoss:0.6599 | SPLoss:3.1161 | CLSLoss:0.4506 | top1:74.8853 | AUROC:0.8277\n",
      "Test | 161/10 | Loss:1.5393 | MainLoss:1.2232 | SPLoss:3.1161 | CLSLoss:0.4506 | top1:60.8785 | AUROC:0.7141\n",
      "\n",
      "Epoch: [309 | 1000] LR: 0.003191\n",
      "Train | 10/10 | Loss:0.5217 | MainLoss:0.2062 | SPLoss:3.1107 | CLSLoss:0.4507 | top1:91.9500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9717 | MainLoss:0.6568 | SPLoss:3.1041 | CLSLoss:0.4506 | top1:74.7313 | AUROC:0.8278\n",
      "Test | 161/10 | Loss:1.5887 | MainLoss:1.2738 | SPLoss:3.1041 | CLSLoss:0.4506 | top1:60.0530 | AUROC:0.7064\n",
      "\n",
      "Epoch: [310 | 1000] LR: 0.003186\n",
      "Train | 10/10 | Loss:0.5572 | MainLoss:0.2428 | SPLoss:3.0993 | CLSLoss:0.4502 | top1:90.8000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9658 | MainLoss:0.6520 | SPLoss:3.0936 | CLSLoss:0.4496 | top1:74.9345 | AUROC:0.8270\n",
      "Test | 161/10 | Loss:1.5286 | MainLoss:1.2148 | SPLoss:3.0936 | CLSLoss:0.4496 | top1:60.7913 | AUROC:0.7093\n",
      "\n",
      "Epoch: [311 | 1000] LR: 0.003181\n",
      "Train | 10/10 | Loss:0.5645 | MainLoss:0.2511 | SPLoss:3.0887 | CLSLoss:0.4495 | top1:90.8500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9593 | MainLoss:0.6466 | SPLoss:3.0822 | CLSLoss:0.4486 | top1:74.6527 | AUROC:0.8277\n",
      "Test | 161/10 | Loss:1.5816 | MainLoss:1.2689 | SPLoss:3.0822 | CLSLoss:0.4486 | top1:59.6947 | AUROC:0.7029\n",
      "\n",
      "Epoch: [312 | 1000] LR: 0.003176\n",
      "Train | 10/10 | Loss:0.4962 | MainLoss:0.1841 | SPLoss:3.0767 | CLSLoss:0.4490 | top1:93.2500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9592 | MainLoss:0.6476 | SPLoss:3.0710 | CLSLoss:0.4495 | top1:74.8001 | AUROC:0.8279\n",
      "Test | 161/10 | Loss:1.5682 | MainLoss:1.2566 | SPLoss:3.0710 | CLSLoss:0.4495 | top1:60.0561 | AUROC:0.7093\n",
      "\n",
      "Epoch: [313 | 1000] LR: 0.003170\n",
      "Train | 10/10 | Loss:0.5467 | MainLoss:0.2356 | SPLoss:3.0661 | CLSLoss:0.4496 | top1:90.8500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9575 | MainLoss:0.6469 | SPLoss:3.0614 | CLSLoss:0.4490 | top1:74.7739 | AUROC:0.8268\n",
      "Test | 161/10 | Loss:1.5460 | MainLoss:1.2354 | SPLoss:3.0614 | CLSLoss:0.4490 | top1:60.4611 | AUROC:0.7137\n",
      "\n",
      "Epoch: [314 | 1000] LR: 0.003165\n",
      "Train | 10/10 | Loss:0.4993 | MainLoss:0.1891 | SPLoss:3.0574 | CLSLoss:0.4493 | top1:93.0500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9549 | MainLoss:0.6453 | SPLoss:3.0514 | CLSLoss:0.4498 | top1:74.9476 | AUROC:0.8299\n",
      "Test | 161/10 | Loss:1.5489 | MainLoss:1.2393 | SPLoss:3.0514 | CLSLoss:0.4498 | top1:60.4735 | AUROC:0.7116\n",
      "\n",
      "Epoch: [315 | 1000] LR: 0.003160\n",
      "Train | 10/10 | Loss:0.4884 | MainLoss:0.1793 | SPLoss:3.0461 | CLSLoss:0.4503 | top1:93.4000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9571 | MainLoss:0.6486 | SPLoss:3.0397 | CLSLoss:0.4507 | top1:74.8820 | AUROC:0.8293\n",
      "Test | 161/10 | Loss:1.5724 | MainLoss:1.2639 | SPLoss:3.0397 | CLSLoss:0.4507 | top1:60.1526 | AUROC:0.7089\n",
      "\n",
      "Epoch: [316 | 1000] LR: 0.003155\n",
      "Train | 10/10 | Loss:0.5492 | MainLoss:0.2412 | SPLoss:3.0349 | CLSLoss:0.4499 | top1:91.0500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9505 | MainLoss:0.6431 | SPLoss:3.0296 | CLSLoss:0.4498 | top1:75.1606 | AUROC:0.8305\n",
      "Test | 161/10 | Loss:1.5392 | MainLoss:1.2318 | SPLoss:3.0296 | CLSLoss:0.4498 | top1:60.5296 | AUROC:0.7101\n",
      "\n",
      "Epoch: [317 | 1000] LR: 0.003150\n",
      "Train | 10/10 | Loss:0.5378 | MainLoss:0.2309 | SPLoss:3.0241 | CLSLoss:0.4494 | top1:91.6500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9472 | MainLoss:0.6409 | SPLoss:3.0180 | CLSLoss:0.4493 | top1:75.0295 | AUROC:0.8295\n",
      "Test | 161/10 | Loss:1.5431 | MainLoss:1.2368 | SPLoss:3.0180 | CLSLoss:0.4493 | top1:60.3769 | AUROC:0.7110\n",
      "\n",
      "Epoch: [318 | 1000] LR: 0.003145\n",
      "Train | 10/10 | Loss:0.5038 | MainLoss:0.1980 | SPLoss:3.0126 | CLSLoss:0.4498 | top1:92.8000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9511 | MainLoss:0.6458 | SPLoss:3.0075 | CLSLoss:0.4498 | top1:74.9803 | AUROC:0.8286\n",
      "Test | 161/10 | Loss:1.5170 | MainLoss:1.2117 | SPLoss:3.0075 | CLSLoss:0.4498 | top1:60.8941 | AUROC:0.7132\n",
      "\n",
      "Epoch: [319 | 1000] LR: 0.003140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 10/10 | Loss:0.5437 | MainLoss:0.2390 | SPLoss:3.0018 | CLSLoss:0.4494 | top1:90.8000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9437 | MainLoss:0.6396 | SPLoss:2.9962 | CLSLoss:0.4491 | top1:74.9574 | AUROC:0.8299\n",
      "Test | 161/10 | Loss:1.5384 | MainLoss:1.2343 | SPLoss:2.9962 | CLSLoss:0.4491 | top1:60.6636 | AUROC:0.7148\n",
      "\n",
      "Epoch: [320 | 1000] LR: 0.003135\n",
      "Train | 10/10 | Loss:0.5504 | MainLoss:0.2467 | SPLoss:2.9921 | CLSLoss:0.4489 | top1:90.8000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9377 | MainLoss:0.6345 | SPLoss:2.9870 | CLSLoss:0.4482 | top1:75.0262 | AUROC:0.8293\n",
      "Test | 161/10 | Loss:1.5204 | MainLoss:1.2173 | SPLoss:2.9870 | CLSLoss:0.4482 | top1:60.8162 | AUROC:0.7149\n",
      "\n",
      "Epoch: [321 | 1000] LR: 0.003129\n",
      "Train | 10/10 | Loss:0.4924 | MainLoss:0.1896 | SPLoss:2.9831 | CLSLoss:0.4486 | top1:93.3500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9417 | MainLoss:0.6395 | SPLoss:2.9770 | CLSLoss:0.4492 | top1:74.8886 | AUROC:0.8285\n",
      "Test | 161/10 | Loss:1.5013 | MainLoss:1.1991 | SPLoss:2.9770 | CLSLoss:0.4492 | top1:61.1090 | AUROC:0.7177\n",
      "\n",
      "Epoch: [322 | 1000] LR: 0.003124\n",
      "Train | 10/10 | Loss:0.5403 | MainLoss:0.2385 | SPLoss:2.9724 | CLSLoss:0.4493 | top1:90.5500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9389 | MainLoss:0.6377 | SPLoss:2.9675 | CLSLoss:0.4490 | top1:74.9705 | AUROC:0.8294\n",
      "Test | 161/10 | Loss:1.5561 | MainLoss:1.2549 | SPLoss:2.9675 | CLSLoss:0.4490 | top1:60.0748 | AUROC:0.7138\n",
      "\n",
      "Epoch: [323 | 1000] LR: 0.003119\n",
      "Train | 10/10 | Loss:0.4901 | MainLoss:0.1893 | SPLoss:2.9633 | CLSLoss:0.4495 | top1:92.6000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9417 | MainLoss:0.6414 | SPLoss:2.9575 | CLSLoss:0.4501 | top1:74.9771 | AUROC:0.8286\n",
      "Test | 161/10 | Loss:1.5488 | MainLoss:1.2485 | SPLoss:2.9575 | CLSLoss:0.4501 | top1:60.3551 | AUROC:0.7157\n",
      "\n",
      "Epoch: [324 | 1000] LR: 0.003114\n",
      "Train | 10/10 | Loss:0.5191 | MainLoss:0.2192 | SPLoss:2.9531 | CLSLoss:0.4504 | top1:91.6000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9378 | MainLoss:0.6385 | SPLoss:2.9481 | CLSLoss:0.4502 | top1:75.0033 | AUROC:0.8289\n",
      "Test | 161/10 | Loss:1.5302 | MainLoss:1.2309 | SPLoss:2.9481 | CLSLoss:0.4502 | top1:60.5234 | AUROC:0.7152\n",
      "\n",
      "Epoch: [325 | 1000] LR: 0.003109\n",
      "Train | 10/10 | Loss:0.4773 | MainLoss:0.1785 | SPLoss:2.9432 | CLSLoss:0.4505 | top1:93.7000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9431 | MainLoss:0.6449 | SPLoss:2.9366 | CLSLoss:0.4515 | top1:75.0164 | AUROC:0.8294\n",
      "Test | 161/10 | Loss:1.5223 | MainLoss:1.2242 | SPLoss:2.9366 | CLSLoss:0.4515 | top1:60.9221 | AUROC:0.7157\n",
      "\n",
      "Epoch: [326 | 1000] LR: 0.003103\n",
      "Train | 10/10 | Loss:0.4931 | MainLoss:0.1954 | SPLoss:2.9315 | CLSLoss:0.4521 | top1:92.7500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9543 | MainLoss:0.6572 | SPLoss:2.9254 | CLSLoss:0.4521 | top1:75.0459 | AUROC:0.8294\n",
      "Test | 161/10 | Loss:1.6029 | MainLoss:1.3059 | SPLoss:2.9254 | CLSLoss:0.4521 | top1:59.9252 | AUROC:0.6996\n",
      "\n",
      "Epoch: [327 | 1000] LR: 0.003098\n",
      "Train | 10/10 | Loss:0.5083 | MainLoss:0.2111 | SPLoss:2.9268 | CLSLoss:0.4519 | top1:92.3000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9542 | MainLoss:0.6572 | SPLoss:2.9243 | CLSLoss:0.4519 | top1:75.1442 | AUROC:0.8295\n",
      "Test | 161/10 | Loss:1.5745 | MainLoss:1.2775 | SPLoss:2.9243 | CLSLoss:0.4519 | top1:60.2368 | AUROC:0.6962\n",
      "\n",
      "Epoch: [328 | 1000] LR: 0.003093\n",
      "Train | 10/10 | Loss:0.4945 | MainLoss:0.1980 | SPLoss:2.9204 | CLSLoss:0.4517 | top1:93.2500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9538 | MainLoss:0.6577 | SPLoss:2.9152 | CLSLoss:0.4518 | top1:74.9115 | AUROC:0.8281\n",
      "Test | 161/10 | Loss:1.5567 | MainLoss:1.2606 | SPLoss:2.9152 | CLSLoss:0.4518 | top1:60.4174 | AUROC:0.6993\n",
      "\n",
      "Epoch: [329 | 1000] LR: 0.003088\n",
      "Train | 10/10 | Loss:0.5023 | MainLoss:0.2066 | SPLoss:2.9121 | CLSLoss:0.4516 | top1:92.3000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9476 | MainLoss:0.6525 | SPLoss:2.9062 | CLSLoss:0.4518 | top1:75.0623 | AUROC:0.8293\n",
      "Test | 161/10 | Loss:1.6111 | MainLoss:1.3160 | SPLoss:2.9062 | CLSLoss:0.4518 | top1:59.6044 | AUROC:0.6947\n",
      "\n",
      "Epoch: [330 | 1000] LR: 0.003082\n",
      "Train | 10/10 | Loss:0.5301 | MainLoss:0.2355 | SPLoss:2.9015 | CLSLoss:0.4513 | top1:91.3500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9453 | MainLoss:0.6513 | SPLoss:2.8951 | CLSLoss:0.4510 | top1:74.9017 | AUROC:0.8276\n",
      "Test | 161/10 | Loss:1.5687 | MainLoss:1.2747 | SPLoss:2.8951 | CLSLoss:0.4510 | top1:60.0156 | AUROC:0.6968\n",
      "\n",
      "Epoch: [331 | 1000] LR: 0.003077\n",
      "Train | 10/10 | Loss:0.5204 | MainLoss:0.2269 | SPLoss:2.8907 | CLSLoss:0.4505 | top1:92.1000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9444 | MainLoss:0.6515 | SPLoss:2.8845 | CLSLoss:0.4507 | top1:74.9345 | AUROC:0.8277\n",
      "Test | 161/10 | Loss:1.5744 | MainLoss:1.2814 | SPLoss:2.8845 | CLSLoss:0.4507 | top1:60.0935 | AUROC:0.6977\n",
      "\n",
      "Epoch: [332 | 1000] LR: 0.003072\n",
      "Train | 10/10 | Loss:0.4826 | MainLoss:0.1900 | SPLoss:2.8803 | CLSLoss:0.4509 | top1:93.0000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9438 | MainLoss:0.6517 | SPLoss:2.8757 | CLSLoss:0.4512 | top1:74.8657 | AUROC:0.8271\n",
      "Test | 161/10 | Loss:1.5849 | MainLoss:1.2929 | SPLoss:2.8757 | CLSLoss:0.4512 | top1:59.9408 | AUROC:0.6974\n",
      "\n",
      "Epoch: [333 | 1000] LR: 0.003066\n",
      "Train | 10/10 | Loss:0.4999 | MainLoss:0.2082 | SPLoss:2.8719 | CLSLoss:0.4513 | top1:92.6500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9449 | MainLoss:0.6537 | SPLoss:2.8665 | CLSLoss:0.4513 | top1:74.7969 | AUROC:0.8260\n",
      "Test | 161/10 | Loss:1.5869 | MainLoss:1.2957 | SPLoss:2.8665 | CLSLoss:0.4513 | top1:59.8879 | AUROC:0.6961\n",
      "\n",
      "Epoch: [334 | 1000] LR: 0.003061\n",
      "Train | 10/10 | Loss:0.4802 | MainLoss:0.1895 | SPLoss:2.8614 | CLSLoss:0.4516 | top1:93.2000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9469 | MainLoss:0.6568 | SPLoss:2.8564 | CLSLoss:0.4522 | top1:74.7903 | AUROC:0.8260\n",
      "Test | 161/10 | Loss:1.6021 | MainLoss:1.3120 | SPLoss:2.8564 | CLSLoss:0.4522 | top1:59.8255 | AUROC:0.6944\n",
      "\n",
      "Epoch: [335 | 1000] LR: 0.003056\n",
      "Train | 10/10 | Loss:0.5007 | MainLoss:0.2109 | SPLoss:2.8530 | CLSLoss:0.4523 | top1:91.8000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9444 | MainLoss:0.6549 | SPLoss:2.8500 | CLSLoss:0.4523 | top1:74.7838 | AUROC:0.8267\n",
      "Test | 161/10 | Loss:1.5520 | MainLoss:1.2625 | SPLoss:2.8500 | CLSLoss:0.4523 | top1:60.8692 | AUROC:0.7148\n",
      "\n",
      "Epoch: [336 | 1000] LR: 0.003050\n",
      "Train | 10/10 | Loss:0.4973 | MainLoss:0.2082 | SPLoss:2.8456 | CLSLoss:0.4523 | top1:92.5000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9418 | MainLoss:0.6532 | SPLoss:2.8402 | CLSLoss:0.4524 | top1:74.7412 | AUROC:0.8278\n",
      "Test | 161/10 | Loss:1.5769 | MainLoss:1.2884 | SPLoss:2.8402 | CLSLoss:0.4524 | top1:60.4891 | AUROC:0.7135\n",
      "\n",
      "Epoch: [337 | 1000] LR: 0.003045\n",
      "Train | 10/10 | Loss:0.5871 | MainLoss:0.2983 | SPLoss:2.8428 | CLSLoss:0.4517 | top1:87.0000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9788 | MainLoss:0.6900 | SPLoss:2.8434 | CLSLoss:0.4509 | top1:72.9587 | AUROC:0.8078\n",
      "Test | 161/10 | Loss:1.5652 | MainLoss:1.2764 | SPLoss:2.8434 | CLSLoss:0.4509 | top1:60.7508 | AUROC:0.7144\n",
      "\n",
      "Epoch: [338 | 1000] LR: 0.003040\n",
      "Train | 10/10 | Loss:0.5783 | MainLoss:0.2898 | SPLoss:2.8404 | CLSLoss:0.4500 | top1:88.1500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9635 | MainLoss:0.6752 | SPLoss:2.8379 | CLSLoss:0.4497 | top1:73.2339 | AUROC:0.8119\n",
      "Test | 161/10 | Loss:1.5263 | MainLoss:1.2380 | SPLoss:2.8379 | CLSLoss:0.4497 | top1:61.3769 | AUROC:0.7205\n",
      "\n",
      "Epoch: [339 | 1000] LR: 0.003034\n",
      "Train | 10/10 | Loss:0.5633 | MainLoss:0.2753 | SPLoss:2.8357 | CLSLoss:0.4493 | top1:89.1000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9554 | MainLoss:0.6676 | SPLoss:2.8334 | CLSLoss:0.4488 | top1:73.3945 | AUROC:0.8140\n",
      "Test | 161/10 | Loss:1.5098 | MainLoss:1.2219 | SPLoss:2.8334 | CLSLoss:0.4488 | top1:61.5203 | AUROC:0.7237\n",
      "\n",
      "Epoch: [340 | 1000] LR: 0.003029\n",
      "Train | 10/10 | Loss:0.5642 | MainLoss:0.2766 | SPLoss:2.8315 | CLSLoss:0.4489 | top1:88.8000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9484 | MainLoss:0.6610 | SPLoss:2.8295 | CLSLoss:0.4481 | top1:73.4338 | AUROC:0.8151\n",
      "Test | 161/10 | Loss:1.5122 | MainLoss:1.2248 | SPLoss:2.8295 | CLSLoss:0.4481 | top1:61.3458 | AUROC:0.7225\n",
      "\n",
      "Epoch: [341 | 1000] LR: 0.003023\n",
      "Train | 10/10 | Loss:0.5473 | MainLoss:0.2599 | SPLoss:2.8287 | CLSLoss:0.4478 | top1:90.1000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9424 | MainLoss:0.6553 | SPLoss:2.8261 | CLSLoss:0.4477 | top1:73.7320 | AUROC:0.8177\n",
      "Test | 161/10 | Loss:1.5381 | MainLoss:1.2510 | SPLoss:2.8261 | CLSLoss:0.4477 | top1:60.8536 | AUROC:0.7190\n",
      "\n",
      "Epoch: [342 | 1000] LR: 0.003018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 10/10 | Loss:0.5198 | MainLoss:0.2329 | SPLoss:2.8242 | CLSLoss:0.4480 | top1:89.9000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9432 | MainLoss:0.6565 | SPLoss:2.8217 | CLSLoss:0.4481 | top1:73.7877 | AUROC:0.8177\n",
      "Test | 161/10 | Loss:1.5574 | MainLoss:1.2708 | SPLoss:2.8217 | CLSLoss:0.4481 | top1:60.4050 | AUROC:0.7135\n",
      "\n",
      "Epoch: [343 | 1000] LR: 0.003013\n",
      "Train | 10/10 | Loss:0.5440 | MainLoss:0.2577 | SPLoss:2.8184 | CLSLoss:0.4480 | top1:89.7000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9367 | MainLoss:0.6508 | SPLoss:2.8146 | CLSLoss:0.4479 | top1:73.8860 | AUROC:0.8192\n",
      "Test | 161/10 | Loss:1.5512 | MainLoss:1.2653 | SPLoss:2.8146 | CLSLoss:0.4479 | top1:60.3707 | AUROC:0.7130\n",
      "\n",
      "Epoch: [344 | 1000] LR: 0.003007\n",
      "Train | 10/10 | Loss:0.5476 | MainLoss:0.2620 | SPLoss:2.8117 | CLSLoss:0.4475 | top1:89.9000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9305 | MainLoss:0.6453 | SPLoss:2.8076 | CLSLoss:0.4475 | top1:74.0695 | AUROC:0.8200\n",
      "Test | 161/10 | Loss:1.5152 | MainLoss:1.2299 | SPLoss:2.8076 | CLSLoss:0.4475 | top1:60.8349 | AUROC:0.7168\n",
      "\n",
      "Epoch: [345 | 1000] LR: 0.003002\n",
      "Train | 10/10 | Loss:0.5381 | MainLoss:0.2531 | SPLoss:2.8053 | CLSLoss:0.4476 | top1:90.0000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9295 | MainLoss:0.6447 | SPLoss:2.8035 | CLSLoss:0.4476 | top1:74.1481 | AUROC:0.8201\n",
      "Test | 161/10 | Loss:1.5244 | MainLoss:1.2396 | SPLoss:2.8035 | CLSLoss:0.4476 | top1:60.7009 | AUROC:0.7193\n",
      "\n",
      "Epoch: [346 | 1000] LR: 0.002996\n",
      "Train | 10/10 | Loss:0.5098 | MainLoss:0.2253 | SPLoss:2.8006 | CLSLoss:0.4479 | top1:91.4500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9318 | MainLoss:0.6477 | SPLoss:2.7968 | CLSLoss:0.4482 | top1:74.1383 | AUROC:0.8199\n",
      "Test | 161/10 | Loss:1.5229 | MainLoss:1.2387 | SPLoss:2.7968 | CLSLoss:0.4482 | top1:60.8567 | AUROC:0.7199\n",
      "\n",
      "Epoch: [347 | 1000] LR: 0.002991\n",
      "Train | 10/10 | Loss:0.5410 | MainLoss:0.2570 | SPLoss:2.7945 | CLSLoss:0.4485 | top1:90.6000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9292 | MainLoss:0.6457 | SPLoss:2.7896 | CLSLoss:0.4479 | top1:74.0695 | AUROC:0.8198\n",
      "Test | 161/10 | Loss:1.5326 | MainLoss:1.2491 | SPLoss:2.7896 | CLSLoss:0.4479 | top1:60.6636 | AUROC:0.7230\n",
      "\n",
      "Epoch: [348 | 1000] LR: 0.002985\n",
      "Train | 10/10 | Loss:0.5081 | MainLoss:0.2249 | SPLoss:2.7870 | CLSLoss:0.4483 | top1:91.0000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9289 | MainLoss:0.6460 | SPLoss:2.7836 | CLSLoss:0.4485 | top1:74.1547 | AUROC:0.8217\n",
      "Test | 161/10 | Loss:1.4797 | MainLoss:1.1969 | SPLoss:2.7836 | CLSLoss:0.4485 | top1:61.7757 | AUROC:0.7294\n",
      "\n",
      "Epoch: [349 | 1000] LR: 0.002980\n",
      "Train | 10/10 | Loss:0.5398 | MainLoss:0.2572 | SPLoss:2.7816 | CLSLoss:0.4486 | top1:89.9000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9240 | MainLoss:0.6416 | SPLoss:2.7785 | CLSLoss:0.4480 | top1:74.1743 | AUROC:0.8219\n",
      "Test | 161/10 | Loss:1.5091 | MainLoss:1.2268 | SPLoss:2.7785 | CLSLoss:0.4480 | top1:61.0685 | AUROC:0.7265\n",
      "\n",
      "Epoch: [350 | 1000] LR: 0.002975\n",
      "Train | 10/10 | Loss:0.5322 | MainLoss:0.2502 | SPLoss:2.7749 | CLSLoss:0.4480 | top1:90.3500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9254 | MainLoss:0.6437 | SPLoss:2.7716 | CLSLoss:0.4481 | top1:74.1448 | AUROC:0.8207\n",
      "Test | 161/10 | Loss:1.4781 | MainLoss:1.1965 | SPLoss:2.7716 | CLSLoss:0.4481 | top1:61.6729 | AUROC:0.7304\n",
      "\n",
      "Epoch: [351 | 1000] LR: 0.002969\n",
      "Train | 10/10 | Loss:0.5127 | MainLoss:0.2312 | SPLoss:2.7698 | CLSLoss:0.4482 | top1:91.1500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9206 | MainLoss:0.6394 | SPLoss:2.7671 | CLSLoss:0.4486 | top1:74.3349 | AUROC:0.8234\n",
      "Test | 161/10 | Loss:1.5333 | MainLoss:1.2521 | SPLoss:2.7671 | CLSLoss:0.4486 | top1:60.7321 | AUROC:0.7238\n",
      "\n",
      "Epoch: [352 | 1000] LR: 0.002964\n",
      "Train | 10/10 | Loss:0.5383 | MainLoss:0.2574 | SPLoss:2.7641 | CLSLoss:0.4484 | top1:89.7500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9187 | MainLoss:0.6382 | SPLoss:2.7609 | CLSLoss:0.4481 | top1:74.3578 | AUROC:0.8238\n",
      "Test | 161/10 | Loss:1.4835 | MainLoss:1.2029 | SPLoss:2.7609 | CLSLoss:0.4481 | top1:61.5171 | AUROC:0.7282\n",
      "\n",
      "Epoch: [353 | 1000] LR: 0.002958\n",
      "Train | 10/10 | Loss:0.5036 | MainLoss:0.2233 | SPLoss:2.7574 | CLSLoss:0.4485 | top1:91.2000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9178 | MainLoss:0.6380 | SPLoss:2.7539 | CLSLoss:0.4485 | top1:74.3283 | AUROC:0.8231\n",
      "Test | 161/10 | Loss:1.5215 | MainLoss:1.2416 | SPLoss:2.7539 | CLSLoss:0.4485 | top1:60.9128 | AUROC:0.7272\n",
      "\n",
      "Epoch: [354 | 1000] LR: 0.002952\n",
      "Train | 10/10 | Loss:0.4772 | MainLoss:0.1976 | SPLoss:2.7512 | CLSLoss:0.4491 | top1:93.1500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9232 | MainLoss:0.6440 | SPLoss:2.7474 | CLSLoss:0.4496 | top1:74.2759 | AUROC:0.8231\n",
      "Test | 161/10 | Loss:1.5217 | MainLoss:1.2425 | SPLoss:2.7474 | CLSLoss:0.4496 | top1:61.0810 | AUROC:0.7271\n",
      "\n",
      "Epoch: [355 | 1000] LR: 0.002947\n",
      "Train | 10/10 | Loss:0.5158 | MainLoss:0.2369 | SPLoss:2.7439 | CLSLoss:0.4499 | top1:90.6500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9228 | MainLoss:0.6442 | SPLoss:2.7408 | CLSLoss:0.4498 | top1:74.4037 | AUROC:0.8240\n",
      "Test | 161/10 | Loss:1.5747 | MainLoss:1.2961 | SPLoss:2.7408 | CLSLoss:0.4498 | top1:60.2087 | AUROC:0.7233\n",
      "\n",
      "Epoch: [356 | 1000] LR: 0.002941\n",
      "Train | 10/10 | Loss:0.4953 | MainLoss:0.2170 | SPLoss:2.7372 | CLSLoss:0.4499 | top1:91.8500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9239 | MainLoss:0.6460 | SPLoss:2.7341 | CLSLoss:0.4503 | top1:74.4921 | AUROC:0.8245\n",
      "Test | 161/10 | Loss:1.5603 | MainLoss:1.2824 | SPLoss:2.7341 | CLSLoss:0.4503 | top1:60.5639 | AUROC:0.7285\n",
      "\n",
      "Epoch: [357 | 1000] LR: 0.002936\n",
      "Train | 10/10 | Loss:0.5318 | MainLoss:0.2541 | SPLoss:2.7317 | CLSLoss:0.4500 | top1:90.5500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9183 | MainLoss:0.6410 | SPLoss:2.7284 | CLSLoss:0.4497 | top1:74.5937 | AUROC:0.8260\n",
      "Test | 161/10 | Loss:1.5361 | MainLoss:1.2587 | SPLoss:2.7284 | CLSLoss:0.4497 | top1:60.9720 | AUROC:0.7301\n",
      "\n",
      "Epoch: [358 | 1000] LR: 0.002930\n",
      "Train | 10/10 | Loss:0.4950 | MainLoss:0.2180 | SPLoss:2.7255 | CLSLoss:0.4501 | top1:92.3000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9173 | MainLoss:0.6405 | SPLoss:2.7226 | CLSLoss:0.4501 | top1:74.7346 | AUROC:0.8274\n",
      "Test | 161/10 | Loss:1.5157 | MainLoss:1.2389 | SPLoss:2.7226 | CLSLoss:0.4501 | top1:61.4611 | AUROC:0.7347\n",
      "\n",
      "Epoch: [359 | 1000] LR: 0.002925\n",
      "Train | 10/10 | Loss:0.5179 | MainLoss:0.2414 | SPLoss:2.7202 | CLSLoss:0.4504 | top1:91.4000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9158 | MainLoss:0.6397 | SPLoss:2.7161 | CLSLoss:0.4500 | top1:74.6035 | AUROC:0.8269\n",
      "Test | 161/10 | Loss:1.5256 | MainLoss:1.2495 | SPLoss:2.7161 | CLSLoss:0.4500 | top1:61.1464 | AUROC:0.7327\n",
      "\n",
      "Epoch: [360 | 1000] LR: 0.002919\n",
      "Train | 10/10 | Loss:0.4848 | MainLoss:0.2090 | SPLoss:2.7129 | CLSLoss:0.4501 | top1:92.2500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9166 | MainLoss:0.6412 | SPLoss:2.7096 | CLSLoss:0.4506 | top1:74.6691 | AUROC:0.8271\n",
      "Test | 161/10 | Loss:1.5395 | MainLoss:1.2640 | SPLoss:2.7096 | CLSLoss:0.4506 | top1:60.9284 | AUROC:0.7288\n",
      "\n",
      "Epoch: [361 | 1000] LR: 0.002914\n",
      "Train | 10/10 | Loss:0.5017 | MainLoss:0.2266 | SPLoss:2.7062 | CLSLoss:0.4505 | top1:91.5500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9160 | MainLoss:0.6412 | SPLoss:2.7023 | CLSLoss:0.4508 | top1:74.6953 | AUROC:0.8266\n",
      "Test | 161/10 | Loss:1.5440 | MainLoss:1.2693 | SPLoss:2.7023 | CLSLoss:0.4508 | top1:60.8006 | AUROC:0.7271\n",
      "\n",
      "Epoch: [362 | 1000] LR: 0.002908\n",
      "Train | 10/10 | Loss:0.5231 | MainLoss:0.2486 | SPLoss:2.7003 | CLSLoss:0.4507 | top1:90.0500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9136 | MainLoss:0.6395 | SPLoss:2.6966 | CLSLoss:0.4506 | top1:74.7772 | AUROC:0.8279\n",
      "Test | 161/10 | Loss:1.5639 | MainLoss:1.2898 | SPLoss:2.6966 | CLSLoss:0.4506 | top1:60.4642 | AUROC:0.7252\n",
      "\n",
      "Epoch: [363 | 1000] LR: 0.002902\n",
      "Train | 10/10 | Loss:0.4822 | MainLoss:0.2082 | SPLoss:2.6948 | CLSLoss:0.4507 | top1:92.5000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9169 | MainLoss:0.6432 | SPLoss:2.6921 | CLSLoss:0.4513 | top1:74.7412 | AUROC:0.8274\n",
      "Test | 161/10 | Loss:1.5700 | MainLoss:1.2963 | SPLoss:2.6921 | CLSLoss:0.4513 | top1:60.3271 | AUROC:0.7206\n",
      "\n",
      "Epoch: [364 | 1000] LR: 0.002897\n",
      "Train | 10/10 | Loss:0.4912 | MainLoss:0.2177 | SPLoss:2.6891 | CLSLoss:0.4512 | top1:91.8500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9155 | MainLoss:0.6425 | SPLoss:2.6853 | CLSLoss:0.4516 | top1:74.7903 | AUROC:0.8276\n",
      "Test | 161/10 | Loss:1.5539 | MainLoss:1.2809 | SPLoss:2.6853 | CLSLoss:0.4516 | top1:60.6916 | AUROC:0.7216\n",
      "\n",
      "Epoch: [365 | 1000] LR: 0.002891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 10/10 | Loss:0.5103 | MainLoss:0.2376 | SPLoss:2.6817 | CLSLoss:0.4513 | top1:91.1500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9131 | MainLoss:0.6407 | SPLoss:2.6784 | CLSLoss:0.4516 | top1:74.7641 | AUROC:0.8279\n",
      "Test | 161/10 | Loss:1.5532 | MainLoss:1.2808 | SPLoss:2.6784 | CLSLoss:0.4516 | top1:60.5171 | AUROC:0.7214\n",
      "\n",
      "Epoch: [366 | 1000] LR: 0.002886\n",
      "Train | 10/10 | Loss:0.4672 | MainLoss:0.1951 | SPLoss:2.6760 | CLSLoss:0.4519 | top1:93.3000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9181 | MainLoss:0.6462 | SPLoss:2.6733 | CLSLoss:0.4523 | top1:74.8362 | AUROC:0.8278\n",
      "Test | 161/10 | Loss:1.5610 | MainLoss:1.2892 | SPLoss:2.6733 | CLSLoss:0.4523 | top1:60.5389 | AUROC:0.7198\n",
      "\n",
      "Epoch: [367 | 1000] LR: 0.002880\n",
      "Train | 10/10 | Loss:0.4855 | MainLoss:0.2138 | SPLoss:2.6710 | CLSLoss:0.4521 | top1:92.0500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9189 | MainLoss:0.6476 | SPLoss:2.6678 | CLSLoss:0.4525 | top1:74.6396 | AUROC:0.8265\n",
      "Test | 161/10 | Loss:1.5194 | MainLoss:1.2481 | SPLoss:2.6678 | CLSLoss:0.4525 | top1:61.3956 | AUROC:0.7306\n",
      "\n",
      "Epoch: [368 | 1000] LR: 0.002874\n",
      "Train | 10/10 | Loss:0.5026 | MainLoss:0.2316 | SPLoss:2.6645 | CLSLoss:0.4526 | top1:91.4500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9160 | MainLoss:0.6453 | SPLoss:2.6617 | CLSLoss:0.4523 | top1:74.6986 | AUROC:0.8275\n",
      "Test | 161/10 | Loss:1.5151 | MainLoss:1.2444 | SPLoss:2.6617 | CLSLoss:0.4523 | top1:61.4798 | AUROC:0.7343\n",
      "\n",
      "Epoch: [369 | 1000] LR: 0.002869\n",
      "Train | 10/10 | Loss:0.4748 | MainLoss:0.2043 | SPLoss:2.6591 | CLSLoss:0.4525 | top1:92.2500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9177 | MainLoss:0.6475 | SPLoss:2.6563 | CLSLoss:0.4530 | top1:74.7706 | AUROC:0.8276\n",
      "Test | 161/10 | Loss:1.5175 | MainLoss:1.2473 | SPLoss:2.6563 | CLSLoss:0.4530 | top1:61.5234 | AUROC:0.7295\n",
      "\n",
      "Epoch: [370 | 1000] LR: 0.002863\n",
      "Train | 10/10 | Loss:0.4692 | MainLoss:0.1993 | SPLoss:2.6535 | CLSLoss:0.4535 | top1:92.7000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9169 | MainLoss:0.6472 | SPLoss:2.6513 | CLSLoss:0.4537 | top1:74.5937 | AUROC:0.8275\n",
      "Test | 161/10 | Loss:1.5147 | MainLoss:1.2451 | SPLoss:2.6513 | CLSLoss:0.4537 | top1:62.2399 | AUROC:0.8048\n",
      "\n",
      "Epoch: [371 | 1000] LR: 0.002857\n",
      "Train | 10/10 | Loss:0.4924 | MainLoss:0.2230 | SPLoss:2.6488 | CLSLoss:0.4539 | top1:91.3500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9189 | MainLoss:0.6499 | SPLoss:2.6444 | CLSLoss:0.4538 | top1:74.5085 | AUROC:0.8258\n",
      "Test | 161/10 | Loss:1.5047 | MainLoss:1.2357 | SPLoss:2.6444 | CLSLoss:0.4538 | top1:62.4143 | AUROC:0.8035\n",
      "\n",
      "Epoch: [372 | 1000] LR: 0.002852\n",
      "Train | 10/10 | Loss:0.4611 | MainLoss:0.1924 | SPLoss:2.6415 | CLSLoss:0.4542 | top1:93.2000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9208 | MainLoss:0.6524 | SPLoss:2.6393 | CLSLoss:0.4546 | top1:74.5544 | AUROC:0.8258\n",
      "Test | 161/10 | Loss:1.5181 | MainLoss:1.2496 | SPLoss:2.6393 | CLSLoss:0.4546 | top1:62.1994 | AUROC:0.8001\n",
      "\n",
      "Epoch: [373 | 1000] LR: 0.002846\n",
      "Train | 10/10 | Loss:0.5084 | MainLoss:0.2401 | SPLoss:2.6382 | CLSLoss:0.4544 | top1:91.0000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9173 | MainLoss:0.6491 | SPLoss:2.6363 | CLSLoss:0.4544 | top1:74.7346 | AUROC:0.8281\n",
      "Test | 161/10 | Loss:1.5353 | MainLoss:1.2672 | SPLoss:2.6363 | CLSLoss:0.4544 | top1:61.7539 | AUROC:0.7943\n",
      "\n",
      "Epoch: [374 | 1000] LR: 0.002840\n",
      "Train | 10/10 | Loss:0.5288 | MainLoss:0.2608 | SPLoss:2.6339 | CLSLoss:0.4541 | top1:89.9500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9099 | MainLoss:0.6422 | SPLoss:2.6314 | CLSLoss:0.4535 | top1:74.8820 | AUROC:0.8298\n",
      "Test | 161/10 | Loss:1.5097 | MainLoss:1.2421 | SPLoss:2.6314 | CLSLoss:0.4535 | top1:62.1059 | AUROC:0.7973\n",
      "\n",
      "Epoch: [375 | 1000] LR: 0.002834\n",
      "Train | 10/10 | Loss:0.4937 | MainLoss:0.2264 | SPLoss:2.6277 | CLSLoss:0.4534 | top1:91.7000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9089 | MainLoss:0.6419 | SPLoss:2.6243 | CLSLoss:0.4534 | top1:74.7641 | AUROC:0.8277\n",
      "Test | 161/10 | Loss:1.4895 | MainLoss:1.2226 | SPLoss:2.6243 | CLSLoss:0.4534 | top1:62.3676 | AUROC:0.7967\n",
      "\n",
      "Epoch: [376 | 1000] LR: 0.002829\n",
      "Train | 10/10 | Loss:0.4536 | MainLoss:0.1868 | SPLoss:2.6220 | CLSLoss:0.4541 | top1:93.1500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9121 | MainLoss:0.6457 | SPLoss:2.6190 | CLSLoss:0.4546 | top1:74.8296 | AUROC:0.8289\n",
      "Test | 161/10 | Loss:1.4958 | MainLoss:1.2294 | SPLoss:2.6190 | CLSLoss:0.4546 | top1:62.4299 | AUROC:0.7982\n",
      "\n",
      "Epoch: [377 | 1000] LR: 0.002823\n",
      "Train | 10/10 | Loss:0.4945 | MainLoss:0.2284 | SPLoss:2.6161 | CLSLoss:0.4544 | top1:91.7500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9126 | MainLoss:0.6469 | SPLoss:2.6120 | CLSLoss:0.4544 | top1:74.8329 | AUROC:0.8285\n",
      "Test | 161/10 | Loss:1.5478 | MainLoss:1.2821 | SPLoss:2.6120 | CLSLoss:0.4544 | top1:61.3769 | AUROC:0.7885\n",
      "\n",
      "Epoch: [378 | 1000] LR: 0.002817\n",
      "Train | 10/10 | Loss:0.4552 | MainLoss:0.1897 | SPLoss:2.6094 | CLSLoss:0.4549 | top1:93.0000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9163 | MainLoss:0.6511 | SPLoss:2.6065 | CLSLoss:0.4552 | top1:74.7018 | AUROC:0.8278\n",
      "Test | 161/10 | Loss:1.5275 | MainLoss:1.2623 | SPLoss:2.6065 | CLSLoss:0.4552 | top1:61.8567 | AUROC:0.7898\n",
      "\n",
      "Epoch: [379 | 1000] LR: 0.002812\n",
      "Train | 10/10 | Loss:0.4708 | MainLoss:0.2060 | SPLoss:2.6034 | CLSLoss:0.4554 | top1:92.5000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9162 | MainLoss:0.6515 | SPLoss:2.6012 | CLSLoss:0.4555 | top1:74.8132 | AUROC:0.8292\n",
      "Test | 161/10 | Loss:1.5291 | MainLoss:1.2644 | SPLoss:2.6012 | CLSLoss:0.4555 | top1:62.0249 | AUROC:0.7953\n",
      "\n",
      "Epoch: [380 | 1000] LR: 0.002806\n",
      "Train | 10/10 | Loss:0.4617 | MainLoss:0.1972 | SPLoss:2.5994 | CLSLoss:0.4555 | top1:93.0500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9186 | MainLoss:0.6543 | SPLoss:2.5967 | CLSLoss:0.4557 | top1:74.7477 | AUROC:0.8292\n",
      "Test | 161/10 | Loss:1.5083 | MainLoss:1.2441 | SPLoss:2.5967 | CLSLoss:0.4557 | top1:62.3956 | AUROC:0.7954\n",
      "\n",
      "Epoch: [381 | 1000] LR: 0.002800\n",
      "Train | 10/10 | Loss:0.4531 | MainLoss:0.1892 | SPLoss:2.5939 | CLSLoss:0.4560 | top1:93.2500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9213 | MainLoss:0.6577 | SPLoss:2.5906 | CLSLoss:0.4564 | top1:74.7870 | AUROC:0.8281\n",
      "Test | 161/10 | Loss:1.5463 | MainLoss:1.2827 | SPLoss:2.5906 | CLSLoss:0.4564 | top1:61.7850 | AUROC:0.7894\n",
      "\n",
      "Epoch: [382 | 1000] LR: 0.002794\n",
      "Train | 10/10 | Loss:0.4453 | MainLoss:0.1820 | SPLoss:2.5875 | CLSLoss:0.4568 | top1:93.8500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9244 | MainLoss:0.6614 | SPLoss:2.5841 | CLSLoss:0.4572 | top1:74.7936 | AUROC:0.8281\n",
      "Test | 161/10 | Loss:1.5557 | MainLoss:1.2928 | SPLoss:2.5841 | CLSLoss:0.4572 | top1:61.6636 | AUROC:0.7890\n",
      "\n",
      "Epoch: [383 | 1000] LR: 0.002789\n",
      "Train | 10/10 | Loss:0.4639 | MainLoss:0.2011 | SPLoss:2.5819 | CLSLoss:0.4572 | top1:92.3000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9232 | MainLoss:0.6607 | SPLoss:2.5798 | CLSLoss:0.4575 | top1:74.7084 | AUROC:0.8274\n",
      "Test | 161/10 | Loss:1.5443 | MainLoss:1.2817 | SPLoss:2.5798 | CLSLoss:0.4575 | top1:61.8785 | AUROC:0.7864\n",
      "\n",
      "Epoch: [384 | 1000] LR: 0.002783\n",
      "Train | 10/10 | Loss:0.4680 | MainLoss:0.2057 | SPLoss:2.5775 | CLSLoss:0.4571 | top1:92.8500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9253 | MainLoss:0.6632 | SPLoss:2.5745 | CLSLoss:0.4574 | top1:74.7543 | AUROC:0.8271\n",
      "Test | 161/10 | Loss:1.5068 | MainLoss:1.2447 | SPLoss:2.5745 | CLSLoss:0.4574 | top1:62.5421 | AUROC:0.7864\n",
      "\n",
      "Epoch: [385 | 1000] LR: 0.002777\n",
      "Train | 10/10 | Loss:0.4538 | MainLoss:0.1920 | SPLoss:2.5723 | CLSLoss:0.4575 | top1:93.4000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9246 | MainLoss:0.6631 | SPLoss:2.5699 | CLSLoss:0.4578 | top1:74.7903 | AUROC:0.8272\n",
      "Test | 161/10 | Loss:1.5265 | MainLoss:1.2649 | SPLoss:2.5699 | CLSLoss:0.4578 | top1:62.2368 | AUROC:0.7868\n",
      "\n",
      "Epoch: [386 | 1000] LR: 0.002771\n",
      "Train | 10/10 | Loss:0.4593 | MainLoss:0.1981 | SPLoss:2.5667 | CLSLoss:0.4581 | top1:92.8000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9274 | MainLoss:0.6666 | SPLoss:2.5628 | CLSLoss:0.4581 | top1:74.6134 | AUROC:0.8262\n",
      "Test | 161/10 | Loss:1.4935 | MainLoss:1.2326 | SPLoss:2.5628 | CLSLoss:0.4581 | top1:62.7726 | AUROC:0.7879\n",
      "\n",
      "Epoch: [387 | 1000] LR: 0.002765\n",
      "Train | 10/10 | Loss:0.4648 | MainLoss:0.2041 | SPLoss:2.5608 | CLSLoss:0.4581 | top1:91.9500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9200 | MainLoss:0.6596 | SPLoss:2.5578 | CLSLoss:0.4583 | top1:74.8657 | AUROC:0.8282\n",
      "Test | 161/10 | Loss:1.5303 | MainLoss:1.2699 | SPLoss:2.5578 | CLSLoss:0.4583 | top1:62.1495 | AUROC:0.7892\n",
      "\n",
      "Epoch: [388 | 1000] LR: 0.002760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 10/10 | Loss:0.4839 | MainLoss:0.2238 | SPLoss:2.5553 | CLSLoss:0.4581 | top1:91.2000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9156 | MainLoss:0.6558 | SPLoss:2.5515 | CLSLoss:0.4579 | top1:74.7838 | AUROC:0.8281\n",
      "Test | 161/10 | Loss:1.5618 | MainLoss:1.3021 | SPLoss:2.5515 | CLSLoss:0.4579 | top1:61.3832 | AUROC:0.7879\n",
      "\n",
      "Epoch: [389 | 1000] LR: 0.002754\n",
      "Train | 10/10 | Loss:0.4461 | MainLoss:0.1866 | SPLoss:2.5494 | CLSLoss:0.4584 | top1:93.4000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9168 | MainLoss:0.6575 | SPLoss:2.5468 | CLSLoss:0.4587 | top1:75.0918 | AUROC:0.8297\n",
      "Test | 161/10 | Loss:1.4863 | MainLoss:1.2270 | SPLoss:2.5468 | CLSLoss:0.4587 | top1:62.8598 | AUROC:0.7951\n",
      "\n",
      "Epoch: [390 | 1000] LR: 0.002748\n",
      "Train | 10/10 | Loss:0.4601 | MainLoss:0.2011 | SPLoss:2.5443 | CLSLoss:0.4590 | top1:92.5000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9165 | MainLoss:0.6578 | SPLoss:2.5412 | CLSLoss:0.4590 | top1:75.0524 | AUROC:0.8293\n",
      "Test | 161/10 | Loss:1.5039 | MainLoss:1.2452 | SPLoss:2.5412 | CLSLoss:0.4590 | top1:62.5109 | AUROC:0.7934\n",
      "\n",
      "Epoch: [391 | 1000] LR: 0.002742\n",
      "Train | 10/10 | Loss:0.4628 | MainLoss:0.2044 | SPLoss:2.5379 | CLSLoss:0.4591 | top1:92.1000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9153 | MainLoss:0.6571 | SPLoss:2.5357 | CLSLoss:0.4589 | top1:75.1114 | AUROC:0.8301\n",
      "Test | 161/10 | Loss:1.5287 | MainLoss:1.2705 | SPLoss:2.5357 | CLSLoss:0.4589 | top1:62.1059 | AUROC:0.7904\n",
      "\n",
      "Epoch: [392 | 1000] LR: 0.002736\n",
      "Train | 10/10 | Loss:0.4256 | MainLoss:0.1678 | SPLoss:2.5327 | CLSLoss:0.4595 | top1:94.0500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9194 | MainLoss:0.6618 | SPLoss:2.5302 | CLSLoss:0.4599 | top1:75.0033 | AUROC:0.8292\n",
      "Test | 161/10 | Loss:1.5059 | MainLoss:1.2483 | SPLoss:2.5302 | CLSLoss:0.4599 | top1:62.6604 | AUROC:0.7923\n",
      "\n",
      "Epoch: [393 | 1000] LR: 0.002730\n",
      "Train | 10/10 | Loss:0.4413 | MainLoss:0.1838 | SPLoss:2.5285 | CLSLoss:0.4599 | top1:93.2000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9190 | MainLoss:0.6619 | SPLoss:2.5252 | CLSLoss:0.4605 | top1:75.0000 | AUROC:0.8298\n",
      "Test | 161/10 | Loss:1.5227 | MainLoss:1.2656 | SPLoss:2.5252 | CLSLoss:0.4605 | top1:62.4050 | AUROC:0.7879\n",
      "\n",
      "Epoch: [394 | 1000] LR: 0.002725\n",
      "Train | 10/10 | Loss:0.4869 | MainLoss:0.2300 | SPLoss:2.5227 | CLSLoss:0.4606 | top1:91.3500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9162 | MainLoss:0.6595 | SPLoss:2.5208 | CLSLoss:0.4599 | top1:74.7641 | AUROC:0.8297\n",
      "Test | 161/10 | Loss:1.5828 | MainLoss:1.3261 | SPLoss:2.5208 | CLSLoss:0.4599 | top1:60.9907 | AUROC:0.7928\n",
      "\n",
      "Epoch: [395 | 1000] LR: 0.002719\n",
      "Train | 10/10 | Loss:0.4623 | MainLoss:0.2059 | SPLoss:2.5176 | CLSLoss:0.4600 | top1:92.4000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9125 | MainLoss:0.6565 | SPLoss:2.5141 | CLSLoss:0.4600 | top1:74.9345 | AUROC:0.8294\n",
      "Test | 161/10 | Loss:1.4977 | MainLoss:1.2417 | SPLoss:2.5141 | CLSLoss:0.4600 | top1:62.6760 | AUROC:0.7957\n",
      "\n",
      "Epoch: [396 | 1000] LR: 0.002713\n",
      "Train | 10/10 | Loss:0.4797 | MainLoss:0.2240 | SPLoss:2.5115 | CLSLoss:0.4598 | top1:92.1000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9115 | MainLoss:0.6561 | SPLoss:2.5085 | CLSLoss:0.4594 | top1:74.8395 | AUROC:0.8290\n",
      "Test | 161/10 | Loss:1.4791 | MainLoss:1.2237 | SPLoss:2.5085 | CLSLoss:0.4594 | top1:62.9938 | AUROC:0.7945\n",
      "\n",
      "Epoch: [397 | 1000] LR: 0.002707\n",
      "Train | 10/10 | Loss:0.4618 | MainLoss:0.2066 | SPLoss:2.5063 | CLSLoss:0.4595 | top1:92.2500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9080 | MainLoss:0.6531 | SPLoss:2.5030 | CLSLoss:0.4595 | top1:74.8886 | AUROC:0.8290\n",
      "Test | 161/10 | Loss:1.5243 | MainLoss:1.2694 | SPLoss:2.5030 | CLSLoss:0.4595 | top1:62.1371 | AUROC:0.7893\n",
      "\n",
      "Epoch: [398 | 1000] LR: 0.002701\n",
      "Train | 10/10 | Loss:0.4621 | MainLoss:0.2075 | SPLoss:2.5000 | CLSLoss:0.4596 | top1:92.7000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9098 | MainLoss:0.6556 | SPLoss:2.4969 | CLSLoss:0.4596 | top1:74.8001 | AUROC:0.8281\n",
      "Test | 161/10 | Loss:1.5433 | MainLoss:1.2891 | SPLoss:2.4969 | CLSLoss:0.4596 | top1:61.7383 | AUROC:0.7872\n",
      "\n",
      "Epoch: [399 | 1000] LR: 0.002695\n",
      "Train | 10/10 | Loss:0.4485 | MainLoss:0.1944 | SPLoss:2.4949 | CLSLoss:0.4599 | top1:92.8500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9086 | MainLoss:0.6548 | SPLoss:2.4925 | CLSLoss:0.4600 | top1:74.7674 | AUROC:0.8284\n",
      "Test | 161/10 | Loss:1.5205 | MainLoss:1.2666 | SPLoss:2.4925 | CLSLoss:0.4600 | top1:62.1184 | AUROC:0.7884\n",
      "\n",
      "Epoch: [400 | 1000] LR: 0.002689\n",
      "Train | 10/10 | Loss:0.4419 | MainLoss:0.1883 | SPLoss:2.4902 | CLSLoss:0.4605 | top1:93.4000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9108 | MainLoss:0.6574 | SPLoss:2.4879 | CLSLoss:0.4605 | top1:74.7117 | AUROC:0.8286\n",
      "Test | 161/10 | Loss:1.4771 | MainLoss:1.2237 | SPLoss:2.4879 | CLSLoss:0.4605 | top1:62.9875 | AUROC:0.7947\n",
      "\n",
      "Epoch: [401 | 1000] LR: 0.002683\n",
      "Train | 10/10 | Loss:0.4968 | MainLoss:0.2436 | SPLoss:2.4860 | CLSLoss:0.4599 | top1:90.6000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9034 | MainLoss:0.6505 | SPLoss:2.4833 | CLSLoss:0.4596 | top1:74.7870 | AUROC:0.8293\n",
      "Test | 161/10 | Loss:1.4850 | MainLoss:1.2321 | SPLoss:2.4833 | CLSLoss:0.4596 | top1:62.6854 | AUROC:0.7883\n",
      "\n",
      "Epoch: [402 | 1000] LR: 0.002677\n",
      "Train | 10/10 | Loss:0.4747 | MainLoss:0.2220 | SPLoss:2.4810 | CLSLoss:0.4597 | top1:92.2000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9043 | MainLoss:0.6520 | SPLoss:2.4771 | CLSLoss:0.4594 | top1:74.7641 | AUROC:0.8281\n",
      "Test | 161/10 | Loss:1.5202 | MainLoss:1.2679 | SPLoss:2.4771 | CLSLoss:0.4594 | top1:61.9564 | AUROC:0.7860\n",
      "\n",
      "Epoch: [403 | 1000] LR: 0.002672\n",
      "Train | 10/10 | Loss:0.4511 | MainLoss:0.1991 | SPLoss:2.4748 | CLSLoss:0.4594 | top1:92.5500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9034 | MainLoss:0.6516 | SPLoss:2.4726 | CLSLoss:0.4596 | top1:74.6953 | AUROC:0.8275\n",
      "Test | 161/10 | Loss:1.4945 | MainLoss:1.2427 | SPLoss:2.4726 | CLSLoss:0.4596 | top1:62.3146 | AUROC:0.7821\n",
      "\n",
      "Epoch: [404 | 1000] LR: 0.002666\n",
      "Train | 10/10 | Loss:0.4322 | MainLoss:0.1806 | SPLoss:2.4702 | CLSLoss:0.4599 | top1:93.1500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9055 | MainLoss:0.6541 | SPLoss:2.4673 | CLSLoss:0.4605 | top1:74.8329 | AUROC:0.8275\n",
      "Test | 161/10 | Loss:1.4667 | MainLoss:1.2154 | SPLoss:2.4673 | CLSLoss:0.4605 | top1:63.0249 | AUROC:0.7861\n",
      "\n",
      "Epoch: [405 | 1000] LR: 0.002660\n",
      "Train | 10/10 | Loss:0.5054 | MainLoss:0.2541 | SPLoss:2.4664 | CLSLoss:0.4601 | top1:89.9500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9024 | MainLoss:0.6513 | SPLoss:2.4645 | CLSLoss:0.4597 | top1:74.7412 | AUROC:0.8286\n",
      "Test | 161/10 | Loss:1.5172 | MainLoss:1.2661 | SPLoss:2.4645 | CLSLoss:0.4597 | top1:61.8941 | AUROC:0.7817\n",
      "\n",
      "Epoch: [406 | 1000] LR: 0.002654\n",
      "Train | 10/10 | Loss:0.4534 | MainLoss:0.2025 | SPLoss:2.4626 | CLSLoss:0.4598 | top1:92.2500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9007 | MainLoss:0.6502 | SPLoss:2.4597 | CLSLoss:0.4601 | top1:74.8984 | AUROC:0.8286\n",
      "Test | 161/10 | Loss:1.5030 | MainLoss:1.2524 | SPLoss:2.4597 | CLSLoss:0.4601 | top1:62.1215 | AUROC:0.7830\n",
      "\n",
      "Epoch: [407 | 1000] LR: 0.002648\n",
      "Train | 10/10 | Loss:0.4549 | MainLoss:0.2047 | SPLoss:2.4566 | CLSLoss:0.4605 | top1:92.7000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9045 | MainLoss:0.6545 | SPLoss:2.4532 | CLSLoss:0.4604 | top1:74.7018 | AUROC:0.8279\n",
      "Test | 161/10 | Loss:1.4241 | MainLoss:1.1742 | SPLoss:2.4532 | CLSLoss:0.4604 | top1:63.6106 | AUROC:0.7927\n",
      "\n",
      "Epoch: [408 | 1000] LR: 0.002642\n",
      "Train | 10/10 | Loss:0.4581 | MainLoss:0.2084 | SPLoss:2.4508 | CLSLoss:0.4606 | top1:92.6500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9045 | MainLoss:0.6551 | SPLoss:2.4482 | CLSLoss:0.4607 | top1:74.7117 | AUROC:0.8274\n",
      "Test | 161/10 | Loss:1.4467 | MainLoss:1.1973 | SPLoss:2.4482 | CLSLoss:0.4607 | top1:63.2056 | AUROC:0.7891\n",
      "\n",
      "Epoch: [409 | 1000] LR: 0.002636\n",
      "Train | 10/10 | Loss:0.4883 | MainLoss:0.2390 | SPLoss:2.4467 | CLSLoss:0.4605 | top1:91.1000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9023 | MainLoss:0.6532 | SPLoss:2.4454 | CLSLoss:0.4601 | top1:74.7870 | AUROC:0.8272\n",
      "Test | 161/10 | Loss:1.4815 | MainLoss:1.2323 | SPLoss:2.4454 | CLSLoss:0.4601 | top1:62.4984 | AUROC:0.7878\n",
      "\n",
      "Epoch: [410 | 1000] LR: 0.002630\n",
      "Train | 10/10 | Loss:0.4600 | MainLoss:0.2110 | SPLoss:2.4443 | CLSLoss:0.4603 | top1:92.0000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9057 | MainLoss:0.6568 | SPLoss:2.4438 | CLSLoss:0.4604 | top1:74.7117 | AUROC:0.8264\n",
      "Test | 161/10 | Loss:1.4621 | MainLoss:1.2131 | SPLoss:2.4438 | CLSLoss:0.4604 | top1:62.7882 | AUROC:0.7803\n",
      "\n",
      "Epoch: [411 | 1000] LR: 0.002624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 10/10 | Loss:0.4445 | MainLoss:0.1957 | SPLoss:2.4417 | CLSLoss:0.4606 | top1:92.8500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9017 | MainLoss:0.6532 | SPLoss:2.4391 | CLSLoss:0.4609 | top1:74.9574 | AUROC:0.8296\n",
      "Test | 161/10 | Loss:1.4403 | MainLoss:1.1918 | SPLoss:2.4391 | CLSLoss:0.4609 | top1:63.2586 | AUROC:0.7887\n",
      "\n",
      "Epoch: [412 | 1000] LR: 0.002618\n",
      "Train | 10/10 | Loss:0.4488 | MainLoss:0.2005 | SPLoss:2.4374 | CLSLoss:0.4609 | top1:91.9000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9019 | MainLoss:0.6539 | SPLoss:2.4346 | CLSLoss:0.4613 | top1:74.9083 | AUROC:0.8287\n",
      "Test | 161/10 | Loss:1.4364 | MainLoss:1.1883 | SPLoss:2.4346 | CLSLoss:0.4613 | top1:63.3458 | AUROC:0.7909\n",
      "\n",
      "Epoch: [413 | 1000] LR: 0.002612\n",
      "Train | 10/10 | Loss:0.4670 | MainLoss:0.2191 | SPLoss:2.4334 | CLSLoss:0.4616 | top1:91.3000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9127 | MainLoss:0.6649 | SPLoss:2.4317 | CLSLoss:0.4613 | top1:74.6527 | AUROC:0.8276\n",
      "Test | 161/10 | Loss:1.5331 | MainLoss:1.2854 | SPLoss:2.4317 | CLSLoss:0.4613 | top1:61.8069 | AUROC:0.7750\n",
      "\n",
      "Epoch: [414 | 1000] LR: 0.002606\n",
      "Train | 10/10 | Loss:0.4696 | MainLoss:0.2219 | SPLoss:2.4301 | CLSLoss:0.4613 | top1:91.8000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9063 | MainLoss:0.6589 | SPLoss:2.4281 | CLSLoss:0.4610 | top1:74.8395 | AUROC:0.8265\n",
      "Test | 161/10 | Loss:1.4380 | MainLoss:1.1905 | SPLoss:2.4281 | CLSLoss:0.4610 | top1:63.4112 | AUROC:0.7806\n",
      "\n",
      "Epoch: [415 | 1000] LR: 0.002600\n",
      "Train | 10/10 | Loss:0.4552 | MainLoss:0.2080 | SPLoss:2.4260 | CLSLoss:0.4613 | top1:91.9000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9016 | MainLoss:0.6547 | SPLoss:2.4230 | CLSLoss:0.4613 | top1:74.8984 | AUROC:0.8283\n",
      "Test | 161/10 | Loss:1.4985 | MainLoss:1.2516 | SPLoss:2.4230 | CLSLoss:0.4613 | top1:62.3707 | AUROC:0.7824\n",
      "\n",
      "Epoch: [416 | 1000] LR: 0.002594\n",
      "Train | 10/10 | Loss:0.4426 | MainLoss:0.1958 | SPLoss:2.4219 | CLSLoss:0.4616 | top1:92.8500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9017 | MainLoss:0.6552 | SPLoss:2.4188 | CLSLoss:0.4617 | top1:75.0098 | AUROC:0.8297\n",
      "Test | 161/10 | Loss:1.4653 | MainLoss:1.2188 | SPLoss:2.4188 | CLSLoss:0.4617 | top1:63.1122 | AUROC:0.7855\n",
      "\n",
      "Epoch: [417 | 1000] LR: 0.002588\n",
      "Train | 10/10 | Loss:0.4319 | MainLoss:0.1856 | SPLoss:2.4169 | CLSLoss:0.4619 | top1:93.6000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9037 | MainLoss:0.6577 | SPLoss:2.4141 | CLSLoss:0.4622 | top1:75.0524 | AUROC:0.8292\n",
      "Test | 161/10 | Loss:1.4659 | MainLoss:1.2198 | SPLoss:2.4141 | CLSLoss:0.4622 | top1:63.2056 | AUROC:0.7864\n",
      "\n",
      "Epoch: [418 | 1000] LR: 0.002582\n",
      "Train | 10/10 | Loss:0.4576 | MainLoss:0.2118 | SPLoss:2.4115 | CLSLoss:0.4620 | top1:91.9500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9030 | MainLoss:0.6575 | SPLoss:2.4089 | CLSLoss:0.4620 | top1:75.0000 | AUROC:0.8292\n",
      "Test | 161/10 | Loss:1.4544 | MainLoss:1.2089 | SPLoss:2.4089 | CLSLoss:0.4620 | top1:63.3676 | AUROC:0.7901\n",
      "\n",
      "Epoch: [419 | 1000] LR: 0.002576\n",
      "Train | 10/10 | Loss:0.4613 | MainLoss:0.2160 | SPLoss:2.4071 | CLSLoss:0.4621 | top1:91.8500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9009 | MainLoss:0.6558 | SPLoss:2.4048 | CLSLoss:0.4619 | top1:75.0950 | AUROC:0.8296\n",
      "Test | 161/10 | Loss:1.4444 | MainLoss:1.1993 | SPLoss:2.4048 | CLSLoss:0.4619 | top1:63.4704 | AUROC:0.7916\n",
      "\n",
      "Epoch: [420 | 1000] LR: 0.002570\n",
      "Train | 10/10 | Loss:0.4692 | MainLoss:0.2244 | SPLoss:2.4025 | CLSLoss:0.4616 | top1:91.5500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.8952 | MainLoss:0.6506 | SPLoss:2.3996 | CLSLoss:0.4614 | top1:75.0000 | AUROC:0.8310\n",
      "Test | 161/10 | Loss:1.4535 | MainLoss:1.2089 | SPLoss:2.3996 | CLSLoss:0.4614 | top1:63.1931 | AUROC:0.7883\n",
      "\n",
      "Epoch: [421 | 1000] LR: 0.002564\n",
      "Train | 10/10 | Loss:0.4471 | MainLoss:0.2026 | SPLoss:2.3980 | CLSLoss:0.4617 | top1:92.1500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.8915 | MainLoss:0.6473 | SPLoss:2.3962 | CLSLoss:0.4619 | top1:75.0033 | AUROC:0.8304\n",
      "Test | 161/10 | Loss:1.4817 | MainLoss:1.2375 | SPLoss:2.3962 | CLSLoss:0.4619 | top1:62.4050 | AUROC:0.7884\n",
      "\n",
      "Epoch: [422 | 1000] LR: 0.002558\n",
      "Train | 10/10 | Loss:0.4080 | MainLoss:0.1640 | SPLoss:2.3945 | CLSLoss:0.4624 | top1:94.0500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9030 | MainLoss:0.6592 | SPLoss:2.3921 | CLSLoss:0.4630 | top1:74.9705 | AUROC:0.8299\n",
      "Test | 161/10 | Loss:1.5222 | MainLoss:1.2784 | SPLoss:2.3921 | CLSLoss:0.4630 | top1:62.0498 | AUROC:0.7779\n",
      "\n",
      "Epoch: [423 | 1000] LR: 0.002552\n",
      "Train | 10/10 | Loss:0.4345 | MainLoss:0.1908 | SPLoss:2.3904 | CLSLoss:0.4633 | top1:93.0500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9045 | MainLoss:0.6611 | SPLoss:2.3882 | CLSLoss:0.4634 | top1:74.9509 | AUROC:0.8312\n",
      "Test | 161/10 | Loss:1.5460 | MainLoss:1.3025 | SPLoss:2.3882 | CLSLoss:0.4634 | top1:61.7227 | AUROC:0.7803\n",
      "\n",
      "Epoch: [424 | 1000] LR: 0.002546\n",
      "Train | 10/10 | Loss:0.4175 | MainLoss:0.1742 | SPLoss:2.3867 | CLSLoss:0.4638 | top1:94.0000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9072 | MainLoss:0.6642 | SPLoss:2.3839 | CLSLoss:0.4641 | top1:75.1409 | AUROC:0.8303\n",
      "Test | 161/10 | Loss:1.5186 | MainLoss:1.2755 | SPLoss:2.3839 | CLSLoss:0.4641 | top1:62.2897 | AUROC:0.7800\n",
      "\n",
      "Epoch: [425 | 1000] LR: 0.002540\n",
      "Train | 10/10 | Loss:0.4546 | MainLoss:0.2119 | SPLoss:2.3812 | CLSLoss:0.4642 | top1:92.6500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9062 | MainLoss:0.6636 | SPLoss:2.3795 | CLSLoss:0.4641 | top1:75.1278 | AUROC:0.8300\n",
      "Test | 161/10 | Loss:1.5074 | MainLoss:1.2648 | SPLoss:2.3795 | CLSLoss:0.4641 | top1:62.4673 | AUROC:0.7805\n",
      "\n",
      "Epoch: [426 | 1000] LR: 0.002534\n",
      "Train | 10/10 | Loss:0.4678 | MainLoss:0.2255 | SPLoss:2.3770 | CLSLoss:0.4638 | top1:91.5000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9025 | MainLoss:0.6604 | SPLoss:2.3745 | CLSLoss:0.4635 | top1:74.9902 | AUROC:0.8294\n",
      "Test | 161/10 | Loss:1.5014 | MainLoss:1.2593 | SPLoss:2.3745 | CLSLoss:0.4635 | top1:62.5109 | AUROC:0.7826\n",
      "\n",
      "Epoch: [427 | 1000] LR: 0.002528\n",
      "Train | 10/10 | Loss:0.4526 | MainLoss:0.2106 | SPLoss:2.3731 | CLSLoss:0.4634 | top1:92.1000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.8997 | MainLoss:0.6580 | SPLoss:2.3710 | CLSLoss:0.4633 | top1:75.0557 | AUROC:0.8298\n",
      "Test | 161/10 | Loss:1.4994 | MainLoss:1.2577 | SPLoss:2.3710 | CLSLoss:0.4633 | top1:62.4486 | AUROC:0.7826\n",
      "\n",
      "Epoch: [428 | 1000] LR: 0.002522\n",
      "Train | 10/10 | Loss:0.4358 | MainLoss:0.1943 | SPLoss:2.3690 | CLSLoss:0.4635 | top1:93.5500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9006 | MainLoss:0.6592 | SPLoss:2.3669 | CLSLoss:0.4635 | top1:75.1180 | AUROC:0.8302\n",
      "Test | 161/10 | Loss:1.5168 | MainLoss:1.2755 | SPLoss:2.3669 | CLSLoss:0.4635 | top1:62.2305 | AUROC:0.7847\n",
      "\n",
      "Epoch: [429 | 1000] LR: 0.002516\n",
      "Train | 10/10 | Loss:0.4370 | MainLoss:0.1958 | SPLoss:2.3651 | CLSLoss:0.4640 | top1:93.3500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9040 | MainLoss:0.6630 | SPLoss:2.3631 | CLSLoss:0.4638 | top1:75.0328 | AUROC:0.8294\n",
      "Test | 161/10 | Loss:1.5171 | MainLoss:1.2762 | SPLoss:2.3631 | CLSLoss:0.4638 | top1:62.1495 | AUROC:0.7824\n",
      "\n",
      "Epoch: [430 | 1000] LR: 0.002510\n",
      "Train | 10/10 | Loss:0.4285 | MainLoss:0.1877 | SPLoss:2.3615 | CLSLoss:0.4640 | top1:92.9000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9052 | MainLoss:0.6646 | SPLoss:2.3593 | CLSLoss:0.4642 | top1:75.0000 | AUROC:0.8287\n",
      "Test | 161/10 | Loss:1.5330 | MainLoss:1.2924 | SPLoss:2.3593 | CLSLoss:0.4642 | top1:61.9034 | AUROC:0.7771\n",
      "\n",
      "Epoch: [431 | 1000] LR: 0.002503\n",
      "Train | 10/10 | Loss:0.4447 | MainLoss:0.2042 | SPLoss:2.3579 | CLSLoss:0.4642 | top1:92.5000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9067 | MainLoss:0.6664 | SPLoss:2.3568 | CLSLoss:0.4642 | top1:74.9869 | AUROC:0.8295\n",
      "Test | 161/10 | Loss:1.5663 | MainLoss:1.3259 | SPLoss:2.3568 | CLSLoss:0.4642 | top1:61.3614 | AUROC:0.7760\n",
      "\n",
      "Epoch: [432 | 1000] LR: 0.002497\n",
      "Train | 10/10 | Loss:0.4006 | MainLoss:0.1605 | SPLoss:2.3547 | CLSLoss:0.4644 | top1:94.1500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9078 | MainLoss:0.6679 | SPLoss:2.3521 | CLSLoss:0.4651 | top1:74.9902 | AUROC:0.8292\n",
      "Test | 161/10 | Loss:1.5087 | MainLoss:1.2689 | SPLoss:2.3521 | CLSLoss:0.4651 | top1:62.3676 | AUROC:0.7787\n",
      "\n",
      "Epoch: [433 | 1000] LR: 0.002491\n",
      "Train | 10/10 | Loss:0.4095 | MainLoss:0.1699 | SPLoss:2.3497 | CLSLoss:0.4654 | top1:94.2000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9082 | MainLoss:0.6689 | SPLoss:2.3464 | CLSLoss:0.4658 | top1:75.1147 | AUROC:0.8297\n",
      "Test | 161/10 | Loss:1.5232 | MainLoss:1.2839 | SPLoss:2.3464 | CLSLoss:0.4658 | top1:62.1807 | AUROC:0.7791\n",
      "\n",
      "Epoch: [434 | 1000] LR: 0.002485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 10/10 | Loss:0.4421 | MainLoss:0.2030 | SPLoss:2.3439 | CLSLoss:0.4660 | top1:92.5500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9009 | MainLoss:0.6620 | SPLoss:2.3421 | CLSLoss:0.4657 | top1:74.9640 | AUROC:0.8297\n",
      "Test | 161/10 | Loss:1.5116 | MainLoss:1.2727 | SPLoss:2.3421 | CLSLoss:0.4657 | top1:62.2056 | AUROC:0.7828\n",
      "\n",
      "Epoch: [435 | 1000] LR: 0.002479\n",
      "Train | 10/10 | Loss:0.4107 | MainLoss:0.1720 | SPLoss:2.3404 | CLSLoss:0.4661 | top1:93.8500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9095 | MainLoss:0.6710 | SPLoss:2.3386 | CLSLoss:0.4663 | top1:74.8788 | AUROC:0.8281\n",
      "Test | 161/10 | Loss:1.5444 | MainLoss:1.3059 | SPLoss:2.3386 | CLSLoss:0.4663 | top1:61.8879 | AUROC:0.7766\n",
      "\n",
      "Epoch: [436 | 1000] LR: 0.002473\n",
      "Train | 10/10 | Loss:0.4644 | MainLoss:0.2260 | SPLoss:2.3376 | CLSLoss:0.4660 | top1:91.4000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9012 | MainLoss:0.6629 | SPLoss:2.3362 | CLSLoss:0.4657 | top1:75.0164 | AUROC:0.8296\n",
      "Test | 161/10 | Loss:1.5063 | MainLoss:1.2681 | SPLoss:2.3362 | CLSLoss:0.4657 | top1:62.4424 | AUROC:0.7799\n",
      "\n",
      "Epoch: [437 | 1000] LR: 0.002467\n",
      "Train | 10/10 | Loss:0.4521 | MainLoss:0.2139 | SPLoss:2.3349 | CLSLoss:0.4656 | top1:92.3500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9024 | MainLoss:0.6644 | SPLoss:2.3332 | CLSLoss:0.4655 | top1:74.9869 | AUROC:0.8281\n",
      "Test | 161/10 | Loss:1.5185 | MainLoss:1.2805 | SPLoss:2.3332 | CLSLoss:0.4655 | top1:62.1838 | AUROC:0.7754\n",
      "\n",
      "Epoch: [438 | 1000] LR: 0.002461\n",
      "Train | 10/10 | Loss:0.4378 | MainLoss:0.2000 | SPLoss:2.3311 | CLSLoss:0.4656 | top1:92.5500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9013 | MainLoss:0.6638 | SPLoss:2.3289 | CLSLoss:0.4657 | top1:75.0033 | AUROC:0.8287\n",
      "Test | 161/10 | Loss:1.5147 | MainLoss:1.2771 | SPLoss:2.3289 | CLSLoss:0.4657 | top1:62.3146 | AUROC:0.7752\n",
      "\n",
      "Epoch: [439 | 1000] LR: 0.002455\n",
      "Train | 10/10 | Loss:0.4790 | MainLoss:0.2417 | SPLoss:2.3269 | CLSLoss:0.4652 | top1:90.6000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.8936 | MainLoss:0.6565 | SPLoss:2.3253 | CLSLoss:0.4648 | top1:75.1343 | AUROC:0.8309\n",
      "Test | 161/10 | Loss:1.5500 | MainLoss:1.3128 | SPLoss:2.3253 | CLSLoss:0.4648 | top1:61.5576 | AUROC:0.7767\n",
      "\n",
      "Epoch: [440 | 1000] LR: 0.002449\n",
      "Train | 10/10 | Loss:0.4027 | MainLoss:0.1657 | SPLoss:2.3233 | CLSLoss:0.4653 | top1:94.8000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.8977 | MainLoss:0.6610 | SPLoss:2.3207 | CLSLoss:0.4657 | top1:75.0623 | AUROC:0.8305\n",
      "Test | 161/10 | Loss:1.5529 | MainLoss:1.3162 | SPLoss:2.3207 | CLSLoss:0.4657 | top1:61.6542 | AUROC:0.7772\n",
      "\n",
      "Epoch: [441 | 1000] LR: 0.002442\n",
      "Train | 10/10 | Loss:0.4446 | MainLoss:0.2081 | SPLoss:2.3181 | CLSLoss:0.4653 | top1:92.9000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.8961 | MainLoss:0.6599 | SPLoss:2.3150 | CLSLoss:0.4654 | top1:75.0623 | AUROC:0.8304\n",
      "Test | 161/10 | Loss:1.5441 | MainLoss:1.3079 | SPLoss:2.3150 | CLSLoss:0.4654 | top1:61.7508 | AUROC:0.7770\n",
      "\n",
      "Epoch: [442 | 1000] LR: 0.002436\n",
      "Train | 10/10 | Loss:0.4183 | MainLoss:0.1824 | SPLoss:2.3129 | CLSLoss:0.4656 | top1:93.3000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.8982 | MainLoss:0.6625 | SPLoss:2.3108 | CLSLoss:0.4658 | top1:74.9705 | AUROC:0.8300\n",
      "Test | 161/10 | Loss:1.5426 | MainLoss:1.3069 | SPLoss:2.3108 | CLSLoss:0.4658 | top1:61.8442 | AUROC:0.7787\n",
      "\n",
      "Epoch: [443 | 1000] LR: 0.002430\n",
      "Train | 10/10 | Loss:0.4403 | MainLoss:0.2048 | SPLoss:2.3086 | CLSLoss:0.4660 | top1:92.4000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9011 | MainLoss:0.6658 | SPLoss:2.3065 | CLSLoss:0.4657 | top1:74.9115 | AUROC:0.8289\n",
      "Test | 161/10 | Loss:1.4791 | MainLoss:1.2438 | SPLoss:2.3065 | CLSLoss:0.4657 | top1:62.9969 | AUROC:0.7807\n",
      "\n",
      "Epoch: [444 | 1000] LR: 0.002424\n",
      "Train | 10/10 | Loss:0.4309 | MainLoss:0.1958 | SPLoss:2.3044 | CLSLoss:0.4657 | top1:93.6000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.8975 | MainLoss:0.6626 | SPLoss:2.3021 | CLSLoss:0.4659 | top1:74.9738 | AUROC:0.8295\n",
      "Test | 161/10 | Loss:1.5279 | MainLoss:1.2930 | SPLoss:2.3021 | CLSLoss:0.4659 | top1:62.0841 | AUROC:0.7783\n",
      "\n",
      "Epoch: [445 | 1000] LR: 0.002418\n",
      "Train | 10/10 | Loss:0.4093 | MainLoss:0.1746 | SPLoss:2.3002 | CLSLoss:0.4663 | top1:93.8500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9006 | MainLoss:0.6661 | SPLoss:2.2983 | CLSLoss:0.4666 | top1:74.9541 | AUROC:0.8302\n",
      "Test | 161/10 | Loss:1.5206 | MainLoss:1.2861 | SPLoss:2.2983 | CLSLoss:0.4666 | top1:62.3925 | AUROC:0.7795\n",
      "\n",
      "Epoch: [446 | 1000] LR: 0.002412\n",
      "Train | 10/10 | Loss:0.4509 | MainLoss:0.2164 | SPLoss:2.2984 | CLSLoss:0.4665 | top1:91.3500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.8967 | MainLoss:0.6622 | SPLoss:2.2982 | CLSLoss:0.4662 | top1:74.9836 | AUROC:0.8303\n",
      "Test | 161/10 | Loss:1.4831 | MainLoss:1.2486 | SPLoss:2.2982 | CLSLoss:0.4662 | top1:62.7009 | AUROC:0.7777\n",
      "\n",
      "Epoch: [447 | 1000] LR: 0.002406\n",
      "Train | 10/10 | Loss:0.4318 | MainLoss:0.1975 | SPLoss:2.2965 | CLSLoss:0.4662 | top1:92.8000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.8888 | MainLoss:0.6546 | SPLoss:2.2949 | CLSLoss:0.4663 | top1:75.1737 | AUROC:0.8312\n",
      "Test | 161/10 | Loss:1.5184 | MainLoss:1.2843 | SPLoss:2.2949 | CLSLoss:0.4663 | top1:61.9938 | AUROC:0.7814\n",
      "\n",
      "Epoch: [448 | 1000] LR: 0.002399\n",
      "Train | 10/10 | Loss:0.4339 | MainLoss:0.1999 | SPLoss:2.2934 | CLSLoss:0.4662 | top1:93.0000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.8960 | MainLoss:0.6622 | SPLoss:2.2914 | CLSLoss:0.4663 | top1:75.0721 | AUROC:0.8295\n",
      "Test | 161/10 | Loss:1.5347 | MainLoss:1.3009 | SPLoss:2.2914 | CLSLoss:0.4663 | top1:61.8660 | AUROC:0.7756\n",
      "\n",
      "Epoch: [449 | 1000] LR: 0.002393\n",
      "Train | 10/10 | Loss:0.4526 | MainLoss:0.2189 | SPLoss:2.2903 | CLSLoss:0.4661 | top1:92.1000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.8954 | MainLoss:0.6619 | SPLoss:2.2884 | CLSLoss:0.4660 | top1:74.9672 | AUROC:0.8290\n",
      "Test | 161/10 | Loss:1.4957 | MainLoss:1.2622 | SPLoss:2.2884 | CLSLoss:0.4660 | top1:62.5514 | AUROC:0.7814\n",
      "\n",
      "Epoch: [450 | 1000] LR: 0.002387\n",
      "Train | 10/10 | Loss:0.4744 | MainLoss:0.2310 | SPLoss:2.3879 | CLSLoss:0.4658 | top1:90.8000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.8991 | MainLoss:0.6544 | SPLoss:2.4005 | CLSLoss:0.4655 | top1:75.1769 | AUROC:0.8312\n",
      "Test | 161/10 | Loss:1.5228 | MainLoss:1.2781 | SPLoss:2.4005 | CLSLoss:0.4655 | top1:62.2056 | AUROC:0.7828\n",
      "\n",
      "Epoch: [451 | 1000] LR: 0.002381\n",
      "Train | 10/10 | Loss:0.4348 | MainLoss:0.1902 | SPLoss:2.3993 | CLSLoss:0.4657 | top1:93.0500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9008 | MainLoss:0.6564 | SPLoss:2.3976 | CLSLoss:0.4658 | top1:75.0524 | AUROC:0.8289\n",
      "Test | 161/10 | Loss:1.5324 | MainLoss:1.2880 | SPLoss:2.3976 | CLSLoss:0.4658 | top1:61.8941 | AUROC:0.7781\n",
      "\n",
      "Epoch: [452 | 1000] LR: 0.002375\n",
      "Train | 10/10 | Loss:0.4084 | MainLoss:0.1642 | SPLoss:2.3959 | CLSLoss:0.4662 | top1:94.6500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9052 | MainLoss:0.6612 | SPLoss:2.3937 | CLSLoss:0.4666 | top1:75.0328 | AUROC:0.8298\n",
      "Test | 161/10 | Loss:1.5276 | MainLoss:1.2836 | SPLoss:2.3937 | CLSLoss:0.4666 | top1:62.1994 | AUROC:0.7836\n",
      "\n",
      "Epoch: [453 | 1000] LR: 0.002369\n",
      "Train | 10/10 | Loss:0.4289 | MainLoss:0.1850 | SPLoss:2.3918 | CLSLoss:0.4666 | top1:93.1500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9068 | MainLoss:0.6632 | SPLoss:2.3896 | CLSLoss:0.4671 | top1:75.0295 | AUROC:0.8297\n",
      "Test | 161/10 | Loss:1.5306 | MainLoss:1.2870 | SPLoss:2.3896 | CLSLoss:0.4671 | top1:62.1869 | AUROC:0.7839\n",
      "\n",
      "Epoch: [454 | 1000] LR: 0.002362\n",
      "Train | 10/10 | Loss:0.4381 | MainLoss:0.1947 | SPLoss:2.3878 | CLSLoss:0.4671 | top1:92.7500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9073 | MainLoss:0.6641 | SPLoss:2.3851 | CLSLoss:0.4673 | top1:74.9279 | AUROC:0.8291\n",
      "Test | 161/10 | Loss:1.5415 | MainLoss:1.2983 | SPLoss:2.3851 | CLSLoss:0.4673 | top1:61.9439 | AUROC:0.7840\n",
      "\n",
      "Epoch: [455 | 1000] LR: 0.002356\n",
      "Train | 10/10 | Loss:0.4148 | MainLoss:0.1719 | SPLoss:2.3828 | CLSLoss:0.4677 | top1:93.7000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9077 | MainLoss:0.6649 | SPLoss:2.3809 | CLSLoss:0.4679 | top1:75.0098 | AUROC:0.8294\n",
      "Test | 161/10 | Loss:1.5316 | MainLoss:1.2888 | SPLoss:2.3809 | CLSLoss:0.4679 | top1:62.1776 | AUROC:0.7878\n",
      "\n",
      "Epoch: [456 | 1000] LR: 0.002350\n",
      "Train | 10/10 | Loss:0.4565 | MainLoss:0.2139 | SPLoss:2.3793 | CLSLoss:0.4677 | top1:92.2500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9079 | MainLoss:0.6655 | SPLoss:2.3767 | CLSLoss:0.4677 | top1:74.8231 | AUROC:0.8287\n",
      "Test | 161/10 | Loss:1.5542 | MainLoss:1.3118 | SPLoss:2.3767 | CLSLoss:0.4677 | top1:61.7695 | AUROC:0.7805\n",
      "\n",
      "Epoch: [457 | 1000] LR: 0.002344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 10/10 | Loss:0.4325 | MainLoss:0.1904 | SPLoss:2.3746 | CLSLoss:0.4680 | top1:93.1000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9095 | MainLoss:0.6676 | SPLoss:2.3716 | CLSLoss:0.4680 | top1:74.8558 | AUROC:0.8280\n",
      "Test | 161/10 | Loss:1.5740 | MainLoss:1.3322 | SPLoss:2.3716 | CLSLoss:0.4680 | top1:61.3738 | AUROC:0.7737\n",
      "\n",
      "Epoch: [458 | 1000] LR: 0.002338\n",
      "Train | 10/10 | Loss:0.4289 | MainLoss:0.1873 | SPLoss:2.3700 | CLSLoss:0.4681 | top1:93.1500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9080 | MainLoss:0.6664 | SPLoss:2.3683 | CLSLoss:0.4683 | top1:74.9738 | AUROC:0.8288\n",
      "Test | 161/10 | Loss:1.5081 | MainLoss:1.2666 | SPLoss:2.3683 | CLSLoss:0.4683 | top1:62.6199 | AUROC:0.7878\n",
      "\n",
      "Epoch: [459 | 1000] LR: 0.002331\n",
      "Train | 10/10 | Loss:0.4637 | MainLoss:0.2224 | SPLoss:2.3661 | CLSLoss:0.4682 | top1:91.8500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9041 | MainLoss:0.6630 | SPLoss:2.3637 | CLSLoss:0.4678 | top1:74.9345 | AUROC:0.8300\n",
      "Test | 161/10 | Loss:1.5415 | MainLoss:1.3005 | SPLoss:2.3637 | CLSLoss:0.4678 | top1:62.0405 | AUROC:0.7873\n",
      "\n",
      "Epoch: [460 | 1000] LR: 0.002325\n",
      "Train | 10/10 | Loss:0.4170 | MainLoss:0.1761 | SPLoss:2.3625 | CLSLoss:0.4681 | top1:93.6500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9053 | MainLoss:0.6646 | SPLoss:2.3610 | CLSLoss:0.4683 | top1:75.0393 | AUROC:0.8295\n",
      "Test | 161/10 | Loss:1.5203 | MainLoss:1.2796 | SPLoss:2.3610 | CLSLoss:0.4683 | top1:62.4766 | AUROC:0.7856\n",
      "\n",
      "Epoch: [461 | 1000] LR: 0.002319\n",
      "Train | 10/10 | Loss:0.4384 | MainLoss:0.1980 | SPLoss:2.3578 | CLSLoss:0.4682 | top1:93.0500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9073 | MainLoss:0.6670 | SPLoss:2.3557 | CLSLoss:0.4682 | top1:74.8395 | AUROC:0.8275\n",
      "Test | 161/10 | Loss:1.5063 | MainLoss:1.2660 | SPLoss:2.3557 | CLSLoss:0.4682 | top1:62.9097 | AUROC:0.8061\n",
      "\n",
      "Epoch: [462 | 1000] LR: 0.002313\n",
      "Train | 10/10 | Loss:0.4360 | MainLoss:0.1959 | SPLoss:2.3546 | CLSLoss:0.4685 | top1:92.8000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9086 | MainLoss:0.6687 | SPLoss:2.3525 | CLSLoss:0.4686 | top1:74.7575 | AUROC:0.8279\n",
      "Test | 161/10 | Loss:1.5321 | MainLoss:1.2922 | SPLoss:2.3525 | CLSLoss:0.4686 | top1:62.4361 | AUROC:0.8035\n",
      "\n",
      "Epoch: [463 | 1000] LR: 0.002307\n",
      "Train | 10/10 | Loss:0.4186 | MainLoss:0.1788 | SPLoss:2.3513 | CLSLoss:0.4688 | top1:93.4500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9085 | MainLoss:0.6688 | SPLoss:2.3496 | CLSLoss:0.4690 | top1:74.9050 | AUROC:0.8290\n",
      "Test | 161/10 | Loss:1.4931 | MainLoss:1.2534 | SPLoss:2.3496 | CLSLoss:0.4690 | top1:63.0997 | AUROC:0.8050\n",
      "\n",
      "Epoch: [464 | 1000] LR: 0.002300\n",
      "Train | 10/10 | Loss:0.4608 | MainLoss:0.2213 | SPLoss:2.3483 | CLSLoss:0.4689 | top1:91.7000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9068 | MainLoss:0.6675 | SPLoss:2.3466 | CLSLoss:0.4687 | top1:74.9115 | AUROC:0.8295\n",
      "Test | 161/10 | Loss:1.4817 | MainLoss:1.2424 | SPLoss:2.3466 | CLSLoss:0.4687 | top1:63.2430 | AUROC:0.8058\n",
      "\n",
      "Epoch: [465 | 1000] LR: 0.002294\n",
      "Train | 10/10 | Loss:0.4451 | MainLoss:0.2060 | SPLoss:2.3443 | CLSLoss:0.4683 | top1:92.8500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9027 | MainLoss:0.6638 | SPLoss:2.3417 | CLSLoss:0.4684 | top1:74.9443 | AUROC:0.8296\n",
      "Test | 161/10 | Loss:1.5022 | MainLoss:1.2633 | SPLoss:2.3417 | CLSLoss:0.4684 | top1:62.8349 | AUROC:0.8037\n",
      "\n",
      "Epoch: [466 | 1000] LR: 0.002288\n",
      "Train | 10/10 | Loss:0.4156 | MainLoss:0.1769 | SPLoss:2.3400 | CLSLoss:0.4687 | top1:94.2000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9052 | MainLoss:0.6667 | SPLoss:2.3380 | CLSLoss:0.4689 | top1:75.0066 | AUROC:0.8298\n",
      "Test | 161/10 | Loss:1.4919 | MainLoss:1.2534 | SPLoss:2.3380 | CLSLoss:0.4689 | top1:63.1495 | AUROC:0.8050\n",
      "\n",
      "Epoch: [467 | 1000] LR: 0.002282\n",
      "Train | 10/10 | Loss:0.4328 | MainLoss:0.1945 | SPLoss:2.3363 | CLSLoss:0.4692 | top1:92.9500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9045 | MainLoss:0.6664 | SPLoss:2.3341 | CLSLoss:0.4690 | top1:74.8952 | AUROC:0.8295\n",
      "Test | 161/10 | Loss:1.4879 | MainLoss:1.2498 | SPLoss:2.3341 | CLSLoss:0.4690 | top1:63.1931 | AUROC:0.8107\n",
      "\n",
      "Epoch: [468 | 1000] LR: 0.002276\n",
      "Train | 10/10 | Loss:0.4282 | MainLoss:0.1902 | SPLoss:2.3325 | CLSLoss:0.4692 | top1:92.5000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9049 | MainLoss:0.6671 | SPLoss:2.3307 | CLSLoss:0.4693 | top1:75.0557 | AUROC:0.8301\n",
      "Test | 161/10 | Loss:1.5334 | MainLoss:1.2957 | SPLoss:2.3307 | CLSLoss:0.4693 | top1:62.5016 | AUROC:0.8077\n",
      "\n",
      "Epoch: [469 | 1000] LR: 0.002269\n",
      "Train | 10/10 | Loss:0.4397 | MainLoss:0.2021 | SPLoss:2.3298 | CLSLoss:0.4695 | top1:92.4000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9027 | MainLoss:0.6652 | SPLoss:2.3281 | CLSLoss:0.4693 | top1:75.1212 | AUROC:0.8311\n",
      "Test | 161/10 | Loss:1.5605 | MainLoss:1.3230 | SPLoss:2.3281 | CLSLoss:0.4693 | top1:61.9969 | AUROC:0.8024\n",
      "\n",
      "Epoch: [470 | 1000] LR: 0.002263\n",
      "Train | 10/10 | Loss:0.4392 | MainLoss:0.2018 | SPLoss:2.3274 | CLSLoss:0.4693 | top1:92.3500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.8979 | MainLoss:0.6606 | SPLoss:2.3263 | CLSLoss:0.4693 | top1:75.1212 | AUROC:0.8314\n",
      "Test | 161/10 | Loss:1.5141 | MainLoss:1.2768 | SPLoss:2.3263 | CLSLoss:0.4693 | top1:62.6542 | AUROC:0.8049\n",
      "\n",
      "Epoch: [471 | 1000] LR: 0.002257\n",
      "Train | 10/10 | Loss:0.4353 | MainLoss:0.1981 | SPLoss:2.3251 | CLSLoss:0.4693 | top1:92.8000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.8982 | MainLoss:0.6612 | SPLoss:2.3235 | CLSLoss:0.4693 | top1:75.1671 | AUROC:0.8311\n",
      "Test | 161/10 | Loss:1.5287 | MainLoss:1.2917 | SPLoss:2.3235 | CLSLoss:0.4693 | top1:62.4299 | AUROC:0.8022\n",
      "\n",
      "Epoch: [472 | 1000] LR: 0.002251\n",
      "Train | 10/10 | Loss:0.4408 | MainLoss:0.2038 | SPLoss:2.3229 | CLSLoss:0.4693 | top1:92.3500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.8968 | MainLoss:0.6601 | SPLoss:2.3206 | CLSLoss:0.4692 | top1:75.0131 | AUROC:0.8306\n",
      "Test | 161/10 | Loss:1.4728 | MainLoss:1.2360 | SPLoss:2.3206 | CLSLoss:0.4692 | top1:63.3520 | AUROC:0.8061\n",
      "\n",
      "Epoch: [473 | 1000] LR: 0.002244\n",
      "Train | 10/10 | Loss:0.4619 | MainLoss:0.2253 | SPLoss:2.3190 | CLSLoss:0.4692 | top1:91.2500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.8976 | MainLoss:0.6612 | SPLoss:2.3169 | CLSLoss:0.4688 | top1:75.0590 | AUROC:0.8312\n",
      "Test | 161/10 | Loss:1.5506 | MainLoss:1.3142 | SPLoss:2.3169 | CLSLoss:0.4688 | top1:61.8785 | AUROC:0.8005\n",
      "\n",
      "Epoch: [474 | 1000] LR: 0.002238\n",
      "Train | 10/10 | Loss:0.4350 | MainLoss:0.1988 | SPLoss:2.3155 | CLSLoss:0.4690 | top1:92.5500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.8941 | MainLoss:0.6580 | SPLoss:2.3143 | CLSLoss:0.4690 | top1:75.1900 | AUROC:0.8316\n",
      "Test | 161/10 | Loss:1.5251 | MainLoss:1.2890 | SPLoss:2.3143 | CLSLoss:0.4690 | top1:62.3676 | AUROC:0.7991\n",
      "\n",
      "Epoch: [475 | 1000] LR: 0.002232\n",
      "Train | 10/10 | Loss:0.4765 | MainLoss:0.2405 | SPLoss:2.3131 | CLSLoss:0.4689 | top1:90.5000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.8885 | MainLoss:0.6525 | SPLoss:2.3128 | CLSLoss:0.4683 | top1:75.1868 | AUROC:0.8321\n",
      "Test | 161/10 | Loss:1.5203 | MainLoss:1.2844 | SPLoss:2.3128 | CLSLoss:0.4683 | top1:62.3115 | AUROC:0.8010\n",
      "\n",
      "Epoch: [476 | 1000] LR: 0.002226\n",
      "Train | 10/10 | Loss:0.4725 | MainLoss:0.2367 | SPLoss:2.3114 | CLSLoss:0.4680 | top1:90.7500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.8830 | MainLoss:0.6474 | SPLoss:2.3099 | CLSLoss:0.4678 | top1:75.1999 | AUROC:0.8317\n",
      "Test | 161/10 | Loss:1.4869 | MainLoss:1.2513 | SPLoss:2.3099 | CLSLoss:0.4678 | top1:62.8692 | AUROC:0.8057\n",
      "\n",
      "Epoch: [477 | 1000] LR: 0.002219\n",
      "Train | 10/10 | Loss:0.4090 | MainLoss:0.1736 | SPLoss:2.3077 | CLSLoss:0.4680 | top1:93.6000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.8873 | MainLoss:0.6521 | SPLoss:2.3050 | CLSLoss:0.4684 | top1:75.1999 | AUROC:0.8310\n",
      "Test | 161/10 | Loss:1.5057 | MainLoss:1.2705 | SPLoss:2.3050 | CLSLoss:0.4684 | top1:62.6012 | AUROC:0.7994\n",
      "\n",
      "Epoch: [478 | 1000] LR: 0.002213\n",
      "Train | 10/10 | Loss:0.4351 | MainLoss:0.2001 | SPLoss:2.3034 | CLSLoss:0.4683 | top1:93.1000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.8891 | MainLoss:0.6542 | SPLoss:2.3023 | CLSLoss:0.4685 | top1:75.3506 | AUROC:0.8319\n",
      "Test | 161/10 | Loss:1.5012 | MainLoss:1.2663 | SPLoss:2.3023 | CLSLoss:0.4685 | top1:62.8162 | AUROC:0.8041\n",
      "\n",
      "Epoch: [479 | 1000] LR: 0.002207\n",
      "Train | 10/10 | Loss:0.4123 | MainLoss:0.1775 | SPLoss:2.3010 | CLSLoss:0.4687 | top1:93.3000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.8930 | MainLoss:0.6583 | SPLoss:2.3003 | CLSLoss:0.4691 | top1:75.2883 | AUROC:0.8320\n",
      "Test | 161/10 | Loss:1.5246 | MainLoss:1.2899 | SPLoss:2.3003 | CLSLoss:0.4691 | top1:62.4393 | AUROC:0.8063\n",
      "\n",
      "Epoch: [480 | 1000] LR: 0.002201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 10/10 | Loss:0.4029 | MainLoss:0.1684 | SPLoss:2.2981 | CLSLoss:0.4695 | top1:94.2000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.8939 | MainLoss:0.6597 | SPLoss:2.2956 | CLSLoss:0.4698 | top1:75.3113 | AUROC:0.8321\n",
      "Test | 161/10 | Loss:1.5038 | MainLoss:1.2695 | SPLoss:2.2956 | CLSLoss:0.4698 | top1:62.9252 | AUROC:0.8062\n",
      "\n",
      "Epoch: [481 | 1000] LR: 0.002194\n",
      "Train | 10/10 | Loss:0.4021 | MainLoss:0.1681 | SPLoss:2.2938 | CLSLoss:0.4703 | top1:94.3000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.8989 | MainLoss:0.6649 | SPLoss:2.2928 | CLSLoss:0.4704 | top1:75.1999 | AUROC:0.8324\n",
      "Test | 161/10 | Loss:1.4720 | MainLoss:1.2380 | SPLoss:2.2928 | CLSLoss:0.4704 | top1:63.5607 | AUROC:0.8045\n",
      "\n",
      "Epoch: [482 | 1000] LR: 0.002188\n",
      "Train | 10/10 | Loss:0.4405 | MainLoss:0.2067 | SPLoss:2.2909 | CLSLoss:0.4704 | top1:92.6500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.8961 | MainLoss:0.6625 | SPLoss:2.2889 | CLSLoss:0.4702 | top1:75.2457 | AUROC:0.8316\n",
      "Test | 161/10 | Loss:1.4997 | MainLoss:1.2661 | SPLoss:2.2889 | CLSLoss:0.4702 | top1:62.9564 | AUROC:0.8001\n",
      "\n",
      "Epoch: [483 | 1000] LR: 0.002182\n",
      "Train | 10/10 | Loss:0.4042 | MainLoss:0.1708 | SPLoss:2.2870 | CLSLoss:0.4705 | top1:93.8500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.8976 | MainLoss:0.6644 | SPLoss:2.2850 | CLSLoss:0.4706 | top1:75.1507 | AUROC:0.8310\n",
      "Test | 161/10 | Loss:1.4979 | MainLoss:1.2647 | SPLoss:2.2850 | CLSLoss:0.4706 | top1:63.0031 | AUROC:0.8010\n",
      "\n",
      "Epoch: [484 | 1000] LR: 0.002176\n",
      "Train | 10/10 | Loss:0.4425 | MainLoss:0.2095 | SPLoss:2.2831 | CLSLoss:0.4705 | top1:92.8000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.8930 | MainLoss:0.6603 | SPLoss:2.2805 | CLSLoss:0.4703 | top1:75.2490 | AUROC:0.8312\n",
      "Test | 161/10 | Loss:1.5151 | MainLoss:1.2824 | SPLoss:2.2805 | CLSLoss:0.4703 | top1:62.5483 | AUROC:0.8014\n",
      "\n",
      "Epoch: [485 | 1000] LR: 0.002169\n",
      "Train | 10/10 | Loss:0.4378 | MainLoss:0.2052 | SPLoss:2.2794 | CLSLoss:0.4702 | top1:92.4000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9035 | MainLoss:0.6711 | SPLoss:2.2773 | CLSLoss:0.4701 | top1:74.7346 | AUROC:0.8259\n",
      "Test | 161/10 | Loss:1.4003 | MainLoss:1.1679 | SPLoss:2.2773 | CLSLoss:0.4701 | top1:65.0156 | AUROC:0.8368\n",
      "\n",
      "Epoch: [486 | 1000] LR: 0.002163\n",
      "Train | 10/10 | Loss:0.4365 | MainLoss:0.2041 | SPLoss:2.2763 | CLSLoss:0.4702 | top1:92.2500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.9077 | MainLoss:0.6756 | SPLoss:2.2747 | CLSLoss:0.4702 | top1:74.6396 | AUROC:0.8247\n",
      "Test | 161/10 | Loss:1.3478 | MainLoss:1.1156 | SPLoss:2.2747 | CLSLoss:0.4702 | top1:66.0872 | AUROC:0.8296\n",
      "\n",
      "Epoch: [487 | 1000] LR: 0.002157\n",
      "Train | 10/10 | Loss:0.4692 | MainLoss:0.2370 | SPLoss:2.2748 | CLSLoss:0.4701 | top1:90.6000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.8912 | MainLoss:0.6589 | SPLoss:2.2761 | CLSLoss:0.4696 | top1:74.8624 | AUROC:0.8291\n",
      "Test | 161/10 | Loss:1.3316 | MainLoss:1.0993 | SPLoss:2.2761 | CLSLoss:0.4696 | top1:66.0062 | AUROC:0.8340\n",
      "\n",
      "Epoch: [488 | 1000] LR: 0.002151\n",
      "Train | 10/10 | Loss:0.4308 | MainLoss:0.1986 | SPLoss:2.2755 | CLSLoss:0.4695 | top1:92.5500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.8866 | MainLoss:0.6544 | SPLoss:2.2753 | CLSLoss:0.4697 | top1:75.0000 | AUROC:0.8302\n",
      "Test | 161/10 | Loss:1.3773 | MainLoss:1.1450 | SPLoss:2.2753 | CLSLoss:0.4697 | top1:65.1153 | AUROC:0.8306\n",
      "\n",
      "Epoch: [489 | 1000] LR: 0.002144\n",
      "Train | 10/10 | Loss:0.3937 | MainLoss:0.1616 | SPLoss:2.2738 | CLSLoss:0.4702 | top1:94.3000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.8945 | MainLoss:0.6625 | SPLoss:2.2727 | CLSLoss:0.4708 | top1:75.0426 | AUROC:0.8296\n",
      "Test | 161/10 | Loss:1.4304 | MainLoss:1.1984 | SPLoss:2.2727 | CLSLoss:0.4708 | top1:64.1963 | AUROC:0.8251\n",
      "\n",
      "Epoch: [490 | 1000] LR: 0.002138\n",
      "Train | 10/10 | Loss:0.4580 | MainLoss:0.2261 | SPLoss:2.2717 | CLSLoss:0.4706 | top1:91.3500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.8925 | MainLoss:0.6607 | SPLoss:2.2706 | CLSLoss:0.4703 | top1:74.9345 | AUROC:0.8300\n",
      "Test | 161/10 | Loss:1.3794 | MainLoss:1.1476 | SPLoss:2.2706 | CLSLoss:0.4703 | top1:65.1807 | AUROC:0.8246\n",
      "\n",
      "Epoch: [491 | 1000] LR: 0.002132\n",
      "Train | 10/10 | Loss:0.4351 | MainLoss:0.2034 | SPLoss:2.2697 | CLSLoss:0.4704 | top1:92.7500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.8908 | MainLoss:0.6593 | SPLoss:2.2676 | CLSLoss:0.4704 | top1:75.0197 | AUROC:0.8296\n",
      "Test | 161/10 | Loss:1.4334 | MainLoss:1.2019 | SPLoss:2.2676 | CLSLoss:0.4704 | top1:64.0810 | AUROC:0.8233\n",
      "\n",
      "Epoch: [492 | 1000] LR: 0.002126\n",
      "Train | 10/10 | Loss:0.4428 | MainLoss:0.2114 | SPLoss:2.2671 | CLSLoss:0.4703 | top1:92.1500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.8876 | MainLoss:0.6563 | SPLoss:2.2660 | CLSLoss:0.4701 | top1:74.9214 | AUROC:0.8291\n",
      "Test | 161/10 | Loss:1.4078 | MainLoss:1.1764 | SPLoss:2.2660 | CLSLoss:0.4701 | top1:64.4798 | AUROC:0.8223\n",
      "\n",
      "Epoch: [493 | 1000] LR: 0.002119\n",
      "Train | 10/10 | Loss:0.4464 | MainLoss:0.2152 | SPLoss:2.2649 | CLSLoss:0.4701 | top1:91.7500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.8900 | MainLoss:0.6589 | SPLoss:2.2640 | CLSLoss:0.4702 | top1:74.8886 | AUROC:0.8293\n",
      "Test | 161/10 | Loss:1.4324 | MainLoss:1.2013 | SPLoss:2.2640 | CLSLoss:0.4702 | top1:64.0187 | AUROC:0.8180\n",
      "\n",
      "Epoch: [494 | 1000] LR: 0.002113\n",
      "Train | 10/10 | Loss:0.4129 | MainLoss:0.1818 | SPLoss:2.2635 | CLSLoss:0.4706 | top1:93.1500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.8971 | MainLoss:0.6662 | SPLoss:2.2618 | CLSLoss:0.4708 | top1:75.0000 | AUROC:0.8292\n",
      "Test | 161/10 | Loss:1.4698 | MainLoss:1.2389 | SPLoss:2.2618 | CLSLoss:0.4708 | top1:63.5140 | AUROC:0.8118\n",
      "\n",
      "Epoch: [495 | 1000] LR: 0.002107\n",
      "Train | 10/10 | Loss:0.4216 | MainLoss:0.1908 | SPLoss:2.2608 | CLSLoss:0.4711 | top1:92.9500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.8982 | MainLoss:0.6676 | SPLoss:2.2587 | CLSLoss:0.4710 | top1:74.9115 | AUROC:0.8288\n",
      "Test | 161/10 | Loss:1.4375 | MainLoss:1.2069 | SPLoss:2.2587 | CLSLoss:0.4710 | top1:64.2274 | AUROC:0.8128\n",
      "\n",
      "Epoch: [496 | 1000] LR: 0.002100\n",
      "Train | 10/10 | Loss:0.4208 | MainLoss:0.1903 | SPLoss:2.2578 | CLSLoss:0.4711 | top1:93.3500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.8932 | MainLoss:0.6628 | SPLoss:2.2566 | CLSLoss:0.4713 | top1:74.9803 | AUROC:0.8293\n",
      "Test | 161/10 | Loss:1.4364 | MainLoss:1.2061 | SPLoss:2.2566 | CLSLoss:0.4713 | top1:64.0592 | AUROC:0.8147\n",
      "\n",
      "Epoch: [497 | 1000] LR: 0.002094\n",
      "Train | 10/10 | Loss:0.4236 | MainLoss:0.1934 | SPLoss:2.2553 | CLSLoss:0.4713 | top1:92.9000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.8928 | MainLoss:0.6627 | SPLoss:2.2537 | CLSLoss:0.4716 | top1:75.0229 | AUROC:0.8303\n",
      "Test | 161/10 | Loss:1.4350 | MainLoss:1.2049 | SPLoss:2.2537 | CLSLoss:0.4716 | top1:64.1651 | AUROC:0.8143\n",
      "\n",
      "Epoch: [498 | 1000] LR: 0.002088\n",
      "Train | 10/10 | Loss:0.4339 | MainLoss:0.2040 | SPLoss:2.2522 | CLSLoss:0.4717 | top1:93.0000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.8944 | MainLoss:0.6647 | SPLoss:2.2500 | CLSLoss:0.4715 | top1:74.9574 | AUROC:0.8296\n",
      "Test | 161/10 | Loss:1.4618 | MainLoss:1.2321 | SPLoss:2.2500 | CLSLoss:0.4715 | top1:63.6417 | AUROC:0.8126\n",
      "\n",
      "Epoch: [499 | 1000] LR: 0.002082\n",
      "Train | 10/10 | Loss:0.4167 | MainLoss:0.1871 | SPLoss:2.2492 | CLSLoss:0.4715 | top1:93.7000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.8942 | MainLoss:0.6647 | SPLoss:2.2476 | CLSLoss:0.4717 | top1:75.0229 | AUROC:0.8302\n",
      "Test | 161/10 | Loss:1.4276 | MainLoss:1.1981 | SPLoss:2.2476 | CLSLoss:0.4717 | top1:64.3178 | AUROC:0.8142\n",
      "\n",
      "Epoch: [500 | 1000] LR: 0.002075\n",
      "Train | 10/10 | Loss:0.4266 | MainLoss:0.1972 | SPLoss:2.2466 | CLSLoss:0.4718 | top1:92.1500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.8922 | MainLoss:0.6630 | SPLoss:2.2452 | CLSLoss:0.4718 | top1:75.0491 | AUROC:0.8310\n",
      "Test | 161/10 | Loss:1.4148 | MainLoss:1.1856 | SPLoss:2.2452 | CLSLoss:0.4718 | top1:64.6137 | AUROC:0.8234\n",
      "\n",
      "Epoch: [501 | 1000] LR: 0.002069\n",
      "Train | 10/10 | Loss:0.4251 | MainLoss:0.1960 | SPLoss:2.2442 | CLSLoss:0.4722 | top1:93.0000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.8974 | MainLoss:0.6683 | SPLoss:2.2441 | CLSLoss:0.4722 | top1:74.8984 | AUROC:0.8297\n",
      "Test | 161/10 | Loss:1.3618 | MainLoss:1.1327 | SPLoss:2.2441 | CLSLoss:0.4722 | top1:65.6324 | AUROC:0.8240\n",
      "\n",
      "Epoch: [502 | 1000] LR: 0.000206\n",
      "Train | 10/10 | Loss:0.4536 | MainLoss:0.2245 | SPLoss:2.2439 | CLSLoss:0.4722 | top1:91.4000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.8943 | MainLoss:0.6653 | SPLoss:2.2437 | CLSLoss:0.4721 | top1:75.0688 | AUROC:0.8309\n",
      "Test | 161/10 | Loss:1.3816 | MainLoss:1.1525 | SPLoss:2.2437 | CLSLoss:0.4721 | top1:65.2150 | AUROC:0.8228\n",
      "\n",
      "Epoch: [503 | 1000] LR: 0.000206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 10/10 | Loss:0.4187 | MainLoss:0.1896 | SPLoss:2.2435 | CLSLoss:0.4721 | top1:93.3000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.8936 | MainLoss:0.6645 | SPLoss:2.2433 | CLSLoss:0.4721 | top1:75.1409 | AUROC:0.8299\n",
      "Test | 161/10 | Loss:1.3916 | MainLoss:1.1625 | SPLoss:2.2433 | CLSLoss:0.4721 | top1:65.0062 | AUROC:0.8225\n",
      "\n",
      "Epoch: [504 | 1000] LR: 0.000205\n",
      "Train | 10/10 | Loss:0.4168 | MainLoss:0.1878 | SPLoss:2.2431 | CLSLoss:0.4722 | top1:93.0500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.8932 | MainLoss:0.6642 | SPLoss:2.2429 | CLSLoss:0.4722 | top1:75.1147 | AUROC:0.8306\n",
      "Test | 161/10 | Loss:1.4024 | MainLoss:1.1734 | SPLoss:2.2429 | CLSLoss:0.4722 | top1:64.7913 | AUROC:0.8220\n",
      "\n",
      "Epoch: [505 | 1000] LR: 0.000204\n",
      "Train | 10/10 | Loss:0.4203 | MainLoss:0.1913 | SPLoss:2.2428 | CLSLoss:0.4722 | top1:93.1500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.8931 | MainLoss:0.6642 | SPLoss:2.2427 | CLSLoss:0.4722 | top1:75.1376 | AUROC:0.8305\n",
      "Test | 161/10 | Loss:1.4052 | MainLoss:1.1762 | SPLoss:2.2427 | CLSLoss:0.4722 | top1:64.7352 | AUROC:0.8218\n",
      "\n",
      "Epoch: [506 | 1000] LR: 0.000204\n",
      "Train | 10/10 | Loss:0.4574 | MainLoss:0.2284 | SPLoss:2.2425 | CLSLoss:0.4722 | top1:91.5000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.8928 | MainLoss:0.6638 | SPLoss:2.2423 | CLSLoss:0.4721 | top1:75.1474 | AUROC:0.8304\n",
      "Test | 161/10 | Loss:1.4073 | MainLoss:1.1783 | SPLoss:2.2423 | CLSLoss:0.4721 | top1:64.6854 | AUROC:0.8218\n",
      "\n",
      "Epoch: [507 | 1000] LR: 0.000203\n",
      "Train | 10/10 | Loss:0.3874 | MainLoss:0.1584 | SPLoss:2.2422 | CLSLoss:0.4722 | top1:94.0500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.8933 | MainLoss:0.6643 | SPLoss:2.2421 | CLSLoss:0.4722 | top1:75.1474 | AUROC:0.8304\n",
      "Test | 161/10 | Loss:1.4080 | MainLoss:1.1791 | SPLoss:2.2421 | CLSLoss:0.4722 | top1:64.6729 | AUROC:0.8215\n",
      "\n",
      "Epoch: [508 | 1000] LR: 0.000203\n",
      "Train | 10/10 | Loss:0.4303 | MainLoss:0.2014 | SPLoss:2.2420 | CLSLoss:0.4722 | top1:93.7000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.8932 | MainLoss:0.6643 | SPLoss:2.2418 | CLSLoss:0.4722 | top1:75.1081 | AUROC:0.8311\n",
      "Test | 161/10 | Loss:1.4132 | MainLoss:1.1843 | SPLoss:2.2418 | CLSLoss:0.4722 | top1:64.5794 | AUROC:0.8213\n",
      "\n",
      "Epoch: [509 | 1000] LR: 0.000202\n",
      "Train | 10/10 | Loss:0.3955 | MainLoss:0.1667 | SPLoss:2.2417 | CLSLoss:0.4722 | top1:93.9500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.8936 | MainLoss:0.6647 | SPLoss:2.2415 | CLSLoss:0.4723 | top1:75.1147 | AUROC:0.8305\n",
      "Test | 161/10 | Loss:1.4122 | MainLoss:1.1833 | SPLoss:2.2415 | CLSLoss:0.4723 | top1:64.5919 | AUROC:0.8208\n",
      "\n",
      "Epoch: [510 | 1000] LR: 0.000201\n",
      "Train | 10/10 | Loss:0.4157 | MainLoss:0.1868 | SPLoss:2.2414 | CLSLoss:0.4723 | top1:93.6500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.8937 | MainLoss:0.6648 | SPLoss:2.2412 | CLSLoss:0.4723 | top1:75.1180 | AUROC:0.8308\n",
      "Test | 161/10 | Loss:1.4136 | MainLoss:1.1847 | SPLoss:2.2412 | CLSLoss:0.4723 | top1:64.5701 | AUROC:0.8213\n",
      "\n",
      "Epoch: [511 | 1000] LR: 0.000201\n",
      "Train | 10/10 | Loss:0.4389 | MainLoss:0.2101 | SPLoss:2.2411 | CLSLoss:0.4723 | top1:92.2500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.8937 | MainLoss:0.6649 | SPLoss:2.2409 | CLSLoss:0.4723 | top1:75.1081 | AUROC:0.8300\n",
      "Test | 161/10 | Loss:1.4151 | MainLoss:1.1863 | SPLoss:2.2409 | CLSLoss:0.4723 | top1:64.5296 | AUROC:0.8211\n",
      "\n",
      "Epoch: [512 | 1000] LR: 0.000200\n",
      "Train | 10/10 | Loss:0.4076 | MainLoss:0.1788 | SPLoss:2.2407 | CLSLoss:0.4723 | top1:94.1000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.8938 | MainLoss:0.6651 | SPLoss:2.2404 | CLSLoss:0.4723 | top1:75.0983 | AUROC:0.8304\n",
      "Test | 161/10 | Loss:1.4125 | MainLoss:1.1838 | SPLoss:2.2404 | CLSLoss:0.4723 | top1:64.5857 | AUROC:0.8211\n",
      "\n",
      "Epoch: [513 | 1000] LR: 0.000199\n",
      "Train | 10/10 | Loss:0.4562 | MainLoss:0.2275 | SPLoss:2.2404 | CLSLoss:0.4723 | top1:91.1000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.8935 | MainLoss:0.6648 | SPLoss:2.2403 | CLSLoss:0.4723 | top1:75.0950 | AUROC:0.8302\n",
      "Test | 161/10 | Loss:1.4148 | MainLoss:1.1861 | SPLoss:2.2403 | CLSLoss:0.4723 | top1:64.5389 | AUROC:0.8207\n",
      "\n",
      "Epoch: [514 | 1000] LR: 0.000199\n",
      "Train | 10/10 | Loss:0.4153 | MainLoss:0.1865 | SPLoss:2.2401 | CLSLoss:0.4723 | top1:93.1000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.8937 | MainLoss:0.6650 | SPLoss:2.2399 | CLSLoss:0.4723 | top1:75.1081 | AUROC:0.8303\n",
      "Test | 161/10 | Loss:1.4122 | MainLoss:1.1835 | SPLoss:2.2399 | CLSLoss:0.4723 | top1:64.5763 | AUROC:0.8210\n",
      "\n",
      "Epoch: [515 | 1000] LR: 0.000198\n",
      "Train | 10/10 | Loss:0.4454 | MainLoss:0.2167 | SPLoss:2.2398 | CLSLoss:0.4723 | top1:92.6000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.8935 | MainLoss:0.6648 | SPLoss:2.2396 | CLSLoss:0.4723 | top1:75.1147 | AUROC:0.8302\n",
      "Test | 161/10 | Loss:1.4121 | MainLoss:1.1834 | SPLoss:2.2396 | CLSLoss:0.4723 | top1:64.5794 | AUROC:0.8209\n",
      "\n",
      "Epoch: [516 | 1000] LR: 0.000197\n",
      "Train | 10/10 | Loss:0.4465 | MainLoss:0.2178 | SPLoss:2.2394 | CLSLoss:0.4723 | top1:91.7000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.8933 | MainLoss:0.6646 | SPLoss:2.2392 | CLSLoss:0.4722 | top1:75.1114 | AUROC:0.8304\n",
      "Test | 161/10 | Loss:1.4117 | MainLoss:1.1830 | SPLoss:2.2392 | CLSLoss:0.4722 | top1:64.5608 | AUROC:0.8207\n",
      "\n",
      "Epoch: [517 | 1000] LR: 0.000197\n",
      "Train | 10/10 | Loss:0.4518 | MainLoss:0.2232 | SPLoss:2.2391 | CLSLoss:0.4722 | top1:91.2500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.8929 | MainLoss:0.6643 | SPLoss:2.2390 | CLSLoss:0.4722 | top1:75.1147 | AUROC:0.8304\n",
      "Test | 161/10 | Loss:1.4107 | MainLoss:1.1821 | SPLoss:2.2390 | CLSLoss:0.4722 | top1:64.5950 | AUROC:0.8210\n",
      "\n",
      "Epoch: [518 | 1000] LR: 0.000196\n",
      "Train | 10/10 | Loss:0.4155 | MainLoss:0.1869 | SPLoss:2.2388 | CLSLoss:0.4722 | top1:93.5500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.8931 | MainLoss:0.6645 | SPLoss:2.2387 | CLSLoss:0.4722 | top1:75.1147 | AUROC:0.8307\n",
      "Test | 161/10 | Loss:1.4114 | MainLoss:1.1829 | SPLoss:2.2387 | CLSLoss:0.4722 | top1:64.5701 | AUROC:0.8210\n",
      "\n",
      "Epoch: [519 | 1000] LR: 0.000196\n",
      "Train | 10/10 | Loss:0.3962 | MainLoss:0.1676 | SPLoss:2.2385 | CLSLoss:0.4723 | top1:94.4000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.8934 | MainLoss:0.6648 | SPLoss:2.2383 | CLSLoss:0.4723 | top1:75.1016 | AUROC:0.8302\n",
      "Test | 161/10 | Loss:1.4163 | MainLoss:1.1878 | SPLoss:2.2383 | CLSLoss:0.4723 | top1:64.5078 | AUROC:0.8210\n",
      "\n",
      "Epoch: [520 | 1000] LR: 0.000195\n",
      "Train | 10/10 | Loss:0.4319 | MainLoss:0.2034 | SPLoss:2.2383 | CLSLoss:0.4723 | top1:92.3000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.8931 | MainLoss:0.6645 | SPLoss:2.2383 | CLSLoss:0.4723 | top1:75.1474 | AUROC:0.8301\n",
      "Test | 161/10 | Loss:1.4119 | MainLoss:1.1834 | SPLoss:2.2383 | CLSLoss:0.4723 | top1:64.5608 | AUROC:0.8209\n",
      "\n",
      "Epoch: [521 | 1000] LR: 0.000194\n",
      "Train | 10/10 | Loss:0.4066 | MainLoss:0.1781 | SPLoss:2.2381 | CLSLoss:0.4723 | top1:94.3000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.8932 | MainLoss:0.6646 | SPLoss:2.2381 | CLSLoss:0.4723 | top1:75.1343 | AUROC:0.8303\n",
      "Test | 161/10 | Loss:1.4128 | MainLoss:1.1843 | SPLoss:2.2381 | CLSLoss:0.4723 | top1:64.5639 | AUROC:0.8208\n",
      "\n",
      "Epoch: [522 | 1000] LR: 0.000194\n",
      "Train | 10/10 | Loss:0.3710 | MainLoss:0.1425 | SPLoss:2.2380 | CLSLoss:0.4724 | top1:95.1500 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.8950 | MainLoss:0.6665 | SPLoss:2.2380 | CLSLoss:0.4724 | top1:75.2228 | AUROC:0.8305\n",
      "Test | 161/10 | Loss:1.3969 | MainLoss:1.1684 | SPLoss:2.2380 | CLSLoss:0.4724 | top1:64.9657 | AUROC:0.8239\n",
      "\n",
      "Epoch: [523 | 1000] LR: 0.000193\n",
      "Train | 10/10 | Loss:0.3914 | MainLoss:0.1629 | SPLoss:2.2378 | CLSLoss:0.4725 | top1:94.3000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.8953 | MainLoss:0.6668 | SPLoss:2.2377 | CLSLoss:0.4725 | top1:75.2359 | AUROC:0.8304\n",
      "Test | 161/10 | Loss:1.3962 | MainLoss:1.1677 | SPLoss:2.2377 | CLSLoss:0.4725 | top1:64.9782 | AUROC:0.8238\n",
      "\n",
      "Epoch: [524 | 1000] LR: 0.000192\n",
      "Train | 10/10 | Loss:0.4496 | MainLoss:0.2211 | SPLoss:2.2376 | CLSLoss:0.4725 | top1:92.0000 | AUROC:0.0000\n",
      "Test | 153/10 | Loss:0.8950 | MainLoss:0.6665 | SPLoss:2.2375 | CLSLoss:0.4725 | top1:75.2163 | AUROC:0.8302\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-b6b4742642ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_auroc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudent_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_auroc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_target_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudent_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0msource_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_auroc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_source_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudent_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-887471094425>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(val_loader, model, criterion, epoch, use_cuda)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;31m# compute output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0mloss_main\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mloss_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gd/EfficientNet/model_pytorch/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0mbs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;31m# Convolution layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;31m# Pooling and final linear layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gd/EfficientNet/model_pytorch/model.py\u001b[0m in \u001b[0;36mextract_features\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdrop_connect_rate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m                 \u001b[0mdrop_connect_rate\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_connect_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop_connect_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gd/EfficientNet/model_pytorch/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, drop_connect_rate)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_se\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0mx_squeezed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madaptive_avg_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0mx_squeezed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_se_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_swish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_se_reduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_squeezed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_squeezed\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gd/EfficientNet/model_pytorch/utils.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0mweight_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mweight_mean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1e-5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m         \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(start_epoch, epochs):\n",
    "    state['lr'] = optimizer.state_dict()['param_groups'][0]['lr']\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "    print('\\nEpoch: [%d | %d] LR: %f' % (epoch + 1, epochs, state['lr']))\n",
    "    \n",
    "    train_loss, train_acc, train_auroc = train(train_loader, student_model, criterion, optimizer, epoch, use_cuda)\n",
    "    test_loss, test_acc, test_auroc = test(val_target_loader, student_model, criterion, epoch, use_cuda)\n",
    "    source_loss, source_acc, source_auroc = test(val_source_loader, student_model, criterion, epoch, use_cuda)\n",
    "\n",
    "\n",
    "    logger.append([state['lr'], train_loss, test_loss,  source_loss, train_acc, test_acc,source_acc, train_auroc, test_auroc, source_auroc])\n",
    "    is_best = test_acc > best_acc\n",
    "    best_acc = max(test_acc, best_acc)\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'state_dict' : student_model.state_dict(),\n",
    "        'acc': test_acc,\n",
    "        'best_acc': best_acc,\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    }, is_best, checkpoint=checkpoint)\n",
    "    scheduler_warmup.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
