{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import collections\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "\n",
    "from model_pytorch import resnext50_32x4d\n",
    "from utils import Bar,Logger, AverageMeter, accuracy, mkdir_p, savefig\n",
    "from warmup_scheduler import GradualWarmupScheduler\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "import cv2\n",
    "\n",
    "from PIL import ImageFile, ImageOps\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU device 1: True\n"
     ]
    }
   ],
   "source": [
    "# GPU Device\n",
    "gpu_id = 1\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(\"GPU device %d:\" %(gpu_id), use_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/media/data2/dataset/GAN_ImageData/StarGAN_128'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained = ''\n",
    "resume = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model_name = 'resnext32x4d' # b0-b7 scale\n",
    "\n",
    "# Optimization\n",
    "num_classes = 2\n",
    "epochs = 300\n",
    "start_epoch = 0\n",
    "train_batch = 400\n",
    "test_batch = 400\n",
    "lr = 0.04\n",
    "schedule = [75, 175, 250]\n",
    "momentum = 0.9\n",
    "gamma = 0.1 # LR is multiplied by gamma on schedule\n",
    "\n",
    "# CheckPoint\n",
    "checkpoint = './log/star/128/32x4d/aug' # dir\n",
    "if not os.path.isdir(checkpoint):\n",
    "    os.makedirs(checkpoint)\n",
    "num_workers = 8\n",
    "\n",
    "# Seed\n",
    "manual_seed = 7\n",
    "random.seed(manual_seed)\n",
    "torch.cuda.manual_seed_all(manual_seed)\n",
    "\n",
    "# Image\n",
    "size = (128, 128)\n",
    "\n",
    "# cutmix\n",
    "cm_prob = 0.5\n",
    "cm_beta = 1.0\n",
    "\n",
    "# augmentation\n",
    "blur_prob = 0.2\n",
    "blog_sig = 0.5\n",
    "jpg_prob = 0.2\n",
    "\n",
    "best_acc = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {}\n",
    "state['num_classes'] = num_classes\n",
    "state['epochs'] = epochs\n",
    "state['start_epoch'] = start_epoch\n",
    "state['train_batch'] = train_batch\n",
    "state['test_batch'] = test_batch\n",
    "state['lr'] = lr\n",
    "state['schedule'] = schedule\n",
    "state['momentum'] = momentum\n",
    "state['gamma'] = gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_augment(img):\n",
    "    img = np.array(img)\n",
    "\n",
    "    if random.random() < blur_prob:\n",
    "        sig = np.random.uniform(0.0, 3.0)\n",
    "        gaussian_blur(img, sig)\n",
    "\n",
    "    if random.random() < jpg_prob:\n",
    "        qual = np.random.uniform(30.0, 100.0)\n",
    "        img = cv2_jpg(img, qual)\n",
    "\n",
    "    return Image.fromarray(img)\n",
    "\n",
    "\n",
    "def gaussian_blur(img, sigma):\n",
    "    gaussian_filter(img[:,:,0], output=img[:,:,0], sigma=sigma)\n",
    "    gaussian_filter(img[:,:,1], output=img[:,:,1], sigma=sigma)\n",
    "    gaussian_filter(img[:,:,2], output=img[:,:,2], sigma=sigma)\n",
    "\n",
    "\n",
    "def cv2_jpg(img, compress_val):\n",
    "    img_cv2 = img[:,:,::-1]\n",
    "    encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), compress_val]\n",
    "    result, encimg = cv2.imencode('.jpg', img_cv2, encode_param)\n",
    "    decimg = cv2.imdecode(encimg, 1)\n",
    "    return decimg[:,:,::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_bbox(size, lam):\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = np.int(W * cut_rat)\n",
    "    cut_h = np.int(H * cut_rat)\n",
    "\n",
    "    # uniform\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join(data_dir, 'train')\n",
    "val_dir = os.path.join(data_dir, 'validation')    \n",
    "\n",
    "train_aug = transforms.Compose([\n",
    "    transforms.Lambda(lambda img: data_augment(img)),\n",
    "    transforms.Resize(size),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "#     transforms.RandomErasing(p=0.3, scale=(0.02, 0.10), ratio=(0.3, 3.3), value=0, inplace=True),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "val_aug = transforms.Compose([\n",
    "    transforms.Resize(size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# pin_memory : cuda pin memeory use\n",
    "train_loader = DataLoader(datasets.ImageFolder(train_dir, transform=train_aug),\n",
    "                          batch_size=train_batch, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "val_loader = DataLoader(datasets.ImageFolder(val_dir, val_aug),\n",
    "                       batch_size=test_batch, shuffle=True, num_workers=num_workers, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnext50_32x4d(pretrained=False, num_classes=2)\n",
    "\n",
    "# Pre-trained\n",
    "if pretrained:\n",
    "    print(\"=> using pre-trained model '{}'\".format(pretrained))\n",
    "    model.load_state_dict(torch.load(pretrained)['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Total params: 22.98M\n"
     ]
    }
   ],
   "source": [
    "model.to('cuda')\n",
    "cudnn.benchmark = True\n",
    "print('    Total params: %.2fM' % (sum(p.numel() for p in model.parameters())/1000000.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=1e-4)\n",
    "scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)\n",
    "scheduler_warmup = GradualWarmupScheduler(optimizer, multiplier=8, total_epoch=10, after_scheduler=scheduler_cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resume\n",
    "if resume:\n",
    "    print('==> Resuming from checkpoint..')\n",
    "    checkpoint = os.path.dirname(resume)\n",
    "#     checkpoint = torch.load(resume)\n",
    "    resume = torch.load(resume)\n",
    "    best_acc = resume['best_acc']\n",
    "    start_epoch = resume['epoch']\n",
    "    model.load_state_dict(resume['state_dict'])\n",
    "    optimizer.load_state_dict(resume['optimizer'])\n",
    "    logger = Logger(os.path.join(checkpoint, 'log.txt'), resume=True)\n",
    "else:\n",
    "    logger = Logger(os.path.join(checkpoint, 'log.txt'))\n",
    "    logger.set_names(['Learning Rate', 'Train Loss', 'Valid Loss', 'Train Acc.', 'Valid Acc.', 'Train AUROC.', 'Valid AUROC.'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch, use_cuda):\n",
    "    model.train()\n",
    "    \n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    arc = AverageMeter()\n",
    "    end = time.time()\n",
    "    \n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        batch_size = inputs.size(0)\n",
    "        if batch_size < train_batch:\n",
    "            continue\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            \n",
    "        r = np.random.rand(1)\n",
    "        if cm_beta > 0 and r < cm_prob:\n",
    "            \n",
    "            rand_index = torch.randperm(inputs.size()[0]).cuda()\n",
    "            tt= targets[rand_index]\n",
    "            boolean = targets==tt\n",
    "            rand_index = rand_index[boolean]\n",
    "            lam = np.random.beta(cm_beta, cm_beta)\n",
    "            bbx1, bby1, bbx2, bby2 = rand_bbox(inputs.size(), lam)\n",
    "            inputs[boolean, :, bbx1:bbx2, bby1:bby2] = inputs[rand_index, :, bbx1:bbx2, bby1:bby2]\n",
    "\n",
    "        # compute output\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1 = accuracy(outputs.data, targets.data)\n",
    "        auroc = roc_auc_score(targets.cpu().detach().numpy(), outputs.cpu().detach().numpy()[:,1])\n",
    "        losses.update(loss.data.tolist(), inputs.size(0))\n",
    "        top1.update(prec1[0], inputs.size(0))\n",
    "        arc.update(auroc, inputs.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print('{batch}/{size} | Loss:{loss:.4f} | top1:{tp1:.4f} | AUROC:{ac:.4f}'.format(\n",
    "                     batch=batch_idx+1, size=len(train_loader), loss=losses.avg, tp1=top1.avg, ac=arc.avg))\n",
    "    print('{batch}/{size} | Loss:{loss:.4f} | top1:{tp1:.4f} | AUROC:{ac:.4f}'.format(\n",
    "                     batch=batch_idx+1, size=len(train_loader), loss=losses.avg, tp1=top1.avg, ac=arc.avg))\n",
    "    return (losses.avg, top1.avg, arc.avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(val_loader, model, criterion, epoch, use_cuda):\n",
    "    global best_acc\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    arc = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(val_loader):\n",
    "            # measure data loading time\n",
    "            data_time.update(time.time() - end)\n",
    "\n",
    "            if use_cuda:\n",
    "                inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "            # compute output\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            prec1 = accuracy(outputs.data, targets.data)\n",
    "            auroc = roc_auc_score(targets.cpu().detach().numpy(), outputs.cpu().detach().numpy()[:,1])\n",
    "            losses.update(loss.data.tolist(), inputs.size(0))\n",
    "            top1.update(prec1[0], inputs.size(0))\n",
    "            arc.update(auroc, inputs.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "    print('{batch}/{size} | Loss:{loss:.4f} | top1:{tp1:.4f} | AUROC:{ac:.4f}'.format(\n",
    "         batch=batch_idx+1, size=len(val_loader), loss=losses.avg, tp1=top1.avg, ac=arc.avg))\n",
    "    return (losses.avg, top1.avg, arc.avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, checkpoint='checkpoint', filename='checkpoint.pth.tar'):\n",
    "    filepath = os.path.join(checkpoint, filename)\n",
    "    torch.save(state, filepath)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filepath, os.path.join(checkpoint, 'model_best.pth.tar'))\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    global state\n",
    "    lr_set = [1, 1e-1, 1e-2, 1e-3, 1e-4, 1e-5]\n",
    "    lr_list = schedule.copy()\n",
    "    lr_list.append(epoch)\n",
    "    lr_list.sort()\n",
    "    idx = lr_list.index(epoch)\n",
    "    state['lr'] *= lr_set[idx]\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = state['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [1 | 300] LR: 0.040000\n",
      "1/687 | Loss:0.7154 | top1:47.7500 | AUROC:0.4702\n",
      "101/687 | Loss:4.1193 | top1:50.0050 | AUROC:0.5094\n",
      "201/687 | Loss:2.4154 | top1:50.4527 | AUROC:0.5359\n",
      "301/687 | Loss:1.8397 | top1:52.3032 | AUROC:0.5573\n",
      "401/687 | Loss:1.5492 | top1:53.6758 | AUROC:0.5726\n",
      "501/687 | Loss:1.3732 | top1:54.7725 | AUROC:0.5855\n",
      "601/687 | Loss:1.2546 | top1:55.7163 | AUROC:0.5967\n",
      "687/687 | Loss:1.1795 | top1:56.4548 | AUROC:0.6071\n",
      "77/77 | Loss:0.6391 | top1:62.9915 | AUROC:0.6866\n",
      "\n",
      "Epoch: [2 | 300] LR: 0.068000\n",
      "1/687 | Loss:0.6269 | top1:65.5000 | AUROC:0.7172\n",
      "101/687 | Loss:0.6502 | top1:61.4257 | AUROC:0.6915\n",
      "201/687 | Loss:0.6415 | top1:62.6940 | AUROC:0.7039\n",
      "301/687 | Loss:0.6317 | top1:63.9252 | AUROC:0.7164\n",
      "401/687 | Loss:0.6185 | top1:65.2070 | AUROC:0.7311\n",
      "501/687 | Loss:0.6092 | top1:66.1387 | AUROC:0.7437\n",
      "601/687 | Loss:0.5979 | top1:67.0986 | AUROC:0.7552\n",
      "687/687 | Loss:0.5882 | top1:67.9042 | AUROC:0.7652\n",
      "77/77 | Loss:0.4689 | top1:77.3263 | AUROC:0.8616\n",
      "\n",
      "Epoch: [3 | 300] LR: 0.096000\n",
      "1/687 | Loss:0.4866 | top1:74.5000 | AUROC:0.8494\n",
      "101/687 | Loss:0.4948 | top1:75.2054 | AUROC:0.8534\n",
      "201/687 | Loss:0.4771 | top1:76.5435 | AUROC:0.8633\n",
      "301/687 | Loss:0.4591 | top1:77.6827 | AUROC:0.8744\n",
      "401/687 | Loss:0.4434 | top1:78.6241 | AUROC:0.8837\n",
      "501/687 | Loss:0.4297 | top1:79.4751 | AUROC:0.8918\n",
      "601/687 | Loss:0.4141 | top1:80.3981 | AUROC:0.8991\n",
      "687/687 | Loss:0.4042 | top1:80.9723 | AUROC:0.9041\n",
      "77/77 | Loss:0.2625 | top1:88.7025 | AUROC:0.9585\n",
      "\n",
      "Epoch: [4 | 300] LR: 0.124000\n",
      "1/687 | Loss:0.3287 | top1:85.5000 | AUROC:0.9341\n",
      "101/687 | Loss:0.3468 | top1:84.2624 | AUROC:0.9412\n",
      "201/687 | Loss:0.3251 | top1:85.5883 | AUROC:0.9454\n",
      "301/687 | Loss:0.3190 | top1:85.8596 | AUROC:0.9478\n",
      "401/687 | Loss:0.3077 | top1:86.4190 | AUROC:0.9515\n",
      "501/687 | Loss:0.2996 | top1:86.8658 | AUROC:0.9538\n",
      "601/687 | Loss:0.2907 | top1:87.3270 | AUROC:0.9563\n",
      "687/687 | Loss:0.2842 | top1:87.6534 | AUROC:0.9583\n",
      "77/77 | Loss:0.2273 | top1:90.3899 | AUROC:0.9810\n",
      "\n",
      "Epoch: [5 | 300] LR: 0.152000\n",
      "1/687 | Loss:0.2621 | top1:86.2500 | AUROC:0.9668\n",
      "101/687 | Loss:0.2291 | top1:90.1708 | AUROC:0.9728\n",
      "201/687 | Loss:0.2302 | top1:90.2512 | AUROC:0.9736\n",
      "301/687 | Loss:0.2295 | top1:90.2915 | AUROC:0.9743\n",
      "401/687 | Loss:0.2249 | top1:90.5474 | AUROC:0.9754\n",
      "501/687 | Loss:0.2183 | top1:90.8553 | AUROC:0.9766\n",
      "601/687 | Loss:0.2122 | top1:91.1410 | AUROC:0.9777\n",
      "687/687 | Loss:0.2070 | top1:91.3783 | AUROC:0.9786\n",
      "77/77 | Loss:0.1973 | top1:92.0577 | AUROC:0.9891\n",
      "\n",
      "Epoch: [6 | 300] LR: 0.180000\n",
      "1/687 | Loss:0.2255 | top1:92.0000 | AUROC:0.9880\n",
      "101/687 | Loss:0.1904 | top1:92.1139 | AUROC:0.9845\n",
      "201/687 | Loss:0.1846 | top1:92.4080 | AUROC:0.9848\n",
      "301/687 | Loss:0.1781 | top1:92.7201 | AUROC:0.9855\n",
      "401/687 | Loss:0.1738 | top1:92.9108 | AUROC:0.9862\n",
      "501/687 | Loss:0.1681 | top1:93.1771 | AUROC:0.9867\n",
      "601/687 | Loss:0.1641 | top1:93.3565 | AUROC:0.9872\n",
      "687/687 | Loss:0.1616 | top1:93.4752 | AUROC:0.9875\n",
      "77/77 | Loss:0.1169 | top1:95.4948 | AUROC:0.9932\n",
      "\n",
      "Epoch: [7 | 300] LR: 0.208000\n",
      "1/687 | Loss:0.1777 | top1:92.7500 | AUROC:0.9811\n",
      "101/687 | Loss:0.1553 | top1:93.9406 | AUROC:0.9899\n",
      "201/687 | Loss:0.1532 | top1:93.9714 | AUROC:0.9898\n",
      "301/687 | Loss:0.1476 | top1:94.1661 | AUROC:0.9901\n",
      "401/687 | Loss:0.1452 | top1:94.2668 | AUROC:0.9904\n",
      "501/687 | Loss:0.1452 | top1:94.2470 | AUROC:0.9907\n",
      "601/687 | Loss:0.1434 | top1:94.3141 | AUROC:0.9908\n",
      "687/687 | Loss:0.1405 | top1:94.4224 | AUROC:0.9911\n",
      "77/77 | Loss:0.0886 | top1:96.7759 | AUROC:0.9957\n",
      "\n",
      "Epoch: [8 | 300] LR: 0.236000\n",
      "1/687 | Loss:0.1100 | top1:95.2500 | AUROC:0.9945\n",
      "101/687 | Loss:0.1298 | top1:94.8812 | AUROC:0.9925\n",
      "201/687 | Loss:0.1376 | top1:94.5622 | AUROC:0.9918\n",
      "301/687 | Loss:0.1322 | top1:94.7840 | AUROC:0.9921\n",
      "401/687 | Loss:0.1292 | top1:94.8915 | AUROC:0.9923\n",
      "501/687 | Loss:0.1277 | top1:94.9696 | AUROC:0.9926\n",
      "601/687 | Loss:0.1282 | top1:94.9509 | AUROC:0.9927\n",
      "687/687 | Loss:0.1268 | top1:95.0222 | AUROC:0.9927\n",
      "77/77 | Loss:0.0951 | top1:96.3565 | AUROC:0.9961\n",
      "\n",
      "Epoch: [9 | 300] LR: 0.264000\n",
      "1/687 | Loss:0.1041 | top1:96.2500 | AUROC:0.9973\n",
      "101/687 | Loss:0.1302 | top1:94.8713 | AUROC:0.9940\n",
      "201/687 | Loss:0.1220 | top1:95.2326 | AUROC:0.9939\n",
      "301/687 | Loss:0.1272 | top1:94.9826 | AUROC:0.9934\n",
      "401/687 | Loss:0.1295 | top1:94.8984 | AUROC:0.9931\n",
      "501/687 | Loss:0.1272 | top1:95.0020 | AUROC:0.9933\n",
      "601/687 | Loss:0.1241 | top1:95.1306 | AUROC:0.9935\n",
      "687/687 | Loss:0.1227 | top1:95.1891 | AUROC:0.9935\n",
      "77/77 | Loss:0.0855 | top1:96.7005 | AUROC:0.9968\n",
      "\n",
      "Epoch: [10 | 300] LR: 0.292000\n",
      "1/687 | Loss:0.1356 | top1:95.5000 | AUROC:0.9923\n",
      "101/687 | Loss:0.1277 | top1:94.9876 | AUROC:0.9932\n",
      "201/687 | Loss:0.1270 | top1:95.0099 | AUROC:0.9932\n",
      "301/687 | Loss:0.1221 | top1:95.2400 | AUROC:0.9936\n",
      "401/687 | Loss:0.1241 | top1:95.1552 | AUROC:0.9936\n",
      "501/687 | Loss:0.1239 | top1:95.1542 | AUROC:0.9935\n",
      "601/687 | Loss:0.1258 | top1:95.0807 | AUROC:0.9933\n",
      "687/687 | Loss:0.1231 | top1:95.2048 | AUROC:0.9936\n",
      "77/77 | Loss:0.0975 | top1:96.1796 | AUROC:0.9973\n",
      "\n",
      "Epoch: [11 | 300] LR: 0.320000\n",
      "1/687 | Loss:0.1520 | top1:94.7500 | AUROC:0.9913\n",
      "101/687 | Loss:0.1187 | top1:95.3812 | AUROC:0.9939\n",
      "201/687 | Loss:0.1157 | top1:95.5236 | AUROC:0.9938\n",
      "301/687 | Loss:0.1168 | top1:95.4643 | AUROC:0.9939\n",
      "401/687 | Loss:0.1224 | top1:95.2151 | AUROC:0.9935\n",
      "501/687 | Loss:0.1208 | top1:95.2650 | AUROC:0.9936\n",
      "601/687 | Loss:0.1192 | top1:95.3386 | AUROC:0.9937\n",
      "687/687 | Loss:0.1212 | top1:95.2591 | AUROC:0.9935\n",
      "77/77 | Loss:0.1430 | top1:94.1907 | AUROC:0.9957\n",
      "\n",
      "Epoch: [12 | 300] LR: 0.320000\n",
      "1/687 | Loss:0.1482 | top1:93.5000 | AUROC:0.9950\n",
      "101/687 | Loss:0.1149 | top1:95.6015 | AUROC:0.9947\n",
      "201/687 | Loss:0.1118 | top1:95.6716 | AUROC:0.9947\n",
      "301/687 | Loss:0.1102 | top1:95.7500 | AUROC:0.9948\n",
      "401/687 | Loss:0.1119 | top1:95.6883 | AUROC:0.9946\n",
      "501/687 | Loss:0.1125 | top1:95.6397 | AUROC:0.9945\n",
      "601/687 | Loss:0.1132 | top1:95.6102 | AUROC:0.9945\n",
      "687/687 | Loss:0.1124 | top1:95.6254 | AUROC:0.9946\n",
      "77/77 | Loss:0.0858 | top1:96.8021 | AUROC:0.9960\n",
      "\n",
      "Epoch: [13 | 300] LR: 0.319991\n",
      "1/687 | Loss:0.1363 | top1:95.5000 | AUROC:0.9904\n",
      "101/687 | Loss:0.1066 | top1:95.9307 | AUROC:0.9951\n",
      "201/687 | Loss:0.1057 | top1:95.8955 | AUROC:0.9949\n",
      "301/687 | Loss:0.1010 | top1:96.0814 | AUROC:0.9953\n",
      "401/687 | Loss:0.1009 | top1:96.0698 | AUROC:0.9954\n",
      "501/687 | Loss:0.1039 | top1:95.9481 | AUROC:0.9951\n",
      "601/687 | Loss:0.1083 | top1:95.7463 | AUROC:0.9949\n",
      "687/687 | Loss:0.1081 | top1:95.7759 | AUROC:0.9948\n",
      "77/77 | Loss:0.0847 | top1:96.8349 | AUROC:0.9962\n",
      "\n",
      "Epoch: [14 | 300] LR: 0.319965\n",
      "1/687 | Loss:0.0740 | top1:97.2500 | AUROC:0.9977\n",
      "101/687 | Loss:0.0910 | top1:96.5322 | AUROC:0.9959\n",
      "201/687 | Loss:0.0925 | top1:96.4552 | AUROC:0.9960\n",
      "301/687 | Loss:0.0947 | top1:96.3845 | AUROC:0.9959\n",
      "401/687 | Loss:0.0981 | top1:96.2637 | AUROC:0.9957\n",
      "501/687 | Loss:0.0985 | top1:96.2300 | AUROC:0.9957\n",
      "601/687 | Loss:0.0995 | top1:96.1938 | AUROC:0.9957\n",
      "687/687 | Loss:0.0996 | top1:96.1753 | AUROC:0.9956\n",
      "77/77 | Loss:0.0645 | top1:97.6704 | AUROC:0.9979\n",
      "\n",
      "Epoch: [15 | 300] LR: 0.319921\n",
      "1/687 | Loss:0.1265 | top1:94.7500 | AUROC:0.9902\n",
      "101/687 | Loss:0.1049 | top1:95.8020 | AUROC:0.9954\n",
      "201/687 | Loss:0.1012 | top1:96.0336 | AUROC:0.9957\n",
      "301/687 | Loss:0.1013 | top1:96.0465 | AUROC:0.9957\n",
      "401/687 | Loss:0.0975 | top1:96.2219 | AUROC:0.9959\n",
      "501/687 | Loss:0.0973 | top1:96.2525 | AUROC:0.9960\n",
      "601/687 | Loss:0.0961 | top1:96.3045 | AUROC:0.9960\n",
      "687/687 | Loss:0.0989 | top1:96.1870 | AUROC:0.9958\n",
      "77/77 | Loss:0.0814 | top1:96.8840 | AUROC:0.9965\n",
      "\n",
      "Epoch: [16 | 300] LR: 0.319860\n",
      "1/687 | Loss:0.0986 | top1:96.7500 | AUROC:0.9944\n",
      "101/687 | Loss:0.0856 | top1:96.7921 | AUROC:0.9963\n",
      "201/687 | Loss:0.0938 | top1:96.4789 | AUROC:0.9957\n",
      "301/687 | Loss:0.0954 | top1:96.4012 | AUROC:0.9958\n",
      "401/687 | Loss:0.0957 | top1:96.3666 | AUROC:0.9958\n",
      "501/687 | Loss:0.0960 | top1:96.3523 | AUROC:0.9958\n",
      "601/687 | Loss:0.0962 | top1:96.3453 | AUROC:0.9959\n",
      "687/687 | Loss:0.0961 | top1:96.3506 | AUROC:0.9959\n",
      "77/77 | Loss:0.0930 | top1:96.3762 | AUROC:0.9980\n",
      "\n",
      "Epoch: [17 | 300] LR: 0.319781\n",
      "1/687 | Loss:0.0716 | top1:97.5000 | AUROC:0.9993\n",
      "101/687 | Loss:0.0796 | top1:96.9802 | AUROC:0.9970\n",
      "201/687 | Loss:0.0884 | top1:96.6107 | AUROC:0.9963\n",
      "301/687 | Loss:0.0892 | top1:96.5656 | AUROC:0.9963\n",
      "401/687 | Loss:0.0874 | top1:96.6396 | AUROC:0.9965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "501/687 | Loss:0.0890 | top1:96.5818 | AUROC:0.9964\n",
      "601/687 | Loss:0.0903 | top1:96.5308 | AUROC:0.9964\n",
      "687/687 | Loss:0.0910 | top1:96.5102 | AUROC:0.9964\n",
      "77/77 | Loss:0.0662 | top1:97.4017 | AUROC:0.9979\n",
      "\n",
      "Epoch: [18 | 300] LR: 0.319684\n",
      "1/687 | Loss:0.0684 | top1:96.5000 | AUROC:0.9983\n",
      "101/687 | Loss:0.0906 | top1:96.5990 | AUROC:0.9965\n",
      "201/687 | Loss:0.0848 | top1:96.7761 | AUROC:0.9968\n",
      "301/687 | Loss:0.0854 | top1:96.7683 | AUROC:0.9967\n",
      "401/687 | Loss:0.0843 | top1:96.8055 | AUROC:0.9967\n",
      "501/687 | Loss:0.0878 | top1:96.6712 | AUROC:0.9965\n",
      "601/687 | Loss:0.0895 | top1:96.5936 | AUROC:0.9965\n",
      "687/687 | Loss:0.0904 | top1:96.5722 | AUROC:0.9964\n",
      "77/77 | Loss:0.0533 | top1:98.0177 | AUROC:0.9985\n",
      "\n",
      "Epoch: [19 | 300] LR: 0.319570\n",
      "1/687 | Loss:0.0783 | top1:97.5000 | AUROC:0.9962\n",
      "101/687 | Loss:0.0830 | top1:96.8465 | AUROC:0.9970\n",
      "201/687 | Loss:0.0819 | top1:96.9055 | AUROC:0.9972\n",
      "301/687 | Loss:0.0846 | top1:96.8032 | AUROC:0.9969\n",
      "401/687 | Loss:0.0852 | top1:96.7880 | AUROC:0.9969\n",
      "501/687 | Loss:0.0863 | top1:96.7445 | AUROC:0.9969\n",
      "601/687 | Loss:0.0867 | top1:96.7188 | AUROC:0.9968\n",
      "687/687 | Loss:0.0877 | top1:96.6808 | AUROC:0.9967\n",
      "77/77 | Loss:0.0566 | top1:97.9161 | AUROC:0.9980\n",
      "\n",
      "Epoch: [20 | 300] LR: 0.319439\n",
      "1/687 | Loss:0.0957 | top1:96.2500 | AUROC:0.9939\n",
      "101/687 | Loss:0.0811 | top1:96.9109 | AUROC:0.9973\n",
      "201/687 | Loss:0.0850 | top1:96.7351 | AUROC:0.9972\n",
      "301/687 | Loss:0.0878 | top1:96.6130 | AUROC:0.9971\n",
      "401/687 | Loss:0.0870 | top1:96.6291 | AUROC:0.9971\n",
      "501/687 | Loss:0.0865 | top1:96.6577 | AUROC:0.9970\n",
      "601/687 | Loss:0.0840 | top1:96.7591 | AUROC:0.9971\n",
      "687/687 | Loss:0.0834 | top1:96.7824 | AUROC:0.9971\n",
      "77/77 | Loss:0.0588 | top1:97.8178 | AUROC:0.9983\n",
      "\n",
      "Epoch: [21 | 300] LR: 0.319290\n",
      "1/687 | Loss:0.1012 | top1:96.5000 | AUROC:0.9935\n",
      "101/687 | Loss:0.0900 | top1:96.5842 | AUROC:0.9970\n",
      "201/687 | Loss:0.0830 | top1:96.8520 | AUROC:0.9972\n",
      "301/687 | Loss:0.0808 | top1:96.8945 | AUROC:0.9973\n",
      "401/687 | Loss:0.0833 | top1:96.7818 | AUROC:0.9973\n",
      "501/687 | Loss:0.0853 | top1:96.7161 | AUROC:0.9972\n",
      "601/687 | Loss:0.0854 | top1:96.7213 | AUROC:0.9971\n",
      "687/687 | Loss:0.0852 | top1:96.7383 | AUROC:0.9971\n",
      "77/77 | Loss:0.0569 | top1:97.8211 | AUROC:0.9983\n",
      "\n",
      "Epoch: [22 | 300] LR: 0.319124\n",
      "1/687 | Loss:0.1027 | top1:96.5000 | AUROC:0.9956\n",
      "101/687 | Loss:0.0811 | top1:96.8738 | AUROC:0.9972\n",
      "201/687 | Loss:0.0781 | top1:97.0249 | AUROC:0.9974\n",
      "301/687 | Loss:0.0786 | top1:97.0141 | AUROC:0.9973\n",
      "401/687 | Loss:0.0780 | top1:97.0374 | AUROC:0.9973\n",
      "501/687 | Loss:0.0790 | top1:96.9915 | AUROC:0.9973\n",
      "601/687 | Loss:0.0801 | top1:96.9484 | AUROC:0.9972\n",
      "687/687 | Loss:0.0804 | top1:96.9333 | AUROC:0.9972\n",
      "77/77 | Loss:0.0558 | top1:97.8866 | AUROC:0.9988\n",
      "\n",
      "Epoch: [23 | 300] LR: 0.318940\n",
      "1/687 | Loss:0.0817 | top1:97.7500 | AUROC:0.9968\n",
      "101/687 | Loss:0.0820 | top1:96.9084 | AUROC:0.9970\n",
      "201/687 | Loss:0.0814 | top1:96.9005 | AUROC:0.9970\n",
      "301/687 | Loss:0.0781 | top1:97.0066 | AUROC:0.9972\n",
      "401/687 | Loss:0.0797 | top1:96.9551 | AUROC:0.9973\n",
      "501/687 | Loss:0.0802 | top1:96.9401 | AUROC:0.9973\n",
      "601/687 | Loss:0.0800 | top1:96.9497 | AUROC:0.9973\n",
      "687/687 | Loss:0.0807 | top1:96.8983 | AUROC:0.9973\n",
      "77/77 | Loss:0.0713 | top1:97.2838 | AUROC:0.9986\n",
      "\n",
      "Epoch: [24 | 300] LR: 0.318738\n",
      "1/687 | Loss:0.0685 | top1:97.2500 | AUROC:0.9995\n",
      "101/687 | Loss:0.0673 | top1:97.4332 | AUROC:0.9981\n",
      "201/687 | Loss:0.0713 | top1:97.2786 | AUROC:0.9979\n",
      "301/687 | Loss:0.0731 | top1:97.2417 | AUROC:0.9977\n",
      "401/687 | Loss:0.0744 | top1:97.1995 | AUROC:0.9976\n",
      "501/687 | Loss:0.0744 | top1:97.1976 | AUROC:0.9976\n",
      "601/687 | Loss:0.0760 | top1:97.1273 | AUROC:0.9976\n",
      "687/687 | Loss:0.0762 | top1:97.1203 | AUROC:0.9975\n",
      "77/77 | Loss:0.0449 | top1:98.4600 | AUROC:0.9989\n",
      "\n",
      "Epoch: [25 | 300] LR: 0.318520\n",
      "1/687 | Loss:0.0364 | top1:99.0000 | AUROC:0.9995\n",
      "101/687 | Loss:0.0826 | top1:96.8985 | AUROC:0.9974\n",
      "201/687 | Loss:0.0822 | top1:96.9067 | AUROC:0.9975\n",
      "301/687 | Loss:0.0811 | top1:96.9402 | AUROC:0.9975\n",
      "401/687 | Loss:0.0789 | top1:96.9938 | AUROC:0.9975\n",
      "501/687 | Loss:0.0794 | top1:96.9436 | AUROC:0.9975\n",
      "601/687 | Loss:0.0768 | top1:97.0458 | AUROC:0.9976\n",
      "687/687 | Loss:0.0773 | top1:97.0200 | AUROC:0.9975\n",
      "77/77 | Loss:0.0609 | top1:97.6606 | AUROC:0.9987\n",
      "\n",
      "Epoch: [26 | 300] LR: 0.318284\n",
      "1/687 | Loss:0.1621 | top1:92.7500 | AUROC:0.9945\n",
      "101/687 | Loss:0.0755 | top1:97.1312 | AUROC:0.9978\n",
      "201/687 | Loss:0.0816 | top1:96.8159 | AUROC:0.9975\n",
      "301/687 | Loss:0.0780 | top1:97.0149 | AUROC:0.9976\n",
      "401/687 | Loss:0.0758 | top1:97.1141 | AUROC:0.9977\n",
      "501/687 | Loss:0.0752 | top1:97.1482 | AUROC:0.9977\n",
      "601/687 | Loss:0.0752 | top1:97.1468 | AUROC:0.9977\n",
      "687/687 | Loss:0.0751 | top1:97.1476 | AUROC:0.9977\n",
      "77/77 | Loss:0.0510 | top1:98.0603 | AUROC:0.9989\n",
      "\n",
      "Epoch: [27 | 300] LR: 0.318030\n",
      "1/687 | Loss:0.0904 | top1:96.2500 | AUROC:0.9982\n",
      "101/687 | Loss:0.0737 | top1:97.2005 | AUROC:0.9977\n",
      "201/687 | Loss:0.0695 | top1:97.3843 | AUROC:0.9979\n",
      "301/687 | Loss:0.0684 | top1:97.4435 | AUROC:0.9980\n",
      "401/687 | Loss:0.0701 | top1:97.3959 | AUROC:0.9979\n",
      "501/687 | Loss:0.0702 | top1:97.3718 | AUROC:0.9979\n",
      "601/687 | Loss:0.0704 | top1:97.3602 | AUROC:0.9979\n",
      "687/687 | Loss:0.0724 | top1:97.2788 | AUROC:0.9978\n",
      "77/77 | Loss:0.0769 | top1:97.3100 | AUROC:0.9985\n",
      "\n",
      "Epoch: [28 | 300] LR: 0.317759\n",
      "1/687 | Loss:0.0695 | top1:97.7500 | AUROC:0.9992\n",
      "101/687 | Loss:0.0946 | top1:96.3366 | AUROC:0.9968\n",
      "201/687 | Loss:0.0825 | top1:96.8507 | AUROC:0.9973\n",
      "301/687 | Loss:0.0797 | top1:96.9477 | AUROC:0.9974\n",
      "401/687 | Loss:0.0763 | top1:97.0923 | AUROC:0.9975\n",
      "501/687 | Loss:0.0762 | top1:97.1123 | AUROC:0.9976\n",
      "601/687 | Loss:0.0758 | top1:97.1219 | AUROC:0.9976\n",
      "687/687 | Loss:0.0752 | top1:97.1531 | AUROC:0.9976\n",
      "77/77 | Loss:0.0554 | top1:97.9423 | AUROC:0.9991\n",
      "\n",
      "Epoch: [29 | 300] LR: 0.317471\n",
      "1/687 | Loss:0.0560 | top1:98.0000 | AUROC:0.9987\n",
      "101/687 | Loss:0.0650 | top1:97.5223 | AUROC:0.9980\n",
      "201/687 | Loss:0.0662 | top1:97.5211 | AUROC:0.9980\n",
      "301/687 | Loss:0.0684 | top1:97.4003 | AUROC:0.9979\n",
      "401/687 | Loss:0.0708 | top1:97.3042 | AUROC:0.9978\n",
      "501/687 | Loss:0.0715 | top1:97.2765 | AUROC:0.9978\n",
      "601/687 | Loss:0.0707 | top1:97.3120 | AUROC:0.9978\n",
      "687/687 | Loss:0.0702 | top1:97.3469 | AUROC:0.9978\n",
      "77/77 | Loss:0.0652 | top1:97.4836 | AUROC:0.9987\n",
      "\n",
      "Epoch: [30 | 300] LR: 0.317166\n",
      "1/687 | Loss:0.0729 | top1:97.2500 | AUROC:0.9970\n",
      "101/687 | Loss:0.0774 | top1:97.1312 | AUROC:0.9978\n",
      "201/687 | Loss:0.0692 | top1:97.3843 | AUROC:0.9980\n",
      "301/687 | Loss:0.0716 | top1:97.3007 | AUROC:0.9980\n",
      "401/687 | Loss:0.0737 | top1:97.2113 | AUROC:0.9979\n",
      "501/687 | Loss:0.0723 | top1:97.2680 | AUROC:0.9979\n",
      "601/687 | Loss:0.0718 | top1:97.2908 | AUROC:0.9979\n",
      "687/687 | Loss:0.0714 | top1:97.2996 | AUROC:0.9979\n",
      "77/77 | Loss:0.0404 | top1:98.5321 | AUROC:0.9990\n",
      "\n",
      "Epoch: [31 | 300] LR: 0.316843\n",
      "1/687 | Loss:0.0433 | top1:99.2500 | AUROC:0.9990\n",
      "101/687 | Loss:0.0656 | top1:97.4530 | AUROC:0.9983\n",
      "201/687 | Loss:0.0641 | top1:97.5311 | AUROC:0.9982\n",
      "301/687 | Loss:0.0626 | top1:97.6130 | AUROC:0.9982\n",
      "401/687 | Loss:0.0642 | top1:97.5480 | AUROC:0.9982\n",
      "501/687 | Loss:0.0669 | top1:97.4496 | AUROC:0.9981\n",
      "601/687 | Loss:0.0682 | top1:97.3977 | AUROC:0.9981\n",
      "687/687 | Loss:0.0681 | top1:97.3896 | AUROC:0.9980\n",
      "77/77 | Loss:0.0407 | top1:98.4568 | AUROC:0.9990\n",
      "\n",
      "Epoch: [32 | 300] LR: 0.316504\n",
      "1/687 | Loss:0.0881 | top1:96.2500 | AUROC:0.9955\n",
      "101/687 | Loss:0.0739 | top1:97.1287 | AUROC:0.9978\n",
      "201/687 | Loss:0.0767 | top1:97.0709 | AUROC:0.9977\n",
      "301/687 | Loss:0.0747 | top1:97.1503 | AUROC:0.9978\n",
      "401/687 | Loss:0.0757 | top1:97.1241 | AUROC:0.9977\n",
      "501/687 | Loss:0.0754 | top1:97.1193 | AUROC:0.9977\n",
      "601/687 | Loss:0.0744 | top1:97.1610 | AUROC:0.9978\n",
      "687/687 | Loss:0.0743 | top1:97.1716 | AUROC:0.9978\n",
      "77/77 | Loss:0.0359 | top1:98.7680 | AUROC:0.9991\n",
      "\n",
      "Epoch: [33 | 300] LR: 0.316147\n",
      "1/687 | Loss:0.0327 | top1:99.0000 | AUROC:0.9995\n",
      "101/687 | Loss:0.0646 | top1:97.6287 | AUROC:0.9979\n",
      "201/687 | Loss:0.0680 | top1:97.4751 | AUROC:0.9979\n",
      "301/687 | Loss:0.0664 | top1:97.5266 | AUROC:0.9980\n",
      "401/687 | Loss:0.0697 | top1:97.3853 | AUROC:0.9979\n",
      "501/687 | Loss:0.0708 | top1:97.3488 | AUROC:0.9979\n",
      "601/687 | Loss:0.0706 | top1:97.3444 | AUROC:0.9979\n",
      "687/687 | Loss:0.0694 | top1:97.3874 | AUROC:0.9979\n",
      "77/77 | Loss:0.0379 | top1:98.5190 | AUROC:0.9993\n",
      "\n",
      "Epoch: [34 | 300] LR: 0.315773\n",
      "1/687 | Loss:0.1094 | top1:95.7500 | AUROC:0.9970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101/687 | Loss:0.0573 | top1:97.8688 | AUROC:0.9987\n",
      "201/687 | Loss:0.0634 | top1:97.6381 | AUROC:0.9983\n",
      "301/687 | Loss:0.0698 | top1:97.3796 | AUROC:0.9981\n",
      "401/687 | Loss:0.0687 | top1:97.4059 | AUROC:0.9981\n",
      "501/687 | Loss:0.0692 | top1:97.3822 | AUROC:0.9980\n",
      "601/687 | Loss:0.0696 | top1:97.3694 | AUROC:0.9980\n",
      "687/687 | Loss:0.0715 | top1:97.2952 | AUROC:0.9979\n",
      "77/77 | Loss:0.0472 | top1:98.2208 | AUROC:0.9989\n",
      "\n",
      "Epoch: [35 | 300] LR: 0.315381\n",
      "1/687 | Loss:0.0540 | top1:98.5000 | AUROC:0.9993\n",
      "101/687 | Loss:0.0780 | top1:97.0099 | AUROC:0.9975\n",
      "201/687 | Loss:0.0720 | top1:97.2699 | AUROC:0.9977\n",
      "301/687 | Loss:0.0676 | top1:97.4103 | AUROC:0.9979\n",
      "401/687 | Loss:0.0686 | top1:97.3809 | AUROC:0.9979\n",
      "501/687 | Loss:0.0713 | top1:97.2710 | AUROC:0.9979\n",
      "601/687 | Loss:0.0696 | top1:97.3486 | AUROC:0.9979\n",
      "687/687 | Loss:0.0707 | top1:97.2912 | AUROC:0.9980\n",
      "77/77 | Loss:0.0444 | top1:98.2733 | AUROC:0.9991\n",
      "\n",
      "Epoch: [36 | 300] LR: 0.314973\n",
      "1/687 | Loss:0.0754 | top1:97.2500 | AUROC:0.9979\n",
      "101/687 | Loss:0.0617 | top1:97.5842 | AUROC:0.9982\n",
      "201/687 | Loss:0.0678 | top1:97.4042 | AUROC:0.9981\n",
      "301/687 | Loss:0.0682 | top1:97.4219 | AUROC:0.9981\n",
      "401/687 | Loss:0.0675 | top1:97.4607 | AUROC:0.9981\n",
      "501/687 | Loss:0.0677 | top1:97.4476 | AUROC:0.9981\n",
      "601/687 | Loss:0.0670 | top1:97.4784 | AUROC:0.9981\n",
      "687/687 | Loss:0.0656 | top1:97.5419 | AUROC:0.9981\n",
      "77/77 | Loss:0.0564 | top1:97.8014 | AUROC:0.9992\n",
      "\n",
      "Epoch: [37 | 300] LR: 0.314548\n",
      "1/687 | Loss:0.0570 | top1:97.7500 | AUROC:0.9999\n",
      "101/687 | Loss:0.0635 | top1:97.6064 | AUROC:0.9982\n",
      "201/687 | Loss:0.0704 | top1:97.3383 | AUROC:0.9980\n",
      "301/687 | Loss:0.0702 | top1:97.3347 | AUROC:0.9981\n",
      "401/687 | Loss:0.0720 | top1:97.2375 | AUROC:0.9980\n",
      "501/687 | Loss:0.0696 | top1:97.3338 | AUROC:0.9981\n",
      "601/687 | Loss:0.0690 | top1:97.3727 | AUROC:0.9981\n",
      "687/687 | Loss:0.0690 | top1:97.3754 | AUROC:0.9981\n",
      "77/77 | Loss:0.0423 | top1:98.6337 | AUROC:0.9992\n",
      "\n",
      "Epoch: [38 | 300] LR: 0.314106\n",
      "1/687 | Loss:0.0454 | top1:99.2500 | AUROC:0.9986\n",
      "101/687 | Loss:0.0631 | top1:97.6856 | AUROC:0.9983\n",
      "201/687 | Loss:0.0641 | top1:97.6505 | AUROC:0.9982\n",
      "301/687 | Loss:0.0663 | top1:97.5316 | AUROC:0.9981\n",
      "401/687 | Loss:0.0650 | top1:97.5923 | AUROC:0.9981\n",
      "501/687 | Loss:0.0645 | top1:97.6028 | AUROC:0.9981\n",
      "601/687 | Loss:0.0645 | top1:97.6077 | AUROC:0.9982\n",
      "687/687 | Loss:0.0643 | top1:97.6272 | AUROC:0.9982\n",
      "77/77 | Loss:0.0351 | top1:98.8336 | AUROC:0.9993\n",
      "\n",
      "Epoch: [39 | 300] LR: 0.313647\n",
      "1/687 | Loss:0.0458 | top1:98.7500 | AUROC:0.9986\n",
      "101/687 | Loss:0.0649 | top1:97.5842 | AUROC:0.9984\n",
      "201/687 | Loss:0.0774 | top1:97.0883 | AUROC:0.9978\n",
      "301/687 | Loss:0.0745 | top1:97.2334 | AUROC:0.9977\n",
      "401/687 | Loss:0.0761 | top1:97.1403 | AUROC:0.9977\n",
      "501/687 | Loss:0.0747 | top1:97.1776 | AUROC:0.9978\n",
      "601/687 | Loss:0.0725 | top1:97.2625 | AUROC:0.9979\n",
      "687/687 | Loss:0.0714 | top1:97.3025 | AUROC:0.9979\n",
      "77/77 | Loss:0.0338 | top1:98.7189 | AUROC:0.9993\n",
      "\n",
      "Epoch: [40 | 300] LR: 0.313171\n",
      "1/687 | Loss:0.0409 | top1:98.5000 | AUROC:0.9992\n",
      "101/687 | Loss:0.0627 | top1:97.6188 | AUROC:0.9986\n",
      "201/687 | Loss:0.0655 | top1:97.5187 | AUROC:0.9985\n",
      "301/687 | Loss:0.0635 | top1:97.6046 | AUROC:0.9984\n",
      "401/687 | Loss:0.0632 | top1:97.6166 | AUROC:0.9984\n",
      "501/687 | Loss:0.0624 | top1:97.6457 | AUROC:0.9984\n",
      "601/687 | Loss:0.0625 | top1:97.6452 | AUROC:0.9984\n",
      "687/687 | Loss:0.0631 | top1:97.6272 | AUROC:0.9984\n",
      "77/77 | Loss:0.0534 | top1:98.0603 | AUROC:0.9994\n",
      "\n",
      "Epoch: [41 | 300] LR: 0.312678\n",
      "1/687 | Loss:0.0583 | top1:97.7500 | AUROC:0.9995\n",
      "101/687 | Loss:0.0731 | top1:97.1411 | AUROC:0.9982\n",
      "201/687 | Loss:0.0679 | top1:97.3993 | AUROC:0.9983\n",
      "301/687 | Loss:0.0685 | top1:97.3937 | AUROC:0.9982\n",
      "401/687 | Loss:0.0672 | top1:97.4526 | AUROC:0.9983\n",
      "501/687 | Loss:0.0652 | top1:97.5299 | AUROC:0.9983\n",
      "601/687 | Loss:0.0639 | top1:97.5853 | AUROC:0.9983\n",
      "687/687 | Loss:0.0645 | top1:97.5678 | AUROC:0.9983\n",
      "77/77 | Loss:0.0680 | top1:97.2510 | AUROC:0.9991\n",
      "\n",
      "Epoch: [42 | 300] LR: 0.312169\n",
      "1/687 | Loss:0.0557 | top1:97.7500 | AUROC:0.9992\n",
      "101/687 | Loss:0.0636 | top1:97.6188 | AUROC:0.9981\n",
      "201/687 | Loss:0.0636 | top1:97.6231 | AUROC:0.9983\n",
      "301/687 | Loss:0.0650 | top1:97.5723 | AUROC:0.9982\n",
      "401/687 | Loss:0.0650 | top1:97.5661 | AUROC:0.9982\n",
      "501/687 | Loss:0.0656 | top1:97.5324 | AUROC:0.9982\n",
      "601/687 | Loss:0.0649 | top1:97.5657 | AUROC:0.9982\n",
      "687/687 | Loss:0.0661 | top1:97.5117 | AUROC:0.9982\n",
      "77/77 | Loss:0.0785 | top1:97.1003 | AUROC:0.9983\n",
      "\n",
      "Epoch: [43 | 300] LR: 0.311643\n",
      "1/687 | Loss:0.0839 | top1:97.5000 | AUROC:0.9957\n",
      "101/687 | Loss:0.0872 | top1:96.6559 | AUROC:0.9972\n",
      "201/687 | Loss:0.0776 | top1:96.9925 | AUROC:0.9974\n",
      "301/687 | Loss:0.0734 | top1:97.1977 | AUROC:0.9977\n",
      "401/687 | Loss:0.0739 | top1:97.1777 | AUROC:0.9978\n",
      "501/687 | Loss:0.0730 | top1:97.2221 | AUROC:0.9979\n",
      "601/687 | Loss:0.0711 | top1:97.2966 | AUROC:0.9980\n",
      "687/687 | Loss:0.0698 | top1:97.3440 | AUROC:0.9980\n",
      "77/77 | Loss:0.0364 | top1:98.6337 | AUROC:0.9992\n",
      "\n",
      "Epoch: [44 | 300] LR: 0.311100\n",
      "1/687 | Loss:0.0411 | top1:99.2500 | AUROC:0.9990\n",
      "101/687 | Loss:0.0594 | top1:97.7871 | AUROC:0.9984\n",
      "201/687 | Loss:0.0593 | top1:97.8209 | AUROC:0.9984\n",
      "301/687 | Loss:0.0612 | top1:97.7209 | AUROC:0.9984\n",
      "401/687 | Loss:0.0606 | top1:97.7469 | AUROC:0.9984\n",
      "501/687 | Loss:0.0598 | top1:97.7630 | AUROC:0.9985\n",
      "601/687 | Loss:0.0612 | top1:97.7180 | AUROC:0.9984\n",
      "687/687 | Loss:0.0610 | top1:97.7150 | AUROC:0.9984\n",
      "77/77 | Loss:0.0311 | top1:98.8762 | AUROC:0.9994\n",
      "\n",
      "Epoch: [45 | 300] LR: 0.310541\n",
      "1/687 | Loss:0.0277 | top1:98.7500 | AUROC:0.9996\n",
      "101/687 | Loss:0.0627 | top1:97.6832 | AUROC:0.9985\n",
      "201/687 | Loss:0.0589 | top1:97.8259 | AUROC:0.9986\n",
      "301/687 | Loss:0.0588 | top1:97.8073 | AUROC:0.9985\n",
      "401/687 | Loss:0.0686 | top1:97.3859 | AUROC:0.9982\n",
      "501/687 | Loss:0.0691 | top1:97.3573 | AUROC:0.9982\n",
      "601/687 | Loss:0.0690 | top1:97.3661 | AUROC:0.9981\n",
      "687/687 | Loss:0.0687 | top1:97.3794 | AUROC:0.9981\n",
      "77/77 | Loss:0.0319 | top1:98.9548 | AUROC:0.9994\n",
      "\n",
      "Epoch: [46 | 300] LR: 0.309965\n",
      "1/687 | Loss:0.0197 | top1:99.5000 | AUROC:0.9999\n",
      "101/687 | Loss:0.0556 | top1:97.8589 | AUROC:0.9985\n",
      "201/687 | Loss:0.0565 | top1:97.8408 | AUROC:0.9986\n",
      "301/687 | Loss:0.0599 | top1:97.7134 | AUROC:0.9985\n",
      "401/687 | Loss:0.0618 | top1:97.6658 | AUROC:0.9984\n",
      "501/687 | Loss:0.0617 | top1:97.6727 | AUROC:0.9984\n",
      "601/687 | Loss:0.0609 | top1:97.6997 | AUROC:0.9984\n",
      "687/687 | Loss:0.0610 | top1:97.7055 | AUROC:0.9984\n",
      "77/77 | Loss:0.0463 | top1:98.2798 | AUROC:0.9990\n",
      "\n",
      "Epoch: [47 | 300] LR: 0.309373\n",
      "1/687 | Loss:0.0628 | top1:96.7500 | AUROC:0.9992\n",
      "101/687 | Loss:0.0583 | top1:97.7648 | AUROC:0.9985\n",
      "201/687 | Loss:0.0638 | top1:97.5460 | AUROC:0.9984\n",
      "301/687 | Loss:0.0647 | top1:97.5324 | AUROC:0.9983\n",
      "401/687 | Loss:0.0624 | top1:97.6253 | AUROC:0.9984\n",
      "501/687 | Loss:0.0622 | top1:97.6312 | AUROC:0.9984\n",
      "601/687 | Loss:0.0618 | top1:97.6456 | AUROC:0.9984\n",
      "687/687 | Loss:0.0627 | top1:97.6210 | AUROC:0.9984\n",
      "77/77 | Loss:0.0371 | top1:98.6730 | AUROC:0.9992\n",
      "\n",
      "Epoch: [48 | 300] LR: 0.308764\n",
      "1/687 | Loss:0.0752 | top1:97.7500 | AUROC:0.9964\n",
      "101/687 | Loss:0.0724 | top1:97.2277 | AUROC:0.9981\n",
      "201/687 | Loss:0.0682 | top1:97.4080 | AUROC:0.9983\n",
      "301/687 | Loss:0.0694 | top1:97.3638 | AUROC:0.9982\n",
      "401/687 | Loss:0.0681 | top1:97.4102 | AUROC:0.9983\n",
      "501/687 | Loss:0.0669 | top1:97.4596 | AUROC:0.9983\n",
      "601/687 | Loss:0.0672 | top1:97.4638 | AUROC:0.9982\n",
      "687/687 | Loss:0.0667 | top1:97.4818 | AUROC:0.9982\n",
      "77/77 | Loss:0.0377 | top1:98.5321 | AUROC:0.9992\n",
      "\n",
      "Epoch: [49 | 300] LR: 0.308139\n",
      "1/687 | Loss:0.0391 | top1:99.0000 | AUROC:0.9992\n",
      "101/687 | Loss:0.0719 | top1:97.2178 | AUROC:0.9982\n",
      "201/687 | Loss:0.0651 | top1:97.4851 | AUROC:0.9983\n",
      "301/687 | Loss:0.0625 | top1:97.6105 | AUROC:0.9984\n",
      "401/687 | Loss:0.0643 | top1:97.5474 | AUROC:0.9982\n",
      "501/687 | Loss:0.0690 | top1:97.3753 | AUROC:0.9980\n",
      "601/687 | Loss:0.0687 | top1:97.3868 | AUROC:0.9980\n",
      "687/687 | Loss:0.0667 | top1:97.4745 | AUROC:0.9981\n",
      "77/77 | Loss:0.0308 | top1:98.8499 | AUROC:0.9995\n",
      "\n",
      "Epoch: [50 | 300] LR: 0.307498\n",
      "1/687 | Loss:0.0431 | top1:98.2500 | AUROC:0.9990\n",
      "101/687 | Loss:0.0637 | top1:97.6460 | AUROC:0.9985\n",
      "201/687 | Loss:0.0647 | top1:97.5709 | AUROC:0.9985\n",
      "301/687 | Loss:0.0633 | top1:97.6146 | AUROC:0.9985\n",
      "401/687 | Loss:0.0607 | top1:97.7257 | AUROC:0.9986\n",
      "501/687 | Loss:0.0598 | top1:97.7620 | AUROC:0.9986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "601/687 | Loss:0.0613 | top1:97.7234 | AUROC:0.9986\n",
      "687/687 | Loss:0.0614 | top1:97.7099 | AUROC:0.9985\n",
      "77/77 | Loss:0.0379 | top1:98.5616 | AUROC:0.9995\n",
      "\n",
      "Epoch: [51 | 300] LR: 0.306841\n",
      "1/687 | Loss:0.0996 | top1:95.2500 | AUROC:0.9984\n",
      "101/687 | Loss:0.0517 | top1:98.0866 | AUROC:0.9988\n",
      "201/687 | Loss:0.0535 | top1:98.0137 | AUROC:0.9987\n",
      "301/687 | Loss:0.0592 | top1:97.7782 | AUROC:0.9986\n",
      "401/687 | Loss:0.0578 | top1:97.8398 | AUROC:0.9986\n",
      "501/687 | Loss:0.0584 | top1:97.8129 | AUROC:0.9986\n",
      "601/687 | Loss:0.0598 | top1:97.7762 | AUROC:0.9985\n",
      "687/687 | Loss:0.0591 | top1:97.8043 | AUROC:0.9985\n",
      "77/77 | Loss:0.0353 | top1:98.6992 | AUROC:0.9994\n",
      "\n",
      "Epoch: [52 | 300] LR: 0.306167\n",
      "1/687 | Loss:0.0293 | top1:99.0000 | AUROC:0.9996\n",
      "101/687 | Loss:0.0613 | top1:97.6262 | AUROC:0.9985\n",
      "201/687 | Loss:0.0696 | top1:97.3184 | AUROC:0.9982\n",
      "301/687 | Loss:0.0647 | top1:97.5241 | AUROC:0.9984\n",
      "401/687 | Loss:0.0628 | top1:97.6166 | AUROC:0.9984\n",
      "501/687 | Loss:0.0636 | top1:97.5968 | AUROC:0.9984\n",
      "601/687 | Loss:0.0648 | top1:97.5524 | AUROC:0.9983\n",
      "687/687 | Loss:0.0646 | top1:97.5598 | AUROC:0.9983\n",
      "77/77 | Loss:0.0395 | top1:98.5649 | AUROC:0.9992\n",
      "\n",
      "Epoch: [53 | 300] LR: 0.305478\n",
      "1/687 | Loss:0.0406 | top1:98.0000 | AUROC:0.9996\n",
      "101/687 | Loss:0.0551 | top1:97.9802 | AUROC:0.9986\n",
      "201/687 | Loss:0.0584 | top1:97.8296 | AUROC:0.9985\n",
      "301/687 | Loss:0.0600 | top1:97.7699 | AUROC:0.9985\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(start_epoch, epochs):\n",
    "    state['lr'] = optimizer.state_dict()['param_groups'][0]['lr']\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "    print('\\nEpoch: [%d | %d] LR: %f' % (epoch + 1, epochs, state['lr']))\n",
    "    \n",
    "    train_loss, train_acc, train_auroc = train(train_loader, model, criterion, optimizer, epoch, use_cuda)\n",
    "    test_loss, test_acc, test_auroc = test(val_loader, model, criterion, epoch, use_cuda)\n",
    "    \n",
    "    logger.append([state['lr'], train_loss, test_loss, train_acc, test_acc, train_auroc, test_auroc])\n",
    "    scheduler_warmup.step()\n",
    "\n",
    "    is_best = test_acc > best_acc\n",
    "    best_acc = max(test_acc, best_acc)\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'state_dict' : model.state_dict(),\n",
    "        'acc': test_acc,\n",
    "        'best_acc': best_acc,\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    }, is_best, checkpoint=checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
