{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import collections\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "\n",
    "from model_pytorch import EfficientNet\n",
    "from utils import Bar,Logger, AverageMeter, accuracy, mkdir_p, savefig\n",
    "from warmup_scheduler import GradualWarmupScheduler\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "import cv2\n",
    "\n",
    "from PIL import ImageFile, ImageOps\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU device 1: True\n"
     ]
    }
   ],
   "source": [
    "# GPU Device\n",
    "gpu_id = 1\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(\"GPU device %d:\" %(gpu_id), use_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = '/media/data2/dataset/GAN_ImageData/StarGAN_128/'\n",
    "target_dir = '/media/data2/dataset/GAN_ImageData/StyleGAN_256/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained = './log/star/128/b0/aug/checkpoint.pth.tar'\n",
    "resume = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model_name = 'efficientnet-b0' # b0-b7 scale\n",
    "\n",
    "# Optimization\n",
    "num_classes = 2\n",
    "epochs = 1000\n",
    "start_epoch = 0\n",
    "train_batch = 250\n",
    "test_batch = 250\n",
    "lr = 0.1\n",
    "momentum = 0.1\n",
    "gamma = 0.1 # LR is multiplied by gamma on schedule\n",
    "\n",
    "# CheckPoint\n",
    "checkpoint = './log/star/128/b0/to_style1/2000shot/self2' # dir\n",
    "if not os.path.isdir(checkpoint):\n",
    "    os.makedirs(checkpoint)\n",
    "num_workers = 8\n",
    "\n",
    "# Seed\n",
    "manual_seed = 7\n",
    "random.seed(manual_seed)\n",
    "torch.cuda.manual_seed_all(manual_seed)\n",
    "\n",
    "# Image\n",
    "size = (128, 128)\n",
    "\n",
    "# cutmix\n",
    "cm_prob = 0.5\n",
    "cm_beta = 1.0\n",
    "\n",
    "# augmentation\n",
    "blur_prob = 0.5\n",
    "blog_sig = 0.5\n",
    "jpg_prob = 0.5\n",
    "\n",
    "best_acc = 0\n",
    "\n",
    "# sp\n",
    "sp_alpha = 0.1\n",
    "sp_beta = 0.1\n",
    "fc_name = '__'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {}\n",
    "state['num_classes'] = num_classes\n",
    "state['epochs'] = epochs\n",
    "state['start_epoch'] = start_epoch\n",
    "state['train_batch'] = train_batch\n",
    "state['test_batch'] = test_batch\n",
    "state['lr'] = lr\n",
    "state['momentum'] = momentum\n",
    "state['gamma'] = gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_augment(img):\n",
    "    img = np.array(img)\n",
    "\n",
    "    if random.random() < blur_prob:\n",
    "        sig = np.random.uniform(0.0, 3.0)\n",
    "        gaussian_blur(img, sig)\n",
    "\n",
    "    if random.random() < jpg_prob:\n",
    "        qual = np.random.uniform(30.0, 100.0)\n",
    "        img = cv2_jpg(img, qual)\n",
    "\n",
    "    return Image.fromarray(img)\n",
    "\n",
    "\n",
    "def gaussian_blur(img, sigma):\n",
    "    gaussian_filter(img[:,:,0], output=img[:,:,0], sigma=sigma)\n",
    "    gaussian_filter(img[:,:,1], output=img[:,:,1], sigma=sigma)\n",
    "    gaussian_filter(img[:,:,2], output=img[:,:,2], sigma=sigma)\n",
    "\n",
    "\n",
    "def cv2_jpg(img, compress_val):\n",
    "    img_cv2 = img[:,:,::-1]\n",
    "    encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), compress_val]\n",
    "    result, encimg = cv2.imencode('.jpg', img_cv2, encode_param)\n",
    "    decimg = cv2.imdecode(encimg, 1)\n",
    "    return decimg[:,:,::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_bbox(size, lam):\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = np.int(W * cut_rat)\n",
    "    cut_h = np.int(H * cut_rat)\n",
    "\n",
    "    # uniform\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join(source_dir, 'style1/2000_shot')\n",
    "val_target_dir = os.path.join(target_dir, 'validation')\n",
    "val_source_dir = os.path.join(source_dir, 'validation')\n",
    "\n",
    "train_aug = transforms.Compose([\n",
    "    transforms.Lambda(lambda img: data_augment(img)),\n",
    "    transforms.Resize(size),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "val_aug = transforms.Compose([\n",
    "    transforms.Resize(size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# pin_memory : cuda pin memeory use\n",
    "train_loader = DataLoader(datasets.ImageFolder(train_dir, transform=train_aug),\n",
    "                          batch_size=train_batch, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "val_target_loader = DataLoader(datasets.ImageFolder(val_target_dir, val_aug),\n",
    "                       batch_size=test_batch, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "val_source_loader = DataLoader(datasets.ImageFolder(val_source_dir, val_aug),\n",
    "                       batch_size=test_batch, shuffle=True, num_workers=num_workers, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> using pre-trained model './log/star/128/b0/aug/checkpoint.pth.tar'\n"
     ]
    }
   ],
   "source": [
    "teacher_model = EfficientNet.from_name(model_name, num_classes=num_classes,\n",
    "                              override_params={'dropout_rate':0.2, 'drop_connect_rate':0.2})\n",
    "student_model = EfficientNet.from_name(model_name, num_classes=num_classes,\n",
    "                              override_params={'dropout_rate':0.2, 'drop_connect_rate':0.2})\n",
    "\n",
    "# Pre-trained\n",
    "if pretrained:\n",
    "    print(\"=> using pre-trained model '{}'\".format(pretrained))\n",
    "    teacher_model.load_state_dict(torch.load(pretrained)['state_dict'])\n",
    "    student_model.load_state_dict(torch.load(pretrained)['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Total params: 4.01M\n"
     ]
    }
   ],
   "source": [
    "teacher_model.to('cuda')\n",
    "student_model.to('cuda')\n",
    "cudnn.benchmark = True\n",
    "print('    Total params: %.2fM' % (sum(p.numel() for p in teacher_model.parameters())/1000000.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = optim.SGD(student_model.parameters(), lr=lr, momentum=momentum)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, 200, gamma=0.1, last_epoch=-1)\n",
    "scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)\n",
    "scheduler_warmup = GradualWarmupScheduler(optimizer, multiplier=2, total_epoch=50, after_scheduler=scheduler_cosine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resume\n",
    "if resume:\n",
    "    print('==> Resuming from checkpoint..')\n",
    "    checkpoint = os.path.dirname(resume)\n",
    "    resume = torch.load(resume)\n",
    "    best_acc = resume['best_acc']\n",
    "    start_epoch = resume['epoch']\n",
    "    student_model.load_state_dict(resume['state_dict'])\n",
    "    optimizer.load_state_dict(resume['optimizer'])\n",
    "    logger = Logger(os.path.join(checkpoint, 'log.txt'), resume=True)\n",
    "else:\n",
    "    logger = Logger(os.path.join(checkpoint, 'log.txt'))\n",
    "    logger.set_names(['Learning Rate', 'Train Loss', 'Valid Loss', 'Source Loss', 'Train AUROC', 'Valid AUROC', 'Source AUROC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EfficientNet(\n",
       "  (_conv_stem): Conv2dStaticSamePadding(\n",
       "    3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
       "    (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "  )\n",
       "  (_gn0): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "  (_blocks): ModuleList(\n",
       "    (0): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        32, 32, kernel_size=(3, 3), stride=[1, 1], groups=32, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        32, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        8, 32, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 16, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (1): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 96, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        96, 96, kernel_size=(3, 3), stride=[2, 2], groups=96, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 96, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        96, 4, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        4, 96, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 24, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (2): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 144, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 144, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 24, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (3): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 144, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        144, 144, kernel_size=(5, 5), stride=[2, 2], groups=144, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 144, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 40, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (4): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 240, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        240, 240, kernel_size=(5, 5), stride=(1, 1), groups=240, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 240, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 40, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (5): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 240, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        240, 240, kernel_size=(3, 3), stride=[2, 2], groups=240, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 240, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 80, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (6): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 480, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 480, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 80, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (7): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 480, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 480, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 80, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (8): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 480, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        480, 480, kernel_size=(5, 5), stride=[1, 1], groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 480, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 112, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (9): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 672, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 672, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 112, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (10): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 672, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 672, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 112, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (11): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 672, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5), stride=[2, 2], groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 672, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 192, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (12): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 1152, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 1152, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 192, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (13): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 1152, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 1152, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 192, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (14): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 1152, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 1152, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 192, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (15): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 1152, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(3, 3), stride=[1, 1], groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 1152, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 320, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "  )\n",
       "  (_conv_head): Conv2dStaticSamePadding(\n",
       "    320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "    (static_padding): Identity()\n",
       "  )\n",
       "  (_gn1): GroupNorm(8, 1280, eps=1e-05, affine=True)\n",
       "  (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n",
       "  (_dropout): Dropout(p=0.2, inplace=False)\n",
       "  (_fc): Linear(in_features=1280, out_features=2, bias=True)\n",
       "  (_swish): MemoryEfficientSwish()\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for param in teacher_model.parameters():\n",
    "    param.requires_grad = False\n",
    "teacher_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_model_weights = {}\n",
    "for name, param in teacher_model.named_parameters():\n",
    "    teacher_model_weights[name] = param.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_cls(model):\n",
    "    l2_cls = torch.tensor(0.).cuda()\n",
    "    for name, param in model.named_parameters():\n",
    "        if name.startswith(fc_name):\n",
    "            l2_cls += 0.5 * torch.norm(param) ** 2\n",
    "    return l2_cls\n",
    "\n",
    "def reg_l2sp(model):\n",
    "    sp_loss = torch.tensor(0.).cuda()\n",
    "    for name, param in model.named_parameters():\n",
    "        if not name.startswith(fc_name):\n",
    "            sp_loss += 0.5 * torch.norm(param - teacher_model_weights[name]) ** 2\n",
    "    return sp_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, teacher_model, student_model, criterion, optimizer, epoch, use_cuda):\n",
    "    teacher_model.eval()\n",
    "    student_model.train()\n",
    "    \n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    arc = AverageMeter()\n",
    "    end = time.time()\n",
    "    cls_losses = AverageMeter()\n",
    "    sp_losses = AverageMeter()\n",
    "    main_losses = AverageMeter()\n",
    "    alpha = AverageMeter()\n",
    "    \n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        batch_size = inputs.size(0)\n",
    "        if batch_size < train_batch:\n",
    "            continue\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            \n",
    "        r = np.random.rand(1)\n",
    "        if cm_beta > 0 and r < cm_prob:\n",
    "            \n",
    "            rand_index = torch.randperm(inputs.size()[0]).cuda()\n",
    "            tt= targets[rand_index]\n",
    "            boolean = targets==tt\n",
    "            rand_index = rand_index[boolean]\n",
    "            lam = np.random.beta(cm_beta, cm_beta)\n",
    "            bbx1, bby1, bbx2, bby2 = rand_bbox(inputs.size(), lam)\n",
    "            inputs[boolean, :, bbx1:bbx2, bby1:bby2] = inputs[rand_index, :, bbx1:bbx2, bby1:bby2]\n",
    "\n",
    "        # compute output\n",
    "        with torch.no_grad():\n",
    "            teacher_outputs = teacher_model(inputs)\n",
    "            teacher_loss = criterion(teacher_outputs, targets)\n",
    "            sp_alpha = 0\n",
    "            sigmoid = nn.Sigmoid()\n",
    "            sp_alpha += sigmoid(-teacher_loss)\n",
    "        \n",
    "        outputs = student_model(inputs)\n",
    "        loss_main = criterion(outputs, targets)\n",
    "        loss_cls = 0\n",
    "        loss_sp = 0\n",
    "        loss_cls = reg_cls(student_model)\n",
    "        loss_sp = reg_l2sp(student_model)\n",
    "        loss =  loss_main + sp_alpha*loss_sp\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        losses.update(loss.data.tolist(), inputs.size(0))\n",
    "        cls_losses.update(loss_cls, inputs.size(0))\n",
    "        sp_losses.update(loss_sp, inputs.size(0))\n",
    "        main_losses.update(loss_main.tolist(), inputs.size(0))\n",
    "        alpha.update(sp_alpha, inputs.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        \n",
    "    print('Train | {batch}/{size} | Loss:{loss:.4f} | MainLoss:{main:.4f} | Alpha:{alp:.4f} | SPLoss:{sp:.4f} | CLSLoss:{cls:.4f} | AUROC:{ac:.4f}'.format(\n",
    "                     batch=batch_idx+1, size=len(train_loader), loss=losses.avg, main=main_losses.avg, alp=alpha.avg, sp=sp_losses.avg, cls=cls_losses.avg, ac=arc.avg))\n",
    "    return (losses.avg, arc.avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(val_loader, model, criterion, epoch, use_cuda):\n",
    "    global best_acc\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    arc = AverageMeter()\n",
    "    cls_losses = AverageMeter()\n",
    "    sp_losses = AverageMeter()\n",
    "    main_losses = AverageMeter()\n",
    "\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(val_loader):\n",
    "            # measure data loading time\n",
    "            data_time.update(time.time() - end)\n",
    "\n",
    "            if use_cuda:\n",
    "                inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "            # compute output\n",
    "            outputs = model(inputs)\n",
    "            loss_main = criterion(outputs, targets)\n",
    "            loss_cls = 0\n",
    "            loss_sp = 0\n",
    "            loss_cls = reg_cls(model)\n",
    "            loss_sp = reg_l2sp(model)\n",
    "            loss = loss_main + 0*loss_sp + 0*loss_cls\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            auroc = roc_auc_score(targets.cpu().detach().numpy(), outputs.cpu().detach().numpy()[:,1])\n",
    "            losses.update(loss.data.tolist(), inputs.size(0))\n",
    "            arc.update(auroc, inputs.size(0))\n",
    "            cls_losses.update(loss_cls, inputs.size(0))\n",
    "            sp_losses.update(loss_sp, inputs.size(0))\n",
    "            main_losses.update(loss_main.tolist(), inputs.size(0))\n",
    "\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "    print('Test | {batch}/{size} | Loss:{loss:.4f} | MainLoss:{main:.4f} | SPLoss:{sp:.4f} | CLSLoss:{cls:.4f} | AUROC:{ac:.4f}'.format(\n",
    "                     batch=batch_idx+1, size=len(train_loader), loss=losses.avg, main=main_losses.avg, sp=sp_losses.avg, cls=cls_losses.avg, ac=arc.avg))\n",
    "    return (losses.avg, arc.avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, checkpoint='checkpoint', filename='checkpoint.pth.tar'):\n",
    "    filepath = os.path.join(checkpoint, filename)\n",
    "    torch.save(state, filepath)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filepath, os.path.join(checkpoint, 'model_best.pth.tar'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [1 | 1000] LR: 0.100000\n",
      "Train | 16/16 | Loss:1.4161 | MainLoss:0.9489 | Alpha:0.0513 | SPLoss:4.6723 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.6939 | MainLoss:0.6939 | SPLoss:4.5847 | CLSLoss:0.0000 | AUROC:0.5255\n",
      "Test | 122/16 | Loss:0.6952 | MainLoss:0.6952 | SPLoss:4.5847 | CLSLoss:0.0000 | AUROC:0.4309\n",
      "\n",
      "Epoch: [2 | 1000] LR: 0.102000\n",
      "Train | 16/16 | Loss:1.0900 | MainLoss:0.6966 | Alpha:0.0519 | SPLoss:3.9336 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.6928 | MainLoss:0.6928 | SPLoss:3.2684 | CLSLoss:0.0000 | AUROC:0.5479\n",
      "Test | 122/16 | Loss:0.6935 | MainLoss:0.6935 | SPLoss:3.2684 | CLSLoss:0.0000 | AUROC:0.5067\n",
      "\n",
      "Epoch: [3 | 1000] LR: 0.104000\n",
      "Train | 16/16 | Loss:0.9729 | MainLoss:0.6935 | Alpha:0.0513 | SPLoss:2.7939 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.6972 | MainLoss:0.6972 | SPLoss:2.3170 | CLSLoss:0.0000 | AUROC:0.5738\n",
      "Test | 122/16 | Loss:0.6950 | MainLoss:0.6950 | SPLoss:2.3170 | CLSLoss:0.0000 | AUROC:0.6483\n",
      "\n",
      "Epoch: [4 | 1000] LR: 0.106000\n",
      "Train | 16/16 | Loss:0.8921 | MainLoss:0.6945 | Alpha:0.0554 | SPLoss:1.9757 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.6883 | MainLoss:0.6883 | SPLoss:1.6312 | CLSLoss:0.0000 | AUROC:0.5968\n",
      "Test | 122/16 | Loss:0.6726 | MainLoss:0.6726 | SPLoss:1.6312 | CLSLoss:0.0000 | AUROC:0.7878\n",
      "\n",
      "Epoch: [5 | 1000] LR: 0.108000\n",
      "Train | 16/16 | Loss:0.8290 | MainLoss:0.6899 | Alpha:0.0516 | SPLoss:1.3909 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.6776 | MainLoss:0.6776 | SPLoss:1.1483 | CLSLoss:0.0000 | AUROC:0.6241\n",
      "Test | 122/16 | Loss:0.6346 | MainLoss:0.6346 | SPLoss:1.1483 | CLSLoss:0.0000 | AUROC:0.9469\n",
      "\n",
      "Epoch: [6 | 1000] LR: 0.110000\n",
      "Train | 16/16 | Loss:0.7837 | MainLoss:0.6849 | Alpha:0.0516 | SPLoss:0.9883 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.6601 | MainLoss:0.6601 | SPLoss:0.8316 | CLSLoss:0.0000 | AUROC:0.6640\n",
      "Test | 122/16 | Loss:0.5763 | MainLoss:0.5763 | SPLoss:0.8316 | CLSLoss:0.0000 | AUROC:0.9743\n",
      "\n",
      "Epoch: [7 | 1000] LR: 0.112000\n",
      "Train | 16/16 | Loss:0.7532 | MainLoss:0.6800 | Alpha:0.0537 | SPLoss:0.7314 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.6531 | MainLoss:0.6531 | SPLoss:0.6424 | CLSLoss:0.0000 | AUROC:0.7005\n",
      "Test | 122/16 | Loss:0.5772 | MainLoss:0.5772 | SPLoss:0.6424 | CLSLoss:0.0000 | AUROC:0.9666\n",
      "\n",
      "Epoch: [8 | 1000] LR: 0.114000\n",
      "Train | 16/16 | Loss:0.7235 | MainLoss:0.6650 | Alpha:0.0479 | SPLoss:0.5847 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.6846 | MainLoss:0.6846 | SPLoss:0.5613 | CLSLoss:0.0000 | AUROC:0.7119\n",
      "Test | 122/16 | Loss:0.5135 | MainLoss:0.5135 | SPLoss:0.5613 | CLSLoss:0.0000 | AUROC:0.9856\n",
      "\n",
      "Epoch: [9 | 1000] LR: 0.116000\n",
      "Train | 16/16 | Loss:0.7088 | MainLoss:0.6570 | Alpha:0.0520 | SPLoss:0.5187 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.6144 | MainLoss:0.6144 | SPLoss:0.5112 | CLSLoss:0.0000 | AUROC:0.7621\n",
      "Test | 122/16 | Loss:0.4876 | MainLoss:0.4876 | SPLoss:0.5112 | CLSLoss:0.0000 | AUROC:0.9749\n",
      "\n",
      "Epoch: [10 | 1000] LR: 0.118000\n",
      "Train | 16/16 | Loss:0.7003 | MainLoss:0.6483 | Alpha:0.0513 | SPLoss:0.5207 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.5803 | MainLoss:0.5803 | SPLoss:0.5504 | CLSLoss:0.0000 | AUROC:0.7930\n",
      "Test | 122/16 | Loss:0.4543 | MainLoss:0.4543 | SPLoss:0.5504 | CLSLoss:0.0000 | AUROC:0.9548\n",
      "\n",
      "Epoch: [11 | 1000] LR: 0.120000\n",
      "Train | 16/16 | Loss:0.6814 | MainLoss:0.6242 | Alpha:0.0498 | SPLoss:0.5722 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.5578 | MainLoss:0.5578 | SPLoss:0.6082 | CLSLoss:0.0000 | AUROC:0.8234\n",
      "Test | 122/16 | Loss:0.4175 | MainLoss:0.4175 | SPLoss:0.6082 | CLSLoss:0.0000 | AUROC:0.9663\n",
      "\n",
      "Epoch: [12 | 1000] LR: 0.122000\n",
      "Train | 16/16 | Loss:0.6585 | MainLoss:0.5920 | Alpha:0.0539 | SPLoss:0.6645 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.4915 | MainLoss:0.4915 | SPLoss:0.7120 | CLSLoss:0.0000 | AUROC:0.8527\n",
      "Test | 122/16 | Loss:0.3326 | MainLoss:0.3326 | SPLoss:0.7120 | CLSLoss:0.0000 | AUROC:0.9730\n",
      "\n",
      "Epoch: [13 | 1000] LR: 0.124000\n",
      "Train | 16/16 | Loss:0.7377 | MainLoss:0.6519 | Alpha:0.0517 | SPLoss:0.8582 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.5560 | MainLoss:0.5560 | SPLoss:0.8214 | CLSLoss:0.0000 | AUROC:0.8078\n",
      "Test | 122/16 | Loss:0.4139 | MainLoss:0.4139 | SPLoss:0.8214 | CLSLoss:0.0000 | AUROC:0.9573\n",
      "\n",
      "Epoch: [14 | 1000] LR: 0.126000\n",
      "Train | 16/16 | Loss:0.6573 | MainLoss:0.5715 | Alpha:0.0508 | SPLoss:0.8584 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.6480 | MainLoss:0.6480 | SPLoss:0.8793 | CLSLoss:0.0000 | AUROC:0.8542\n",
      "Test | 122/16 | Loss:0.2913 | MainLoss:0.2913 | SPLoss:0.8793 | CLSLoss:0.0000 | AUROC:0.9769\n",
      "\n",
      "Epoch: [15 | 1000] LR: 0.128000\n",
      "Train | 16/16 | Loss:0.6409 | MainLoss:0.5404 | Alpha:0.0502 | SPLoss:1.0054 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.4346 | MainLoss:0.4346 | SPLoss:1.0139 | CLSLoss:0.0000 | AUROC:0.8895\n",
      "Test | 122/16 | Loss:0.2578 | MainLoss:0.2578 | SPLoss:1.0139 | CLSLoss:0.0000 | AUROC:0.9692\n",
      "\n",
      "Epoch: [16 | 1000] LR: 0.130000\n",
      "Train | 16/16 | Loss:0.6713 | MainLoss:0.5522 | Alpha:0.0522 | SPLoss:1.1918 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.5344 | MainLoss:0.5344 | SPLoss:1.4306 | CLSLoss:0.0000 | AUROC:0.8933\n",
      "Test | 122/16 | Loss:0.5482 | MainLoss:0.5482 | SPLoss:1.4306 | CLSLoss:0.0000 | AUROC:0.8438\n",
      "\n",
      "Epoch: [17 | 1000] LR: 0.132000\n",
      "Train | 16/16 | Loss:0.6240 | MainLoss:0.4897 | Alpha:0.0512 | SPLoss:1.3426 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.6742 | MainLoss:0.6742 | SPLoss:1.3902 | CLSLoss:0.0000 | AUROC:0.9016\n",
      "Test | 122/16 | Loss:0.5285 | MainLoss:0.5285 | SPLoss:1.3902 | CLSLoss:0.0000 | AUROC:0.9387\n",
      "\n",
      "Epoch: [18 | 1000] LR: 0.134000\n",
      "Train | 16/16 | Loss:0.5858 | MainLoss:0.4451 | Alpha:0.0506 | SPLoss:1.4073 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.4735 | MainLoss:0.4735 | SPLoss:1.4533 | CLSLoss:0.0000 | AUROC:0.9263\n",
      "Test | 122/16 | Loss:0.4681 | MainLoss:0.4681 | SPLoss:1.4533 | CLSLoss:0.0000 | AUROC:0.9041\n",
      "\n",
      "Epoch: [19 | 1000] LR: 0.136000\n",
      "Train | 16/16 | Loss:0.6460 | MainLoss:0.4882 | Alpha:0.0494 | SPLoss:1.5773 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.3582 | MainLoss:0.3582 | SPLoss:1.6626 | CLSLoss:0.0000 | AUROC:0.9351\n",
      "Test | 122/16 | Loss:0.4671 | MainLoss:0.4671 | SPLoss:1.6626 | CLSLoss:0.0000 | AUROC:0.8647\n",
      "\n",
      "Epoch: [20 | 1000] LR: 0.138000\n",
      "Train | 16/16 | Loss:0.6663 | MainLoss:0.4920 | Alpha:0.0521 | SPLoss:1.7436 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.3402 | MainLoss:0.3402 | SPLoss:1.7129 | CLSLoss:0.0000 | AUROC:0.9358\n",
      "Test | 122/16 | Loss:0.3979 | MainLoss:0.3979 | SPLoss:1.7129 | CLSLoss:0.0000 | AUROC:0.9065\n",
      "\n",
      "Epoch: [21 | 1000] LR: 0.140000\n",
      "Train | 16/16 | Loss:0.5959 | MainLoss:0.4269 | Alpha:0.0515 | SPLoss:1.6897 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.3351 | MainLoss:0.3351 | SPLoss:1.7464 | CLSLoss:0.0000 | AUROC:0.9465\n",
      "Test | 122/16 | Loss:0.4424 | MainLoss:0.4424 | SPLoss:1.7464 | CLSLoss:0.0000 | AUROC:0.8934\n",
      "\n",
      "Epoch: [22 | 1000] LR: 0.142000\n",
      "Train | 16/16 | Loss:0.5626 | MainLoss:0.3874 | Alpha:0.0507 | SPLoss:1.7529 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2939 | MainLoss:0.2939 | SPLoss:1.7589 | CLSLoss:0.0000 | AUROC:0.9514\n",
      "Test | 122/16 | Loss:0.3676 | MainLoss:0.3676 | SPLoss:1.7589 | CLSLoss:0.0000 | AUROC:0.9213\n",
      "\n",
      "Epoch: [23 | 1000] LR: 0.144000\n",
      "Train | 16/16 | Loss:0.5442 | MainLoss:0.3648 | Alpha:0.0498 | SPLoss:1.7942 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.3950 | MainLoss:0.3950 | SPLoss:1.8062 | CLSLoss:0.0000 | AUROC:0.9540\n",
      "Test | 122/16 | Loss:0.4595 | MainLoss:0.4595 | SPLoss:1.8062 | CLSLoss:0.0000 | AUROC:0.9257\n",
      "\n",
      "Epoch: [24 | 1000] LR: 0.146000\n",
      "Train | 16/16 | Loss:0.6707 | MainLoss:0.4731 | Alpha:0.0508 | SPLoss:1.9757 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.3501 | MainLoss:0.3501 | SPLoss:2.0110 | CLSLoss:0.0000 | AUROC:0.9512\n",
      "Test | 122/16 | Loss:0.4685 | MainLoss:0.4685 | SPLoss:2.0110 | CLSLoss:0.0000 | AUROC:0.8590\n",
      "\n",
      "Epoch: [25 | 1000] LR: 0.148000\n",
      "Train | 16/16 | Loss:0.5395 | MainLoss:0.3438 | Alpha:0.0506 | SPLoss:1.9564 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2990 | MainLoss:0.2990 | SPLoss:1.9754 | CLSLoss:0.0000 | AUROC:0.9594\n",
      "Test | 122/16 | Loss:0.4298 | MainLoss:0.4298 | SPLoss:1.9754 | CLSLoss:0.0000 | AUROC:0.8892\n",
      "\n",
      "Epoch: [26 | 1000] LR: 0.150000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 16/16 | Loss:0.6015 | MainLoss:0.3953 | Alpha:0.0521 | SPLoss:2.0625 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2536 | MainLoss:0.2536 | SPLoss:2.0721 | CLSLoss:0.0000 | AUROC:0.9626\n",
      "Test | 122/16 | Loss:0.4642 | MainLoss:0.4642 | SPLoss:2.0721 | CLSLoss:0.0000 | AUROC:0.8787\n",
      "\n",
      "Epoch: [27 | 1000] LR: 0.152000\n",
      "Train | 16/16 | Loss:0.5467 | MainLoss:0.3401 | Alpha:0.0536 | SPLoss:2.0656 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.3264 | MainLoss:0.3264 | SPLoss:2.0578 | CLSLoss:0.0000 | AUROC:0.9626\n",
      "Test | 122/16 | Loss:0.5064 | MainLoss:0.5064 | SPLoss:2.0578 | CLSLoss:0.0000 | AUROC:0.8522\n",
      "\n",
      "Epoch: [28 | 1000] LR: 0.154000\n",
      "Train | 16/16 | Loss:0.5819 | MainLoss:0.3682 | Alpha:0.0507 | SPLoss:2.1371 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.3572 | MainLoss:0.3572 | SPLoss:2.0923 | CLSLoss:0.0000 | AUROC:0.9541\n",
      "Test | 122/16 | Loss:0.4595 | MainLoss:0.4595 | SPLoss:2.0923 | CLSLoss:0.0000 | AUROC:0.8792\n",
      "\n",
      "Epoch: [29 | 1000] LR: 0.156000\n",
      "Train | 16/16 | Loss:0.6123 | MainLoss:0.3940 | Alpha:0.0524 | SPLoss:2.1833 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2767 | MainLoss:0.2767 | SPLoss:2.2531 | CLSLoss:0.0000 | AUROC:0.9594\n",
      "Test | 122/16 | Loss:0.5270 | MainLoss:0.5270 | SPLoss:2.2531 | CLSLoss:0.0000 | AUROC:0.8412\n",
      "\n",
      "Epoch: [30 | 1000] LR: 0.158000\n",
      "Train | 16/16 | Loss:0.6289 | MainLoss:0.3903 | Alpha:0.0509 | SPLoss:2.3864 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2813 | MainLoss:0.2813 | SPLoss:2.3196 | CLSLoss:0.0000 | AUROC:0.9552\n",
      "Test | 122/16 | Loss:0.6121 | MainLoss:0.6121 | SPLoss:2.3196 | CLSLoss:0.0000 | AUROC:0.7870\n",
      "\n",
      "Epoch: [31 | 1000] LR: 0.160000\n",
      "Train | 16/16 | Loss:0.5508 | MainLoss:0.3311 | Alpha:0.0553 | SPLoss:2.1975 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.6862 | MainLoss:0.6862 | SPLoss:2.1042 | CLSLoss:0.0000 | AUROC:0.9550\n",
      "Test | 122/16 | Loss:0.7760 | MainLoss:0.7760 | SPLoss:2.1042 | CLSLoss:0.0000 | AUROC:0.9187\n",
      "\n",
      "Epoch: [32 | 1000] LR: 0.162000\n",
      "Train | 16/16 | Loss:0.5898 | MainLoss:0.3687 | Alpha:0.0504 | SPLoss:2.2101 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2466 | MainLoss:0.2466 | SPLoss:2.1549 | CLSLoss:0.0000 | AUROC:0.9665\n",
      "Test | 122/16 | Loss:0.5475 | MainLoss:0.5475 | SPLoss:2.1549 | CLSLoss:0.0000 | AUROC:0.8459\n",
      "\n",
      "Epoch: [33 | 1000] LR: 0.164000\n",
      "Train | 16/16 | Loss:0.5847 | MainLoss:0.3662 | Alpha:0.0525 | SPLoss:2.1851 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2667 | MainLoss:0.2667 | SPLoss:2.2024 | CLSLoss:0.0000 | AUROC:0.9623\n",
      "Test | 122/16 | Loss:0.5817 | MainLoss:0.5817 | SPLoss:2.2024 | CLSLoss:0.0000 | AUROC:0.8132\n",
      "\n",
      "Epoch: [34 | 1000] LR: 0.166000\n",
      "Train | 16/16 | Loss:0.5598 | MainLoss:0.3444 | Alpha:0.0509 | SPLoss:2.1542 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.3395 | MainLoss:0.3395 | SPLoss:2.1679 | CLSLoss:0.0000 | AUROC:0.9629\n",
      "Test | 122/16 | Loss:0.5556 | MainLoss:0.5556 | SPLoss:2.1679 | CLSLoss:0.0000 | AUROC:0.7974\n",
      "\n",
      "Epoch: [35 | 1000] LR: 0.168000\n",
      "Train | 16/16 | Loss:0.5357 | MainLoss:0.3237 | Alpha:0.0506 | SPLoss:2.1202 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2655 | MainLoss:0.2655 | SPLoss:2.0473 | CLSLoss:0.0000 | AUROC:0.9662\n",
      "Test | 122/16 | Loss:0.5201 | MainLoss:0.5201 | SPLoss:2.0473 | CLSLoss:0.0000 | AUROC:0.8511\n",
      "\n",
      "Epoch: [36 | 1000] LR: 0.170000\n",
      "Train | 16/16 | Loss:0.5471 | MainLoss:0.3351 | Alpha:0.0506 | SPLoss:2.1198 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2589 | MainLoss:0.2589 | SPLoss:1.9831 | CLSLoss:0.0000 | AUROC:0.9629\n",
      "Test | 122/16 | Loss:0.3988 | MainLoss:0.3988 | SPLoss:1.9831 | CLSLoss:0.0000 | AUROC:0.9273\n",
      "\n",
      "Epoch: [37 | 1000] LR: 0.172000\n",
      "Train | 16/16 | Loss:0.6120 | MainLoss:0.3919 | Alpha:0.0517 | SPLoss:2.2009 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2675 | MainLoss:0.2675 | SPLoss:2.2373 | CLSLoss:0.0000 | AUROC:0.9629\n",
      "Test | 122/16 | Loss:0.4631 | MainLoss:0.4631 | SPLoss:2.2373 | CLSLoss:0.0000 | AUROC:0.8678\n",
      "\n",
      "Epoch: [38 | 1000] LR: 0.174000\n",
      "Train | 16/16 | Loss:0.5408 | MainLoss:0.3209 | Alpha:0.0501 | SPLoss:2.1992 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.4183 | MainLoss:0.4183 | SPLoss:2.3221 | CLSLoss:0.0000 | AUROC:0.9610\n",
      "Test | 122/16 | Loss:0.6789 | MainLoss:0.6789 | SPLoss:2.3221 | CLSLoss:0.0000 | AUROC:0.7254\n",
      "\n",
      "Epoch: [39 | 1000] LR: 0.176000\n",
      "Train | 16/16 | Loss:0.5662 | MainLoss:0.3433 | Alpha:0.0516 | SPLoss:2.2286 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2452 | MainLoss:0.2452 | SPLoss:2.1991 | CLSLoss:0.0000 | AUROC:0.9662\n",
      "Test | 122/16 | Loss:0.6213 | MainLoss:0.6213 | SPLoss:2.1991 | CLSLoss:0.0000 | AUROC:0.8264\n",
      "\n",
      "Epoch: [40 | 1000] LR: 0.178000\n",
      "Train | 16/16 | Loss:0.5638 | MainLoss:0.3513 | Alpha:0.0517 | SPLoss:2.1251 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.4221 | MainLoss:0.4221 | SPLoss:2.6407 | CLSLoss:0.0000 | AUROC:0.9386\n",
      "Test | 122/16 | Loss:0.6722 | MainLoss:0.6722 | SPLoss:2.6407 | CLSLoss:0.0000 | AUROC:0.6487\n",
      "\n",
      "Epoch: [41 | 1000] LR: 0.180000\n",
      "Train | 16/16 | Loss:0.5977 | MainLoss:0.3562 | Alpha:0.0494 | SPLoss:2.4142 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2546 | MainLoss:0.2546 | SPLoss:2.2411 | CLSLoss:0.0000 | AUROC:0.9672\n",
      "Test | 122/16 | Loss:0.4973 | MainLoss:0.4973 | SPLoss:2.2411 | CLSLoss:0.0000 | AUROC:0.8518\n",
      "\n",
      "Epoch: [42 | 1000] LR: 0.182000\n",
      "Train | 16/16 | Loss:307.3070 | MainLoss:0.3915 | Alpha:0.0528 | SPLoss:3069.1545 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.3012 | MainLoss:0.3012 | SPLoss:15287.6465 | CLSLoss:0.0000 | AUROC:0.9650\n",
      "Test | 122/16 | Loss:0.6945 | MainLoss:0.6945 | SPLoss:15287.6514 | CLSLoss:0.0000 | AUROC:0.8433\n",
      "\n",
      "Epoch: [43 | 1000] LR: 0.184000\n",
      "Train | 16/16 | Loss:1163.1066 | MainLoss:0.3380 | Alpha:0.0502 | SPLoss:11627.6846 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.5904 | MainLoss:0.5904 | SPLoss:8217.6787 | CLSLoss:0.0000 | AUROC:0.9640\n",
      "Test | 122/16 | Loss:0.7981 | MainLoss:0.7981 | SPLoss:8217.6680 | CLSLoss:0.0000 | AUROC:0.7005\n",
      "\n",
      "Epoch: [44 | 1000] LR: 0.186000\n",
      "Train | 16/16 | Loss:623.4734 | MainLoss:0.3234 | Alpha:0.0503 | SPLoss:6231.5000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2594 | MainLoss:0.2594 | SPLoss:4386.3276 | CLSLoss:0.0000 | AUROC:0.9610\n",
      "Test | 122/16 | Loss:0.5394 | MainLoss:0.5394 | SPLoss:4386.3296 | CLSLoss:0.0000 | AUROC:0.8449\n",
      "\n",
      "Epoch: [45 | 1000] LR: 0.188000\n",
      "Train | 16/16 | Loss:332.1000 | MainLoss:0.3756 | Alpha:0.0500 | SPLoss:3317.2446 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2374 | MainLoss:0.2374 | SPLoss:2325.9248 | CLSLoss:0.0000 | AUROC:0.9676\n",
      "Test | 122/16 | Loss:0.5344 | MainLoss:0.5344 | SPLoss:2325.9231 | CLSLoss:0.0000 | AUROC:0.8522\n",
      "\n",
      "Epoch: [46 | 1000] LR: 0.190000\n",
      "Train | 16/16 | Loss:175.8125 | MainLoss:0.3859 | Alpha:0.0515 | SPLoss:1754.2659 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.3386 | MainLoss:0.3386 | SPLoss:1225.5502 | CLSLoss:0.0000 | AUROC:0.9618\n",
      "Test | 122/16 | Loss:0.6516 | MainLoss:0.6516 | SPLoss:1225.5514 | CLSLoss:0.0000 | AUROC:0.8295\n",
      "\n",
      "Epoch: [47 | 1000] LR: 0.192000\n",
      "Train | 16/16 | Loss:92.5512 | MainLoss:0.3505 | Alpha:0.0506 | SPLoss:922.0071 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.3749 | MainLoss:0.3749 | SPLoss:641.7867 | CLSLoss:0.0000 | AUROC:0.9610\n",
      "Test | 122/16 | Loss:0.6418 | MainLoss:0.6418 | SPLoss:641.7868 | CLSLoss:0.0000 | AUROC:0.8870\n",
      "\n",
      "Epoch: [48 | 1000] LR: 0.194000\n",
      "Train | 16/16 | Loss:48.5409 | MainLoss:0.3613 | Alpha:0.0504 | SPLoss:481.7964 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2784 | MainLoss:0.2784 | SPLoss:334.3514 | CLSLoss:0.0000 | AUROC:0.9638\n",
      "Test | 122/16 | Loss:0.5107 | MainLoss:0.5107 | SPLoss:334.3517 | CLSLoss:0.0000 | AUROC:0.8471\n",
      "\n",
      "Epoch: [49 | 1000] LR: 0.196000\n",
      "Train | 16/16 | Loss:25.4254 | MainLoss:0.3735 | Alpha:0.0509 | SPLoss:250.5194 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2726 | MainLoss:0.2726 | SPLoss:173.6762 | CLSLoss:0.0000 | AUROC:0.9583\n",
      "Test | 122/16 | Loss:0.6451 | MainLoss:0.6451 | SPLoss:173.6761 | CLSLoss:0.0000 | AUROC:0.7705\n",
      "\n",
      "Epoch: [50 | 1000] LR: 0.198000\n",
      "Train | 16/16 | Loss:13.3970 | MainLoss:0.3945 | Alpha:0.0523 | SPLoss:130.0244 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2614 | MainLoss:0.2614 | SPLoss:89.9400 | CLSLoss:0.0000 | AUROC:0.9584\n",
      "Test | 122/16 | Loss:0.4941 | MainLoss:0.4941 | SPLoss:89.9400 | CLSLoss:0.0000 | AUROC:0.8882\n",
      "\n",
      "Epoch: [51 | 1000] LR: 0.200000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 16/16 | Loss:7.0922 | MainLoss:0.3453 | Alpha:0.0513 | SPLoss:67.4697 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.4692 | MainLoss:0.4692 | SPLoss:46.7549 | CLSLoss:0.0000 | AUROC:0.9518\n",
      "Test | 122/16 | Loss:0.5771 | MainLoss:0.5771 | SPLoss:46.7550 | CLSLoss:0.0000 | AUROC:0.9276\n",
      "\n",
      "Epoch: [52 | 1000] LR: 0.200000\n",
      "Train | 16/16 | Loss:3.9595 | MainLoss:0.4030 | Alpha:0.0531 | SPLoss:35.5657 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2527 | MainLoss:0.2527 | SPLoss:24.9995 | CLSLoss:0.0000 | AUROC:0.9639\n",
      "Test | 122/16 | Loss:0.5696 | MainLoss:0.5696 | SPLoss:24.9995 | CLSLoss:0.0000 | AUROC:0.8122\n",
      "\n",
      "Epoch: [53 | 1000] LR: 0.200000\n",
      "Train | 16/16 | Loss:2.2322 | MainLoss:0.3251 | Alpha:0.0518 | SPLoss:19.0707 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.5536 | MainLoss:0.5536 | SPLoss:13.9439 | CLSLoss:0.0000 | AUROC:0.9564\n",
      "Test | 122/16 | Loss:0.7276 | MainLoss:0.7276 | SPLoss:13.9439 | CLSLoss:0.0000 | AUROC:0.7564\n",
      "\n",
      "Epoch: [54 | 1000] LR: 0.199998\n",
      "Train | 16/16 | Loss:1.4818 | MainLoss:0.3794 | Alpha:0.0502 | SPLoss:11.0232 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2725 | MainLoss:0.2725 | SPLoss:8.1699 | CLSLoss:0.0000 | AUROC:0.9663\n",
      "Test | 122/16 | Loss:0.5715 | MainLoss:0.5715 | SPLoss:8.1699 | CLSLoss:0.0000 | AUROC:0.8809\n",
      "\n",
      "Epoch: [55 | 1000] LR: 0.199996\n",
      "Train | 16/16 | Loss:1.0156 | MainLoss:0.3447 | Alpha:0.0505 | SPLoss:6.7087 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.3685 | MainLoss:0.3685 | SPLoss:5.6182 | CLSLoss:0.0000 | AUROC:0.9526\n",
      "Test | 122/16 | Loss:0.7905 | MainLoss:0.7905 | SPLoss:5.6181 | CLSLoss:0.0000 | AUROC:0.7199\n",
      "\n",
      "Epoch: [56 | 1000] LR: 0.199992\n",
      "Train | 16/16 | Loss:0.8286 | MainLoss:0.3458 | Alpha:0.0510 | SPLoss:4.8278 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2827 | MainLoss:0.2827 | SPLoss:4.1516 | CLSLoss:0.0000 | AUROC:0.9609\n",
      "Test | 122/16 | Loss:0.6657 | MainLoss:0.6657 | SPLoss:4.1516 | CLSLoss:0.0000 | AUROC:0.8211\n",
      "\n",
      "Epoch: [57 | 1000] LR: 0.199988\n",
      "Train | 16/16 | Loss:0.7443 | MainLoss:0.3654 | Alpha:0.0515 | SPLoss:3.7891 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2737 | MainLoss:0.2737 | SPLoss:3.2205 | CLSLoss:0.0000 | AUROC:0.9641\n",
      "Test | 122/16 | Loss:0.5931 | MainLoss:0.5931 | SPLoss:3.2205 | CLSLoss:0.0000 | AUROC:0.8509\n",
      "\n",
      "Epoch: [58 | 1000] LR: 0.199982\n",
      "Train | 16/16 | Loss:0.7597 | MainLoss:0.4113 | Alpha:0.0511 | SPLoss:3.4842 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.4340 | MainLoss:0.4340 | SPLoss:2.9487 | CLSLoss:0.0000 | AUROC:0.9603\n",
      "Test | 122/16 | Loss:0.7554 | MainLoss:0.7554 | SPLoss:2.9487 | CLSLoss:0.0000 | AUROC:0.8889\n",
      "\n",
      "Epoch: [59 | 1000] LR: 0.199976\n",
      "Train | 16/16 | Loss:0.6205 | MainLoss:0.3393 | Alpha:0.0498 | SPLoss:2.8125 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2391 | MainLoss:0.2391 | SPLoss:2.6376 | CLSLoss:0.0000 | AUROC:0.9659\n",
      "Test | 122/16 | Loss:0.6276 | MainLoss:0.6276 | SPLoss:2.6376 | CLSLoss:0.0000 | AUROC:0.8077\n",
      "\n",
      "Epoch: [60 | 1000] LR: 0.199968\n",
      "Train | 16/16 | Loss:0.5958 | MainLoss:0.3412 | Alpha:0.0536 | SPLoss:2.5453 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2493 | MainLoss:0.2493 | SPLoss:2.4026 | CLSLoss:0.0000 | AUROC:0.9645\n",
      "Test | 122/16 | Loss:0.4890 | MainLoss:0.4890 | SPLoss:2.4026 | CLSLoss:0.0000 | AUROC:0.8857\n",
      "\n",
      "Epoch: [61 | 1000] LR: 0.199960\n",
      "Train | 16/16 | Loss:0.7970 | MainLoss:0.4721 | Alpha:0.0500 | SPLoss:3.2489 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.3295 | MainLoss:0.3295 | SPLoss:3.7533 | CLSLoss:0.0000 | AUROC:0.9467\n",
      "Test | 122/16 | Loss:0.9379 | MainLoss:0.9379 | SPLoss:3.7533 | CLSLoss:0.0000 | AUROC:0.5344\n",
      "\n",
      "Epoch: [62 | 1000] LR: 0.199951\n",
      "Train | 16/16 | Loss:0.7006 | MainLoss:0.3799 | Alpha:0.0500 | SPLoss:3.2073 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2680 | MainLoss:0.2680 | SPLoss:2.6625 | CLSLoss:0.0000 | AUROC:0.9601\n",
      "Test | 122/16 | Loss:0.6863 | MainLoss:0.6863 | SPLoss:2.6625 | CLSLoss:0.0000 | AUROC:0.7572\n",
      "\n",
      "Epoch: [63 | 1000] LR: 0.199940\n",
      "Train | 16/16 | Loss:0.6626 | MainLoss:0.3957 | Alpha:0.0505 | SPLoss:2.6692 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2844 | MainLoss:0.2844 | SPLoss:2.6338 | CLSLoss:0.0000 | AUROC:0.9582\n",
      "Test | 122/16 | Loss:0.7133 | MainLoss:0.7133 | SPLoss:2.6338 | CLSLoss:0.0000 | AUROC:0.8260\n",
      "\n",
      "Epoch: [64 | 1000] LR: 0.199929\n",
      "Train | 16/16 | Loss:0.6562 | MainLoss:0.3986 | Alpha:0.0501 | SPLoss:2.5766 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.3218 | MainLoss:0.3218 | SPLoss:2.6521 | CLSLoss:0.0000 | AUROC:0.9537\n",
      "Test | 122/16 | Loss:0.6085 | MainLoss:0.6085 | SPLoss:2.6521 | CLSLoss:0.0000 | AUROC:0.7840\n",
      "\n",
      "Epoch: [65 | 1000] LR: 0.199917\n",
      "Train | 16/16 | Loss:0.6562 | MainLoss:0.3963 | Alpha:0.0536 | SPLoss:2.5985 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.3084 | MainLoss:0.3084 | SPLoss:2.6722 | CLSLoss:0.0000 | AUROC:0.9545\n",
      "Test | 122/16 | Loss:0.7649 | MainLoss:0.7649 | SPLoss:2.6722 | CLSLoss:0.0000 | AUROC:0.6840\n",
      "\n",
      "Epoch: [66 | 1000] LR: 0.199903\n",
      "Train | 16/16 | Loss:0.6178 | MainLoss:0.3729 | Alpha:0.0492 | SPLoss:2.4493 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2592 | MainLoss:0.2592 | SPLoss:2.4420 | CLSLoss:0.0000 | AUROC:0.9605\n",
      "Test | 122/16 | Loss:0.7382 | MainLoss:0.7382 | SPLoss:2.4420 | CLSLoss:0.0000 | AUROC:0.7567\n",
      "\n",
      "Epoch: [67 | 1000] LR: 0.199889\n",
      "Train | 16/16 | Loss:0.5285 | MainLoss:0.3032 | Alpha:0.0521 | SPLoss:2.2536 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.4466 | MainLoss:0.4466 | SPLoss:2.2407 | CLSLoss:0.0000 | AUROC:0.9688\n",
      "Test | 122/16 | Loss:0.6266 | MainLoss:0.6266 | SPLoss:2.2407 | CLSLoss:0.0000 | AUROC:0.8104\n",
      "\n",
      "Epoch: [68 | 1000] LR: 0.199874\n",
      "Train | 16/16 | Loss:0.6584 | MainLoss:0.4048 | Alpha:0.0506 | SPLoss:2.5355 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2692 | MainLoss:0.2692 | SPLoss:2.5588 | CLSLoss:0.0000 | AUROC:0.9633\n",
      "Test | 122/16 | Loss:0.7016 | MainLoss:0.7016 | SPLoss:2.5588 | CLSLoss:0.0000 | AUROC:0.7226\n",
      "\n",
      "Epoch: [69 | 1000] LR: 0.199857\n",
      "Train | 16/16 | Loss:0.5902 | MainLoss:0.3509 | Alpha:0.0537 | SPLoss:2.3924 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2630 | MainLoss:0.2630 | SPLoss:2.2173 | CLSLoss:0.0000 | AUROC:0.9683\n",
      "Test | 122/16 | Loss:0.5474 | MainLoss:0.5474 | SPLoss:2.2173 | CLSLoss:0.0000 | AUROC:0.8935\n",
      "\n",
      "Epoch: [70 | 1000] LR: 0.199840\n",
      "Train | 16/16 | Loss:0.5720 | MainLoss:0.3408 | Alpha:0.0516 | SPLoss:2.3114 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2482 | MainLoss:0.2482 | SPLoss:2.2504 | CLSLoss:0.0000 | AUROC:0.9639\n",
      "Test | 122/16 | Loss:0.6514 | MainLoss:0.6514 | SPLoss:2.2504 | CLSLoss:0.0000 | AUROC:0.8612\n",
      "\n",
      "Epoch: [71 | 1000] LR: 0.199822\n",
      "Train | 16/16 | Loss:0.8755 | MainLoss:0.5690 | Alpha:0.0512 | SPLoss:3.0651 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.5048 | MainLoss:0.5048 | SPLoss:3.5870 | CLSLoss:0.0000 | AUROC:0.8975\n",
      "Test | 122/16 | Loss:0.6508 | MainLoss:0.6508 | SPLoss:3.5870 | CLSLoss:0.0000 | AUROC:0.6983\n",
      "\n",
      "Epoch: [72 | 1000] LR: 0.199803\n",
      "Train | 16/16 | Loss:0.7414 | MainLoss:0.4395 | Alpha:0.0504 | SPLoss:3.0189 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2987 | MainLoss:0.2987 | SPLoss:2.6288 | CLSLoss:0.0000 | AUROC:0.9463\n",
      "Test | 122/16 | Loss:0.5141 | MainLoss:0.5141 | SPLoss:2.6288 | CLSLoss:0.0000 | AUROC:0.8483\n",
      "\n",
      "Epoch: [73 | 1000] LR: 0.199782\n",
      "Train | 16/16 | Loss:0.6486 | MainLoss:0.3904 | Alpha:0.0516 | SPLoss:2.5819 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.3210 | MainLoss:0.3210 | SPLoss:2.4524 | CLSLoss:0.0000 | AUROC:0.9539\n",
      "Test | 122/16 | Loss:0.4615 | MainLoss:0.4615 | SPLoss:2.4524 | CLSLoss:0.0000 | AUROC:0.8702\n",
      "\n",
      "Epoch: [74 | 1000] LR: 0.199761\n",
      "Train | 16/16 | Loss:0.6110 | MainLoss:0.3683 | Alpha:0.0523 | SPLoss:2.4270 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2568 | MainLoss:0.2568 | SPLoss:2.3710 | CLSLoss:0.0000 | AUROC:0.9618\n",
      "Test | 122/16 | Loss:0.6205 | MainLoss:0.6205 | SPLoss:2.3710 | CLSLoss:0.0000 | AUROC:0.8236\n",
      "\n",
      "Epoch: [75 | 1000] LR: 0.199739\n",
      "Train | 16/16 | Loss:0.5990 | MainLoss:0.3647 | Alpha:0.0513 | SPLoss:2.3435 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2595 | MainLoss:0.2595 | SPLoss:2.3478 | CLSLoss:0.0000 | AUROC:0.9585\n",
      "Test | 122/16 | Loss:0.6200 | MainLoss:0.6200 | SPLoss:2.3478 | CLSLoss:0.0000 | AUROC:0.8215\n",
      "\n",
      "Epoch: [76 | 1000] LR: 0.199716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 16/16 | Loss:0.5832 | MainLoss:0.3453 | Alpha:0.0533 | SPLoss:2.3786 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.5194 | MainLoss:0.5194 | SPLoss:2.1638 | CLSLoss:0.0000 | AUROC:0.9530\n",
      "Test | 122/16 | Loss:0.7576 | MainLoss:0.7576 | SPLoss:2.1638 | CLSLoss:0.0000 | AUROC:0.8939\n",
      "\n",
      "Epoch: [77 | 1000] LR: 0.199692\n",
      "Train | 16/16 | Loss:0.5857 | MainLoss:0.3527 | Alpha:0.0510 | SPLoss:2.3302 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2489 | MainLoss:0.2489 | SPLoss:2.3765 | CLSLoss:0.0000 | AUROC:0.9647\n",
      "Test | 122/16 | Loss:0.6648 | MainLoss:0.6648 | SPLoss:2.3765 | CLSLoss:0.0000 | AUROC:0.7645\n",
      "\n",
      "Epoch: [78 | 1000] LR: 0.199667\n",
      "Train | 16/16 | Loss:0.5627 | MainLoss:0.3281 | Alpha:0.0505 | SPLoss:2.3455 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2456 | MainLoss:0.2456 | SPLoss:2.2027 | CLSLoss:0.0000 | AUROC:0.9646\n",
      "Test | 122/16 | Loss:0.5988 | MainLoss:0.5988 | SPLoss:2.2027 | CLSLoss:0.0000 | AUROC:0.8518\n",
      "\n",
      "Epoch: [79 | 1000] LR: 0.199640\n",
      "Train | 16/16 | Loss:0.5792 | MainLoss:0.3425 | Alpha:0.0507 | SPLoss:2.3670 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2484 | MainLoss:0.2484 | SPLoss:2.2042 | CLSLoss:0.0000 | AUROC:0.9658\n",
      "Test | 122/16 | Loss:0.4918 | MainLoss:0.4918 | SPLoss:2.2042 | CLSLoss:0.0000 | AUROC:0.8571\n",
      "\n",
      "Epoch: [80 | 1000] LR: 0.199613\n",
      "Train | 16/16 | Loss:0.5806 | MainLoss:0.3444 | Alpha:0.0532 | SPLoss:2.3621 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.4498 | MainLoss:0.4498 | SPLoss:2.3092 | CLSLoss:0.0000 | AUROC:0.9572\n",
      "Test | 122/16 | Loss:0.6291 | MainLoss:0.6291 | SPLoss:2.3092 | CLSLoss:0.0000 | AUROC:0.7786\n",
      "\n",
      "Epoch: [81 | 1000] LR: 0.199585\n",
      "Train | 16/16 | Loss:0.6746 | MainLoss:0.4204 | Alpha:0.0514 | SPLoss:2.5420 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2804 | MainLoss:0.2804 | SPLoss:2.3108 | CLSLoss:0.0000 | AUROC:0.9557\n",
      "Test | 122/16 | Loss:0.5214 | MainLoss:0.5214 | SPLoss:2.3108 | CLSLoss:0.0000 | AUROC:0.8394\n",
      "\n",
      "Epoch: [82 | 1000] LR: 0.199556\n",
      "Train | 16/16 | Loss:0.6154 | MainLoss:0.3708 | Alpha:0.0510 | SPLoss:2.4457 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.3475 | MainLoss:0.3475 | SPLoss:2.5423 | CLSLoss:0.0000 | AUROC:0.9489\n",
      "Test | 122/16 | Loss:0.8008 | MainLoss:0.8008 | SPLoss:2.5423 | CLSLoss:0.0000 | AUROC:0.7991\n",
      "\n",
      "Epoch: [83 | 1000] LR: 0.199526\n",
      "Train | 16/16 | Loss:0.5866 | MainLoss:0.3437 | Alpha:0.0529 | SPLoss:2.4293 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2601 | MainLoss:0.2601 | SPLoss:2.2644 | CLSLoss:0.0000 | AUROC:0.9609\n",
      "Test | 122/16 | Loss:0.5125 | MainLoss:0.5125 | SPLoss:2.2644 | CLSLoss:0.0000 | AUROC:0.8547\n",
      "\n",
      "Epoch: [84 | 1000] LR: 0.199495\n",
      "Train | 16/16 | Loss:0.5771 | MainLoss:0.3433 | Alpha:0.0531 | SPLoss:2.3385 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2525 | MainLoss:0.2525 | SPLoss:2.2586 | CLSLoss:0.0000 | AUROC:0.9627\n",
      "Test | 122/16 | Loss:0.5721 | MainLoss:0.5721 | SPLoss:2.2586 | CLSLoss:0.0000 | AUROC:0.8401\n",
      "\n",
      "Epoch: [85 | 1000] LR: 0.199463\n",
      "Train | 16/16 | Loss:0.5746 | MainLoss:0.3388 | Alpha:0.0526 | SPLoss:2.3576 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2537 | MainLoss:0.2537 | SPLoss:2.2170 | CLSLoss:0.0000 | AUROC:0.9609\n",
      "Test | 122/16 | Loss:0.5244 | MainLoss:0.5244 | SPLoss:2.2170 | CLSLoss:0.0000 | AUROC:0.8655\n",
      "\n",
      "Epoch: [86 | 1000] LR: 0.199430\n",
      "Train | 16/16 | Loss:0.6888 | MainLoss:0.4267 | Alpha:0.0520 | SPLoss:2.6215 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2937 | MainLoss:0.2937 | SPLoss:2.5724 | CLSLoss:0.0000 | AUROC:0.9598\n",
      "Test | 122/16 | Loss:0.6342 | MainLoss:0.6342 | SPLoss:2.5724 | CLSLoss:0.0000 | AUROC:0.7390\n",
      "\n",
      "Epoch: [87 | 1000] LR: 0.199396\n",
      "Train | 16/16 | Loss:0.5926 | MainLoss:0.3470 | Alpha:0.0527 | SPLoss:2.4560 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2711 | MainLoss:0.2711 | SPLoss:2.3548 | CLSLoss:0.0000 | AUROC:0.9625\n",
      "Test | 122/16 | Loss:0.6354 | MainLoss:0.6354 | SPLoss:2.3548 | CLSLoss:0.0000 | AUROC:0.7760\n",
      "\n",
      "Epoch: [88 | 1000] LR: 0.199361\n",
      "Train | 16/16 | Loss:0.6080 | MainLoss:0.3640 | Alpha:0.0505 | SPLoss:2.4406 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2942 | MainLoss:0.2942 | SPLoss:2.3473 | CLSLoss:0.0000 | AUROC:0.9627\n",
      "Test | 122/16 | Loss:0.4991 | MainLoss:0.4991 | SPLoss:2.3473 | CLSLoss:0.0000 | AUROC:0.8428\n",
      "\n",
      "Epoch: [89 | 1000] LR: 0.199325\n",
      "Train | 16/16 | Loss:0.6013 | MainLoss:0.3655 | Alpha:0.0496 | SPLoss:2.3580 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2556 | MainLoss:0.2556 | SPLoss:2.4232 | CLSLoss:0.0000 | AUROC:0.9626\n",
      "Test | 122/16 | Loss:0.7427 | MainLoss:0.7427 | SPLoss:2.4232 | CLSLoss:0.0000 | AUROC:0.7442\n",
      "\n",
      "Epoch: [90 | 1000] LR: 0.199288\n",
      "Train | 16/16 | Loss:0.5814 | MainLoss:0.3536 | Alpha:0.0503 | SPLoss:2.2776 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.3399 | MainLoss:0.3399 | SPLoss:2.4396 | CLSLoss:0.0000 | AUROC:0.9618\n",
      "Test | 122/16 | Loss:0.5644 | MainLoss:0.5644 | SPLoss:2.4396 | CLSLoss:0.0000 | AUROC:0.7844\n",
      "\n",
      "Epoch: [91 | 1000] LR: 0.199250\n",
      "Train | 16/16 | Loss:5376.1855 | MainLoss:0.3399 | Alpha:0.0494 | SPLoss:53758.4570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2536 | MainLoss:0.2536 | SPLoss:73246.6016 | CLSLoss:0.0000 | AUROC:0.9603\n",
      "Test | 122/16 | Loss:0.6634 | MainLoss:0.6634 | SPLoss:73246.6797 | CLSLoss:0.0000 | AUROC:0.8166\n",
      "\n",
      "Epoch: [92 | 1000] LR: 0.199211\n",
      "Train | 16/16 | Loss:5451.4759 | MainLoss:0.3557 | Alpha:0.0520 | SPLoss:54511.2031 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2721 | MainLoss:0.2721 | SPLoss:37361.7930 | CLSLoss:0.0000 | AUROC:0.9603\n",
      "Test | 122/16 | Loss:0.4735 | MainLoss:0.4735 | SPLoss:37361.7266 | CLSLoss:0.0000 | AUROC:0.8638\n",
      "\n",
      "Epoch: [93 | 1000] LR: 0.199172\n",
      "Train | 16/16 | Loss:2781.0513 | MainLoss:0.3455 | Alpha:0.0503 | SPLoss:27807.0566 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.4243 | MainLoss:0.4243 | SPLoss:19060.8711 | CLSLoss:0.0000 | AUROC:0.9591\n",
      "Test | 122/16 | Loss:0.6793 | MainLoss:0.6793 | SPLoss:19060.8750 | CLSLoss:0.0000 | AUROC:0.6859\n",
      "\n",
      "Epoch: [94 | 1000] LR: 0.199131\n",
      "Train | 16/16 | Loss:1419.0434 | MainLoss:0.3156 | Alpha:0.0518 | SPLoss:14187.2783 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.3320 | MainLoss:0.3320 | SPLoss:9726.0010 | CLSLoss:0.0000 | AUROC:0.9658\n",
      "Test | 122/16 | Loss:0.5067 | MainLoss:0.5067 | SPLoss:9726.0078 | CLSLoss:0.0000 | AUROC:0.8405\n",
      "\n",
      "Epoch: [95 | 1000] LR: 0.199089\n",
      "Train | 16/16 | Loss:724.3810 | MainLoss:0.3775 | Alpha:0.0518 | SPLoss:7240.0352 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.4582 | MainLoss:0.4582 | SPLoss:4964.6499 | CLSLoss:0.0000 | AUROC:0.9315\n",
      "Test | 122/16 | Loss:0.9046 | MainLoss:0.9046 | SPLoss:4964.6489 | CLSLoss:0.0000 | AUROC:0.6161\n",
      "\n",
      "Epoch: [96 | 1000] LR: 0.199046\n",
      "Train | 16/16 | Loss:369.9461 | MainLoss:0.3505 | Alpha:0.0498 | SPLoss:3695.9556 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2384 | MainLoss:0.2384 | SPLoss:2534.5750 | CLSLoss:0.0000 | AUROC:0.9670\n",
      "Test | 122/16 | Loss:0.5954 | MainLoss:0.5954 | SPLoss:2534.5740 | CLSLoss:0.0000 | AUROC:0.8355\n",
      "\n",
      "Epoch: [97 | 1000] LR: 0.199002\n",
      "Train | 16/16 | Loss:189.0819 | MainLoss:0.3418 | Alpha:0.0507 | SPLoss:1887.4005 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2648 | MainLoss:0.2648 | SPLoss:1295.1016 | CLSLoss:0.0000 | AUROC:0.9644\n",
      "Test | 122/16 | Loss:0.6918 | MainLoss:0.6918 | SPLoss:1295.1027 | CLSLoss:0.0000 | AUROC:0.7406\n",
      "\n",
      "Epoch: [98 | 1000] LR: 0.198958\n",
      "Train | 16/16 | Loss:96.8344 | MainLoss:0.3659 | Alpha:0.0520 | SPLoss:964.6843 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2790 | MainLoss:0.2790 | SPLoss:662.4433 | CLSLoss:0.0000 | AUROC:0.9592\n",
      "Test | 122/16 | Loss:0.7008 | MainLoss:0.7008 | SPLoss:662.4432 | CLSLoss:0.0000 | AUROC:0.7206\n",
      "\n",
      "Epoch: [99 | 1000] LR: 0.198912\n",
      "Train | 16/16 | Loss:49.6719 | MainLoss:0.3107 | Alpha:0.0496 | SPLoss:493.6112 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2295 | MainLoss:0.2295 | SPLoss:339.1350 | CLSLoss:0.0000 | AUROC:0.9692\n",
      "Test | 122/16 | Loss:0.5479 | MainLoss:0.5479 | SPLoss:339.1356 | CLSLoss:0.0000 | AUROC:0.8465\n",
      "\n",
      "Epoch: [100 | 1000] LR: 0.198865\n",
      "Train | 16/16 | Loss:25.7170 | MainLoss:0.3925 | Alpha:0.0504 | SPLoss:253.2449 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.3218 | MainLoss:0.3218 | SPLoss:174.7643 | CLSLoss:0.0000 | AUROC:0.9449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 122/16 | Loss:0.7485 | MainLoss:0.7485 | SPLoss:174.7641 | CLSLoss:0.0000 | AUROC:0.6561\n",
      "\n",
      "Epoch: [101 | 1000] LR: 0.198817\n",
      "Train | 16/16 | Loss:13.4233 | MainLoss:0.3634 | Alpha:0.0495 | SPLoss:130.5983 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.3174 | MainLoss:0.3174 | SPLoss:90.1826 | CLSLoss:0.0000 | AUROC:0.9658\n",
      "Test | 122/16 | Loss:0.7495 | MainLoss:0.7495 | SPLoss:90.1826 | CLSLoss:0.0000 | AUROC:0.8661\n",
      "\n",
      "Epoch: [102 | 1000] LR: 0.198769\n",
      "Train | 16/16 | Loss:7.1439 | MainLoss:0.3602 | Alpha:0.0499 | SPLoss:67.8368 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2909 | MainLoss:0.2909 | SPLoss:47.4155 | CLSLoss:0.0000 | AUROC:0.9603\n",
      "Test | 122/16 | Loss:0.6814 | MainLoss:0.6814 | SPLoss:47.4155 | CLSLoss:0.0000 | AUROC:0.7437\n",
      "\n",
      "Epoch: [103 | 1000] LR: 0.198719\n",
      "Train | 16/16 | Loss:3.8901 | MainLoss:0.3137 | Alpha:0.0515 | SPLoss:35.7640 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2709 | MainLoss:0.2709 | SPLoss:25.0972 | CLSLoss:0.0000 | AUROC:0.9663\n",
      "Test | 122/16 | Loss:0.6306 | MainLoss:0.6306 | SPLoss:25.0972 | CLSLoss:0.0000 | AUROC:0.8907\n",
      "\n",
      "Epoch: [104 | 1000] LR: 0.198669\n",
      "Train | 16/16 | Loss:2.2826 | MainLoss:0.3522 | Alpha:0.0504 | SPLoss:19.3046 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2711 | MainLoss:0.2711 | SPLoss:13.9197 | CLSLoss:0.0000 | AUROC:0.9682\n",
      "Test | 122/16 | Loss:0.5610 | MainLoss:0.5610 | SPLoss:13.9197 | CLSLoss:0.0000 | AUROC:0.8033\n",
      "\n",
      "Epoch: [105 | 1000] LR: 0.198617\n",
      "Train | 16/16 | Loss:1.4532 | MainLoss:0.3542 | Alpha:0.0530 | SPLoss:10.9907 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2377 | MainLoss:0.2377 | SPLoss:8.2513 | CLSLoss:0.0000 | AUROC:0.9670\n",
      "Test | 122/16 | Loss:0.5681 | MainLoss:0.5681 | SPLoss:8.2513 | CLSLoss:0.0000 | AUROC:0.8471\n",
      "\n",
      "Epoch: [106 | 1000] LR: 0.198564\n",
      "Train | 16/16 | Loss:0.9994 | MainLoss:0.3259 | Alpha:0.0515 | SPLoss:6.7344 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.3049 | MainLoss:0.3049 | SPLoss:5.3889 | CLSLoss:0.0000 | AUROC:0.9664\n",
      "Test | 122/16 | Loss:0.4813 | MainLoss:0.4813 | SPLoss:5.3889 | CLSLoss:0.0000 | AUROC:0.8631\n",
      "\n",
      "Epoch: [107 | 1000] LR: 0.198511\n",
      "Train | 16/16 | Loss:0.8111 | MainLoss:0.3510 | Alpha:0.0516 | SPLoss:4.6013 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2517 | MainLoss:0.2517 | SPLoss:3.8007 | CLSLoss:0.0000 | AUROC:0.9670\n",
      "Test | 122/16 | Loss:0.5365 | MainLoss:0.5365 | SPLoss:3.8007 | CLSLoss:0.0000 | AUROC:0.8367\n",
      "\n",
      "Epoch: [108 | 1000] LR: 0.198456\n",
      "Train | 16/16 | Loss:0.8180 | MainLoss:0.4473 | Alpha:0.0528 | SPLoss:3.7067 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2737 | MainLoss:0.2737 | SPLoss:3.6052 | CLSLoss:0.0000 | AUROC:0.9575\n",
      "Test | 122/16 | Loss:0.7851 | MainLoss:0.7851 | SPLoss:3.6052 | CLSLoss:0.0000 | AUROC:0.7634\n",
      "\n",
      "Epoch: [109 | 1000] LR: 0.198401\n",
      "Train | 16/16 | Loss:0.6223 | MainLoss:0.3095 | Alpha:0.0502 | SPLoss:3.1276 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.3122 | MainLoss:0.3122 | SPLoss:2.7362 | CLSLoss:0.0000 | AUROC:0.9669\n",
      "Test | 122/16 | Loss:0.5142 | MainLoss:0.5142 | SPLoss:2.7362 | CLSLoss:0.0000 | AUROC:0.8494\n",
      "\n",
      "Epoch: [110 | 1000] LR: 0.198345\n",
      "Train | 16/16 | Loss:0.7003 | MainLoss:0.4186 | Alpha:0.0515 | SPLoss:2.8170 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.3917 | MainLoss:0.3917 | SPLoss:2.9847 | CLSLoss:0.0000 | AUROC:0.9525\n",
      "Test | 122/16 | Loss:0.7033 | MainLoss:0.7033 | SPLoss:2.9847 | CLSLoss:0.0000 | AUROC:0.6863\n",
      "\n",
      "Epoch: [111 | 1000] LR: 0.198287\n",
      "Train | 16/16 | Loss:0.6140 | MainLoss:0.3559 | Alpha:0.0522 | SPLoss:2.5810 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2537 | MainLoss:0.2537 | SPLoss:2.3374 | CLSLoss:0.0000 | AUROC:0.9662\n",
      "Test | 122/16 | Loss:0.5867 | MainLoss:0.5867 | SPLoss:2.3374 | CLSLoss:0.0000 | AUROC:0.8618\n",
      "\n",
      "Epoch: [112 | 1000] LR: 0.198229\n",
      "Train | 16/16 | Loss:0.6223 | MainLoss:0.3754 | Alpha:0.0515 | SPLoss:2.4691 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2918 | MainLoss:0.2918 | SPLoss:2.5315 | CLSLoss:0.0000 | AUROC:0.9572\n",
      "Test | 122/16 | Loss:0.5932 | MainLoss:0.5932 | SPLoss:2.5315 | CLSLoss:0.0000 | AUROC:0.7866\n",
      "\n",
      "Epoch: [113 | 1000] LR: 0.198169\n",
      "Train | 16/16 | Loss:0.5981 | MainLoss:0.3517 | Alpha:0.0527 | SPLoss:2.4641 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.5090 | MainLoss:0.5090 | SPLoss:2.9327 | CLSLoss:0.0000 | AUROC:0.9339\n",
      "Test | 122/16 | Loss:0.9885 | MainLoss:0.9885 | SPLoss:2.9327 | CLSLoss:0.0000 | AUROC:0.6467\n",
      "\n",
      "Epoch: [114 | 1000] LR: 0.198109\n",
      "Train | 16/16 | Loss:0.6753 | MainLoss:0.4046 | Alpha:0.0519 | SPLoss:2.7072 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2908 | MainLoss:0.2908 | SPLoss:2.6398 | CLSLoss:0.0000 | AUROC:0.9642\n",
      "Test | 122/16 | Loss:0.5656 | MainLoss:0.5656 | SPLoss:2.6398 | CLSLoss:0.0000 | AUROC:0.7980\n",
      "\n",
      "Epoch: [115 | 1000] LR: 0.198048\n",
      "Train | 16/16 | Loss:0.5624 | MainLoss:0.3158 | Alpha:0.0517 | SPLoss:2.4662 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2389 | MainLoss:0.2389 | SPLoss:2.3124 | CLSLoss:0.0000 | AUROC:0.9655\n",
      "Test | 122/16 | Loss:0.5574 | MainLoss:0.5574 | SPLoss:2.3124 | CLSLoss:0.0000 | AUROC:0.8540\n",
      "\n",
      "Epoch: [116 | 1000] LR: 0.197986\n",
      "Train | 16/16 | Loss:0.6539 | MainLoss:0.4112 | Alpha:0.0521 | SPLoss:2.4268 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.3206 | MainLoss:0.3206 | SPLoss:2.9276 | CLSLoss:0.0000 | AUROC:0.9482\n",
      "Test | 122/16 | Loss:0.6057 | MainLoss:0.6057 | SPLoss:2.9276 | CLSLoss:0.0000 | AUROC:0.7751\n",
      "\n",
      "Epoch: [117 | 1000] LR: 0.197922\n",
      "Train | 16/16 | Loss:0.6097 | MainLoss:0.3393 | Alpha:0.0513 | SPLoss:2.7042 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2533 | MainLoss:0.2533 | SPLoss:2.4530 | CLSLoss:0.0000 | AUROC:0.9652\n",
      "Test | 122/16 | Loss:0.7089 | MainLoss:0.7089 | SPLoss:2.4530 | CLSLoss:0.0000 | AUROC:0.8521\n",
      "\n",
      "Epoch: [118 | 1000] LR: 0.197858\n",
      "Train | 16/16 | Loss:0.6116 | MainLoss:0.3693 | Alpha:0.0512 | SPLoss:2.4224 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2665 | MainLoss:0.2665 | SPLoss:2.4790 | CLSLoss:0.0000 | AUROC:0.9641\n",
      "Test | 122/16 | Loss:0.6748 | MainLoss:0.6748 | SPLoss:2.4790 | CLSLoss:0.0000 | AUROC:0.7685\n",
      "\n",
      "Epoch: [119 | 1000] LR: 0.197793\n",
      "Train | 16/16 | Loss:0.5669 | MainLoss:0.3374 | Alpha:0.0506 | SPLoss:2.2947 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.3553 | MainLoss:0.3553 | SPLoss:2.1913 | CLSLoss:0.0000 | AUROC:0.9686\n",
      "Test | 122/16 | Loss:0.4892 | MainLoss:0.4892 | SPLoss:2.1913 | CLSLoss:0.0000 | AUROC:0.8718\n",
      "\n",
      "Epoch: [120 | 1000] LR: 0.197727\n",
      "Train | 16/16 | Loss:0.5607 | MainLoss:0.3332 | Alpha:0.0518 | SPLoss:2.2752 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2523 | MainLoss:0.2523 | SPLoss:2.1950 | CLSLoss:0.0000 | AUROC:0.9682\n",
      "Test | 122/16 | Loss:0.4521 | MainLoss:0.4521 | SPLoss:2.1950 | CLSLoss:0.0000 | AUROC:0.8786\n",
      "\n",
      "Epoch: [121 | 1000] LR: 0.197660\n",
      "Train | 16/16 | Loss:0.6975 | MainLoss:0.4338 | Alpha:0.0498 | SPLoss:2.6363 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2513 | MainLoss:0.2513 | SPLoss:2.8542 | CLSLoss:0.0000 | AUROC:0.9641\n",
      "Test | 122/16 | Loss:0.8229 | MainLoss:0.8229 | SPLoss:2.8542 | CLSLoss:0.0000 | AUROC:0.6992\n",
      "\n",
      "Epoch: [122 | 1000] LR: 0.197592\n",
      "Train | 16/16 | Loss:0.6054 | MainLoss:0.3403 | Alpha:0.0500 | SPLoss:2.6511 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2716 | MainLoss:0.2716 | SPLoss:2.6952 | CLSLoss:0.0000 | AUROC:0.9598\n",
      "Test | 122/16 | Loss:0.7113 | MainLoss:0.7113 | SPLoss:2.6952 | CLSLoss:0.0000 | AUROC:0.7479\n",
      "\n",
      "Epoch: [123 | 1000] LR: 0.197523\n",
      "Train | 16/16 | Loss:0.6324 | MainLoss:0.3698 | Alpha:0.0518 | SPLoss:2.6261 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2934 | MainLoss:0.2934 | SPLoss:2.9581 | CLSLoss:0.0000 | AUROC:0.9503\n",
      "Test | 122/16 | Loss:0.8379 | MainLoss:0.8379 | SPLoss:2.9581 | CLSLoss:0.0000 | AUROC:0.6522\n",
      "\n",
      "Epoch: [124 | 1000] LR: 0.197453\n",
      "Train | 16/16 | Loss:5.5072 | MainLoss:0.3670 | Alpha:0.0513 | SPLoss:51.4024 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.4279 | MainLoss:0.4279 | SPLoss:40.8579 | CLSLoss:0.0000 | AUROC:0.9060\n",
      "Test | 122/16 | Loss:0.7694 | MainLoss:0.7694 | SPLoss:40.8580 | CLSLoss:0.0000 | AUROC:0.5821\n",
      "\n",
      "Epoch: [125 | 1000] LR: 0.197382\n",
      "Train | 16/16 | Loss:3.4839 | MainLoss:0.3842 | Alpha:0.0519 | SPLoss:30.9969 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2820 | MainLoss:0.2820 | SPLoss:21.9336 | CLSLoss:0.0000 | AUROC:0.9619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 122/16 | Loss:0.5324 | MainLoss:0.5324 | SPLoss:21.9337 | CLSLoss:0.0000 | AUROC:0.8334\n",
      "\n",
      "Epoch: [126 | 1000] LR: 0.197310\n",
      "Train | 16/16 | Loss:2.0881 | MainLoss:0.3793 | Alpha:0.0527 | SPLoss:17.0875 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2539 | MainLoss:0.2539 | SPLoss:12.3123 | CLSLoss:0.0000 | AUROC:0.9611\n",
      "Test | 122/16 | Loss:0.5164 | MainLoss:0.5164 | SPLoss:12.3123 | CLSLoss:0.0000 | AUROC:0.8791\n",
      "\n",
      "Epoch: [127 | 1000] LR: 0.197237\n",
      "Train | 16/16 | Loss:1.3201 | MainLoss:0.3384 | Alpha:0.0500 | SPLoss:9.8172 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.4083 | MainLoss:0.4083 | SPLoss:7.5610 | CLSLoss:0.0000 | AUROC:0.9647\n",
      "Test | 122/16 | Loss:0.6080 | MainLoss:0.6080 | SPLoss:7.5610 | CLSLoss:0.0000 | AUROC:0.7926\n",
      "\n",
      "Epoch: [128 | 1000] LR: 0.197163\n",
      "Train | 16/16 | Loss:0.9920 | MainLoss:0.3648 | Alpha:0.0515 | SPLoss:6.2724 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2552 | MainLoss:0.2552 | SPLoss:5.1336 | CLSLoss:0.0000 | AUROC:0.9645\n",
      "Test | 122/16 | Loss:0.5860 | MainLoss:0.5860 | SPLoss:5.1336 | CLSLoss:0.0000 | AUROC:0.8041\n",
      "\n",
      "Epoch: [129 | 1000] LR: 0.197088\n",
      "Train | 16/16 | Loss:0.7640 | MainLoss:0.3251 | Alpha:0.0529 | SPLoss:4.3893 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2304 | MainLoss:0.2304 | SPLoss:3.5916 | CLSLoss:0.0000 | AUROC:0.9671\n",
      "Test | 122/16 | Loss:0.4579 | MainLoss:0.4579 | SPLoss:3.5916 | CLSLoss:0.0000 | AUROC:0.8974\n",
      "\n",
      "Epoch: [130 | 1000] LR: 0.197013\n",
      "Train | 16/16 | Loss:0.6972 | MainLoss:0.3492 | Alpha:0.0516 | SPLoss:3.4793 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.3910 | MainLoss:0.3910 | SPLoss:2.9830 | CLSLoss:0.0000 | AUROC:0.9622\n",
      "Test | 122/16 | Loss:0.8007 | MainLoss:0.8007 | SPLoss:2.9830 | CLSLoss:0.0000 | AUROC:0.8752\n",
      "\n",
      "Epoch: [131 | 1000] LR: 0.196936\n",
      "Train | 16/16 | Loss:0.6771 | MainLoss:0.3783 | Alpha:0.0505 | SPLoss:2.9881 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2675 | MainLoss:0.2675 | SPLoss:2.8755 | CLSLoss:0.0000 | AUROC:0.9564\n",
      "Test | 122/16 | Loss:0.6176 | MainLoss:0.6176 | SPLoss:2.8755 | CLSLoss:0.0000 | AUROC:0.8318\n",
      "\n",
      "Epoch: [132 | 1000] LR: 0.196858\n",
      "Train | 16/16 | Loss:0.5741 | MainLoss:0.3074 | Alpha:0.0506 | SPLoss:2.6670 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2497 | MainLoss:0.2497 | SPLoss:2.4682 | CLSLoss:0.0000 | AUROC:0.9687\n",
      "Test | 122/16 | Loss:0.5421 | MainLoss:0.5421 | SPLoss:2.4682 | CLSLoss:0.0000 | AUROC:0.8817\n",
      "\n",
      "Epoch: [133 | 1000] LR: 0.196780\n",
      "Train | 16/16 | Loss:0.6016 | MainLoss:0.3509 | Alpha:0.0533 | SPLoss:2.5065 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.4854 | MainLoss:0.4854 | SPLoss:2.5841 | CLSLoss:0.0000 | AUROC:0.9507\n",
      "Test | 122/16 | Loss:1.0356 | MainLoss:1.0356 | SPLoss:2.5841 | CLSLoss:0.0000 | AUROC:0.7825\n",
      "\n",
      "Epoch: [134 | 1000] LR: 0.196700\n",
      "Train | 16/16 | Loss:0.5934 | MainLoss:0.3402 | Alpha:0.0501 | SPLoss:2.5312 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2551 | MainLoss:0.2551 | SPLoss:2.3546 | CLSLoss:0.0000 | AUROC:0.9668\n",
      "Test | 122/16 | Loss:0.6499 | MainLoss:0.6499 | SPLoss:2.3546 | CLSLoss:0.0000 | AUROC:0.8479\n",
      "\n",
      "Epoch: [135 | 1000] LR: 0.196620\n",
      "Train | 16/16 | Loss:0.6050 | MainLoss:0.3683 | Alpha:0.0499 | SPLoss:2.3672 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.3256 | MainLoss:0.3256 | SPLoss:2.7226 | CLSLoss:0.0000 | AUROC:0.9451\n",
      "Test | 122/16 | Loss:0.7413 | MainLoss:0.7413 | SPLoss:2.7226 | CLSLoss:0.0000 | AUROC:0.7094\n",
      "\n",
      "Epoch: [136 | 1000] LR: 0.196538\n",
      "Train | 16/16 | Loss:0.5713 | MainLoss:0.3254 | Alpha:0.0517 | SPLoss:2.4587 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.3520 | MainLoss:0.3520 | SPLoss:2.2575 | CLSLoss:0.0000 | AUROC:0.9622\n",
      "Test | 122/16 | Loss:0.6551 | MainLoss:0.6551 | SPLoss:2.2575 | CLSLoss:0.0000 | AUROC:0.9047\n",
      "\n",
      "Epoch: [137 | 1000] LR: 0.196456\n",
      "Train | 16/16 | Loss:0.5964 | MainLoss:0.3543 | Alpha:0.0543 | SPLoss:2.4205 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2735 | MainLoss:0.2735 | SPLoss:2.3519 | CLSLoss:0.0000 | AUROC:0.9718\n",
      "Test | 122/16 | Loss:0.5624 | MainLoss:0.5624 | SPLoss:2.3519 | CLSLoss:0.0000 | AUROC:0.8097\n",
      "\n",
      "Epoch: [138 | 1000] LR: 0.196372\n",
      "Train | 16/16 | Loss:0.5188 | MainLoss:0.2948 | Alpha:0.0523 | SPLoss:2.2404 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.3385 | MainLoss:0.3385 | SPLoss:2.1793 | CLSLoss:0.0000 | AUROC:0.9686\n",
      "Test | 122/16 | Loss:0.5109 | MainLoss:0.5109 | SPLoss:2.1793 | CLSLoss:0.0000 | AUROC:0.8554\n",
      "\n",
      "Epoch: [139 | 1000] LR: 0.196288\n",
      "Train | 16/16 | Loss:0.6309 | MainLoss:0.3918 | Alpha:0.0513 | SPLoss:2.3901 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.4651 | MainLoss:0.4651 | SPLoss:2.5476 | CLSLoss:0.0000 | AUROC:0.9468\n",
      "Test | 122/16 | Loss:0.7382 | MainLoss:0.7382 | SPLoss:2.5477 | CLSLoss:0.0000 | AUROC:0.6647\n",
      "\n",
      "Epoch: [140 | 1000] LR: 0.196203\n",
      "Train | 16/16 | Loss:0.5682 | MainLoss:0.3406 | Alpha:0.0512 | SPLoss:2.2765 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2362 | MainLoss:0.2362 | SPLoss:2.1589 | CLSLoss:0.0000 | AUROC:0.9657\n",
      "Test | 122/16 | Loss:0.6019 | MainLoss:0.6019 | SPLoss:2.1589 | CLSLoss:0.0000 | AUROC:0.8576\n",
      "\n",
      "Epoch: [141 | 1000] LR: 0.196117\n",
      "Train | 16/16 | Loss:0.5689 | MainLoss:0.3368 | Alpha:0.0508 | SPLoss:2.3210 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.3665 | MainLoss:0.3665 | SPLoss:2.4902 | CLSLoss:0.0000 | AUROC:0.9691\n",
      "Test | 122/16 | Loss:0.6030 | MainLoss:0.6030 | SPLoss:2.4902 | CLSLoss:0.0000 | AUROC:0.7930\n",
      "\n",
      "Epoch: [142 | 1000] LR: 0.196029\n",
      "Train | 16/16 | Loss:0.6785 | MainLoss:0.4031 | Alpha:0.0506 | SPLoss:2.7543 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2456 | MainLoss:0.2456 | SPLoss:2.4999 | CLSLoss:0.0000 | AUROC:0.9659\n",
      "Test | 122/16 | Loss:0.5313 | MainLoss:0.5313 | SPLoss:2.4999 | CLSLoss:0.0000 | AUROC:0.8557\n",
      "\n",
      "Epoch: [143 | 1000] LR: 0.195941\n",
      "Train | 16/16 | Loss:0.6611 | MainLoss:0.3968 | Alpha:0.0525 | SPLoss:2.6432 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.3468 | MainLoss:0.3468 | SPLoss:3.2091 | CLSLoss:0.0000 | AUROC:0.9396\n",
      "Test | 122/16 | Loss:0.8105 | MainLoss:0.8105 | SPLoss:3.2091 | CLSLoss:0.0000 | AUROC:0.6091\n",
      "\n",
      "Epoch: [144 | 1000] LR: 0.195852\n",
      "Train | 16/16 | Loss:0.6234 | MainLoss:0.3412 | Alpha:0.0512 | SPLoss:2.8219 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.3245 | MainLoss:0.3245 | SPLoss:2.4918 | CLSLoss:0.0000 | AUROC:0.9634\n",
      "Test | 122/16 | Loss:0.5426 | MainLoss:0.5426 | SPLoss:2.4918 | CLSLoss:0.0000 | AUROC:0.8420\n",
      "\n",
      "Epoch: [145 | 1000] LR: 0.195762\n",
      "Train | 16/16 | Loss:0.6048 | MainLoss:0.3558 | Alpha:0.0498 | SPLoss:2.4904 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2647 | MainLoss:0.2647 | SPLoss:2.4234 | CLSLoss:0.0000 | AUROC:0.9634\n",
      "Test | 122/16 | Loss:0.7468 | MainLoss:0.7468 | SPLoss:2.4234 | CLSLoss:0.0000 | AUROC:0.8260\n",
      "\n",
      "Epoch: [146 | 1000] LR: 0.195671\n",
      "Train | 16/16 | Loss:0.5576 | MainLoss:0.3211 | Alpha:0.0510 | SPLoss:2.3653 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2410 | MainLoss:0.2410 | SPLoss:2.2270 | CLSLoss:0.0000 | AUROC:0.9693\n",
      "Test | 122/16 | Loss:0.4575 | MainLoss:0.4575 | SPLoss:2.2270 | CLSLoss:0.0000 | AUROC:0.8865\n",
      "\n",
      "Epoch: [147 | 1000] LR: 0.195579\n",
      "Train | 16/16 | Loss:0.5930 | MainLoss:0.3384 | Alpha:0.0517 | SPLoss:2.5453 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2918 | MainLoss:0.2918 | SPLoss:2.4375 | CLSLoss:0.0000 | AUROC:0.9689\n",
      "Test | 122/16 | Loss:0.5620 | MainLoss:0.5620 | SPLoss:2.4375 | CLSLoss:0.0000 | AUROC:0.8292\n",
      "\n",
      "Epoch: [148 | 1000] LR: 0.195486\n",
      "Train | 16/16 | Loss:0.7378 | MainLoss:0.4424 | Alpha:0.0545 | SPLoss:2.9543 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2695 | MainLoss:0.2695 | SPLoss:2.7054 | CLSLoss:0.0000 | AUROC:0.9612\n",
      "Test | 122/16 | Loss:0.7231 | MainLoss:0.7231 | SPLoss:2.7054 | CLSLoss:0.0000 | AUROC:0.7035\n",
      "\n",
      "Epoch: [149 | 1000] LR: 0.195393\n",
      "Train | 16/16 | Loss:0.5789 | MainLoss:0.3289 | Alpha:0.0525 | SPLoss:2.5005 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2435 | MainLoss:0.2435 | SPLoss:2.3757 | CLSLoss:0.0000 | AUROC:0.9682\n",
      "Test | 122/16 | Loss:0.5343 | MainLoss:0.5343 | SPLoss:2.3757 | CLSLoss:0.0000 | AUROC:0.8425\n",
      "\n",
      "Epoch: [150 | 1000] LR: 0.195298\n",
      "Train | 16/16 | Loss:0.5680 | MainLoss:0.3335 | Alpha:0.0517 | SPLoss:2.3456 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.5322 | MainLoss:0.5322 | SPLoss:2.4617 | CLSLoss:0.0000 | AUROC:0.9664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 122/16 | Loss:0.7273 | MainLoss:0.7273 | SPLoss:2.4617 | CLSLoss:0.0000 | AUROC:0.7636\n",
      "\n",
      "Epoch: [151 | 1000] LR: 0.195202\n",
      "Train | 16/16 | Loss:0.6188 | MainLoss:0.3613 | Alpha:0.0505 | SPLoss:2.5752 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.3421 | MainLoss:0.3421 | SPLoss:2.3686 | CLSLoss:0.0000 | AUROC:0.9691\n",
      "Test | 122/16 | Loss:0.5505 | MainLoss:0.5505 | SPLoss:2.3686 | CLSLoss:0.0000 | AUROC:0.8191\n",
      "\n",
      "Epoch: [152 | 1000] LR: 0.195106\n",
      "Train | 16/16 | Loss:0.6199 | MainLoss:0.3788 | Alpha:0.0540 | SPLoss:2.4109 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.4339 | MainLoss:0.4339 | SPLoss:2.4587 | CLSLoss:0.0000 | AUROC:0.9542\n",
      "Test | 122/16 | Loss:0.7755 | MainLoss:0.7755 | SPLoss:2.4587 | CLSLoss:0.0000 | AUROC:0.8488\n",
      "\n",
      "Epoch: [153 | 1000] LR: 0.195008\n",
      "Train | 16/16 | Loss:0.6082 | MainLoss:0.3591 | Alpha:0.0526 | SPLoss:2.4907 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2614 | MainLoss:0.2614 | SPLoss:2.5312 | CLSLoss:0.0000 | AUROC:0.9666\n",
      "Test | 122/16 | Loss:0.6364 | MainLoss:0.6364 | SPLoss:2.5312 | CLSLoss:0.0000 | AUROC:0.7893\n",
      "\n",
      "Epoch: [154 | 1000] LR: 0.194910\n",
      "Train | 16/16 | Loss:0.5871 | MainLoss:0.3474 | Alpha:0.0515 | SPLoss:2.3968 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2817 | MainLoss:0.2817 | SPLoss:2.4306 | CLSLoss:0.0000 | AUROC:0.9610\n",
      "Test | 122/16 | Loss:0.7142 | MainLoss:0.7142 | SPLoss:2.4306 | CLSLoss:0.0000 | AUROC:0.7717\n",
      "\n",
      "Epoch: [155 | 1000] LR: 0.194810\n",
      "Train | 16/16 | Loss:1.3087 | MainLoss:0.3209 | Alpha:0.0506 | SPLoss:9.8779 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2591 | MainLoss:0.2591 | SPLoss:9.4027 | CLSLoss:0.0000 | AUROC:0.9677\n",
      "Test | 122/16 | Loss:0.4980 | MainLoss:0.4980 | SPLoss:9.4027 | CLSLoss:0.0000 | AUROC:0.8639\n",
      "\n",
      "Epoch: [156 | 1000] LR: 0.194710\n",
      "Train | 16/16 | Loss:1.1025 | MainLoss:0.3319 | Alpha:0.0514 | SPLoss:7.7063 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2484 | MainLoss:0.2484 | SPLoss:5.9074 | CLSLoss:0.0000 | AUROC:0.9627\n",
      "Test | 122/16 | Loss:0.4113 | MainLoss:0.4113 | SPLoss:5.9074 | CLSLoss:0.0000 | AUROC:0.9185\n",
      "\n",
      "Epoch: [157 | 1000] LR: 0.194609\n",
      "Train | 16/16 | Loss:0.9538 | MainLoss:0.4139 | Alpha:0.0524 | SPLoss:5.3986 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2626 | MainLoss:0.2626 | SPLoss:4.7059 | CLSLoss:0.0000 | AUROC:0.9617\n",
      "Test | 122/16 | Loss:0.8786 | MainLoss:0.8786 | SPLoss:4.7059 | CLSLoss:0.0000 | AUROC:0.7199\n",
      "\n",
      "Epoch: [158 | 1000] LR: 0.194506\n",
      "Train | 16/16 | Loss:0.7486 | MainLoss:0.3421 | Alpha:0.0515 | SPLoss:4.0651 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2603 | MainLoss:0.2603 | SPLoss:3.7153 | CLSLoss:0.0000 | AUROC:0.9599\n",
      "Test | 122/16 | Loss:0.7904 | MainLoss:0.7904 | SPLoss:3.7153 | CLSLoss:0.0000 | AUROC:0.7270\n",
      "\n",
      "Epoch: [159 | 1000] LR: 0.194403\n",
      "Train | 16/16 | Loss:0.8312 | MainLoss:0.3370 | Alpha:0.0520 | SPLoss:4.9426 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.3552 | MainLoss:0.3552 | SPLoss:5.1212 | CLSLoss:0.0000 | AUROC:0.9556\n",
      "Test | 122/16 | Loss:0.8779 | MainLoss:0.8779 | SPLoss:5.1212 | CLSLoss:0.0000 | AUROC:0.7037\n",
      "\n",
      "Epoch: [160 | 1000] LR: 0.194299\n",
      "Train | 16/16 | Loss:0.7770 | MainLoss:0.3497 | Alpha:0.0498 | SPLoss:4.2735 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.4216 | MainLoss:0.4216 | SPLoss:4.0119 | CLSLoss:0.0000 | AUROC:0.9554\n",
      "Test | 122/16 | Loss:0.6192 | MainLoss:0.6192 | SPLoss:4.0119 | CLSLoss:0.0000 | AUROC:0.7338\n",
      "\n",
      "Epoch: [161 | 1000] LR: 0.194194\n",
      "Train | 16/16 | Loss:0.6787 | MainLoss:0.3296 | Alpha:0.0509 | SPLoss:3.4905 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2483 | MainLoss:0.2483 | SPLoss:3.1520 | CLSLoss:0.0000 | AUROC:0.9633\n",
      "Test | 122/16 | Loss:0.8196 | MainLoss:0.8196 | SPLoss:3.1520 | CLSLoss:0.0000 | AUROC:0.7584\n",
      "\n",
      "Epoch: [162 | 1000] LR: 0.194088\n",
      "Train | 16/16 | Loss:0.6207 | MainLoss:0.3321 | Alpha:0.0528 | SPLoss:2.8859 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.3642 | MainLoss:0.3642 | SPLoss:2.7890 | CLSLoss:0.0000 | AUROC:0.9521\n",
      "Test | 122/16 | Loss:1.0378 | MainLoss:1.0378 | SPLoss:2.7890 | CLSLoss:0.0000 | AUROC:0.7946\n",
      "\n",
      "Epoch: [163 | 1000] LR: 0.193981\n",
      "Train | 16/16 | Loss:0.6376 | MainLoss:0.3598 | Alpha:0.0499 | SPLoss:2.7786 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2297 | MainLoss:0.2297 | SPLoss:2.5092 | CLSLoss:0.0000 | AUROC:0.9685\n",
      "Test | 122/16 | Loss:0.5521 | MainLoss:0.5521 | SPLoss:2.5092 | CLSLoss:0.0000 | AUROC:0.8534\n",
      "\n",
      "Epoch: [164 | 1000] LR: 0.193873\n",
      "Train | 16/16 | Loss:0.5864 | MainLoss:0.3373 | Alpha:0.0522 | SPLoss:2.4910 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.3682 | MainLoss:0.3682 | SPLoss:2.4873 | CLSLoss:0.0000 | AUROC:0.9701\n",
      "Test | 122/16 | Loss:0.5900 | MainLoss:0.5900 | SPLoss:2.4873 | CLSLoss:0.0000 | AUROC:0.7985\n",
      "\n",
      "Epoch: [165 | 1000] LR: 0.193765\n",
      "Train | 16/16 | Loss:0.5794 | MainLoss:0.3354 | Alpha:0.0507 | SPLoss:2.4403 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2516 | MainLoss:0.2516 | SPLoss:2.4406 | CLSLoss:0.0000 | AUROC:0.9705\n",
      "Test | 122/16 | Loss:0.5633 | MainLoss:0.5633 | SPLoss:2.4406 | CLSLoss:0.0000 | AUROC:0.8216\n",
      "\n",
      "Epoch: [166 | 1000] LR: 0.193655\n",
      "Train | 16/16 | Loss:0.5749 | MainLoss:0.3315 | Alpha:0.0518 | SPLoss:2.4338 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2966 | MainLoss:0.2966 | SPLoss:2.4622 | CLSLoss:0.0000 | AUROC:0.9670\n",
      "Test | 122/16 | Loss:0.6813 | MainLoss:0.6813 | SPLoss:2.4622 | CLSLoss:0.0000 | AUROC:0.7455\n",
      "\n",
      "Epoch: [167 | 1000] LR: 0.193544\n",
      "Train | 16/16 | Loss:0.5797 | MainLoss:0.3378 | Alpha:0.0508 | SPLoss:2.4194 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2461 | MainLoss:0.2461 | SPLoss:2.3218 | CLSLoss:0.0000 | AUROC:0.9730\n",
      "Test | 122/16 | Loss:0.5171 | MainLoss:0.5171 | SPLoss:2.3218 | CLSLoss:0.0000 | AUROC:0.8451\n",
      "\n",
      "Epoch: [168 | 1000] LR: 0.193433\n",
      "Train | 16/16 | Loss:0.5946 | MainLoss:0.3572 | Alpha:0.0528 | SPLoss:2.3740 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2409 | MainLoss:0.2409 | SPLoss:2.3348 | CLSLoss:0.0000 | AUROC:0.9681\n",
      "Test | 122/16 | Loss:0.6640 | MainLoss:0.6640 | SPLoss:2.3348 | CLSLoss:0.0000 | AUROC:0.8349\n",
      "\n",
      "Epoch: [169 | 1000] LR: 0.193320\n",
      "Train | 16/16 | Loss:0.5421 | MainLoss:0.3088 | Alpha:0.0514 | SPLoss:2.3340 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.3013 | MainLoss:0.3013 | SPLoss:2.3095 | CLSLoss:0.0000 | AUROC:0.9740\n",
      "Test | 122/16 | Loss:0.5330 | MainLoss:0.5330 | SPLoss:2.3095 | CLSLoss:0.0000 | AUROC:0.8497\n",
      "\n",
      "Epoch: [170 | 1000] LR: 0.193207\n",
      "Train | 16/16 | Loss:0.5911 | MainLoss:0.3569 | Alpha:0.0539 | SPLoss:2.3417 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.4882 | MainLoss:0.4882 | SPLoss:2.3292 | CLSLoss:0.0000 | AUROC:0.9660\n",
      "Test | 122/16 | Loss:0.6129 | MainLoss:0.6129 | SPLoss:2.3292 | CLSLoss:0.0000 | AUROC:0.8321\n",
      "\n",
      "Epoch: [171 | 1000] LR: 0.193093\n",
      "Train | 16/16 | Loss:0.6468 | MainLoss:0.4065 | Alpha:0.0514 | SPLoss:2.4031 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2566 | MainLoss:0.2566 | SPLoss:2.6430 | CLSLoss:0.0000 | AUROC:0.9620\n",
      "Test | 122/16 | Loss:0.7125 | MainLoss:0.7125 | SPLoss:2.6430 | CLSLoss:0.0000 | AUROC:0.7628\n",
      "\n",
      "Epoch: [172 | 1000] LR: 0.192978\n",
      "Train | 16/16 | Loss:0.6107 | MainLoss:0.3617 | Alpha:0.0509 | SPLoss:2.4900 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2402 | MainLoss:0.2402 | SPLoss:2.4002 | CLSLoss:0.0000 | AUROC:0.9661\n",
      "Test | 122/16 | Loss:0.6241 | MainLoss:0.6241 | SPLoss:2.4002 | CLSLoss:0.0000 | AUROC:0.8195\n",
      "\n",
      "Epoch: [173 | 1000] LR: 0.192862\n",
      "Train | 16/16 | Loss:0.5521 | MainLoss:0.3221 | Alpha:0.0507 | SPLoss:2.3000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2312 | MainLoss:0.2312 | SPLoss:2.2532 | CLSLoss:0.0000 | AUROC:0.9685\n",
      "Test | 122/16 | Loss:0.6332 | MainLoss:0.6332 | SPLoss:2.2532 | CLSLoss:0.0000 | AUROC:0.8513\n",
      "\n",
      "Epoch: [174 | 1000] LR: 0.192745\n",
      "Train | 16/16 | Loss:0.5466 | MainLoss:0.3205 | Alpha:0.0522 | SPLoss:2.2615 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.4087 | MainLoss:0.4087 | SPLoss:2.3287 | CLSLoss:0.0000 | AUROC:0.9656\n",
      "Test | 122/16 | Loss:0.5863 | MainLoss:0.5863 | SPLoss:2.3287 | CLSLoss:0.0000 | AUROC:0.8198\n",
      "\n",
      "Epoch: [175 | 1000] LR: 0.192627\n",
      "Train | 16/16 | Loss:0.5323 | MainLoss:0.3093 | Alpha:0.0504 | SPLoss:2.2295 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.4103 | MainLoss:0.4103 | SPLoss:2.2852 | CLSLoss:0.0000 | AUROC:0.9656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 122/16 | Loss:0.9091 | MainLoss:0.9091 | SPLoss:2.2852 | CLSLoss:0.0000 | AUROC:0.8367\n",
      "\n",
      "Epoch: [176 | 1000] LR: 0.192508\n",
      "Train | 16/16 | Loss:0.6238 | MainLoss:0.3723 | Alpha:0.0521 | SPLoss:2.5151 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.3898 | MainLoss:0.3898 | SPLoss:2.6987 | CLSLoss:0.0000 | AUROC:0.9606\n",
      "Test | 122/16 | Loss:0.8053 | MainLoss:0.8053 | SPLoss:2.6987 | CLSLoss:0.0000 | AUROC:0.7139\n",
      "\n",
      "Epoch: [177 | 1000] LR: 0.192388\n",
      "Train | 16/16 | Loss:0.6492 | MainLoss:0.3957 | Alpha:0.0515 | SPLoss:2.5349 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2995 | MainLoss:0.2995 | SPLoss:2.6437 | CLSLoss:0.0000 | AUROC:0.9572\n",
      "Test | 122/16 | Loss:0.7753 | MainLoss:0.7753 | SPLoss:2.6437 | CLSLoss:0.0000 | AUROC:0.6936\n",
      "\n",
      "Epoch: [178 | 1000] LR: 0.192267\n",
      "Train | 16/16 | Loss:0.6335 | MainLoss:0.3797 | Alpha:0.0520 | SPLoss:2.5372 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.3172 | MainLoss:0.3172 | SPLoss:2.8215 | CLSLoss:0.0000 | AUROC:0.9605\n",
      "Test | 122/16 | Loss:0.6166 | MainLoss:0.6166 | SPLoss:2.8215 | CLSLoss:0.0000 | AUROC:0.7478\n",
      "\n",
      "Epoch: [179 | 1000] LR: 0.192146\n",
      "Train | 16/16 | Loss:0.5954 | MainLoss:0.3387 | Alpha:0.0497 | SPLoss:2.5671 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.3083 | MainLoss:0.3083 | SPLoss:2.4636 | CLSLoss:0.0000 | AUROC:0.9685\n",
      "Test | 122/16 | Loss:0.7270 | MainLoss:0.7270 | SPLoss:2.4636 | CLSLoss:0.0000 | AUROC:0.8647\n",
      "\n",
      "Epoch: [180 | 1000] LR: 0.192023\n",
      "Train | 16/16 | Loss:0.6354 | MainLoss:0.3742 | Alpha:0.0507 | SPLoss:2.6118 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2956 | MainLoss:0.2956 | SPLoss:2.6260 | CLSLoss:0.0000 | AUROC:0.9636\n",
      "Test | 122/16 | Loss:0.6719 | MainLoss:0.6719 | SPLoss:2.6260 | CLSLoss:0.0000 | AUROC:0.7354\n",
      "\n",
      "Epoch: [181 | 1000] LR: 0.191900\n",
      "Train | 16/16 | Loss:0.5619 | MainLoss:0.3233 | Alpha:0.0501 | SPLoss:2.3864 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2785 | MainLoss:0.2785 | SPLoss:2.2717 | CLSLoss:0.0000 | AUROC:0.9681\n",
      "Test | 122/16 | Loss:0.5084 | MainLoss:0.5084 | SPLoss:2.2717 | CLSLoss:0.0000 | AUROC:0.8456\n",
      "\n",
      "Epoch: [182 | 1000] LR: 0.191775\n",
      "Train | 16/16 | Loss:0.5749 | MainLoss:0.3371 | Alpha:0.0525 | SPLoss:2.3782 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.3704 | MainLoss:0.3704 | SPLoss:2.3882 | CLSLoss:0.0000 | AUROC:0.9688\n",
      "Test | 122/16 | Loss:0.5357 | MainLoss:0.5357 | SPLoss:2.3882 | CLSLoss:0.0000 | AUROC:0.8386\n",
      "\n",
      "Epoch: [183 | 1000] LR: 0.191650\n",
      "Train | 16/16 | Loss:0.5479 | MainLoss:0.3112 | Alpha:0.0517 | SPLoss:2.3662 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.3522 | MainLoss:0.3522 | SPLoss:2.2578 | CLSLoss:0.0000 | AUROC:0.9664\n",
      "Test | 122/16 | Loss:0.5273 | MainLoss:0.5273 | SPLoss:2.2578 | CLSLoss:0.0000 | AUROC:0.8498\n",
      "\n",
      "Epoch: [184 | 1000] LR: 0.191524\n",
      "Train | 16/16 | Loss:0.5785 | MainLoss:0.3413 | Alpha:0.0518 | SPLoss:2.3719 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2367 | MainLoss:0.2367 | SPLoss:2.2634 | CLSLoss:0.0000 | AUROC:0.9660\n",
      "Test | 122/16 | Loss:0.4899 | MainLoss:0.4899 | SPLoss:2.2634 | CLSLoss:0.0000 | AUROC:0.8794\n",
      "\n",
      "Epoch: [185 | 1000] LR: 0.191397\n",
      "Train | 16/16 | Loss:0.7642 | MainLoss:0.4396 | Alpha:0.0504 | SPLoss:3.2453 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2761 | MainLoss:0.2761 | SPLoss:3.1516 | CLSLoss:0.0000 | AUROC:0.9645\n",
      "Test | 122/16 | Loss:0.7757 | MainLoss:0.7757 | SPLoss:3.1516 | CLSLoss:0.0000 | AUROC:0.6659\n",
      "\n",
      "Epoch: [186 | 1000] LR: 0.191269\n",
      "Train | 16/16 | Loss:0.6443 | MainLoss:0.3564 | Alpha:0.0510 | SPLoss:2.8793 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2525 | MainLoss:0.2525 | SPLoss:2.5025 | CLSLoss:0.0000 | AUROC:0.9641\n",
      "Test | 122/16 | Loss:0.4988 | MainLoss:0.4988 | SPLoss:2.5025 | CLSLoss:0.0000 | AUROC:0.8644\n",
      "\n",
      "Epoch: [187 | 1000] LR: 0.191140\n",
      "Train | 16/16 | Loss:0.7216 | MainLoss:0.4246 | Alpha:0.0504 | SPLoss:2.9705 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2951 | MainLoss:0.2951 | SPLoss:2.9684 | CLSLoss:0.0000 | AUROC:0.9496\n",
      "Test | 122/16 | Loss:0.8219 | MainLoss:0.8219 | SPLoss:2.9684 | CLSLoss:0.0000 | AUROC:0.6826\n",
      "\n",
      "Epoch: [188 | 1000] LR: 0.191011\n",
      "Train | 16/16 | Loss:0.5953 | MainLoss:0.3207 | Alpha:0.0504 | SPLoss:2.7461 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.4340 | MainLoss:0.4340 | SPLoss:2.6573 | CLSLoss:0.0000 | AUROC:0.9656\n",
      "Test | 122/16 | Loss:0.7385 | MainLoss:0.7385 | SPLoss:2.6573 | CLSLoss:0.0000 | AUROC:0.7143\n",
      "\n",
      "Epoch: [189 | 1000] LR: 0.190880\n",
      "Train | 16/16 | Loss:0.5922 | MainLoss:0.3381 | Alpha:0.0513 | SPLoss:2.5412 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2181 | MainLoss:0.2181 | SPLoss:2.3307 | CLSLoss:0.0000 | AUROC:0.9719\n",
      "Test | 122/16 | Loss:0.5375 | MainLoss:0.5375 | SPLoss:2.3307 | CLSLoss:0.0000 | AUROC:0.8668\n",
      "\n",
      "Epoch: [190 | 1000] LR: 0.190748\n",
      "Train | 16/16 | Loss:0.6220 | MainLoss:0.3687 | Alpha:0.0510 | SPLoss:2.5324 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.3091 | MainLoss:0.3091 | SPLoss:2.5710 | CLSLoss:0.0000 | AUROC:0.9629\n",
      "Test | 122/16 | Loss:0.6372 | MainLoss:0.6372 | SPLoss:2.5710 | CLSLoss:0.0000 | AUROC:0.7449\n",
      "\n",
      "Epoch: [191 | 1000] LR: 0.190616\n",
      "Train | 16/16 | Loss:0.5550 | MainLoss:0.3163 | Alpha:0.0532 | SPLoss:2.3872 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.3109 | MainLoss:0.3109 | SPLoss:2.2590 | CLSLoss:0.0000 | AUROC:0.9635\n",
      "Test | 122/16 | Loss:0.7507 | MainLoss:0.7507 | SPLoss:2.2590 | CLSLoss:0.0000 | AUROC:0.8577\n",
      "\n",
      "Epoch: [192 | 1000] LR: 0.190483\n",
      "Train | 16/16 | Loss:0.5405 | MainLoss:0.3094 | Alpha:0.0534 | SPLoss:2.3104 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2698 | MainLoss:0.2698 | SPLoss:2.2950 | CLSLoss:0.0000 | AUROC:0.9654\n",
      "Test | 122/16 | Loss:0.5100 | MainLoss:0.5100 | SPLoss:2.2950 | CLSLoss:0.0000 | AUROC:0.8554\n",
      "\n",
      "Epoch: [193 | 1000] LR: 0.190348\n",
      "Train | 16/16 | Loss:0.5766 | MainLoss:0.3414 | Alpha:0.0512 | SPLoss:2.3528 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2352 | MainLoss:0.2352 | SPLoss:2.3235 | CLSLoss:0.0000 | AUROC:0.9723\n",
      "Test | 122/16 | Loss:0.5454 | MainLoss:0.5454 | SPLoss:2.3235 | CLSLoss:0.0000 | AUROC:0.8434\n",
      "\n",
      "Epoch: [194 | 1000] LR: 0.190213\n",
      "Train | 16/16 | Loss:0.5323 | MainLoss:0.2992 | Alpha:0.0493 | SPLoss:2.3312 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2644 | MainLoss:0.2644 | SPLoss:2.2310 | CLSLoss:0.0000 | AUROC:0.9737\n",
      "Test | 122/16 | Loss:0.4461 | MainLoss:0.4461 | SPLoss:2.2310 | CLSLoss:0.0000 | AUROC:0.8794\n",
      "\n",
      "Epoch: [195 | 1000] LR: 0.190077\n",
      "Train | 16/16 | Loss:0.6672 | MainLoss:0.4092 | Alpha:0.0525 | SPLoss:2.5802 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2512 | MainLoss:0.2512 | SPLoss:2.4934 | CLSLoss:0.0000 | AUROC:0.9667\n",
      "Test | 122/16 | Loss:0.4843 | MainLoss:0.4843 | SPLoss:2.4934 | CLSLoss:0.0000 | AUROC:0.8741\n",
      "\n",
      "Epoch: [196 | 1000] LR: 0.189941\n",
      "Train | 16/16 | Loss:0.6137 | MainLoss:0.3574 | Alpha:0.0501 | SPLoss:2.5627 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2687 | MainLoss:0.2687 | SPLoss:2.4997 | CLSLoss:0.0000 | AUROC:0.9659\n",
      "Test | 122/16 | Loss:0.5685 | MainLoss:0.5685 | SPLoss:2.4997 | CLSLoss:0.0000 | AUROC:0.8227\n",
      "\n",
      "Epoch: [197 | 1000] LR: 0.189803\n",
      "Train | 16/16 | Loss:0.5779 | MainLoss:0.3376 | Alpha:0.0510 | SPLoss:2.4031 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2474 | MainLoss:0.2474 | SPLoss:2.5447 | CLSLoss:0.0000 | AUROC:0.9649\n",
      "Test | 122/16 | Loss:0.7618 | MainLoss:0.7618 | SPLoss:2.5447 | CLSLoss:0.0000 | AUROC:0.7695\n",
      "\n",
      "Epoch: [198 | 1000] LR: 0.189664\n",
      "Train | 16/16 | Loss:0.5691 | MainLoss:0.3305 | Alpha:0.0516 | SPLoss:2.3855 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.4504 | MainLoss:0.4504 | SPLoss:2.5610 | CLSLoss:0.0000 | AUROC:0.9639\n",
      "Test | 122/16 | Loss:0.7014 | MainLoss:0.7014 | SPLoss:2.5610 | CLSLoss:0.0000 | AUROC:0.7006\n",
      "\n",
      "Epoch: [199 | 1000] LR: 0.189525\n",
      "Train | 16/16 | Loss:0.6285 | MainLoss:0.3803 | Alpha:0.0521 | SPLoss:2.4821 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2758 | MainLoss:0.2758 | SPLoss:2.8048 | CLSLoss:0.0000 | AUROC:0.9606\n",
      "Test | 122/16 | Loss:0.8958 | MainLoss:0.8958 | SPLoss:2.8048 | CLSLoss:0.0000 | AUROC:0.6110\n",
      "\n",
      "Epoch: [200 | 1000] LR: 0.189384\n",
      "Train | 16/16 | Loss:0.7215 | MainLoss:0.4279 | Alpha:0.0502 | SPLoss:2.9363 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.3459 | MainLoss:0.3459 | SPLoss:2.7837 | CLSLoss:0.0000 | AUROC:0.9613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 122/16 | Loss:0.5332 | MainLoss:0.5332 | SPLoss:2.7837 | CLSLoss:0.0000 | AUROC:0.8182\n",
      "\n",
      "Epoch: [201 | 1000] LR: 0.018924\n",
      "Train | 16/16 | Loss:0.5758 | MainLoss:0.3053 | Alpha:0.0522 | SPLoss:2.7045 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2545 | MainLoss:0.2545 | SPLoss:2.6377 | CLSLoss:0.0000 | AUROC:0.9643\n",
      "Test | 122/16 | Loss:0.5017 | MainLoss:0.5017 | SPLoss:2.6377 | CLSLoss:0.0000 | AUROC:0.8629\n",
      "\n",
      "Epoch: [202 | 1000] LR: 0.018910\n",
      "Train | 16/16 | Loss:0.5336 | MainLoss:0.2743 | Alpha:0.0472 | SPLoss:2.5927 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2407 | MainLoss:0.2407 | SPLoss:2.5416 | CLSLoss:0.0000 | AUROC:0.9661\n",
      "Test | 122/16 | Loss:0.4616 | MainLoss:0.4616 | SPLoss:2.5417 | CLSLoss:0.0000 | AUROC:0.8911\n",
      "\n",
      "Epoch: [203 | 1000] LR: 0.018896\n",
      "Train | 16/16 | Loss:0.5248 | MainLoss:0.2740 | Alpha:0.0503 | SPLoss:2.5086 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2364 | MainLoss:0.2364 | SPLoss:2.4641 | CLSLoss:0.0000 | AUROC:0.9681\n",
      "Test | 122/16 | Loss:0.4198 | MainLoss:0.4198 | SPLoss:2.4642 | CLSLoss:0.0000 | AUROC:0.9058\n",
      "\n",
      "Epoch: [204 | 1000] LR: 0.018881\n",
      "Train | 16/16 | Loss:0.5125 | MainLoss:0.2695 | Alpha:0.0516 | SPLoss:2.4293 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2264 | MainLoss:0.2264 | SPLoss:2.3933 | CLSLoss:0.0000 | AUROC:0.9694\n",
      "Test | 122/16 | Loss:0.4235 | MainLoss:0.4235 | SPLoss:2.3933 | CLSLoss:0.0000 | AUROC:0.9087\n",
      "\n",
      "Epoch: [205 | 1000] LR: 0.018867\n",
      "Train | 16/16 | Loss:0.4981 | MainLoss:0.2609 | Alpha:0.0514 | SPLoss:2.3724 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2236 | MainLoss:0.2236 | SPLoss:2.3459 | CLSLoss:0.0000 | AUROC:0.9703\n",
      "Test | 122/16 | Loss:0.4261 | MainLoss:0.4261 | SPLoss:2.3459 | CLSLoss:0.0000 | AUROC:0.9072\n",
      "\n",
      "Epoch: [206 | 1000] LR: 0.018852\n",
      "Train | 16/16 | Loss:0.4956 | MainLoss:0.2636 | Alpha:0.0532 | SPLoss:2.3196 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2170 | MainLoss:0.2170 | SPLoss:2.2960 | CLSLoss:0.0000 | AUROC:0.9719\n",
      "Test | 122/16 | Loss:0.4100 | MainLoss:0.4100 | SPLoss:2.2960 | CLSLoss:0.0000 | AUROC:0.9155\n",
      "\n",
      "Epoch: [207 | 1000] LR: 0.018838\n",
      "Train | 16/16 | Loss:0.4820 | MainLoss:0.2548 | Alpha:0.0510 | SPLoss:2.2724 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2177 | MainLoss:0.2177 | SPLoss:2.2463 | CLSLoss:0.0000 | AUROC:0.9723\n",
      "Test | 122/16 | Loss:0.3831 | MainLoss:0.3831 | SPLoss:2.2463 | CLSLoss:0.0000 | AUROC:0.9228\n",
      "\n",
      "Epoch: [208 | 1000] LR: 0.018823\n",
      "Train | 16/16 | Loss:0.4712 | MainLoss:0.2486 | Alpha:0.0504 | SPLoss:2.2268 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2124 | MainLoss:0.2124 | SPLoss:2.2076 | CLSLoss:0.0000 | AUROC:0.9726\n",
      "Test | 122/16 | Loss:0.3891 | MainLoss:0.3891 | SPLoss:2.2076 | CLSLoss:0.0000 | AUROC:0.9226\n",
      "\n",
      "Epoch: [209 | 1000] LR: 0.018808\n",
      "Train | 16/16 | Loss:0.4680 | MainLoss:0.2490 | Alpha:0.0513 | SPLoss:2.1902 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2108 | MainLoss:0.2108 | SPLoss:2.1744 | CLSLoss:0.0000 | AUROC:0.9739\n",
      "Test | 122/16 | Loss:0.3779 | MainLoss:0.3779 | SPLoss:2.1744 | CLSLoss:0.0000 | AUROC:0.9250\n",
      "\n",
      "Epoch: [210 | 1000] LR: 0.018793\n",
      "Train | 16/16 | Loss:0.4523 | MainLoss:0.2359 | Alpha:0.0511 | SPLoss:2.1642 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2158 | MainLoss:0.2158 | SPLoss:2.1423 | CLSLoss:0.0000 | AUROC:0.9739\n",
      "Test | 122/16 | Loss:0.3650 | MainLoss:0.3650 | SPLoss:2.1423 | CLSLoss:0.0000 | AUROC:0.9273\n",
      "\n",
      "Epoch: [211 | 1000] LR: 0.018778\n",
      "Train | 16/16 | Loss:0.4473 | MainLoss:0.2336 | Alpha:0.0510 | SPLoss:2.1375 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2055 | MainLoss:0.2055 | SPLoss:2.1207 | CLSLoss:0.0000 | AUROC:0.9738\n",
      "Test | 122/16 | Loss:0.3791 | MainLoss:0.3791 | SPLoss:2.1207 | CLSLoss:0.0000 | AUROC:0.9291\n",
      "\n",
      "Epoch: [212 | 1000] LR: 0.018763\n",
      "Train | 16/16 | Loss:0.4423 | MainLoss:0.2315 | Alpha:0.0494 | SPLoss:2.1075 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2073 | MainLoss:0.2073 | SPLoss:2.0921 | CLSLoss:0.0000 | AUROC:0.9745\n",
      "Test | 122/16 | Loss:0.3703 | MainLoss:0.3703 | SPLoss:2.0921 | CLSLoss:0.0000 | AUROC:0.9282\n",
      "\n",
      "Epoch: [213 | 1000] LR: 0.018748\n",
      "Train | 16/16 | Loss:0.4425 | MainLoss:0.2346 | Alpha:0.0514 | SPLoss:2.0789 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2001 | MainLoss:0.2001 | SPLoss:2.0679 | CLSLoss:0.0000 | AUROC:0.9752\n",
      "Test | 122/16 | Loss:0.3755 | MainLoss:0.3755 | SPLoss:2.0679 | CLSLoss:0.0000 | AUROC:0.9283\n",
      "\n",
      "Epoch: [214 | 1000] LR: 0.018733\n",
      "Train | 16/16 | Loss:0.4325 | MainLoss:0.2260 | Alpha:0.0527 | SPLoss:2.0655 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2020 | MainLoss:0.2020 | SPLoss:2.0517 | CLSLoss:0.0000 | AUROC:0.9748\n",
      "Test | 122/16 | Loss:0.3935 | MainLoss:0.3935 | SPLoss:2.0517 | CLSLoss:0.0000 | AUROC:0.9238\n",
      "\n",
      "Epoch: [215 | 1000] LR: 0.018717\n",
      "Train | 16/16 | Loss:0.4294 | MainLoss:0.2251 | Alpha:0.0529 | SPLoss:2.0427 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2061 | MainLoss:0.2061 | SPLoss:2.0472 | CLSLoss:0.0000 | AUROC:0.9761\n",
      "Test | 122/16 | Loss:0.4098 | MainLoss:0.4098 | SPLoss:2.0472 | CLSLoss:0.0000 | AUROC:0.9158\n",
      "\n",
      "Epoch: [216 | 1000] LR: 0.018702\n",
      "Train | 16/16 | Loss:0.4215 | MainLoss:0.2186 | Alpha:0.0513 | SPLoss:2.0288 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1938 | MainLoss:0.1938 | SPLoss:2.0083 | CLSLoss:0.0000 | AUROC:0.9759\n",
      "Test | 122/16 | Loss:0.4002 | MainLoss:0.4002 | SPLoss:2.0083 | CLSLoss:0.0000 | AUROC:0.9274\n",
      "\n",
      "Epoch: [217 | 1000] LR: 0.018686\n",
      "Train | 16/16 | Loss:0.4249 | MainLoss:0.2249 | Alpha:0.0498 | SPLoss:1.9996 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1951 | MainLoss:0.1951 | SPLoss:1.9904 | CLSLoss:0.0000 | AUROC:0.9761\n",
      "Test | 122/16 | Loss:0.3797 | MainLoss:0.3797 | SPLoss:1.9904 | CLSLoss:0.0000 | AUROC:0.9275\n",
      "\n",
      "Epoch: [218 | 1000] LR: 0.018671\n",
      "Train | 16/16 | Loss:0.4224 | MainLoss:0.2231 | Alpha:0.0516 | SPLoss:1.9924 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1958 | MainLoss:0.1958 | SPLoss:1.9802 | CLSLoss:0.0000 | AUROC:0.9761\n",
      "Test | 122/16 | Loss:0.3753 | MainLoss:0.3753 | SPLoss:1.9802 | CLSLoss:0.0000 | AUROC:0.9316\n",
      "\n",
      "Epoch: [219 | 1000] LR: 0.018655\n",
      "Train | 16/16 | Loss:0.4190 | MainLoss:0.2211 | Alpha:0.0510 | SPLoss:1.9797 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2023 | MainLoss:0.2023 | SPLoss:1.9768 | CLSLoss:0.0000 | AUROC:0.9767\n",
      "Test | 122/16 | Loss:0.3956 | MainLoss:0.3956 | SPLoss:1.9768 | CLSLoss:0.0000 | AUROC:0.9217\n",
      "\n",
      "Epoch: [220 | 1000] LR: 0.018639\n",
      "Train | 16/16 | Loss:0.4190 | MainLoss:0.2218 | Alpha:0.0510 | SPLoss:1.9726 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1949 | MainLoss:0.1949 | SPLoss:1.9637 | CLSLoss:0.0000 | AUROC:0.9762\n",
      "Test | 122/16 | Loss:0.4113 | MainLoss:0.4113 | SPLoss:1.9637 | CLSLoss:0.0000 | AUROC:0.9205\n",
      "\n",
      "Epoch: [221 | 1000] LR: 0.018623\n",
      "Train | 16/16 | Loss:0.4232 | MainLoss:0.2275 | Alpha:0.0523 | SPLoss:1.9571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1968 | MainLoss:0.1968 | SPLoss:1.9519 | CLSLoss:0.0000 | AUROC:0.9769\n",
      "Test | 122/16 | Loss:0.3903 | MainLoss:0.3903 | SPLoss:1.9519 | CLSLoss:0.0000 | AUROC:0.9227\n",
      "\n",
      "Epoch: [222 | 1000] LR: 0.018607\n",
      "Train | 16/16 | Loss:0.4194 | MainLoss:0.2253 | Alpha:0.0519 | SPLoss:1.9411 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1977 | MainLoss:0.1977 | SPLoss:1.9416 | CLSLoss:0.0000 | AUROC:0.9769\n",
      "Test | 122/16 | Loss:0.3877 | MainLoss:0.3877 | SPLoss:1.9416 | CLSLoss:0.0000 | AUROC:0.9239\n",
      "\n",
      "Epoch: [223 | 1000] LR: 0.018591\n",
      "Train | 16/16 | Loss:0.4166 | MainLoss:0.2229 | Alpha:0.0515 | SPLoss:1.9367 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1922 | MainLoss:0.1922 | SPLoss:1.9220 | CLSLoss:0.0000 | AUROC:0.9770\n",
      "Test | 122/16 | Loss:0.4194 | MainLoss:0.4194 | SPLoss:1.9220 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [224 | 1000] LR: 0.018575\n",
      "Train | 16/16 | Loss:0.4300 | MainLoss:0.2374 | Alpha:0.0518 | SPLoss:1.9264 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2013 | MainLoss:0.2013 | SPLoss:1.9259 | CLSLoss:0.0000 | AUROC:0.9777\n",
      "Test | 122/16 | Loss:0.3878 | MainLoss:0.3878 | SPLoss:1.9259 | CLSLoss:0.0000 | AUROC:0.9213\n",
      "\n",
      "Epoch: [225 | 1000] LR: 0.018559\n",
      "Train | 16/16 | Loss:0.4124 | MainLoss:0.2209 | Alpha:0.0525 | SPLoss:1.9145 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1898 | MainLoss:0.1898 | SPLoss:1.9119 | CLSLoss:0.0000 | AUROC:0.9773\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 122/16 | Loss:0.4230 | MainLoss:0.4230 | SPLoss:1.9119 | CLSLoss:0.0000 | AUROC:0.9266\n",
      "\n",
      "Epoch: [226 | 1000] LR: 0.018543\n",
      "Train | 16/16 | Loss:0.4107 | MainLoss:0.2194 | Alpha:0.0523 | SPLoss:1.9131 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1908 | MainLoss:0.1908 | SPLoss:1.8984 | CLSLoss:0.0000 | AUROC:0.9772\n",
      "Test | 122/16 | Loss:0.4100 | MainLoss:0.4100 | SPLoss:1.8984 | CLSLoss:0.0000 | AUROC:0.9288\n",
      "\n",
      "Epoch: [227 | 1000] LR: 0.018526\n",
      "Train | 16/16 | Loss:0.4179 | MainLoss:0.2274 | Alpha:0.0514 | SPLoss:1.9048 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1909 | MainLoss:0.1909 | SPLoss:1.8987 | CLSLoss:0.0000 | AUROC:0.9778\n",
      "Test | 122/16 | Loss:0.3982 | MainLoss:0.3982 | SPLoss:1.8987 | CLSLoss:0.0000 | AUROC:0.9281\n",
      "\n",
      "Epoch: [228 | 1000] LR: 0.018510\n",
      "Train | 16/16 | Loss:0.4159 | MainLoss:0.2261 | Alpha:0.0529 | SPLoss:1.8979 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1920 | MainLoss:0.1920 | SPLoss:1.8903 | CLSLoss:0.0000 | AUROC:0.9779\n",
      "Test | 122/16 | Loss:0.3805 | MainLoss:0.3805 | SPLoss:1.8903 | CLSLoss:0.0000 | AUROC:0.9274\n",
      "\n",
      "Epoch: [229 | 1000] LR: 0.018493\n",
      "Train | 16/16 | Loss:0.4099 | MainLoss:0.2214 | Alpha:0.0521 | SPLoss:1.8850 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2067 | MainLoss:0.2067 | SPLoss:1.8879 | CLSLoss:0.0000 | AUROC:0.9780\n",
      "Test | 122/16 | Loss:0.3895 | MainLoss:0.3895 | SPLoss:1.8879 | CLSLoss:0.0000 | AUROC:0.9205\n",
      "\n",
      "Epoch: [230 | 1000] LR: 0.018477\n",
      "Train | 16/16 | Loss:0.4184 | MainLoss:0.2311 | Alpha:0.0519 | SPLoss:1.8726 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1963 | MainLoss:0.1963 | SPLoss:1.8773 | CLSLoss:0.0000 | AUROC:0.9783\n",
      "Test | 122/16 | Loss:0.3830 | MainLoss:0.3830 | SPLoss:1.8773 | CLSLoss:0.0000 | AUROC:0.9222\n",
      "\n",
      "Epoch: [231 | 1000] LR: 0.018460\n",
      "Train | 16/16 | Loss:0.3979 | MainLoss:0.2099 | Alpha:0.0517 | SPLoss:1.8804 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1905 | MainLoss:0.1905 | SPLoss:1.8734 | CLSLoss:0.0000 | AUROC:0.9790\n",
      "Test | 122/16 | Loss:0.4127 | MainLoss:0.4127 | SPLoss:1.8734 | CLSLoss:0.0000 | AUROC:0.9194\n",
      "\n",
      "Epoch: [232 | 1000] LR: 0.018443\n",
      "Train | 16/16 | Loss:0.4157 | MainLoss:0.2292 | Alpha:0.0512 | SPLoss:1.8655 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1969 | MainLoss:0.1969 | SPLoss:1.8627 | CLSLoss:0.0000 | AUROC:0.9791\n",
      "Test | 122/16 | Loss:0.3797 | MainLoss:0.3797 | SPLoss:1.8627 | CLSLoss:0.0000 | AUROC:0.9240\n",
      "\n",
      "Epoch: [233 | 1000] LR: 0.018426\n",
      "Train | 16/16 | Loss:0.4026 | MainLoss:0.2171 | Alpha:0.0513 | SPLoss:1.8550 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1902 | MainLoss:0.1902 | SPLoss:1.8550 | CLSLoss:0.0000 | AUROC:0.9784\n",
      "Test | 122/16 | Loss:0.3777 | MainLoss:0.3777 | SPLoss:1.8550 | CLSLoss:0.0000 | AUROC:0.9298\n",
      "\n",
      "Epoch: [234 | 1000] LR: 0.018409\n",
      "Train | 16/16 | Loss:0.4118 | MainLoss:0.2262 | Alpha:0.0514 | SPLoss:1.8567 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1927 | MainLoss:0.1927 | SPLoss:1.8561 | CLSLoss:0.0000 | AUROC:0.9783\n",
      "Test | 122/16 | Loss:0.3862 | MainLoss:0.3862 | SPLoss:1.8561 | CLSLoss:0.0000 | AUROC:0.9275\n",
      "\n",
      "Epoch: [235 | 1000] LR: 0.018392\n",
      "Train | 16/16 | Loss:0.4117 | MainLoss:0.2266 | Alpha:0.0512 | SPLoss:1.8515 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1876 | MainLoss:0.1876 | SPLoss:1.8470 | CLSLoss:0.0000 | AUROC:0.9786\n",
      "Test | 122/16 | Loss:0.3588 | MainLoss:0.3588 | SPLoss:1.8470 | CLSLoss:0.0000 | AUROC:0.9344\n",
      "\n",
      "Epoch: [236 | 1000] LR: 0.018375\n",
      "Train | 16/16 | Loss:0.3957 | MainLoss:0.2106 | Alpha:0.0503 | SPLoss:1.8505 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2008 | MainLoss:0.2008 | SPLoss:1.8601 | CLSLoss:0.0000 | AUROC:0.9788\n",
      "Test | 122/16 | Loss:0.3904 | MainLoss:0.3904 | SPLoss:1.8601 | CLSLoss:0.0000 | AUROC:0.9231\n",
      "\n",
      "Epoch: [237 | 1000] LR: 0.018358\n",
      "Train | 16/16 | Loss:0.3984 | MainLoss:0.2133 | Alpha:0.0498 | SPLoss:1.8512 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1884 | MainLoss:0.1884 | SPLoss:1.8463 | CLSLoss:0.0000 | AUROC:0.9783\n",
      "Test | 122/16 | Loss:0.3732 | MainLoss:0.3732 | SPLoss:1.8463 | CLSLoss:0.0000 | AUROC:0.9317\n",
      "\n",
      "Epoch: [238 | 1000] LR: 0.018341\n",
      "Train | 16/16 | Loss:0.3982 | MainLoss:0.2136 | Alpha:0.0512 | SPLoss:1.8457 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1840 | MainLoss:0.1840 | SPLoss:1.8443 | CLSLoss:0.0000 | AUROC:0.9783\n",
      "Test | 122/16 | Loss:0.3849 | MainLoss:0.3849 | SPLoss:1.8443 | CLSLoss:0.0000 | AUROC:0.9325\n",
      "\n",
      "Epoch: [239 | 1000] LR: 0.018323\n",
      "Train | 16/16 | Loss:0.3963 | MainLoss:0.2118 | Alpha:0.0506 | SPLoss:1.8447 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1945 | MainLoss:0.1945 | SPLoss:1.8488 | CLSLoss:0.0000 | AUROC:0.9786\n",
      "Test | 122/16 | Loss:0.3760 | MainLoss:0.3760 | SPLoss:1.8488 | CLSLoss:0.0000 | AUROC:0.9263\n",
      "\n",
      "Epoch: [240 | 1000] LR: 0.018306\n",
      "Train | 16/16 | Loss:0.3939 | MainLoss:0.2091 | Alpha:0.0514 | SPLoss:1.8484 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1876 | MainLoss:0.1876 | SPLoss:1.8384 | CLSLoss:0.0000 | AUROC:0.9786\n",
      "Test | 122/16 | Loss:0.4293 | MainLoss:0.4293 | SPLoss:1.8383 | CLSLoss:0.0000 | AUROC:0.9300\n",
      "\n",
      "Epoch: [241 | 1000] LR: 0.018288\n",
      "Train | 16/16 | Loss:0.3936 | MainLoss:0.2090 | Alpha:0.0515 | SPLoss:1.8459 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1832 | MainLoss:0.1832 | SPLoss:1.8419 | CLSLoss:0.0000 | AUROC:0.9789\n",
      "Test | 122/16 | Loss:0.4294 | MainLoss:0.4294 | SPLoss:1.8420 | CLSLoss:0.0000 | AUROC:0.9211\n",
      "\n",
      "Epoch: [242 | 1000] LR: 0.018271\n",
      "Train | 16/16 | Loss:0.3842 | MainLoss:0.1998 | Alpha:0.0497 | SPLoss:1.8435 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1923 | MainLoss:0.1923 | SPLoss:1.8414 | CLSLoss:0.0000 | AUROC:0.9788\n",
      "Test | 122/16 | Loss:0.4040 | MainLoss:0.4040 | SPLoss:1.8413 | CLSLoss:0.0000 | AUROC:0.9187\n",
      "\n",
      "Epoch: [243 | 1000] LR: 0.018253\n",
      "Train | 16/16 | Loss:0.3993 | MainLoss:0.2160 | Alpha:0.0500 | SPLoss:1.8333 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1911 | MainLoss:0.1911 | SPLoss:1.8362 | CLSLoss:0.0000 | AUROC:0.9784\n",
      "Test | 122/16 | Loss:0.3946 | MainLoss:0.3946 | SPLoss:1.8362 | CLSLoss:0.0000 | AUROC:0.9259\n",
      "\n",
      "Epoch: [244 | 1000] LR: 0.018235\n",
      "Train | 16/16 | Loss:0.3961 | MainLoss:0.2126 | Alpha:0.0509 | SPLoss:1.8346 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1866 | MainLoss:0.1866 | SPLoss:1.8353 | CLSLoss:0.0000 | AUROC:0.9790\n",
      "Test | 122/16 | Loss:0.3998 | MainLoss:0.3998 | SPLoss:1.8353 | CLSLoss:0.0000 | AUROC:0.9225\n",
      "\n",
      "Epoch: [245 | 1000] LR: 0.018217\n",
      "Train | 16/16 | Loss:0.4008 | MainLoss:0.2176 | Alpha:0.0489 | SPLoss:1.8322 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1880 | MainLoss:0.1880 | SPLoss:1.8409 | CLSLoss:0.0000 | AUROC:0.9791\n",
      "Test | 122/16 | Loss:0.4089 | MainLoss:0.4089 | SPLoss:1.8409 | CLSLoss:0.0000 | AUROC:0.9183\n",
      "\n",
      "Epoch: [246 | 1000] LR: 0.018200\n",
      "Train | 16/16 | Loss:0.3826 | MainLoss:0.1994 | Alpha:0.0515 | SPLoss:1.8324 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1866 | MainLoss:0.1866 | SPLoss:1.8255 | CLSLoss:0.0000 | AUROC:0.9786\n",
      "Test | 122/16 | Loss:0.4193 | MainLoss:0.4193 | SPLoss:1.8255 | CLSLoss:0.0000 | AUROC:0.9213\n",
      "\n",
      "Epoch: [247 | 1000] LR: 0.018181\n",
      "Train | 16/16 | Loss:0.4059 | MainLoss:0.2240 | Alpha:0.0529 | SPLoss:1.8190 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1819 | MainLoss:0.1819 | SPLoss:1.8169 | CLSLoss:0.0000 | AUROC:0.9794\n",
      "Test | 122/16 | Loss:0.4166 | MainLoss:0.4166 | SPLoss:1.8169 | CLSLoss:0.0000 | AUROC:0.9244\n",
      "\n",
      "Epoch: [248 | 1000] LR: 0.018163\n",
      "Train | 16/16 | Loss:0.3859 | MainLoss:0.2042 | Alpha:0.0514 | SPLoss:1.8176 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1902 | MainLoss:0.1902 | SPLoss:1.8242 | CLSLoss:0.0000 | AUROC:0.9789\n",
      "Test | 122/16 | Loss:0.4262 | MainLoss:0.4262 | SPLoss:1.8242 | CLSLoss:0.0000 | AUROC:0.9177\n",
      "\n",
      "Epoch: [249 | 1000] LR: 0.018145\n",
      "Train | 16/16 | Loss:0.4007 | MainLoss:0.2185 | Alpha:0.0498 | SPLoss:1.8220 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2044 | MainLoss:0.2044 | SPLoss:1.8219 | CLSLoss:0.0000 | AUROC:0.9791\n",
      "Test | 122/16 | Loss:0.3938 | MainLoss:0.3938 | SPLoss:1.8219 | CLSLoss:0.0000 | AUROC:0.9164\n",
      "\n",
      "Epoch: [250 | 1000] LR: 0.018127\n",
      "Train | 16/16 | Loss:0.3944 | MainLoss:0.2129 | Alpha:0.0512 | SPLoss:1.8151 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1846 | MainLoss:0.1846 | SPLoss:1.8048 | CLSLoss:0.0000 | AUROC:0.9784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 122/16 | Loss:0.4002 | MainLoss:0.4002 | SPLoss:1.8048 | CLSLoss:0.0000 | AUROC:0.9317\n",
      "\n",
      "Epoch: [251 | 1000] LR: 0.018109\n",
      "Train | 16/16 | Loss:0.4081 | MainLoss:0.2269 | Alpha:0.0503 | SPLoss:1.8123 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1825 | MainLoss:0.1825 | SPLoss:1.8147 | CLSLoss:0.0000 | AUROC:0.9786\n",
      "Test | 122/16 | Loss:0.4337 | MainLoss:0.4337 | SPLoss:1.8147 | CLSLoss:0.0000 | AUROC:0.9246\n",
      "\n",
      "Epoch: [252 | 1000] LR: 0.018090\n",
      "Train | 16/16 | Loss:0.3713 | MainLoss:0.1895 | Alpha:0.0507 | SPLoss:1.8176 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2090 | MainLoss:0.2090 | SPLoss:1.8258 | CLSLoss:0.0000 | AUROC:0.9788\n",
      "Test | 122/16 | Loss:0.4304 | MainLoss:0.4304 | SPLoss:1.8258 | CLSLoss:0.0000 | AUROC:0.9125\n",
      "\n",
      "Epoch: [253 | 1000] LR: 0.018072\n",
      "Train | 16/16 | Loss:0.3880 | MainLoss:0.2061 | Alpha:0.0517 | SPLoss:1.8196 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1993 | MainLoss:0.1993 | SPLoss:1.8140 | CLSLoss:0.0000 | AUROC:0.9783\n",
      "Test | 122/16 | Loss:0.3974 | MainLoss:0.3974 | SPLoss:1.8140 | CLSLoss:0.0000 | AUROC:0.9175\n",
      "\n",
      "Epoch: [254 | 1000] LR: 0.018053\n",
      "Train | 16/16 | Loss:0.4044 | MainLoss:0.2235 | Alpha:0.0500 | SPLoss:1.8095 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1860 | MainLoss:0.1860 | SPLoss:1.8056 | CLSLoss:0.0000 | AUROC:0.9784\n",
      "Test | 122/16 | Loss:0.4260 | MainLoss:0.4260 | SPLoss:1.8056 | CLSLoss:0.0000 | AUROC:0.9190\n",
      "\n",
      "Epoch: [255 | 1000] LR: 0.018034\n",
      "Train | 16/16 | Loss:0.3963 | MainLoss:0.2163 | Alpha:0.0518 | SPLoss:1.8008 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1843 | MainLoss:0.1843 | SPLoss:1.8036 | CLSLoss:0.0000 | AUROC:0.9788\n",
      "Test | 122/16 | Loss:0.4337 | MainLoss:0.4337 | SPLoss:1.8036 | CLSLoss:0.0000 | AUROC:0.9236\n",
      "\n",
      "Epoch: [256 | 1000] LR: 0.018016\n",
      "Train | 16/16 | Loss:0.3750 | MainLoss:0.1945 | Alpha:0.0489 | SPLoss:1.8053 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1807 | MainLoss:0.1807 | SPLoss:1.8040 | CLSLoss:0.0000 | AUROC:0.9795\n",
      "Test | 122/16 | Loss:0.4355 | MainLoss:0.4355 | SPLoss:1.8040 | CLSLoss:0.0000 | AUROC:0.9254\n",
      "\n",
      "Epoch: [257 | 1000] LR: 0.017997\n",
      "Train | 16/16 | Loss:0.3962 | MainLoss:0.2152 | Alpha:0.0488 | SPLoss:1.8101 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1813 | MainLoss:0.1813 | SPLoss:1.8073 | CLSLoss:0.0000 | AUROC:0.9790\n",
      "Test | 122/16 | Loss:0.4038 | MainLoss:0.4038 | SPLoss:1.8073 | CLSLoss:0.0000 | AUROC:0.9264\n",
      "\n",
      "Epoch: [258 | 1000] LR: 0.017978\n",
      "Train | 16/16 | Loss:0.4013 | MainLoss:0.2199 | Alpha:0.0519 | SPLoss:1.8134 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2065 | MainLoss:0.2065 | SPLoss:1.8144 | CLSLoss:0.0000 | AUROC:0.9793\n",
      "Test | 122/16 | Loss:0.3910 | MainLoss:0.3910 | SPLoss:1.8144 | CLSLoss:0.0000 | AUROC:0.9177\n",
      "\n",
      "Epoch: [259 | 1000] LR: 0.017959\n",
      "Train | 16/16 | Loss:0.3970 | MainLoss:0.2158 | Alpha:0.0523 | SPLoss:1.8116 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1948 | MainLoss:0.1948 | SPLoss:1.8172 | CLSLoss:0.0000 | AUROC:0.9791\n",
      "Test | 122/16 | Loss:0.3992 | MainLoss:0.3992 | SPLoss:1.8172 | CLSLoss:0.0000 | AUROC:0.9190\n",
      "\n",
      "Epoch: [260 | 1000] LR: 0.017940\n",
      "Train | 16/16 | Loss:0.3811 | MainLoss:0.1997 | Alpha:0.0523 | SPLoss:1.8140 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1879 | MainLoss:0.1879 | SPLoss:1.8159 | CLSLoss:0.0000 | AUROC:0.9790\n",
      "Test | 122/16 | Loss:0.4204 | MainLoss:0.4204 | SPLoss:1.8159 | CLSLoss:0.0000 | AUROC:0.9202\n",
      "\n",
      "Epoch: [261 | 1000] LR: 0.017921\n",
      "Train | 16/16 | Loss:0.3645 | MainLoss:0.1837 | Alpha:0.0505 | SPLoss:1.8085 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1957 | MainLoss:0.1957 | SPLoss:1.8092 | CLSLoss:0.0000 | AUROC:0.9793\n",
      "Test | 122/16 | Loss:0.4108 | MainLoss:0.4108 | SPLoss:1.8092 | CLSLoss:0.0000 | AUROC:0.9217\n",
      "\n",
      "Epoch: [262 | 1000] LR: 0.017902\n",
      "Train | 16/16 | Loss:0.3891 | MainLoss:0.2086 | Alpha:0.0507 | SPLoss:1.8044 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1843 | MainLoss:0.1843 | SPLoss:1.7946 | CLSLoss:0.0000 | AUROC:0.9789\n",
      "Test | 122/16 | Loss:0.4012 | MainLoss:0.4012 | SPLoss:1.7946 | CLSLoss:0.0000 | AUROC:0.9255\n",
      "\n",
      "Epoch: [263 | 1000] LR: 0.017882\n",
      "Train | 16/16 | Loss:0.3994 | MainLoss:0.2197 | Alpha:0.0528 | SPLoss:1.7976 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1842 | MainLoss:0.1842 | SPLoss:1.7963 | CLSLoss:0.0000 | AUROC:0.9792\n",
      "Test | 122/16 | Loss:0.4352 | MainLoss:0.4352 | SPLoss:1.7963 | CLSLoss:0.0000 | AUROC:0.9298\n",
      "\n",
      "Epoch: [264 | 1000] LR: 0.017863\n",
      "Train | 16/16 | Loss:0.3903 | MainLoss:0.2096 | Alpha:0.0496 | SPLoss:1.8066 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1942 | MainLoss:0.1942 | SPLoss:1.8137 | CLSLoss:0.0000 | AUROC:0.9795\n",
      "Test | 122/16 | Loss:0.4122 | MainLoss:0.4122 | SPLoss:1.8137 | CLSLoss:0.0000 | AUROC:0.9161\n",
      "\n",
      "Epoch: [265 | 1000] LR: 0.017843\n",
      "Train | 16/16 | Loss:0.3895 | MainLoss:0.2079 | Alpha:0.0496 | SPLoss:1.8162 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1836 | MainLoss:0.1836 | SPLoss:1.8156 | CLSLoss:0.0000 | AUROC:0.9794\n",
      "Test | 122/16 | Loss:0.4286 | MainLoss:0.4286 | SPLoss:1.8156 | CLSLoss:0.0000 | AUROC:0.9181\n",
      "\n",
      "Epoch: [266 | 1000] LR: 0.017824\n",
      "Train | 16/16 | Loss:0.3920 | MainLoss:0.2110 | Alpha:0.0497 | SPLoss:1.8100 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1827 | MainLoss:0.1827 | SPLoss:1.8050 | CLSLoss:0.0000 | AUROC:0.9796\n",
      "Test | 122/16 | Loss:0.4196 | MainLoss:0.4196 | SPLoss:1.8050 | CLSLoss:0.0000 | AUROC:0.9239\n",
      "\n",
      "Epoch: [267 | 1000] LR: 0.017804\n",
      "Train | 16/16 | Loss:0.3845 | MainLoss:0.2034 | Alpha:0.0518 | SPLoss:1.8115 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1849 | MainLoss:0.1849 | SPLoss:1.8141 | CLSLoss:0.0000 | AUROC:0.9799\n",
      "Test | 122/16 | Loss:0.4224 | MainLoss:0.4224 | SPLoss:1.8141 | CLSLoss:0.0000 | AUROC:0.9189\n",
      "\n",
      "Epoch: [268 | 1000] LR: 0.017785\n",
      "Train | 16/16 | Loss:0.3934 | MainLoss:0.2125 | Alpha:0.0515 | SPLoss:1.8090 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1941 | MainLoss:0.1941 | SPLoss:1.8141 | CLSLoss:0.0000 | AUROC:0.9791\n",
      "Test | 122/16 | Loss:0.4052 | MainLoss:0.4052 | SPLoss:1.8141 | CLSLoss:0.0000 | AUROC:0.9244\n",
      "\n",
      "Epoch: [269 | 1000] LR: 0.017765\n",
      "Train | 16/16 | Loss:0.3857 | MainLoss:0.2044 | Alpha:0.0518 | SPLoss:1.8134 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1823 | MainLoss:0.1823 | SPLoss:1.8182 | CLSLoss:0.0000 | AUROC:0.9795\n",
      "Test | 122/16 | Loss:0.4322 | MainLoss:0.4322 | SPLoss:1.8182 | CLSLoss:0.0000 | AUROC:0.9156\n",
      "\n",
      "Epoch: [270 | 1000] LR: 0.017745\n",
      "Train | 16/16 | Loss:0.3928 | MainLoss:0.2112 | Alpha:0.0520 | SPLoss:1.8162 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1866 | MainLoss:0.1866 | SPLoss:1.8134 | CLSLoss:0.0000 | AUROC:0.9796\n",
      "Test | 122/16 | Loss:0.3912 | MainLoss:0.3912 | SPLoss:1.8134 | CLSLoss:0.0000 | AUROC:0.9232\n",
      "\n",
      "Epoch: [271 | 1000] LR: 0.017725\n",
      "Train | 16/16 | Loss:0.4042 | MainLoss:0.2225 | Alpha:0.0518 | SPLoss:1.8171 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1789 | MainLoss:0.1789 | SPLoss:1.8170 | CLSLoss:0.0000 | AUROC:0.9799\n",
      "Test | 122/16 | Loss:0.4372 | MainLoss:0.4372 | SPLoss:1.8170 | CLSLoss:0.0000 | AUROC:0.9190\n",
      "\n",
      "Epoch: [272 | 1000] LR: 0.017705\n",
      "Train | 16/16 | Loss:0.3891 | MainLoss:0.2063 | Alpha:0.0518 | SPLoss:1.8279 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1861 | MainLoss:0.1861 | SPLoss:1.8293 | CLSLoss:0.0000 | AUROC:0.9798\n",
      "Test | 122/16 | Loss:0.4459 | MainLoss:0.4459 | SPLoss:1.8293 | CLSLoss:0.0000 | AUROC:0.9093\n",
      "\n",
      "Epoch: [273 | 1000] LR: 0.017685\n",
      "Train | 16/16 | Loss:0.3896 | MainLoss:0.2079 | Alpha:0.0501 | SPLoss:1.8176 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1804 | MainLoss:0.1804 | SPLoss:1.8096 | CLSLoss:0.0000 | AUROC:0.9796\n",
      "Test | 122/16 | Loss:0.4266 | MainLoss:0.4266 | SPLoss:1.8096 | CLSLoss:0.0000 | AUROC:0.9247\n",
      "\n",
      "Epoch: [274 | 1000] LR: 0.017665\n",
      "Train | 16/16 | Loss:0.3874 | MainLoss:0.2064 | Alpha:0.0504 | SPLoss:1.8092 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1926 | MainLoss:0.1926 | SPLoss:1.8144 | CLSLoss:0.0000 | AUROC:0.9801\n",
      "Test | 122/16 | Loss:0.3893 | MainLoss:0.3893 | SPLoss:1.8144 | CLSLoss:0.0000 | AUROC:0.9181\n",
      "\n",
      "Epoch: [275 | 1000] LR: 0.017645\n",
      "Train | 16/16 | Loss:0.3933 | MainLoss:0.2117 | Alpha:0.0507 | SPLoss:1.8161 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1792 | MainLoss:0.1792 | SPLoss:1.8132 | CLSLoss:0.0000 | AUROC:0.9801\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 122/16 | Loss:0.4283 | MainLoss:0.4283 | SPLoss:1.8132 | CLSLoss:0.0000 | AUROC:0.9229\n",
      "\n",
      "Epoch: [276 | 1000] LR: 0.017624\n",
      "Train | 16/16 | Loss:0.3703 | MainLoss:0.1894 | Alpha:0.0501 | SPLoss:1.8090 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1833 | MainLoss:0.1833 | SPLoss:1.8054 | CLSLoss:0.0000 | AUROC:0.9795\n",
      "Test | 122/16 | Loss:0.4450 | MainLoss:0.4450 | SPLoss:1.8054 | CLSLoss:0.0000 | AUROC:0.9263\n",
      "\n",
      "Epoch: [277 | 1000] LR: 0.017604\n",
      "Train | 16/16 | Loss:0.3841 | MainLoss:0.2034 | Alpha:0.0520 | SPLoss:1.8074 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1776 | MainLoss:0.1776 | SPLoss:1.8053 | CLSLoss:0.0000 | AUROC:0.9802\n",
      "Test | 122/16 | Loss:0.4181 | MainLoss:0.4181 | SPLoss:1.8053 | CLSLoss:0.0000 | AUROC:0.9290\n",
      "\n",
      "Epoch: [278 | 1000] LR: 0.017584\n",
      "Train | 16/16 | Loss:0.3894 | MainLoss:0.2080 | Alpha:0.0516 | SPLoss:1.8135 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1873 | MainLoss:0.1873 | SPLoss:1.8207 | CLSLoss:0.0000 | AUROC:0.9812\n",
      "Test | 122/16 | Loss:0.4153 | MainLoss:0.4153 | SPLoss:1.8207 | CLSLoss:0.0000 | AUROC:0.9142\n",
      "\n",
      "Epoch: [279 | 1000] LR: 0.017563\n",
      "Train | 16/16 | Loss:0.4052 | MainLoss:0.2228 | Alpha:0.0539 | SPLoss:1.8236 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1797 | MainLoss:0.1797 | SPLoss:1.8130 | CLSLoss:0.0000 | AUROC:0.9797\n",
      "Test | 122/16 | Loss:0.4245 | MainLoss:0.4245 | SPLoss:1.8130 | CLSLoss:0.0000 | AUROC:0.9232\n",
      "\n",
      "Epoch: [280 | 1000] LR: 0.017543\n",
      "Train | 16/16 | Loss:0.3839 | MainLoss:0.2025 | Alpha:0.0507 | SPLoss:1.8141 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1828 | MainLoss:0.1828 | SPLoss:1.8140 | CLSLoss:0.0000 | AUROC:0.9809\n",
      "Test | 122/16 | Loss:0.3889 | MainLoss:0.3889 | SPLoss:1.8140 | CLSLoss:0.0000 | AUROC:0.9254\n",
      "\n",
      "Epoch: [281 | 1000] LR: 0.017522\n",
      "Train | 16/16 | Loss:0.3658 | MainLoss:0.1835 | Alpha:0.0497 | SPLoss:1.8224 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1873 | MainLoss:0.1873 | SPLoss:1.8247 | CLSLoss:0.0000 | AUROC:0.9804\n",
      "Test | 122/16 | Loss:0.4344 | MainLoss:0.4344 | SPLoss:1.8247 | CLSLoss:0.0000 | AUROC:0.9195\n",
      "\n",
      "Epoch: [282 | 1000] LR: 0.017501\n",
      "Train | 16/16 | Loss:0.3807 | MainLoss:0.1989 | Alpha:0.0507 | SPLoss:1.8181 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1838 | MainLoss:0.1838 | SPLoss:1.8099 | CLSLoss:0.0000 | AUROC:0.9797\n",
      "Test | 122/16 | Loss:0.4027 | MainLoss:0.4027 | SPLoss:1.8099 | CLSLoss:0.0000 | AUROC:0.9260\n",
      "\n",
      "Epoch: [283 | 1000] LR: 0.017480\n",
      "Train | 16/16 | Loss:0.3759 | MainLoss:0.1954 | Alpha:0.0527 | SPLoss:1.8047 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1830 | MainLoss:0.1830 | SPLoss:1.8091 | CLSLoss:0.0000 | AUROC:0.9792\n",
      "Test | 122/16 | Loss:0.4230 | MainLoss:0.4230 | SPLoss:1.8091 | CLSLoss:0.0000 | AUROC:0.9238\n",
      "\n",
      "Epoch: [284 | 1000] LR: 0.017459\n",
      "Train | 16/16 | Loss:0.3905 | MainLoss:0.2093 | Alpha:0.0494 | SPLoss:1.8126 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1859 | MainLoss:0.1859 | SPLoss:1.8118 | CLSLoss:0.0000 | AUROC:0.9792\n",
      "Test | 122/16 | Loss:0.4355 | MainLoss:0.4355 | SPLoss:1.8118 | CLSLoss:0.0000 | AUROC:0.9203\n",
      "\n",
      "Epoch: [285 | 1000] LR: 0.017438\n",
      "Train | 16/16 | Loss:0.3668 | MainLoss:0.1862 | Alpha:0.0507 | SPLoss:1.8063 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1843 | MainLoss:0.1843 | SPLoss:1.8117 | CLSLoss:0.0000 | AUROC:0.9794\n",
      "Test | 122/16 | Loss:0.4451 | MainLoss:0.4451 | SPLoss:1.8117 | CLSLoss:0.0000 | AUROC:0.9190\n",
      "\n",
      "Epoch: [286 | 1000] LR: 0.017417\n",
      "Train | 16/16 | Loss:0.3732 | MainLoss:0.1920 | Alpha:0.0505 | SPLoss:1.8129 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2124 | MainLoss:0.2124 | SPLoss:1.8173 | CLSLoss:0.0000 | AUROC:0.9794\n",
      "Test | 122/16 | Loss:0.4282 | MainLoss:0.4282 | SPLoss:1.8173 | CLSLoss:0.0000 | AUROC:0.9089\n",
      "\n",
      "Epoch: [287 | 1000] LR: 0.017396\n",
      "Train | 16/16 | Loss:0.3913 | MainLoss:0.2102 | Alpha:0.0513 | SPLoss:1.8108 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1792 | MainLoss:0.1792 | SPLoss:1.8068 | CLSLoss:0.0000 | AUROC:0.9798\n",
      "Test | 122/16 | Loss:0.4143 | MainLoss:0.4143 | SPLoss:1.8068 | CLSLoss:0.0000 | AUROC:0.9281\n",
      "\n",
      "Epoch: [288 | 1000] LR: 0.017375\n",
      "Train | 16/16 | Loss:0.3879 | MainLoss:0.2068 | Alpha:0.0504 | SPLoss:1.8105 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1825 | MainLoss:0.1825 | SPLoss:1.8248 | CLSLoss:0.0000 | AUROC:0.9806\n",
      "Test | 122/16 | Loss:0.4501 | MainLoss:0.4501 | SPLoss:1.8248 | CLSLoss:0.0000 | AUROC:0.9123\n",
      "\n",
      "Epoch: [289 | 1000] LR: 0.017354\n",
      "Train | 16/16 | Loss:0.3941 | MainLoss:0.2124 | Alpha:0.0516 | SPLoss:1.8172 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1784 | MainLoss:0.1784 | SPLoss:1.8100 | CLSLoss:0.0000 | AUROC:0.9809\n",
      "Test | 122/16 | Loss:0.4110 | MainLoss:0.4110 | SPLoss:1.8100 | CLSLoss:0.0000 | AUROC:0.9187\n",
      "\n",
      "Epoch: [290 | 1000] LR: 0.017333\n",
      "Train | 16/16 | Loss:0.3738 | MainLoss:0.1930 | Alpha:0.0527 | SPLoss:1.8087 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1802 | MainLoss:0.1802 | SPLoss:1.8091 | CLSLoss:0.0000 | AUROC:0.9805\n",
      "Test | 122/16 | Loss:0.4151 | MainLoss:0.4151 | SPLoss:1.8091 | CLSLoss:0.0000 | AUROC:0.9198\n",
      "\n",
      "Epoch: [291 | 1000] LR: 0.017311\n",
      "Train | 16/16 | Loss:0.3878 | MainLoss:0.2070 | Alpha:0.0497 | SPLoss:1.8086 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1750 | MainLoss:0.1750 | SPLoss:1.8127 | CLSLoss:0.0000 | AUROC:0.9811\n",
      "Test | 122/16 | Loss:0.4310 | MainLoss:0.4310 | SPLoss:1.8127 | CLSLoss:0.0000 | AUROC:0.9208\n",
      "\n",
      "Epoch: [292 | 1000] LR: 0.017290\n",
      "Train | 16/16 | Loss:0.3829 | MainLoss:0.2012 | Alpha:0.0512 | SPLoss:1.8173 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1820 | MainLoss:0.1820 | SPLoss:1.8260 | CLSLoss:0.0000 | AUROC:0.9807\n",
      "Test | 122/16 | Loss:0.4544 | MainLoss:0.4544 | SPLoss:1.8260 | CLSLoss:0.0000 | AUROC:0.9053\n",
      "\n",
      "Epoch: [293 | 1000] LR: 0.017268\n",
      "Train | 16/16 | Loss:0.3846 | MainLoss:0.2018 | Alpha:0.0487 | SPLoss:1.8275 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2057 | MainLoss:0.2057 | SPLoss:1.8272 | CLSLoss:0.0000 | AUROC:0.9811\n",
      "Test | 122/16 | Loss:0.4458 | MainLoss:0.4458 | SPLoss:1.8272 | CLSLoss:0.0000 | AUROC:0.9076\n",
      "\n",
      "Epoch: [294 | 1000] LR: 0.017247\n",
      "Train | 16/16 | Loss:0.4025 | MainLoss:0.2203 | Alpha:0.0546 | SPLoss:1.8214 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1813 | MainLoss:0.1813 | SPLoss:1.8269 | CLSLoss:0.0000 | AUROC:0.9806\n",
      "Test | 122/16 | Loss:0.4676 | MainLoss:0.4676 | SPLoss:1.8269 | CLSLoss:0.0000 | AUROC:0.9085\n",
      "\n",
      "Epoch: [295 | 1000] LR: 0.017225\n",
      "Train | 16/16 | Loss:0.3745 | MainLoss:0.1921 | Alpha:0.0489 | SPLoss:1.8237 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1783 | MainLoss:0.1783 | SPLoss:1.8173 | CLSLoss:0.0000 | AUROC:0.9803\n",
      "Test | 122/16 | Loss:0.4681 | MainLoss:0.4681 | SPLoss:1.8173 | CLSLoss:0.0000 | AUROC:0.9133\n",
      "\n",
      "Epoch: [296 | 1000] LR: 0.017203\n",
      "Train | 16/16 | Loss:0.3703 | MainLoss:0.1885 | Alpha:0.0517 | SPLoss:1.8177 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1905 | MainLoss:0.1905 | SPLoss:1.8168 | CLSLoss:0.0000 | AUROC:0.9812\n",
      "Test | 122/16 | Loss:0.4662 | MainLoss:0.4662 | SPLoss:1.8168 | CLSLoss:0.0000 | AUROC:0.9069\n",
      "\n",
      "Epoch: [297 | 1000] LR: 0.017181\n",
      "Train | 16/16 | Loss:0.3854 | MainLoss:0.2036 | Alpha:0.0506 | SPLoss:1.8179 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1795 | MainLoss:0.1795 | SPLoss:1.8138 | CLSLoss:0.0000 | AUROC:0.9808\n",
      "Test | 122/16 | Loss:0.4490 | MainLoss:0.4490 | SPLoss:1.8138 | CLSLoss:0.0000 | AUROC:0.9123\n",
      "\n",
      "Epoch: [298 | 1000] LR: 0.017159\n",
      "Train | 16/16 | Loss:0.3782 | MainLoss:0.1974 | Alpha:0.0509 | SPLoss:1.8083 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1766 | MainLoss:0.1766 | SPLoss:1.8037 | CLSLoss:0.0000 | AUROC:0.9802\n",
      "Test | 122/16 | Loss:0.4694 | MainLoss:0.4694 | SPLoss:1.8037 | CLSLoss:0.0000 | AUROC:0.9202\n",
      "\n",
      "Epoch: [299 | 1000] LR: 0.017137\n",
      "Train | 16/16 | Loss:0.3833 | MainLoss:0.2024 | Alpha:0.0507 | SPLoss:1.8092 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1969 | MainLoss:0.1969 | SPLoss:1.8167 | CLSLoss:0.0000 | AUROC:0.9812\n",
      "Test | 122/16 | Loss:0.4238 | MainLoss:0.4238 | SPLoss:1.8167 | CLSLoss:0.0000 | AUROC:0.9106\n",
      "\n",
      "Epoch: [300 | 1000] LR: 0.017115\n",
      "Train | 16/16 | Loss:0.3879 | MainLoss:0.2070 | Alpha:0.0510 | SPLoss:1.8082 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1912 | MainLoss:0.1912 | SPLoss:1.8021 | CLSLoss:0.0000 | AUROC:0.9808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 122/16 | Loss:0.3900 | MainLoss:0.3900 | SPLoss:1.8021 | CLSLoss:0.0000 | AUROC:0.9204\n",
      "\n",
      "Epoch: [301 | 1000] LR: 0.017093\n",
      "Train | 16/16 | Loss:0.3746 | MainLoss:0.1950 | Alpha:0.0523 | SPLoss:1.7963 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1953 | MainLoss:0.1953 | SPLoss:1.8011 | CLSLoss:0.0000 | AUROC:0.9810\n",
      "Test | 122/16 | Loss:0.4137 | MainLoss:0.4137 | SPLoss:1.8011 | CLSLoss:0.0000 | AUROC:0.9188\n",
      "\n",
      "Epoch: [302 | 1000] LR: 0.017071\n",
      "Train | 16/16 | Loss:0.3921 | MainLoss:0.2117 | Alpha:0.0505 | SPLoss:1.8045 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1785 | MainLoss:0.1785 | SPLoss:1.8046 | CLSLoss:0.0000 | AUROC:0.9814\n",
      "Test | 122/16 | Loss:0.5010 | MainLoss:0.5010 | SPLoss:1.8046 | CLSLoss:0.0000 | AUROC:0.9232\n",
      "\n",
      "Epoch: [303 | 1000] LR: 0.017049\n",
      "Train | 16/16 | Loss:0.3816 | MainLoss:0.2005 | Alpha:0.0509 | SPLoss:1.8119 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1772 | MainLoss:0.1772 | SPLoss:1.8093 | CLSLoss:0.0000 | AUROC:0.9813\n",
      "Test | 122/16 | Loss:0.4495 | MainLoss:0.4495 | SPLoss:1.8093 | CLSLoss:0.0000 | AUROC:0.9113\n",
      "\n",
      "Epoch: [304 | 1000] LR: 0.017026\n",
      "Train | 16/16 | Loss:0.3611 | MainLoss:0.1808 | Alpha:0.0509 | SPLoss:1.8026 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1733 | MainLoss:0.1733 | SPLoss:1.7966 | CLSLoss:0.0000 | AUROC:0.9812\n",
      "Test | 122/16 | Loss:0.4371 | MainLoss:0.4371 | SPLoss:1.7966 | CLSLoss:0.0000 | AUROC:0.9179\n",
      "\n",
      "Epoch: [305 | 1000] LR: 0.017004\n",
      "Train | 16/16 | Loss:0.3835 | MainLoss:0.2038 | Alpha:0.0534 | SPLoss:1.7967 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1887 | MainLoss:0.1887 | SPLoss:1.7947 | CLSLoss:0.0000 | AUROC:0.9811\n",
      "Test | 122/16 | Loss:0.4120 | MainLoss:0.4120 | SPLoss:1.7947 | CLSLoss:0.0000 | AUROC:0.9117\n",
      "\n",
      "Epoch: [306 | 1000] LR: 0.016982\n",
      "Train | 16/16 | Loss:0.3781 | MainLoss:0.1979 | Alpha:0.0510 | SPLoss:1.8013 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1749 | MainLoss:0.1749 | SPLoss:1.7941 | CLSLoss:0.0000 | AUROC:0.9811\n",
      "Test | 122/16 | Loss:0.4963 | MainLoss:0.4963 | SPLoss:1.7941 | CLSLoss:0.0000 | AUROC:0.9195\n",
      "\n",
      "Epoch: [307 | 1000] LR: 0.016959\n",
      "Train | 16/16 | Loss:0.3719 | MainLoss:0.1923 | Alpha:0.0522 | SPLoss:1.7958 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1748 | MainLoss:0.1748 | SPLoss:1.7930 | CLSLoss:0.0000 | AUROC:0.9810\n",
      "Test | 122/16 | Loss:0.4736 | MainLoss:0.4736 | SPLoss:1.7930 | CLSLoss:0.0000 | AUROC:0.9223\n",
      "\n",
      "Epoch: [308 | 1000] LR: 0.016937\n",
      "Train | 16/16 | Loss:0.3794 | MainLoss:0.2000 | Alpha:0.0515 | SPLoss:1.7940 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1950 | MainLoss:0.1950 | SPLoss:1.8070 | CLSLoss:0.0000 | AUROC:0.9810\n",
      "Test | 122/16 | Loss:0.4587 | MainLoss:0.4587 | SPLoss:1.8070 | CLSLoss:0.0000 | AUROC:0.9025\n",
      "\n",
      "Epoch: [309 | 1000] LR: 0.016914\n",
      "Train | 16/16 | Loss:0.3841 | MainLoss:0.2045 | Alpha:0.0509 | SPLoss:1.7961 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1778 | MainLoss:0.1778 | SPLoss:1.7858 | CLSLoss:0.0000 | AUROC:0.9805\n",
      "Test | 122/16 | Loss:0.4377 | MainLoss:0.4377 | SPLoss:1.7858 | CLSLoss:0.0000 | AUROC:0.9304\n",
      "\n",
      "Epoch: [310 | 1000] LR: 0.016891\n",
      "Train | 16/16 | Loss:0.3870 | MainLoss:0.2078 | Alpha:0.0518 | SPLoss:1.7924 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1744 | MainLoss:0.1744 | SPLoss:1.7935 | CLSLoss:0.0000 | AUROC:0.9811\n",
      "Test | 122/16 | Loss:0.4412 | MainLoss:0.4412 | SPLoss:1.7935 | CLSLoss:0.0000 | AUROC:0.9202\n",
      "\n",
      "Epoch: [311 | 1000] LR: 0.016868\n",
      "Train | 16/16 | Loss:0.3733 | MainLoss:0.1938 | Alpha:0.0497 | SPLoss:1.7955 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2061 | MainLoss:0.2061 | SPLoss:1.8003 | CLSLoss:0.0000 | AUROC:0.9814\n",
      "Test | 122/16 | Loss:0.4226 | MainLoss:0.4226 | SPLoss:1.8003 | CLSLoss:0.0000 | AUROC:0.9068\n",
      "\n",
      "Epoch: [312 | 1000] LR: 0.016845\n",
      "Train | 16/16 | Loss:0.3826 | MainLoss:0.2030 | Alpha:0.0496 | SPLoss:1.7961 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1780 | MainLoss:0.1780 | SPLoss:1.7982 | CLSLoss:0.0000 | AUROC:0.9819\n",
      "Test | 122/16 | Loss:0.4329 | MainLoss:0.4329 | SPLoss:1.7982 | CLSLoss:0.0000 | AUROC:0.9124\n",
      "\n",
      "Epoch: [313 | 1000] LR: 0.016823\n",
      "Train | 16/16 | Loss:0.3940 | MainLoss:0.2141 | Alpha:0.0495 | SPLoss:1.7985 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1749 | MainLoss:0.1749 | SPLoss:1.7933 | CLSLoss:0.0000 | AUROC:0.9817\n",
      "Test | 122/16 | Loss:0.4389 | MainLoss:0.4389 | SPLoss:1.7933 | CLSLoss:0.0000 | AUROC:0.9142\n",
      "\n",
      "Epoch: [314 | 1000] LR: 0.016800\n",
      "Train | 16/16 | Loss:0.3705 | MainLoss:0.1915 | Alpha:0.0525 | SPLoss:1.7897 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1830 | MainLoss:0.1830 | SPLoss:1.7970 | CLSLoss:0.0000 | AUROC:0.9809\n",
      "Test | 122/16 | Loss:0.4192 | MainLoss:0.4192 | SPLoss:1.7970 | CLSLoss:0.0000 | AUROC:0.9156\n",
      "\n",
      "Epoch: [315 | 1000] LR: 0.016776\n",
      "Train | 16/16 | Loss:0.3813 | MainLoss:0.2020 | Alpha:0.0494 | SPLoss:1.7936 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1882 | MainLoss:0.1882 | SPLoss:1.7901 | CLSLoss:0.0000 | AUROC:0.9812\n",
      "Test | 122/16 | Loss:0.3991 | MainLoss:0.3991 | SPLoss:1.7901 | CLSLoss:0.0000 | AUROC:0.9231\n",
      "\n",
      "Epoch: [316 | 1000] LR: 0.016753\n",
      "Train | 16/16 | Loss:0.3752 | MainLoss:0.1957 | Alpha:0.0504 | SPLoss:1.7946 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1728 | MainLoss:0.1728 | SPLoss:1.7964 | CLSLoss:0.0000 | AUROC:0.9810\n",
      "Test | 122/16 | Loss:0.4638 | MainLoss:0.4638 | SPLoss:1.7964 | CLSLoss:0.0000 | AUROC:0.9170\n",
      "\n",
      "Epoch: [317 | 1000] LR: 0.016730\n",
      "Train | 16/16 | Loss:0.3622 | MainLoss:0.1823 | Alpha:0.0508 | SPLoss:1.7989 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1760 | MainLoss:0.1760 | SPLoss:1.7931 | CLSLoss:0.0000 | AUROC:0.9809\n",
      "Test | 122/16 | Loss:0.4533 | MainLoss:0.4533 | SPLoss:1.7931 | CLSLoss:0.0000 | AUROC:0.9200\n",
      "\n",
      "Epoch: [318 | 1000] LR: 0.016707\n",
      "Train | 16/16 | Loss:0.3539 | MainLoss:0.1744 | Alpha:0.0496 | SPLoss:1.7947 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1801 | MainLoss:0.1801 | SPLoss:1.7913 | CLSLoss:0.0000 | AUROC:0.9813\n",
      "Test | 122/16 | Loss:0.5358 | MainLoss:0.5358 | SPLoss:1.7913 | CLSLoss:0.0000 | AUROC:0.9191\n",
      "\n",
      "Epoch: [319 | 1000] LR: 0.016684\n",
      "Train | 16/16 | Loss:0.3816 | MainLoss:0.2027 | Alpha:0.0515 | SPLoss:1.7894 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1721 | MainLoss:0.1721 | SPLoss:1.7814 | CLSLoss:0.0000 | AUROC:0.9812\n",
      "Test | 122/16 | Loss:0.4331 | MainLoss:0.4331 | SPLoss:1.7814 | CLSLoss:0.0000 | AUROC:0.9229\n",
      "\n",
      "Epoch: [320 | 1000] LR: 0.016660\n",
      "Train | 16/16 | Loss:0.3676 | MainLoss:0.1893 | Alpha:0.0515 | SPLoss:1.7825 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2022 | MainLoss:0.2022 | SPLoss:1.7759 | CLSLoss:0.0000 | AUROC:0.9811\n",
      "Test | 122/16 | Loss:0.5377 | MainLoss:0.5377 | SPLoss:1.7759 | CLSLoss:0.0000 | AUROC:0.9316\n",
      "\n",
      "Epoch: [321 | 1000] LR: 0.016637\n",
      "Train | 16/16 | Loss:0.3867 | MainLoss:0.2076 | Alpha:0.0511 | SPLoss:1.7910 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1686 | MainLoss:0.1686 | SPLoss:1.7934 | CLSLoss:0.0000 | AUROC:0.9823\n",
      "Test | 122/16 | Loss:0.4488 | MainLoss:0.4488 | SPLoss:1.7934 | CLSLoss:0.0000 | AUROC:0.9114\n",
      "\n",
      "Epoch: [322 | 1000] LR: 0.016613\n",
      "Train | 16/16 | Loss:0.3836 | MainLoss:0.2039 | Alpha:0.0530 | SPLoss:1.7967 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2480 | MainLoss:0.2480 | SPLoss:1.8104 | CLSLoss:0.0000 | AUROC:0.9816\n",
      "Test | 122/16 | Loss:0.4342 | MainLoss:0.4342 | SPLoss:1.8104 | CLSLoss:0.0000 | AUROC:0.8996\n",
      "\n",
      "Epoch: [323 | 1000] LR: 0.016590\n",
      "Train | 16/16 | Loss:0.3923 | MainLoss:0.2120 | Alpha:0.0521 | SPLoss:1.8031 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1729 | MainLoss:0.1729 | SPLoss:1.7963 | CLSLoss:0.0000 | AUROC:0.9815\n",
      "Test | 122/16 | Loss:0.4566 | MainLoss:0.4566 | SPLoss:1.7963 | CLSLoss:0.0000 | AUROC:0.9206\n",
      "\n",
      "Epoch: [324 | 1000] LR: 0.016566\n",
      "Train | 16/16 | Loss:0.3818 | MainLoss:0.2022 | Alpha:0.0517 | SPLoss:1.7965 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1715 | MainLoss:0.1715 | SPLoss:1.7960 | CLSLoss:0.0000 | AUROC:0.9815\n",
      "Test | 122/16 | Loss:0.4829 | MainLoss:0.4829 | SPLoss:1.7960 | CLSLoss:0.0000 | AUROC:0.9216\n",
      "\n",
      "Epoch: [325 | 1000] LR: 0.016542\n",
      "Train | 16/16 | Loss:0.3818 | MainLoss:0.2019 | Alpha:0.0506 | SPLoss:1.7994 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1658 | MainLoss:0.1658 | SPLoss:1.7997 | CLSLoss:0.0000 | AUROC:0.9826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 122/16 | Loss:0.4388 | MainLoss:0.4388 | SPLoss:1.7997 | CLSLoss:0.0000 | AUROC:0.9188\n",
      "\n",
      "Epoch: [326 | 1000] LR: 0.016518\n",
      "Train | 16/16 | Loss:0.3897 | MainLoss:0.2095 | Alpha:0.0499 | SPLoss:1.8014 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1791 | MainLoss:0.1791 | SPLoss:1.8076 | CLSLoss:0.0000 | AUROC:0.9820\n",
      "Test | 122/16 | Loss:0.4307 | MainLoss:0.4307 | SPLoss:1.8076 | CLSLoss:0.0000 | AUROC:0.9119\n",
      "\n",
      "Epoch: [327 | 1000] LR: 0.016494\n",
      "Train | 16/16 | Loss:0.3936 | MainLoss:0.2140 | Alpha:0.0496 | SPLoss:1.7969 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1703 | MainLoss:0.1703 | SPLoss:1.7926 | CLSLoss:0.0000 | AUROC:0.9821\n",
      "Test | 122/16 | Loss:0.4609 | MainLoss:0.4609 | SPLoss:1.7926 | CLSLoss:0.0000 | AUROC:0.9234\n",
      "\n",
      "Epoch: [328 | 1000] LR: 0.016471\n",
      "Train | 16/16 | Loss:0.3716 | MainLoss:0.1917 | Alpha:0.0508 | SPLoss:1.7992 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1840 | MainLoss:0.1840 | SPLoss:1.8113 | CLSLoss:0.0000 | AUROC:0.9817\n",
      "Test | 122/16 | Loss:0.4294 | MainLoss:0.4294 | SPLoss:1.8113 | CLSLoss:0.0000 | AUROC:0.9072\n",
      "\n",
      "Epoch: [329 | 1000] LR: 0.016447\n",
      "Train | 16/16 | Loss:0.3813 | MainLoss:0.2001 | Alpha:0.0504 | SPLoss:1.8127 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1700 | MainLoss:0.1700 | SPLoss:1.8146 | CLSLoss:0.0000 | AUROC:0.9818\n",
      "Test | 122/16 | Loss:0.4828 | MainLoss:0.4828 | SPLoss:1.8146 | CLSLoss:0.0000 | AUROC:0.9126\n",
      "\n",
      "Epoch: [330 | 1000] LR: 0.016423\n",
      "Train | 16/16 | Loss:0.3812 | MainLoss:0.1993 | Alpha:0.0490 | SPLoss:1.8192 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1737 | MainLoss:0.1737 | SPLoss:1.8174 | CLSLoss:0.0000 | AUROC:0.9816\n",
      "Test | 122/16 | Loss:0.4554 | MainLoss:0.4554 | SPLoss:1.8175 | CLSLoss:0.0000 | AUROC:0.9114\n",
      "\n",
      "Epoch: [331 | 1000] LR: 0.016398\n",
      "Train | 16/16 | Loss:0.3620 | MainLoss:0.1810 | Alpha:0.0511 | SPLoss:1.8101 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1912 | MainLoss:0.1912 | SPLoss:1.8083 | CLSLoss:0.0000 | AUROC:0.9815\n",
      "Test | 122/16 | Loss:0.4464 | MainLoss:0.4464 | SPLoss:1.8083 | CLSLoss:0.0000 | AUROC:0.9124\n",
      "\n",
      "Epoch: [332 | 1000] LR: 0.016374\n",
      "Train | 16/16 | Loss:0.3728 | MainLoss:0.1923 | Alpha:0.0493 | SPLoss:1.8050 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1849 | MainLoss:0.1849 | SPLoss:1.8095 | CLSLoss:0.0000 | AUROC:0.9816\n",
      "Test | 122/16 | Loss:0.4674 | MainLoss:0.4674 | SPLoss:1.8095 | CLSLoss:0.0000 | AUROC:0.9080\n",
      "\n",
      "Epoch: [333 | 1000] LR: 0.016350\n",
      "Train | 16/16 | Loss:0.3701 | MainLoss:0.1896 | Alpha:0.0516 | SPLoss:1.8046 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2054 | MainLoss:0.2054 | SPLoss:1.8115 | CLSLoss:0.0000 | AUROC:0.9817\n",
      "Test | 122/16 | Loss:0.4802 | MainLoss:0.4802 | SPLoss:1.8115 | CLSLoss:0.0000 | AUROC:0.8971\n",
      "\n",
      "Epoch: [334 | 1000] LR: 0.016326\n",
      "Train | 16/16 | Loss:0.3850 | MainLoss:0.2044 | Alpha:0.0531 | SPLoss:1.8064 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1794 | MainLoss:0.1794 | SPLoss:1.7957 | CLSLoss:0.0000 | AUROC:0.9810\n",
      "Test | 122/16 | Loss:0.5115 | MainLoss:0.5115 | SPLoss:1.7957 | CLSLoss:0.0000 | AUROC:0.9192\n",
      "\n",
      "Epoch: [335 | 1000] LR: 0.016301\n",
      "Train | 16/16 | Loss:0.3618 | MainLoss:0.1823 | Alpha:0.0515 | SPLoss:1.7950 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1714 | MainLoss:0.1714 | SPLoss:1.7896 | CLSLoss:0.0000 | AUROC:0.9817\n",
      "Test | 122/16 | Loss:0.4733 | MainLoss:0.4733 | SPLoss:1.7896 | CLSLoss:0.0000 | AUROC:0.9219\n",
      "\n",
      "Epoch: [336 | 1000] LR: 0.016277\n",
      "Train | 16/16 | Loss:0.3754 | MainLoss:0.1965 | Alpha:0.0511 | SPLoss:1.7883 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2000 | MainLoss:0.2000 | SPLoss:1.7838 | CLSLoss:0.0000 | AUROC:0.9812\n",
      "Test | 122/16 | Loss:0.3931 | MainLoss:0.3931 | SPLoss:1.7838 | CLSLoss:0.0000 | AUROC:0.9174\n",
      "\n",
      "Epoch: [337 | 1000] LR: 0.016252\n",
      "Train | 16/16 | Loss:0.3826 | MainLoss:0.2039 | Alpha:0.0506 | SPLoss:1.7875 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1723 | MainLoss:0.1723 | SPLoss:1.7902 | CLSLoss:0.0000 | AUROC:0.9814\n",
      "Test | 122/16 | Loss:0.4452 | MainLoss:0.4452 | SPLoss:1.7902 | CLSLoss:0.0000 | AUROC:0.9214\n",
      "\n",
      "Epoch: [338 | 1000] LR: 0.016228\n",
      "Train | 16/16 | Loss:0.3686 | MainLoss:0.1892 | Alpha:0.0525 | SPLoss:1.7941 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1822 | MainLoss:0.1822 | SPLoss:1.8001 | CLSLoss:0.0000 | AUROC:0.9822\n",
      "Test | 122/16 | Loss:0.4421 | MainLoss:0.4421 | SPLoss:1.8001 | CLSLoss:0.0000 | AUROC:0.9102\n",
      "\n",
      "Epoch: [339 | 1000] LR: 0.016203\n",
      "Train | 16/16 | Loss:0.3597 | MainLoss:0.1803 | Alpha:0.0518 | SPLoss:1.7941 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1696 | MainLoss:0.1696 | SPLoss:1.7902 | CLSLoss:0.0000 | AUROC:0.9818\n",
      "Test | 122/16 | Loss:0.4962 | MainLoss:0.4962 | SPLoss:1.7902 | CLSLoss:0.0000 | AUROC:0.9153\n",
      "\n",
      "Epoch: [340 | 1000] LR: 0.016179\n",
      "Train | 16/16 | Loss:0.4005 | MainLoss:0.2208 | Alpha:0.0521 | SPLoss:1.7969 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1811 | MainLoss:0.1811 | SPLoss:1.7988 | CLSLoss:0.0000 | AUROC:0.9815\n",
      "Test | 122/16 | Loss:0.4099 | MainLoss:0.4099 | SPLoss:1.7988 | CLSLoss:0.0000 | AUROC:0.9154\n",
      "\n",
      "Epoch: [341 | 1000] LR: 0.016154\n",
      "Train | 16/16 | Loss:0.3684 | MainLoss:0.1879 | Alpha:0.0515 | SPLoss:1.8050 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1766 | MainLoss:0.1766 | SPLoss:1.8087 | CLSLoss:0.0000 | AUROC:0.9821\n",
      "Test | 122/16 | Loss:0.4782 | MainLoss:0.4782 | SPLoss:1.8087 | CLSLoss:0.0000 | AUROC:0.9039\n",
      "\n",
      "Epoch: [342 | 1000] LR: 0.016129\n",
      "Train | 16/16 | Loss:0.3790 | MainLoss:0.1983 | Alpha:0.0510 | SPLoss:1.8070 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1727 | MainLoss:0.1727 | SPLoss:1.8086 | CLSLoss:0.0000 | AUROC:0.9824\n",
      "Test | 122/16 | Loss:0.4803 | MainLoss:0.4803 | SPLoss:1.8086 | CLSLoss:0.0000 | AUROC:0.9027\n",
      "\n",
      "Epoch: [343 | 1000] LR: 0.016104\n",
      "Train | 16/16 | Loss:0.3629 | MainLoss:0.1830 | Alpha:0.0517 | SPLoss:1.7990 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1951 | MainLoss:0.1951 | SPLoss:1.7904 | CLSLoss:0.0000 | AUROC:0.9818\n",
      "Test | 122/16 | Loss:0.5310 | MainLoss:0.5310 | SPLoss:1.7904 | CLSLoss:0.0000 | AUROC:0.9291\n",
      "\n",
      "Epoch: [344 | 1000] LR: 0.016079\n",
      "Train | 16/16 | Loss:0.3862 | MainLoss:0.2057 | Alpha:0.0507 | SPLoss:1.8051 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1694 | MainLoss:0.1694 | SPLoss:1.8091 | CLSLoss:0.0000 | AUROC:0.9822\n",
      "Test | 122/16 | Loss:0.4914 | MainLoss:0.4914 | SPLoss:1.8091 | CLSLoss:0.0000 | AUROC:0.9059\n",
      "\n",
      "Epoch: [345 | 1000] LR: 0.016054\n",
      "Train | 16/16 | Loss:0.3898 | MainLoss:0.2096 | Alpha:0.0505 | SPLoss:1.8019 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1725 | MainLoss:0.1725 | SPLoss:1.7996 | CLSLoss:0.0000 | AUROC:0.9812\n",
      "Test | 122/16 | Loss:0.4644 | MainLoss:0.4644 | SPLoss:1.7996 | CLSLoss:0.0000 | AUROC:0.9159\n",
      "\n",
      "Epoch: [346 | 1000] LR: 0.016029\n",
      "Train | 16/16 | Loss:0.3787 | MainLoss:0.1979 | Alpha:0.0516 | SPLoss:1.8080 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1683 | MainLoss:0.1683 | SPLoss:1.8084 | CLSLoss:0.0000 | AUROC:0.9823\n",
      "Test | 122/16 | Loss:0.4765 | MainLoss:0.4765 | SPLoss:1.8084 | CLSLoss:0.0000 | AUROC:0.9152\n",
      "\n",
      "Epoch: [347 | 1000] LR: 0.016004\n",
      "Train | 16/16 | Loss:0.3653 | MainLoss:0.1844 | Alpha:0.0506 | SPLoss:1.8089 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1862 | MainLoss:0.1862 | SPLoss:1.8094 | CLSLoss:0.0000 | AUROC:0.9822\n",
      "Test | 122/16 | Loss:0.4492 | MainLoss:0.4492 | SPLoss:1.8094 | CLSLoss:0.0000 | AUROC:0.9055\n",
      "\n",
      "Epoch: [348 | 1000] LR: 0.015979\n",
      "Train | 16/16 | Loss:0.3911 | MainLoss:0.2107 | Alpha:0.0533 | SPLoss:1.8040 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2546 | MainLoss:0.2546 | SPLoss:1.8229 | CLSLoss:0.0000 | AUROC:0.9819\n",
      "Test | 122/16 | Loss:0.4797 | MainLoss:0.4797 | SPLoss:1.8229 | CLSLoss:0.0000 | AUROC:0.8831\n",
      "\n",
      "Epoch: [349 | 1000] LR: 0.015954\n",
      "Train | 16/16 | Loss:0.3795 | MainLoss:0.1980 | Alpha:0.0515 | SPLoss:1.8148 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1751 | MainLoss:0.1751 | SPLoss:1.8156 | CLSLoss:0.0000 | AUROC:0.9821\n",
      "Test | 122/16 | Loss:0.4853 | MainLoss:0.4853 | SPLoss:1.8156 | CLSLoss:0.0000 | AUROC:0.9016\n",
      "\n",
      "Epoch: [350 | 1000] LR: 0.015929\n",
      "Train | 16/16 | Loss:0.3919 | MainLoss:0.2109 | Alpha:0.0504 | SPLoss:1.8102 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1902 | MainLoss:0.1902 | SPLoss:1.8154 | CLSLoss:0.0000 | AUROC:0.9828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 122/16 | Loss:0.4313 | MainLoss:0.4313 | SPLoss:1.8154 | CLSLoss:0.0000 | AUROC:0.9020\n",
      "\n",
      "Epoch: [351 | 1000] LR: 0.015903\n",
      "Train | 16/16 | Loss:0.3679 | MainLoss:0.1866 | Alpha:0.0505 | SPLoss:1.8121 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1734 | MainLoss:0.1734 | SPLoss:1.8009 | CLSLoss:0.0000 | AUROC:0.9826\n",
      "Test | 122/16 | Loss:0.4264 | MainLoss:0.4264 | SPLoss:1.8009 | CLSLoss:0.0000 | AUROC:0.9155\n",
      "\n",
      "Epoch: [352 | 1000] LR: 0.015878\n",
      "Train | 16/16 | Loss:0.3652 | MainLoss:0.1846 | Alpha:0.0526 | SPLoss:1.8063 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1782 | MainLoss:0.1782 | SPLoss:1.8105 | CLSLoss:0.0000 | AUROC:0.9820\n",
      "Test | 122/16 | Loss:0.4844 | MainLoss:0.4844 | SPLoss:1.8105 | CLSLoss:0.0000 | AUROC:0.9033\n",
      "\n",
      "Epoch: [353 | 1000] LR: 0.015852\n",
      "Train | 16/16 | Loss:0.3793 | MainLoss:0.1990 | Alpha:0.0528 | SPLoss:1.8027 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1697 | MainLoss:0.1697 | SPLoss:1.8051 | CLSLoss:0.0000 | AUROC:0.9819\n",
      "Test | 122/16 | Loss:0.4868 | MainLoss:0.4868 | SPLoss:1.8051 | CLSLoss:0.0000 | AUROC:0.9109\n",
      "\n",
      "Epoch: [354 | 1000] LR: 0.015827\n",
      "Train | 16/16 | Loss:0.3744 | MainLoss:0.1940 | Alpha:0.0502 | SPLoss:1.8041 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1821 | MainLoss:0.1821 | SPLoss:1.8063 | CLSLoss:0.0000 | AUROC:0.9825\n",
      "Test | 122/16 | Loss:0.4384 | MainLoss:0.4384 | SPLoss:1.8063 | CLSLoss:0.0000 | AUROC:0.9108\n",
      "\n",
      "Epoch: [355 | 1000] LR: 0.015801\n",
      "Train | 16/16 | Loss:0.3731 | MainLoss:0.1927 | Alpha:0.0509 | SPLoss:1.8033 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1815 | MainLoss:0.1815 | SPLoss:1.8119 | CLSLoss:0.0000 | AUROC:0.9828\n",
      "Test | 122/16 | Loss:0.4746 | MainLoss:0.4746 | SPLoss:1.8119 | CLSLoss:0.0000 | AUROC:0.9039\n",
      "\n",
      "Epoch: [356 | 1000] LR: 0.015776\n",
      "Train | 16/16 | Loss:0.3746 | MainLoss:0.1944 | Alpha:0.0495 | SPLoss:1.8022 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1687 | MainLoss:0.1687 | SPLoss:1.8035 | CLSLoss:0.0000 | AUROC:0.9824\n",
      "Test | 122/16 | Loss:0.4441 | MainLoss:0.4441 | SPLoss:1.8035 | CLSLoss:0.0000 | AUROC:0.9168\n",
      "\n",
      "Epoch: [357 | 1000] LR: 0.015750\n",
      "Train | 16/16 | Loss:0.3683 | MainLoss:0.1883 | Alpha:0.0497 | SPLoss:1.8001 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1740 | MainLoss:0.1740 | SPLoss:1.8022 | CLSLoss:0.0000 | AUROC:0.9830\n",
      "Test | 122/16 | Loss:0.4724 | MainLoss:0.4724 | SPLoss:1.8022 | CLSLoss:0.0000 | AUROC:0.9086\n",
      "\n",
      "Epoch: [358 | 1000] LR: 0.015724\n",
      "Train | 16/16 | Loss:0.3837 | MainLoss:0.2033 | Alpha:0.0510 | SPLoss:1.8038 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1897 | MainLoss:0.1897 | SPLoss:1.8065 | CLSLoss:0.0000 | AUROC:0.9829\n",
      "Test | 122/16 | Loss:0.4296 | MainLoss:0.4296 | SPLoss:1.8065 | CLSLoss:0.0000 | AUROC:0.9042\n",
      "\n",
      "Epoch: [359 | 1000] LR: 0.015699\n",
      "Train | 16/16 | Loss:0.3733 | MainLoss:0.1927 | Alpha:0.0518 | SPLoss:1.8068 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1849 | MainLoss:0.1849 | SPLoss:1.8088 | CLSLoss:0.0000 | AUROC:0.9827\n",
      "Test | 122/16 | Loss:0.4733 | MainLoss:0.4733 | SPLoss:1.8088 | CLSLoss:0.0000 | AUROC:0.8993\n",
      "\n",
      "Epoch: [360 | 1000] LR: 0.015673\n",
      "Train | 16/16 | Loss:0.3830 | MainLoss:0.2026 | Alpha:0.0502 | SPLoss:1.8043 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1670 | MainLoss:0.1670 | SPLoss:1.7975 | CLSLoss:0.0000 | AUROC:0.9827\n",
      "Test | 122/16 | Loss:0.4747 | MainLoss:0.4747 | SPLoss:1.7975 | CLSLoss:0.0000 | AUROC:0.9100\n",
      "\n",
      "Epoch: [361 | 1000] LR: 0.015647\n",
      "Train | 16/16 | Loss:0.3800 | MainLoss:0.1996 | Alpha:0.0496 | SPLoss:1.8039 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1759 | MainLoss:0.1759 | SPLoss:1.8041 | CLSLoss:0.0000 | AUROC:0.9832\n",
      "Test | 122/16 | Loss:0.4097 | MainLoss:0.4097 | SPLoss:1.8041 | CLSLoss:0.0000 | AUROC:0.9131\n",
      "\n",
      "Epoch: [362 | 1000] LR: 0.015621\n",
      "Train | 16/16 | Loss:0.3784 | MainLoss:0.1976 | Alpha:0.0506 | SPLoss:1.8074 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2081 | MainLoss:0.2081 | SPLoss:1.8172 | CLSLoss:0.0000 | AUROC:0.9829\n",
      "Test | 122/16 | Loss:0.4574 | MainLoss:0.4574 | SPLoss:1.8172 | CLSLoss:0.0000 | AUROC:0.8984\n",
      "\n",
      "Epoch: [363 | 1000] LR: 0.015595\n",
      "Train | 16/16 | Loss:0.3907 | MainLoss:0.2098 | Alpha:0.0510 | SPLoss:1.8099 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1772 | MainLoss:0.1772 | SPLoss:1.8075 | CLSLoss:0.0000 | AUROC:0.9826\n",
      "Test | 122/16 | Loss:0.4320 | MainLoss:0.4320 | SPLoss:1.8075 | CLSLoss:0.0000 | AUROC:0.9102\n",
      "\n",
      "Epoch: [364 | 1000] LR: 0.015569\n",
      "Train | 16/16 | Loss:0.3692 | MainLoss:0.1884 | Alpha:0.0508 | SPLoss:1.8083 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1669 | MainLoss:0.1669 | SPLoss:1.8069 | CLSLoss:0.0000 | AUROC:0.9827\n",
      "Test | 122/16 | Loss:0.4890 | MainLoss:0.4890 | SPLoss:1.8069 | CLSLoss:0.0000 | AUROC:0.9129\n",
      "\n",
      "Epoch: [365 | 1000] LR: 0.015543\n",
      "Train | 16/16 | Loss:0.3905 | MainLoss:0.2096 | Alpha:0.0512 | SPLoss:1.8085 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1698 | MainLoss:0.1698 | SPLoss:1.8106 | CLSLoss:0.0000 | AUROC:0.9832\n",
      "Test | 122/16 | Loss:0.4420 | MainLoss:0.4420 | SPLoss:1.8106 | CLSLoss:0.0000 | AUROC:0.9123\n",
      "\n",
      "Epoch: [366 | 1000] LR: 0.015516\n",
      "Train | 16/16 | Loss:0.3581 | MainLoss:0.1773 | Alpha:0.0521 | SPLoss:1.8075 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1698 | MainLoss:0.1698 | SPLoss:1.8067 | CLSLoss:0.0000 | AUROC:0.9827\n",
      "Test | 122/16 | Loss:0.4588 | MainLoss:0.4588 | SPLoss:1.8067 | CLSLoss:0.0000 | AUROC:0.9190\n",
      "\n",
      "Epoch: [367 | 1000] LR: 0.015490\n",
      "Train | 16/16 | Loss:0.3899 | MainLoss:0.2088 | Alpha:0.0536 | SPLoss:1.8103 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1652 | MainLoss:0.1652 | SPLoss:1.8063 | CLSLoss:0.0000 | AUROC:0.9831\n",
      "Test | 122/16 | Loss:0.4375 | MainLoss:0.4375 | SPLoss:1.8063 | CLSLoss:0.0000 | AUROC:0.9188\n",
      "\n",
      "Epoch: [368 | 1000] LR: 0.015464\n",
      "Train | 16/16 | Loss:0.3758 | MainLoss:0.1954 | Alpha:0.0515 | SPLoss:1.8037 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1895 | MainLoss:0.1895 | SPLoss:1.8028 | CLSLoss:0.0000 | AUROC:0.9821\n",
      "Test | 122/16 | Loss:0.4267 | MainLoss:0.4267 | SPLoss:1.8028 | CLSLoss:0.0000 | AUROC:0.9109\n",
      "\n",
      "Epoch: [369 | 1000] LR: 0.015438\n",
      "Train | 16/16 | Loss:0.3665 | MainLoss:0.1866 | Alpha:0.0510 | SPLoss:1.7990 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1777 | MainLoss:0.1777 | SPLoss:1.7968 | CLSLoss:0.0000 | AUROC:0.9823\n",
      "Test | 122/16 | Loss:0.4271 | MainLoss:0.4271 | SPLoss:1.7968 | CLSLoss:0.0000 | AUROC:0.9098\n",
      "\n",
      "Epoch: [370 | 1000] LR: 0.015411\n",
      "Train | 16/16 | Loss:0.3766 | MainLoss:0.1965 | Alpha:0.0514 | SPLoss:1.8011 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1948 | MainLoss:0.1948 | SPLoss:1.8040 | CLSLoss:0.0000 | AUROC:0.9821\n",
      "Test | 122/16 | Loss:0.4398 | MainLoss:0.4398 | SPLoss:1.8040 | CLSLoss:0.0000 | AUROC:0.9039\n",
      "\n",
      "Epoch: [371 | 1000] LR: 0.015385\n",
      "Train | 16/16 | Loss:0.3764 | MainLoss:0.1962 | Alpha:0.0523 | SPLoss:1.8019 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1842 | MainLoss:0.1842 | SPLoss:1.7955 | CLSLoss:0.0000 | AUROC:0.9823\n",
      "Test | 122/16 | Loss:0.4356 | MainLoss:0.4356 | SPLoss:1.7955 | CLSLoss:0.0000 | AUROC:0.9098\n",
      "\n",
      "Epoch: [372 | 1000] LR: 0.015358\n",
      "Train | 16/16 | Loss:0.3818 | MainLoss:0.2017 | Alpha:0.0508 | SPLoss:1.8008 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1704 | MainLoss:0.1704 | SPLoss:1.7987 | CLSLoss:0.0000 | AUROC:0.9824\n",
      "Test | 122/16 | Loss:0.4344 | MainLoss:0.4344 | SPLoss:1.7987 | CLSLoss:0.0000 | AUROC:0.9174\n",
      "\n",
      "Epoch: [373 | 1000] LR: 0.015332\n",
      "Train | 16/16 | Loss:0.3862 | MainLoss:0.2058 | Alpha:0.0508 | SPLoss:1.8043 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1691 | MainLoss:0.1691 | SPLoss:1.8046 | CLSLoss:0.0000 | AUROC:0.9823\n",
      "Test | 122/16 | Loss:0.4836 | MainLoss:0.4836 | SPLoss:1.8046 | CLSLoss:0.0000 | AUROC:0.9171\n",
      "\n",
      "Epoch: [374 | 1000] LR: 0.015305\n",
      "Train | 16/16 | Loss:0.3980 | MainLoss:0.2175 | Alpha:0.0524 | SPLoss:1.8052 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1818 | MainLoss:0.1818 | SPLoss:1.8040 | CLSLoss:0.0000 | AUROC:0.9823\n",
      "Test | 122/16 | Loss:0.4054 | MainLoss:0.4054 | SPLoss:1.8040 | CLSLoss:0.0000 | AUROC:0.9155\n",
      "\n",
      "Epoch: [375 | 1000] LR: 0.015278\n",
      "Train | 16/16 | Loss:0.3610 | MainLoss:0.1806 | Alpha:0.0499 | SPLoss:1.8035 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1802 | MainLoss:0.1802 | SPLoss:1.8102 | CLSLoss:0.0000 | AUROC:0.9825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 122/16 | Loss:0.4378 | MainLoss:0.4378 | SPLoss:1.8102 | CLSLoss:0.0000 | AUROC:0.9108\n",
      "\n",
      "Epoch: [376 | 1000] LR: 0.015252\n",
      "Train | 16/16 | Loss:0.3721 | MainLoss:0.1914 | Alpha:0.0517 | SPLoss:1.8072 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1740 | MainLoss:0.1740 | SPLoss:1.7955 | CLSLoss:0.0000 | AUROC:0.9822\n",
      "Test | 122/16 | Loss:0.4822 | MainLoss:0.4822 | SPLoss:1.7955 | CLSLoss:0.0000 | AUROC:0.9239\n",
      "\n",
      "Epoch: [377 | 1000] LR: 0.015225\n",
      "Train | 16/16 | Loss:0.3707 | MainLoss:0.1911 | Alpha:0.0514 | SPLoss:1.7958 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1737 | MainLoss:0.1737 | SPLoss:1.7921 | CLSLoss:0.0000 | AUROC:0.9824\n",
      "Test | 122/16 | Loss:0.4213 | MainLoss:0.4213 | SPLoss:1.7921 | CLSLoss:0.0000 | AUROC:0.9199\n",
      "\n",
      "Epoch: [378 | 1000] LR: 0.015198\n",
      "Train | 16/16 | Loss:0.3608 | MainLoss:0.1818 | Alpha:0.0523 | SPLoss:1.7896 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2121 | MainLoss:0.2121 | SPLoss:1.7937 | CLSLoss:0.0000 | AUROC:0.9823\n",
      "Test | 122/16 | Loss:0.4565 | MainLoss:0.4565 | SPLoss:1.7937 | CLSLoss:0.0000 | AUROC:0.9022\n",
      "\n",
      "Epoch: [379 | 1000] LR: 0.015171\n",
      "Train | 16/16 | Loss:0.3836 | MainLoss:0.2043 | Alpha:0.0516 | SPLoss:1.7936 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1872 | MainLoss:0.1872 | SPLoss:1.8130 | CLSLoss:0.0000 | AUROC:0.9829\n",
      "Test | 122/16 | Loss:0.4672 | MainLoss:0.4672 | SPLoss:1.8130 | CLSLoss:0.0000 | AUROC:0.9048\n",
      "\n",
      "Epoch: [380 | 1000] LR: 0.015144\n",
      "Train | 16/16 | Loss:0.3774 | MainLoss:0.1970 | Alpha:0.0510 | SPLoss:1.8047 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1683 | MainLoss:0.1683 | SPLoss:1.7949 | CLSLoss:0.0000 | AUROC:0.9824\n",
      "Test | 122/16 | Loss:0.4296 | MainLoss:0.4296 | SPLoss:1.7949 | CLSLoss:0.0000 | AUROC:0.9213\n",
      "\n",
      "Epoch: [381 | 1000] LR: 0.015117\n",
      "Train | 16/16 | Loss:0.3637 | MainLoss:0.1838 | Alpha:0.0503 | SPLoss:1.7997 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1712 | MainLoss:0.1712 | SPLoss:1.8011 | CLSLoss:0.0000 | AUROC:0.9823\n",
      "Test | 122/16 | Loss:0.4523 | MainLoss:0.4523 | SPLoss:1.8011 | CLSLoss:0.0000 | AUROC:0.9175\n",
      "\n",
      "Epoch: [382 | 1000] LR: 0.015090\n",
      "Train | 16/16 | Loss:0.3828 | MainLoss:0.2032 | Alpha:0.0524 | SPLoss:1.7965 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1681 | MainLoss:0.1681 | SPLoss:1.8008 | CLSLoss:0.0000 | AUROC:0.9829\n",
      "Test | 122/16 | Loss:0.4474 | MainLoss:0.4474 | SPLoss:1.8008 | CLSLoss:0.0000 | AUROC:0.9120\n",
      "\n",
      "Epoch: [383 | 1000] LR: 0.015063\n",
      "Train | 16/16 | Loss:0.3805 | MainLoss:0.2002 | Alpha:0.0501 | SPLoss:1.8029 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1705 | MainLoss:0.1705 | SPLoss:1.7968 | CLSLoss:0.0000 | AUROC:0.9832\n",
      "Test | 122/16 | Loss:0.5239 | MainLoss:0.5239 | SPLoss:1.7968 | CLSLoss:0.0000 | AUROC:0.9151\n",
      "\n",
      "Epoch: [384 | 1000] LR: 0.015036\n",
      "Train | 16/16 | Loss:0.3743 | MainLoss:0.1941 | Alpha:0.0508 | SPLoss:1.8024 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1639 | MainLoss:0.1639 | SPLoss:1.8013 | CLSLoss:0.0000 | AUROC:0.9834\n",
      "Test | 122/16 | Loss:0.4649 | MainLoss:0.4649 | SPLoss:1.8013 | CLSLoss:0.0000 | AUROC:0.9121\n",
      "\n",
      "Epoch: [385 | 1000] LR: 0.015009\n",
      "Train | 16/16 | Loss:0.3801 | MainLoss:0.1999 | Alpha:0.0534 | SPLoss:1.8021 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1641 | MainLoss:0.1641 | SPLoss:1.7992 | CLSLoss:0.0000 | AUROC:0.9835\n",
      "Test | 122/16 | Loss:0.4712 | MainLoss:0.4712 | SPLoss:1.7992 | CLSLoss:0.0000 | AUROC:0.9112\n",
      "\n",
      "Epoch: [386 | 1000] LR: 0.014982\n",
      "Train | 16/16 | Loss:0.3719 | MainLoss:0.1911 | Alpha:0.0511 | SPLoss:1.8075 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1941 | MainLoss:0.1941 | SPLoss:1.8117 | CLSLoss:0.0000 | AUROC:0.9829\n",
      "Test | 122/16 | Loss:0.4469 | MainLoss:0.4469 | SPLoss:1.8117 | CLSLoss:0.0000 | AUROC:0.9014\n",
      "\n",
      "Epoch: [387 | 1000] LR: 0.014955\n",
      "Train | 16/16 | Loss:0.3867 | MainLoss:0.2060 | Alpha:0.0518 | SPLoss:1.8071 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1648 | MainLoss:0.1648 | SPLoss:1.8093 | CLSLoss:0.0000 | AUROC:0.9831\n",
      "Test | 122/16 | Loss:0.4784 | MainLoss:0.4784 | SPLoss:1.8093 | CLSLoss:0.0000 | AUROC:0.9128\n",
      "\n",
      "Epoch: [388 | 1000] LR: 0.014927\n",
      "Train | 16/16 | Loss:0.3726 | MainLoss:0.1915 | Alpha:0.0514 | SPLoss:1.8112 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1689 | MainLoss:0.1689 | SPLoss:1.8041 | CLSLoss:0.0000 | AUROC:0.9829\n",
      "Test | 122/16 | Loss:0.4591 | MainLoss:0.4591 | SPLoss:1.8041 | CLSLoss:0.0000 | AUROC:0.9130\n",
      "\n",
      "Epoch: [389 | 1000] LR: 0.014900\n",
      "Train | 16/16 | Loss:0.3796 | MainLoss:0.1987 | Alpha:0.0539 | SPLoss:1.8087 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1700 | MainLoss:0.1700 | SPLoss:1.8052 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.4304 | MainLoss:0.4304 | SPLoss:1.8052 | CLSLoss:0.0000 | AUROC:0.9125\n",
      "\n",
      "Epoch: [390 | 1000] LR: 0.014873\n",
      "Train | 16/16 | Loss:0.3870 | MainLoss:0.2062 | Alpha:0.0530 | SPLoss:1.8082 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1909 | MainLoss:0.1909 | SPLoss:1.8145 | CLSLoss:0.0000 | AUROC:0.9834\n",
      "Test | 122/16 | Loss:0.4342 | MainLoss:0.4342 | SPLoss:1.8145 | CLSLoss:0.0000 | AUROC:0.9054\n",
      "\n",
      "Epoch: [391 | 1000] LR: 0.014845\n",
      "Train | 16/16 | Loss:0.3617 | MainLoss:0.1805 | Alpha:0.0522 | SPLoss:1.8118 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1696 | MainLoss:0.1696 | SPLoss:1.8064 | CLSLoss:0.0000 | AUROC:0.9820\n",
      "Test | 122/16 | Loss:0.5017 | MainLoss:0.5017 | SPLoss:1.8064 | CLSLoss:0.0000 | AUROC:0.9173\n",
      "\n",
      "Epoch: [392 | 1000] LR: 0.014818\n",
      "Train | 16/16 | Loss:0.3709 | MainLoss:0.1903 | Alpha:0.0548 | SPLoss:1.8060 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1768 | MainLoss:0.1768 | SPLoss:1.8124 | CLSLoss:0.0000 | AUROC:0.9827\n",
      "Test | 122/16 | Loss:0.4532 | MainLoss:0.4532 | SPLoss:1.8124 | CLSLoss:0.0000 | AUROC:0.9079\n",
      "\n",
      "Epoch: [393 | 1000] LR: 0.014790\n",
      "Train | 16/16 | Loss:0.3667 | MainLoss:0.1859 | Alpha:0.0526 | SPLoss:1.8078 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1681 | MainLoss:0.1681 | SPLoss:1.8103 | CLSLoss:0.0000 | AUROC:0.9824\n",
      "Test | 122/16 | Loss:0.4888 | MainLoss:0.4888 | SPLoss:1.8103 | CLSLoss:0.0000 | AUROC:0.9104\n",
      "\n",
      "Epoch: [394 | 1000] LR: 0.014762\n",
      "Train | 16/16 | Loss:0.3851 | MainLoss:0.2035 | Alpha:0.0557 | SPLoss:1.8155 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1833 | MainLoss:0.1833 | SPLoss:1.8136 | CLSLoss:0.0000 | AUROC:0.9814\n",
      "Test | 122/16 | Loss:0.5062 | MainLoss:0.5062 | SPLoss:1.8136 | CLSLoss:0.0000 | AUROC:0.9205\n",
      "\n",
      "Epoch: [395 | 1000] LR: 0.014735\n",
      "Train | 16/16 | Loss:0.3888 | MainLoss:0.2069 | Alpha:0.0512 | SPLoss:1.8193 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1694 | MainLoss:0.1694 | SPLoss:1.8253 | CLSLoss:0.0000 | AUROC:0.9823\n",
      "Test | 122/16 | Loss:0.4666 | MainLoss:0.4666 | SPLoss:1.8253 | CLSLoss:0.0000 | AUROC:0.9078\n",
      "\n",
      "Epoch: [396 | 1000] LR: 0.014707\n",
      "Train | 16/16 | Loss:0.3577 | MainLoss:0.1751 | Alpha:0.0518 | SPLoss:1.8254 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1777 | MainLoss:0.1777 | SPLoss:1.8150 | CLSLoss:0.0000 | AUROC:0.9825\n",
      "Test | 122/16 | Loss:0.4664 | MainLoss:0.4664 | SPLoss:1.8150 | CLSLoss:0.0000 | AUROC:0.9115\n",
      "\n",
      "Epoch: [397 | 1000] LR: 0.014679\n",
      "Train | 16/16 | Loss:0.3646 | MainLoss:0.1836 | Alpha:0.0508 | SPLoss:1.8101 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1713 | MainLoss:0.1713 | SPLoss:1.8069 | CLSLoss:0.0000 | AUROC:0.9827\n",
      "Test | 122/16 | Loss:0.4387 | MainLoss:0.4387 | SPLoss:1.8069 | CLSLoss:0.0000 | AUROC:0.9168\n",
      "\n",
      "Epoch: [398 | 1000] LR: 0.014652\n",
      "Train | 16/16 | Loss:0.3885 | MainLoss:0.2073 | Alpha:0.0514 | SPLoss:1.8120 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.2107 | MainLoss:0.2107 | SPLoss:1.8330 | CLSLoss:0.0000 | AUROC:0.9835\n",
      "Test | 122/16 | Loss:0.4336 | MainLoss:0.4336 | SPLoss:1.8330 | CLSLoss:0.0000 | AUROC:0.8940\n",
      "\n",
      "Epoch: [399 | 1000] LR: 0.014624\n",
      "Train | 16/16 | Loss:0.3670 | MainLoss:0.1851 | Alpha:0.0537 | SPLoss:1.8190 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1676 | MainLoss:0.1676 | SPLoss:1.8072 | CLSLoss:0.0000 | AUROC:0.9824\n",
      "Test | 122/16 | Loss:0.4762 | MainLoss:0.4762 | SPLoss:1.8072 | CLSLoss:0.0000 | AUROC:0.9148\n",
      "\n",
      "Epoch: [400 | 1000] LR: 0.014596\n",
      "Train | 16/16 | Loss:0.3635 | MainLoss:0.1827 | Alpha:0.0512 | SPLoss:1.8081 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1742 | MainLoss:0.1742 | SPLoss:1.8079 | CLSLoss:0.0000 | AUROC:0.9823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 122/16 | Loss:0.4960 | MainLoss:0.4960 | SPLoss:1.8079 | CLSLoss:0.0000 | AUROC:0.9126\n",
      "\n",
      "Epoch: [401 | 1000] LR: 0.001457\n",
      "Train | 16/16 | Loss:0.3598 | MainLoss:0.1790 | Alpha:0.0511 | SPLoss:1.8073 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1725 | MainLoss:0.1725 | SPLoss:1.8078 | CLSLoss:0.0000 | AUROC:0.9824\n",
      "Test | 122/16 | Loss:0.4880 | MainLoss:0.4880 | SPLoss:1.8078 | CLSLoss:0.0000 | AUROC:0.9115\n",
      "\n",
      "Epoch: [402 | 1000] LR: 0.001454\n",
      "Train | 16/16 | Loss:0.3470 | MainLoss:0.1663 | Alpha:0.0526 | SPLoss:1.8068 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1714 | MainLoss:0.1714 | SPLoss:1.8055 | CLSLoss:0.0000 | AUROC:0.9824\n",
      "Test | 122/16 | Loss:0.4912 | MainLoss:0.4912 | SPLoss:1.8055 | CLSLoss:0.0000 | AUROC:0.9116\n",
      "\n",
      "Epoch: [403 | 1000] LR: 0.001451\n",
      "Train | 16/16 | Loss:0.3526 | MainLoss:0.1721 | Alpha:0.0495 | SPLoss:1.8057 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1694 | MainLoss:0.1694 | SPLoss:1.8057 | CLSLoss:0.0000 | AUROC:0.9827\n",
      "Test | 122/16 | Loss:0.4930 | MainLoss:0.4930 | SPLoss:1.8057 | CLSLoss:0.0000 | AUROC:0.9113\n",
      "\n",
      "Epoch: [404 | 1000] LR: 0.001448\n",
      "Train | 16/16 | Loss:0.3604 | MainLoss:0.1798 | Alpha:0.0505 | SPLoss:1.8058 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1714 | MainLoss:0.1714 | SPLoss:1.8049 | CLSLoss:0.0000 | AUROC:0.9830\n",
      "Test | 122/16 | Loss:0.4779 | MainLoss:0.4779 | SPLoss:1.8049 | CLSLoss:0.0000 | AUROC:0.9103\n",
      "\n",
      "Epoch: [405 | 1000] LR: 0.001446\n",
      "Train | 16/16 | Loss:0.3508 | MainLoss:0.1703 | Alpha:0.0496 | SPLoss:1.8048 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1708 | MainLoss:0.1708 | SPLoss:1.8061 | CLSLoss:0.0000 | AUROC:0.9828\n",
      "Test | 122/16 | Loss:0.4863 | MainLoss:0.4863 | SPLoss:1.8061 | CLSLoss:0.0000 | AUROC:0.9090\n",
      "\n",
      "Epoch: [406 | 1000] LR: 0.001443\n",
      "Train | 16/16 | Loss:0.3577 | MainLoss:0.1772 | Alpha:0.0499 | SPLoss:1.8053 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1715 | MainLoss:0.1715 | SPLoss:1.8043 | CLSLoss:0.0000 | AUROC:0.9829\n",
      "Test | 122/16 | Loss:0.4726 | MainLoss:0.4726 | SPLoss:1.8043 | CLSLoss:0.0000 | AUROC:0.9109\n",
      "\n",
      "Epoch: [407 | 1000] LR: 0.001440\n",
      "Train | 16/16 | Loss:0.3506 | MainLoss:0.1702 | Alpha:0.0502 | SPLoss:1.8035 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1723 | MainLoss:0.1723 | SPLoss:1.8026 | CLSLoss:0.0000 | AUROC:0.9827\n",
      "Test | 122/16 | Loss:0.4683 | MainLoss:0.4683 | SPLoss:1.8026 | CLSLoss:0.0000 | AUROC:0.9116\n",
      "\n",
      "Epoch: [408 | 1000] LR: 0.001437\n",
      "Train | 16/16 | Loss:0.3540 | MainLoss:0.1738 | Alpha:0.0495 | SPLoss:1.8021 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1719 | MainLoss:0.1719 | SPLoss:1.8024 | CLSLoss:0.0000 | AUROC:0.9829\n",
      "Test | 122/16 | Loss:0.4712 | MainLoss:0.4712 | SPLoss:1.8024 | CLSLoss:0.0000 | AUROC:0.9102\n",
      "\n",
      "Epoch: [409 | 1000] LR: 0.001434\n",
      "Train | 16/16 | Loss:0.3565 | MainLoss:0.1764 | Alpha:0.0512 | SPLoss:1.8010 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1684 | MainLoss:0.1684 | SPLoss:1.7999 | CLSLoss:0.0000 | AUROC:0.9830\n",
      "Test | 122/16 | Loss:0.4748 | MainLoss:0.4748 | SPLoss:1.7999 | CLSLoss:0.0000 | AUROC:0.9111\n",
      "\n",
      "Epoch: [410 | 1000] LR: 0.001431\n",
      "Train | 16/16 | Loss:0.3669 | MainLoss:0.1870 | Alpha:0.0494 | SPLoss:1.7998 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1740 | MainLoss:0.1740 | SPLoss:1.8006 | CLSLoss:0.0000 | AUROC:0.9833\n",
      "Test | 122/16 | Loss:0.4633 | MainLoss:0.4633 | SPLoss:1.8006 | CLSLoss:0.0000 | AUROC:0.9086\n",
      "\n",
      "Epoch: [411 | 1000] LR: 0.001429\n",
      "Train | 16/16 | Loss:0.3665 | MainLoss:0.1865 | Alpha:0.0512 | SPLoss:1.7997 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1661 | MainLoss:0.1661 | SPLoss:1.7991 | CLSLoss:0.0000 | AUROC:0.9830\n",
      "Test | 122/16 | Loss:0.4723 | MainLoss:0.4723 | SPLoss:1.7991 | CLSLoss:0.0000 | AUROC:0.9123\n",
      "\n",
      "Epoch: [412 | 1000] LR: 0.001426\n",
      "Train | 16/16 | Loss:0.3623 | MainLoss:0.1824 | Alpha:0.0508 | SPLoss:1.7993 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1678 | MainLoss:0.1678 | SPLoss:1.8000 | CLSLoss:0.0000 | AUROC:0.9830\n",
      "Test | 122/16 | Loss:0.4702 | MainLoss:0.4702 | SPLoss:1.8000 | CLSLoss:0.0000 | AUROC:0.9109\n",
      "\n",
      "Epoch: [413 | 1000] LR: 0.001423\n",
      "Train | 16/16 | Loss:0.3688 | MainLoss:0.1888 | Alpha:0.0495 | SPLoss:1.7998 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1647 | MainLoss:0.1647 | SPLoss:1.7991 | CLSLoss:0.0000 | AUROC:0.9831\n",
      "Test | 122/16 | Loss:0.4760 | MainLoss:0.4760 | SPLoss:1.7991 | CLSLoss:0.0000 | AUROC:0.9121\n",
      "\n",
      "Epoch: [414 | 1000] LR: 0.001420\n",
      "Train | 16/16 | Loss:0.3685 | MainLoss:0.1886 | Alpha:0.0533 | SPLoss:1.7991 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1651 | MainLoss:0.1651 | SPLoss:1.7984 | CLSLoss:0.0000 | AUROC:0.9833\n",
      "Test | 122/16 | Loss:0.4718 | MainLoss:0.4718 | SPLoss:1.7984 | CLSLoss:0.0000 | AUROC:0.9119\n",
      "\n",
      "Epoch: [415 | 1000] LR: 0.001417\n",
      "Train | 16/16 | Loss:0.3699 | MainLoss:0.1901 | Alpha:0.0514 | SPLoss:1.7977 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1666 | MainLoss:0.1666 | SPLoss:1.7977 | CLSLoss:0.0000 | AUROC:0.9833\n",
      "Test | 122/16 | Loss:0.4644 | MainLoss:0.4644 | SPLoss:1.7977 | CLSLoss:0.0000 | AUROC:0.9118\n",
      "\n",
      "Epoch: [416 | 1000] LR: 0.001414\n",
      "Train | 16/16 | Loss:0.3450 | MainLoss:0.1651 | Alpha:0.0497 | SPLoss:1.7986 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1667 | MainLoss:0.1667 | SPLoss:1.7984 | CLSLoss:0.0000 | AUROC:0.9833\n",
      "Test | 122/16 | Loss:0.4736 | MainLoss:0.4736 | SPLoss:1.7984 | CLSLoss:0.0000 | AUROC:0.9121\n",
      "\n",
      "Epoch: [417 | 1000] LR: 0.001412\n",
      "Train | 16/16 | Loss:0.3559 | MainLoss:0.1760 | Alpha:0.0507 | SPLoss:1.7991 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1673 | MainLoss:0.1673 | SPLoss:1.7987 | CLSLoss:0.0000 | AUROC:0.9829\n",
      "Test | 122/16 | Loss:0.4777 | MainLoss:0.4777 | SPLoss:1.7987 | CLSLoss:0.0000 | AUROC:0.9115\n",
      "\n",
      "Epoch: [418 | 1000] LR: 0.001409\n",
      "Train | 16/16 | Loss:0.3496 | MainLoss:0.1696 | Alpha:0.0490 | SPLoss:1.7994 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1727 | MainLoss:0.1727 | SPLoss:1.8006 | CLSLoss:0.0000 | AUROC:0.9835\n",
      "Test | 122/16 | Loss:0.4779 | MainLoss:0.4779 | SPLoss:1.8006 | CLSLoss:0.0000 | AUROC:0.9077\n",
      "\n",
      "Epoch: [419 | 1000] LR: 0.001406\n",
      "Train | 16/16 | Loss:0.3443 | MainLoss:0.1642 | Alpha:0.0511 | SPLoss:1.8010 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1692 | MainLoss:0.1692 | SPLoss:1.8005 | CLSLoss:0.0000 | AUROC:0.9834\n",
      "Test | 122/16 | Loss:0.4934 | MainLoss:0.4934 | SPLoss:1.8005 | CLSLoss:0.0000 | AUROC:0.9082\n",
      "\n",
      "Epoch: [420 | 1000] LR: 0.001403\n",
      "Train | 16/16 | Loss:0.3570 | MainLoss:0.1770 | Alpha:0.0517 | SPLoss:1.8005 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1703 | MainLoss:0.1703 | SPLoss:1.8009 | CLSLoss:0.0000 | AUROC:0.9833\n",
      "Test | 122/16 | Loss:0.4954 | MainLoss:0.4954 | SPLoss:1.8009 | CLSLoss:0.0000 | AUROC:0.9058\n",
      "\n",
      "Epoch: [421 | 1000] LR: 0.001400\n",
      "Train | 16/16 | Loss:0.3456 | MainLoss:0.1656 | Alpha:0.0500 | SPLoss:1.8007 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1689 | MainLoss:0.1689 | SPLoss:1.7993 | CLSLoss:0.0000 | AUROC:0.9834\n",
      "Test | 122/16 | Loss:0.4921 | MainLoss:0.4921 | SPLoss:1.7993 | CLSLoss:0.0000 | AUROC:0.9084\n",
      "\n",
      "Epoch: [422 | 1000] LR: 0.001397\n",
      "Train | 16/16 | Loss:0.3707 | MainLoss:0.1908 | Alpha:0.0523 | SPLoss:1.7989 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1699 | MainLoss:0.1699 | SPLoss:1.7994 | CLSLoss:0.0000 | AUROC:0.9836\n",
      "Test | 122/16 | Loss:0.4833 | MainLoss:0.4833 | SPLoss:1.7994 | CLSLoss:0.0000 | AUROC:0.9068\n",
      "\n",
      "Epoch: [423 | 1000] LR: 0.001394\n",
      "Train | 16/16 | Loss:0.3533 | MainLoss:0.1734 | Alpha:0.0498 | SPLoss:1.7991 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1694 | MainLoss:0.1694 | SPLoss:1.7991 | CLSLoss:0.0000 | AUROC:0.9833\n",
      "Test | 122/16 | Loss:0.4910 | MainLoss:0.4910 | SPLoss:1.7991 | CLSLoss:0.0000 | AUROC:0.9071\n",
      "\n",
      "Epoch: [424 | 1000] LR: 0.001391\n",
      "Train | 16/16 | Loss:0.3564 | MainLoss:0.1766 | Alpha:0.0510 | SPLoss:1.7983 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1678 | MainLoss:0.1678 | SPLoss:1.7972 | CLSLoss:0.0000 | AUROC:0.9835\n",
      "Test | 122/16 | Loss:0.4877 | MainLoss:0.4877 | SPLoss:1.7972 | CLSLoss:0.0000 | AUROC:0.9086\n",
      "\n",
      "Epoch: [425 | 1000] LR: 0.001388\n",
      "Train | 16/16 | Loss:0.3590 | MainLoss:0.1793 | Alpha:0.0524 | SPLoss:1.7972 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1656 | MainLoss:0.1656 | SPLoss:1.7959 | CLSLoss:0.0000 | AUROC:0.9835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 122/16 | Loss:0.4974 | MainLoss:0.4974 | SPLoss:1.7959 | CLSLoss:0.0000 | AUROC:0.9089\n",
      "\n",
      "Epoch: [426 | 1000] LR: 0.001386\n",
      "Train | 16/16 | Loss:0.3347 | MainLoss:0.1550 | Alpha:0.0496 | SPLoss:1.7966 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1657 | MainLoss:0.1657 | SPLoss:1.7960 | CLSLoss:0.0000 | AUROC:0.9832\n",
      "Test | 122/16 | Loss:0.5080 | MainLoss:0.5080 | SPLoss:1.7960 | CLSLoss:0.0000 | AUROC:0.9092\n",
      "\n",
      "Epoch: [427 | 1000] LR: 0.001383\n",
      "Train | 16/16 | Loss:0.3454 | MainLoss:0.1657 | Alpha:0.0518 | SPLoss:1.7970 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1706 | MainLoss:0.1706 | SPLoss:1.7971 | CLSLoss:0.0000 | AUROC:0.9834\n",
      "Test | 122/16 | Loss:0.5097 | MainLoss:0.5097 | SPLoss:1.7971 | CLSLoss:0.0000 | AUROC:0.9052\n",
      "\n",
      "Epoch: [428 | 1000] LR: 0.001380\n",
      "Train | 16/16 | Loss:0.3620 | MainLoss:0.1826 | Alpha:0.0507 | SPLoss:1.7950 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1662 | MainLoss:0.1662 | SPLoss:1.7936 | CLSLoss:0.0000 | AUROC:0.9836\n",
      "Test | 122/16 | Loss:0.4989 | MainLoss:0.4989 | SPLoss:1.7936 | CLSLoss:0.0000 | AUROC:0.9091\n",
      "\n",
      "Epoch: [429 | 1000] LR: 0.001377\n",
      "Train | 16/16 | Loss:0.3605 | MainLoss:0.1812 | Alpha:0.0511 | SPLoss:1.7930 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1648 | MainLoss:0.1648 | SPLoss:1.7929 | CLSLoss:0.0000 | AUROC:0.9836\n",
      "Test | 122/16 | Loss:0.4998 | MainLoss:0.4998 | SPLoss:1.7929 | CLSLoss:0.0000 | AUROC:0.9092\n",
      "\n",
      "Epoch: [430 | 1000] LR: 0.001374\n",
      "Train | 16/16 | Loss:0.3575 | MainLoss:0.1780 | Alpha:0.0497 | SPLoss:1.7943 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1675 | MainLoss:0.1675 | SPLoss:1.7946 | CLSLoss:0.0000 | AUROC:0.9836\n",
      "Test | 122/16 | Loss:0.4941 | MainLoss:0.4941 | SPLoss:1.7946 | CLSLoss:0.0000 | AUROC:0.9081\n",
      "\n",
      "Epoch: [431 | 1000] LR: 0.001371\n",
      "Train | 16/16 | Loss:0.3461 | MainLoss:0.1666 | Alpha:0.0512 | SPLoss:1.7944 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1659 | MainLoss:0.1659 | SPLoss:1.7937 | CLSLoss:0.0000 | AUROC:0.9835\n",
      "Test | 122/16 | Loss:0.5012 | MainLoss:0.5012 | SPLoss:1.7937 | CLSLoss:0.0000 | AUROC:0.9082\n",
      "\n",
      "Epoch: [432 | 1000] LR: 0.001368\n",
      "Train | 16/16 | Loss:0.3482 | MainLoss:0.1689 | Alpha:0.0502 | SPLoss:1.7939 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7923 | CLSLoss:0.0000 | AUROC:0.9836\n",
      "Test | 122/16 | Loss:0.4989 | MainLoss:0.4989 | SPLoss:1.7923 | CLSLoss:0.0000 | AUROC:0.9096\n",
      "\n",
      "Epoch: [433 | 1000] LR: 0.001365\n",
      "Train | 16/16 | Loss:0.3578 | MainLoss:0.1785 | Alpha:0.0508 | SPLoss:1.7925 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1669 | MainLoss:0.1669 | SPLoss:1.7929 | CLSLoss:0.0000 | AUROC:0.9837\n",
      "Test | 122/16 | Loss:0.4845 | MainLoss:0.4845 | SPLoss:1.7929 | CLSLoss:0.0000 | AUROC:0.9087\n",
      "\n",
      "Epoch: [434 | 1000] LR: 0.001362\n",
      "Train | 16/16 | Loss:0.3590 | MainLoss:0.1797 | Alpha:0.0524 | SPLoss:1.7931 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1665 | MainLoss:0.1665 | SPLoss:1.7927 | CLSLoss:0.0000 | AUROC:0.9834\n",
      "Test | 122/16 | Loss:0.4867 | MainLoss:0.4867 | SPLoss:1.7927 | CLSLoss:0.0000 | AUROC:0.9084\n",
      "\n",
      "Epoch: [435 | 1000] LR: 0.001359\n",
      "Train | 16/16 | Loss:0.3392 | MainLoss:0.1599 | Alpha:0.0510 | SPLoss:1.7930 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1654 | MainLoss:0.1654 | SPLoss:1.7923 | CLSLoss:0.0000 | AUROC:0.9832\n",
      "Test | 122/16 | Loss:0.4940 | MainLoss:0.4940 | SPLoss:1.7923 | CLSLoss:0.0000 | AUROC:0.9095\n",
      "\n",
      "Epoch: [436 | 1000] LR: 0.001356\n",
      "Train | 16/16 | Loss:0.3461 | MainLoss:0.1669 | Alpha:0.0522 | SPLoss:1.7923 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1653 | MainLoss:0.1653 | SPLoss:1.7921 | CLSLoss:0.0000 | AUROC:0.9835\n",
      "Test | 122/16 | Loss:0.4998 | MainLoss:0.4998 | SPLoss:1.7921 | CLSLoss:0.0000 | AUROC:0.9094\n",
      "\n",
      "Epoch: [437 | 1000] LR: 0.001353\n",
      "Train | 16/16 | Loss:0.3666 | MainLoss:0.1874 | Alpha:0.0518 | SPLoss:1.7922 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1662 | MainLoss:0.1662 | SPLoss:1.7909 | CLSLoss:0.0000 | AUROC:0.9836\n",
      "Test | 122/16 | Loss:0.4839 | MainLoss:0.4839 | SPLoss:1.7909 | CLSLoss:0.0000 | AUROC:0.9100\n",
      "\n",
      "Epoch: [438 | 1000] LR: 0.001351\n",
      "Train | 16/16 | Loss:0.3446 | MainLoss:0.1655 | Alpha:0.0507 | SPLoss:1.7912 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1734 | MainLoss:0.1734 | SPLoss:1.7910 | CLSLoss:0.0000 | AUROC:0.9833\n",
      "Test | 122/16 | Loss:0.4781 | MainLoss:0.4781 | SPLoss:1.7910 | CLSLoss:0.0000 | AUROC:0.9071\n",
      "\n",
      "Epoch: [439 | 1000] LR: 0.001348\n",
      "Train | 16/16 | Loss:0.3633 | MainLoss:0.1843 | Alpha:0.0539 | SPLoss:1.7900 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1620 | MainLoss:0.1620 | SPLoss:1.7894 | CLSLoss:0.0000 | AUROC:0.9834\n",
      "Test | 122/16 | Loss:0.5108 | MainLoss:0.5108 | SPLoss:1.7894 | CLSLoss:0.0000 | AUROC:0.9115\n",
      "\n",
      "Epoch: [440 | 1000] LR: 0.001345\n",
      "Train | 16/16 | Loss:0.3608 | MainLoss:0.1819 | Alpha:0.0494 | SPLoss:1.7895 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1670 | MainLoss:0.1670 | SPLoss:1.7901 | CLSLoss:0.0000 | AUROC:0.9837\n",
      "Test | 122/16 | Loss:0.4895 | MainLoss:0.4895 | SPLoss:1.7901 | CLSLoss:0.0000 | AUROC:0.9069\n",
      "\n",
      "Epoch: [441 | 1000] LR: 0.001342\n",
      "Train | 16/16 | Loss:0.3664 | MainLoss:0.1875 | Alpha:0.0524 | SPLoss:1.7896 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1650 | MainLoss:0.1650 | SPLoss:1.7888 | CLSLoss:0.0000 | AUROC:0.9835\n",
      "Test | 122/16 | Loss:0.4879 | MainLoss:0.4879 | SPLoss:1.7888 | CLSLoss:0.0000 | AUROC:0.9086\n",
      "\n",
      "Epoch: [442 | 1000] LR: 0.001339\n",
      "Train | 16/16 | Loss:0.3581 | MainLoss:0.1793 | Alpha:0.0524 | SPLoss:1.7887 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1634 | MainLoss:0.1634 | SPLoss:1.7880 | CLSLoss:0.0000 | AUROC:0.9837\n",
      "Test | 122/16 | Loss:0.4950 | MainLoss:0.4950 | SPLoss:1.7880 | CLSLoss:0.0000 | AUROC:0.9097\n",
      "\n",
      "Epoch: [443 | 1000] LR: 0.001336\n",
      "Train | 16/16 | Loss:0.3599 | MainLoss:0.1811 | Alpha:0.0520 | SPLoss:1.7878 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1699 | MainLoss:0.1699 | SPLoss:1.7878 | CLSLoss:0.0000 | AUROC:0.9838\n",
      "Test | 122/16 | Loss:0.4764 | MainLoss:0.4764 | SPLoss:1.7878 | CLSLoss:0.0000 | AUROC:0.9080\n",
      "\n",
      "Epoch: [444 | 1000] LR: 0.001333\n",
      "Train | 16/16 | Loss:0.3643 | MainLoss:0.1855 | Alpha:0.0510 | SPLoss:1.7876 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1672 | MainLoss:0.1672 | SPLoss:1.7881 | CLSLoss:0.0000 | AUROC:0.9841\n",
      "Test | 122/16 | Loss:0.4827 | MainLoss:0.4827 | SPLoss:1.7881 | CLSLoss:0.0000 | AUROC:0.9079\n",
      "\n",
      "Epoch: [445 | 1000] LR: 0.001330\n",
      "Train | 16/16 | Loss:0.3628 | MainLoss:0.1839 | Alpha:0.0512 | SPLoss:1.7888 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1633 | MainLoss:0.1633 | SPLoss:1.7896 | CLSLoss:0.0000 | AUROC:0.9840\n",
      "Test | 122/16 | Loss:0.4985 | MainLoss:0.4985 | SPLoss:1.7896 | CLSLoss:0.0000 | AUROC:0.9073\n",
      "\n",
      "Epoch: [446 | 1000] LR: 0.001327\n",
      "Train | 16/16 | Loss:0.3709 | MainLoss:0.1918 | Alpha:0.0523 | SPLoss:1.7902 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1700 | MainLoss:0.1700 | SPLoss:1.7909 | CLSLoss:0.0000 | AUROC:0.9837\n",
      "Test | 122/16 | Loss:0.4862 | MainLoss:0.4862 | SPLoss:1.7909 | CLSLoss:0.0000 | AUROC:0.9030\n",
      "\n",
      "Epoch: [447 | 1000] LR: 0.001324\n",
      "Train | 16/16 | Loss:0.3575 | MainLoss:0.1785 | Alpha:0.0529 | SPLoss:1.7899 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1635 | MainLoss:0.1635 | SPLoss:1.7886 | CLSLoss:0.0000 | AUROC:0.9838\n",
      "Test | 122/16 | Loss:0.4974 | MainLoss:0.4974 | SPLoss:1.7886 | CLSLoss:0.0000 | AUROC:0.9074\n",
      "\n",
      "Epoch: [448 | 1000] LR: 0.001321\n",
      "Train | 16/16 | Loss:0.3527 | MainLoss:0.1739 | Alpha:0.0519 | SPLoss:1.7879 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1646 | MainLoss:0.1646 | SPLoss:1.7875 | CLSLoss:0.0000 | AUROC:0.9836\n",
      "Test | 122/16 | Loss:0.4991 | MainLoss:0.4991 | SPLoss:1.7875 | CLSLoss:0.0000 | AUROC:0.9071\n",
      "\n",
      "Epoch: [449 | 1000] LR: 0.001318\n",
      "Train | 16/16 | Loss:0.3392 | MainLoss:0.1604 | Alpha:0.0531 | SPLoss:1.7884 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1674 | MainLoss:0.1674 | SPLoss:1.7888 | CLSLoss:0.0000 | AUROC:0.9837\n",
      "Test | 122/16 | Loss:0.5054 | MainLoss:0.5054 | SPLoss:1.7888 | CLSLoss:0.0000 | AUROC:0.9054\n",
      "\n",
      "Epoch: [450 | 1000] LR: 0.001315\n",
      "Train | 16/16 | Loss:0.3394 | MainLoss:0.1606 | Alpha:0.0498 | SPLoss:1.7882 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1697 | MainLoss:0.1697 | SPLoss:1.7877 | CLSLoss:0.0000 | AUROC:0.9840\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 122/16 | Loss:0.4987 | MainLoss:0.4987 | SPLoss:1.7877 | CLSLoss:0.0000 | AUROC:0.9061\n",
      "\n",
      "Epoch: [451 | 1000] LR: 0.001312\n",
      "Train | 16/16 | Loss:0.3458 | MainLoss:0.1670 | Alpha:0.0512 | SPLoss:1.7874 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1651 | MainLoss:0.1651 | SPLoss:1.7860 | CLSLoss:0.0000 | AUROC:0.9839\n",
      "Test | 122/16 | Loss:0.5078 | MainLoss:0.5078 | SPLoss:1.7860 | CLSLoss:0.0000 | AUROC:0.9073\n",
      "\n",
      "Epoch: [452 | 1000] LR: 0.001309\n",
      "Train | 16/16 | Loss:0.3453 | MainLoss:0.1668 | Alpha:0.0497 | SPLoss:1.7856 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1681 | MainLoss:0.1681 | SPLoss:1.7848 | CLSLoss:0.0000 | AUROC:0.9838\n",
      "Test | 122/16 | Loss:0.4943 | MainLoss:0.4943 | SPLoss:1.7848 | CLSLoss:0.0000 | AUROC:0.9072\n",
      "\n",
      "Epoch: [453 | 1000] LR: 0.001306\n",
      "Train | 16/16 | Loss:0.3428 | MainLoss:0.1644 | Alpha:0.0482 | SPLoss:1.7841 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1679 | MainLoss:0.1679 | SPLoss:1.7835 | CLSLoss:0.0000 | AUROC:0.9837\n",
      "Test | 122/16 | Loss:0.4902 | MainLoss:0.4902 | SPLoss:1.7835 | CLSLoss:0.0000 | AUROC:0.9095\n",
      "\n",
      "Epoch: [454 | 1000] LR: 0.001303\n",
      "Train | 16/16 | Loss:0.3370 | MainLoss:0.1586 | Alpha:0.0520 | SPLoss:1.7835 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1652 | MainLoss:0.1652 | SPLoss:1.7830 | CLSLoss:0.0000 | AUROC:0.9839\n",
      "Test | 122/16 | Loss:0.5037 | MainLoss:0.5037 | SPLoss:1.7830 | CLSLoss:0.0000 | AUROC:0.9109\n",
      "\n",
      "Epoch: [455 | 1000] LR: 0.001300\n",
      "Train | 16/16 | Loss:0.3573 | MainLoss:0.1789 | Alpha:0.0526 | SPLoss:1.7833 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1639 | MainLoss:0.1639 | SPLoss:1.7823 | CLSLoss:0.0000 | AUROC:0.9838\n",
      "Test | 122/16 | Loss:0.5009 | MainLoss:0.5009 | SPLoss:1.7823 | CLSLoss:0.0000 | AUROC:0.9109\n",
      "\n",
      "Epoch: [456 | 1000] LR: 0.001297\n",
      "Train | 16/16 | Loss:0.3434 | MainLoss:0.1652 | Alpha:0.0525 | SPLoss:1.7821 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1647 | MainLoss:0.1647 | SPLoss:1.7819 | CLSLoss:0.0000 | AUROC:0.9837\n",
      "Test | 122/16 | Loss:0.5008 | MainLoss:0.5008 | SPLoss:1.7819 | CLSLoss:0.0000 | AUROC:0.9101\n",
      "\n",
      "Epoch: [457 | 1000] LR: 0.001294\n",
      "Train | 16/16 | Loss:0.3417 | MainLoss:0.1635 | Alpha:0.0513 | SPLoss:1.7820 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1677 | MainLoss:0.1677 | SPLoss:1.7820 | CLSLoss:0.0000 | AUROC:0.9838\n",
      "Test | 122/16 | Loss:0.4959 | MainLoss:0.4959 | SPLoss:1.7820 | CLSLoss:0.0000 | AUROC:0.9082\n",
      "\n",
      "Epoch: [458 | 1000] LR: 0.001291\n",
      "Train | 16/16 | Loss:0.3578 | MainLoss:0.1795 | Alpha:0.0512 | SPLoss:1.7828 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1644 | MainLoss:0.1644 | SPLoss:1.7822 | CLSLoss:0.0000 | AUROC:0.9836\n",
      "Test | 122/16 | Loss:0.5059 | MainLoss:0.5059 | SPLoss:1.7822 | CLSLoss:0.0000 | AUROC:0.9077\n",
      "\n",
      "Epoch: [459 | 1000] LR: 0.001288\n",
      "Train | 16/16 | Loss:0.3442 | MainLoss:0.1659 | Alpha:0.0506 | SPLoss:1.7826 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1715 | MainLoss:0.1715 | SPLoss:1.7832 | CLSLoss:0.0000 | AUROC:0.9835\n",
      "Test | 122/16 | Loss:0.4937 | MainLoss:0.4937 | SPLoss:1.7832 | CLSLoss:0.0000 | AUROC:0.9052\n",
      "\n",
      "Epoch: [460 | 1000] LR: 0.001285\n",
      "Train | 16/16 | Loss:0.3475 | MainLoss:0.1692 | Alpha:0.0517 | SPLoss:1.7825 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1674 | MainLoss:0.1674 | SPLoss:1.7821 | CLSLoss:0.0000 | AUROC:0.9837\n",
      "Test | 122/16 | Loss:0.4961 | MainLoss:0.4961 | SPLoss:1.7821 | CLSLoss:0.0000 | AUROC:0.9068\n",
      "\n",
      "Epoch: [461 | 1000] LR: 0.001282\n",
      "Train | 16/16 | Loss:0.3503 | MainLoss:0.1721 | Alpha:0.0532 | SPLoss:1.7823 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1641 | MainLoss:0.1641 | SPLoss:1.7808 | CLSLoss:0.0000 | AUROC:0.9833\n",
      "Test | 122/16 | Loss:0.5020 | MainLoss:0.5020 | SPLoss:1.7808 | CLSLoss:0.0000 | AUROC:0.9091\n",
      "\n",
      "Epoch: [462 | 1000] LR: 0.001279\n",
      "Train | 16/16 | Loss:0.3553 | MainLoss:0.1772 | Alpha:0.0519 | SPLoss:1.7811 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7818 | CLSLoss:0.0000 | AUROC:0.9836\n",
      "Test | 122/16 | Loss:0.5032 | MainLoss:0.5032 | SPLoss:1.7818 | CLSLoss:0.0000 | AUROC:0.9079\n",
      "\n",
      "Epoch: [463 | 1000] LR: 0.001276\n",
      "Train | 16/16 | Loss:0.3525 | MainLoss:0.1743 | Alpha:0.0516 | SPLoss:1.7821 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1665 | MainLoss:0.1665 | SPLoss:1.7821 | CLSLoss:0.0000 | AUROC:0.9839\n",
      "Test | 122/16 | Loss:0.4991 | MainLoss:0.4991 | SPLoss:1.7821 | CLSLoss:0.0000 | AUROC:0.9059\n",
      "\n",
      "Epoch: [464 | 1000] LR: 0.001273\n",
      "Train | 16/16 | Loss:0.3531 | MainLoss:0.1749 | Alpha:0.0494 | SPLoss:1.7818 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1663 | MainLoss:0.1663 | SPLoss:1.7818 | CLSLoss:0.0000 | AUROC:0.9838\n",
      "Test | 122/16 | Loss:0.4935 | MainLoss:0.4935 | SPLoss:1.7818 | CLSLoss:0.0000 | AUROC:0.9070\n",
      "\n",
      "Epoch: [465 | 1000] LR: 0.001270\n",
      "Train | 16/16 | Loss:0.3447 | MainLoss:0.1665 | Alpha:0.0505 | SPLoss:1.7815 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1657 | MainLoss:0.1657 | SPLoss:1.7807 | CLSLoss:0.0000 | AUROC:0.9840\n",
      "Test | 122/16 | Loss:0.4947 | MainLoss:0.4947 | SPLoss:1.7807 | CLSLoss:0.0000 | AUROC:0.9080\n",
      "\n",
      "Epoch: [466 | 1000] LR: 0.001267\n",
      "Train | 16/16 | Loss:0.3588 | MainLoss:0.1807 | Alpha:0.0512 | SPLoss:1.7807 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1686 | MainLoss:0.1686 | SPLoss:1.7805 | CLSLoss:0.0000 | AUROC:0.9838\n",
      "Test | 122/16 | Loss:0.4817 | MainLoss:0.4817 | SPLoss:1.7805 | CLSLoss:0.0000 | AUROC:0.9076\n",
      "\n",
      "Epoch: [467 | 1000] LR: 0.001264\n",
      "Train | 16/16 | Loss:0.3445 | MainLoss:0.1665 | Alpha:0.0502 | SPLoss:1.7803 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1673 | MainLoss:0.1673 | SPLoss:1.7804 | CLSLoss:0.0000 | AUROC:0.9837\n",
      "Test | 122/16 | Loss:0.4916 | MainLoss:0.4916 | SPLoss:1.7804 | CLSLoss:0.0000 | AUROC:0.9074\n",
      "\n",
      "Epoch: [468 | 1000] LR: 0.001261\n",
      "Train | 16/16 | Loss:0.3509 | MainLoss:0.1729 | Alpha:0.0505 | SPLoss:1.7806 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1685 | MainLoss:0.1685 | SPLoss:1.7806 | CLSLoss:0.0000 | AUROC:0.9838\n",
      "Test | 122/16 | Loss:0.4889 | MainLoss:0.4889 | SPLoss:1.7806 | CLSLoss:0.0000 | AUROC:0.9069\n",
      "\n",
      "Epoch: [469 | 1000] LR: 0.001258\n",
      "Train | 16/16 | Loss:0.3437 | MainLoss:0.1657 | Alpha:0.0506 | SPLoss:1.7799 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1655 | MainLoss:0.1655 | SPLoss:1.7795 | CLSLoss:0.0000 | AUROC:0.9836\n",
      "Test | 122/16 | Loss:0.5019 | MainLoss:0.5019 | SPLoss:1.7795 | CLSLoss:0.0000 | AUROC:0.9095\n",
      "\n",
      "Epoch: [470 | 1000] LR: 0.001255\n",
      "Train | 16/16 | Loss:0.3449 | MainLoss:0.1670 | Alpha:0.0517 | SPLoss:1.7791 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1664 | MainLoss:0.1664 | SPLoss:1.7786 | CLSLoss:0.0000 | AUROC:0.9834\n",
      "Test | 122/16 | Loss:0.4970 | MainLoss:0.4970 | SPLoss:1.7786 | CLSLoss:0.0000 | AUROC:0.9092\n",
      "\n",
      "Epoch: [471 | 1000] LR: 0.001252\n",
      "Train | 16/16 | Loss:0.3414 | MainLoss:0.1635 | Alpha:0.0493 | SPLoss:1.7790 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1707 | MainLoss:0.1707 | SPLoss:1.7783 | CLSLoss:0.0000 | AUROC:0.9839\n",
      "Test | 122/16 | Loss:0.4895 | MainLoss:0.4895 | SPLoss:1.7783 | CLSLoss:0.0000 | AUROC:0.9077\n",
      "\n",
      "Epoch: [472 | 1000] LR: 0.001249\n",
      "Train | 16/16 | Loss:0.3633 | MainLoss:0.1855 | Alpha:0.0512 | SPLoss:1.7781 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1683 | MainLoss:0.1683 | SPLoss:1.7779 | CLSLoss:0.0000 | AUROC:0.9837\n",
      "Test | 122/16 | Loss:0.4823 | MainLoss:0.4823 | SPLoss:1.7779 | CLSLoss:0.0000 | AUROC:0.9086\n",
      "\n",
      "Epoch: [473 | 1000] LR: 0.001246\n",
      "Train | 16/16 | Loss:0.3425 | MainLoss:0.1648 | Alpha:0.0497 | SPLoss:1.7771 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1705 | MainLoss:0.1705 | SPLoss:1.7781 | CLSLoss:0.0000 | AUROC:0.9841\n",
      "Test | 122/16 | Loss:0.4873 | MainLoss:0.4873 | SPLoss:1.7781 | CLSLoss:0.0000 | AUROC:0.9061\n",
      "\n",
      "Epoch: [474 | 1000] LR: 0.001243\n",
      "Train | 16/16 | Loss:0.3594 | MainLoss:0.1817 | Alpha:0.0506 | SPLoss:1.7772 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1661 | MainLoss:0.1661 | SPLoss:1.7769 | CLSLoss:0.0000 | AUROC:0.9840\n",
      "Test | 122/16 | Loss:0.4918 | MainLoss:0.4918 | SPLoss:1.7769 | CLSLoss:0.0000 | AUROC:0.9074\n",
      "\n",
      "Epoch: [475 | 1000] LR: 0.001240\n",
      "Train | 16/16 | Loss:0.3541 | MainLoss:0.1764 | Alpha:0.0512 | SPLoss:1.7768 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1658 | MainLoss:0.1658 | SPLoss:1.7769 | CLSLoss:0.0000 | AUROC:0.9839\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 122/16 | Loss:0.4904 | MainLoss:0.4904 | SPLoss:1.7769 | CLSLoss:0.0000 | AUROC:0.9081\n",
      "\n",
      "Epoch: [476 | 1000] LR: 0.001236\n",
      "Train | 16/16 | Loss:0.3483 | MainLoss:0.1705 | Alpha:0.0499 | SPLoss:1.7776 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1700 | MainLoss:0.1700 | SPLoss:1.7784 | CLSLoss:0.0000 | AUROC:0.9840\n",
      "Test | 122/16 | Loss:0.4857 | MainLoss:0.4857 | SPLoss:1.7784 | CLSLoss:0.0000 | AUROC:0.9058\n",
      "\n",
      "Epoch: [477 | 1000] LR: 0.001233\n",
      "Train | 16/16 | Loss:0.3609 | MainLoss:0.1831 | Alpha:0.0497 | SPLoss:1.7781 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1610 | MainLoss:0.1610 | SPLoss:1.7771 | CLSLoss:0.0000 | AUROC:0.9840\n",
      "Test | 122/16 | Loss:0.5072 | MainLoss:0.5072 | SPLoss:1.7771 | CLSLoss:0.0000 | AUROC:0.9096\n",
      "\n",
      "Epoch: [478 | 1000] LR: 0.001230\n",
      "Train | 16/16 | Loss:0.3426 | MainLoss:0.1648 | Alpha:0.0481 | SPLoss:1.7783 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1716 | MainLoss:0.1716 | SPLoss:1.7796 | CLSLoss:0.0000 | AUROC:0.9840\n",
      "Test | 122/16 | Loss:0.4914 | MainLoss:0.4914 | SPLoss:1.7796 | CLSLoss:0.0000 | AUROC:0.9047\n",
      "\n",
      "Epoch: [479 | 1000] LR: 0.001227\n",
      "Train | 16/16 | Loss:0.3384 | MainLoss:0.1606 | Alpha:0.0499 | SPLoss:1.7786 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1661 | MainLoss:0.1661 | SPLoss:1.7771 | CLSLoss:0.0000 | AUROC:0.9841\n",
      "Test | 122/16 | Loss:0.4947 | MainLoss:0.4947 | SPLoss:1.7771 | CLSLoss:0.0000 | AUROC:0.9096\n",
      "\n",
      "Epoch: [480 | 1000] LR: 0.001224\n",
      "Train | 16/16 | Loss:0.3465 | MainLoss:0.1688 | Alpha:0.0519 | SPLoss:1.7769 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1665 | MainLoss:0.1665 | SPLoss:1.7771 | CLSLoss:0.0000 | AUROC:0.9840\n",
      "Test | 122/16 | Loss:0.5003 | MainLoss:0.5003 | SPLoss:1.7771 | CLSLoss:0.0000 | AUROC:0.9080\n",
      "\n",
      "Epoch: [481 | 1000] LR: 0.001221\n",
      "Train | 16/16 | Loss:0.3576 | MainLoss:0.1799 | Alpha:0.0513 | SPLoss:1.7771 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1661 | MainLoss:0.1661 | SPLoss:1.7775 | CLSLoss:0.0000 | AUROC:0.9840\n",
      "Test | 122/16 | Loss:0.4999 | MainLoss:0.4999 | SPLoss:1.7775 | CLSLoss:0.0000 | AUROC:0.9067\n",
      "\n",
      "Epoch: [482 | 1000] LR: 0.001218\n",
      "Train | 16/16 | Loss:0.3589 | MainLoss:0.1811 | Alpha:0.0525 | SPLoss:1.7773 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1673 | MainLoss:0.1673 | SPLoss:1.7768 | CLSLoss:0.0000 | AUROC:0.9838\n",
      "Test | 122/16 | Loss:0.4870 | MainLoss:0.4870 | SPLoss:1.7768 | CLSLoss:0.0000 | AUROC:0.9067\n",
      "\n",
      "Epoch: [483 | 1000] LR: 0.001215\n",
      "Train | 16/16 | Loss:0.3274 | MainLoss:0.1497 | Alpha:0.0510 | SPLoss:1.7769 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1691 | MainLoss:0.1691 | SPLoss:1.7767 | CLSLoss:0.0000 | AUROC:0.9838\n",
      "Test | 122/16 | Loss:0.4923 | MainLoss:0.4923 | SPLoss:1.7767 | CLSLoss:0.0000 | AUROC:0.9076\n",
      "\n",
      "Epoch: [484 | 1000] LR: 0.001212\n",
      "Train | 16/16 | Loss:0.3483 | MainLoss:0.1706 | Alpha:0.0508 | SPLoss:1.7768 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1666 | MainLoss:0.1666 | SPLoss:1.7774 | CLSLoss:0.0000 | AUROC:0.9839\n",
      "Test | 122/16 | Loss:0.5021 | MainLoss:0.5021 | SPLoss:1.7774 | CLSLoss:0.0000 | AUROC:0.9069\n",
      "\n",
      "Epoch: [485 | 1000] LR: 0.001209\n",
      "Train | 16/16 | Loss:0.3564 | MainLoss:0.1786 | Alpha:0.0511 | SPLoss:1.7776 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1702 | MainLoss:0.1702 | SPLoss:1.7787 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.4952 | MainLoss:0.4952 | SPLoss:1.7787 | CLSLoss:0.0000 | AUROC:0.9044\n",
      "\n",
      "Epoch: [486 | 1000] LR: 0.001206\n",
      "Train | 16/16 | Loss:0.3484 | MainLoss:0.1706 | Alpha:0.0511 | SPLoss:1.7780 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1632 | MainLoss:0.1632 | SPLoss:1.7769 | CLSLoss:0.0000 | AUROC:0.9839\n",
      "Test | 122/16 | Loss:0.5040 | MainLoss:0.5040 | SPLoss:1.7769 | CLSLoss:0.0000 | AUROC:0.9092\n",
      "\n",
      "Epoch: [487 | 1000] LR: 0.001203\n",
      "Train | 16/16 | Loss:0.3495 | MainLoss:0.1717 | Alpha:0.0507 | SPLoss:1.7779 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1643 | MainLoss:0.1643 | SPLoss:1.7772 | CLSLoss:0.0000 | AUROC:0.9839\n",
      "Test | 122/16 | Loss:0.5079 | MainLoss:0.5079 | SPLoss:1.7772 | CLSLoss:0.0000 | AUROC:0.9066\n",
      "\n",
      "Epoch: [488 | 1000] LR: 0.001200\n",
      "Train | 16/16 | Loss:0.3538 | MainLoss:0.1762 | Alpha:0.0517 | SPLoss:1.7764 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1680 | MainLoss:0.1680 | SPLoss:1.7762 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.4889 | MainLoss:0.4889 | SPLoss:1.7762 | CLSLoss:0.0000 | AUROC:0.9062\n",
      "\n",
      "Epoch: [489 | 1000] LR: 0.001197\n",
      "Train | 16/16 | Loss:0.3523 | MainLoss:0.1747 | Alpha:0.0504 | SPLoss:1.7763 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1656 | MainLoss:0.1656 | SPLoss:1.7762 | CLSLoss:0.0000 | AUROC:0.9837\n",
      "Test | 122/16 | Loss:0.4957 | MainLoss:0.4957 | SPLoss:1.7762 | CLSLoss:0.0000 | AUROC:0.9053\n",
      "\n",
      "Epoch: [490 | 1000] LR: 0.001194\n",
      "Train | 16/16 | Loss:0.3528 | MainLoss:0.1752 | Alpha:0.0519 | SPLoss:1.7765 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1630 | MainLoss:0.1630 | SPLoss:1.7764 | CLSLoss:0.0000 | AUROC:0.9840\n",
      "Test | 122/16 | Loss:0.5071 | MainLoss:0.5071 | SPLoss:1.7763 | CLSLoss:0.0000 | AUROC:0.9056\n",
      "\n",
      "Epoch: [491 | 1000] LR: 0.001190\n",
      "Train | 16/16 | Loss:0.3421 | MainLoss:0.1644 | Alpha:0.0487 | SPLoss:1.7768 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1708 | MainLoss:0.1708 | SPLoss:1.7771 | CLSLoss:0.0000 | AUROC:0.9838\n",
      "Test | 122/16 | Loss:0.4944 | MainLoss:0.4944 | SPLoss:1.7771 | CLSLoss:0.0000 | AUROC:0.9039\n",
      "\n",
      "Epoch: [492 | 1000] LR: 0.001187\n",
      "Train | 16/16 | Loss:0.3431 | MainLoss:0.1654 | Alpha:0.0521 | SPLoss:1.7767 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1656 | MainLoss:0.1656 | SPLoss:1.7768 | CLSLoss:0.0000 | AUROC:0.9841\n",
      "Test | 122/16 | Loss:0.5087 | MainLoss:0.5087 | SPLoss:1.7768 | CLSLoss:0.0000 | AUROC:0.9047\n",
      "\n",
      "Epoch: [493 | 1000] LR: 0.001184\n",
      "Train | 16/16 | Loss:0.3563 | MainLoss:0.1786 | Alpha:0.0496 | SPLoss:1.7763 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1677 | MainLoss:0.1677 | SPLoss:1.7765 | CLSLoss:0.0000 | AUROC:0.9844\n",
      "Test | 122/16 | Loss:0.4990 | MainLoss:0.4990 | SPLoss:1.7765 | CLSLoss:0.0000 | AUROC:0.9037\n",
      "\n",
      "Epoch: [494 | 1000] LR: 0.001181\n",
      "Train | 16/16 | Loss:0.3576 | MainLoss:0.1800 | Alpha:0.0510 | SPLoss:1.7761 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1642 | MainLoss:0.1642 | SPLoss:1.7760 | CLSLoss:0.0000 | AUROC:0.9841\n",
      "Test | 122/16 | Loss:0.5079 | MainLoss:0.5079 | SPLoss:1.7760 | CLSLoss:0.0000 | AUROC:0.9057\n",
      "\n",
      "Epoch: [495 | 1000] LR: 0.001178\n",
      "Train | 16/16 | Loss:0.3422 | MainLoss:0.1646 | Alpha:0.0507 | SPLoss:1.7757 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1638 | MainLoss:0.1638 | SPLoss:1.7752 | CLSLoss:0.0000 | AUROC:0.9839\n",
      "Test | 122/16 | Loss:0.5121 | MainLoss:0.5121 | SPLoss:1.7752 | CLSLoss:0.0000 | AUROC:0.9062\n",
      "\n",
      "Epoch: [496 | 1000] LR: 0.001175\n",
      "Train | 16/16 | Loss:0.3474 | MainLoss:0.1699 | Alpha:0.0500 | SPLoss:1.7755 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1646 | MainLoss:0.1646 | SPLoss:1.7756 | CLSLoss:0.0000 | AUROC:0.9841\n",
      "Test | 122/16 | Loss:0.5106 | MainLoss:0.5106 | SPLoss:1.7756 | CLSLoss:0.0000 | AUROC:0.9059\n",
      "\n",
      "Epoch: [497 | 1000] LR: 0.001172\n",
      "Train | 16/16 | Loss:0.3592 | MainLoss:0.1817 | Alpha:0.0502 | SPLoss:1.7746 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1666 | MainLoss:0.1666 | SPLoss:1.7744 | CLSLoss:0.0000 | AUROC:0.9839\n",
      "Test | 122/16 | Loss:0.5012 | MainLoss:0.5012 | SPLoss:1.7744 | CLSLoss:0.0000 | AUROC:0.9054\n",
      "\n",
      "Epoch: [498 | 1000] LR: 0.001169\n",
      "Train | 16/16 | Loss:0.3591 | MainLoss:0.1816 | Alpha:0.0497 | SPLoss:1.7745 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1639 | MainLoss:0.1639 | SPLoss:1.7740 | CLSLoss:0.0000 | AUROC:0.9839\n",
      "Test | 122/16 | Loss:0.5048 | MainLoss:0.5048 | SPLoss:1.7740 | CLSLoss:0.0000 | AUROC:0.9070\n",
      "\n",
      "Epoch: [499 | 1000] LR: 0.001166\n",
      "Train | 16/16 | Loss:0.3440 | MainLoss:0.1666 | Alpha:0.0522 | SPLoss:1.7737 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7726 | CLSLoss:0.0000 | AUROC:0.9839\n",
      "Test | 122/16 | Loss:0.4985 | MainLoss:0.4985 | SPLoss:1.7726 | CLSLoss:0.0000 | AUROC:0.9084\n",
      "\n",
      "Epoch: [500 | 1000] LR: 0.001163\n",
      "Train | 16/16 | Loss:0.3517 | MainLoss:0.1745 | Alpha:0.0510 | SPLoss:1.7722 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1618 | MainLoss:0.1618 | SPLoss:1.7713 | CLSLoss:0.0000 | AUROC:0.9839\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 122/16 | Loss:0.5025 | MainLoss:0.5025 | SPLoss:1.7713 | CLSLoss:0.0000 | AUROC:0.9109\n",
      "\n",
      "Epoch: [501 | 1000] LR: 0.001160\n",
      "Train | 16/16 | Loss:0.3454 | MainLoss:0.1682 | Alpha:0.0501 | SPLoss:1.7719 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1681 | MainLoss:0.1681 | SPLoss:1.7714 | CLSLoss:0.0000 | AUROC:0.9840\n",
      "Test | 122/16 | Loss:0.4869 | MainLoss:0.4869 | SPLoss:1.7714 | CLSLoss:0.0000 | AUROC:0.9073\n",
      "\n",
      "Epoch: [502 | 1000] LR: 0.001156\n",
      "Train | 16/16 | Loss:0.3340 | MainLoss:0.1569 | Alpha:0.0530 | SPLoss:1.7711 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1670 | MainLoss:0.1670 | SPLoss:1.7702 | CLSLoss:0.0000 | AUROC:0.9839\n",
      "Test | 122/16 | Loss:0.4919 | MainLoss:0.4919 | SPLoss:1.7702 | CLSLoss:0.0000 | AUROC:0.9100\n",
      "\n",
      "Epoch: [503 | 1000] LR: 0.001153\n",
      "Train | 16/16 | Loss:0.3282 | MainLoss:0.1512 | Alpha:0.0499 | SPLoss:1.7702 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1688 | MainLoss:0.1688 | SPLoss:1.7712 | CLSLoss:0.0000 | AUROC:0.9838\n",
      "Test | 122/16 | Loss:0.5032 | MainLoss:0.5032 | SPLoss:1.7712 | CLSLoss:0.0000 | AUROC:0.9089\n",
      "\n",
      "Epoch: [504 | 1000] LR: 0.001150\n",
      "Train | 16/16 | Loss:0.3299 | MainLoss:0.1528 | Alpha:0.0517 | SPLoss:1.7708 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1674 | MainLoss:0.1674 | SPLoss:1.7710 | CLSLoss:0.0000 | AUROC:0.9835\n",
      "Test | 122/16 | Loss:0.5106 | MainLoss:0.5106 | SPLoss:1.7710 | CLSLoss:0.0000 | AUROC:0.9101\n",
      "\n",
      "Epoch: [505 | 1000] LR: 0.001147\n",
      "Train | 16/16 | Loss:0.3536 | MainLoss:0.1765 | Alpha:0.0509 | SPLoss:1.7707 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1649 | MainLoss:0.1649 | SPLoss:1.7699 | CLSLoss:0.0000 | AUROC:0.9837\n",
      "Test | 122/16 | Loss:0.5115 | MainLoss:0.5115 | SPLoss:1.7699 | CLSLoss:0.0000 | AUROC:0.9099\n",
      "\n",
      "Epoch: [506 | 1000] LR: 0.001144\n",
      "Train | 16/16 | Loss:0.3508 | MainLoss:0.1738 | Alpha:0.0506 | SPLoss:1.7702 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1697 | MainLoss:0.1697 | SPLoss:1.7697 | CLSLoss:0.0000 | AUROC:0.9837\n",
      "Test | 122/16 | Loss:0.4922 | MainLoss:0.4922 | SPLoss:1.7697 | CLSLoss:0.0000 | AUROC:0.9080\n",
      "\n",
      "Epoch: [507 | 1000] LR: 0.001141\n",
      "Train | 16/16 | Loss:0.3392 | MainLoss:0.1621 | Alpha:0.0516 | SPLoss:1.7701 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1654 | MainLoss:0.1654 | SPLoss:1.7691 | CLSLoss:0.0000 | AUROC:0.9837\n",
      "Test | 122/16 | Loss:0.5056 | MainLoss:0.5056 | SPLoss:1.7691 | CLSLoss:0.0000 | AUROC:0.9085\n",
      "\n",
      "Epoch: [508 | 1000] LR: 0.001138\n",
      "Train | 16/16 | Loss:0.3658 | MainLoss:0.1889 | Alpha:0.0493 | SPLoss:1.7693 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1628 | MainLoss:0.1628 | SPLoss:1.7685 | CLSLoss:0.0000 | AUROC:0.9838\n",
      "Test | 122/16 | Loss:0.5009 | MainLoss:0.5009 | SPLoss:1.7685 | CLSLoss:0.0000 | AUROC:0.9098\n",
      "\n",
      "Epoch: [509 | 1000] LR: 0.001135\n",
      "Train | 16/16 | Loss:0.3618 | MainLoss:0.1849 | Alpha:0.0495 | SPLoss:1.7691 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1659 | MainLoss:0.1659 | SPLoss:1.7694 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.4863 | MainLoss:0.4863 | SPLoss:1.7694 | CLSLoss:0.0000 | AUROC:0.9071\n",
      "\n",
      "Epoch: [510 | 1000] LR: 0.001132\n",
      "Train | 16/16 | Loss:0.3462 | MainLoss:0.1692 | Alpha:0.0528 | SPLoss:1.7700 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1674 | MainLoss:0.1674 | SPLoss:1.7702 | CLSLoss:0.0000 | AUROC:0.9839\n",
      "Test | 122/16 | Loss:0.4900 | MainLoss:0.4900 | SPLoss:1.7702 | CLSLoss:0.0000 | AUROC:0.9066\n",
      "\n",
      "Epoch: [511 | 1000] LR: 0.001128\n",
      "Train | 16/16 | Loss:0.3720 | MainLoss:0.1950 | Alpha:0.0504 | SPLoss:1.7703 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1636 | MainLoss:0.1636 | SPLoss:1.7699 | CLSLoss:0.0000 | AUROC:0.9841\n",
      "Test | 122/16 | Loss:0.4974 | MainLoss:0.4974 | SPLoss:1.7699 | CLSLoss:0.0000 | AUROC:0.9058\n",
      "\n",
      "Epoch: [512 | 1000] LR: 0.001125\n",
      "Train | 16/16 | Loss:0.3640 | MainLoss:0.1870 | Alpha:0.0538 | SPLoss:1.7701 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1665 | MainLoss:0.1665 | SPLoss:1.7710 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.4956 | MainLoss:0.4956 | SPLoss:1.7710 | CLSLoss:0.0000 | AUROC:0.9035\n",
      "\n",
      "Epoch: [513 | 1000] LR: 0.001122\n",
      "Train | 16/16 | Loss:0.3503 | MainLoss:0.1732 | Alpha:0.0511 | SPLoss:1.7707 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1628 | MainLoss:0.1628 | SPLoss:1.7695 | CLSLoss:0.0000 | AUROC:0.9836\n",
      "Test | 122/16 | Loss:0.5096 | MainLoss:0.5096 | SPLoss:1.7695 | CLSLoss:0.0000 | AUROC:0.9065\n",
      "\n",
      "Epoch: [514 | 1000] LR: 0.001119\n",
      "Train | 16/16 | Loss:0.3478 | MainLoss:0.1708 | Alpha:0.0524 | SPLoss:1.7697 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1664 | MainLoss:0.1664 | SPLoss:1.7695 | CLSLoss:0.0000 | AUROC:0.9840\n",
      "Test | 122/16 | Loss:0.5025 | MainLoss:0.5025 | SPLoss:1.7695 | CLSLoss:0.0000 | AUROC:0.9051\n",
      "\n",
      "Epoch: [515 | 1000] LR: 0.001116\n",
      "Train | 16/16 | Loss:0.3591 | MainLoss:0.1822 | Alpha:0.0519 | SPLoss:1.7692 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1632 | MainLoss:0.1632 | SPLoss:1.7689 | CLSLoss:0.0000 | AUROC:0.9841\n",
      "Test | 122/16 | Loss:0.5070 | MainLoss:0.5070 | SPLoss:1.7689 | CLSLoss:0.0000 | AUROC:0.9066\n",
      "\n",
      "Epoch: [516 | 1000] LR: 0.001113\n",
      "Train | 16/16 | Loss:0.3455 | MainLoss:0.1686 | Alpha:0.0521 | SPLoss:1.7692 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1652 | MainLoss:0.1652 | SPLoss:1.7690 | CLSLoss:0.0000 | AUROC:0.9843\n",
      "Test | 122/16 | Loss:0.5047 | MainLoss:0.5047 | SPLoss:1.7690 | CLSLoss:0.0000 | AUROC:0.9052\n",
      "\n",
      "Epoch: [517 | 1000] LR: 0.001110\n",
      "Train | 16/16 | Loss:0.3580 | MainLoss:0.1810 | Alpha:0.0493 | SPLoss:1.7693 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1611 | MainLoss:0.1611 | SPLoss:1.7682 | CLSLoss:0.0000 | AUROC:0.9841\n",
      "Test | 122/16 | Loss:0.5136 | MainLoss:0.5136 | SPLoss:1.7682 | CLSLoss:0.0000 | AUROC:0.9070\n",
      "\n",
      "Epoch: [518 | 1000] LR: 0.001107\n",
      "Train | 16/16 | Loss:0.3504 | MainLoss:0.1735 | Alpha:0.0524 | SPLoss:1.7684 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1675 | MainLoss:0.1675 | SPLoss:1.7690 | CLSLoss:0.0000 | AUROC:0.9841\n",
      "Test | 122/16 | Loss:0.4980 | MainLoss:0.4980 | SPLoss:1.7690 | CLSLoss:0.0000 | AUROC:0.9039\n",
      "\n",
      "Epoch: [519 | 1000] LR: 0.001103\n",
      "Train | 16/16 | Loss:0.3487 | MainLoss:0.1718 | Alpha:0.0505 | SPLoss:1.7690 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1639 | MainLoss:0.1639 | SPLoss:1.7689 | CLSLoss:0.0000 | AUROC:0.9841\n",
      "Test | 122/16 | Loss:0.5139 | MainLoss:0.5139 | SPLoss:1.7689 | CLSLoss:0.0000 | AUROC:0.9041\n",
      "\n",
      "Epoch: [520 | 1000] LR: 0.001100\n",
      "Train | 16/16 | Loss:0.3530 | MainLoss:0.1760 | Alpha:0.0515 | SPLoss:1.7691 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1661 | MainLoss:0.1661 | SPLoss:1.7692 | CLSLoss:0.0000 | AUROC:0.9840\n",
      "Test | 122/16 | Loss:0.5092 | MainLoss:0.5092 | SPLoss:1.7692 | CLSLoss:0.0000 | AUROC:0.9034\n",
      "\n",
      "Epoch: [521 | 1000] LR: 0.001097\n",
      "Train | 16/16 | Loss:0.3349 | MainLoss:0.1580 | Alpha:0.0523 | SPLoss:1.7689 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1634 | MainLoss:0.1634 | SPLoss:1.7682 | CLSLoss:0.0000 | AUROC:0.9839\n",
      "Test | 122/16 | Loss:0.5226 | MainLoss:0.5226 | SPLoss:1.7682 | CLSLoss:0.0000 | AUROC:0.9057\n",
      "\n",
      "Epoch: [522 | 1000] LR: 0.001094\n",
      "Train | 16/16 | Loss:0.3446 | MainLoss:0.1678 | Alpha:0.0504 | SPLoss:1.7681 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1692 | MainLoss:0.1692 | SPLoss:1.7678 | CLSLoss:0.0000 | AUROC:0.9839\n",
      "Test | 122/16 | Loss:0.5005 | MainLoss:0.5005 | SPLoss:1.7678 | CLSLoss:0.0000 | AUROC:0.9049\n",
      "\n",
      "Epoch: [523 | 1000] LR: 0.001091\n",
      "Train | 16/16 | Loss:0.3409 | MainLoss:0.1642 | Alpha:0.0513 | SPLoss:1.7669 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1663 | MainLoss:0.1663 | SPLoss:1.7668 | CLSLoss:0.0000 | AUROC:0.9839\n",
      "Test | 122/16 | Loss:0.5083 | MainLoss:0.5083 | SPLoss:1.7668 | CLSLoss:0.0000 | AUROC:0.9062\n",
      "\n",
      "Epoch: [524 | 1000] LR: 0.001088\n",
      "Train | 16/16 | Loss:0.3513 | MainLoss:0.1746 | Alpha:0.0508 | SPLoss:1.7670 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1625 | MainLoss:0.1625 | SPLoss:1.7668 | CLSLoss:0.0000 | AUROC:0.9835\n",
      "Test | 122/16 | Loss:0.5211 | MainLoss:0.5211 | SPLoss:1.7668 | CLSLoss:0.0000 | AUROC:0.9071\n",
      "\n",
      "Epoch: [525 | 1000] LR: 0.001085\n",
      "Train | 16/16 | Loss:0.3407 | MainLoss:0.1639 | Alpha:0.0515 | SPLoss:1.7675 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1650 | MainLoss:0.1650 | SPLoss:1.7681 | CLSLoss:0.0000 | AUROC:0.9836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 122/16 | Loss:0.5184 | MainLoss:0.5184 | SPLoss:1.7680 | CLSLoss:0.0000 | AUROC:0.9050\n",
      "\n",
      "Epoch: [526 | 1000] LR: 0.001082\n",
      "Train | 16/16 | Loss:0.3362 | MainLoss:0.1594 | Alpha:0.0516 | SPLoss:1.7680 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1676 | MainLoss:0.1676 | SPLoss:1.7684 | CLSLoss:0.0000 | AUROC:0.9838\n",
      "Test | 122/16 | Loss:0.5137 | MainLoss:0.5137 | SPLoss:1.7684 | CLSLoss:0.0000 | AUROC:0.9041\n",
      "\n",
      "Epoch: [527 | 1000] LR: 0.001078\n",
      "Train | 16/16 | Loss:0.3431 | MainLoss:0.1662 | Alpha:0.0489 | SPLoss:1.7686 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1677 | MainLoss:0.1677 | SPLoss:1.7689 | CLSLoss:0.0000 | AUROC:0.9841\n",
      "Test | 122/16 | Loss:0.5152 | MainLoss:0.5152 | SPLoss:1.7688 | CLSLoss:0.0000 | AUROC:0.9036\n",
      "\n",
      "Epoch: [528 | 1000] LR: 0.001075\n",
      "Train | 16/16 | Loss:0.3458 | MainLoss:0.1689 | Alpha:0.0493 | SPLoss:1.7689 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1636 | MainLoss:0.1636 | SPLoss:1.7675 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5246 | MainLoss:0.5246 | SPLoss:1.7675 | CLSLoss:0.0000 | AUROC:0.9054\n",
      "\n",
      "Epoch: [529 | 1000] LR: 0.001072\n",
      "Train | 16/16 | Loss:0.3484 | MainLoss:0.1717 | Alpha:0.0505 | SPLoss:1.7669 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1621 | MainLoss:0.1621 | SPLoss:1.7662 | CLSLoss:0.0000 | AUROC:0.9839\n",
      "Test | 122/16 | Loss:0.5212 | MainLoss:0.5212 | SPLoss:1.7662 | CLSLoss:0.0000 | AUROC:0.9057\n",
      "\n",
      "Epoch: [530 | 1000] LR: 0.001069\n",
      "Train | 16/16 | Loss:0.3447 | MainLoss:0.1681 | Alpha:0.0522 | SPLoss:1.7661 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1655 | MainLoss:0.1655 | SPLoss:1.7661 | CLSLoss:0.0000 | AUROC:0.9841\n",
      "Test | 122/16 | Loss:0.5112 | MainLoss:0.5112 | SPLoss:1.7661 | CLSLoss:0.0000 | AUROC:0.9033\n",
      "\n",
      "Epoch: [531 | 1000] LR: 0.001066\n",
      "Train | 16/16 | Loss:0.3329 | MainLoss:0.1564 | Alpha:0.0516 | SPLoss:1.7657 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1674 | MainLoss:0.1674 | SPLoss:1.7657 | CLSLoss:0.0000 | AUROC:0.9838\n",
      "Test | 122/16 | Loss:0.5185 | MainLoss:0.5185 | SPLoss:1.7657 | CLSLoss:0.0000 | AUROC:0.9039\n",
      "\n",
      "Epoch: [532 | 1000] LR: 0.001063\n",
      "Train | 16/16 | Loss:0.3421 | MainLoss:0.1656 | Alpha:0.0513 | SPLoss:1.7650 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1667 | MainLoss:0.1667 | SPLoss:1.7649 | CLSLoss:0.0000 | AUROC:0.9839\n",
      "Test | 122/16 | Loss:0.5210 | MainLoss:0.5210 | SPLoss:1.7649 | CLSLoss:0.0000 | AUROC:0.9039\n",
      "\n",
      "Epoch: [533 | 1000] LR: 0.001060\n",
      "Train | 16/16 | Loss:0.3493 | MainLoss:0.1728 | Alpha:0.0509 | SPLoss:1.7646 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1718 | MainLoss:0.1718 | SPLoss:1.7647 | CLSLoss:0.0000 | AUROC:0.9841\n",
      "Test | 122/16 | Loss:0.5002 | MainLoss:0.5002 | SPLoss:1.7647 | CLSLoss:0.0000 | AUROC:0.9024\n",
      "\n",
      "Epoch: [534 | 1000] LR: 0.001057\n",
      "Train | 16/16 | Loss:0.3600 | MainLoss:0.1836 | Alpha:0.0503 | SPLoss:1.7645 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1669 | MainLoss:0.1669 | SPLoss:1.7642 | CLSLoss:0.0000 | AUROC:0.9839\n",
      "Test | 122/16 | Loss:0.5007 | MainLoss:0.5007 | SPLoss:1.7642 | CLSLoss:0.0000 | AUROC:0.9045\n",
      "\n",
      "Epoch: [535 | 1000] LR: 0.001053\n",
      "Train | 16/16 | Loss:0.3511 | MainLoss:0.1748 | Alpha:0.0510 | SPLoss:1.7633 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1627 | MainLoss:0.1627 | SPLoss:1.7633 | CLSLoss:0.0000 | AUROC:0.9839\n",
      "Test | 122/16 | Loss:0.5103 | MainLoss:0.5103 | SPLoss:1.7633 | CLSLoss:0.0000 | AUROC:0.9082\n",
      "\n",
      "Epoch: [536 | 1000] LR: 0.001050\n",
      "Train | 16/16 | Loss:0.3393 | MainLoss:0.1629 | Alpha:0.0495 | SPLoss:1.7643 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1649 | MainLoss:0.1649 | SPLoss:1.7644 | CLSLoss:0.0000 | AUROC:0.9839\n",
      "Test | 122/16 | Loss:0.5074 | MainLoss:0.5074 | SPLoss:1.7644 | CLSLoss:0.0000 | AUROC:0.9072\n",
      "\n",
      "Epoch: [537 | 1000] LR: 0.001047\n",
      "Train | 16/16 | Loss:0.3501 | MainLoss:0.1737 | Alpha:0.0516 | SPLoss:1.7642 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1663 | MainLoss:0.1663 | SPLoss:1.7635 | CLSLoss:0.0000 | AUROC:0.9841\n",
      "Test | 122/16 | Loss:0.5018 | MainLoss:0.5018 | SPLoss:1.7635 | CLSLoss:0.0000 | AUROC:0.9067\n",
      "\n",
      "Epoch: [538 | 1000] LR: 0.001044\n",
      "Train | 16/16 | Loss:0.3547 | MainLoss:0.1784 | Alpha:0.0508 | SPLoss:1.7639 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1678 | MainLoss:0.1678 | SPLoss:1.7649 | CLSLoss:0.0000 | AUROC:0.9839\n",
      "Test | 122/16 | Loss:0.5014 | MainLoss:0.5014 | SPLoss:1.7649 | CLSLoss:0.0000 | AUROC:0.9037\n",
      "\n",
      "Epoch: [539 | 1000] LR: 0.001041\n",
      "Train | 16/16 | Loss:0.3379 | MainLoss:0.1615 | Alpha:0.0506 | SPLoss:1.7639 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1654 | MainLoss:0.1654 | SPLoss:1.7640 | CLSLoss:0.0000 | AUROC:0.9841\n",
      "Test | 122/16 | Loss:0.5102 | MainLoss:0.5102 | SPLoss:1.7640 | CLSLoss:0.0000 | AUROC:0.9058\n",
      "\n",
      "Epoch: [540 | 1000] LR: 0.001038\n",
      "Train | 16/16 | Loss:0.3376 | MainLoss:0.1612 | Alpha:0.0507 | SPLoss:1.7640 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1672 | MainLoss:0.1672 | SPLoss:1.7642 | CLSLoss:0.0000 | AUROC:0.9837\n",
      "Test | 122/16 | Loss:0.5170 | MainLoss:0.5170 | SPLoss:1.7642 | CLSLoss:0.0000 | AUROC:0.9056\n",
      "\n",
      "Epoch: [541 | 1000] LR: 0.001035\n",
      "Train | 16/16 | Loss:0.3405 | MainLoss:0.1642 | Alpha:0.0497 | SPLoss:1.7637 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1662 | MainLoss:0.1662 | SPLoss:1.7630 | CLSLoss:0.0000 | AUROC:0.9840\n",
      "Test | 122/16 | Loss:0.5168 | MainLoss:0.5168 | SPLoss:1.7630 | CLSLoss:0.0000 | AUROC:0.9065\n",
      "\n",
      "Epoch: [542 | 1000] LR: 0.001031\n",
      "Train | 16/16 | Loss:0.3400 | MainLoss:0.1636 | Alpha:0.0509 | SPLoss:1.7632 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1714 | MainLoss:0.1714 | SPLoss:1.7627 | CLSLoss:0.0000 | AUROC:0.9837\n",
      "Test | 122/16 | Loss:0.4996 | MainLoss:0.4996 | SPLoss:1.7627 | CLSLoss:0.0000 | AUROC:0.9048\n",
      "\n",
      "Epoch: [543 | 1000] LR: 0.001028\n",
      "Train | 16/16 | Loss:0.3484 | MainLoss:0.1721 | Alpha:0.0514 | SPLoss:1.7625 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1640 | MainLoss:0.1640 | SPLoss:1.7636 | CLSLoss:0.0000 | AUROC:0.9840\n",
      "Test | 122/16 | Loss:0.5254 | MainLoss:0.5254 | SPLoss:1.7635 | CLSLoss:0.0000 | AUROC:0.9056\n",
      "\n",
      "Epoch: [544 | 1000] LR: 0.001025\n",
      "Train | 16/16 | Loss:0.3363 | MainLoss:0.1599 | Alpha:0.0511 | SPLoss:1.7638 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1655 | MainLoss:0.1655 | SPLoss:1.7635 | CLSLoss:0.0000 | AUROC:0.9836\n",
      "Test | 122/16 | Loss:0.5203 | MainLoss:0.5203 | SPLoss:1.7635 | CLSLoss:0.0000 | AUROC:0.9052\n",
      "\n",
      "Epoch: [545 | 1000] LR: 0.001022\n",
      "Train | 16/16 | Loss:0.3482 | MainLoss:0.1718 | Alpha:0.0499 | SPLoss:1.7638 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1637 | MainLoss:0.1637 | SPLoss:1.7634 | CLSLoss:0.0000 | AUROC:0.9841\n",
      "Test | 122/16 | Loss:0.5270 | MainLoss:0.5270 | SPLoss:1.7634 | CLSLoss:0.0000 | AUROC:0.9055\n",
      "\n",
      "Epoch: [546 | 1000] LR: 0.001019\n",
      "Train | 16/16 | Loss:0.3501 | MainLoss:0.1736 | Alpha:0.0511 | SPLoss:1.7642 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1692 | MainLoss:0.1692 | SPLoss:1.7646 | CLSLoss:0.0000 | AUROC:0.9838\n",
      "Test | 122/16 | Loss:0.5136 | MainLoss:0.5136 | SPLoss:1.7646 | CLSLoss:0.0000 | AUROC:0.9011\n",
      "\n",
      "Epoch: [547 | 1000] LR: 0.001016\n",
      "Train | 16/16 | Loss:0.3511 | MainLoss:0.1748 | Alpha:0.0505 | SPLoss:1.7637 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1659 | MainLoss:0.1659 | SPLoss:1.7636 | CLSLoss:0.0000 | AUROC:0.9840\n",
      "Test | 122/16 | Loss:0.5124 | MainLoss:0.5124 | SPLoss:1.7636 | CLSLoss:0.0000 | AUROC:0.9032\n",
      "\n",
      "Epoch: [548 | 1000] LR: 0.001013\n",
      "Train | 16/16 | Loss:0.3463 | MainLoss:0.1701 | Alpha:0.0514 | SPLoss:1.7626 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1623 | MainLoss:0.1623 | SPLoss:1.7615 | CLSLoss:0.0000 | AUROC:0.9840\n",
      "Test | 122/16 | Loss:0.5199 | MainLoss:0.5199 | SPLoss:1.7615 | CLSLoss:0.0000 | AUROC:0.9062\n",
      "\n",
      "Epoch: [549 | 1000] LR: 0.001009\n",
      "Train | 16/16 | Loss:0.3428 | MainLoss:0.1666 | Alpha:0.0483 | SPLoss:1.7620 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1692 | MainLoss:0.1692 | SPLoss:1.7617 | CLSLoss:0.0000 | AUROC:0.9840\n",
      "Test | 122/16 | Loss:0.5046 | MainLoss:0.5046 | SPLoss:1.7617 | CLSLoss:0.0000 | AUROC:0.9026\n",
      "\n",
      "Epoch: [550 | 1000] LR: 0.001006\n",
      "Train | 16/16 | Loss:0.3540 | MainLoss:0.1778 | Alpha:0.0507 | SPLoss:1.7614 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1661 | MainLoss:0.1661 | SPLoss:1.7619 | CLSLoss:0.0000 | AUROC:0.9842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 122/16 | Loss:0.5084 | MainLoss:0.5084 | SPLoss:1.7619 | CLSLoss:0.0000 | AUROC:0.9031\n",
      "\n",
      "Epoch: [551 | 1000] LR: 0.001003\n",
      "Train | 16/16 | Loss:0.3525 | MainLoss:0.1763 | Alpha:0.0510 | SPLoss:1.7617 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1641 | MainLoss:0.1641 | SPLoss:1.7616 | CLSLoss:0.0000 | AUROC:0.9838\n",
      "Test | 122/16 | Loss:0.5147 | MainLoss:0.5147 | SPLoss:1.7616 | CLSLoss:0.0000 | AUROC:0.9048\n",
      "\n",
      "Epoch: [552 | 1000] LR: 0.001000\n",
      "Train | 16/16 | Loss:0.3341 | MainLoss:0.1579 | Alpha:0.0509 | SPLoss:1.7621 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1648 | MainLoss:0.1648 | SPLoss:1.7619 | CLSLoss:0.0000 | AUROC:0.9836\n",
      "Test | 122/16 | Loss:0.5247 | MainLoss:0.5247 | SPLoss:1.7619 | CLSLoss:0.0000 | AUROC:0.9036\n",
      "\n",
      "Epoch: [553 | 1000] LR: 0.000997\n",
      "Train | 16/16 | Loss:0.3480 | MainLoss:0.1718 | Alpha:0.0506 | SPLoss:1.7624 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1712 | MainLoss:0.1712 | SPLoss:1.7628 | CLSLoss:0.0000 | AUROC:0.9841\n",
      "Test | 122/16 | Loss:0.5113 | MainLoss:0.5113 | SPLoss:1.7628 | CLSLoss:0.0000 | AUROC:0.9008\n",
      "\n",
      "Epoch: [554 | 1000] LR: 0.000994\n",
      "Train | 16/16 | Loss:0.3463 | MainLoss:0.1700 | Alpha:0.0516 | SPLoss:1.7622 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1703 | MainLoss:0.1703 | SPLoss:1.7621 | CLSLoss:0.0000 | AUROC:0.9838\n",
      "Test | 122/16 | Loss:0.5028 | MainLoss:0.5028 | SPLoss:1.7621 | CLSLoss:0.0000 | AUROC:0.9032\n",
      "\n",
      "Epoch: [555 | 1000] LR: 0.000991\n",
      "Train | 16/16 | Loss:0.3433 | MainLoss:0.1672 | Alpha:0.0507 | SPLoss:1.7613 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1659 | MainLoss:0.1659 | SPLoss:1.7612 | CLSLoss:0.0000 | AUROC:0.9839\n",
      "Test | 122/16 | Loss:0.5100 | MainLoss:0.5100 | SPLoss:1.7612 | CLSLoss:0.0000 | AUROC:0.9060\n",
      "\n",
      "Epoch: [556 | 1000] LR: 0.000987\n",
      "Train | 16/16 | Loss:0.3348 | MainLoss:0.1586 | Alpha:0.0493 | SPLoss:1.7618 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1642 | MainLoss:0.1642 | SPLoss:1.7618 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5291 | MainLoss:0.5291 | SPLoss:1.7618 | CLSLoss:0.0000 | AUROC:0.9041\n",
      "\n",
      "Epoch: [557 | 1000] LR: 0.000984\n",
      "Train | 16/16 | Loss:0.3575 | MainLoss:0.1812 | Alpha:0.0516 | SPLoss:1.7624 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1651 | MainLoss:0.1651 | SPLoss:1.7625 | CLSLoss:0.0000 | AUROC:0.9837\n",
      "Test | 122/16 | Loss:0.5262 | MainLoss:0.5262 | SPLoss:1.7625 | CLSLoss:0.0000 | AUROC:0.9026\n",
      "\n",
      "Epoch: [558 | 1000] LR: 0.000981\n",
      "Train | 16/16 | Loss:0.3506 | MainLoss:0.1744 | Alpha:0.0506 | SPLoss:1.7622 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1716 | MainLoss:0.1716 | SPLoss:1.7627 | CLSLoss:0.0000 | AUROC:0.9838\n",
      "Test | 122/16 | Loss:0.5027 | MainLoss:0.5027 | SPLoss:1.7627 | CLSLoss:0.0000 | AUROC:0.9015\n",
      "\n",
      "Epoch: [559 | 1000] LR: 0.000978\n",
      "Train | 16/16 | Loss:0.3506 | MainLoss:0.1744 | Alpha:0.0497 | SPLoss:1.7620 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1644 | MainLoss:0.1644 | SPLoss:1.7617 | CLSLoss:0.0000 | AUROC:0.9841\n",
      "Test | 122/16 | Loss:0.5189 | MainLoss:0.5189 | SPLoss:1.7617 | CLSLoss:0.0000 | AUROC:0.9035\n",
      "\n",
      "Epoch: [560 | 1000] LR: 0.000975\n",
      "Train | 16/16 | Loss:0.3551 | MainLoss:0.1789 | Alpha:0.0510 | SPLoss:1.7619 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1659 | MainLoss:0.1659 | SPLoss:1.7618 | CLSLoss:0.0000 | AUROC:0.9841\n",
      "Test | 122/16 | Loss:0.5130 | MainLoss:0.5130 | SPLoss:1.7618 | CLSLoss:0.0000 | AUROC:0.9021\n",
      "\n",
      "Epoch: [561 | 1000] LR: 0.000972\n",
      "Train | 16/16 | Loss:0.3577 | MainLoss:0.1815 | Alpha:0.0502 | SPLoss:1.7614 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1613 | MainLoss:0.1613 | SPLoss:1.7608 | CLSLoss:0.0000 | AUROC:0.9839\n",
      "Test | 122/16 | Loss:0.5271 | MainLoss:0.5271 | SPLoss:1.7608 | CLSLoss:0.0000 | AUROC:0.9048\n",
      "\n",
      "Epoch: [562 | 1000] LR: 0.000969\n",
      "Train | 16/16 | Loss:0.3417 | MainLoss:0.1655 | Alpha:0.0506 | SPLoss:1.7617 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1688 | MainLoss:0.1688 | SPLoss:1.7617 | CLSLoss:0.0000 | AUROC:0.9839\n",
      "Test | 122/16 | Loss:0.5108 | MainLoss:0.5108 | SPLoss:1.7617 | CLSLoss:0.0000 | AUROC:0.9010\n",
      "\n",
      "Epoch: [563 | 1000] LR: 0.000965\n",
      "Train | 16/16 | Loss:0.3588 | MainLoss:0.1826 | Alpha:0.0517 | SPLoss:1.7617 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1642 | MainLoss:0.1642 | SPLoss:1.7613 | CLSLoss:0.0000 | AUROC:0.9841\n",
      "Test | 122/16 | Loss:0.5201 | MainLoss:0.5201 | SPLoss:1.7613 | CLSLoss:0.0000 | AUROC:0.9030\n",
      "\n",
      "Epoch: [564 | 1000] LR: 0.000962\n",
      "Train | 16/16 | Loss:0.3567 | MainLoss:0.1806 | Alpha:0.0506 | SPLoss:1.7614 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1628 | MainLoss:0.1628 | SPLoss:1.7603 | CLSLoss:0.0000 | AUROC:0.9837\n",
      "Test | 122/16 | Loss:0.5129 | MainLoss:0.5129 | SPLoss:1.7603 | CLSLoss:0.0000 | AUROC:0.9059\n",
      "\n",
      "Epoch: [565 | 1000] LR: 0.000959\n",
      "Train | 16/16 | Loss:0.3413 | MainLoss:0.1653 | Alpha:0.0507 | SPLoss:1.7604 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1681 | MainLoss:0.1681 | SPLoss:1.7603 | CLSLoss:0.0000 | AUROC:0.9841\n",
      "Test | 122/16 | Loss:0.5007 | MainLoss:0.5007 | SPLoss:1.7603 | CLSLoss:0.0000 | AUROC:0.9031\n",
      "\n",
      "Epoch: [566 | 1000] LR: 0.000956\n",
      "Train | 16/16 | Loss:0.3382 | MainLoss:0.1622 | Alpha:0.0528 | SPLoss:1.7599 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1661 | MainLoss:0.1661 | SPLoss:1.7599 | CLSLoss:0.0000 | AUROC:0.9838\n",
      "Test | 122/16 | Loss:0.5066 | MainLoss:0.5066 | SPLoss:1.7599 | CLSLoss:0.0000 | AUROC:0.9050\n",
      "\n",
      "Epoch: [567 | 1000] LR: 0.000953\n",
      "Train | 16/16 | Loss:0.3678 | MainLoss:0.1918 | Alpha:0.0504 | SPLoss:1.7598 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1684 | MainLoss:0.1684 | SPLoss:1.7599 | CLSLoss:0.0000 | AUROC:0.9838\n",
      "Test | 122/16 | Loss:0.4957 | MainLoss:0.4957 | SPLoss:1.7599 | CLSLoss:0.0000 | AUROC:0.9039\n",
      "\n",
      "Epoch: [568 | 1000] LR: 0.000950\n",
      "Train | 16/16 | Loss:0.3343 | MainLoss:0.1583 | Alpha:0.0508 | SPLoss:1.7601 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1701 | MainLoss:0.1701 | SPLoss:1.7604 | CLSLoss:0.0000 | AUROC:0.9841\n",
      "Test | 122/16 | Loss:0.5034 | MainLoss:0.5034 | SPLoss:1.7605 | CLSLoss:0.0000 | AUROC:0.9015\n",
      "\n",
      "Epoch: [569 | 1000] LR: 0.000947\n",
      "Train | 16/16 | Loss:0.3499 | MainLoss:0.1739 | Alpha:0.0515 | SPLoss:1.7601 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1651 | MainLoss:0.1651 | SPLoss:1.7602 | CLSLoss:0.0000 | AUROC:0.9840\n",
      "Test | 122/16 | Loss:0.5128 | MainLoss:0.5128 | SPLoss:1.7602 | CLSLoss:0.0000 | AUROC:0.9036\n",
      "\n",
      "Epoch: [570 | 1000] LR: 0.000943\n",
      "Train | 16/16 | Loss:0.3448 | MainLoss:0.1687 | Alpha:0.0509 | SPLoss:1.7605 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1664 | MainLoss:0.1664 | SPLoss:1.7611 | CLSLoss:0.0000 | AUROC:0.9844\n",
      "Test | 122/16 | Loss:0.5204 | MainLoss:0.5204 | SPLoss:1.7611 | CLSLoss:0.0000 | AUROC:0.9010\n",
      "\n",
      "Epoch: [571 | 1000] LR: 0.000940\n",
      "Train | 16/16 | Loss:0.3647 | MainLoss:0.1887 | Alpha:0.0521 | SPLoss:1.7602 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1667 | MainLoss:0.1667 | SPLoss:1.7603 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5127 | MainLoss:0.5127 | SPLoss:1.7603 | CLSLoss:0.0000 | AUROC:0.9009\n",
      "\n",
      "Epoch: [572 | 1000] LR: 0.000937\n",
      "Train | 16/16 | Loss:0.3414 | MainLoss:0.1654 | Alpha:0.0519 | SPLoss:1.7604 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1629 | MainLoss:0.1629 | SPLoss:1.7599 | CLSLoss:0.0000 | AUROC:0.9839\n",
      "Test | 122/16 | Loss:0.5229 | MainLoss:0.5229 | SPLoss:1.7599 | CLSLoss:0.0000 | AUROC:0.9046\n",
      "\n",
      "Epoch: [573 | 1000] LR: 0.000934\n",
      "Train | 16/16 | Loss:0.3442 | MainLoss:0.1682 | Alpha:0.0500 | SPLoss:1.7601 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1638 | MainLoss:0.1638 | SPLoss:1.7594 | CLSLoss:0.0000 | AUROC:0.9839\n",
      "Test | 122/16 | Loss:0.5139 | MainLoss:0.5139 | SPLoss:1.7594 | CLSLoss:0.0000 | AUROC:0.9052\n",
      "\n",
      "Epoch: [574 | 1000] LR: 0.000931\n",
      "Train | 16/16 | Loss:0.3594 | MainLoss:0.1834 | Alpha:0.0519 | SPLoss:1.7597 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1612 | MainLoss:0.1612 | SPLoss:1.7592 | CLSLoss:0.0000 | AUROC:0.9839\n",
      "Test | 122/16 | Loss:0.5216 | MainLoss:0.5216 | SPLoss:1.7592 | CLSLoss:0.0000 | AUROC:0.9068\n",
      "\n",
      "Epoch: [575 | 1000] LR: 0.000928\n",
      "Train | 16/16 | Loss:0.3541 | MainLoss:0.1782 | Alpha:0.0540 | SPLoss:1.7593 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1633 | MainLoss:0.1633 | SPLoss:1.7589 | CLSLoss:0.0000 | AUROC:0.9840\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 122/16 | Loss:0.5007 | MainLoss:0.5007 | SPLoss:1.7589 | CLSLoss:0.0000 | AUROC:0.9065\n",
      "\n",
      "Epoch: [576 | 1000] LR: 0.000925\n",
      "Train | 16/16 | Loss:0.3514 | MainLoss:0.1755 | Alpha:0.0518 | SPLoss:1.7593 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1655 | MainLoss:0.1655 | SPLoss:1.7599 | CLSLoss:0.0000 | AUROC:0.9841\n",
      "Test | 122/16 | Loss:0.4988 | MainLoss:0.4988 | SPLoss:1.7599 | CLSLoss:0.0000 | AUROC:0.9051\n",
      "\n",
      "Epoch: [577 | 1000] LR: 0.000922\n",
      "Train | 16/16 | Loss:0.3509 | MainLoss:0.1749 | Alpha:0.0510 | SPLoss:1.7596 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1654 | MainLoss:0.1654 | SPLoss:1.7590 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.4935 | MainLoss:0.4935 | SPLoss:1.7590 | CLSLoss:0.0000 | AUROC:0.9061\n",
      "\n",
      "Epoch: [578 | 1000] LR: 0.000918\n",
      "Train | 16/16 | Loss:0.3311 | MainLoss:0.1552 | Alpha:0.0500 | SPLoss:1.7591 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1623 | MainLoss:0.1623 | SPLoss:1.7582 | CLSLoss:0.0000 | AUROC:0.9840\n",
      "Test | 122/16 | Loss:0.5147 | MainLoss:0.5147 | SPLoss:1.7582 | CLSLoss:0.0000 | AUROC:0.9072\n",
      "\n",
      "Epoch: [579 | 1000] LR: 0.000915\n",
      "Train | 16/16 | Loss:0.3491 | MainLoss:0.1732 | Alpha:0.0505 | SPLoss:1.7583 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1638 | MainLoss:0.1638 | SPLoss:1.7578 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5012 | MainLoss:0.5012 | SPLoss:1.7578 | CLSLoss:0.0000 | AUROC:0.9068\n",
      "\n",
      "Epoch: [580 | 1000] LR: 0.000912\n",
      "Train | 16/16 | Loss:0.3501 | MainLoss:0.1743 | Alpha:0.0508 | SPLoss:1.7578 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1649 | MainLoss:0.1649 | SPLoss:1.7579 | CLSLoss:0.0000 | AUROC:0.9838\n",
      "Test | 122/16 | Loss:0.4954 | MainLoss:0.4954 | SPLoss:1.7579 | CLSLoss:0.0000 | AUROC:0.9070\n",
      "\n",
      "Epoch: [581 | 1000] LR: 0.000909\n",
      "Train | 16/16 | Loss:0.3616 | MainLoss:0.1858 | Alpha:0.0498 | SPLoss:1.7579 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1628 | MainLoss:0.1628 | SPLoss:1.7577 | CLSLoss:0.0000 | AUROC:0.9841\n",
      "Test | 122/16 | Loss:0.4978 | MainLoss:0.4978 | SPLoss:1.7577 | CLSLoss:0.0000 | AUROC:0.9080\n",
      "\n",
      "Epoch: [582 | 1000] LR: 0.000906\n",
      "Train | 16/16 | Loss:0.3397 | MainLoss:0.1639 | Alpha:0.0507 | SPLoss:1.7581 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1623 | MainLoss:0.1623 | SPLoss:1.7580 | CLSLoss:0.0000 | AUROC:0.9836\n",
      "Test | 122/16 | Loss:0.5093 | MainLoss:0.5093 | SPLoss:1.7580 | CLSLoss:0.0000 | AUROC:0.9078\n",
      "\n",
      "Epoch: [583 | 1000] LR: 0.000903\n",
      "Train | 16/16 | Loss:0.3424 | MainLoss:0.1665 | Alpha:0.0506 | SPLoss:1.7586 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1705 | MainLoss:0.1705 | SPLoss:1.7595 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5014 | MainLoss:0.5014 | SPLoss:1.7595 | CLSLoss:0.0000 | AUROC:0.9024\n",
      "\n",
      "Epoch: [584 | 1000] LR: 0.000900\n",
      "Train | 16/16 | Loss:0.3541 | MainLoss:0.1782 | Alpha:0.0501 | SPLoss:1.7599 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1666 | MainLoss:0.1666 | SPLoss:1.7606 | CLSLoss:0.0000 | AUROC:0.9841\n",
      "Test | 122/16 | Loss:0.5157 | MainLoss:0.5157 | SPLoss:1.7606 | CLSLoss:0.0000 | AUROC:0.9016\n",
      "\n",
      "Epoch: [585 | 1000] LR: 0.000897\n",
      "Train | 16/16 | Loss:0.3470 | MainLoss:0.1709 | Alpha:0.0513 | SPLoss:1.7607 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1635 | MainLoss:0.1635 | SPLoss:1.7599 | CLSLoss:0.0000 | AUROC:0.9844\n",
      "Test | 122/16 | Loss:0.5213 | MainLoss:0.5213 | SPLoss:1.7599 | CLSLoss:0.0000 | AUROC:0.9033\n",
      "\n",
      "Epoch: [586 | 1000] LR: 0.000893\n",
      "Train | 16/16 | Loss:0.3561 | MainLoss:0.1801 | Alpha:0.0521 | SPLoss:1.7600 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1653 | MainLoss:0.1653 | SPLoss:1.7595 | CLSLoss:0.0000 | AUROC:0.9840\n",
      "Test | 122/16 | Loss:0.5113 | MainLoss:0.5113 | SPLoss:1.7595 | CLSLoss:0.0000 | AUROC:0.9030\n",
      "\n",
      "Epoch: [587 | 1000] LR: 0.000890\n",
      "Train | 16/16 | Loss:0.3500 | MainLoss:0.1741 | Alpha:0.0515 | SPLoss:1.7596 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1648 | MainLoss:0.1648 | SPLoss:1.7595 | CLSLoss:0.0000 | AUROC:0.9841\n",
      "Test | 122/16 | Loss:0.5192 | MainLoss:0.5192 | SPLoss:1.7595 | CLSLoss:0.0000 | AUROC:0.9021\n",
      "\n",
      "Epoch: [588 | 1000] LR: 0.000887\n",
      "Train | 16/16 | Loss:0.3539 | MainLoss:0.1780 | Alpha:0.0489 | SPLoss:1.7593 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1705 | MainLoss:0.1705 | SPLoss:1.7593 | CLSLoss:0.0000 | AUROC:0.9845\n",
      "Test | 122/16 | Loss:0.5043 | MainLoss:0.5043 | SPLoss:1.7593 | CLSLoss:0.0000 | AUROC:0.9002\n",
      "\n",
      "Epoch: [589 | 1000] LR: 0.000884\n",
      "Train | 16/16 | Loss:0.3498 | MainLoss:0.1739 | Alpha:0.0524 | SPLoss:1.7589 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1637 | MainLoss:0.1637 | SPLoss:1.7584 | CLSLoss:0.0000 | AUROC:0.9841\n",
      "Test | 122/16 | Loss:0.5196 | MainLoss:0.5196 | SPLoss:1.7584 | CLSLoss:0.0000 | AUROC:0.9028\n",
      "\n",
      "Epoch: [590 | 1000] LR: 0.000881\n",
      "Train | 16/16 | Loss:0.3452 | MainLoss:0.1694 | Alpha:0.0507 | SPLoss:1.7582 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1638 | MainLoss:0.1638 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5121 | MainLoss:0.5121 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.9047\n",
      "\n",
      "Epoch: [591 | 1000] LR: 0.000878\n",
      "Train | 16/16 | Loss:0.3508 | MainLoss:0.1752 | Alpha:0.0502 | SPLoss:1.7569 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1634 | MainLoss:0.1634 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9841\n",
      "Test | 122/16 | Loss:0.5110 | MainLoss:0.5110 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9046\n",
      "\n",
      "Epoch: [592 | 1000] LR: 0.000875\n",
      "Train | 16/16 | Loss:0.3466 | MainLoss:0.1709 | Alpha:0.0515 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1626 | MainLoss:0.1626 | SPLoss:1.7574 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5205 | MainLoss:0.5205 | SPLoss:1.7574 | CLSLoss:0.0000 | AUROC:0.9041\n",
      "\n",
      "Epoch: [593 | 1000] LR: 0.000872\n",
      "Train | 16/16 | Loss:0.3437 | MainLoss:0.1680 | Alpha:0.0504 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1629 | MainLoss:0.1629 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5162 | MainLoss:0.5162 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9052\n",
      "\n",
      "Epoch: [594 | 1000] LR: 0.000868\n",
      "Train | 16/16 | Loss:0.3492 | MainLoss:0.1734 | Alpha:0.0502 | SPLoss:1.7581 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1671 | MainLoss:0.1671 | SPLoss:1.7590 | CLSLoss:0.0000 | AUROC:0.9843\n",
      "Test | 122/16 | Loss:0.5101 | MainLoss:0.5101 | SPLoss:1.7590 | CLSLoss:0.0000 | AUROC:0.9017\n",
      "\n",
      "Epoch: [595 | 1000] LR: 0.000865\n",
      "Train | 16/16 | Loss:0.3408 | MainLoss:0.1649 | Alpha:0.0499 | SPLoss:1.7590 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1628 | MainLoss:0.1628 | SPLoss:1.7584 | CLSLoss:0.0000 | AUROC:0.9839\n",
      "Test | 122/16 | Loss:0.5253 | MainLoss:0.5253 | SPLoss:1.7584 | CLSLoss:0.0000 | AUROC:0.9043\n",
      "\n",
      "Epoch: [596 | 1000] LR: 0.000862\n",
      "Train | 16/16 | Loss:0.3466 | MainLoss:0.1708 | Alpha:0.0506 | SPLoss:1.7587 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1708 | MainLoss:0.1708 | SPLoss:1.7587 | CLSLoss:0.0000 | AUROC:0.9841\n",
      "Test | 122/16 | Loss:0.5023 | MainLoss:0.5023 | SPLoss:1.7587 | CLSLoss:0.0000 | AUROC:0.9011\n",
      "\n",
      "Epoch: [597 | 1000] LR: 0.000859\n",
      "Train | 16/16 | Loss:0.3464 | MainLoss:0.1706 | Alpha:0.0487 | SPLoss:1.7582 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1674 | MainLoss:0.1674 | SPLoss:1.7584 | CLSLoss:0.0000 | AUROC:0.9843\n",
      "Test | 122/16 | Loss:0.5073 | MainLoss:0.5073 | SPLoss:1.7584 | CLSLoss:0.0000 | AUROC:0.9025\n",
      "\n",
      "Epoch: [598 | 1000] LR: 0.000856\n",
      "Train | 16/16 | Loss:0.3420 | MainLoss:0.1662 | Alpha:0.0504 | SPLoss:1.7583 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1616 | MainLoss:0.1616 | SPLoss:1.7583 | CLSLoss:0.0000 | AUROC:0.9841\n",
      "Test | 122/16 | Loss:0.5259 | MainLoss:0.5259 | SPLoss:1.7583 | CLSLoss:0.0000 | AUROC:0.9048\n",
      "\n",
      "Epoch: [599 | 1000] LR: 0.000853\n",
      "Train | 16/16 | Loss:0.3329 | MainLoss:0.1570 | Alpha:0.0522 | SPLoss:1.7584 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1666 | MainLoss:0.1666 | SPLoss:1.7586 | CLSLoss:0.0000 | AUROC:0.9843\n",
      "Test | 122/16 | Loss:0.5132 | MainLoss:0.5132 | SPLoss:1.7586 | CLSLoss:0.0000 | AUROC:0.9030\n",
      "\n",
      "Epoch: [600 | 1000] LR: 0.000850\n",
      "Train | 16/16 | Loss:0.3552 | MainLoss:0.1794 | Alpha:0.0507 | SPLoss:1.7582 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1658 | MainLoss:0.1658 | SPLoss:1.7575 | CLSLoss:0.0000 | AUROC:0.9844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 122/16 | Loss:0.5045 | MainLoss:0.5045 | SPLoss:1.7575 | CLSLoss:0.0000 | AUROC:0.9045\n",
      "\n",
      "Epoch: [601 | 1000] LR: 0.000085\n",
      "Train | 16/16 | Loss:0.3525 | MainLoss:0.1767 | Alpha:0.0495 | SPLoss:1.7574 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1654 | MainLoss:0.1654 | SPLoss:1.7575 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5057 | MainLoss:0.5057 | SPLoss:1.7575 | CLSLoss:0.0000 | AUROC:0.9046\n",
      "\n",
      "Epoch: [602 | 1000] LR: 0.000084\n",
      "Train | 16/16 | Loss:0.3399 | MainLoss:0.1642 | Alpha:0.0505 | SPLoss:1.7575 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1644 | MainLoss:0.1644 | SPLoss:1.7575 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5098 | MainLoss:0.5098 | SPLoss:1.7575 | CLSLoss:0.0000 | AUROC:0.9047\n",
      "\n",
      "Epoch: [603 | 1000] LR: 0.000084\n",
      "Train | 16/16 | Loss:0.3423 | MainLoss:0.1665 | Alpha:0.0520 | SPLoss:1.7575 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1643 | MainLoss:0.1643 | SPLoss:1.7575 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5101 | MainLoss:0.5101 | SPLoss:1.7575 | CLSLoss:0.0000 | AUROC:0.9048\n",
      "\n",
      "Epoch: [604 | 1000] LR: 0.000084\n",
      "Train | 16/16 | Loss:0.3492 | MainLoss:0.1735 | Alpha:0.0509 | SPLoss:1.7575 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7574 | CLSLoss:0.0000 | AUROC:0.9844\n",
      "Test | 122/16 | Loss:0.5080 | MainLoss:0.5080 | SPLoss:1.7574 | CLSLoss:0.0000 | AUROC:0.9050\n",
      "\n",
      "Epoch: [605 | 1000] LR: 0.000083\n",
      "Train | 16/16 | Loss:0.3443 | MainLoss:0.1686 | Alpha:0.0502 | SPLoss:1.7574 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1646 | MainLoss:0.1646 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5075 | MainLoss:0.5075 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.9047\n",
      "\n",
      "Epoch: [606 | 1000] LR: 0.000083\n",
      "Train | 16/16 | Loss:0.3592 | MainLoss:0.1835 | Alpha:0.0529 | SPLoss:1.7574 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1656 | MainLoss:0.1656 | SPLoss:1.7574 | CLSLoss:0.0000 | AUROC:0.9843\n",
      "Test | 122/16 | Loss:0.5043 | MainLoss:0.5043 | SPLoss:1.7574 | CLSLoss:0.0000 | AUROC:0.9043\n",
      "\n",
      "Epoch: [607 | 1000] LR: 0.000083\n",
      "Train | 16/16 | Loss:0.3544 | MainLoss:0.1787 | Alpha:0.0505 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1643 | MainLoss:0.1643 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5077 | MainLoss:0.5077 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.9048\n",
      "\n",
      "Epoch: [608 | 1000] LR: 0.000082\n",
      "Train | 16/16 | Loss:0.3423 | MainLoss:0.1666 | Alpha:0.0527 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1639 | MainLoss:0.1639 | SPLoss:1.7574 | CLSLoss:0.0000 | AUROC:0.9839\n",
      "Test | 122/16 | Loss:0.5095 | MainLoss:0.5095 | SPLoss:1.7574 | CLSLoss:0.0000 | AUROC:0.9046\n",
      "\n",
      "Epoch: [609 | 1000] LR: 0.000082\n",
      "Train | 16/16 | Loss:0.3363 | MainLoss:0.1605 | Alpha:0.0542 | SPLoss:1.7574 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1638 | MainLoss:0.1638 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.9841\n",
      "Test | 122/16 | Loss:0.5105 | MainLoss:0.5105 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.9045\n",
      "\n",
      "Epoch: [610 | 1000] LR: 0.000082\n",
      "Train | 16/16 | Loss:0.3466 | MainLoss:0.1708 | Alpha:0.0520 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1639 | MainLoss:0.1639 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5102 | MainLoss:0.5102 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.9052\n",
      "\n",
      "Epoch: [611 | 1000] LR: 0.000082\n",
      "Train | 16/16 | Loss:0.3517 | MainLoss:0.1759 | Alpha:0.0513 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1647 | MainLoss:0.1647 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.9841\n",
      "Test | 122/16 | Loss:0.5074 | MainLoss:0.5074 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.9044\n",
      "\n",
      "Epoch: [612 | 1000] LR: 0.000081\n",
      "Train | 16/16 | Loss:0.3605 | MainLoss:0.1848 | Alpha:0.0518 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1639 | MainLoss:0.1639 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.9843\n",
      "Test | 122/16 | Loss:0.5094 | MainLoss:0.5094 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.9047\n",
      "\n",
      "Epoch: [613 | 1000] LR: 0.000081\n",
      "Train | 16/16 | Loss:0.3526 | MainLoss:0.1768 | Alpha:0.0512 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.9845\n",
      "Test | 122/16 | Loss:0.5075 | MainLoss:0.5075 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.9044\n",
      "\n",
      "Epoch: [614 | 1000] LR: 0.000081\n",
      "Train | 16/16 | Loss:0.3515 | MainLoss:0.1758 | Alpha:0.0517 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1644 | MainLoss:0.1644 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9841\n",
      "Test | 122/16 | Loss:0.5077 | MainLoss:0.5077 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9044\n",
      "\n",
      "Epoch: [615 | 1000] LR: 0.000080\n",
      "Train | 16/16 | Loss:0.3472 | MainLoss:0.1714 | Alpha:0.0494 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1647 | MainLoss:0.1647 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9846\n",
      "Test | 122/16 | Loss:0.5065 | MainLoss:0.5065 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9049\n",
      "\n",
      "Epoch: [616 | 1000] LR: 0.000080\n",
      "Train | 16/16 | Loss:0.3649 | MainLoss:0.1892 | Alpha:0.0516 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9841\n",
      "Test | 122/16 | Loss:0.5059 | MainLoss:0.5059 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9047\n",
      "\n",
      "Epoch: [617 | 1000] LR: 0.000080\n",
      "Train | 16/16 | Loss:0.3429 | MainLoss:0.1672 | Alpha:0.0518 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1646 | MainLoss:0.1646 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5065 | MainLoss:0.5065 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9042\n",
      "\n",
      "Epoch: [618 | 1000] LR: 0.000079\n",
      "Train | 16/16 | Loss:0.3635 | MainLoss:0.1878 | Alpha:0.0534 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1640 | MainLoss:0.1640 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9840\n",
      "Test | 122/16 | Loss:0.5076 | MainLoss:0.5076 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9048\n",
      "\n",
      "Epoch: [619 | 1000] LR: 0.000079\n",
      "Train | 16/16 | Loss:0.3440 | MainLoss:0.1683 | Alpha:0.0512 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1648 | MainLoss:0.1648 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9844\n",
      "Test | 122/16 | Loss:0.5057 | MainLoss:0.5057 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9044\n",
      "\n",
      "Epoch: [620 | 1000] LR: 0.000079\n",
      "Train | 16/16 | Loss:0.3390 | MainLoss:0.1633 | Alpha:0.0535 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1648 | MainLoss:0.1648 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9839\n",
      "Test | 122/16 | Loss:0.5065 | MainLoss:0.5065 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9042\n",
      "\n",
      "Epoch: [621 | 1000] LR: 0.000078\n",
      "Train | 16/16 | Loss:0.3442 | MainLoss:0.1685 | Alpha:0.0519 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1642 | MainLoss:0.1642 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9839\n",
      "Test | 122/16 | Loss:0.5088 | MainLoss:0.5088 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9043\n",
      "\n",
      "Epoch: [622 | 1000] LR: 0.000078\n",
      "Train | 16/16 | Loss:0.3512 | MainLoss:0.1755 | Alpha:0.0512 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1643 | MainLoss:0.1643 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.9843\n",
      "Test | 122/16 | Loss:0.5091 | MainLoss:0.5091 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.9041\n",
      "\n",
      "Epoch: [623 | 1000] LR: 0.000078\n",
      "Train | 16/16 | Loss:0.3545 | MainLoss:0.1788 | Alpha:0.0506 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1643 | MainLoss:0.1643 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.9843\n",
      "Test | 122/16 | Loss:0.5086 | MainLoss:0.5086 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.9043\n",
      "\n",
      "Epoch: [624 | 1000] LR: 0.000078\n",
      "Train | 16/16 | Loss:0.3432 | MainLoss:0.1674 | Alpha:0.0499 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1641 | MainLoss:0.1641 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.9841\n",
      "Test | 122/16 | Loss:0.5099 | MainLoss:0.5099 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.9042\n",
      "\n",
      "Epoch: [625 | 1000] LR: 0.000077\n",
      "Train | 16/16 | Loss:0.3557 | MainLoss:0.1799 | Alpha:0.0510 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1637 | MainLoss:0.1637 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.9845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 122/16 | Loss:0.5112 | MainLoss:0.5112 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.9043\n",
      "\n",
      "Epoch: [626 | 1000] LR: 0.000077\n",
      "Train | 16/16 | Loss:0.3544 | MainLoss:0.1787 | Alpha:0.0515 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1630 | MainLoss:0.1630 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9843\n",
      "Test | 122/16 | Loss:0.5133 | MainLoss:0.5133 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9045\n",
      "\n",
      "Epoch: [627 | 1000] LR: 0.000077\n",
      "Train | 16/16 | Loss:0.3371 | MainLoss:0.1613 | Alpha:0.0520 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1632 | MainLoss:0.1632 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.9843\n",
      "Test | 122/16 | Loss:0.5136 | MainLoss:0.5136 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.9044\n",
      "\n",
      "Epoch: [628 | 1000] LR: 0.000076\n",
      "Train | 16/16 | Loss:0.3295 | MainLoss:0.1538 | Alpha:0.0503 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1637 | MainLoss:0.1637 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5118 | MainLoss:0.5118 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.9046\n",
      "\n",
      "Epoch: [629 | 1000] LR: 0.000076\n",
      "Train | 16/16 | Loss:0.3469 | MainLoss:0.1712 | Alpha:0.0503 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1632 | MainLoss:0.1632 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9843\n",
      "Test | 122/16 | Loss:0.5137 | MainLoss:0.5137 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9047\n",
      "\n",
      "Epoch: [630 | 1000] LR: 0.000076\n",
      "Train | 16/16 | Loss:0.3476 | MainLoss:0.1719 | Alpha:0.0483 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1634 | MainLoss:0.1634 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5128 | MainLoss:0.5128 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9044\n",
      "\n",
      "Epoch: [631 | 1000] LR: 0.000075\n",
      "Train | 16/16 | Loss:0.3431 | MainLoss:0.1674 | Alpha:0.0493 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1628 | MainLoss:0.1628 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9841\n",
      "Test | 122/16 | Loss:0.5149 | MainLoss:0.5149 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9048\n",
      "\n",
      "Epoch: [632 | 1000] LR: 0.000075\n",
      "Train | 16/16 | Loss:0.3593 | MainLoss:0.1835 | Alpha:0.0508 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1635 | MainLoss:0.1635 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9843\n",
      "Test | 122/16 | Loss:0.5118 | MainLoss:0.5118 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9044\n",
      "\n",
      "Epoch: [633 | 1000] LR: 0.000075\n",
      "Train | 16/16 | Loss:0.3524 | MainLoss:0.1767 | Alpha:0.0509 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1639 | MainLoss:0.1639 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9841\n",
      "Test | 122/16 | Loss:0.5106 | MainLoss:0.5106 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9044\n",
      "\n",
      "Epoch: [634 | 1000] LR: 0.000075\n",
      "Train | 16/16 | Loss:0.3483 | MainLoss:0.1726 | Alpha:0.0530 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1641 | MainLoss:0.1641 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9843\n",
      "Test | 122/16 | Loss:0.5103 | MainLoss:0.5103 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9038\n",
      "\n",
      "Epoch: [635 | 1000] LR: 0.000074\n",
      "Train | 16/16 | Loss:0.3540 | MainLoss:0.1783 | Alpha:0.0491 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1643 | MainLoss:0.1643 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5097 | MainLoss:0.5097 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9035\n",
      "\n",
      "Epoch: [636 | 1000] LR: 0.000074\n",
      "Train | 16/16 | Loss:0.3380 | MainLoss:0.1623 | Alpha:0.0506 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1652 | MainLoss:0.1652 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.9844\n",
      "Test | 122/16 | Loss:0.5076 | MainLoss:0.5076 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.9034\n",
      "\n",
      "Epoch: [637 | 1000] LR: 0.000074\n",
      "Train | 16/16 | Loss:0.3459 | MainLoss:0.1701 | Alpha:0.0513 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9844\n",
      "Test | 122/16 | Loss:0.5102 | MainLoss:0.5102 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9040\n",
      "\n",
      "Epoch: [638 | 1000] LR: 0.000073\n",
      "Train | 16/16 | Loss:0.3433 | MainLoss:0.1675 | Alpha:0.0501 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1639 | MainLoss:0.1639 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9840\n",
      "Test | 122/16 | Loss:0.5124 | MainLoss:0.5124 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9037\n",
      "\n",
      "Epoch: [639 | 1000] LR: 0.000073\n",
      "Train | 16/16 | Loss:0.3588 | MainLoss:0.1831 | Alpha:0.0507 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1640 | MainLoss:0.1640 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5112 | MainLoss:0.5112 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9038\n",
      "\n",
      "Epoch: [640 | 1000] LR: 0.000073\n",
      "Train | 16/16 | Loss:0.3360 | MainLoss:0.1603 | Alpha:0.0495 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1638 | MainLoss:0.1638 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9841\n",
      "Test | 122/16 | Loss:0.5122 | MainLoss:0.5122 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9040\n",
      "\n",
      "Epoch: [641 | 1000] LR: 0.000072\n",
      "Train | 16/16 | Loss:0.3490 | MainLoss:0.1733 | Alpha:0.0530 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1639 | MainLoss:0.1639 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5122 | MainLoss:0.5122 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.9038\n",
      "\n",
      "Epoch: [642 | 1000] LR: 0.000072\n",
      "Train | 16/16 | Loss:0.3499 | MainLoss:0.1742 | Alpha:0.0512 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1640 | MainLoss:0.1640 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5118 | MainLoss:0.5118 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9038\n",
      "\n",
      "Epoch: [643 | 1000] LR: 0.000072\n",
      "Train | 16/16 | Loss:0.3508 | MainLoss:0.1750 | Alpha:0.0507 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1633 | MainLoss:0.1633 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9843\n",
      "Test | 122/16 | Loss:0.5138 | MainLoss:0.5138 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9041\n",
      "\n",
      "Epoch: [644 | 1000] LR: 0.000071\n",
      "Train | 16/16 | Loss:0.3546 | MainLoss:0.1789 | Alpha:0.0530 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1636 | MainLoss:0.1636 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9843\n",
      "Test | 122/16 | Loss:0.5120 | MainLoss:0.5120 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9040\n",
      "\n",
      "Epoch: [645 | 1000] LR: 0.000071\n",
      "Train | 16/16 | Loss:0.3432 | MainLoss:0.1675 | Alpha:0.0495 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1642 | MainLoss:0.1642 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9844\n",
      "Test | 122/16 | Loss:0.5113 | MainLoss:0.5113 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9038\n",
      "\n",
      "Epoch: [646 | 1000] LR: 0.000071\n",
      "Train | 16/16 | Loss:0.3421 | MainLoss:0.1664 | Alpha:0.0522 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1641 | MainLoss:0.1641 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5120 | MainLoss:0.5120 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9035\n",
      "\n",
      "Epoch: [647 | 1000] LR: 0.000071\n",
      "Train | 16/16 | Loss:0.3535 | MainLoss:0.1777 | Alpha:0.0515 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1642 | MainLoss:0.1642 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.9843\n",
      "Test | 122/16 | Loss:0.5121 | MainLoss:0.5121 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.9032\n",
      "\n",
      "Epoch: [648 | 1000] LR: 0.000070\n",
      "Train | 16/16 | Loss:0.3465 | MainLoss:0.1708 | Alpha:0.0522 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1643 | MainLoss:0.1643 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9845\n",
      "Test | 122/16 | Loss:0.5120 | MainLoss:0.5120 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9036\n",
      "\n",
      "Epoch: [649 | 1000] LR: 0.000070\n",
      "Train | 16/16 | Loss:0.3573 | MainLoss:0.1816 | Alpha:0.0500 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1635 | MainLoss:0.1635 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9844\n",
      "Test | 122/16 | Loss:0.5135 | MainLoss:0.5135 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9040\n",
      "\n",
      "Epoch: [650 | 1000] LR: 0.000070\n",
      "Train | 16/16 | Loss:0.3434 | MainLoss:0.1677 | Alpha:0.0497 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1646 | MainLoss:0.1646 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 122/16 | Loss:0.5099 | MainLoss:0.5099 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9033\n",
      "\n",
      "Epoch: [651 | 1000] LR: 0.000069\n",
      "Train | 16/16 | Loss:0.3466 | MainLoss:0.1708 | Alpha:0.0508 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1653 | MainLoss:0.1653 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.9846\n",
      "Test | 122/16 | Loss:0.5081 | MainLoss:0.5081 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.9033\n",
      "\n",
      "Epoch: [652 | 1000] LR: 0.000069\n",
      "Train | 16/16 | Loss:0.3423 | MainLoss:0.1666 | Alpha:0.0505 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1647 | MainLoss:0.1647 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.9840\n",
      "Test | 122/16 | Loss:0.5101 | MainLoss:0.5101 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.9034\n",
      "\n",
      "Epoch: [653 | 1000] LR: 0.000069\n",
      "Train | 16/16 | Loss:0.3540 | MainLoss:0.1783 | Alpha:0.0514 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1641 | MainLoss:0.1641 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5113 | MainLoss:0.5113 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9035\n",
      "\n",
      "Epoch: [654 | 1000] LR: 0.000069\n",
      "Train | 16/16 | Loss:0.3639 | MainLoss:0.1882 | Alpha:0.0516 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1639 | MainLoss:0.1639 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9843\n",
      "Test | 122/16 | Loss:0.5111 | MainLoss:0.5111 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9038\n",
      "\n",
      "Epoch: [655 | 1000] LR: 0.000068\n",
      "Train | 16/16 | Loss:0.3559 | MainLoss:0.1802 | Alpha:0.0528 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1642 | MainLoss:0.1642 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9844\n",
      "Test | 122/16 | Loss:0.5101 | MainLoss:0.5101 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9038\n",
      "\n",
      "Epoch: [656 | 1000] LR: 0.000068\n",
      "Train | 16/16 | Loss:0.3401 | MainLoss:0.1643 | Alpha:0.0518 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1643 | MainLoss:0.1643 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9845\n",
      "Test | 122/16 | Loss:0.5098 | MainLoss:0.5098 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9039\n",
      "\n",
      "Epoch: [657 | 1000] LR: 0.000068\n",
      "Train | 16/16 | Loss:0.3450 | MainLoss:0.1693 | Alpha:0.0498 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1636 | MainLoss:0.1636 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9840\n",
      "Test | 122/16 | Loss:0.5118 | MainLoss:0.5118 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9043\n",
      "\n",
      "Epoch: [658 | 1000] LR: 0.000067\n",
      "Train | 16/16 | Loss:0.3414 | MainLoss:0.1657 | Alpha:0.0515 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1640 | MainLoss:0.1640 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9840\n",
      "Test | 122/16 | Loss:0.5110 | MainLoss:0.5110 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9040\n",
      "\n",
      "Epoch: [659 | 1000] LR: 0.000067\n",
      "Train | 16/16 | Loss:0.3372 | MainLoss:0.1614 | Alpha:0.0505 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1647 | MainLoss:0.1647 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5093 | MainLoss:0.5093 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9037\n",
      "\n",
      "Epoch: [660 | 1000] LR: 0.000067\n",
      "Train | 16/16 | Loss:0.3532 | MainLoss:0.1775 | Alpha:0.0527 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1642 | MainLoss:0.1642 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9843\n",
      "Test | 122/16 | Loss:0.5110 | MainLoss:0.5110 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9037\n",
      "\n",
      "Epoch: [661 | 1000] LR: 0.000066\n",
      "Train | 16/16 | Loss:0.3440 | MainLoss:0.1683 | Alpha:0.0514 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1636 | MainLoss:0.1636 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9844\n",
      "Test | 122/16 | Loss:0.5135 | MainLoss:0.5135 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9039\n",
      "\n",
      "Epoch: [662 | 1000] LR: 0.000066\n",
      "Train | 16/16 | Loss:0.3557 | MainLoss:0.1800 | Alpha:0.0496 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1640 | MainLoss:0.1640 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9841\n",
      "Test | 122/16 | Loss:0.5122 | MainLoss:0.5122 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9034\n",
      "\n",
      "Epoch: [663 | 1000] LR: 0.000066\n",
      "Train | 16/16 | Loss:0.3346 | MainLoss:0.1589 | Alpha:0.0509 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1642 | MainLoss:0.1642 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9844\n",
      "Test | 122/16 | Loss:0.5122 | MainLoss:0.5122 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9037\n",
      "\n",
      "Epoch: [664 | 1000] LR: 0.000066\n",
      "Train | 16/16 | Loss:0.3419 | MainLoss:0.1662 | Alpha:0.0488 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1642 | MainLoss:0.1642 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9846\n",
      "Test | 122/16 | Loss:0.5124 | MainLoss:0.5124 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9036\n",
      "\n",
      "Epoch: [665 | 1000] LR: 0.000065\n",
      "Train | 16/16 | Loss:0.3257 | MainLoss:0.1500 | Alpha:0.0506 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1639 | MainLoss:0.1639 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9844\n",
      "Test | 122/16 | Loss:0.5139 | MainLoss:0.5139 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9040\n",
      "\n",
      "Epoch: [666 | 1000] LR: 0.000065\n",
      "Train | 16/16 | Loss:0.3435 | MainLoss:0.1678 | Alpha:0.0505 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1644 | MainLoss:0.1644 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5126 | MainLoss:0.5126 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9034\n",
      "\n",
      "Epoch: [667 | 1000] LR: 0.000065\n",
      "Train | 16/16 | Loss:0.3439 | MainLoss:0.1681 | Alpha:0.0495 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1646 | MainLoss:0.1646 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9844\n",
      "Test | 122/16 | Loss:0.5122 | MainLoss:0.5122 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9035\n",
      "\n",
      "Epoch: [668 | 1000] LR: 0.000064\n",
      "Train | 16/16 | Loss:0.3571 | MainLoss:0.1813 | Alpha:0.0520 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1644 | MainLoss:0.1644 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.9843\n",
      "Test | 122/16 | Loss:0.5128 | MainLoss:0.5128 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.9035\n",
      "\n",
      "Epoch: [669 | 1000] LR: 0.000064\n",
      "Train | 16/16 | Loss:0.3515 | MainLoss:0.1757 | Alpha:0.0522 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1643 | MainLoss:0.1643 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5129 | MainLoss:0.5129 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9038\n",
      "\n",
      "Epoch: [670 | 1000] LR: 0.000064\n",
      "Train | 16/16 | Loss:0.3468 | MainLoss:0.1711 | Alpha:0.0511 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1635 | MainLoss:0.1635 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9843\n",
      "Test | 122/16 | Loss:0.5148 | MainLoss:0.5148 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9039\n",
      "\n",
      "Epoch: [671 | 1000] LR: 0.000063\n",
      "Train | 16/16 | Loss:0.3471 | MainLoss:0.1714 | Alpha:0.0496 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1637 | MainLoss:0.1637 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9844\n",
      "Test | 122/16 | Loss:0.5142 | MainLoss:0.5142 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9038\n",
      "\n",
      "Epoch: [672 | 1000] LR: 0.000063\n",
      "Train | 16/16 | Loss:0.3367 | MainLoss:0.1609 | Alpha:0.0513 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1638 | MainLoss:0.1638 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9844\n",
      "Test | 122/16 | Loss:0.5141 | MainLoss:0.5141 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9034\n",
      "\n",
      "Epoch: [673 | 1000] LR: 0.000063\n",
      "Train | 16/16 | Loss:0.3475 | MainLoss:0.1718 | Alpha:0.0505 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1638 | MainLoss:0.1638 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5140 | MainLoss:0.5140 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9041\n",
      "\n",
      "Epoch: [674 | 1000] LR: 0.000063\n",
      "Train | 16/16 | Loss:0.3516 | MainLoss:0.1759 | Alpha:0.0518 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1639 | MainLoss:0.1639 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5141 | MainLoss:0.5141 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9035\n",
      "\n",
      "Epoch: [675 | 1000] LR: 0.000062\n",
      "Train | 16/16 | Loss:0.3377 | MainLoss:0.1619 | Alpha:0.0515 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1642 | MainLoss:0.1642 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 122/16 | Loss:0.5133 | MainLoss:0.5133 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9036\n",
      "\n",
      "Epoch: [676 | 1000] LR: 0.000062\n",
      "Train | 16/16 | Loss:0.3516 | MainLoss:0.1758 | Alpha:0.0535 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1644 | MainLoss:0.1644 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5133 | MainLoss:0.5133 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9034\n",
      "\n",
      "Epoch: [677 | 1000] LR: 0.000062\n",
      "Train | 16/16 | Loss:0.3478 | MainLoss:0.1721 | Alpha:0.0500 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1643 | MainLoss:0.1643 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9841\n",
      "Test | 122/16 | Loss:0.5132 | MainLoss:0.5132 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9035\n",
      "\n",
      "Epoch: [678 | 1000] LR: 0.000061\n",
      "Train | 16/16 | Loss:0.3481 | MainLoss:0.1724 | Alpha:0.0519 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1642 | MainLoss:0.1642 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9843\n",
      "Test | 122/16 | Loss:0.5137 | MainLoss:0.5137 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9035\n",
      "\n",
      "Epoch: [679 | 1000] LR: 0.000061\n",
      "Train | 16/16 | Loss:0.3474 | MainLoss:0.1717 | Alpha:0.0513 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1638 | MainLoss:0.1638 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9844\n",
      "Test | 122/16 | Loss:0.5152 | MainLoss:0.5152 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9037\n",
      "\n",
      "Epoch: [680 | 1000] LR: 0.000061\n",
      "Train | 16/16 | Loss:0.3535 | MainLoss:0.1778 | Alpha:0.0519 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1638 | MainLoss:0.1638 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9844\n",
      "Test | 122/16 | Loss:0.5154 | MainLoss:0.5154 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9034\n",
      "\n",
      "Epoch: [681 | 1000] LR: 0.000061\n",
      "Train | 16/16 | Loss:0.3454 | MainLoss:0.1696 | Alpha:0.0511 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1641 | MainLoss:0.1641 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9843\n",
      "Test | 122/16 | Loss:0.5150 | MainLoss:0.5150 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9033\n",
      "\n",
      "Epoch: [682 | 1000] LR: 0.000060\n",
      "Train | 16/16 | Loss:0.3422 | MainLoss:0.1665 | Alpha:0.0507 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1641 | MainLoss:0.1641 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9844\n",
      "Test | 122/16 | Loss:0.5151 | MainLoss:0.5151 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9037\n",
      "\n",
      "Epoch: [683 | 1000] LR: 0.000060\n",
      "Train | 16/16 | Loss:0.3422 | MainLoss:0.1664 | Alpha:0.0512 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1644 | MainLoss:0.1644 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.9843\n",
      "Test | 122/16 | Loss:0.5147 | MainLoss:0.5147 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.9030\n",
      "\n",
      "Epoch: [684 | 1000] LR: 0.000060\n",
      "Train | 16/16 | Loss:0.3516 | MainLoss:0.1759 | Alpha:0.0515 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1643 | MainLoss:0.1643 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9843\n",
      "Test | 122/16 | Loss:0.5150 | MainLoss:0.5150 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9032\n",
      "\n",
      "Epoch: [685 | 1000] LR: 0.000059\n",
      "Train | 16/16 | Loss:0.3451 | MainLoss:0.1694 | Alpha:0.0504 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1641 | MainLoss:0.1641 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9844\n",
      "Test | 122/16 | Loss:0.5159 | MainLoss:0.5159 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9032\n",
      "\n",
      "Epoch: [686 | 1000] LR: 0.000059\n",
      "Train | 16/16 | Loss:0.3463 | MainLoss:0.1705 | Alpha:0.0514 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1643 | MainLoss:0.1643 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5154 | MainLoss:0.5154 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9031\n",
      "\n",
      "Epoch: [687 | 1000] LR: 0.000059\n",
      "Train | 16/16 | Loss:0.3419 | MainLoss:0.1661 | Alpha:0.0507 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1644 | MainLoss:0.1644 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5156 | MainLoss:0.5156 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.9029\n",
      "\n",
      "Epoch: [688 | 1000] LR: 0.000059\n",
      "Train | 16/16 | Loss:0.3482 | MainLoss:0.1724 | Alpha:0.0502 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1646 | MainLoss:0.1646 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.9845\n",
      "Test | 122/16 | Loss:0.5150 | MainLoss:0.5150 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.9032\n",
      "\n",
      "Epoch: [689 | 1000] LR: 0.000058\n",
      "Train | 16/16 | Loss:0.3590 | MainLoss:0.1832 | Alpha:0.0519 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1646 | MainLoss:0.1646 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.9843\n",
      "Test | 122/16 | Loss:0.5149 | MainLoss:0.5149 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.9027\n",
      "\n",
      "Epoch: [690 | 1000] LR: 0.000058\n",
      "Train | 16/16 | Loss:0.3416 | MainLoss:0.1659 | Alpha:0.0500 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1647 | MainLoss:0.1647 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.9845\n",
      "Test | 122/16 | Loss:0.5151 | MainLoss:0.5151 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.9028\n",
      "\n",
      "Epoch: [691 | 1000] LR: 0.000058\n",
      "Train | 16/16 | Loss:0.3480 | MainLoss:0.1723 | Alpha:0.0508 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1637 | MainLoss:0.1637 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9844\n",
      "Test | 122/16 | Loss:0.5183 | MainLoss:0.5183 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9028\n",
      "\n",
      "Epoch: [692 | 1000] LR: 0.000057\n",
      "Train | 16/16 | Loss:0.3458 | MainLoss:0.1701 | Alpha:0.0527 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1642 | MainLoss:0.1642 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.9843\n",
      "Test | 122/16 | Loss:0.5178 | MainLoss:0.5178 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.9026\n",
      "\n",
      "Epoch: [693 | 1000] LR: 0.000057\n",
      "Train | 16/16 | Loss:0.3416 | MainLoss:0.1659 | Alpha:0.0516 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1648 | MainLoss:0.1648 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.9841\n",
      "Test | 122/16 | Loss:0.5158 | MainLoss:0.5158 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.9028\n",
      "\n",
      "Epoch: [694 | 1000] LR: 0.000057\n",
      "Train | 16/16 | Loss:0.3475 | MainLoss:0.1718 | Alpha:0.0504 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1646 | MainLoss:0.1646 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5165 | MainLoss:0.5165 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.9026\n",
      "\n",
      "Epoch: [695 | 1000] LR: 0.000057\n",
      "Train | 16/16 | Loss:0.3514 | MainLoss:0.1757 | Alpha:0.0541 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1643 | MainLoss:0.1643 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.9844\n",
      "Test | 122/16 | Loss:0.5168 | MainLoss:0.5168 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.9025\n",
      "\n",
      "Epoch: [696 | 1000] LR: 0.000056\n",
      "Train | 16/16 | Loss:0.3365 | MainLoss:0.1608 | Alpha:0.0535 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1640 | MainLoss:0.1640 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9843\n",
      "Test | 122/16 | Loss:0.5176 | MainLoss:0.5176 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9029\n",
      "\n",
      "Epoch: [697 | 1000] LR: 0.000056\n",
      "Train | 16/16 | Loss:0.3341 | MainLoss:0.1584 | Alpha:0.0502 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1643 | MainLoss:0.1643 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.9840\n",
      "Test | 122/16 | Loss:0.5175 | MainLoss:0.5175 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.9032\n",
      "\n",
      "Epoch: [698 | 1000] LR: 0.000056\n",
      "Train | 16/16 | Loss:0.3402 | MainLoss:0.1644 | Alpha:0.0504 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1641 | MainLoss:0.1641 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.9841\n",
      "Test | 122/16 | Loss:0.5184 | MainLoss:0.5184 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.9029\n",
      "\n",
      "Epoch: [699 | 1000] LR: 0.000055\n",
      "Train | 16/16 | Loss:0.3480 | MainLoss:0.1723 | Alpha:0.0496 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1637 | MainLoss:0.1637 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5198 | MainLoss:0.5198 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9032\n",
      "\n",
      "Epoch: [700 | 1000] LR: 0.000055\n",
      "Train | 16/16 | Loss:0.3435 | MainLoss:0.1678 | Alpha:0.0510 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1640 | MainLoss:0.1640 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 122/16 | Loss:0.5192 | MainLoss:0.5192 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9031\n",
      "\n",
      "Epoch: [701 | 1000] LR: 0.000055\n",
      "Train | 16/16 | Loss:0.3516 | MainLoss:0.1759 | Alpha:0.0506 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1640 | MainLoss:0.1640 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.9843\n",
      "Test | 122/16 | Loss:0.5189 | MainLoss:0.5189 | SPLoss:1.7573 | CLSLoss:0.0000 | AUROC:0.9027\n",
      "\n",
      "Epoch: [702 | 1000] LR: 0.000055\n",
      "Train | 16/16 | Loss:0.3464 | MainLoss:0.1707 | Alpha:0.0514 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1630 | MainLoss:0.1630 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5224 | MainLoss:0.5224 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9030\n",
      "\n",
      "Epoch: [703 | 1000] LR: 0.000054\n",
      "Train | 16/16 | Loss:0.3450 | MainLoss:0.1693 | Alpha:0.0506 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1628 | MainLoss:0.1628 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5234 | MainLoss:0.5234 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9032\n",
      "\n",
      "Epoch: [704 | 1000] LR: 0.000054\n",
      "Train | 16/16 | Loss:0.3357 | MainLoss:0.1600 | Alpha:0.0507 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1634 | MainLoss:0.1634 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9843\n",
      "Test | 122/16 | Loss:0.5212 | MainLoss:0.5212 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9029\n",
      "\n",
      "Epoch: [705 | 1000] LR: 0.000054\n",
      "Train | 16/16 | Loss:0.3404 | MainLoss:0.1647 | Alpha:0.0506 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1640 | MainLoss:0.1640 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9841\n",
      "Test | 122/16 | Loss:0.5199 | MainLoss:0.5199 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9029\n",
      "\n",
      "Epoch: [706 | 1000] LR: 0.000053\n",
      "Train | 16/16 | Loss:0.3388 | MainLoss:0.1631 | Alpha:0.0523 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1636 | MainLoss:0.1636 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9841\n",
      "Test | 122/16 | Loss:0.5216 | MainLoss:0.5216 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9029\n",
      "\n",
      "Epoch: [707 | 1000] LR: 0.000053\n",
      "Train | 16/16 | Loss:0.3320 | MainLoss:0.1562 | Alpha:0.0510 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1636 | MainLoss:0.1636 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5217 | MainLoss:0.5217 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9030\n",
      "\n",
      "Epoch: [708 | 1000] LR: 0.000053\n",
      "Train | 16/16 | Loss:0.3425 | MainLoss:0.1668 | Alpha:0.0509 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1638 | MainLoss:0.1638 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5211 | MainLoss:0.5211 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9026\n",
      "\n",
      "Epoch: [709 | 1000] LR: 0.000053\n",
      "Train | 16/16 | Loss:0.3428 | MainLoss:0.1671 | Alpha:0.0513 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1643 | MainLoss:0.1643 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5197 | MainLoss:0.5197 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9026\n",
      "\n",
      "Epoch: [710 | 1000] LR: 0.000052\n",
      "Train | 16/16 | Loss:0.3326 | MainLoss:0.1569 | Alpha:0.0522 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1639 | MainLoss:0.1639 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5208 | MainLoss:0.5208 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9028\n",
      "\n",
      "Epoch: [711 | 1000] LR: 0.000052\n",
      "Train | 16/16 | Loss:0.3452 | MainLoss:0.1694 | Alpha:0.0517 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1644 | MainLoss:0.1644 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9846\n",
      "Test | 122/16 | Loss:0.5189 | MainLoss:0.5189 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9029\n",
      "\n",
      "Epoch: [712 | 1000] LR: 0.000052\n",
      "Train | 16/16 | Loss:0.3484 | MainLoss:0.1727 | Alpha:0.0499 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1650 | MainLoss:0.1650 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9845\n",
      "Test | 122/16 | Loss:0.5169 | MainLoss:0.5169 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9025\n",
      "\n",
      "Epoch: [713 | 1000] LR: 0.000052\n",
      "Train | 16/16 | Loss:0.3557 | MainLoss:0.1800 | Alpha:0.0524 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1647 | MainLoss:0.1647 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9845\n",
      "Test | 122/16 | Loss:0.5171 | MainLoss:0.5171 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9028\n",
      "\n",
      "Epoch: [714 | 1000] LR: 0.000051\n",
      "Train | 16/16 | Loss:0.3461 | MainLoss:0.1704 | Alpha:0.0504 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1648 | MainLoss:0.1648 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5164 | MainLoss:0.5164 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9029\n",
      "\n",
      "Epoch: [715 | 1000] LR: 0.000051\n",
      "Train | 16/16 | Loss:0.3390 | MainLoss:0.1633 | Alpha:0.0504 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1649 | MainLoss:0.1649 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9844\n",
      "Test | 122/16 | Loss:0.5164 | MainLoss:0.5164 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9026\n",
      "\n",
      "Epoch: [716 | 1000] LR: 0.000051\n",
      "Train | 16/16 | Loss:0.3481 | MainLoss:0.1724 | Alpha:0.0507 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1652 | MainLoss:0.1652 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9846\n",
      "Test | 122/16 | Loss:0.5155 | MainLoss:0.5155 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9027\n",
      "\n",
      "Epoch: [717 | 1000] LR: 0.000050\n",
      "Train | 16/16 | Loss:0.3402 | MainLoss:0.1644 | Alpha:0.0506 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1649 | MainLoss:0.1649 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5163 | MainLoss:0.5163 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9027\n",
      "\n",
      "Epoch: [718 | 1000] LR: 0.000050\n",
      "Train | 16/16 | Loss:0.3537 | MainLoss:0.1780 | Alpha:0.0511 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1651 | MainLoss:0.1651 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9845\n",
      "Test | 122/16 | Loss:0.5154 | MainLoss:0.5154 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9027\n",
      "\n",
      "Epoch: [719 | 1000] LR: 0.000050\n",
      "Train | 16/16 | Loss:0.3399 | MainLoss:0.1642 | Alpha:0.0516 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1652 | MainLoss:0.1652 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9841\n",
      "Test | 122/16 | Loss:0.5151 | MainLoss:0.5151 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9025\n",
      "\n",
      "Epoch: [720 | 1000] LR: 0.000050\n",
      "Train | 16/16 | Loss:0.3490 | MainLoss:0.1733 | Alpha:0.0520 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1657 | MainLoss:0.1657 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9841\n",
      "Test | 122/16 | Loss:0.5141 | MainLoss:0.5141 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9025\n",
      "\n",
      "Epoch: [721 | 1000] LR: 0.000049\n",
      "Train | 16/16 | Loss:0.3471 | MainLoss:0.1714 | Alpha:0.0488 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1648 | MainLoss:0.1648 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9843\n",
      "Test | 122/16 | Loss:0.5165 | MainLoss:0.5165 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9027\n",
      "\n",
      "Epoch: [722 | 1000] LR: 0.000049\n",
      "Train | 16/16 | Loss:0.3540 | MainLoss:0.1783 | Alpha:0.0521 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1648 | MainLoss:0.1648 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9844\n",
      "Test | 122/16 | Loss:0.5167 | MainLoss:0.5167 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9026\n",
      "\n",
      "Epoch: [723 | 1000] LR: 0.000049\n",
      "Train | 16/16 | Loss:0.3361 | MainLoss:0.1604 | Alpha:0.0508 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1647 | MainLoss:0.1647 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9843\n",
      "Test | 122/16 | Loss:0.5170 | MainLoss:0.5170 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9026\n",
      "\n",
      "Epoch: [724 | 1000] LR: 0.000049\n",
      "Train | 16/16 | Loss:0.3448 | MainLoss:0.1691 | Alpha:0.0496 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1644 | MainLoss:0.1644 | SPLoss:1.7569 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5180 | MainLoss:0.5180 | SPLoss:1.7569 | CLSLoss:0.0000 | AUROC:0.9030\n",
      "\n",
      "Epoch: [725 | 1000] LR: 0.000048\n",
      "Train | 16/16 | Loss:0.3442 | MainLoss:0.1685 | Alpha:0.0517 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1650 | MainLoss:0.1650 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 122/16 | Loss:0.5165 | MainLoss:0.5165 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9025\n",
      "\n",
      "Epoch: [726 | 1000] LR: 0.000048\n",
      "Train | 16/16 | Loss:0.3551 | MainLoss:0.1794 | Alpha:0.0512 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1646 | MainLoss:0.1646 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9845\n",
      "Test | 122/16 | Loss:0.5174 | MainLoss:0.5174 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9031\n",
      "\n",
      "Epoch: [727 | 1000] LR: 0.000048\n",
      "Train | 16/16 | Loss:0.3414 | MainLoss:0.1657 | Alpha:0.0499 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1647 | MainLoss:0.1647 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9846\n",
      "Test | 122/16 | Loss:0.5173 | MainLoss:0.5173 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9023\n",
      "\n",
      "Epoch: [728 | 1000] LR: 0.000047\n",
      "Train | 16/16 | Loss:0.3474 | MainLoss:0.1717 | Alpha:0.0520 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1642 | MainLoss:0.1642 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9839\n",
      "Test | 122/16 | Loss:0.5190 | MainLoss:0.5190 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9031\n",
      "\n",
      "Epoch: [729 | 1000] LR: 0.000047\n",
      "Train | 16/16 | Loss:0.3492 | MainLoss:0.1735 | Alpha:0.0501 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1641 | MainLoss:0.1641 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9843\n",
      "Test | 122/16 | Loss:0.5197 | MainLoss:0.5197 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9029\n",
      "\n",
      "Epoch: [730 | 1000] LR: 0.000047\n",
      "Train | 16/16 | Loss:0.3395 | MainLoss:0.1638 | Alpha:0.0503 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1639 | MainLoss:0.1639 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5208 | MainLoss:0.5208 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9028\n",
      "\n",
      "Epoch: [731 | 1000] LR: 0.000047\n",
      "Train | 16/16 | Loss:0.3503 | MainLoss:0.1746 | Alpha:0.0520 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1639 | MainLoss:0.1639 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9844\n",
      "Test | 122/16 | Loss:0.5206 | MainLoss:0.5206 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9028\n",
      "\n",
      "Epoch: [732 | 1000] LR: 0.000046\n",
      "Train | 16/16 | Loss:0.3536 | MainLoss:0.1779 | Alpha:0.0511 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1636 | MainLoss:0.1636 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5219 | MainLoss:0.5219 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9031\n",
      "\n",
      "Epoch: [733 | 1000] LR: 0.000046\n",
      "Train | 16/16 | Loss:0.3414 | MainLoss:0.1657 | Alpha:0.0500 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1642 | MainLoss:0.1642 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9844\n",
      "Test | 122/16 | Loss:0.5200 | MainLoss:0.5200 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9027\n",
      "\n",
      "Epoch: [734 | 1000] LR: 0.000046\n",
      "Train | 16/16 | Loss:0.3529 | MainLoss:0.1772 | Alpha:0.0514 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1640 | MainLoss:0.1640 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9846\n",
      "Test | 122/16 | Loss:0.5209 | MainLoss:0.5209 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9029\n",
      "\n",
      "Epoch: [735 | 1000] LR: 0.000046\n",
      "Train | 16/16 | Loss:0.3387 | MainLoss:0.1630 | Alpha:0.0523 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1639 | MainLoss:0.1639 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9846\n",
      "Test | 122/16 | Loss:0.5213 | MainLoss:0.5213 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9028\n",
      "\n",
      "Epoch: [736 | 1000] LR: 0.000045\n",
      "Train | 16/16 | Loss:0.3416 | MainLoss:0.1659 | Alpha:0.0509 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1643 | MainLoss:0.1643 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9841\n",
      "Test | 122/16 | Loss:0.5202 | MainLoss:0.5202 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9025\n",
      "\n",
      "Epoch: [737 | 1000] LR: 0.000045\n",
      "Train | 16/16 | Loss:0.3376 | MainLoss:0.1619 | Alpha:0.0505 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1647 | MainLoss:0.1647 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9841\n",
      "Test | 122/16 | Loss:0.5190 | MainLoss:0.5190 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9026\n",
      "\n",
      "Epoch: [738 | 1000] LR: 0.000045\n",
      "Train | 16/16 | Loss:0.3364 | MainLoss:0.1606 | Alpha:0.0513 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1646 | MainLoss:0.1646 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9841\n",
      "Test | 122/16 | Loss:0.5195 | MainLoss:0.5195 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9025\n",
      "\n",
      "Epoch: [739 | 1000] LR: 0.000045\n",
      "Train | 16/16 | Loss:0.3491 | MainLoss:0.1734 | Alpha:0.0510 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1640 | MainLoss:0.1640 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9846\n",
      "Test | 122/16 | Loss:0.5210 | MainLoss:0.5210 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9030\n",
      "\n",
      "Epoch: [740 | 1000] LR: 0.000044\n",
      "Train | 16/16 | Loss:0.3489 | MainLoss:0.1732 | Alpha:0.0523 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1643 | MainLoss:0.1643 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9845\n",
      "Test | 122/16 | Loss:0.5198 | MainLoss:0.5198 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9027\n",
      "\n",
      "Epoch: [741 | 1000] LR: 0.000044\n",
      "Train | 16/16 | Loss:0.3428 | MainLoss:0.1671 | Alpha:0.0519 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9844\n",
      "Test | 122/16 | Loss:0.5194 | MainLoss:0.5194 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9027\n",
      "\n",
      "Epoch: [742 | 1000] LR: 0.000044\n",
      "Train | 16/16 | Loss:0.3538 | MainLoss:0.1781 | Alpha:0.0539 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1640 | MainLoss:0.1640 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9843\n",
      "Test | 122/16 | Loss:0.5210 | MainLoss:0.5210 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9024\n",
      "\n",
      "Epoch: [743 | 1000] LR: 0.000044\n",
      "Train | 16/16 | Loss:0.3457 | MainLoss:0.1700 | Alpha:0.0526 | SPLoss:1.7569 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1638 | MainLoss:0.1638 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5219 | MainLoss:0.5219 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9027\n",
      "\n",
      "Epoch: [744 | 1000] LR: 0.000043\n",
      "Train | 16/16 | Loss:0.3547 | MainLoss:0.1790 | Alpha:0.0514 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1641 | MainLoss:0.1641 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9845\n",
      "Test | 122/16 | Loss:0.5204 | MainLoss:0.5204 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9024\n",
      "\n",
      "Epoch: [745 | 1000] LR: 0.000043\n",
      "Train | 16/16 | Loss:0.3483 | MainLoss:0.1726 | Alpha:0.0520 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1644 | MainLoss:0.1644 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9843\n",
      "Test | 122/16 | Loss:0.5192 | MainLoss:0.5192 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9027\n",
      "\n",
      "Epoch: [746 | 1000] LR: 0.000043\n",
      "Train | 16/16 | Loss:0.3548 | MainLoss:0.1791 | Alpha:0.0498 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1644 | MainLoss:0.1644 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9843\n",
      "Test | 122/16 | Loss:0.5195 | MainLoss:0.5195 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9025\n",
      "\n",
      "Epoch: [747 | 1000] LR: 0.000042\n",
      "Train | 16/16 | Loss:0.3414 | MainLoss:0.1657 | Alpha:0.0507 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1643 | MainLoss:0.1643 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5197 | MainLoss:0.5197 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9027\n",
      "\n",
      "Epoch: [748 | 1000] LR: 0.000042\n",
      "Train | 16/16 | Loss:0.3418 | MainLoss:0.1661 | Alpha:0.0515 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9841\n",
      "Test | 122/16 | Loss:0.5195 | MainLoss:0.5195 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9024\n",
      "\n",
      "Epoch: [749 | 1000] LR: 0.000042\n",
      "Train | 16/16 | Loss:0.3352 | MainLoss:0.1595 | Alpha:0.0517 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1647 | MainLoss:0.1647 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9843\n",
      "Test | 122/16 | Loss:0.5191 | MainLoss:0.5191 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9025\n",
      "\n",
      "Epoch: [750 | 1000] LR: 0.000042\n",
      "Train | 16/16 | Loss:0.3504 | MainLoss:0.1747 | Alpha:0.0511 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1644 | MainLoss:0.1644 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9846\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 122/16 | Loss:0.5203 | MainLoss:0.5203 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9023\n",
      "\n",
      "Epoch: [751 | 1000] LR: 0.000041\n",
      "Train | 16/16 | Loss:0.3591 | MainLoss:0.1834 | Alpha:0.0520 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1648 | MainLoss:0.1648 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9844\n",
      "Test | 122/16 | Loss:0.5187 | MainLoss:0.5187 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9021\n",
      "\n",
      "Epoch: [752 | 1000] LR: 0.000041\n",
      "Train | 16/16 | Loss:0.3590 | MainLoss:0.1833 | Alpha:0.0518 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1649 | MainLoss:0.1649 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9843\n",
      "Test | 122/16 | Loss:0.5180 | MainLoss:0.5180 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9021\n",
      "\n",
      "Epoch: [753 | 1000] LR: 0.000041\n",
      "Train | 16/16 | Loss:0.3342 | MainLoss:0.1585 | Alpha:0.0502 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1646 | MainLoss:0.1646 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5195 | MainLoss:0.5195 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9022\n",
      "\n",
      "Epoch: [754 | 1000] LR: 0.000041\n",
      "Train | 16/16 | Loss:0.3517 | MainLoss:0.1760 | Alpha:0.0520 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9844\n",
      "Test | 122/16 | Loss:0.5200 | MainLoss:0.5200 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9021\n",
      "\n",
      "Epoch: [755 | 1000] LR: 0.000040\n",
      "Train | 16/16 | Loss:0.3381 | MainLoss:0.1624 | Alpha:0.0525 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1642 | MainLoss:0.1642 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5210 | MainLoss:0.5210 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9026\n",
      "\n",
      "Epoch: [756 | 1000] LR: 0.000040\n",
      "Train | 16/16 | Loss:0.3513 | MainLoss:0.1756 | Alpha:0.0498 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1638 | MainLoss:0.1638 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5222 | MainLoss:0.5222 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9026\n",
      "\n",
      "Epoch: [757 | 1000] LR: 0.000040\n",
      "Train | 16/16 | Loss:0.3497 | MainLoss:0.1740 | Alpha:0.0528 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1638 | MainLoss:0.1638 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9846\n",
      "Test | 122/16 | Loss:0.5222 | MainLoss:0.5222 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9029\n",
      "\n",
      "Epoch: [758 | 1000] LR: 0.000040\n",
      "Train | 16/16 | Loss:0.3558 | MainLoss:0.1801 | Alpha:0.0502 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1638 | MainLoss:0.1638 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9846\n",
      "Test | 122/16 | Loss:0.5223 | MainLoss:0.5223 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9028\n",
      "\n",
      "Epoch: [759 | 1000] LR: 0.000039\n",
      "Train | 16/16 | Loss:0.3382 | MainLoss:0.1625 | Alpha:0.0505 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1637 | MainLoss:0.1637 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9844\n",
      "Test | 122/16 | Loss:0.5225 | MainLoss:0.5225 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9023\n",
      "\n",
      "Epoch: [760 | 1000] LR: 0.000039\n",
      "Train | 16/16 | Loss:0.3483 | MainLoss:0.1726 | Alpha:0.0522 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1640 | MainLoss:0.1640 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5213 | MainLoss:0.5213 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9022\n",
      "\n",
      "Epoch: [761 | 1000] LR: 0.000039\n",
      "Train | 16/16 | Loss:0.3451 | MainLoss:0.1694 | Alpha:0.0494 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1640 | MainLoss:0.1640 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9843\n",
      "Test | 122/16 | Loss:0.5216 | MainLoss:0.5216 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9020\n",
      "\n",
      "Epoch: [762 | 1000] LR: 0.000039\n",
      "Train | 16/16 | Loss:0.3592 | MainLoss:0.1835 | Alpha:0.0525 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1638 | MainLoss:0.1638 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9845\n",
      "Test | 122/16 | Loss:0.5219 | MainLoss:0.5219 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9024\n",
      "\n",
      "Epoch: [763 | 1000] LR: 0.000038\n",
      "Train | 16/16 | Loss:0.3425 | MainLoss:0.1668 | Alpha:0.0507 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1642 | MainLoss:0.1642 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9841\n",
      "Test | 122/16 | Loss:0.5206 | MainLoss:0.5206 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9023\n",
      "\n",
      "Epoch: [764 | 1000] LR: 0.000038\n",
      "Train | 16/16 | Loss:0.3360 | MainLoss:0.1602 | Alpha:0.0499 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1643 | MainLoss:0.1643 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9841\n",
      "Test | 122/16 | Loss:0.5200 | MainLoss:0.5200 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9022\n",
      "\n",
      "Epoch: [765 | 1000] LR: 0.000038\n",
      "Train | 16/16 | Loss:0.3406 | MainLoss:0.1649 | Alpha:0.0496 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1642 | MainLoss:0.1642 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9841\n",
      "Test | 122/16 | Loss:0.5211 | MainLoss:0.5211 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9020\n",
      "\n",
      "Epoch: [766 | 1000] LR: 0.000038\n",
      "Train | 16/16 | Loss:0.3554 | MainLoss:0.1797 | Alpha:0.0518 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1644 | MainLoss:0.1644 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9843\n",
      "Test | 122/16 | Loss:0.5201 | MainLoss:0.5201 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9021\n",
      "\n",
      "Epoch: [767 | 1000] LR: 0.000037\n",
      "Train | 16/16 | Loss:0.3434 | MainLoss:0.1677 | Alpha:0.0496 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1650 | MainLoss:0.1650 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9840\n",
      "Test | 122/16 | Loss:0.5182 | MainLoss:0.5182 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9020\n",
      "\n",
      "Epoch: [768 | 1000] LR: 0.000037\n",
      "Train | 16/16 | Loss:0.3459 | MainLoss:0.1702 | Alpha:0.0508 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1646 | MainLoss:0.1646 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9844\n",
      "Test | 122/16 | Loss:0.5192 | MainLoss:0.5192 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9024\n",
      "\n",
      "Epoch: [769 | 1000] LR: 0.000037\n",
      "Train | 16/16 | Loss:0.3436 | MainLoss:0.1679 | Alpha:0.0493 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1643 | MainLoss:0.1643 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9843\n",
      "Test | 122/16 | Loss:0.5201 | MainLoss:0.5201 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9024\n",
      "\n",
      "Epoch: [770 | 1000] LR: 0.000037\n",
      "Train | 16/16 | Loss:0.3375 | MainLoss:0.1618 | Alpha:0.0500 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1646 | MainLoss:0.1646 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9845\n",
      "Test | 122/16 | Loss:0.5192 | MainLoss:0.5192 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9020\n",
      "\n",
      "Epoch: [771 | 1000] LR: 0.000036\n",
      "Train | 16/16 | Loss:0.3342 | MainLoss:0.1585 | Alpha:0.0511 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1647 | MainLoss:0.1647 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5192 | MainLoss:0.5192 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9017\n",
      "\n",
      "Epoch: [772 | 1000] LR: 0.000036\n",
      "Train | 16/16 | Loss:0.3414 | MainLoss:0.1657 | Alpha:0.0518 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1650 | MainLoss:0.1650 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9840\n",
      "Test | 122/16 | Loss:0.5185 | MainLoss:0.5185 | SPLoss:1.7572 | CLSLoss:0.0000 | AUROC:0.9022\n",
      "\n",
      "Epoch: [773 | 1000] LR: 0.000036\n",
      "Train | 16/16 | Loss:0.3500 | MainLoss:0.1743 | Alpha:0.0512 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5196 | MainLoss:0.5196 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9024\n",
      "\n",
      "Epoch: [774 | 1000] LR: 0.000036\n",
      "Train | 16/16 | Loss:0.3292 | MainLoss:0.1535 | Alpha:0.0513 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1643 | MainLoss:0.1643 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9843\n",
      "Test | 122/16 | Loss:0.5199 | MainLoss:0.5199 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9025\n",
      "\n",
      "Epoch: [775 | 1000] LR: 0.000036\n",
      "Train | 16/16 | Loss:0.3565 | MainLoss:0.1808 | Alpha:0.0500 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1642 | MainLoss:0.1642 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 122/16 | Loss:0.5198 | MainLoss:0.5198 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9021\n",
      "\n",
      "Epoch: [776 | 1000] LR: 0.000035\n",
      "Train | 16/16 | Loss:0.3455 | MainLoss:0.1698 | Alpha:0.0520 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1641 | MainLoss:0.1641 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9844\n",
      "Test | 122/16 | Loss:0.5202 | MainLoss:0.5202 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9021\n",
      "\n",
      "Epoch: [777 | 1000] LR: 0.000035\n",
      "Train | 16/16 | Loss:0.3523 | MainLoss:0.1766 | Alpha:0.0505 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1642 | MainLoss:0.1642 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9843\n",
      "Test | 122/16 | Loss:0.5198 | MainLoss:0.5198 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9021\n",
      "\n",
      "Epoch: [778 | 1000] LR: 0.000035\n",
      "Train | 16/16 | Loss:0.3473 | MainLoss:0.1716 | Alpha:0.0509 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1643 | MainLoss:0.1643 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5189 | MainLoss:0.5189 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9026\n",
      "\n",
      "Epoch: [779 | 1000] LR: 0.000035\n",
      "Train | 16/16 | Loss:0.3331 | MainLoss:0.1574 | Alpha:0.0515 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1641 | MainLoss:0.1641 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5201 | MainLoss:0.5201 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9023\n",
      "\n",
      "Epoch: [780 | 1000] LR: 0.000034\n",
      "Train | 16/16 | Loss:0.3669 | MainLoss:0.1912 | Alpha:0.0557 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1638 | MainLoss:0.1638 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9845\n",
      "Test | 122/16 | Loss:0.5210 | MainLoss:0.5210 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9021\n",
      "\n",
      "Epoch: [781 | 1000] LR: 0.000034\n",
      "Train | 16/16 | Loss:0.3419 | MainLoss:0.1662 | Alpha:0.0493 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1642 | MainLoss:0.1642 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5202 | MainLoss:0.5202 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9025\n",
      "\n",
      "Epoch: [782 | 1000] LR: 0.000034\n",
      "Train | 16/16 | Loss:0.3500 | MainLoss:0.1742 | Alpha:0.0506 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1643 | MainLoss:0.1643 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9841\n",
      "Test | 122/16 | Loss:0.5200 | MainLoss:0.5200 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9023\n",
      "\n",
      "Epoch: [783 | 1000] LR: 0.000034\n",
      "Train | 16/16 | Loss:0.3565 | MainLoss:0.1808 | Alpha:0.0502 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1642 | MainLoss:0.1642 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9843\n",
      "Test | 122/16 | Loss:0.5205 | MainLoss:0.5205 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9024\n",
      "\n",
      "Epoch: [784 | 1000] LR: 0.000033\n",
      "Train | 16/16 | Loss:0.3487 | MainLoss:0.1730 | Alpha:0.0542 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1641 | MainLoss:0.1641 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9846\n",
      "Test | 122/16 | Loss:0.5208 | MainLoss:0.5208 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9019\n",
      "\n",
      "Epoch: [785 | 1000] LR: 0.000033\n",
      "Train | 16/16 | Loss:0.3456 | MainLoss:0.1699 | Alpha:0.0500 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1643 | MainLoss:0.1643 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5204 | MainLoss:0.5204 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9020\n",
      "\n",
      "Epoch: [786 | 1000] LR: 0.000033\n",
      "Train | 16/16 | Loss:0.3477 | MainLoss:0.1720 | Alpha:0.0535 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1642 | MainLoss:0.1642 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9841\n",
      "Test | 122/16 | Loss:0.5201 | MainLoss:0.5201 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9024\n",
      "\n",
      "Epoch: [787 | 1000] LR: 0.000033\n",
      "Train | 16/16 | Loss:0.3410 | MainLoss:0.1653 | Alpha:0.0522 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1641 | MainLoss:0.1641 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9840\n",
      "Test | 122/16 | Loss:0.5203 | MainLoss:0.5203 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9021\n",
      "\n",
      "Epoch: [788 | 1000] LR: 0.000032\n",
      "Train | 16/16 | Loss:0.3375 | MainLoss:0.1618 | Alpha:0.0515 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1639 | MainLoss:0.1639 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9841\n",
      "Test | 122/16 | Loss:0.5213 | MainLoss:0.5213 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9026\n",
      "\n",
      "Epoch: [789 | 1000] LR: 0.000032\n",
      "Train | 16/16 | Loss:0.3416 | MainLoss:0.1659 | Alpha:0.0534 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1638 | MainLoss:0.1638 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9844\n",
      "Test | 122/16 | Loss:0.5217 | MainLoss:0.5217 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9022\n",
      "\n",
      "Epoch: [790 | 1000] LR: 0.000032\n",
      "Train | 16/16 | Loss:0.3441 | MainLoss:0.1684 | Alpha:0.0501 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1642 | MainLoss:0.1642 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9840\n",
      "Test | 122/16 | Loss:0.5204 | MainLoss:0.5204 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9021\n",
      "\n",
      "Epoch: [791 | 1000] LR: 0.000032\n",
      "Train | 16/16 | Loss:0.3411 | MainLoss:0.1654 | Alpha:0.0517 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9845\n",
      "Test | 122/16 | Loss:0.5192 | MainLoss:0.5192 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9021\n",
      "\n",
      "Epoch: [792 | 1000] LR: 0.000032\n",
      "Train | 16/16 | Loss:0.3352 | MainLoss:0.1595 | Alpha:0.0525 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5196 | MainLoss:0.5196 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9024\n",
      "\n",
      "Epoch: [793 | 1000] LR: 0.000031\n",
      "Train | 16/16 | Loss:0.3324 | MainLoss:0.1567 | Alpha:0.0534 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1649 | MainLoss:0.1649 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9844\n",
      "Test | 122/16 | Loss:0.5186 | MainLoss:0.5186 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9022\n",
      "\n",
      "Epoch: [794 | 1000] LR: 0.000031\n",
      "Train | 16/16 | Loss:0.3413 | MainLoss:0.1656 | Alpha:0.0494 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1651 | MainLoss:0.1651 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9843\n",
      "Test | 122/16 | Loss:0.5181 | MainLoss:0.5181 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9019\n",
      "\n",
      "Epoch: [795 | 1000] LR: 0.000031\n",
      "Train | 16/16 | Loss:0.3436 | MainLoss:0.1679 | Alpha:0.0503 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1650 | MainLoss:0.1650 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9846\n",
      "Test | 122/16 | Loss:0.5185 | MainLoss:0.5185 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9022\n",
      "\n",
      "Epoch: [796 | 1000] LR: 0.000031\n",
      "Train | 16/16 | Loss:0.3587 | MainLoss:0.1829 | Alpha:0.0496 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1647 | MainLoss:0.1647 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9843\n",
      "Test | 122/16 | Loss:0.5190 | MainLoss:0.5190 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9019\n",
      "\n",
      "Epoch: [797 | 1000] LR: 0.000030\n",
      "Train | 16/16 | Loss:0.3372 | MainLoss:0.1615 | Alpha:0.0509 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9843\n",
      "Test | 122/16 | Loss:0.5196 | MainLoss:0.5196 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9024\n",
      "\n",
      "Epoch: [798 | 1000] LR: 0.000030\n",
      "Train | 16/16 | Loss:0.3470 | MainLoss:0.1713 | Alpha:0.0490 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1651 | MainLoss:0.1651 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9844\n",
      "Test | 122/16 | Loss:0.5179 | MainLoss:0.5179 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9017\n",
      "\n",
      "Epoch: [799 | 1000] LR: 0.000030\n",
      "Train | 16/16 | Loss:0.3371 | MainLoss:0.1614 | Alpha:0.0511 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1649 | MainLoss:0.1649 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9844\n",
      "Test | 122/16 | Loss:0.5187 | MainLoss:0.5187 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9016\n",
      "\n",
      "Epoch: [800 | 1000] LR: 0.000030\n",
      "Train | 16/16 | Loss:0.3457 | MainLoss:0.1699 | Alpha:0.0502 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1651 | MainLoss:0.1651 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9846\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 122/16 | Loss:0.5184 | MainLoss:0.5184 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9020\n",
      "\n",
      "Epoch: [801 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.3487 | MainLoss:0.1730 | Alpha:0.0505 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1650 | MainLoss:0.1650 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9843\n",
      "Test | 122/16 | Loss:0.5185 | MainLoss:0.5185 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9021\n",
      "\n",
      "Epoch: [802 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.3372 | MainLoss:0.1614 | Alpha:0.0503 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1650 | MainLoss:0.1650 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9845\n",
      "Test | 122/16 | Loss:0.5186 | MainLoss:0.5186 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9022\n",
      "\n",
      "Epoch: [803 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.3386 | MainLoss:0.1629 | Alpha:0.0516 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1650 | MainLoss:0.1650 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9844\n",
      "Test | 122/16 | Loss:0.5186 | MainLoss:0.5186 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9018\n",
      "\n",
      "Epoch: [804 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.3371 | MainLoss:0.1614 | Alpha:0.0505 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1650 | MainLoss:0.1650 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9845\n",
      "Test | 122/16 | Loss:0.5188 | MainLoss:0.5188 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9017\n",
      "\n",
      "Epoch: [805 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.3377 | MainLoss:0.1619 | Alpha:0.0505 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1649 | MainLoss:0.1649 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9840\n",
      "Test | 122/16 | Loss:0.5189 | MainLoss:0.5189 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9020\n",
      "\n",
      "Epoch: [806 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.3285 | MainLoss:0.1528 | Alpha:0.0514 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1649 | MainLoss:0.1649 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9845\n",
      "Test | 122/16 | Loss:0.5189 | MainLoss:0.5189 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9019\n",
      "\n",
      "Epoch: [807 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.3417 | MainLoss:0.1659 | Alpha:0.0497 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1649 | MainLoss:0.1649 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9844\n",
      "Test | 122/16 | Loss:0.5190 | MainLoss:0.5190 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9021\n",
      "\n",
      "Epoch: [808 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.3375 | MainLoss:0.1618 | Alpha:0.0505 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1649 | MainLoss:0.1649 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5190 | MainLoss:0.5190 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9020\n",
      "\n",
      "Epoch: [809 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.3347 | MainLoss:0.1590 | Alpha:0.0518 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1649 | MainLoss:0.1649 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9843\n",
      "Test | 122/16 | Loss:0.5190 | MainLoss:0.5190 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9021\n",
      "\n",
      "Epoch: [810 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.3412 | MainLoss:0.1655 | Alpha:0.0505 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1649 | MainLoss:0.1649 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9844\n",
      "Test | 122/16 | Loss:0.5189 | MainLoss:0.5189 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9019\n",
      "\n",
      "Epoch: [811 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.3458 | MainLoss:0.1701 | Alpha:0.0505 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1649 | MainLoss:0.1649 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9845\n",
      "Test | 122/16 | Loss:0.5190 | MainLoss:0.5190 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9019\n",
      "\n",
      "Epoch: [812 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.3368 | MainLoss:0.1611 | Alpha:0.0499 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1649 | MainLoss:0.1649 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9843\n",
      "Test | 122/16 | Loss:0.5189 | MainLoss:0.5189 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9020\n",
      "\n",
      "Epoch: [813 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.3568 | MainLoss:0.1811 | Alpha:0.0510 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1650 | MainLoss:0.1650 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5188 | MainLoss:0.5188 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9018\n",
      "\n",
      "Epoch: [814 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.3512 | MainLoss:0.1755 | Alpha:0.0499 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1649 | MainLoss:0.1649 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9844\n",
      "Test | 122/16 | Loss:0.5188 | MainLoss:0.5188 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9020\n",
      "\n",
      "Epoch: [815 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.3478 | MainLoss:0.1721 | Alpha:0.0512 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1649 | MainLoss:0.1649 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9845\n",
      "Test | 122/16 | Loss:0.5188 | MainLoss:0.5188 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9020\n",
      "\n",
      "Epoch: [816 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.3440 | MainLoss:0.1683 | Alpha:0.0519 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1649 | MainLoss:0.1649 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9843\n",
      "Test | 122/16 | Loss:0.5190 | MainLoss:0.5190 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9021\n",
      "\n",
      "Epoch: [817 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.3503 | MainLoss:0.1746 | Alpha:0.0523 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1649 | MainLoss:0.1649 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9844\n",
      "Test | 122/16 | Loss:0.5190 | MainLoss:0.5190 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9019\n",
      "\n",
      "Epoch: [818 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.3435 | MainLoss:0.1678 | Alpha:0.0495 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1649 | MainLoss:0.1649 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9843\n",
      "Test | 122/16 | Loss:0.5190 | MainLoss:0.5190 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9019\n",
      "\n",
      "Epoch: [819 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.3411 | MainLoss:0.1654 | Alpha:0.0496 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1648 | MainLoss:0.1648 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9844\n",
      "Test | 122/16 | Loss:0.5192 | MainLoss:0.5192 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9020\n",
      "\n",
      "Epoch: [820 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.3414 | MainLoss:0.1656 | Alpha:0.0511 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1648 | MainLoss:0.1648 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9846\n",
      "Test | 122/16 | Loss:0.5191 | MainLoss:0.5191 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9018\n",
      "\n",
      "Epoch: [821 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.3574 | MainLoss:0.1817 | Alpha:0.0502 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1649 | MainLoss:0.1649 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5191 | MainLoss:0.5191 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9019\n",
      "\n",
      "Epoch: [822 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.3354 | MainLoss:0.1597 | Alpha:0.0510 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1649 | MainLoss:0.1649 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9844\n",
      "Test | 122/16 | Loss:0.5191 | MainLoss:0.5191 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9022\n",
      "\n",
      "Epoch: [823 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.3389 | MainLoss:0.1632 | Alpha:0.0501 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1649 | MainLoss:0.1649 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9844\n",
      "Test | 122/16 | Loss:0.5190 | MainLoss:0.5190 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9023\n",
      "\n",
      "Epoch: [824 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.3481 | MainLoss:0.1724 | Alpha:0.0501 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1649 | MainLoss:0.1649 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9845\n",
      "Test | 122/16 | Loss:0.5190 | MainLoss:0.5190 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9020\n",
      "\n",
      "Epoch: [825 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.3464 | MainLoss:0.1707 | Alpha:0.0513 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1649 | MainLoss:0.1649 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 122/16 | Loss:0.5190 | MainLoss:0.5190 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9018\n",
      "\n",
      "Epoch: [826 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.3480 | MainLoss:0.1723 | Alpha:0.0528 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1649 | MainLoss:0.1649 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9843\n",
      "Test | 122/16 | Loss:0.5190 | MainLoss:0.5190 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9022\n",
      "\n",
      "Epoch: [827 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.3389 | MainLoss:0.1632 | Alpha:0.0499 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1649 | MainLoss:0.1649 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9841\n",
      "Test | 122/16 | Loss:0.5191 | MainLoss:0.5191 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9021\n",
      "\n",
      "Epoch: [828 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.3581 | MainLoss:0.1824 | Alpha:0.0523 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1649 | MainLoss:0.1649 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5190 | MainLoss:0.5190 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9021\n",
      "\n",
      "Epoch: [829 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.3299 | MainLoss:0.1542 | Alpha:0.0518 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1649 | MainLoss:0.1649 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5190 | MainLoss:0.5190 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9020\n",
      "\n",
      "Epoch: [830 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.3484 | MainLoss:0.1727 | Alpha:0.0522 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1649 | MainLoss:0.1649 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9840\n",
      "Test | 122/16 | Loss:0.5191 | MainLoss:0.5191 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9019\n",
      "\n",
      "Epoch: [831 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.3498 | MainLoss:0.1741 | Alpha:0.0510 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1649 | MainLoss:0.1649 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9845\n",
      "Test | 122/16 | Loss:0.5190 | MainLoss:0.5190 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9018\n",
      "\n",
      "Epoch: [832 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.3596 | MainLoss:0.1839 | Alpha:0.0526 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1648 | MainLoss:0.1648 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5190 | MainLoss:0.5190 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9019\n",
      "\n",
      "Epoch: [833 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.3606 | MainLoss:0.1849 | Alpha:0.0533 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1648 | MainLoss:0.1648 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9840\n",
      "Test | 122/16 | Loss:0.5191 | MainLoss:0.5191 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9023\n",
      "\n",
      "Epoch: [834 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.3486 | MainLoss:0.1729 | Alpha:0.0495 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1648 | MainLoss:0.1648 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5190 | MainLoss:0.5190 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9017\n",
      "\n",
      "Epoch: [835 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.3516 | MainLoss:0.1759 | Alpha:0.0516 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1648 | MainLoss:0.1648 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9845\n",
      "Test | 122/16 | Loss:0.5190 | MainLoss:0.5190 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9017\n",
      "\n",
      "Epoch: [836 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.3420 | MainLoss:0.1663 | Alpha:0.0513 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1648 | MainLoss:0.1648 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9841\n",
      "Test | 122/16 | Loss:0.5190 | MainLoss:0.5190 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9020\n",
      "\n",
      "Epoch: [837 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.3491 | MainLoss:0.1734 | Alpha:0.0507 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1648 | MainLoss:0.1648 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9843\n",
      "Test | 122/16 | Loss:0.5190 | MainLoss:0.5190 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9018\n",
      "\n",
      "Epoch: [838 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.3455 | MainLoss:0.1698 | Alpha:0.0536 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1648 | MainLoss:0.1648 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9844\n",
      "Test | 122/16 | Loss:0.5190 | MainLoss:0.5190 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9020\n",
      "\n",
      "Epoch: [839 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.3523 | MainLoss:0.1766 | Alpha:0.0529 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1648 | MainLoss:0.1648 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5191 | MainLoss:0.5191 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9018\n",
      "\n",
      "Epoch: [840 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.3624 | MainLoss:0.1867 | Alpha:0.0551 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1648 | MainLoss:0.1648 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9844\n",
      "Test | 122/16 | Loss:0.5192 | MainLoss:0.5192 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9023\n",
      "\n",
      "Epoch: [841 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.3415 | MainLoss:0.1658 | Alpha:0.0512 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1648 | MainLoss:0.1648 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9843\n",
      "Test | 122/16 | Loss:0.5192 | MainLoss:0.5192 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9021\n",
      "\n",
      "Epoch: [842 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.3707 | MainLoss:0.1950 | Alpha:0.0494 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1648 | MainLoss:0.1648 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9843\n",
      "Test | 122/16 | Loss:0.5192 | MainLoss:0.5192 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9019\n",
      "\n",
      "Epoch: [843 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.3655 | MainLoss:0.1898 | Alpha:0.0525 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1648 | MainLoss:0.1648 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9844\n",
      "Test | 122/16 | Loss:0.5192 | MainLoss:0.5192 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9022\n",
      "\n",
      "Epoch: [844 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.3502 | MainLoss:0.1745 | Alpha:0.0512 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1647 | MainLoss:0.1647 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9843\n",
      "Test | 122/16 | Loss:0.5192 | MainLoss:0.5192 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9017\n",
      "\n",
      "Epoch: [845 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.3370 | MainLoss:0.1613 | Alpha:0.0515 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1647 | MainLoss:0.1647 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9840\n",
      "Test | 122/16 | Loss:0.5192 | MainLoss:0.5192 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9020\n",
      "\n",
      "Epoch: [846 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.3454 | MainLoss:0.1697 | Alpha:0.0507 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1647 | MainLoss:0.1647 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9844\n",
      "Test | 122/16 | Loss:0.5192 | MainLoss:0.5192 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9020\n",
      "\n",
      "Epoch: [847 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.3358 | MainLoss:0.1601 | Alpha:0.0514 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1647 | MainLoss:0.1647 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9843\n",
      "Test | 122/16 | Loss:0.5193 | MainLoss:0.5193 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9022\n",
      "\n",
      "Epoch: [848 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.3411 | MainLoss:0.1654 | Alpha:0.0504 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1647 | MainLoss:0.1647 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5193 | MainLoss:0.5193 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9019\n",
      "\n",
      "Epoch: [849 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.3504 | MainLoss:0.1747 | Alpha:0.0504 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1647 | MainLoss:0.1647 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9843\n",
      "Test | 122/16 | Loss:0.5193 | MainLoss:0.5193 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9021\n",
      "\n",
      "Epoch: [850 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.3584 | MainLoss:0.1827 | Alpha:0.0529 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1647 | MainLoss:0.1647 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 122/16 | Loss:0.5194 | MainLoss:0.5194 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9023\n",
      "\n",
      "Epoch: [851 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.3530 | MainLoss:0.1773 | Alpha:0.0519 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1647 | MainLoss:0.1647 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9840\n",
      "Test | 122/16 | Loss:0.5194 | MainLoss:0.5194 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9022\n",
      "\n",
      "Epoch: [852 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.3440 | MainLoss:0.1683 | Alpha:0.0505 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1647 | MainLoss:0.1647 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5194 | MainLoss:0.5194 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9022\n",
      "\n",
      "Epoch: [853 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.3487 | MainLoss:0.1729 | Alpha:0.0493 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1647 | MainLoss:0.1647 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9841\n",
      "Test | 122/16 | Loss:0.5194 | MainLoss:0.5194 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9021\n",
      "\n",
      "Epoch: [854 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.3412 | MainLoss:0.1655 | Alpha:0.0505 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1647 | MainLoss:0.1647 | SPLoss:1.7571 | CLSLoss:0.0000 | AUROC:0.9846\n",
      "Test | 122/16 | Loss:0.5195 | MainLoss:0.5195 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9022\n",
      "\n",
      "Epoch: [855 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.3441 | MainLoss:0.1684 | Alpha:0.0500 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1647 | MainLoss:0.1647 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5195 | MainLoss:0.5195 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9023\n",
      "\n",
      "Epoch: [856 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.3525 | MainLoss:0.1768 | Alpha:0.0528 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1646 | MainLoss:0.1646 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5195 | MainLoss:0.5195 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9026\n",
      "\n",
      "Epoch: [857 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.3458 | MainLoss:0.1701 | Alpha:0.0504 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1647 | MainLoss:0.1647 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9843\n",
      "Test | 122/16 | Loss:0.5195 | MainLoss:0.5195 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9022\n",
      "\n",
      "Epoch: [858 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.3439 | MainLoss:0.1682 | Alpha:0.0492 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1646 | MainLoss:0.1646 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9844\n",
      "Test | 122/16 | Loss:0.5196 | MainLoss:0.5196 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9021\n",
      "\n",
      "Epoch: [859 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.3382 | MainLoss:0.1625 | Alpha:0.0517 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1646 | MainLoss:0.1646 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5196 | MainLoss:0.5196 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9023\n",
      "\n",
      "Epoch: [860 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.3513 | MainLoss:0.1755 | Alpha:0.0510 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1646 | MainLoss:0.1646 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5195 | MainLoss:0.5195 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9022\n",
      "\n",
      "Epoch: [861 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.3515 | MainLoss:0.1758 | Alpha:0.0504 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1646 | MainLoss:0.1646 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9845\n",
      "Test | 122/16 | Loss:0.5196 | MainLoss:0.5196 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9019\n",
      "\n",
      "Epoch: [862 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.3588 | MainLoss:0.1831 | Alpha:0.0519 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1646 | MainLoss:0.1646 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9845\n",
      "Test | 122/16 | Loss:0.5195 | MainLoss:0.5195 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9021\n",
      "\n",
      "Epoch: [863 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.3560 | MainLoss:0.1803 | Alpha:0.0500 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1646 | MainLoss:0.1646 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5195 | MainLoss:0.5195 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9022\n",
      "\n",
      "Epoch: [864 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.3452 | MainLoss:0.1695 | Alpha:0.0518 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1646 | MainLoss:0.1646 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5195 | MainLoss:0.5195 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9023\n",
      "\n",
      "Epoch: [865 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.3343 | MainLoss:0.1586 | Alpha:0.0503 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1646 | MainLoss:0.1646 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5196 | MainLoss:0.5196 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9018\n",
      "\n",
      "Epoch: [866 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.3521 | MainLoss:0.1764 | Alpha:0.0538 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1646 | MainLoss:0.1646 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9843\n",
      "Test | 122/16 | Loss:0.5196 | MainLoss:0.5196 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9020\n",
      "\n",
      "Epoch: [867 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.3434 | MainLoss:0.1677 | Alpha:0.0522 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1646 | MainLoss:0.1646 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9844\n",
      "Test | 122/16 | Loss:0.5196 | MainLoss:0.5196 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9020\n",
      "\n",
      "Epoch: [868 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.3531 | MainLoss:0.1774 | Alpha:0.0531 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1646 | MainLoss:0.1646 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9846\n",
      "Test | 122/16 | Loss:0.5196 | MainLoss:0.5196 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9023\n",
      "\n",
      "Epoch: [869 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.3541 | MainLoss:0.1784 | Alpha:0.0509 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1646 | MainLoss:0.1646 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5196 | MainLoss:0.5196 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9021\n",
      "\n",
      "Epoch: [870 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.3364 | MainLoss:0.1607 | Alpha:0.0519 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1646 | MainLoss:0.1646 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5196 | MainLoss:0.5196 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9022\n",
      "\n",
      "Epoch: [871 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.3412 | MainLoss:0.1655 | Alpha:0.0507 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1646 | MainLoss:0.1646 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9844\n",
      "Test | 122/16 | Loss:0.5197 | MainLoss:0.5197 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9021\n",
      "\n",
      "Epoch: [872 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.3355 | MainLoss:0.1598 | Alpha:0.0531 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1646 | MainLoss:0.1646 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9846\n",
      "Test | 122/16 | Loss:0.5197 | MainLoss:0.5197 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9020\n",
      "\n",
      "Epoch: [873 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.3486 | MainLoss:0.1729 | Alpha:0.0529 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9841\n",
      "Test | 122/16 | Loss:0.5197 | MainLoss:0.5197 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9023\n",
      "\n",
      "Epoch: [874 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.3591 | MainLoss:0.1834 | Alpha:0.0526 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9845\n",
      "Test | 122/16 | Loss:0.5198 | MainLoss:0.5198 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9022\n",
      "\n",
      "Epoch: [875 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.3375 | MainLoss:0.1618 | Alpha:0.0500 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 122/16 | Loss:0.5198 | MainLoss:0.5198 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9023\n",
      "\n",
      "Epoch: [876 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.3492 | MainLoss:0.1735 | Alpha:0.0509 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5198 | MainLoss:0.5198 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9022\n",
      "\n",
      "Epoch: [877 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.3586 | MainLoss:0.1829 | Alpha:0.0531 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9843\n",
      "Test | 122/16 | Loss:0.5199 | MainLoss:0.5199 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9026\n",
      "\n",
      "Epoch: [878 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.3338 | MainLoss:0.1581 | Alpha:0.0522 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9843\n",
      "Test | 122/16 | Loss:0.5198 | MainLoss:0.5198 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9022\n",
      "\n",
      "Epoch: [879 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.3448 | MainLoss:0.1691 | Alpha:0.0520 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9844\n",
      "Test | 122/16 | Loss:0.5199 | MainLoss:0.5199 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9021\n",
      "\n",
      "Epoch: [880 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.3390 | MainLoss:0.1633 | Alpha:0.0498 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5198 | MainLoss:0.5198 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9019\n",
      "\n",
      "Epoch: [881 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.3561 | MainLoss:0.1804 | Alpha:0.0525 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9845\n",
      "Test | 122/16 | Loss:0.5198 | MainLoss:0.5198 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9021\n",
      "\n",
      "Epoch: [882 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.3424 | MainLoss:0.1667 | Alpha:0.0523 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5199 | MainLoss:0.5199 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9022\n",
      "\n",
      "Epoch: [883 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.3513 | MainLoss:0.1756 | Alpha:0.0543 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9843\n",
      "Test | 122/16 | Loss:0.5199 | MainLoss:0.5199 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9024\n",
      "\n",
      "Epoch: [884 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.3492 | MainLoss:0.1735 | Alpha:0.0523 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9844\n",
      "Test | 122/16 | Loss:0.5199 | MainLoss:0.5199 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9023\n",
      "\n",
      "Epoch: [885 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.3388 | MainLoss:0.1631 | Alpha:0.0522 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5199 | MainLoss:0.5199 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9023\n",
      "\n",
      "Epoch: [886 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.3363 | MainLoss:0.1606 | Alpha:0.0503 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5199 | MainLoss:0.5199 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9022\n",
      "\n",
      "Epoch: [887 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.3548 | MainLoss:0.1791 | Alpha:0.0512 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9843\n",
      "Test | 122/16 | Loss:0.5199 | MainLoss:0.5199 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9022\n",
      "\n",
      "Epoch: [888 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.3536 | MainLoss:0.1779 | Alpha:0.0517 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5199 | MainLoss:0.5199 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9022\n",
      "\n",
      "Epoch: [889 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.3578 | MainLoss:0.1821 | Alpha:0.0511 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5199 | MainLoss:0.5199 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9023\n",
      "\n",
      "Epoch: [890 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.3439 | MainLoss:0.1682 | Alpha:0.0529 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5199 | MainLoss:0.5199 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9021\n",
      "\n",
      "Epoch: [891 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.3501 | MainLoss:0.1744 | Alpha:0.0522 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5199 | MainLoss:0.5199 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9020\n",
      "\n",
      "Epoch: [892 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.3376 | MainLoss:0.1619 | Alpha:0.0522 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9846\n",
      "Test | 122/16 | Loss:0.5199 | MainLoss:0.5199 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9020\n",
      "\n",
      "Epoch: [893 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.3374 | MainLoss:0.1617 | Alpha:0.0524 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9843\n",
      "Test | 122/16 | Loss:0.5199 | MainLoss:0.5199 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9027\n",
      "\n",
      "Epoch: [894 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.3501 | MainLoss:0.1744 | Alpha:0.0513 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9844\n",
      "Test | 122/16 | Loss:0.5199 | MainLoss:0.5199 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9024\n",
      "\n",
      "Epoch: [895 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.3497 | MainLoss:0.1740 | Alpha:0.0524 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5199 | MainLoss:0.5199 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9026\n",
      "\n",
      "Epoch: [896 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.3503 | MainLoss:0.1746 | Alpha:0.0512 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9840\n",
      "Test | 122/16 | Loss:0.5199 | MainLoss:0.5199 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9020\n",
      "\n",
      "Epoch: [897 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.3390 | MainLoss:0.1633 | Alpha:0.0499 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9843\n",
      "Test | 122/16 | Loss:0.5199 | MainLoss:0.5199 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9021\n",
      "\n",
      "Epoch: [898 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.3526 | MainLoss:0.1769 | Alpha:0.0504 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5199 | MainLoss:0.5199 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9023\n",
      "\n",
      "Epoch: [899 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.3554 | MainLoss:0.1797 | Alpha:0.0494 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9845\n",
      "Test | 122/16 | Loss:0.5199 | MainLoss:0.5199 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9022\n",
      "\n",
      "Epoch: [900 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.3527 | MainLoss:0.1770 | Alpha:0.0511 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9840\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 122/16 | Loss:0.5199 | MainLoss:0.5199 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9021\n",
      "\n",
      "Epoch: [901 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.3632 | MainLoss:0.1875 | Alpha:0.0507 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9844\n",
      "Test | 122/16 | Loss:0.5199 | MainLoss:0.5199 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9020\n",
      "\n",
      "Epoch: [902 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.3518 | MainLoss:0.1761 | Alpha:0.0504 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5199 | MainLoss:0.5199 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9021\n",
      "\n",
      "Epoch: [903 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.3547 | MainLoss:0.1790 | Alpha:0.0520 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9841\n",
      "Test | 122/16 | Loss:0.5199 | MainLoss:0.5199 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9019\n",
      "\n",
      "Epoch: [904 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.3528 | MainLoss:0.1771 | Alpha:0.0512 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5199 | MainLoss:0.5199 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9022\n",
      "\n",
      "Epoch: [905 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.3420 | MainLoss:0.1663 | Alpha:0.0496 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5199 | MainLoss:0.5199 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9021\n",
      "\n",
      "Epoch: [906 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.3388 | MainLoss:0.1631 | Alpha:0.0502 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9847\n",
      "Test | 122/16 | Loss:0.5199 | MainLoss:0.5199 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9017\n",
      "\n",
      "Epoch: [907 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.3405 | MainLoss:0.1648 | Alpha:0.0488 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9841\n",
      "Test | 122/16 | Loss:0.5199 | MainLoss:0.5199 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9021\n",
      "\n",
      "Epoch: [908 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.3534 | MainLoss:0.1777 | Alpha:0.0487 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9840\n",
      "Test | 122/16 | Loss:0.5199 | MainLoss:0.5199 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9021\n",
      "\n",
      "Epoch: [909 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.3310 | MainLoss:0.1553 | Alpha:0.0509 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9841\n",
      "Test | 122/16 | Loss:0.5199 | MainLoss:0.5199 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9021\n",
      "\n",
      "Epoch: [910 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.3470 | MainLoss:0.1713 | Alpha:0.0516 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9845\n",
      "Test | 122/16 | Loss:0.5199 | MainLoss:0.5199 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9023\n",
      "\n",
      "Epoch: [911 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.3529 | MainLoss:0.1772 | Alpha:0.0499 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9844\n",
      "Test | 122/16 | Loss:0.5199 | MainLoss:0.5199 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9024\n",
      "\n",
      "Epoch: [912 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.3371 | MainLoss:0.1614 | Alpha:0.0494 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5199 | MainLoss:0.5199 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9023\n",
      "\n",
      "Epoch: [913 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.3562 | MainLoss:0.1805 | Alpha:0.0514 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9844\n",
      "Test | 122/16 | Loss:0.5199 | MainLoss:0.5199 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9024\n",
      "\n",
      "Epoch: [914 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.3440 | MainLoss:0.1682 | Alpha:0.0494 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9843\n",
      "Test | 122/16 | Loss:0.5199 | MainLoss:0.5199 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9023\n",
      "\n",
      "Epoch: [915 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.3470 | MainLoss:0.1713 | Alpha:0.0514 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9844\n",
      "Test | 122/16 | Loss:0.5199 | MainLoss:0.5199 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9022\n",
      "\n",
      "Epoch: [916 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.3629 | MainLoss:0.1872 | Alpha:0.0528 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9844\n",
      "Test | 122/16 | Loss:0.5199 | MainLoss:0.5199 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9021\n",
      "\n",
      "Epoch: [917 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.3293 | MainLoss:0.1536 | Alpha:0.0495 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9841\n",
      "Test | 122/16 | Loss:0.5199 | MainLoss:0.5199 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9021\n",
      "\n",
      "Epoch: [918 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.3475 | MainLoss:0.1718 | Alpha:0.0502 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9845\n",
      "Test | 122/16 | Loss:0.5199 | MainLoss:0.5199 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9024\n",
      "\n",
      "Epoch: [919 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.3472 | MainLoss:0.1715 | Alpha:0.0511 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9843\n",
      "Test | 122/16 | Loss:0.5199 | MainLoss:0.5199 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9021\n",
      "\n",
      "Epoch: [920 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.3465 | MainLoss:0.1708 | Alpha:0.0500 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5199 | MainLoss:0.5199 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9021\n",
      "\n",
      "Epoch: [921 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.3616 | MainLoss:0.1859 | Alpha:0.0493 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9844\n",
      "Test | 122/16 | Loss:0.5199 | MainLoss:0.5199 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9022\n",
      "\n",
      "Epoch: [922 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.3401 | MainLoss:0.1644 | Alpha:0.0507 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9845\n",
      "Test | 122/16 | Loss:0.5199 | MainLoss:0.5199 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9021\n",
      "\n",
      "Epoch: [923 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.3557 | MainLoss:0.1800 | Alpha:0.0516 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9841\n",
      "Test | 122/16 | Loss:0.5199 | MainLoss:0.5199 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9021\n",
      "\n",
      "Epoch: [924 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.3379 | MainLoss:0.1622 | Alpha:0.0514 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9845\n",
      "Test | 122/16 | Loss:0.5199 | MainLoss:0.5199 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9026\n",
      "\n",
      "Epoch: [925 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.3456 | MainLoss:0.1699 | Alpha:0.0511 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 122/16 | Loss:0.5199 | MainLoss:0.5199 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9021\n",
      "\n",
      "Epoch: [926 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.3455 | MainLoss:0.1698 | Alpha:0.0493 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9844\n",
      "Test | 122/16 | Loss:0.5199 | MainLoss:0.5199 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9022\n",
      "\n",
      "Epoch: [927 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.3392 | MainLoss:0.1635 | Alpha:0.0516 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9844\n",
      "Test | 122/16 | Loss:0.5199 | MainLoss:0.5199 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9024\n",
      "\n",
      "Epoch: [928 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.3376 | MainLoss:0.1619 | Alpha:0.0519 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9843\n",
      "Test | 122/16 | Loss:0.5199 | MainLoss:0.5199 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9019\n",
      "\n",
      "Epoch: [929 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.3434 | MainLoss:0.1677 | Alpha:0.0495 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9846\n",
      "Test | 122/16 | Loss:0.5199 | MainLoss:0.5199 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9025\n",
      "\n",
      "Epoch: [930 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.3614 | MainLoss:0.1857 | Alpha:0.0511 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9843\n",
      "Test | 122/16 | Loss:0.5199 | MainLoss:0.5199 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9019\n",
      "\n",
      "Epoch: [931 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.3401 | MainLoss:0.1644 | Alpha:0.0511 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9844\n",
      "Test | 122/16 | Loss:0.5199 | MainLoss:0.5199 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9023\n",
      "\n",
      "Epoch: [932 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.3591 | MainLoss:0.1834 | Alpha:0.0511 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9843\n",
      "Test | 122/16 | Loss:0.5199 | MainLoss:0.5199 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9020\n",
      "\n",
      "Epoch: [933 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.3515 | MainLoss:0.1758 | Alpha:0.0505 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9841\n",
      "Test | 122/16 | Loss:0.5199 | MainLoss:0.5199 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9019\n",
      "\n",
      "Epoch: [934 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.3460 | MainLoss:0.1703 | Alpha:0.0514 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9846\n",
      "Test | 122/16 | Loss:0.5199 | MainLoss:0.5199 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9023\n",
      "\n",
      "Epoch: [935 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.3407 | MainLoss:0.1650 | Alpha:0.0508 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9843\n",
      "Test | 122/16 | Loss:0.5199 | MainLoss:0.5199 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9022\n",
      "\n",
      "Epoch: [936 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.3441 | MainLoss:0.1684 | Alpha:0.0513 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9844\n",
      "Test | 122/16 | Loss:0.5199 | MainLoss:0.5199 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9024\n",
      "\n",
      "Epoch: [937 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.3574 | MainLoss:0.1817 | Alpha:0.0500 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9846\n",
      "Test | 122/16 | Loss:0.5199 | MainLoss:0.5199 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9024\n",
      "\n",
      "Epoch: [938 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.3365 | MainLoss:0.1608 | Alpha:0.0491 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9845\n",
      "Test | 122/16 | Loss:0.5199 | MainLoss:0.5199 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9022\n",
      "\n",
      "Epoch: [939 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.3475 | MainLoss:0.1718 | Alpha:0.0515 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9845\n",
      "Test | 122/16 | Loss:0.5199 | MainLoss:0.5199 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9024\n",
      "\n",
      "Epoch: [940 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.3467 | MainLoss:0.1710 | Alpha:0.0477 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9840\n",
      "Test | 122/16 | Loss:0.5200 | MainLoss:0.5200 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9019\n",
      "\n",
      "Epoch: [941 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.3491 | MainLoss:0.1734 | Alpha:0.0505 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5200 | MainLoss:0.5200 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9023\n",
      "\n",
      "Epoch: [942 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.3489 | MainLoss:0.1732 | Alpha:0.0499 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9843\n",
      "Test | 122/16 | Loss:0.5199 | MainLoss:0.5199 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9021\n",
      "\n",
      "Epoch: [943 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.3459 | MainLoss:0.1702 | Alpha:0.0495 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9841\n",
      "Test | 122/16 | Loss:0.5199 | MainLoss:0.5199 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9022\n",
      "\n",
      "Epoch: [944 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.3491 | MainLoss:0.1734 | Alpha:0.0512 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9844\n",
      "Test | 122/16 | Loss:0.5200 | MainLoss:0.5200 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9020\n",
      "\n",
      "Epoch: [945 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.3606 | MainLoss:0.1849 | Alpha:0.0517 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9843\n",
      "Test | 122/16 | Loss:0.5199 | MainLoss:0.5199 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9022\n",
      "\n",
      "Epoch: [946 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.3406 | MainLoss:0.1649 | Alpha:0.0522 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9843\n",
      "Test | 122/16 | Loss:0.5199 | MainLoss:0.5199 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9023\n",
      "\n",
      "Epoch: [947 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.3467 | MainLoss:0.1710 | Alpha:0.0491 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9844\n",
      "Test | 122/16 | Loss:0.5199 | MainLoss:0.5199 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9023\n",
      "\n",
      "Epoch: [948 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.3409 | MainLoss:0.1652 | Alpha:0.0506 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5199 | MainLoss:0.5199 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9023\n",
      "\n",
      "Epoch: [949 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.3503 | MainLoss:0.1746 | Alpha:0.0515 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1644 | MainLoss:0.1644 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9841\n",
      "Test | 122/16 | Loss:0.5200 | MainLoss:0.5200 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9020\n",
      "\n",
      "Epoch: [950 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.3430 | MainLoss:0.1673 | Alpha:0.0511 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1644 | MainLoss:0.1644 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9841\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 122/16 | Loss:0.5200 | MainLoss:0.5200 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9023\n",
      "\n",
      "Epoch: [951 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.3468 | MainLoss:0.1711 | Alpha:0.0506 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1644 | MainLoss:0.1644 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9847\n",
      "Test | 122/16 | Loss:0.5200 | MainLoss:0.5200 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9022\n",
      "\n",
      "Epoch: [952 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.3464 | MainLoss:0.1707 | Alpha:0.0521 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1644 | MainLoss:0.1644 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5200 | MainLoss:0.5200 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9022\n",
      "\n",
      "Epoch: [953 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.3385 | MainLoss:0.1628 | Alpha:0.0492 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1644 | MainLoss:0.1644 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5200 | MainLoss:0.5200 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9023\n",
      "\n",
      "Epoch: [954 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.3460 | MainLoss:0.1703 | Alpha:0.0493 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1644 | MainLoss:0.1644 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9844\n",
      "Test | 122/16 | Loss:0.5200 | MainLoss:0.5200 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9024\n",
      "\n",
      "Epoch: [955 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.3459 | MainLoss:0.1702 | Alpha:0.0495 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1644 | MainLoss:0.1644 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9841\n",
      "Test | 122/16 | Loss:0.5200 | MainLoss:0.5200 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9024\n",
      "\n",
      "Epoch: [956 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.3533 | MainLoss:0.1776 | Alpha:0.0504 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1644 | MainLoss:0.1644 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9841\n",
      "Test | 122/16 | Loss:0.5200 | MainLoss:0.5200 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9022\n",
      "\n",
      "Epoch: [957 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.3495 | MainLoss:0.1738 | Alpha:0.0508 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1644 | MainLoss:0.1644 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5200 | MainLoss:0.5200 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9023\n",
      "\n",
      "Epoch: [958 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.3429 | MainLoss:0.1672 | Alpha:0.0507 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1644 | MainLoss:0.1644 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9845\n",
      "Test | 122/16 | Loss:0.5200 | MainLoss:0.5200 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9024\n",
      "\n",
      "Epoch: [959 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.3448 | MainLoss:0.1691 | Alpha:0.0511 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1644 | MainLoss:0.1644 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9841\n",
      "Test | 122/16 | Loss:0.5200 | MainLoss:0.5200 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9024\n",
      "\n",
      "Epoch: [960 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.3419 | MainLoss:0.1662 | Alpha:0.0524 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1644 | MainLoss:0.1644 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9843\n",
      "Test | 122/16 | Loss:0.5200 | MainLoss:0.5200 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9021\n",
      "\n",
      "Epoch: [961 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.3282 | MainLoss:0.1525 | Alpha:0.0512 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9841\n",
      "Test | 122/16 | Loss:0.5200 | MainLoss:0.5200 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9021\n",
      "\n",
      "Epoch: [962 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.3476 | MainLoss:0.1719 | Alpha:0.0502 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9841\n",
      "Test | 122/16 | Loss:0.5200 | MainLoss:0.5200 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9020\n",
      "\n",
      "Epoch: [963 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.3431 | MainLoss:0.1674 | Alpha:0.0506 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5200 | MainLoss:0.5200 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9019\n",
      "\n",
      "Epoch: [964 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.3485 | MainLoss:0.1728 | Alpha:0.0531 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1644 | MainLoss:0.1644 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9846\n",
      "Test | 122/16 | Loss:0.5200 | MainLoss:0.5200 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9021\n",
      "\n",
      "Epoch: [965 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.3427 | MainLoss:0.1670 | Alpha:0.0538 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9843\n",
      "Test | 122/16 | Loss:0.5200 | MainLoss:0.5200 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9021\n",
      "\n",
      "Epoch: [966 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.3360 | MainLoss:0.1603 | Alpha:0.0505 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9843\n",
      "Test | 122/16 | Loss:0.5200 | MainLoss:0.5200 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9022\n",
      "\n",
      "Epoch: [967 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.3309 | MainLoss:0.1552 | Alpha:0.0500 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9843\n",
      "Test | 122/16 | Loss:0.5200 | MainLoss:0.5200 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9023\n",
      "\n",
      "Epoch: [968 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.3536 | MainLoss:0.1779 | Alpha:0.0523 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9844\n",
      "Test | 122/16 | Loss:0.5200 | MainLoss:0.5200 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9020\n",
      "\n",
      "Epoch: [969 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.3413 | MainLoss:0.1656 | Alpha:0.0516 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9844\n",
      "Test | 122/16 | Loss:0.5200 | MainLoss:0.5200 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9021\n",
      "\n",
      "Epoch: [970 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.3385 | MainLoss:0.1628 | Alpha:0.0545 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5200 | MainLoss:0.5200 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9020\n",
      "\n",
      "Epoch: [971 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.3661 | MainLoss:0.1904 | Alpha:0.0513 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9845\n",
      "Test | 122/16 | Loss:0.5200 | MainLoss:0.5200 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9023\n",
      "\n",
      "Epoch: [972 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.3422 | MainLoss:0.1665 | Alpha:0.0520 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9845\n",
      "Test | 122/16 | Loss:0.5200 | MainLoss:0.5200 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9019\n",
      "\n",
      "Epoch: [973 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.3597 | MainLoss:0.1840 | Alpha:0.0529 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5200 | MainLoss:0.5200 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9023\n",
      "\n",
      "Epoch: [974 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.3440 | MainLoss:0.1683 | Alpha:0.0511 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1644 | MainLoss:0.1644 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5200 | MainLoss:0.5200 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9022\n",
      "\n",
      "Epoch: [975 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.3499 | MainLoss:0.1742 | Alpha:0.0526 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 122/16 | Loss:0.5200 | MainLoss:0.5200 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9022\n",
      "\n",
      "Epoch: [976 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.3372 | MainLoss:0.1615 | Alpha:0.0493 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9841\n",
      "Test | 122/16 | Loss:0.5200 | MainLoss:0.5200 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9021\n",
      "\n",
      "Epoch: [977 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.3288 | MainLoss:0.1531 | Alpha:0.0498 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9839\n",
      "Test | 122/16 | Loss:0.5200 | MainLoss:0.5200 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9023\n",
      "\n",
      "Epoch: [978 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.3629 | MainLoss:0.1872 | Alpha:0.0488 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9839\n",
      "Test | 122/16 | Loss:0.5200 | MainLoss:0.5200 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9022\n",
      "\n",
      "Epoch: [979 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.3343 | MainLoss:0.1586 | Alpha:0.0505 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5200 | MainLoss:0.5200 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9023\n",
      "\n",
      "Epoch: [980 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.3537 | MainLoss:0.1780 | Alpha:0.0510 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5200 | MainLoss:0.5200 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9025\n",
      "\n",
      "Epoch: [981 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.3477 | MainLoss:0.1720 | Alpha:0.0518 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5200 | MainLoss:0.5200 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9026\n",
      "\n",
      "Epoch: [982 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.3585 | MainLoss:0.1828 | Alpha:0.0523 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5200 | MainLoss:0.5200 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9020\n",
      "\n",
      "Epoch: [983 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.3480 | MainLoss:0.1723 | Alpha:0.0505 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9843\n",
      "Test | 122/16 | Loss:0.5200 | MainLoss:0.5200 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9022\n",
      "\n",
      "Epoch: [984 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.3441 | MainLoss:0.1684 | Alpha:0.0507 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9843\n",
      "Test | 122/16 | Loss:0.5200 | MainLoss:0.5200 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9021\n",
      "\n",
      "Epoch: [985 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.3474 | MainLoss:0.1717 | Alpha:0.0520 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5200 | MainLoss:0.5200 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9023\n",
      "\n",
      "Epoch: [986 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.3462 | MainLoss:0.1705 | Alpha:0.0514 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5200 | MainLoss:0.5200 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9021\n",
      "\n",
      "Epoch: [987 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.3481 | MainLoss:0.1724 | Alpha:0.0512 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9843\n",
      "Test | 122/16 | Loss:0.5200 | MainLoss:0.5200 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9019\n",
      "\n",
      "Epoch: [988 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.3544 | MainLoss:0.1787 | Alpha:0.0501 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9841\n",
      "Test | 122/16 | Loss:0.5200 | MainLoss:0.5200 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9022\n",
      "\n",
      "Epoch: [989 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.3483 | MainLoss:0.1726 | Alpha:0.0500 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9847\n",
      "Test | 122/16 | Loss:0.5200 | MainLoss:0.5200 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9027\n",
      "\n",
      "Epoch: [990 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.3390 | MainLoss:0.1633 | Alpha:0.0511 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9843\n",
      "Test | 122/16 | Loss:0.5200 | MainLoss:0.5200 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9022\n",
      "\n",
      "Epoch: [991 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.3572 | MainLoss:0.1815 | Alpha:0.0526 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9843\n",
      "Test | 122/16 | Loss:0.5200 | MainLoss:0.5200 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9021\n",
      "\n",
      "Epoch: [992 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.3517 | MainLoss:0.1760 | Alpha:0.0527 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5200 | MainLoss:0.5200 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9022\n",
      "\n",
      "Epoch: [993 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.3442 | MainLoss:0.1685 | Alpha:0.0523 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9845\n",
      "Test | 122/16 | Loss:0.5200 | MainLoss:0.5200 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9019\n",
      "\n",
      "Epoch: [994 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.3338 | MainLoss:0.1581 | Alpha:0.0498 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1644 | MainLoss:0.1644 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9841\n",
      "Test | 122/16 | Loss:0.5200 | MainLoss:0.5200 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9022\n",
      "\n",
      "Epoch: [995 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.3419 | MainLoss:0.1662 | Alpha:0.0519 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1644 | MainLoss:0.1644 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9844\n",
      "Test | 122/16 | Loss:0.5200 | MainLoss:0.5200 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9026\n",
      "\n",
      "Epoch: [996 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.3604 | MainLoss:0.1847 | Alpha:0.0508 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1644 | MainLoss:0.1644 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5200 | MainLoss:0.5200 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9023\n",
      "\n",
      "Epoch: [997 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.3498 | MainLoss:0.1741 | Alpha:0.0506 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1644 | MainLoss:0.1644 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9844\n",
      "Test | 122/16 | Loss:0.5200 | MainLoss:0.5200 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9020\n",
      "\n",
      "Epoch: [998 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.3473 | MainLoss:0.1716 | Alpha:0.0517 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1644 | MainLoss:0.1644 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9842\n",
      "Test | 122/16 | Loss:0.5200 | MainLoss:0.5200 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9022\n",
      "\n",
      "Epoch: [999 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.3522 | MainLoss:0.1765 | Alpha:0.0515 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1645 | MainLoss:0.1645 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9843\n",
      "Test | 122/16 | Loss:0.5200 | MainLoss:0.5200 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9020\n",
      "\n",
      "Epoch: [1000 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.3439 | MainLoss:0.1682 | Alpha:0.0495 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 31/16 | Loss:0.1644 | MainLoss:0.1644 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 122/16 | Loss:0.5200 | MainLoss:0.5200 | SPLoss:1.7570 | CLSLoss:0.0000 | AUROC:0.9020\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(start_epoch, epochs):\n",
    "    state['lr'] = optimizer.state_dict()['param_groups'][0]['lr']\n",
    "#     adjust_learning_rate(optimizer, epoch)\n",
    "    print('\\nEpoch: [%d | %d] LR: %f' % (epoch + 1, epochs, state['lr']))\n",
    "    \n",
    "    train_loss, train_auroc = train(train_loader, teacher_model, student_model, criterion, optimizer, epoch, use_cuda)\n",
    "    test_loss, test_auroc = test(val_target_loader, student_model, criterion, epoch, use_cuda)\n",
    "    source_loss, source_auroc = test(val_source_loader, student_model, criterion, epoch, use_cuda)\n",
    "\n",
    "\n",
    "    logger.append([state['lr'], train_loss, test_loss,  source_loss, train_auroc, test_auroc, source_auroc])\n",
    "    is_best = test_auroc+source_auroc > best_acc\n",
    "    best_acc = max(test_auroc+source_auroc, best_acc)\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'state_dict' : student_model.state_dict(),\n",
    "        'best_acc': best_acc,\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    }, is_best, checkpoint=checkpoint)\n",
    "    scheduler_warmup.step()\n",
    "    scheduler.step()\n",
    "    \n",
    "    if (epoch+1)%500 == 0:\n",
    "        teacher_model.load_state_dict(student_model.state_dict())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
