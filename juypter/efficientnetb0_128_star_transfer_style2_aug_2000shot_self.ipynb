{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import collections\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "\n",
    "from model_pytorch import EfficientNet\n",
    "from utils import Bar,Logger, AverageMeter, accuracy, mkdir_p, savefig\n",
    "from warmup_scheduler import GradualWarmupScheduler\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "import cv2\n",
    "\n",
    "from PIL import ImageFile, ImageOps\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU device 1: True\n"
     ]
    }
   ],
   "source": [
    "# GPU Device\n",
    "gpu_id = 1\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(\"GPU device %d:\" %(gpu_id), use_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = '/media/data2/dataset/GAN_ImageData/StarGAN_128/'\n",
    "target_dir = '/media/data2/dataset/GAN_ImageData/StyleGAN2_256/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained = './log/star/128/b0/aug/checkpoint.pth.tar'\n",
    "resume = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model_name = 'efficientnet-b0' # b0-b7 scale\n",
    "\n",
    "# Optimization\n",
    "num_classes = 2\n",
    "epochs = 1000\n",
    "start_epoch = 0\n",
    "train_batch = 250\n",
    "test_batch = 250\n",
    "lr = 0.03\n",
    "momentum = 0.1\n",
    "gamma = 0.1 # LR is multiplied by gamma on schedule\n",
    "\n",
    "# CheckPoint\n",
    "checkpoint = './log/star/128/b0/to_style2/2000shot/self2' # dir\n",
    "if not os.path.isdir(checkpoint):\n",
    "    os.makedirs(checkpoint)\n",
    "num_workers = 8\n",
    "\n",
    "# Seed\n",
    "manual_seed = 7\n",
    "random.seed(manual_seed)\n",
    "torch.cuda.manual_seed_all(manual_seed)\n",
    "\n",
    "# Image\n",
    "size = (128, 128)\n",
    "\n",
    "# cutmix\n",
    "cm_prob = 0.5\n",
    "cm_beta = 1.0\n",
    "\n",
    "# augmentation\n",
    "blur_prob = 0.5\n",
    "blog_sig = 0.5\n",
    "jpg_prob = 0.5\n",
    "\n",
    "best_acc = 0\n",
    "\n",
    "# sp\n",
    "sp_alpha = 0.1\n",
    "sp_beta = 0.1\n",
    "fc_name = '_fc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {}\n",
    "state['num_classes'] = num_classes\n",
    "state['epochs'] = epochs\n",
    "state['start_epoch'] = start_epoch\n",
    "state['train_batch'] = train_batch\n",
    "state['test_batch'] = test_batch\n",
    "state['lr'] = lr\n",
    "state['momentum'] = momentum\n",
    "state['gamma'] = gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_augment(img):\n",
    "    img = np.array(img)\n",
    "\n",
    "    if random.random() < blur_prob:\n",
    "        sig = np.random.uniform(0.0, 3.0)\n",
    "        gaussian_blur(img, sig)\n",
    "\n",
    "    if random.random() < jpg_prob:\n",
    "        qual = np.random.uniform(30.0, 100.0)\n",
    "        img = cv2_jpg(img, qual)\n",
    "\n",
    "    return Image.fromarray(img)\n",
    "\n",
    "\n",
    "def gaussian_blur(img, sigma):\n",
    "    gaussian_filter(img[:,:,0], output=img[:,:,0], sigma=sigma)\n",
    "    gaussian_filter(img[:,:,1], output=img[:,:,1], sigma=sigma)\n",
    "    gaussian_filter(img[:,:,2], output=img[:,:,2], sigma=sigma)\n",
    "\n",
    "\n",
    "def cv2_jpg(img, compress_val):\n",
    "    img_cv2 = img[:,:,::-1]\n",
    "    encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), compress_val]\n",
    "    result, encimg = cv2.imencode('.jpg', img_cv2, encode_param)\n",
    "    decimg = cv2.imdecode(encimg, 1)\n",
    "    return decimg[:,:,::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_bbox(size, lam):\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = np.int(W * cut_rat)\n",
    "    cut_h = np.int(H * cut_rat)\n",
    "\n",
    "    # uniform\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join(source_dir, 'style2/2000_shot')\n",
    "val_target_dir = os.path.join(target_dir, 'validation')\n",
    "val_source_dir = os.path.join(source_dir, 'validation')\n",
    "\n",
    "train_aug = transforms.Compose([\n",
    "    transforms.Lambda(lambda img: data_augment(img)),\n",
    "    transforms.Resize(size),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "val_aug = transforms.Compose([\n",
    "    transforms.Resize(size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# pin_memory : cuda pin memeory use\n",
    "train_loader = DataLoader(datasets.ImageFolder(train_dir, transform=train_aug),\n",
    "                          batch_size=train_batch, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "val_target_loader = DataLoader(datasets.ImageFolder(val_target_dir, val_aug),\n",
    "                       batch_size=test_batch, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "val_source_loader = DataLoader(datasets.ImageFolder(val_source_dir, val_aug),\n",
    "                       batch_size=test_batch, shuffle=True, num_workers=num_workers, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> using pre-trained model './log/star/128/b0/aug/checkpoint.pth.tar'\n"
     ]
    }
   ],
   "source": [
    "teacher_model = EfficientNet.from_name(model_name, num_classes=num_classes,\n",
    "                              override_params={'dropout_rate':0.2, 'drop_connect_rate':0.2})\n",
    "student_model = EfficientNet.from_name(model_name, num_classes=num_classes,\n",
    "                              override_params={'dropout_rate':0.2, 'drop_connect_rate':0.2})\n",
    "\n",
    "# Pre-trained\n",
    "if pretrained:\n",
    "    print(\"=> using pre-trained model '{}'\".format(pretrained))\n",
    "    teacher_model.load_state_dict(torch.load(pretrained)['state_dict'])\n",
    "    student_model.load_state_dict(torch.load(pretrained)['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Total params: 4.01M\n"
     ]
    }
   ],
   "source": [
    "teacher_model.to('cuda')\n",
    "student_model.to('cuda')\n",
    "cudnn.benchmark = True\n",
    "print('    Total params: %.2fM' % (sum(p.numel() for p in teacher_model.parameters())/1000000.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = optim.SGD(student_model.parameters(), lr=lr, momentum=momentum)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, 200, gamma=0.1, last_epoch=-1)\n",
    "scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)\n",
    "scheduler_warmup = GradualWarmupScheduler(optimizer, multiplier=8, total_epoch=100, after_scheduler=scheduler_cosine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resume\n",
    "if resume:\n",
    "    print('==> Resuming from checkpoint..')\n",
    "    checkpoint = os.path.dirname(resume)\n",
    "    resume = torch.load(resume)\n",
    "    best_acc = resume['best_acc']\n",
    "    start_epoch = resume['epoch']\n",
    "    student_model.load_state_dict(resume['state_dict'])\n",
    "    optimizer.load_state_dict(resume['optimizer'])\n",
    "    logger = Logger(os.path.join(checkpoint, 'log.txt'), resume=True)\n",
    "else:\n",
    "    logger = Logger(os.path.join(checkpoint, 'log.txt'))\n",
    "    logger.set_names(['Learning Rate', 'Train Loss', 'Valid Loss', 'Source Loss', 'Train AUROC', 'Valid AUROC', 'Source AUROC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EfficientNet(\n",
       "  (_conv_stem): Conv2dStaticSamePadding(\n",
       "    3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
       "    (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "  )\n",
       "  (_gn0): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "  (_blocks): ModuleList(\n",
       "    (0): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        32, 32, kernel_size=(3, 3), stride=[1, 1], groups=32, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        32, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        8, 32, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 16, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (1): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 96, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        96, 96, kernel_size=(3, 3), stride=[2, 2], groups=96, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 96, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        96, 4, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        4, 96, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 24, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (2): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 144, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 144, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 24, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (3): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 144, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        144, 144, kernel_size=(5, 5), stride=[2, 2], groups=144, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 144, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 40, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (4): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 240, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        240, 240, kernel_size=(5, 5), stride=(1, 1), groups=240, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 240, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 40, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (5): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 240, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        240, 240, kernel_size=(3, 3), stride=[2, 2], groups=240, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 240, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 80, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (6): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 480, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 480, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 80, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (7): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 480, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 480, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 80, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (8): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 480, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        480, 480, kernel_size=(5, 5), stride=[1, 1], groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 480, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 112, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (9): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 672, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 672, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 112, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (10): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 672, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 672, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 112, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (11): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 672, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5), stride=[2, 2], groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 672, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 192, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (12): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 1152, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 1152, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 192, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (13): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 1152, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 1152, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 192, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (14): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 1152, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 1152, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 192, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (15): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 1152, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(3, 3), stride=[1, 1], groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 1152, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 320, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "  )\n",
       "  (_conv_head): Conv2dStaticSamePadding(\n",
       "    320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "    (static_padding): Identity()\n",
       "  )\n",
       "  (_gn1): GroupNorm(8, 1280, eps=1e-05, affine=True)\n",
       "  (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n",
       "  (_dropout): Dropout(p=0.2, inplace=False)\n",
       "  (_fc): Linear(in_features=1280, out_features=2, bias=True)\n",
       "  (_swish): MemoryEfficientSwish()\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for param in teacher_model.parameters():\n",
    "    param.requires_grad = False\n",
    "teacher_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_model_weights = {}\n",
    "for name, param in teacher_model.named_parameters():\n",
    "    teacher_model_weights[name] = param.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_cls(model):\n",
    "    l2_cls = torch.tensor(0.).cuda()\n",
    "    for name, param in model.named_parameters():\n",
    "        if name.startswith(fc_name):\n",
    "            l2_cls += 0.5 * torch.norm(param) ** 2\n",
    "    return l2_cls\n",
    "\n",
    "def reg_l2sp(model):\n",
    "    sp_loss = torch.tensor(0.).cuda()\n",
    "    for name, param in model.named_parameters():\n",
    "        if not name.startswith(fc_name):\n",
    "            sp_loss += 0.5 * torch.norm(param - teacher_model_weights[name]) ** 2\n",
    "    return sp_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, teacher_model, student_model, criterion, optimizer, epoch, use_cuda):\n",
    "    teacher_model.eval()\n",
    "    student_model.train()\n",
    "    \n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    arc = AverageMeter()\n",
    "    end = time.time()\n",
    "    cls_losses = AverageMeter()\n",
    "    sp_losses = AverageMeter()\n",
    "    main_losses = AverageMeter()\n",
    "    alpha = AverageMeter()\n",
    "    \n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        batch_size = inputs.size(0)\n",
    "        if batch_size < train_batch:\n",
    "            continue\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            \n",
    "        r = np.random.rand(1)\n",
    "        if cm_beta > 0 and r < cm_prob:\n",
    "            \n",
    "            rand_index = torch.randperm(inputs.size()[0]).cuda()\n",
    "            tt= targets[rand_index]\n",
    "            boolean = targets==tt\n",
    "            rand_index = rand_index[boolean]\n",
    "            lam = np.random.beta(cm_beta, cm_beta)\n",
    "            bbx1, bby1, bbx2, bby2 = rand_bbox(inputs.size(), lam)\n",
    "            inputs[boolean, :, bbx1:bbx2, bby1:bby2] = inputs[rand_index, :, bbx1:bbx2, bby1:bby2]\n",
    "\n",
    "        # compute output\n",
    "        with torch.no_grad():\n",
    "            teacher_outputs = teacher_model(inputs)\n",
    "            teacher_loss = criterion(teacher_outputs, targets)\n",
    "            sp_alpha = 0\n",
    "            sigmoid = nn.Sigmoid()\n",
    "            sp_alpha += sigmoid(-teacher_loss)\n",
    "        \n",
    "        outputs = student_model(inputs)\n",
    "        loss_main = criterion(outputs, targets)\n",
    "        loss_cls = 0\n",
    "        loss_sp = 0\n",
    "        loss_cls = reg_cls(student_model)\n",
    "        loss_sp = reg_l2sp(student_model)\n",
    "        loss =  loss_main + sp_alpha*loss_sp + sp_alpha*loss_cls\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        losses.update(loss.data.tolist(), inputs.size(0))\n",
    "        cls_losses.update(loss_cls, inputs.size(0))\n",
    "        sp_losses.update(loss_sp, inputs.size(0))\n",
    "        main_losses.update(loss_main.tolist(), inputs.size(0))\n",
    "        alpha.update(sp_alpha, inputs.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        \n",
    "    print('Train | {batch}/{size} | Loss:{loss:.4f} | MainLoss:{main:.4f} | Alpha:{alp:.4f} | SPLoss:{sp:.4f} | CLSLoss:{cls:.4f} | AUROC:{ac:.4f}'.format(\n",
    "                     batch=batch_idx+1, size=len(train_loader), loss=losses.avg, main=main_losses.avg, alp=alpha.avg, sp=sp_losses.avg, cls=cls_losses.avg, ac=arc.avg))\n",
    "    return (losses.avg, arc.avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(val_loader, model, criterion, epoch, use_cuda):\n",
    "    global best_acc\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    arc = AverageMeter()\n",
    "    cls_losses = AverageMeter()\n",
    "    sp_losses = AverageMeter()\n",
    "    main_losses = AverageMeter()\n",
    "\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(val_loader):\n",
    "            # measure data loading time\n",
    "            data_time.update(time.time() - end)\n",
    "\n",
    "            if use_cuda:\n",
    "                inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "            # compute output\n",
    "            outputs = model(inputs)\n",
    "            loss_main = criterion(outputs, targets)\n",
    "            loss_cls = 0\n",
    "            loss_sp = 0\n",
    "            loss_cls = reg_cls(model)\n",
    "            loss_sp = reg_l2sp(model)\n",
    "            loss = loss_main + 0*loss_sp + 0*loss_cls\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            auroc = roc_auc_score(targets.cpu().detach().numpy(), outputs.cpu().detach().numpy()[:,1])\n",
    "            losses.update(loss.data.tolist(), inputs.size(0))\n",
    "            arc.update(auroc, inputs.size(0))\n",
    "            cls_losses.update(loss_cls, inputs.size(0))\n",
    "            sp_losses.update(loss_sp, inputs.size(0))\n",
    "            main_losses.update(loss_main.tolist(), inputs.size(0))\n",
    "\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "    print('Test | {batch}/{size} | Loss:{loss:.4f} | MainLoss:{main:.4f} | SPLoss:{sp:.4f} | CLSLoss:{cls:.4f} | AUROC:{ac:.4f}'.format(\n",
    "                     batch=batch_idx+1, size=len(train_loader), loss=losses.avg, main=main_losses.avg, sp=sp_losses.avg, cls=cls_losses.avg, ac=arc.avg))\n",
    "    return (losses.avg, arc.avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, checkpoint='checkpoint', filename='checkpoint.pth.tar'):\n",
    "    filepath = os.path.join(checkpoint, filename)\n",
    "    torch.save(state, filepath)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filepath, os.path.join(checkpoint, 'model_best.pth.tar'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [1 | 1000] LR: 0.100000\n",
      "Train | 16/16 | Loss:2.3402 | MainLoss:0.9054 | Alpha:0.0592 | SPLoss:14.3483 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6885 | MainLoss:0.6885 | SPLoss:13.9745 | CLSLoss:0.0000 | AUROC:0.5664\n",
      "Test | 122/16 | Loss:0.6308 | MainLoss:0.6308 | SPLoss:13.9745 | CLSLoss:0.0000 | AUROC:0.9449\n",
      "\n",
      "Epoch: [2 | 1000] LR: 0.102000\n",
      "Train | 16/16 | Loss:1.8830 | MainLoss:0.6972 | Alpha:0.0563 | SPLoss:11.8582 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6832 | MainLoss:0.6832 | SPLoss:9.7205 | CLSLoss:0.0000 | AUROC:0.5920\n",
      "Test | 122/16 | Loss:0.6135 | MainLoss:0.6135 | SPLoss:9.7205 | CLSLoss:0.0000 | AUROC:0.9631\n",
      "\n",
      "Epoch: [3 | 1000] LR: 0.104000\n",
      "Train | 16/16 | Loss:1.5081 | MainLoss:0.6866 | Alpha:0.0596 | SPLoss:8.2150 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6717 | MainLoss:0.6717 | SPLoss:6.7302 | CLSLoss:0.0000 | AUROC:0.6348\n",
      "Test | 122/16 | Loss:0.5602 | MainLoss:0.5602 | SPLoss:6.7302 | CLSLoss:0.0000 | AUROC:0.9774\n",
      "\n",
      "Epoch: [4 | 1000] LR: 0.106000\n",
      "Train | 16/16 | Loss:1.2447 | MainLoss:0.6755 | Alpha:0.0568 | SPLoss:5.6918 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6467 | MainLoss:0.6467 | SPLoss:4.6655 | CLSLoss:0.0000 | AUROC:0.6785\n",
      "Test | 122/16 | Loss:0.4913 | MainLoss:0.4913 | SPLoss:4.6655 | CLSLoss:0.0000 | AUROC:0.9804\n",
      "\n",
      "Epoch: [5 | 1000] LR: 0.108000\n",
      "Train | 16/16 | Loss:1.0624 | MainLoss:0.6646 | Alpha:0.0560 | SPLoss:3.9776 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6372 | MainLoss:0.6372 | SPLoss:3.2800 | CLSLoss:0.0000 | AUROC:0.7145\n",
      "Test | 122/16 | Loss:0.4724 | MainLoss:0.4724 | SPLoss:3.2801 | CLSLoss:0.0000 | AUROC:0.9862\n",
      "\n",
      "Epoch: [6 | 1000] LR: 0.110000\n",
      "Train | 16/16 | Loss:0.9370 | MainLoss:0.6552 | Alpha:0.0568 | SPLoss:2.8180 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6028 | MainLoss:0.6028 | SPLoss:2.3558 | CLSLoss:0.0000 | AUROC:0.7388\n",
      "Test | 122/16 | Loss:0.3690 | MainLoss:0.3690 | SPLoss:2.3558 | CLSLoss:0.0000 | AUROC:0.9857\n",
      "\n",
      "Epoch: [7 | 1000] LR: 0.112000\n",
      "Train | 16/16 | Loss:0.8441 | MainLoss:0.6374 | Alpha:0.0575 | SPLoss:2.0671 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.5909 | MainLoss:0.5909 | SPLoss:1.7670 | CLSLoss:0.0000 | AUROC:0.7739\n",
      "Test | 122/16 | Loss:0.3186 | MainLoss:0.3186 | SPLoss:1.7670 | CLSLoss:0.0000 | AUROC:0.9879\n",
      "\n",
      "Epoch: [8 | 1000] LR: 0.114000\n",
      "Train | 16/16 | Loss:0.7800 | MainLoss:0.6224 | Alpha:0.0585 | SPLoss:1.5753 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.5553 | MainLoss:0.5553 | SPLoss:1.3703 | CLSLoss:0.0000 | AUROC:0.7904\n",
      "Test | 122/16 | Loss:0.2930 | MainLoss:0.2930 | SPLoss:1.3703 | CLSLoss:0.0000 | AUROC:0.9838\n",
      "\n",
      "Epoch: [9 | 1000] LR: 0.116000\n",
      "Train | 16/16 | Loss:0.7426 | MainLoss:0.6162 | Alpha:0.0569 | SPLoss:1.2644 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6350 | MainLoss:0.6350 | SPLoss:1.1479 | CLSLoss:0.0000 | AUROC:0.8124\n",
      "Test | 122/16 | Loss:0.4676 | MainLoss:0.4676 | SPLoss:1.1479 | CLSLoss:0.0000 | AUROC:0.9793\n",
      "\n",
      "Epoch: [10 | 1000] LR: 0.118000\n",
      "Train | 16/16 | Loss:0.7048 | MainLoss:0.5955 | Alpha:0.0577 | SPLoss:1.0931 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.5218 | MainLoss:0.5218 | SPLoss:1.0434 | CLSLoss:0.0000 | AUROC:0.8390\n",
      "Test | 122/16 | Loss:0.3109 | MainLoss:0.3109 | SPLoss:1.0434 | CLSLoss:0.0000 | AUROC:0.9814\n",
      "\n",
      "Epoch: [11 | 1000] LR: 0.120000\n",
      "Train | 16/16 | Loss:0.6830 | MainLoss:0.5788 | Alpha:0.0589 | SPLoss:1.0424 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.4918 | MainLoss:0.4918 | SPLoss:1.0106 | CLSLoss:0.0000 | AUROC:0.8534\n",
      "Test | 122/16 | Loss:0.2499 | MainLoss:0.2499 | SPLoss:1.0106 | CLSLoss:0.0000 | AUROC:0.9820\n",
      "\n",
      "Epoch: [12 | 1000] LR: 0.122000\n",
      "Train | 16/16 | Loss:0.6850 | MainLoss:0.5770 | Alpha:0.0557 | SPLoss:1.0802 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.4675 | MainLoss:0.4675 | SPLoss:1.1022 | CLSLoss:0.0000 | AUROC:0.8768\n",
      "Test | 122/16 | Loss:0.2941 | MainLoss:0.2941 | SPLoss:1.1022 | CLSLoss:0.0000 | AUROC:0.9698\n",
      "\n",
      "Epoch: [13 | 1000] LR: 0.124000\n",
      "Train | 16/16 | Loss:0.6313 | MainLoss:0.5196 | Alpha:0.0578 | SPLoss:1.1165 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.4443 | MainLoss:0.4443 | SPLoss:1.1833 | CLSLoss:0.0000 | AUROC:0.8909\n",
      "Test | 122/16 | Loss:0.2938 | MainLoss:0.2938 | SPLoss:1.1833 | CLSLoss:0.0000 | AUROC:0.9670\n",
      "\n",
      "Epoch: [14 | 1000] LR: 0.126000\n",
      "Train | 16/16 | Loss:0.6449 | MainLoss:0.5213 | Alpha:0.0582 | SPLoss:1.2362 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.4339 | MainLoss:0.4339 | SPLoss:1.3049 | CLSLoss:0.0000 | AUROC:0.9028\n",
      "Test | 122/16 | Loss:0.3434 | MainLoss:0.3434 | SPLoss:1.3049 | CLSLoss:0.0000 | AUROC:0.9523\n",
      "\n",
      "Epoch: [15 | 1000] LR: 0.128000\n",
      "Train | 16/16 | Loss:0.6201 | MainLoss:0.4865 | Alpha:0.0576 | SPLoss:1.3365 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3881 | MainLoss:0.3881 | SPLoss:1.3488 | CLSLoss:0.0000 | AUROC:0.9141\n",
      "Test | 122/16 | Loss:0.2898 | MainLoss:0.2898 | SPLoss:1.3488 | CLSLoss:0.0000 | AUROC:0.9586\n",
      "\n",
      "Epoch: [16 | 1000] LR: 0.130000\n",
      "Train | 16/16 | Loss:0.5983 | MainLoss:0.4593 | Alpha:0.0588 | SPLoss:1.3899 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3886 | MainLoss:0.3886 | SPLoss:1.4603 | CLSLoss:0.0000 | AUROC:0.9230\n",
      "Test | 122/16 | Loss:0.3457 | MainLoss:0.3457 | SPLoss:1.4603 | CLSLoss:0.0000 | AUROC:0.9396\n",
      "\n",
      "Epoch: [17 | 1000] LR: 0.132000\n",
      "Train | 16/16 | Loss:0.6043 | MainLoss:0.4576 | Alpha:0.0575 | SPLoss:1.4671 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3513 | MainLoss:0.3513 | SPLoss:1.5286 | CLSLoss:0.0000 | AUROC:0.9270\n",
      "Test | 122/16 | Loss:0.3365 | MainLoss:0.3365 | SPLoss:1.5286 | CLSLoss:0.0000 | AUROC:0.9338\n",
      "\n",
      "Epoch: [18 | 1000] LR: 0.134000\n",
      "Train | 16/16 | Loss:0.5958 | MainLoss:0.4420 | Alpha:0.0600 | SPLoss:1.5385 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3604 | MainLoss:0.3604 | SPLoss:1.5605 | CLSLoss:0.0000 | AUROC:0.9304\n",
      "Test | 122/16 | Loss:0.3698 | MainLoss:0.3698 | SPLoss:1.5605 | CLSLoss:0.0000 | AUROC:0.9354\n",
      "\n",
      "Epoch: [19 | 1000] LR: 0.136000\n",
      "Train | 16/16 | Loss:0.5915 | MainLoss:0.4323 | Alpha:0.0570 | SPLoss:1.5915 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3651 | MainLoss:0.3651 | SPLoss:1.6754 | CLSLoss:0.0000 | AUROC:0.9382\n",
      "Test | 122/16 | Loss:0.4010 | MainLoss:0.4010 | SPLoss:1.6754 | CLSLoss:0.0000 | AUROC:0.9126\n",
      "\n",
      "Epoch: [20 | 1000] LR: 0.138000\n",
      "Train | 16/16 | Loss:0.5844 | MainLoss:0.4173 | Alpha:0.0570 | SPLoss:1.6706 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3599 | MainLoss:0.3599 | SPLoss:1.6131 | CLSLoss:0.0000 | AUROC:0.9344\n",
      "Test | 122/16 | Loss:0.2783 | MainLoss:0.2783 | SPLoss:1.6131 | CLSLoss:0.0000 | AUROC:0.9613\n",
      "\n",
      "Epoch: [21 | 1000] LR: 0.140000\n",
      "Train | 16/16 | Loss:0.5924 | MainLoss:0.4214 | Alpha:0.0569 | SPLoss:1.7094 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3090 | MainLoss:0.3090 | SPLoss:1.7389 | CLSLoss:0.0000 | AUROC:0.9428\n",
      "Test | 122/16 | Loss:0.3220 | MainLoss:0.3220 | SPLoss:1.7389 | CLSLoss:0.0000 | AUROC:0.9392\n",
      "\n",
      "Epoch: [22 | 1000] LR: 0.142000\n",
      "Train | 16/16 | Loss:0.5887 | MainLoss:0.4118 | Alpha:0.0559 | SPLoss:1.7685 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3377 | MainLoss:0.3377 | SPLoss:1.9374 | CLSLoss:0.0000 | AUROC:0.9413\n",
      "Test | 122/16 | Loss:0.4775 | MainLoss:0.4775 | SPLoss:1.9374 | CLSLoss:0.0000 | AUROC:0.8566\n",
      "\n",
      "Epoch: [23 | 1000] LR: 0.144000\n",
      "Train | 16/16 | Loss:0.5737 | MainLoss:0.3898 | Alpha:0.0585 | SPLoss:1.8398 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2863 | MainLoss:0.2863 | SPLoss:1.7770 | CLSLoss:0.0000 | AUROC:0.9509\n",
      "Test | 122/16 | Loss:0.3107 | MainLoss:0.3107 | SPLoss:1.7770 | CLSLoss:0.0000 | AUROC:0.9467\n",
      "\n",
      "Epoch: [24 | 1000] LR: 0.146000\n",
      "Train | 16/16 | Loss:0.5933 | MainLoss:0.4100 | Alpha:0.0595 | SPLoss:1.8334 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3038 | MainLoss:0.3038 | SPLoss:1.7992 | CLSLoss:0.0000 | AUROC:0.9446\n",
      "Test | 122/16 | Loss:0.2975 | MainLoss:0.2975 | SPLoss:1.7992 | CLSLoss:0.0000 | AUROC:0.9469\n",
      "\n",
      "Epoch: [25 | 1000] LR: 0.148000\n",
      "Train | 16/16 | Loss:0.6051 | MainLoss:0.4179 | Alpha:0.0562 | SPLoss:1.8727 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.4349 | MainLoss:0.4349 | SPLoss:1.8742 | CLSLoss:0.0000 | AUROC:0.9499\n",
      "Test | 122/16 | Loss:0.4622 | MainLoss:0.4622 | SPLoss:1.8742 | CLSLoss:0.0000 | AUROC:0.9162\n",
      "\n",
      "Epoch: [26 | 1000] LR: 0.150000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 16/16 | Loss:0.5840 | MainLoss:0.3958 | Alpha:0.0565 | SPLoss:1.8819 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3352 | MainLoss:0.3352 | SPLoss:1.9642 | CLSLoss:0.0000 | AUROC:0.9507\n",
      "Test | 122/16 | Loss:0.4562 | MainLoss:0.4562 | SPLoss:1.9642 | CLSLoss:0.0000 | AUROC:0.8941\n",
      "\n",
      "Epoch: [27 | 1000] LR: 0.152000\n",
      "Train | 16/16 | Loss:0.6107 | MainLoss:0.4153 | Alpha:0.0564 | SPLoss:1.9543 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2908 | MainLoss:0.2908 | SPLoss:1.9952 | CLSLoss:0.0000 | AUROC:0.9584\n",
      "Test | 122/16 | Loss:0.4239 | MainLoss:0.4239 | SPLoss:1.9952 | CLSLoss:0.0000 | AUROC:0.8899\n",
      "\n",
      "Epoch: [28 | 1000] LR: 0.154000\n",
      "Train | 16/16 | Loss:0.5693 | MainLoss:0.3749 | Alpha:0.0581 | SPLoss:1.9444 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3333 | MainLoss:0.3333 | SPLoss:1.9648 | CLSLoss:0.0000 | AUROC:0.9561\n",
      "Test | 122/16 | Loss:0.3997 | MainLoss:0.3997 | SPLoss:1.9648 | CLSLoss:0.0000 | AUROC:0.9099\n",
      "\n",
      "Epoch: [29 | 1000] LR: 0.156000\n",
      "Train | 16/16 | Loss:0.5689 | MainLoss:0.3702 | Alpha:0.0590 | SPLoss:1.9868 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2738 | MainLoss:0.2738 | SPLoss:2.0164 | CLSLoss:0.0000 | AUROC:0.9592\n",
      "Test | 122/16 | Loss:0.3391 | MainLoss:0.3391 | SPLoss:2.0164 | CLSLoss:0.0000 | AUROC:0.9314\n",
      "\n",
      "Epoch: [30 | 1000] LR: 0.158000\n",
      "Train | 16/16 | Loss:0.6754 | MainLoss:0.4319 | Alpha:0.0572 | SPLoss:2.4350 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3365 | MainLoss:0.3365 | SPLoss:2.3720 | CLSLoss:0.0000 | AUROC:0.9417\n",
      "Test | 122/16 | Loss:0.5678 | MainLoss:0.5678 | SPLoss:2.3720 | CLSLoss:0.0000 | AUROC:0.7987\n",
      "\n",
      "Epoch: [31 | 1000] LR: 0.160000\n",
      "Train | 16/16 | Loss:0.6184 | MainLoss:0.3947 | Alpha:0.0579 | SPLoss:2.2371 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3055 | MainLoss:0.3055 | SPLoss:2.0896 | CLSLoss:0.0000 | AUROC:0.9514\n",
      "Test | 122/16 | Loss:0.5403 | MainLoss:0.5403 | SPLoss:2.0896 | CLSLoss:0.0000 | AUROC:0.9028\n",
      "\n",
      "Epoch: [32 | 1000] LR: 0.162000\n",
      "Train | 16/16 | Loss:0.5805 | MainLoss:0.3758 | Alpha:0.0579 | SPLoss:2.0473 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2656 | MainLoss:0.2656 | SPLoss:1.9820 | CLSLoss:0.0000 | AUROC:0.9586\n",
      "Test | 122/16 | Loss:0.3795 | MainLoss:0.3795 | SPLoss:1.9820 | CLSLoss:0.0000 | AUROC:0.9241\n",
      "\n",
      "Epoch: [33 | 1000] LR: 0.164000\n",
      "Train | 16/16 | Loss:0.6250 | MainLoss:0.4123 | Alpha:0.0564 | SPLoss:2.1273 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2752 | MainLoss:0.2752 | SPLoss:2.0954 | CLSLoss:0.0000 | AUROC:0.9586\n",
      "Test | 122/16 | Loss:0.4087 | MainLoss:0.4087 | SPLoss:2.0954 | CLSLoss:0.0000 | AUROC:0.9027\n",
      "\n",
      "Epoch: [34 | 1000] LR: 0.166000\n",
      "Train | 16/16 | Loss:0.6629 | MainLoss:0.4411 | Alpha:0.0568 | SPLoss:2.2184 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3560 | MainLoss:0.3560 | SPLoss:2.0756 | CLSLoss:0.0000 | AUROC:0.9499\n",
      "Test | 122/16 | Loss:0.5126 | MainLoss:0.5126 | SPLoss:2.0756 | CLSLoss:0.0000 | AUROC:0.8759\n",
      "\n",
      "Epoch: [35 | 1000] LR: 0.168000\n",
      "Train | 16/16 | Loss:0.5738 | MainLoss:0.3717 | Alpha:0.0583 | SPLoss:2.0212 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2739 | MainLoss:0.2739 | SPLoss:2.0268 | CLSLoss:0.0000 | AUROC:0.9570\n",
      "Test | 122/16 | Loss:0.3926 | MainLoss:0.3926 | SPLoss:2.0268 | CLSLoss:0.0000 | AUROC:0.9072\n",
      "\n",
      "Epoch: [36 | 1000] LR: 0.170000\n",
      "Train | 16/16 | Loss:0.5723 | MainLoss:0.3679 | Alpha:0.0586 | SPLoss:2.0448 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2882 | MainLoss:0.2882 | SPLoss:2.0901 | CLSLoss:0.0000 | AUROC:0.9589\n",
      "Test | 122/16 | Loss:0.5161 | MainLoss:0.5161 | SPLoss:2.0901 | CLSLoss:0.0000 | AUROC:0.8782\n",
      "\n",
      "Epoch: [37 | 1000] LR: 0.172000\n",
      "Train | 16/16 | Loss:0.5827 | MainLoss:0.3752 | Alpha:0.0588 | SPLoss:2.0747 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.4717 | MainLoss:0.4717 | SPLoss:1.9524 | CLSLoss:0.0000 | AUROC:0.9508\n",
      "Test | 122/16 | Loss:0.5150 | MainLoss:0.5150 | SPLoss:1.9524 | CLSLoss:0.0000 | AUROC:0.9510\n",
      "\n",
      "Epoch: [38 | 1000] LR: 0.174000\n",
      "Train | 16/16 | Loss:0.6245 | MainLoss:0.4116 | Alpha:0.0569 | SPLoss:2.1292 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2847 | MainLoss:0.2847 | SPLoss:2.1325 | CLSLoss:0.0000 | AUROC:0.9577\n",
      "Test | 122/16 | Loss:0.4952 | MainLoss:0.4952 | SPLoss:2.1325 | CLSLoss:0.0000 | AUROC:0.8460\n",
      "\n",
      "Epoch: [39 | 1000] LR: 0.176000\n",
      "Train | 16/16 | Loss:0.6413 | MainLoss:0.4187 | Alpha:0.0569 | SPLoss:2.2263 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2996 | MainLoss:0.2996 | SPLoss:2.1327 | CLSLoss:0.0000 | AUROC:0.9585\n",
      "Test | 122/16 | Loss:0.4666 | MainLoss:0.4666 | SPLoss:2.1327 | CLSLoss:0.0000 | AUROC:0.8619\n",
      "\n",
      "Epoch: [40 | 1000] LR: 0.178000\n",
      "Train | 16/16 | Loss:0.5706 | MainLoss:0.3653 | Alpha:0.0576 | SPLoss:2.0526 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.4947 | MainLoss:0.4947 | SPLoss:2.0563 | CLSLoss:0.0000 | AUROC:0.9540\n",
      "Test | 122/16 | Loss:0.5519 | MainLoss:0.5519 | SPLoss:2.0563 | CLSLoss:0.0000 | AUROC:0.9133\n",
      "\n",
      "Epoch: [41 | 1000] LR: 0.180000\n",
      "Train | 16/16 | Loss:0.6754 | MainLoss:0.4511 | Alpha:0.0563 | SPLoss:2.2427 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3298 | MainLoss:0.3298 | SPLoss:2.4172 | CLSLoss:0.0000 | AUROC:0.9386\n",
      "Test | 122/16 | Loss:0.6085 | MainLoss:0.6085 | SPLoss:2.4172 | CLSLoss:0.0000 | AUROC:0.7852\n",
      "\n",
      "Epoch: [42 | 1000] LR: 0.182000\n",
      "Train | 16/16 | Loss:0.5694 | MainLoss:0.3508 | Alpha:0.0566 | SPLoss:2.1854 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2662 | MainLoss:0.2662 | SPLoss:2.0029 | CLSLoss:0.0000 | AUROC:0.9574\n",
      "Test | 122/16 | Loss:0.3372 | MainLoss:0.3372 | SPLoss:2.0029 | CLSLoss:0.0000 | AUROC:0.9398\n",
      "\n",
      "Epoch: [43 | 1000] LR: 0.184000\n",
      "Train | 16/16 | Loss:0.5738 | MainLoss:0.3698 | Alpha:0.0584 | SPLoss:2.0399 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3158 | MainLoss:0.3158 | SPLoss:2.0471 | CLSLoss:0.0000 | AUROC:0.9623\n",
      "Test | 122/16 | Loss:0.3957 | MainLoss:0.3957 | SPLoss:2.0471 | CLSLoss:0.0000 | AUROC:0.9080\n",
      "\n",
      "Epoch: [44 | 1000] LR: 0.186000\n",
      "Train | 16/16 | Loss:0.6097 | MainLoss:0.3982 | Alpha:0.0557 | SPLoss:2.1150 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2924 | MainLoss:0.2924 | SPLoss:2.0061 | CLSLoss:0.0000 | AUROC:0.9571\n",
      "Test | 122/16 | Loss:0.3975 | MainLoss:0.3975 | SPLoss:2.0061 | CLSLoss:0.0000 | AUROC:0.9389\n",
      "\n",
      "Epoch: [45 | 1000] LR: 0.188000\n",
      "Train | 16/16 | Loss:0.5922 | MainLoss:0.3841 | Alpha:0.0598 | SPLoss:2.0808 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.5387 | MainLoss:0.5387 | SPLoss:2.2021 | CLSLoss:0.0000 | AUROC:0.9503\n",
      "Test | 122/16 | Loss:1.0100 | MainLoss:1.0100 | SPLoss:2.2021 | CLSLoss:0.0000 | AUROC:0.8287\n",
      "\n",
      "Epoch: [46 | 1000] LR: 0.190000\n",
      "Train | 16/16 | Loss:0.6392 | MainLoss:0.4142 | Alpha:0.0562 | SPLoss:2.2501 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.4042 | MainLoss:0.4042 | SPLoss:2.2964 | CLSLoss:0.0000 | AUROC:0.9612\n",
      "Test | 122/16 | Loss:0.5613 | MainLoss:0.5613 | SPLoss:2.2964 | CLSLoss:0.0000 | AUROC:0.8011\n",
      "\n",
      "Epoch: [47 | 1000] LR: 0.192000\n",
      "Train | 16/16 | Loss:0.5880 | MainLoss:0.3759 | Alpha:0.0570 | SPLoss:2.1212 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.4115 | MainLoss:0.4115 | SPLoss:2.0513 | CLSLoss:0.0000 | AUROC:0.9571\n",
      "Test | 122/16 | Loss:0.5317 | MainLoss:0.5317 | SPLoss:2.0513 | CLSLoss:0.0000 | AUROC:0.9231\n",
      "\n",
      "Epoch: [48 | 1000] LR: 0.194000\n",
      "Train | 16/16 | Loss:0.6300 | MainLoss:0.4109 | Alpha:0.0582 | SPLoss:2.1918 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2947 | MainLoss:0.2947 | SPLoss:2.3943 | CLSLoss:0.0000 | AUROC:0.9549\n",
      "Test | 122/16 | Loss:0.6501 | MainLoss:0.6501 | SPLoss:2.3943 | CLSLoss:0.0000 | AUROC:0.7378\n",
      "\n",
      "Epoch: [49 | 1000] LR: 0.196000\n",
      "Train | 16/16 | Loss:0.6330 | MainLoss:0.4069 | Alpha:0.0589 | SPLoss:2.2606 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3420 | MainLoss:0.3420 | SPLoss:2.3408 | CLSLoss:0.0000 | AUROC:0.9478\n",
      "Test | 122/16 | Loss:0.5416 | MainLoss:0.5416 | SPLoss:2.3408 | CLSLoss:0.0000 | AUROC:0.8243\n",
      "\n",
      "Epoch: [50 | 1000] LR: 0.198000\n",
      "Train | 16/16 | Loss:0.6328 | MainLoss:0.3955 | Alpha:0.0571 | SPLoss:2.3736 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3035 | MainLoss:0.3035 | SPLoss:2.4024 | CLSLoss:0.0000 | AUROC:0.9544\n",
      "Test | 122/16 | Loss:0.5284 | MainLoss:0.5284 | SPLoss:2.4024 | CLSLoss:0.0000 | AUROC:0.8269\n",
      "\n",
      "Epoch: [51 | 1000] LR: 0.200000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 16/16 | Loss:0.6571 | MainLoss:0.4188 | Alpha:0.0563 | SPLoss:2.3830 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3716 | MainLoss:0.3716 | SPLoss:2.4931 | CLSLoss:0.0000 | AUROC:0.9421\n",
      "Test | 122/16 | Loss:0.6671 | MainLoss:0.6671 | SPLoss:2.4931 | CLSLoss:0.0000 | AUROC:0.7426\n",
      "\n",
      "Epoch: [52 | 1000] LR: 0.200000\n",
      "Train | 16/16 | Loss:0.5851 | MainLoss:0.3639 | Alpha:0.0576 | SPLoss:2.2120 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2872 | MainLoss:0.2872 | SPLoss:2.1456 | CLSLoss:0.0000 | AUROC:0.9549\n",
      "Test | 122/16 | Loss:0.4892 | MainLoss:0.4892 | SPLoss:2.1456 | CLSLoss:0.0000 | AUROC:0.8603\n",
      "\n",
      "Epoch: [53 | 1000] LR: 0.200000\n",
      "Train | 16/16 | Loss:0.5977 | MainLoss:0.3819 | Alpha:0.0573 | SPLoss:2.1577 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3276 | MainLoss:0.3276 | SPLoss:2.1830 | CLSLoss:0.0000 | AUROC:0.9519\n",
      "Test | 122/16 | Loss:0.5521 | MainLoss:0.5521 | SPLoss:2.1830 | CLSLoss:0.0000 | AUROC:0.8899\n",
      "\n",
      "Epoch: [54 | 1000] LR: 0.199998\n",
      "Train | 16/16 | Loss:0.6205 | MainLoss:0.3708 | Alpha:0.0587 | SPLoss:2.4971 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3399 | MainLoss:0.3399 | SPLoss:3.4159 | CLSLoss:0.0000 | AUROC:0.9605\n",
      "Test | 122/16 | Loss:0.4464 | MainLoss:0.4464 | SPLoss:3.4159 | CLSLoss:0.0000 | AUROC:0.8866\n",
      "\n",
      "Epoch: [55 | 1000] LR: 0.199996\n",
      "Train | 16/16 | Loss:0.7116 | MainLoss:0.3948 | Alpha:0.0564 | SPLoss:3.1680 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2513 | MainLoss:0.2513 | SPLoss:2.7080 | CLSLoss:0.0000 | AUROC:0.9628\n",
      "Test | 122/16 | Loss:0.3916 | MainLoss:0.3916 | SPLoss:2.7080 | CLSLoss:0.0000 | AUROC:0.9087\n",
      "\n",
      "Epoch: [56 | 1000] LR: 0.199992\n",
      "Train | 16/16 | Loss:18.8269 | MainLoss:0.4768 | Alpha:0.0582 | SPLoss:183.5012 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3513 | MainLoss:0.3513 | SPLoss:305.7584 | CLSLoss:0.0000 | AUROC:0.9435\n",
      "Test | 122/16 | Loss:0.5382 | MainLoss:0.5382 | SPLoss:305.7583 | CLSLoss:0.0000 | AUROC:0.8276\n",
      "\n",
      "Epoch: [57 | 1000] LR: 0.199988\n",
      "Train | 16/16 | Loss:22.9421 | MainLoss:0.5094 | Alpha:0.0558 | SPLoss:224.3273 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.4424 | MainLoss:0.4424 | SPLoss:151.0657 | CLSLoss:0.0000 | AUROC:0.9097\n",
      "Test | 122/16 | Loss:0.7809 | MainLoss:0.7809 | SPLoss:151.0658 | CLSLoss:0.0000 | AUROC:0.6982\n",
      "\n",
      "Epoch: [58 | 1000] LR: 0.199982\n",
      "Train | 16/16 | Loss:11.4745 | MainLoss:0.4135 | Alpha:0.0561 | SPLoss:110.6094 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.7223 | MainLoss:0.7223 | SPLoss:74.6660 | CLSLoss:0.0000 | AUROC:0.9542\n",
      "Test | 122/16 | Loss:0.7951 | MainLoss:0.7951 | SPLoss:74.6660 | CLSLoss:0.0000 | AUROC:0.8161\n",
      "\n",
      "Epoch: [59 | 1000] LR: 0.199976\n",
      "Train | 16/16 | Loss:5.9633 | MainLoss:0.4530 | Alpha:0.0573 | SPLoss:55.1025 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3166 | MainLoss:0.3166 | SPLoss:37.4543 | CLSLoss:0.0000 | AUROC:0.9493\n",
      "Test | 122/16 | Loss:0.5454 | MainLoss:0.5454 | SPLoss:37.4543 | CLSLoss:0.0000 | AUROC:0.8527\n",
      "\n",
      "Epoch: [60 | 1000] LR: 0.199968\n",
      "Train | 16/16 | Loss:3.2095 | MainLoss:0.4161 | Alpha:0.0559 | SPLoss:27.9342 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.5828 | MainLoss:0.5828 | SPLoss:306.1691 | CLSLoss:0.0000 | AUROC:0.8559\n",
      "Test | 122/16 | Loss:0.5923 | MainLoss:0.5923 | SPLoss:306.1694 | CLSLoss:0.0000 | AUROC:0.8549\n",
      "\n",
      "Epoch: [61 | 1000] LR: 0.199960\n",
      "Train | 16/16 | Loss:15476.0228 | MainLoss:0.4345 | Alpha:0.0571 | SPLoss:154755.8906 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2820 | MainLoss:0.2820 | SPLoss:115238.8438 | CLSLoss:0.0000 | AUROC:0.9567\n",
      "Test | 122/16 | Loss:0.5509 | MainLoss:0.5509 | SPLoss:115238.8984 | CLSLoss:0.0000 | AUROC:0.8760\n",
      "\n",
      "Epoch: [62 | 1000] LR: 0.199951\n",
      "Train | 16/16 | Loss:8398.6860 | MainLoss:0.4138 | Alpha:0.0570 | SPLoss:83982.7188 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2623 | MainLoss:0.2623 | SPLoss:56049.1875 | CLSLoss:0.0000 | AUROC:0.9592\n",
      "Test | 122/16 | Loss:0.5549 | MainLoss:0.5549 | SPLoss:56049.1641 | CLSLoss:0.0000 | AUROC:0.8450\n",
      "\n",
      "Epoch: [63 | 1000] LR: 0.199940\n",
      "Train | 16/16 | Loss:4090.1907 | MainLoss:0.4092 | Alpha:0.0567 | SPLoss:40897.8164 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3004 | MainLoss:0.3004 | SPLoss:27325.8809 | CLSLoss:0.0000 | AUROC:0.9578\n",
      "Test | 122/16 | Loss:0.5040 | MainLoss:0.5040 | SPLoss:27325.8887 | CLSLoss:0.0000 | AUROC:0.9005\n",
      "\n",
      "Epoch: [64 | 1000] LR: 0.199929\n",
      "Train | 16/16 | Loss:1991.9470 | MainLoss:0.3935 | Alpha:0.0570 | SPLoss:19915.5352 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3043 | MainLoss:0.3043 | SPLoss:13292.4902 | CLSLoss:0.0000 | AUROC:0.9535\n",
      "Test | 122/16 | Loss:0.4342 | MainLoss:0.4342 | SPLoss:13292.5029 | CLSLoss:0.0000 | AUROC:0.9128\n",
      "\n",
      "Epoch: [65 | 1000] LR: 0.199917\n",
      "Train | 16/16 | Loss:969.2185 | MainLoss:0.3972 | Alpha:0.0571 | SPLoss:9688.2139 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3169 | MainLoss:0.3169 | SPLoss:6467.0723 | CLSLoss:0.0000 | AUROC:0.9487\n",
      "Test | 122/16 | Loss:0.5863 | MainLoss:0.5863 | SPLoss:6467.0723 | CLSLoss:0.0000 | AUROC:0.8118\n",
      "\n",
      "Epoch: [66 | 1000] LR: 0.199903\n",
      "Train | 16/16 | Loss:471.7496 | MainLoss:0.3706 | Alpha:0.0562 | SPLoss:4713.7905 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.4753 | MainLoss:0.4753 | SPLoss:3147.1865 | CLSLoss:0.0000 | AUROC:0.9471\n",
      "Test | 122/16 | Loss:0.6617 | MainLoss:0.6617 | SPLoss:3147.1895 | CLSLoss:0.0000 | AUROC:0.7133\n",
      "\n",
      "Epoch: [67 | 1000] LR: 0.199889\n",
      "Train | 16/16 | Loss:229.8581 | MainLoss:0.4223 | Alpha:0.0557 | SPLoss:2294.3586 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.4611 | MainLoss:0.4611 | SPLoss:1532.5172 | CLSLoss:0.0000 | AUROC:0.9480\n",
      "Test | 122/16 | Loss:0.6918 | MainLoss:0.6918 | SPLoss:1532.5166 | CLSLoss:0.0000 | AUROC:0.6575\n",
      "\n",
      "Epoch: [68 | 1000] LR: 0.199874\n",
      "Train | 16/16 | Loss:112.1886 | MainLoss:0.3814 | Alpha:0.0576 | SPLoss:1118.0714 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2522 | MainLoss:0.2522 | SPLoss:746.9445 | CLSLoss:0.0000 | AUROC:0.9619\n",
      "Test | 122/16 | Loss:0.4981 | MainLoss:0.4981 | SPLoss:746.9442 | CLSLoss:0.0000 | AUROC:0.9016\n",
      "\n",
      "Epoch: [69 | 1000] LR: 0.199857\n",
      "Train | 16/16 | Loss:54.9491 | MainLoss:0.4246 | Alpha:0.0564 | SPLoss:545.2452 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2588 | MainLoss:0.2588 | SPLoss:364.5693 | CLSLoss:0.0000 | AUROC:0.9602\n",
      "Test | 122/16 | Loss:0.5151 | MainLoss:0.5151 | SPLoss:364.5692 | CLSLoss:0.0000 | AUROC:0.8717\n",
      "\n",
      "Epoch: [70 | 1000] LR: 0.199840\n",
      "Train | 16/16 | Loss:27.0058 | MainLoss:0.3779 | Alpha:0.0569 | SPLoss:266.2786 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2603 | MainLoss:0.2603 | SPLoss:178.3588 | CLSLoss:0.0000 | AUROC:0.9633\n",
      "Test | 122/16 | Loss:0.3649 | MainLoss:0.3649 | SPLoss:178.3587 | CLSLoss:0.0000 | AUROC:0.9190\n",
      "\n",
      "Epoch: [71 | 1000] LR: 0.199822\n",
      "Train | 16/16 | Loss:13.6526 | MainLoss:0.5406 | Alpha:0.0563 | SPLoss:131.1201 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.5045 | MainLoss:0.5045 | SPLoss:89.2817 | CLSLoss:0.0000 | AUROC:0.9364\n",
      "Test | 122/16 | Loss:0.7123 | MainLoss:0.7123 | SPLoss:89.2817 | CLSLoss:0.0000 | AUROC:0.7153\n",
      "\n",
      "Epoch: [72 | 1000] LR: 0.199803\n",
      "Train | 16/16 | Loss:6.9696 | MainLoss:0.4205 | Alpha:0.0584 | SPLoss:65.4911 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3062 | MainLoss:0.3062 | SPLoss:44.3798 | CLSLoss:0.0000 | AUROC:0.9551\n",
      "Test | 122/16 | Loss:0.4807 | MainLoss:0.4807 | SPLoss:44.3798 | CLSLoss:0.0000 | AUROC:0.8565\n",
      "\n",
      "Epoch: [73 | 1000] LR: 0.199782\n",
      "Train | 16/16 | Loss:3.6800 | MainLoss:0.3845 | Alpha:0.0562 | SPLoss:32.9556 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2538 | MainLoss:0.2538 | SPLoss:22.6139 | CLSLoss:0.0000 | AUROC:0.9636\n",
      "Test | 122/16 | Loss:0.4186 | MainLoss:0.4186 | SPLoss:22.6140 | CLSLoss:0.0000 | AUROC:0.9000\n",
      "\n",
      "Epoch: [74 | 1000] LR: 0.199761\n",
      "Train | 16/16 | Loss:2.1441 | MainLoss:0.4227 | Alpha:0.0571 | SPLoss:17.2148 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3207 | MainLoss:0.3207 | SPLoss:12.5005 | CLSLoss:0.0000 | AUROC:0.9479\n",
      "Test | 122/16 | Loss:0.7863 | MainLoss:0.7863 | SPLoss:12.5005 | CLSLoss:0.0000 | AUROC:0.6871\n",
      "\n",
      "Epoch: [75 | 1000] LR: 0.199739\n",
      "Train | 16/16 | Loss:2.0805 | MainLoss:0.3955 | Alpha:0.0569 | SPLoss:16.8500 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2764 | MainLoss:0.2764 | SPLoss:19.2645 | CLSLoss:0.0000 | AUROC:0.9596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 122/16 | Loss:0.5235 | MainLoss:0.5235 | SPLoss:19.2645 | CLSLoss:0.0000 | AUROC:0.8411\n",
      "\n",
      "Epoch: [76 | 1000] LR: 0.199716\n",
      "Train | 16/16 | Loss:1.8677 | MainLoss:0.3980 | Alpha:0.0573 | SPLoss:14.6970 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2789 | MainLoss:0.2789 | SPLoss:10.7566 | CLSLoss:0.0000 | AUROC:0.9582\n",
      "Test | 122/16 | Loss:0.6876 | MainLoss:0.6876 | SPLoss:10.7566 | CLSLoss:0.0000 | AUROC:0.7370\n",
      "\n",
      "Epoch: [77 | 1000] LR: 0.199692\n",
      "Train | 16/16 | Loss:1.3080 | MainLoss:0.4494 | Alpha:0.0572 | SPLoss:8.5866 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3067 | MainLoss:0.3067 | SPLoss:6.5338 | CLSLoss:0.0000 | AUROC:0.9564\n",
      "Test | 122/16 | Loss:0.5767 | MainLoss:0.5767 | SPLoss:6.5338 | CLSLoss:0.0000 | AUROC:0.7863\n",
      "\n",
      "Epoch: [78 | 1000] LR: 0.199667\n",
      "Train | 16/16 | Loss:0.9395 | MainLoss:0.4086 | Alpha:0.0580 | SPLoss:5.3090 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3166 | MainLoss:0.3166 | SPLoss:4.1880 | CLSLoss:0.0000 | AUROC:0.9574\n",
      "Test | 122/16 | Loss:0.4777 | MainLoss:0.4777 | SPLoss:4.1880 | CLSLoss:0.0000 | AUROC:0.8594\n",
      "\n",
      "Epoch: [79 | 1000] LR: 0.199640\n",
      "Train | 16/16 | Loss:0.7596 | MainLoss:0.3908 | Alpha:0.0560 | SPLoss:3.6872 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3009 | MainLoss:0.3009 | SPLoss:3.5155 | CLSLoss:0.0000 | AUROC:0.9507\n",
      "Test | 122/16 | Loss:0.7533 | MainLoss:0.7533 | SPLoss:3.5155 | CLSLoss:0.0000 | AUROC:0.6825\n",
      "\n",
      "Epoch: [80 | 1000] LR: 0.199613\n",
      "Train | 16/16 | Loss:4.0017 | MainLoss:0.4024 | Alpha:0.0596 | SPLoss:35.9932 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3031 | MainLoss:0.3031 | SPLoss:50.6719 | CLSLoss:0.0000 | AUROC:0.9532\n",
      "Test | 122/16 | Loss:0.5019 | MainLoss:0.5019 | SPLoss:50.6719 | CLSLoss:0.0000 | AUROC:0.8469\n",
      "\n",
      "Epoch: [81 | 1000] LR: 0.199585\n",
      "Train | 16/16 | Loss:4.1451 | MainLoss:0.3946 | Alpha:0.0560 | SPLoss:37.5054 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3010 | MainLoss:0.3010 | SPLoss:25.7962 | CLSLoss:0.0000 | AUROC:0.9599\n",
      "Test | 122/16 | Loss:0.4673 | MainLoss:0.4673 | SPLoss:25.7962 | CLSLoss:0.0000 | AUROC:0.8634\n",
      "\n",
      "Epoch: [82 | 1000] LR: 0.199556\n",
      "Train | 16/16 | Loss:2.3069 | MainLoss:0.3609 | Alpha:0.0570 | SPLoss:19.4606 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2604 | MainLoss:0.2604 | SPLoss:13.6733 | CLSLoss:0.0000 | AUROC:0.9611\n",
      "Test | 122/16 | Loss:0.4904 | MainLoss:0.4904 | SPLoss:13.6733 | CLSLoss:0.0000 | AUROC:0.8878\n",
      "\n",
      "Epoch: [83 | 1000] LR: 0.199526\n",
      "Train | 16/16 | Loss:1.4429 | MainLoss:0.3763 | Alpha:0.0600 | SPLoss:10.6669 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3987 | MainLoss:0.3987 | SPLoss:8.0667 | CLSLoss:0.0000 | AUROC:0.9546\n",
      "Test | 122/16 | Loss:0.8553 | MainLoss:0.8553 | SPLoss:8.0667 | CLSLoss:0.0000 | AUROC:0.8798\n",
      "\n",
      "Epoch: [84 | 1000] LR: 0.199495\n",
      "Train | 16/16 | Loss:1.0429 | MainLoss:0.3832 | Alpha:0.0567 | SPLoss:6.5974 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2530 | MainLoss:0.2530 | SPLoss:5.0625 | CLSLoss:0.0000 | AUROC:0.9659\n",
      "Test | 122/16 | Loss:0.4193 | MainLoss:0.4193 | SPLoss:5.0625 | CLSLoss:0.0000 | AUROC:0.8975\n",
      "\n",
      "Epoch: [85 | 1000] LR: 0.199463\n",
      "Train | 16/16 | Loss:0.8118 | MainLoss:0.3758 | Alpha:0.0612 | SPLoss:4.3603 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2692 | MainLoss:0.2692 | SPLoss:3.5504 | CLSLoss:0.0000 | AUROC:0.9645\n",
      "Test | 122/16 | Loss:0.3794 | MainLoss:0.3794 | SPLoss:3.5504 | CLSLoss:0.0000 | AUROC:0.9159\n",
      "\n",
      "Epoch: [86 | 1000] LR: 0.199430\n",
      "Train | 16/16 | Loss:0.7318 | MainLoss:0.4005 | Alpha:0.0562 | SPLoss:3.3137 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2969 | MainLoss:0.2969 | SPLoss:3.0348 | CLSLoss:0.0000 | AUROC:0.9576\n",
      "Test | 122/16 | Loss:0.5902 | MainLoss:0.5902 | SPLoss:3.0348 | CLSLoss:0.0000 | AUROC:0.7858\n",
      "\n",
      "Epoch: [87 | 1000] LR: 0.199396\n",
      "Train | 16/16 | Loss:0.7493 | MainLoss:0.4373 | Alpha:0.0593 | SPLoss:3.1202 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3765 | MainLoss:0.3765 | SPLoss:3.2542 | CLSLoss:0.0000 | AUROC:0.9384\n",
      "Test | 122/16 | Loss:0.8212 | MainLoss:0.8212 | SPLoss:3.2542 | CLSLoss:0.0000 | AUROC:0.5986\n",
      "\n",
      "Epoch: [88 | 1000] LR: 0.199361\n",
      "Train | 16/16 | Loss:0.6671 | MainLoss:0.3922 | Alpha:0.0575 | SPLoss:2.7492 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3128 | MainLoss:0.3128 | SPLoss:2.5100 | CLSLoss:0.0000 | AUROC:0.9548\n",
      "Test | 122/16 | Loss:0.6412 | MainLoss:0.6412 | SPLoss:2.5100 | CLSLoss:0.0000 | AUROC:0.7998\n",
      "\n",
      "Epoch: [89 | 1000] LR: 0.199325\n",
      "Train | 16/16 | Loss:0.6159 | MainLoss:0.3717 | Alpha:0.0560 | SPLoss:2.4419 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2870 | MainLoss:0.2870 | SPLoss:2.3770 | CLSLoss:0.0000 | AUROC:0.9627\n",
      "Test | 122/16 | Loss:0.4695 | MainLoss:0.4695 | SPLoss:2.3770 | CLSLoss:0.0000 | AUROC:0.8658\n",
      "\n",
      "Epoch: [90 | 1000] LR: 0.199288\n",
      "Train | 16/16 | Loss:0.6463 | MainLoss:0.4055 | Alpha:0.0584 | SPLoss:2.4080 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3756 | MainLoss:0.3756 | SPLoss:2.9810 | CLSLoss:0.0000 | AUROC:0.9477\n",
      "Test | 122/16 | Loss:0.7246 | MainLoss:0.7246 | SPLoss:2.9810 | CLSLoss:0.0000 | AUROC:0.6329\n",
      "\n",
      "Epoch: [91 | 1000] LR: 0.199250\n",
      "Train | 16/16 | Loss:0.6139 | MainLoss:0.3593 | Alpha:0.0581 | SPLoss:2.5457 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2929 | MainLoss:0.2929 | SPLoss:2.1415 | CLSLoss:0.0000 | AUROC:0.9603\n",
      "Test | 122/16 | Loss:0.3722 | MainLoss:0.3722 | SPLoss:2.1415 | CLSLoss:0.0000 | AUROC:0.9234\n",
      "\n",
      "Epoch: [92 | 1000] LR: 0.199211\n",
      "Train | 16/16 | Loss:0.7109 | MainLoss:0.4522 | Alpha:0.0570 | SPLoss:2.5868 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.5109 | MainLoss:0.5109 | SPLoss:3.0924 | CLSLoss:0.0000 | AUROC:0.9260\n",
      "Test | 122/16 | Loss:0.8288 | MainLoss:0.8288 | SPLoss:3.0923 | CLSLoss:0.0000 | AUROC:0.6698\n",
      "\n",
      "Epoch: [93 | 1000] LR: 0.199172\n",
      "Train | 16/16 | Loss:0.6673 | MainLoss:0.3948 | Alpha:0.0579 | SPLoss:2.7259 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2967 | MainLoss:0.2967 | SPLoss:2.3965 | CLSLoss:0.0000 | AUROC:0.9619\n",
      "Test | 122/16 | Loss:0.4064 | MainLoss:0.4064 | SPLoss:2.3965 | CLSLoss:0.0000 | AUROC:0.9045\n",
      "\n",
      "Epoch: [94 | 1000] LR: 0.199131\n",
      "Train | 16/16 | Loss:0.6379 | MainLoss:0.3950 | Alpha:0.0558 | SPLoss:2.4292 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2672 | MainLoss:0.2672 | SPLoss:2.3500 | CLSLoss:0.0000 | AUROC:0.9649\n",
      "Test | 122/16 | Loss:0.4393 | MainLoss:0.4393 | SPLoss:2.3500 | CLSLoss:0.0000 | AUROC:0.8826\n",
      "\n",
      "Epoch: [95 | 1000] LR: 0.199089\n",
      "Train | 16/16 | Loss:0.6816 | MainLoss:0.4256 | Alpha:0.0574 | SPLoss:2.5603 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3091 | MainLoss:0.3091 | SPLoss:2.4551 | CLSLoss:0.0000 | AUROC:0.9483\n",
      "Test | 122/16 | Loss:0.6172 | MainLoss:0.6172 | SPLoss:2.4551 | CLSLoss:0.0000 | AUROC:0.8134\n",
      "\n",
      "Epoch: [96 | 1000] LR: 0.199046\n",
      "Train | 16/16 | Loss:0.6008 | MainLoss:0.3721 | Alpha:0.0562 | SPLoss:2.2864 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2651 | MainLoss:0.2651 | SPLoss:2.1092 | CLSLoss:0.0000 | AUROC:0.9636\n",
      "Test | 122/16 | Loss:0.4076 | MainLoss:0.4076 | SPLoss:2.1092 | CLSLoss:0.0000 | AUROC:0.9235\n",
      "\n",
      "Epoch: [97 | 1000] LR: 0.199002\n",
      "Train | 16/16 | Loss:1.0269 | MainLoss:0.3716 | Alpha:0.0565 | SPLoss:6.5529 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2531 | MainLoss:0.2531 | SPLoss:20.3436 | CLSLoss:0.0000 | AUROC:0.9647\n",
      "Test | 122/16 | Loss:0.7052 | MainLoss:0.7052 | SPLoss:20.3436 | CLSLoss:0.0000 | AUROC:0.7602\n",
      "\n",
      "Epoch: [98 | 1000] LR: 0.198958\n",
      "Train | 16/16 | Loss:1.9488 | MainLoss:0.4069 | Alpha:0.0593 | SPLoss:15.4194 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2762 | MainLoss:0.2762 | SPLoss:11.1119 | CLSLoss:0.0000 | AUROC:0.9554\n",
      "Test | 122/16 | Loss:0.5791 | MainLoss:0.5791 | SPLoss:11.1119 | CLSLoss:0.0000 | AUROC:0.8233\n",
      "\n",
      "Epoch: [99 | 1000] LR: 0.198912\n",
      "Train | 16/16 | Loss:1.2828 | MainLoss:0.4104 | Alpha:0.0555 | SPLoss:8.7244 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3076 | MainLoss:0.3076 | SPLoss:6.7266 | CLSLoss:0.0000 | AUROC:0.9504\n",
      "Test | 122/16 | Loss:0.6308 | MainLoss:0.6308 | SPLoss:6.7266 | CLSLoss:0.0000 | AUROC:0.7609\n",
      "\n",
      "Epoch: [100 | 1000] LR: 0.198865\n",
      "Train | 16/16 | Loss:0.8914 | MainLoss:0.3525 | Alpha:0.0562 | SPLoss:5.3892 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2428 | MainLoss:0.2428 | SPLoss:4.3150 | CLSLoss:0.0000 | AUROC:0.9639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 122/16 | Loss:0.4857 | MainLoss:0.4857 | SPLoss:4.3150 | CLSLoss:0.0000 | AUROC:0.8923\n",
      "\n",
      "Epoch: [101 | 1000] LR: 0.198817\n",
      "Train | 16/16 | Loss:0.3257 | MainLoss:0.3079 | Alpha:0.4301 | SPLoss:0.1779 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2075 | MainLoss:0.2075 | SPLoss:0.3392 | CLSLoss:0.0000 | AUROC:0.9744\n",
      "Test | 122/16 | Loss:0.5466 | MainLoss:0.5466 | SPLoss:0.3392 | CLSLoss:0.0000 | AUROC:0.8505\n",
      "\n",
      "Epoch: [102 | 1000] LR: 0.198769\n",
      "Train | 16/16 | Loss:0.3225 | MainLoss:0.2801 | Alpha:0.4299 | SPLoss:0.4244 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1926 | MainLoss:0.1926 | SPLoss:0.4487 | CLSLoss:0.0000 | AUROC:0.9781\n",
      "Test | 122/16 | Loss:0.5150 | MainLoss:0.5150 | SPLoss:0.4487 | CLSLoss:0.0000 | AUROC:0.8715\n",
      "\n",
      "Epoch: [103 | 1000] LR: 0.198719\n",
      "Train | 16/16 | Loss:0.3251 | MainLoss:0.2747 | Alpha:0.4262 | SPLoss:0.5045 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1986 | MainLoss:0.1986 | SPLoss:0.5494 | CLSLoss:0.0000 | AUROC:0.9814\n",
      "Test | 122/16 | Loss:0.5745 | MainLoss:0.5745 | SPLoss:0.5494 | CLSLoss:0.0000 | AUROC:0.8236\n",
      "\n",
      "Epoch: [104 | 1000] LR: 0.198669\n",
      "Train | 16/16 | Loss:0.3179 | MainLoss:0.2629 | Alpha:0.4275 | SPLoss:0.5502 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2534 | MainLoss:0.2534 | SPLoss:0.5677 | CLSLoss:0.0000 | AUROC:0.9820\n",
      "Test | 122/16 | Loss:0.5108 | MainLoss:0.5108 | SPLoss:0.5677 | CLSLoss:0.0000 | AUROC:0.8571\n",
      "\n",
      "Epoch: [105 | 1000] LR: 0.198617\n",
      "Train | 16/16 | Loss:0.3211 | MainLoss:0.2539 | Alpha:0.4286 | SPLoss:0.6718 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1798 | MainLoss:0.1798 | SPLoss:0.7300 | CLSLoss:0.0000 | AUROC:0.9817\n",
      "Test | 122/16 | Loss:0.6585 | MainLoss:0.6585 | SPLoss:0.7300 | CLSLoss:0.0000 | AUROC:0.8182\n",
      "\n",
      "Epoch: [106 | 1000] LR: 0.198564\n",
      "Train | 16/16 | Loss:0.3014 | MainLoss:0.2321 | Alpha:0.4301 | SPLoss:0.6932 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1996 | MainLoss:0.1996 | SPLoss:0.6398 | CLSLoss:0.0000 | AUROC:0.9828\n",
      "Test | 122/16 | Loss:0.4750 | MainLoss:0.4750 | SPLoss:0.6398 | CLSLoss:0.0000 | AUROC:0.8799\n",
      "\n",
      "Epoch: [107 | 1000] LR: 0.198511\n",
      "Train | 16/16 | Loss:0.3443 | MainLoss:0.2761 | Alpha:0.4298 | SPLoss:0.6820 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1751 | MainLoss:0.1751 | SPLoss:0.6747 | CLSLoss:0.0000 | AUROC:0.9830\n",
      "Test | 122/16 | Loss:0.5532 | MainLoss:0.5532 | SPLoss:0.6747 | CLSLoss:0.0000 | AUROC:0.8515\n",
      "\n",
      "Epoch: [108 | 1000] LR: 0.198456\n",
      "Train | 16/16 | Loss:0.3443 | MainLoss:0.2706 | Alpha:0.4284 | SPLoss:0.7367 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1767 | MainLoss:0.1767 | SPLoss:0.7023 | CLSLoss:0.0000 | AUROC:0.9805\n",
      "Test | 122/16 | Loss:0.6204 | MainLoss:0.6204 | SPLoss:0.7023 | CLSLoss:0.0000 | AUROC:0.8323\n",
      "\n",
      "Epoch: [109 | 1000] LR: 0.198401\n",
      "Train | 16/16 | Loss:0.3301 | MainLoss:0.2570 | Alpha:0.4280 | SPLoss:0.7307 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1839 | MainLoss:0.1839 | SPLoss:0.7971 | CLSLoss:0.0000 | AUROC:0.9796\n",
      "Test | 122/16 | Loss:0.5111 | MainLoss:0.5111 | SPLoss:0.7971 | CLSLoss:0.0000 | AUROC:0.8668\n",
      "\n",
      "Epoch: [110 | 1000] LR: 0.198345\n",
      "Train | 16/16 | Loss:0.3523 | MainLoss:0.2741 | Alpha:0.4252 | SPLoss:0.7821 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1898 | MainLoss:0.1898 | SPLoss:0.7022 | CLSLoss:0.0000 | AUROC:0.9832\n",
      "Test | 122/16 | Loss:0.5289 | MainLoss:0.5289 | SPLoss:0.7022 | CLSLoss:0.0000 | AUROC:0.8362\n",
      "\n",
      "Epoch: [111 | 1000] LR: 0.198287\n",
      "Train | 16/16 | Loss:0.3232 | MainLoss:0.2514 | Alpha:0.4259 | SPLoss:0.7182 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3080 | MainLoss:0.3080 | SPLoss:0.8239 | CLSLoss:0.0000 | AUROC:0.9808\n",
      "Test | 122/16 | Loss:0.5247 | MainLoss:0.5247 | SPLoss:0.8239 | CLSLoss:0.0000 | AUROC:0.8328\n",
      "\n",
      "Epoch: [112 | 1000] LR: 0.198229\n",
      "Train | 16/16 | Loss:0.3157 | MainLoss:0.2380 | Alpha:0.4290 | SPLoss:0.7776 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1694 | MainLoss:0.1694 | SPLoss:0.7184 | CLSLoss:0.0000 | AUROC:0.9817\n",
      "Test | 122/16 | Loss:0.5184 | MainLoss:0.5184 | SPLoss:0.7184 | CLSLoss:0.0000 | AUROC:0.8747\n",
      "\n",
      "Epoch: [113 | 1000] LR: 0.198169\n",
      "Train | 16/16 | Loss:0.3369 | MainLoss:0.2636 | Alpha:0.4283 | SPLoss:0.7325 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2271 | MainLoss:0.2271 | SPLoss:0.7004 | CLSLoss:0.0000 | AUROC:0.9832\n",
      "Test | 122/16 | Loss:0.4903 | MainLoss:0.4903 | SPLoss:0.7004 | CLSLoss:0.0000 | AUROC:0.8581\n",
      "\n",
      "Epoch: [114 | 1000] LR: 0.198109\n",
      "Train | 16/16 | Loss:0.3000 | MainLoss:0.2323 | Alpha:0.4301 | SPLoss:0.6766 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1784 | MainLoss:0.1784 | SPLoss:0.6426 | CLSLoss:0.0000 | AUROC:0.9826\n",
      "Test | 122/16 | Loss:0.6954 | MainLoss:0.6954 | SPLoss:0.6426 | CLSLoss:0.0000 | AUROC:0.8739\n",
      "\n",
      "Epoch: [115 | 1000] LR: 0.198048\n",
      "Train | 16/16 | Loss:0.3502 | MainLoss:0.2812 | Alpha:0.4223 | SPLoss:0.6901 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1707 | MainLoss:0.1707 | SPLoss:0.7946 | CLSLoss:0.0000 | AUROC:0.9831\n",
      "Test | 122/16 | Loss:0.5806 | MainLoss:0.5806 | SPLoss:0.7946 | CLSLoss:0.0000 | AUROC:0.8369\n",
      "\n",
      "Epoch: [116 | 1000] LR: 0.197986\n",
      "Train | 16/16 | Loss:0.3563 | MainLoss:0.2717 | Alpha:0.4228 | SPLoss:0.8462 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1969 | MainLoss:0.1969 | SPLoss:0.7993 | CLSLoss:0.0000 | AUROC:0.9833\n",
      "Test | 122/16 | Loss:0.5039 | MainLoss:0.5039 | SPLoss:0.7993 | CLSLoss:0.0000 | AUROC:0.8649\n",
      "\n",
      "Epoch: [117 | 1000] LR: 0.197922\n",
      "Train | 16/16 | Loss:0.3173 | MainLoss:0.2384 | Alpha:0.4262 | SPLoss:0.7891 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1695 | MainLoss:0.1695 | SPLoss:0.7448 | CLSLoss:0.0000 | AUROC:0.9828\n",
      "Test | 122/16 | Loss:0.5039 | MainLoss:0.5039 | SPLoss:0.7448 | CLSLoss:0.0000 | AUROC:0.8829\n",
      "\n",
      "Epoch: [118 | 1000] LR: 0.197858\n",
      "Train | 16/16 | Loss:0.3344 | MainLoss:0.2579 | Alpha:0.4251 | SPLoss:0.7651 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2045 | MainLoss:0.2045 | SPLoss:0.7707 | CLSLoss:0.0000 | AUROC:0.9830\n",
      "Test | 122/16 | Loss:0.5279 | MainLoss:0.5279 | SPLoss:0.7707 | CLSLoss:0.0000 | AUROC:0.8335\n",
      "\n",
      "Epoch: [119 | 1000] LR: 0.197793\n",
      "Train | 16/16 | Loss:0.3177 | MainLoss:0.2443 | Alpha:0.4265 | SPLoss:0.7331 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2221 | MainLoss:0.2221 | SPLoss:0.7264 | CLSLoss:0.0000 | AUROC:0.9820\n",
      "Test | 122/16 | Loss:0.5949 | MainLoss:0.5949 | SPLoss:0.7264 | CLSLoss:0.0000 | AUROC:0.7831\n",
      "\n",
      "Epoch: [120 | 1000] LR: 0.197727\n",
      "Train | 16/16 | Loss:0.2974 | MainLoss:0.2303 | Alpha:0.4269 | SPLoss:0.6713 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2725 | MainLoss:0.2725 | SPLoss:0.7161 | CLSLoss:0.0000 | AUROC:0.9818\n",
      "Test | 122/16 | Loss:0.5257 | MainLoss:0.5257 | SPLoss:0.7161 | CLSLoss:0.0000 | AUROC:0.8450\n",
      "\n",
      "Epoch: [121 | 1000] LR: 0.197660\n",
      "Train | 16/16 | Loss:0.3345 | MainLoss:0.2657 | Alpha:0.4232 | SPLoss:0.6874 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2025 | MainLoss:0.2025 | SPLoss:0.7041 | CLSLoss:0.0000 | AUROC:0.9808\n",
      "Test | 122/16 | Loss:0.4942 | MainLoss:0.4942 | SPLoss:0.7041 | CLSLoss:0.0000 | AUROC:0.8555\n",
      "\n",
      "Epoch: [122 | 1000] LR: 0.197592\n",
      "Train | 16/16 | Loss:0.3354 | MainLoss:0.2464 | Alpha:0.4267 | SPLoss:0.8905 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1808 | MainLoss:0.1808 | SPLoss:4.8216 | CLSLoss:0.0000 | AUROC:0.9841\n",
      "Test | 122/16 | Loss:0.4591 | MainLoss:0.4591 | SPLoss:4.8216 | CLSLoss:0.0000 | AUROC:0.8802\n",
      "\n",
      "Epoch: [123 | 1000] LR: 0.197523\n",
      "Train | 16/16 | Loss:0.7466 | MainLoss:0.3452 | Alpha:0.4253 | SPLoss:4.0139 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2081 | MainLoss:0.2081 | SPLoss:3.0300 | CLSLoss:0.0000 | AUROC:0.9785\n",
      "Test | 122/16 | Loss:0.8163 | MainLoss:0.8163 | SPLoss:3.0300 | CLSLoss:0.0000 | AUROC:0.7997\n",
      "\n",
      "Epoch: [124 | 1000] LR: 0.197453\n",
      "Train | 16/16 | Loss:0.4889 | MainLoss:0.2496 | Alpha:0.4292 | SPLoss:2.3930 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2237 | MainLoss:0.2237 | SPLoss:1.8032 | CLSLoss:0.0000 | AUROC:0.9829\n",
      "Test | 122/16 | Loss:0.5444 | MainLoss:0.5444 | SPLoss:1.8032 | CLSLoss:0.0000 | AUROC:0.8359\n",
      "\n",
      "Epoch: [125 | 1000] LR: 0.197382\n",
      "Train | 16/16 | Loss:0.4211 | MainLoss:0.2679 | Alpha:0.4263 | SPLoss:1.5325 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1995 | MainLoss:0.1995 | SPLoss:1.3132 | CLSLoss:0.0000 | AUROC:0.9788\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 122/16 | Loss:0.6680 | MainLoss:0.6680 | SPLoss:1.3132 | CLSLoss:0.0000 | AUROC:0.7919\n",
      "\n",
      "Epoch: [126 | 1000] LR: 0.197310\n",
      "Train | 16/16 | Loss:0.3592 | MainLoss:0.2441 | Alpha:0.4278 | SPLoss:1.1509 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1934 | MainLoss:0.1934 | SPLoss:0.9820 | CLSLoss:0.0000 | AUROC:0.9832\n",
      "Test | 122/16 | Loss:0.5315 | MainLoss:0.5315 | SPLoss:0.9820 | CLSLoss:0.0000 | AUROC:0.8441\n",
      "\n",
      "Epoch: [127 | 1000] LR: 0.197237\n",
      "Train | 16/16 | Loss:0.3673 | MainLoss:0.2735 | Alpha:0.4270 | SPLoss:0.9381 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1739 | MainLoss:0.1739 | SPLoss:0.8390 | CLSLoss:0.0000 | AUROC:0.9838\n",
      "Test | 122/16 | Loss:0.4959 | MainLoss:0.4959 | SPLoss:0.8390 | CLSLoss:0.0000 | AUROC:0.8677\n",
      "\n",
      "Epoch: [128 | 1000] LR: 0.197163\n",
      "Train | 16/16 | Loss:0.3161 | MainLoss:0.2403 | Alpha:0.4246 | SPLoss:0.7587 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1933 | MainLoss:0.1933 | SPLoss:0.6893 | CLSLoss:0.0000 | AUROC:0.9803\n",
      "Test | 122/16 | Loss:0.5120 | MainLoss:0.5120 | SPLoss:0.6893 | CLSLoss:0.0000 | AUROC:0.8561\n",
      "\n",
      "Epoch: [129 | 1000] LR: 0.197088\n",
      "Train | 16/16 | Loss:0.3124 | MainLoss:0.2434 | Alpha:0.4280 | SPLoss:0.6892 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1855 | MainLoss:0.1855 | SPLoss:0.6658 | CLSLoss:0.0000 | AUROC:0.9814\n",
      "Test | 122/16 | Loss:0.5174 | MainLoss:0.5174 | SPLoss:0.6658 | CLSLoss:0.0000 | AUROC:0.8653\n",
      "\n",
      "Epoch: [130 | 1000] LR: 0.197013\n",
      "Train | 16/16 | Loss:0.3358 | MainLoss:0.2652 | Alpha:0.4242 | SPLoss:0.7061 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2154 | MainLoss:0.2154 | SPLoss:0.6532 | CLSLoss:0.0000 | AUROC:0.9832\n",
      "Test | 122/16 | Loss:0.4952 | MainLoss:0.4952 | SPLoss:0.6532 | CLSLoss:0.0000 | AUROC:0.8547\n",
      "\n",
      "Epoch: [131 | 1000] LR: 0.196936\n",
      "Train | 16/16 | Loss:0.3416 | MainLoss:0.2661 | Alpha:0.4261 | SPLoss:0.7545 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3002 | MainLoss:0.3002 | SPLoss:0.8041 | CLSLoss:0.0000 | AUROC:0.9814\n",
      "Test | 122/16 | Loss:0.5871 | MainLoss:0.5871 | SPLoss:0.8041 | CLSLoss:0.0000 | AUROC:0.8129\n",
      "\n",
      "Epoch: [132 | 1000] LR: 0.196858\n",
      "Train | 16/16 | Loss:0.3351 | MainLoss:0.2611 | Alpha:0.4274 | SPLoss:0.7395 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1754 | MainLoss:0.1754 | SPLoss:0.6811 | CLSLoss:0.0000 | AUROC:0.9810\n",
      "Test | 122/16 | Loss:0.6227 | MainLoss:0.6227 | SPLoss:0.6811 | CLSLoss:0.0000 | AUROC:0.8231\n",
      "\n",
      "Epoch: [133 | 1000] LR: 0.196780\n",
      "Train | 16/16 | Loss:0.3192 | MainLoss:0.2543 | Alpha:0.4253 | SPLoss:0.6486 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1765 | MainLoss:0.1765 | SPLoss:0.6479 | CLSLoss:0.0000 | AUROC:0.9818\n",
      "Test | 122/16 | Loss:0.5660 | MainLoss:0.5660 | SPLoss:0.6479 | CLSLoss:0.0000 | AUROC:0.8349\n",
      "\n",
      "Epoch: [134 | 1000] LR: 0.196700\n",
      "Train | 16/16 | Loss:0.3044 | MainLoss:0.2391 | Alpha:0.4296 | SPLoss:0.6527 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1869 | MainLoss:0.1869 | SPLoss:0.6585 | CLSLoss:0.0000 | AUROC:0.9803\n",
      "Test | 122/16 | Loss:0.7207 | MainLoss:0.7207 | SPLoss:0.6585 | CLSLoss:0.0000 | AUROC:0.8620\n",
      "\n",
      "Epoch: [135 | 1000] LR: 0.196620\n",
      "Train | 16/16 | Loss:0.3078 | MainLoss:0.2440 | Alpha:0.4247 | SPLoss:0.6374 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1618 | MainLoss:0.1618 | SPLoss:0.6724 | CLSLoss:0.0000 | AUROC:0.9830\n",
      "Test | 122/16 | Loss:0.7186 | MainLoss:0.7186 | SPLoss:0.6724 | CLSLoss:0.0000 | AUROC:0.8543\n",
      "\n",
      "Epoch: [136 | 1000] LR: 0.196538\n",
      "Train | 16/16 | Loss:0.3117 | MainLoss:0.2412 | Alpha:0.4261 | SPLoss:0.7046 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1625 | MainLoss:0.1625 | SPLoss:0.6567 | CLSLoss:0.0000 | AUROC:0.9829\n",
      "Test | 122/16 | Loss:0.5037 | MainLoss:0.5037 | SPLoss:0.6567 | CLSLoss:0.0000 | AUROC:0.9078\n",
      "\n",
      "Epoch: [137 | 1000] LR: 0.196456\n",
      "Train | 16/16 | Loss:0.3485 | MainLoss:0.2760 | Alpha:0.4271 | SPLoss:0.7252 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1684 | MainLoss:0.1684 | SPLoss:0.6659 | CLSLoss:0.0000 | AUROC:0.9839\n",
      "Test | 122/16 | Loss:0.5248 | MainLoss:0.5248 | SPLoss:0.6659 | CLSLoss:0.0000 | AUROC:0.8634\n",
      "\n",
      "Epoch: [138 | 1000] LR: 0.196372\n",
      "Train | 16/16 | Loss:0.3127 | MainLoss:0.2471 | Alpha:0.4253 | SPLoss:0.6558 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1760 | MainLoss:0.1760 | SPLoss:0.6511 | CLSLoss:0.0000 | AUROC:0.9827\n",
      "Test | 122/16 | Loss:0.6300 | MainLoss:0.6300 | SPLoss:0.6511 | CLSLoss:0.0000 | AUROC:0.8161\n",
      "\n",
      "Epoch: [139 | 1000] LR: 0.196288\n",
      "Train | 16/16 | Loss:0.3170 | MainLoss:0.2528 | Alpha:0.4253 | SPLoss:0.6423 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1834 | MainLoss:0.1834 | SPLoss:0.6214 | CLSLoss:0.0000 | AUROC:0.9820\n",
      "Test | 122/16 | Loss:0.5317 | MainLoss:0.5317 | SPLoss:0.6214 | CLSLoss:0.0000 | AUROC:0.9190\n",
      "\n",
      "Epoch: [140 | 1000] LR: 0.196203\n",
      "Train | 16/16 | Loss:0.3289 | MainLoss:0.2619 | Alpha:0.4266 | SPLoss:0.6703 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1852 | MainLoss:0.1852 | SPLoss:0.7094 | CLSLoss:0.0000 | AUROC:0.9809\n",
      "Test | 122/16 | Loss:0.4515 | MainLoss:0.4515 | SPLoss:0.7094 | CLSLoss:0.0000 | AUROC:0.8823\n",
      "\n",
      "Epoch: [141 | 1000] LR: 0.196117\n",
      "Train | 16/16 | Loss:0.2930 | MainLoss:0.2247 | Alpha:0.4288 | SPLoss:0.6828 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1727 | MainLoss:0.1727 | SPLoss:0.6190 | CLSLoss:0.0000 | AUROC:0.9822\n",
      "Test | 122/16 | Loss:0.5010 | MainLoss:0.5010 | SPLoss:0.6190 | CLSLoss:0.0000 | AUROC:0.9074\n",
      "\n",
      "Epoch: [142 | 1000] LR: 0.196029\n",
      "Train | 16/16 | Loss:0.3068 | MainLoss:0.2441 | Alpha:0.4283 | SPLoss:0.6267 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1858 | MainLoss:0.1858 | SPLoss:0.6319 | CLSLoss:0.0000 | AUROC:0.9834\n",
      "Test | 122/16 | Loss:0.5257 | MainLoss:0.5257 | SPLoss:0.6319 | CLSLoss:0.0000 | AUROC:0.8543\n",
      "\n",
      "Epoch: [143 | 1000] LR: 0.195941\n",
      "Train | 16/16 | Loss:0.3480 | MainLoss:0.2750 | Alpha:0.4264 | SPLoss:0.7298 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1891 | MainLoss:0.1891 | SPLoss:0.7573 | CLSLoss:0.0000 | AUROC:0.9770\n",
      "Test | 122/16 | Loss:0.8703 | MainLoss:0.8703 | SPLoss:0.7573 | CLSLoss:0.0000 | AUROC:0.7527\n",
      "\n",
      "Epoch: [144 | 1000] LR: 0.195852\n",
      "Train | 16/16 | Loss:0.3373 | MainLoss:0.2601 | Alpha:0.4277 | SPLoss:0.7717 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1672 | MainLoss:0.1672 | SPLoss:0.8243 | CLSLoss:0.0000 | AUROC:0.9825\n",
      "Test | 122/16 | Loss:0.5499 | MainLoss:0.5499 | SPLoss:0.8243 | CLSLoss:0.0000 | AUROC:0.8527\n",
      "\n",
      "Epoch: [145 | 1000] LR: 0.195762\n",
      "Train | 16/16 | Loss:0.3701 | MainLoss:0.2383 | Alpha:0.4297 | SPLoss:1.3186 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1770 | MainLoss:0.1770 | SPLoss:1.6806 | CLSLoss:0.0000 | AUROC:0.9821\n",
      "Test | 122/16 | Loss:0.5952 | MainLoss:0.5952 | SPLoss:1.6806 | CLSLoss:0.0000 | AUROC:0.8400\n",
      "\n",
      "Epoch: [146 | 1000] LR: 0.195671\n",
      "Train | 16/16 | Loss:0.4172 | MainLoss:0.2721 | Alpha:0.4273 | SPLoss:1.4508 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1617 | MainLoss:0.1617 | SPLoss:1.2103 | CLSLoss:0.0000 | AUROC:0.9837\n",
      "Test | 122/16 | Loss:0.5691 | MainLoss:0.5691 | SPLoss:1.2103 | CLSLoss:0.0000 | AUROC:0.8531\n",
      "\n",
      "Epoch: [147 | 1000] LR: 0.195579\n",
      "Train | 16/16 | Loss:0.3708 | MainLoss:0.2600 | Alpha:0.4288 | SPLoss:1.1089 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3564 | MainLoss:0.3564 | SPLoss:1.0679 | CLSLoss:0.0000 | AUROC:0.9777\n",
      "Test | 122/16 | Loss:0.6896 | MainLoss:0.6896 | SPLoss:1.0679 | CLSLoss:0.0000 | AUROC:0.7506\n",
      "\n",
      "Epoch: [148 | 1000] LR: 0.195486\n",
      "Train | 16/16 | Loss:0.3354 | MainLoss:0.2419 | Alpha:0.4269 | SPLoss:0.9344 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1808 | MainLoss:0.1808 | SPLoss:0.8248 | CLSLoss:0.0000 | AUROC:0.9826\n",
      "Test | 122/16 | Loss:0.5673 | MainLoss:0.5673 | SPLoss:0.8248 | CLSLoss:0.0000 | AUROC:0.8391\n",
      "\n",
      "Epoch: [149 | 1000] LR: 0.195393\n",
      "Train | 16/16 | Loss:0.3140 | MainLoss:0.2360 | Alpha:0.4254 | SPLoss:0.7801 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1803 | MainLoss:0.1803 | SPLoss:0.7462 | CLSLoss:0.0000 | AUROC:0.9825\n",
      "Test | 122/16 | Loss:0.6470 | MainLoss:0.6470 | SPLoss:0.7462 | CLSLoss:0.0000 | AUROC:0.8147\n",
      "\n",
      "Epoch: [150 | 1000] LR: 0.195298\n",
      "Train | 16/16 | Loss:0.3103 | MainLoss:0.2396 | Alpha:0.4255 | SPLoss:0.7065 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1644 | MainLoss:0.1644 | SPLoss:0.6760 | CLSLoss:0.0000 | AUROC:0.9833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 122/16 | Loss:0.5938 | MainLoss:0.5938 | SPLoss:0.6760 | CLSLoss:0.0000 | AUROC:0.8477\n",
      "\n",
      "Epoch: [151 | 1000] LR: 0.195202\n",
      "Train | 16/16 | Loss:0.3407 | MainLoss:0.2736 | Alpha:0.4287 | SPLoss:0.6705 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.5666 | MainLoss:0.5666 | SPLoss:1.0751 | CLSLoss:0.0000 | AUROC:0.9701\n",
      "Test | 122/16 | Loss:0.8263 | MainLoss:0.8263 | SPLoss:1.0751 | CLSLoss:0.0000 | AUROC:0.6817\n",
      "\n",
      "Epoch: [152 | 1000] LR: 0.195106\n",
      "Train | 16/16 | Loss:0.4081 | MainLoss:0.3124 | Alpha:0.4254 | SPLoss:0.9563 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1869 | MainLoss:0.1869 | SPLoss:0.8022 | CLSLoss:0.0000 | AUROC:0.9811\n",
      "Test | 122/16 | Loss:0.6676 | MainLoss:0.6676 | SPLoss:0.8022 | CLSLoss:0.0000 | AUROC:0.7768\n",
      "\n",
      "Epoch: [153 | 1000] LR: 0.195008\n",
      "Train | 16/16 | Loss:0.3384 | MainLoss:0.2605 | Alpha:0.4279 | SPLoss:0.7789 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2076 | MainLoss:0.2076 | SPLoss:0.7241 | CLSLoss:0.0000 | AUROC:0.9831\n",
      "Test | 122/16 | Loss:0.5382 | MainLoss:0.5382 | SPLoss:0.7241 | CLSLoss:0.0000 | AUROC:0.8327\n",
      "\n",
      "Epoch: [154 | 1000] LR: 0.194910\n",
      "Train | 16/16 | Loss:0.4072 | MainLoss:0.3167 | Alpha:0.4286 | SPLoss:0.9052 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2126 | MainLoss:0.2126 | SPLoss:1.3164 | CLSLoss:0.0000 | AUROC:0.9756\n",
      "Test | 122/16 | Loss:0.8202 | MainLoss:0.8202 | SPLoss:1.3164 | CLSLoss:0.0000 | AUROC:0.7024\n",
      "\n",
      "Epoch: [155 | 1000] LR: 0.194810\n",
      "Train | 16/16 | Loss:0.3716 | MainLoss:0.2623 | Alpha:0.4284 | SPLoss:1.0925 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1669 | MainLoss:0.1669 | SPLoss:0.8903 | CLSLoss:0.0000 | AUROC:0.9830\n",
      "Test | 122/16 | Loss:0.5876 | MainLoss:0.5876 | SPLoss:0.8903 | CLSLoss:0.0000 | AUROC:0.8488\n",
      "\n",
      "Epoch: [156 | 1000] LR: 0.194710\n",
      "Train | 16/16 | Loss:0.3224 | MainLoss:0.2416 | Alpha:0.4281 | SPLoss:0.8088 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1837 | MainLoss:0.1837 | SPLoss:0.7443 | CLSLoss:0.0000 | AUROC:0.9841\n",
      "Test | 122/16 | Loss:0.4766 | MainLoss:0.4766 | SPLoss:0.7443 | CLSLoss:0.0000 | AUROC:0.8617\n",
      "\n",
      "Epoch: [157 | 1000] LR: 0.194609\n",
      "Train | 16/16 | Loss:0.3195 | MainLoss:0.2488 | Alpha:0.4270 | SPLoss:0.7077 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1725 | MainLoss:0.1725 | SPLoss:0.6808 | CLSLoss:0.0000 | AUROC:0.9831\n",
      "Test | 122/16 | Loss:0.4725 | MainLoss:0.4725 | SPLoss:0.6808 | CLSLoss:0.0000 | AUROC:0.9146\n",
      "\n",
      "Epoch: [158 | 1000] LR: 0.194506\n",
      "Train | 16/16 | Loss:0.3215 | MainLoss:0.2543 | Alpha:0.4257 | SPLoss:0.6728 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1563 | MainLoss:0.1563 | SPLoss:0.6291 | CLSLoss:0.0000 | AUROC:0.9847\n",
      "Test | 122/16 | Loss:0.4229 | MainLoss:0.4229 | SPLoss:0.6291 | CLSLoss:0.0000 | AUROC:0.9121\n",
      "\n",
      "Epoch: [159 | 1000] LR: 0.194403\n",
      "Train | 16/16 | Loss:0.3196 | MainLoss:0.2515 | Alpha:0.4291 | SPLoss:0.6811 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1824 | MainLoss:0.1824 | SPLoss:0.6922 | CLSLoss:0.0000 | AUROC:0.9818\n",
      "Test | 122/16 | Loss:0.5879 | MainLoss:0.5879 | SPLoss:0.6922 | CLSLoss:0.0000 | AUROC:0.8319\n",
      "\n",
      "Epoch: [160 | 1000] LR: 0.194299\n",
      "Train | 16/16 | Loss:0.4222 | MainLoss:0.3254 | Alpha:0.4264 | SPLoss:0.9680 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2026 | MainLoss:0.2026 | SPLoss:0.8932 | CLSLoss:0.0000 | AUROC:0.9831\n",
      "Test | 122/16 | Loss:0.7255 | MainLoss:0.7255 | SPLoss:0.8932 | CLSLoss:0.0000 | AUROC:0.8787\n",
      "\n",
      "Epoch: [161 | 1000] LR: 0.194194\n",
      "Train | 16/16 | Loss:0.3328 | MainLoss:0.2507 | Alpha:0.4273 | SPLoss:0.8210 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1684 | MainLoss:0.1684 | SPLoss:0.7566 | CLSLoss:0.0000 | AUROC:0.9854\n",
      "Test | 122/16 | Loss:0.5207 | MainLoss:0.5207 | SPLoss:0.7566 | CLSLoss:0.0000 | AUROC:0.8557\n",
      "\n",
      "Epoch: [162 | 1000] LR: 0.194088\n",
      "Train | 16/16 | Loss:0.3201 | MainLoss:0.2456 | Alpha:0.4290 | SPLoss:0.7453 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2263 | MainLoss:0.2263 | SPLoss:0.7247 | CLSLoss:0.0000 | AUROC:0.9825\n",
      "Test | 122/16 | Loss:0.6121 | MainLoss:0.6121 | SPLoss:0.7247 | CLSLoss:0.0000 | AUROC:0.7771\n",
      "\n",
      "Epoch: [163 | 1000] LR: 0.193981\n",
      "Train | 16/16 | Loss:0.3165 | MainLoss:0.2431 | Alpha:0.4286 | SPLoss:0.7343 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1678 | MainLoss:0.1678 | SPLoss:0.7372 | CLSLoss:0.0000 | AUROC:0.9833\n",
      "Test | 122/16 | Loss:0.5594 | MainLoss:0.5594 | SPLoss:0.7372 | CLSLoss:0.0000 | AUROC:0.8720\n",
      "\n",
      "Epoch: [164 | 1000] LR: 0.193873\n",
      "Train | 16/16 | Loss:0.3619 | MainLoss:0.2692 | Alpha:0.4259 | SPLoss:0.9275 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2480 | MainLoss:0.2480 | SPLoss:1.3167 | CLSLoss:0.0000 | AUROC:0.9789\n",
      "Test | 122/16 | Loss:0.9173 | MainLoss:0.9173 | SPLoss:1.3167 | CLSLoss:0.0000 | AUROC:0.8299\n",
      "\n",
      "Epoch: [165 | 1000] LR: 0.193765\n",
      "Train | 16/16 | Loss:0.3627 | MainLoss:0.2513 | Alpha:0.4284 | SPLoss:1.1138 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1640 | MainLoss:0.1640 | SPLoss:0.9220 | CLSLoss:0.0000 | AUROC:0.9829\n",
      "Test | 122/16 | Loss:0.5522 | MainLoss:0.5522 | SPLoss:0.9220 | CLSLoss:0.0000 | AUROC:0.8963\n",
      "\n",
      "Epoch: [166 | 1000] LR: 0.193655\n",
      "Train | 16/16 | Loss:0.3826 | MainLoss:0.2744 | Alpha:0.4288 | SPLoss:1.0821 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1712 | MainLoss:0.1712 | SPLoss:1.0140 | CLSLoss:0.0000 | AUROC:0.9825\n",
      "Test | 122/16 | Loss:0.5619 | MainLoss:0.5619 | SPLoss:1.0140 | CLSLoss:0.0000 | AUROC:0.8582\n",
      "\n",
      "Epoch: [167 | 1000] LR: 0.193544\n",
      "Train | 16/16 | Loss:0.3698 | MainLoss:0.2753 | Alpha:0.4248 | SPLoss:0.9451 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1753 | MainLoss:0.1753 | SPLoss:0.8881 | CLSLoss:0.0000 | AUROC:0.9812\n",
      "Test | 122/16 | Loss:0.6425 | MainLoss:0.6425 | SPLoss:0.8881 | CLSLoss:0.0000 | AUROC:0.8265\n",
      "\n",
      "Epoch: [168 | 1000] LR: 0.193433\n",
      "Train | 16/16 | Loss:0.3506 | MainLoss:0.2512 | Alpha:0.4285 | SPLoss:0.9946 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1781 | MainLoss:0.1781 | SPLoss:0.9438 | CLSLoss:0.0000 | AUROC:0.9825\n",
      "Test | 122/16 | Loss:0.4991 | MainLoss:0.4991 | SPLoss:0.9438 | CLSLoss:0.0000 | AUROC:0.8788\n",
      "\n",
      "Epoch: [169 | 1000] LR: 0.193320\n",
      "Train | 16/16 | Loss:796.3983 | MainLoss:0.3779 | Alpha:0.4283 | SPLoss:7960.2056 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3060 | MainLoss:0.3060 | SPLoss:9056.5908 | CLSLoss:0.0000 | AUROC:0.9754\n",
      "Test | 122/16 | Loss:0.6287 | MainLoss:0.6287 | SPLoss:9056.5801 | CLSLoss:0.0000 | AUROC:0.7815\n",
      "\n",
      "Epoch: [170 | 1000] LR: 0.193207\n",
      "Train | 16/16 | Loss:667.0042 | MainLoss:0.2705 | Alpha:0.4258 | SPLoss:6667.3369 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2478 | MainLoss:0.2478 | SPLoss:4514.9937 | CLSLoss:0.0000 | AUROC:0.9792\n",
      "Test | 122/16 | Loss:0.5488 | MainLoss:0.5488 | SPLoss:4515.0005 | CLSLoss:0.0000 | AUROC:0.8292\n",
      "\n",
      "Epoch: [171 | 1000] LR: 0.193093\n",
      "Train | 16/16 | Loss:332.7703 | MainLoss:0.2989 | Alpha:0.4277 | SPLoss:3324.7136 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2436 | MainLoss:0.2436 | SPLoss:2252.1348 | CLSLoss:0.0000 | AUROC:0.9735\n",
      "Test | 122/16 | Loss:0.7170 | MainLoss:0.7170 | SPLoss:2252.1316 | CLSLoss:0.0000 | AUROC:0.7345\n",
      "\n",
      "Epoch: [172 | 1000] LR: 0.192978\n",
      "Train | 16/16 | Loss:166.1287 | MainLoss:0.2610 | Alpha:0.4248 | SPLoss:1658.6772 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1986 | MainLoss:0.1986 | SPLoss:1123.9084 | CLSLoss:0.0000 | AUROC:0.9799\n",
      "Test | 122/16 | Loss:0.7574 | MainLoss:0.7574 | SPLoss:1123.9100 | CLSLoss:0.0000 | AUROC:0.8647\n",
      "\n",
      "Epoch: [173 | 1000] LR: 0.192862\n",
      "Train | 16/16 | Loss:83.0308 | MainLoss:0.2334 | Alpha:0.4288 | SPLoss:827.9737 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2740 | MainLoss:0.2740 | SPLoss:561.2797 | CLSLoss:0.0000 | AUROC:0.9835\n",
      "Test | 122/16 | Loss:0.4423 | MainLoss:0.4423 | SPLoss:561.2800 | CLSLoss:0.0000 | AUROC:0.9020\n",
      "\n",
      "Epoch: [174 | 1000] LR: 0.192745\n",
      "Train | 16/16 | Loss:41.6292 | MainLoss:0.2657 | Alpha:0.4253 | SPLoss:413.6357 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1861 | MainLoss:0.1861 | SPLoss:280.5819 | CLSLoss:0.0000 | AUROC:0.9814\n",
      "Test | 122/16 | Loss:0.4830 | MainLoss:0.4830 | SPLoss:280.5820 | CLSLoss:0.0000 | AUROC:0.8675\n",
      "\n",
      "Epoch: [175 | 1000] LR: 0.192627\n",
      "Train | 16/16 | Loss:20.9380 | MainLoss:0.2470 | Alpha:0.4268 | SPLoss:206.9107 | CLSLoss:0.0000 | AUROC:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 32/16 | Loss:0.1655 | MainLoss:0.1655 | SPLoss:140.4970 | CLSLoss:0.0000 | AUROC:0.9837\n",
      "Test | 122/16 | Loss:0.5252 | MainLoss:0.5252 | SPLoss:140.4970 | CLSLoss:0.0000 | AUROC:0.8660\n",
      "\n",
      "Epoch: [176 | 1000] LR: 0.192508\n",
      "Train | 16/16 | Loss:10.6101 | MainLoss:0.2398 | Alpha:0.4275 | SPLoss:103.7024 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1644 | MainLoss:0.1644 | SPLoss:70.5201 | CLSLoss:0.0000 | AUROC:0.9829\n",
      "Test | 122/16 | Loss:0.6364 | MainLoss:0.6364 | SPLoss:70.5200 | CLSLoss:0.0000 | AUROC:0.8458\n",
      "\n",
      "Epoch: [177 | 1000] LR: 0.192388\n",
      "Train | 16/16 | Loss:5.4518 | MainLoss:0.2372 | Alpha:0.4260 | SPLoss:52.1459 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2350 | MainLoss:0.2350 | SPLoss:35.5779 | CLSLoss:0.0000 | AUROC:0.9807\n",
      "Test | 122/16 | Loss:0.7220 | MainLoss:0.7220 | SPLoss:35.5778 | CLSLoss:0.0000 | AUROC:0.8861\n",
      "\n",
      "Epoch: [178 | 1000] LR: 0.192267\n",
      "Train | 16/16 | Loss:2.8976 | MainLoss:0.2579 | Alpha:0.4273 | SPLoss:26.3971 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1745 | MainLoss:0.1745 | SPLoss:18.1349 | CLSLoss:0.0000 | AUROC:0.9808\n",
      "Test | 122/16 | Loss:0.5332 | MainLoss:0.5332 | SPLoss:18.1349 | CLSLoss:0.0000 | AUROC:0.8829\n",
      "\n",
      "Epoch: [179 | 1000] LR: 0.192146\n",
      "Train | 16/16 | Loss:1.6149 | MainLoss:0.2560 | Alpha:0.4270 | SPLoss:13.5884 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2008 | MainLoss:0.2008 | SPLoss:9.4287 | CLSLoss:0.0000 | AUROC:0.9817\n",
      "Test | 122/16 | Loss:0.5265 | MainLoss:0.5265 | SPLoss:9.4287 | CLSLoss:0.0000 | AUROC:0.8494\n",
      "\n",
      "Epoch: [180 | 1000] LR: 0.192023\n",
      "Train | 16/16 | Loss:0.9316 | MainLoss:0.2204 | Alpha:0.4302 | SPLoss:7.1118 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2431 | MainLoss:0.2431 | SPLoss:5.0890 | CLSLoss:0.0000 | AUROC:0.9798\n",
      "Test | 122/16 | Loss:0.7733 | MainLoss:0.7733 | SPLoss:5.0890 | CLSLoss:0.0000 | AUROC:0.9051\n",
      "\n",
      "Epoch: [181 | 1000] LR: 0.191900\n",
      "Train | 16/16 | Loss:0.6829 | MainLoss:0.2845 | Alpha:0.4255 | SPLoss:3.9842 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2307 | MainLoss:0.2307 | SPLoss:2.9836 | CLSLoss:0.0000 | AUROC:0.9718\n",
      "Test | 122/16 | Loss:1.0543 | MainLoss:1.0543 | SPLoss:2.9837 | CLSLoss:0.0000 | AUROC:0.7322\n",
      "\n",
      "Epoch: [182 | 1000] LR: 0.191775\n",
      "Train | 16/16 | Loss:0.4916 | MainLoss:0.2544 | Alpha:0.4266 | SPLoss:2.3722 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1759 | MainLoss:0.1759 | SPLoss:1.8064 | CLSLoss:0.0000 | AUROC:0.9808\n",
      "Test | 122/16 | Loss:0.4816 | MainLoss:0.4816 | SPLoss:1.8064 | CLSLoss:0.0000 | AUROC:0.8838\n",
      "\n",
      "Epoch: [183 | 1000] LR: 0.191650\n",
      "Train | 16/16 | Loss:0.3936 | MainLoss:0.2441 | Alpha:0.4268 | SPLoss:1.4952 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1837 | MainLoss:0.1837 | SPLoss:1.2112 | CLSLoss:0.0000 | AUROC:0.9810\n",
      "Test | 122/16 | Loss:0.6039 | MainLoss:0.6039 | SPLoss:1.2112 | CLSLoss:0.0000 | AUROC:0.8183\n",
      "\n",
      "Epoch: [184 | 1000] LR: 0.191524\n",
      "Train | 16/16 | Loss:0.4925 | MainLoss:0.3517 | Alpha:0.4280 | SPLoss:1.4082 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3617 | MainLoss:0.3617 | SPLoss:2.1183 | CLSLoss:0.0000 | AUROC:0.9421\n",
      "Test | 122/16 | Loss:0.6573 | MainLoss:0.6573 | SPLoss:2.1183 | CLSLoss:0.0000 | AUROC:0.7149\n",
      "\n",
      "Epoch: [185 | 1000] LR: 0.191397\n",
      "Train | 16/16 | Loss:0.4836 | MainLoss:0.3077 | Alpha:0.4289 | SPLoss:1.7583 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2189 | MainLoss:0.2189 | SPLoss:1.3750 | CLSLoss:0.0000 | AUROC:0.9823\n",
      "Test | 122/16 | Loss:0.5485 | MainLoss:0.5485 | SPLoss:1.3750 | CLSLoss:0.0000 | AUROC:0.8303\n",
      "\n",
      "Epoch: [186 | 1000] LR: 0.191269\n",
      "Train | 16/16 | Loss:0.3696 | MainLoss:0.2532 | Alpha:0.4266 | SPLoss:1.1643 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1728 | MainLoss:0.1728 | SPLoss:0.9645 | CLSLoss:0.0000 | AUROC:0.9835\n",
      "Test | 122/16 | Loss:0.4937 | MainLoss:0.4937 | SPLoss:0.9645 | CLSLoss:0.0000 | AUROC:0.8710\n",
      "\n",
      "Epoch: [187 | 1000] LR: 0.191140\n",
      "Train | 16/16 | Loss:0.3262 | MainLoss:0.2401 | Alpha:0.4271 | SPLoss:0.8606 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2443 | MainLoss:0.2443 | SPLoss:0.7838 | CLSLoss:0.0000 | AUROC:0.9827\n",
      "Test | 122/16 | Loss:0.5020 | MainLoss:0.5020 | SPLoss:0.7838 | CLSLoss:0.0000 | AUROC:0.8616\n",
      "\n",
      "Epoch: [188 | 1000] LR: 0.191011\n",
      "Train | 16/16 | Loss:0.3106 | MainLoss:0.2385 | Alpha:0.4294 | SPLoss:0.7209 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.4250 | MainLoss:0.4250 | SPLoss:0.7574 | CLSLoss:0.0000 | AUROC:0.9747\n",
      "Test | 122/16 | Loss:0.7593 | MainLoss:0.7593 | SPLoss:0.7574 | CLSLoss:0.0000 | AUROC:0.6978\n",
      "\n",
      "Epoch: [189 | 1000] LR: 0.190880\n",
      "Train | 16/16 | Loss:0.3328 | MainLoss:0.2617 | Alpha:0.4281 | SPLoss:0.7111 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1943 | MainLoss:0.1943 | SPLoss:0.6734 | CLSLoss:0.0000 | AUROC:0.9807\n",
      "Test | 122/16 | Loss:0.7062 | MainLoss:0.7062 | SPLoss:0.6734 | CLSLoss:0.0000 | AUROC:0.7795\n",
      "\n",
      "Epoch: [190 | 1000] LR: 0.190748\n",
      "Train | 16/16 | Loss:0.3099 | MainLoss:0.2419 | Alpha:0.4307 | SPLoss:0.6804 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1778 | MainLoss:0.1778 | SPLoss:0.7088 | CLSLoss:0.0000 | AUROC:0.9798\n",
      "Test | 122/16 | Loss:0.5476 | MainLoss:0.5476 | SPLoss:0.7088 | CLSLoss:0.0000 | AUROC:0.8836\n",
      "\n",
      "Epoch: [191 | 1000] LR: 0.190616\n",
      "Train | 16/16 | Loss:0.3091 | MainLoss:0.2373 | Alpha:0.4261 | SPLoss:0.7180 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1664 | MainLoss:0.1664 | SPLoss:0.7135 | CLSLoss:0.0000 | AUROC:0.9824\n",
      "Test | 122/16 | Loss:0.5766 | MainLoss:0.5766 | SPLoss:0.7135 | CLSLoss:0.0000 | AUROC:0.8704\n",
      "\n",
      "Epoch: [192 | 1000] LR: 0.190483\n",
      "Train | 16/16 | Loss:0.3612 | MainLoss:0.2849 | Alpha:0.4276 | SPLoss:0.7629 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1730 | MainLoss:0.1730 | SPLoss:0.7389 | CLSLoss:0.0000 | AUROC:0.9815\n",
      "Test | 122/16 | Loss:0.6533 | MainLoss:0.6533 | SPLoss:0.7389 | CLSLoss:0.0000 | AUROC:0.8173\n",
      "\n",
      "Epoch: [193 | 1000] LR: 0.190348\n",
      "Train | 16/16 | Loss:0.3365 | MainLoss:0.2618 | Alpha:0.4231 | SPLoss:0.7462 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1703 | MainLoss:0.1703 | SPLoss:0.7106 | CLSLoss:0.0000 | AUROC:0.9848\n",
      "Test | 122/16 | Loss:0.4662 | MainLoss:0.4662 | SPLoss:0.7106 | CLSLoss:0.0000 | AUROC:0.8807\n",
      "\n",
      "Epoch: [194 | 1000] LR: 0.190213\n",
      "Train | 16/16 | Loss:0.3252 | MainLoss:0.2488 | Alpha:0.4285 | SPLoss:0.7647 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1718 | MainLoss:0.1718 | SPLoss:0.7759 | CLSLoss:0.0000 | AUROC:0.9819\n",
      "Test | 122/16 | Loss:0.5226 | MainLoss:0.5226 | SPLoss:0.7759 | CLSLoss:0.0000 | AUROC:0.8658\n",
      "\n",
      "Epoch: [195 | 1000] LR: 0.190077\n",
      "Train | 16/16 | Loss:0.3064 | MainLoss:0.2325 | Alpha:0.4277 | SPLoss:0.7392 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2931 | MainLoss:0.2931 | SPLoss:0.7260 | CLSLoss:0.0000 | AUROC:0.9840\n",
      "Test | 122/16 | Loss:0.5054 | MainLoss:0.5054 | SPLoss:0.7260 | CLSLoss:0.0000 | AUROC:0.8578\n",
      "\n",
      "Epoch: [196 | 1000] LR: 0.189941\n",
      "Train | 16/16 | Loss:0.3185 | MainLoss:0.2457 | Alpha:0.4292 | SPLoss:0.7280 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1635 | MainLoss:0.1635 | SPLoss:0.6848 | CLSLoss:0.0000 | AUROC:0.9839\n",
      "Test | 122/16 | Loss:0.5220 | MainLoss:0.5220 | SPLoss:0.6848 | CLSLoss:0.0000 | AUROC:0.8733\n",
      "\n",
      "Epoch: [197 | 1000] LR: 0.189803\n",
      "Train | 16/16 | Loss:0.3306 | MainLoss:0.2604 | Alpha:0.4247 | SPLoss:0.7025 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1762 | MainLoss:0.1762 | SPLoss:0.6933 | CLSLoss:0.0000 | AUROC:0.9819\n",
      "Test | 122/16 | Loss:0.5254 | MainLoss:0.5254 | SPLoss:0.6933 | CLSLoss:0.0000 | AUROC:0.8653\n",
      "\n",
      "Epoch: [198 | 1000] LR: 0.189664\n",
      "Train | 16/16 | Loss:0.3386 | MainLoss:0.2684 | Alpha:0.4237 | SPLoss:0.7019 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1757 | MainLoss:0.1757 | SPLoss:0.6884 | CLSLoss:0.0000 | AUROC:0.9846\n",
      "Test | 122/16 | Loss:0.4384 | MainLoss:0.4384 | SPLoss:0.6884 | CLSLoss:0.0000 | AUROC:0.8841\n",
      "\n",
      "Epoch: [199 | 1000] LR: 0.189525\n",
      "Train | 16/16 | Loss:0.3004 | MainLoss:0.2330 | Alpha:0.4257 | SPLoss:0.6734 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1779 | MainLoss:0.1779 | SPLoss:0.6718 | CLSLoss:0.0000 | AUROC:0.9788\n",
      "Test | 122/16 | Loss:0.6109 | MainLoss:0.6109 | SPLoss:0.6718 | CLSLoss:0.0000 | AUROC:0.8628\n",
      "\n",
      "Epoch: [200 | 1000] LR: 0.189384\n",
      "Train | 16/16 | Loss:0.5315 | MainLoss:0.2639 | Alpha:0.4253 | SPLoss:2.6762 | CLSLoss:0.0000 | AUROC:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 32/16 | Loss:0.1823 | MainLoss:0.1823 | SPLoss:2.9313 | CLSLoss:0.0000 | AUROC:0.9824\n",
      "Test | 122/16 | Loss:0.5258 | MainLoss:0.5258 | SPLoss:2.9313 | CLSLoss:0.0000 | AUROC:0.8571\n",
      "\n",
      "Epoch: [201 | 1000] LR: 0.018924\n",
      "Train | 16/16 | Loss:0.2111 | MainLoss:0.2109 | Alpha:0.4483 | SPLoss:0.0027 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1624 | MainLoss:0.1624 | SPLoss:0.0056 | CLSLoss:0.0000 | AUROC:0.9845\n",
      "Test | 122/16 | Loss:0.5031 | MainLoss:0.5031 | SPLoss:0.0056 | CLSLoss:0.0000 | AUROC:0.8736\n",
      "\n",
      "Epoch: [202 | 1000] LR: 0.018910\n",
      "Train | 16/16 | Loss:0.2057 | MainLoss:0.2048 | Alpha:0.4463 | SPLoss:0.0090 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1574 | MainLoss:0.1574 | SPLoss:0.0123 | CLSLoss:0.0000 | AUROC:0.9853\n",
      "Test | 122/16 | Loss:0.4809 | MainLoss:0.4809 | SPLoss:0.0123 | CLSLoss:0.0000 | AUROC:0.8820\n",
      "\n",
      "Epoch: [203 | 1000] LR: 0.018896\n",
      "Train | 16/16 | Loss:0.2050 | MainLoss:0.2035 | Alpha:0.4457 | SPLoss:0.0153 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1526 | MainLoss:0.1526 | SPLoss:0.0185 | CLSLoss:0.0000 | AUROC:0.9854\n",
      "Test | 122/16 | Loss:0.4953 | MainLoss:0.4953 | SPLoss:0.0185 | CLSLoss:0.0000 | AUROC:0.8826\n",
      "\n",
      "Epoch: [204 | 1000] LR: 0.018881\n",
      "Train | 16/16 | Loss:0.1914 | MainLoss:0.1891 | Alpha:0.4479 | SPLoss:0.0227 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1502 | MainLoss:0.1502 | SPLoss:0.0251 | CLSLoss:0.0000 | AUROC:0.9859\n",
      "Test | 122/16 | Loss:0.4863 | MainLoss:0.4863 | SPLoss:0.0251 | CLSLoss:0.0000 | AUROC:0.8852\n",
      "\n",
      "Epoch: [205 | 1000] LR: 0.018867\n",
      "Train | 16/16 | Loss:0.1857 | MainLoss:0.1829 | Alpha:0.4476 | SPLoss:0.0284 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1462 | MainLoss:0.1462 | SPLoss:0.0321 | CLSLoss:0.0000 | AUROC:0.9860\n",
      "Test | 122/16 | Loss:0.4757 | MainLoss:0.4757 | SPLoss:0.0321 | CLSLoss:0.0000 | AUROC:0.8935\n",
      "\n",
      "Epoch: [206 | 1000] LR: 0.018852\n",
      "Train | 16/16 | Loss:0.1714 | MainLoss:0.1678 | Alpha:0.4511 | SPLoss:0.0361 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1476 | MainLoss:0.1476 | SPLoss:0.0394 | CLSLoss:0.0000 | AUROC:0.9863\n",
      "Test | 122/16 | Loss:0.4589 | MainLoss:0.4589 | SPLoss:0.0394 | CLSLoss:0.0000 | AUROC:0.8972\n",
      "\n",
      "Epoch: [207 | 1000] LR: 0.018838\n",
      "Train | 16/16 | Loss:0.1902 | MainLoss:0.1859 | Alpha:0.4463 | SPLoss:0.0431 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1480 | MainLoss:0.1480 | SPLoss:0.0468 | CLSLoss:0.0000 | AUROC:0.9864\n",
      "Test | 122/16 | Loss:0.4681 | MainLoss:0.4681 | SPLoss:0.0468 | CLSLoss:0.0000 | AUROC:0.8929\n",
      "\n",
      "Epoch: [208 | 1000] LR: 0.018823\n",
      "Train | 16/16 | Loss:0.1961 | MainLoss:0.1911 | Alpha:0.4446 | SPLoss:0.0500 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1439 | MainLoss:0.1439 | SPLoss:0.0541 | CLSLoss:0.0000 | AUROC:0.9865\n",
      "Test | 122/16 | Loss:0.4448 | MainLoss:0.4448 | SPLoss:0.0541 | CLSLoss:0.0000 | AUROC:0.9027\n",
      "\n",
      "Epoch: [209 | 1000] LR: 0.018808\n",
      "Train | 16/16 | Loss:0.1864 | MainLoss:0.1806 | Alpha:0.4463 | SPLoss:0.0576 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1405 | MainLoss:0.1405 | SPLoss:0.0613 | CLSLoss:0.0000 | AUROC:0.9868\n",
      "Test | 122/16 | Loss:0.4516 | MainLoss:0.4516 | SPLoss:0.0613 | CLSLoss:0.0000 | AUROC:0.9056\n",
      "\n",
      "Epoch: [210 | 1000] LR: 0.018793\n",
      "Train | 16/16 | Loss:0.1681 | MainLoss:0.1617 | Alpha:0.4499 | SPLoss:0.0645 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1397 | MainLoss:0.1397 | SPLoss:0.0688 | CLSLoss:0.0000 | AUROC:0.9871\n",
      "Test | 122/16 | Loss:0.4609 | MainLoss:0.4609 | SPLoss:0.0688 | CLSLoss:0.0000 | AUROC:0.9077\n",
      "\n",
      "Epoch: [211 | 1000] LR: 0.018778\n",
      "Train | 16/16 | Loss:0.1804 | MainLoss:0.1733 | Alpha:0.4488 | SPLoss:0.0709 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1352 | MainLoss:0.1352 | SPLoss:0.0760 | CLSLoss:0.0000 | AUROC:0.9873\n",
      "Test | 122/16 | Loss:0.4971 | MainLoss:0.4971 | SPLoss:0.0760 | CLSLoss:0.0000 | AUROC:0.9060\n",
      "\n",
      "Epoch: [212 | 1000] LR: 0.018763\n",
      "Train | 16/16 | Loss:0.1764 | MainLoss:0.1685 | Alpha:0.4494 | SPLoss:0.0787 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1380 | MainLoss:0.1380 | SPLoss:0.0818 | CLSLoss:0.0000 | AUROC:0.9880\n",
      "Test | 122/16 | Loss:0.4664 | MainLoss:0.4664 | SPLoss:0.0818 | CLSLoss:0.0000 | AUROC:0.9009\n",
      "\n",
      "Epoch: [213 | 1000] LR: 0.018748\n",
      "Train | 16/16 | Loss:0.1707 | MainLoss:0.1622 | Alpha:0.4486 | SPLoss:0.0846 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1345 | MainLoss:0.1345 | SPLoss:0.0875 | CLSLoss:0.0000 | AUROC:0.9881\n",
      "Test | 122/16 | Loss:0.4597 | MainLoss:0.4597 | SPLoss:0.0875 | CLSLoss:0.0000 | AUROC:0.9046\n",
      "\n",
      "Epoch: [214 | 1000] LR: 0.018733\n",
      "Train | 16/16 | Loss:0.1899 | MainLoss:0.1809 | Alpha:0.4444 | SPLoss:0.0903 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1355 | MainLoss:0.1355 | SPLoss:0.0931 | CLSLoss:0.0000 | AUROC:0.9879\n",
      "Test | 122/16 | Loss:0.4589 | MainLoss:0.4589 | SPLoss:0.0931 | CLSLoss:0.0000 | AUROC:0.9035\n",
      "\n",
      "Epoch: [215 | 1000] LR: 0.018717\n",
      "Train | 16/16 | Loss:0.1742 | MainLoss:0.1646 | Alpha:0.4484 | SPLoss:0.0962 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1331 | MainLoss:0.1331 | SPLoss:0.1003 | CLSLoss:0.0000 | AUROC:0.9880\n",
      "Test | 122/16 | Loss:0.4513 | MainLoss:0.4513 | SPLoss:0.1003 | CLSLoss:0.0000 | AUROC:0.9097\n",
      "\n",
      "Epoch: [216 | 1000] LR: 0.018702\n",
      "Train | 16/16 | Loss:0.1879 | MainLoss:0.1773 | Alpha:0.4441 | SPLoss:0.1064 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1372 | MainLoss:0.1372 | SPLoss:0.1111 | CLSLoss:0.0000 | AUROC:0.9884\n",
      "Test | 122/16 | Loss:0.4366 | MainLoss:0.4366 | SPLoss:0.1111 | CLSLoss:0.0000 | AUROC:0.9036\n",
      "\n",
      "Epoch: [217 | 1000] LR: 0.018686\n",
      "Train | 16/16 | Loss:0.1750 | MainLoss:0.1636 | Alpha:0.4490 | SPLoss:0.1143 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1328 | MainLoss:0.1328 | SPLoss:0.1163 | CLSLoss:0.0000 | AUROC:0.9883\n",
      "Test | 122/16 | Loss:0.4667 | MainLoss:0.4667 | SPLoss:0.1163 | CLSLoss:0.0000 | AUROC:0.9014\n",
      "\n",
      "Epoch: [218 | 1000] LR: 0.018671\n",
      "Train | 16/16 | Loss:0.1737 | MainLoss:0.1618 | Alpha:0.4466 | SPLoss:0.1187 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1278 | MainLoss:0.1278 | SPLoss:0.1225 | CLSLoss:0.0000 | AUROC:0.9887\n",
      "Test | 122/16 | Loss:0.4633 | MainLoss:0.4633 | SPLoss:0.1225 | CLSLoss:0.0000 | AUROC:0.9113\n",
      "\n",
      "Epoch: [219 | 1000] LR: 0.018655\n",
      "Train | 16/16 | Loss:0.1703 | MainLoss:0.1578 | Alpha:0.4492 | SPLoss:0.1243 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1288 | MainLoss:0.1288 | SPLoss:0.1262 | CLSLoss:0.0000 | AUROC:0.9887\n",
      "Test | 122/16 | Loss:0.4373 | MainLoss:0.4373 | SPLoss:0.1262 | CLSLoss:0.0000 | AUROC:0.9123\n",
      "\n",
      "Epoch: [220 | 1000] LR: 0.018639\n",
      "Train | 16/16 | Loss:0.1707 | MainLoss:0.1579 | Alpha:0.4493 | SPLoss:0.1274 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1270 | MainLoss:0.1270 | SPLoss:0.1301 | CLSLoss:0.0000 | AUROC:0.9891\n",
      "Test | 122/16 | Loss:0.4691 | MainLoss:0.4691 | SPLoss:0.1301 | CLSLoss:0.0000 | AUROC:0.9082\n",
      "\n",
      "Epoch: [221 | 1000] LR: 0.018623\n",
      "Train | 16/16 | Loss:0.1684 | MainLoss:0.1553 | Alpha:0.4484 | SPLoss:0.1312 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1302 | MainLoss:0.1302 | SPLoss:0.1325 | CLSLoss:0.0000 | AUROC:0.9889\n",
      "Test | 122/16 | Loss:0.4397 | MainLoss:0.4397 | SPLoss:0.1325 | CLSLoss:0.0000 | AUROC:0.9098\n",
      "\n",
      "Epoch: [222 | 1000] LR: 0.018607\n",
      "Train | 16/16 | Loss:0.1808 | MainLoss:0.1674 | Alpha:0.4483 | SPLoss:0.1346 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1264 | MainLoss:0.1264 | SPLoss:0.1357 | CLSLoss:0.0000 | AUROC:0.9889\n",
      "Test | 122/16 | Loss:0.4654 | MainLoss:0.4654 | SPLoss:0.1357 | CLSLoss:0.0000 | AUROC:0.9044\n",
      "\n",
      "Epoch: [223 | 1000] LR: 0.018591\n",
      "Train | 16/16 | Loss:0.1739 | MainLoss:0.1601 | Alpha:0.4480 | SPLoss:0.1377 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1310 | MainLoss:0.1310 | SPLoss:0.1397 | CLSLoss:0.0000 | AUROC:0.9892\n",
      "Test | 122/16 | Loss:0.4590 | MainLoss:0.4590 | SPLoss:0.1397 | CLSLoss:0.0000 | AUROC:0.9003\n",
      "\n",
      "Epoch: [224 | 1000] LR: 0.018575\n",
      "Train | 16/16 | Loss:0.1719 | MainLoss:0.1577 | Alpha:0.4489 | SPLoss:0.1415 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1255 | MainLoss:0.1255 | SPLoss:0.1448 | CLSLoss:0.0000 | AUROC:0.9890\n",
      "Test | 122/16 | Loss:0.4554 | MainLoss:0.4554 | SPLoss:0.1448 | CLSLoss:0.0000 | AUROC:0.9116\n",
      "\n",
      "Epoch: [225 | 1000] LR: 0.018559\n",
      "Train | 16/16 | Loss:0.1760 | MainLoss:0.1613 | Alpha:0.4464 | SPLoss:0.1471 | CLSLoss:0.0000 | AUROC:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 32/16 | Loss:0.1309 | MainLoss:0.1309 | SPLoss:0.1505 | CLSLoss:0.0000 | AUROC:0.9893\n",
      "Test | 122/16 | Loss:0.4299 | MainLoss:0.4299 | SPLoss:0.1505 | CLSLoss:0.0000 | AUROC:0.9087\n",
      "\n",
      "Epoch: [226 | 1000] LR: 0.018543\n",
      "Train | 16/16 | Loss:0.1787 | MainLoss:0.1634 | Alpha:0.4458 | SPLoss:0.1535 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1251 | MainLoss:0.1251 | SPLoss:0.1578 | CLSLoss:0.0000 | AUROC:0.9891\n",
      "Test | 122/16 | Loss:0.4670 | MainLoss:0.4670 | SPLoss:0.1578 | CLSLoss:0.0000 | AUROC:0.9081\n",
      "\n",
      "Epoch: [227 | 1000] LR: 0.018526\n",
      "Train | 16/16 | Loss:0.1663 | MainLoss:0.1504 | Alpha:0.4488 | SPLoss:0.1590 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1273 | MainLoss:0.1273 | SPLoss:0.1606 | CLSLoss:0.0000 | AUROC:0.9890\n",
      "Test | 122/16 | Loss:0.4701 | MainLoss:0.4701 | SPLoss:0.1606 | CLSLoss:0.0000 | AUROC:0.9077\n",
      "\n",
      "Epoch: [228 | 1000] LR: 0.018510\n",
      "Train | 16/16 | Loss:0.1649 | MainLoss:0.1487 | Alpha:0.4492 | SPLoss:0.1619 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1351 | MainLoss:0.1351 | SPLoss:0.1630 | CLSLoss:0.0000 | AUROC:0.9893\n",
      "Test | 122/16 | Loss:0.4540 | MainLoss:0.4540 | SPLoss:0.1630 | CLSLoss:0.0000 | AUROC:0.9028\n",
      "\n",
      "Epoch: [229 | 1000] LR: 0.018493\n",
      "Train | 16/16 | Loss:0.1722 | MainLoss:0.1556 | Alpha:0.4483 | SPLoss:0.1656 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1266 | MainLoss:0.1266 | SPLoss:0.1666 | CLSLoss:0.0000 | AUROC:0.9892\n",
      "Test | 122/16 | Loss:0.4510 | MainLoss:0.4510 | SPLoss:0.1666 | CLSLoss:0.0000 | AUROC:0.9079\n",
      "\n",
      "Epoch: [230 | 1000] LR: 0.018477\n",
      "Train | 16/16 | Loss:0.1817 | MainLoss:0.1650 | Alpha:0.4476 | SPLoss:0.1678 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1251 | MainLoss:0.1251 | SPLoss:0.1690 | CLSLoss:0.0000 | AUROC:0.9894\n",
      "Test | 122/16 | Loss:0.4502 | MainLoss:0.4502 | SPLoss:0.1690 | CLSLoss:0.0000 | AUROC:0.9080\n",
      "\n",
      "Epoch: [231 | 1000] LR: 0.018460\n",
      "Train | 16/16 | Loss:0.1648 | MainLoss:0.1477 | Alpha:0.4492 | SPLoss:0.1702 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1271 | MainLoss:0.1271 | SPLoss:0.1724 | CLSLoss:0.0000 | AUROC:0.9892\n",
      "Test | 122/16 | Loss:0.4453 | MainLoss:0.4453 | SPLoss:0.1724 | CLSLoss:0.0000 | AUROC:0.9110\n",
      "\n",
      "Epoch: [232 | 1000] LR: 0.018443\n",
      "Train | 16/16 | Loss:0.1628 | MainLoss:0.1454 | Alpha:0.4490 | SPLoss:0.1741 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1251 | MainLoss:0.1251 | SPLoss:0.1774 | CLSLoss:0.0000 | AUROC:0.9894\n",
      "Test | 122/16 | Loss:0.4459 | MainLoss:0.4459 | SPLoss:0.1774 | CLSLoss:0.0000 | AUROC:0.9174\n",
      "\n",
      "Epoch: [233 | 1000] LR: 0.018426\n",
      "Train | 16/16 | Loss:0.1651 | MainLoss:0.1474 | Alpha:0.4493 | SPLoss:0.1768 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1313 | MainLoss:0.1313 | SPLoss:0.1789 | CLSLoss:0.0000 | AUROC:0.9891\n",
      "Test | 122/16 | Loss:0.4391 | MainLoss:0.4391 | SPLoss:0.1789 | CLSLoss:0.0000 | AUROC:0.9077\n",
      "\n",
      "Epoch: [234 | 1000] LR: 0.018409\n",
      "Train | 16/16 | Loss:0.1687 | MainLoss:0.1507 | Alpha:0.4488 | SPLoss:0.1804 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1241 | MainLoss:0.1241 | SPLoss:0.1826 | CLSLoss:0.0000 | AUROC:0.9897\n",
      "Test | 122/16 | Loss:0.4724 | MainLoss:0.4724 | SPLoss:0.1826 | CLSLoss:0.0000 | AUROC:0.9115\n",
      "\n",
      "Epoch: [235 | 1000] LR: 0.018392\n",
      "Train | 16/16 | Loss:0.1730 | MainLoss:0.1546 | Alpha:0.4464 | SPLoss:0.1843 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1226 | MainLoss:0.1226 | SPLoss:0.1873 | CLSLoss:0.0000 | AUROC:0.9897\n",
      "Test | 122/16 | Loss:0.4705 | MainLoss:0.4705 | SPLoss:0.1873 | CLSLoss:0.0000 | AUROC:0.9095\n",
      "\n",
      "Epoch: [236 | 1000] LR: 0.018375\n",
      "Train | 16/16 | Loss:0.1719 | MainLoss:0.1530 | Alpha:0.4467 | SPLoss:0.1894 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1258 | MainLoss:0.1258 | SPLoss:0.1922 | CLSLoss:0.0000 | AUROC:0.9897\n",
      "Test | 122/16 | Loss:0.4280 | MainLoss:0.4280 | SPLoss:0.1922 | CLSLoss:0.0000 | AUROC:0.9126\n",
      "\n",
      "Epoch: [237 | 1000] LR: 0.018358\n",
      "Train | 16/16 | Loss:0.1630 | MainLoss:0.1436 | Alpha:0.4495 | SPLoss:0.1937 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1235 | MainLoss:0.1235 | SPLoss:0.1952 | CLSLoss:0.0000 | AUROC:0.9896\n",
      "Test | 122/16 | Loss:0.4491 | MainLoss:0.4491 | SPLoss:0.1952 | CLSLoss:0.0000 | AUROC:0.9103\n",
      "\n",
      "Epoch: [238 | 1000] LR: 0.018341\n",
      "Train | 16/16 | Loss:0.1750 | MainLoss:0.1553 | Alpha:0.4466 | SPLoss:0.1969 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1260 | MainLoss:0.1260 | SPLoss:0.1995 | CLSLoss:0.0000 | AUROC:0.9902\n",
      "Test | 122/16 | Loss:0.4172 | MainLoss:0.4172 | SPLoss:0.1995 | CLSLoss:0.0000 | AUROC:0.9139\n",
      "\n",
      "Epoch: [239 | 1000] LR: 0.018323\n",
      "Train | 16/16 | Loss:0.1706 | MainLoss:0.1503 | Alpha:0.4458 | SPLoss:0.2024 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1198 | MainLoss:0.1198 | SPLoss:0.2048 | CLSLoss:0.0000 | AUROC:0.9903\n",
      "Test | 122/16 | Loss:0.4812 | MainLoss:0.4812 | SPLoss:0.2048 | CLSLoss:0.0000 | AUROC:0.9104\n",
      "\n",
      "Epoch: [240 | 1000] LR: 0.018306\n",
      "Train | 16/16 | Loss:0.1736 | MainLoss:0.1530 | Alpha:0.4472 | SPLoss:0.2054 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1217 | MainLoss:0.1217 | SPLoss:0.2097 | CLSLoss:0.0000 | AUROC:0.9900\n",
      "Test | 122/16 | Loss:0.4511 | MainLoss:0.4511 | SPLoss:0.2097 | CLSLoss:0.0000 | AUROC:0.9098\n",
      "\n",
      "Epoch: [241 | 1000] LR: 0.018288\n",
      "Train | 16/16 | Loss:0.1693 | MainLoss:0.1482 | Alpha:0.4486 | SPLoss:0.2112 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1220 | MainLoss:0.1220 | SPLoss:0.2113 | CLSLoss:0.0000 | AUROC:0.9901\n",
      "Test | 122/16 | Loss:0.4380 | MainLoss:0.4380 | SPLoss:0.2113 | CLSLoss:0.0000 | AUROC:0.9117\n",
      "\n",
      "Epoch: [242 | 1000] LR: 0.018271\n",
      "Train | 16/16 | Loss:0.1691 | MainLoss:0.1478 | Alpha:0.4465 | SPLoss:0.2130 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1227 | MainLoss:0.1227 | SPLoss:0.2149 | CLSLoss:0.0000 | AUROC:0.9901\n",
      "Test | 122/16 | Loss:0.4387 | MainLoss:0.4387 | SPLoss:0.2149 | CLSLoss:0.0000 | AUROC:0.9120\n",
      "\n",
      "Epoch: [243 | 1000] LR: 0.018253\n",
      "Train | 16/16 | Loss:0.1652 | MainLoss:0.1436 | Alpha:0.4478 | SPLoss:0.2164 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1234 | MainLoss:0.1234 | SPLoss:0.2179 | CLSLoss:0.0000 | AUROC:0.9900\n",
      "Test | 122/16 | Loss:0.4309 | MainLoss:0.4309 | SPLoss:0.2179 | CLSLoss:0.0000 | AUROC:0.9151\n",
      "\n",
      "Epoch: [244 | 1000] LR: 0.018235\n",
      "Train | 16/16 | Loss:0.1668 | MainLoss:0.1450 | Alpha:0.4502 | SPLoss:0.2177 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1224 | MainLoss:0.1224 | SPLoss:0.2178 | CLSLoss:0.0000 | AUROC:0.9903\n",
      "Test | 122/16 | Loss:0.4642 | MainLoss:0.4642 | SPLoss:0.2178 | CLSLoss:0.0000 | AUROC:0.9055\n",
      "\n",
      "Epoch: [245 | 1000] LR: 0.018217\n",
      "Train | 16/16 | Loss:0.1589 | MainLoss:0.1369 | Alpha:0.4493 | SPLoss:0.2204 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1289 | MainLoss:0.1289 | SPLoss:0.2207 | CLSLoss:0.0000 | AUROC:0.9899\n",
      "Test | 122/16 | Loss:0.4481 | MainLoss:0.4481 | SPLoss:0.2207 | CLSLoss:0.0000 | AUROC:0.9080\n",
      "\n",
      "Epoch: [246 | 1000] LR: 0.018200\n",
      "Train | 16/16 | Loss:0.1667 | MainLoss:0.1444 | Alpha:0.4496 | SPLoss:0.2226 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1268 | MainLoss:0.1268 | SPLoss:0.2236 | CLSLoss:0.0000 | AUROC:0.9899\n",
      "Test | 122/16 | Loss:0.4901 | MainLoss:0.4901 | SPLoss:0.2236 | CLSLoss:0.0000 | AUROC:0.9010\n",
      "\n",
      "Epoch: [247 | 1000] LR: 0.018181\n",
      "Train | 16/16 | Loss:0.1525 | MainLoss:0.1300 | Alpha:0.4525 | SPLoss:0.2244 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1249 | MainLoss:0.1249 | SPLoss:0.2234 | CLSLoss:0.0000 | AUROC:0.9900\n",
      "Test | 122/16 | Loss:0.4649 | MainLoss:0.4649 | SPLoss:0.2234 | CLSLoss:0.0000 | AUROC:0.9071\n",
      "\n",
      "Epoch: [248 | 1000] LR: 0.018163\n",
      "Train | 16/16 | Loss:0.1610 | MainLoss:0.1386 | Alpha:0.4501 | SPLoss:0.2236 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1215 | MainLoss:0.1215 | SPLoss:0.2253 | CLSLoss:0.0000 | AUROC:0.9903\n",
      "Test | 122/16 | Loss:0.4727 | MainLoss:0.4727 | SPLoss:0.2253 | CLSLoss:0.0000 | AUROC:0.9113\n",
      "\n",
      "Epoch: [249 | 1000] LR: 0.018145\n",
      "Train | 16/16 | Loss:0.1734 | MainLoss:0.1510 | Alpha:0.4489 | SPLoss:0.2240 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1251 | MainLoss:0.1251 | SPLoss:0.2232 | CLSLoss:0.0000 | AUROC:0.9903\n",
      "Test | 122/16 | Loss:0.4409 | MainLoss:0.4409 | SPLoss:0.2232 | CLSLoss:0.0000 | AUROC:0.9107\n",
      "\n",
      "Epoch: [250 | 1000] LR: 0.018127\n",
      "Train | 16/16 | Loss:0.1631 | MainLoss:0.1405 | Alpha:0.4500 | SPLoss:0.2258 | CLSLoss:0.0000 | AUROC:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 32/16 | Loss:0.1228 | MainLoss:0.1228 | SPLoss:0.2284 | CLSLoss:0.0000 | AUROC:0.9897\n",
      "Test | 122/16 | Loss:0.4794 | MainLoss:0.4794 | SPLoss:0.2284 | CLSLoss:0.0000 | AUROC:0.9100\n",
      "\n",
      "Epoch: [251 | 1000] LR: 0.018109\n",
      "Train | 16/16 | Loss:0.1670 | MainLoss:0.1441 | Alpha:0.4495 | SPLoss:0.2289 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1221 | MainLoss:0.1221 | SPLoss:0.2290 | CLSLoss:0.0000 | AUROC:0.9898\n",
      "Test | 122/16 | Loss:0.4755 | MainLoss:0.4755 | SPLoss:0.2290 | CLSLoss:0.0000 | AUROC:0.9123\n",
      "\n",
      "Epoch: [252 | 1000] LR: 0.018090\n",
      "Train | 16/16 | Loss:0.1550 | MainLoss:0.1321 | Alpha:0.4513 | SPLoss:0.2285 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1222 | MainLoss:0.1222 | SPLoss:0.2301 | CLSLoss:0.0000 | AUROC:0.9897\n",
      "Test | 122/16 | Loss:0.4844 | MainLoss:0.4844 | SPLoss:0.2301 | CLSLoss:0.0000 | AUROC:0.9161\n",
      "\n",
      "Epoch: [253 | 1000] LR: 0.018072\n",
      "Train | 16/16 | Loss:0.1742 | MainLoss:0.1512 | Alpha:0.4465 | SPLoss:0.2302 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1229 | MainLoss:0.1229 | SPLoss:0.2306 | CLSLoss:0.0000 | AUROC:0.9900\n",
      "Test | 122/16 | Loss:0.4398 | MainLoss:0.4398 | SPLoss:0.2306 | CLSLoss:0.0000 | AUROC:0.9122\n",
      "\n",
      "Epoch: [254 | 1000] LR: 0.018053\n",
      "Train | 16/16 | Loss:0.1686 | MainLoss:0.1456 | Alpha:0.4491 | SPLoss:0.2302 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1254 | MainLoss:0.1254 | SPLoss:0.2288 | CLSLoss:0.0000 | AUROC:0.9901\n",
      "Test | 122/16 | Loss:0.4525 | MainLoss:0.4525 | SPLoss:0.2288 | CLSLoss:0.0000 | AUROC:0.9068\n",
      "\n",
      "Epoch: [255 | 1000] LR: 0.018034\n",
      "Train | 16/16 | Loss:0.1721 | MainLoss:0.1490 | Alpha:0.4464 | SPLoss:0.2306 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1207 | MainLoss:0.1207 | SPLoss:0.2328 | CLSLoss:0.0000 | AUROC:0.9901\n",
      "Test | 122/16 | Loss:0.4475 | MainLoss:0.4475 | SPLoss:0.2328 | CLSLoss:0.0000 | AUROC:0.9119\n",
      "\n",
      "Epoch: [256 | 1000] LR: 0.018016\n",
      "Train | 16/16 | Loss:0.1645 | MainLoss:0.1412 | Alpha:0.4498 | SPLoss:0.2322 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1288 | MainLoss:0.1288 | SPLoss:0.2317 | CLSLoss:0.0000 | AUROC:0.9903\n",
      "Test | 122/16 | Loss:0.4271 | MainLoss:0.4271 | SPLoss:0.2317 | CLSLoss:0.0000 | AUROC:0.9106\n",
      "\n",
      "Epoch: [257 | 1000] LR: 0.017997\n",
      "Train | 16/16 | Loss:0.1662 | MainLoss:0.1429 | Alpha:0.4478 | SPLoss:0.2330 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1234 | MainLoss:0.1234 | SPLoss:0.2333 | CLSLoss:0.0000 | AUROC:0.9899\n",
      "Test | 122/16 | Loss:0.4354 | MainLoss:0.4354 | SPLoss:0.2333 | CLSLoss:0.0000 | AUROC:0.9131\n",
      "\n",
      "Epoch: [258 | 1000] LR: 0.017978\n",
      "Train | 16/16 | Loss:0.1519 | MainLoss:0.1285 | Alpha:0.4521 | SPLoss:0.2338 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1234 | MainLoss:0.1234 | SPLoss:0.2365 | CLSLoss:0.0000 | AUROC:0.9899\n",
      "Test | 122/16 | Loss:0.4464 | MainLoss:0.4464 | SPLoss:0.2365 | CLSLoss:0.0000 | AUROC:0.9132\n",
      "\n",
      "Epoch: [259 | 1000] LR: 0.017959\n",
      "Train | 16/16 | Loss:0.1665 | MainLoss:0.1428 | Alpha:0.4485 | SPLoss:0.2373 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1252 | MainLoss:0.1252 | SPLoss:0.2384 | CLSLoss:0.0000 | AUROC:0.9898\n",
      "Test | 122/16 | Loss:0.4137 | MainLoss:0.4137 | SPLoss:0.2384 | CLSLoss:0.0000 | AUROC:0.9159\n",
      "\n",
      "Epoch: [260 | 1000] LR: 0.017940\n",
      "Train | 16/16 | Loss:0.1758 | MainLoss:0.1516 | Alpha:0.4455 | SPLoss:0.2419 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1246 | MainLoss:0.1246 | SPLoss:0.2451 | CLSLoss:0.0000 | AUROC:0.9898\n",
      "Test | 122/16 | Loss:0.4134 | MainLoss:0.4134 | SPLoss:0.2451 | CLSLoss:0.0000 | AUROC:0.9186\n",
      "\n",
      "Epoch: [261 | 1000] LR: 0.017921\n",
      "Train | 16/16 | Loss:0.1599 | MainLoss:0.1353 | Alpha:0.4486 | SPLoss:0.2459 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1236 | MainLoss:0.1236 | SPLoss:0.2472 | CLSLoss:0.0000 | AUROC:0.9896\n",
      "Test | 122/16 | Loss:0.4442 | MainLoss:0.4442 | SPLoss:0.2472 | CLSLoss:0.0000 | AUROC:0.9163\n",
      "\n",
      "Epoch: [262 | 1000] LR: 0.017902\n",
      "Train | 16/16 | Loss:0.1757 | MainLoss:0.1509 | Alpha:0.4461 | SPLoss:0.2478 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1245 | MainLoss:0.1245 | SPLoss:0.2478 | CLSLoss:0.0000 | AUROC:0.9893\n",
      "Test | 122/16 | Loss:0.4216 | MainLoss:0.4216 | SPLoss:0.2478 | CLSLoss:0.0000 | AUROC:0.9153\n",
      "\n",
      "Epoch: [263 | 1000] LR: 0.017882\n",
      "Train | 16/16 | Loss:0.1635 | MainLoss:0.1388 | Alpha:0.4489 | SPLoss:0.2474 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1255 | MainLoss:0.1255 | SPLoss:0.2474 | CLSLoss:0.0000 | AUROC:0.9899\n",
      "Test | 122/16 | Loss:0.4156 | MainLoss:0.4156 | SPLoss:0.2474 | CLSLoss:0.0000 | AUROC:0.9172\n",
      "\n",
      "Epoch: [264 | 1000] LR: 0.017863\n",
      "Train | 16/16 | Loss:0.1771 | MainLoss:0.1521 | Alpha:0.4466 | SPLoss:0.2499 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1276 | MainLoss:0.1276 | SPLoss:0.2494 | CLSLoss:0.0000 | AUROC:0.9902\n",
      "Test | 122/16 | Loss:0.4032 | MainLoss:0.4032 | SPLoss:0.2494 | CLSLoss:0.0000 | AUROC:0.9151\n",
      "\n",
      "Epoch: [265 | 1000] LR: 0.017843\n",
      "Train | 16/16 | Loss:0.1622 | MainLoss:0.1373 | Alpha:0.4505 | SPLoss:0.2493 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1273 | MainLoss:0.1273 | SPLoss:0.2470 | CLSLoss:0.0000 | AUROC:0.9902\n",
      "Test | 122/16 | Loss:0.4046 | MainLoss:0.4046 | SPLoss:0.2470 | CLSLoss:0.0000 | AUROC:0.9165\n",
      "\n",
      "Epoch: [266 | 1000] LR: 0.017824\n",
      "Train | 16/16 | Loss:0.1559 | MainLoss:0.1311 | Alpha:0.4490 | SPLoss:0.2476 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1260 | MainLoss:0.1260 | SPLoss:0.2487 | CLSLoss:0.0000 | AUROC:0.9901\n",
      "Test | 122/16 | Loss:0.4181 | MainLoss:0.4181 | SPLoss:0.2487 | CLSLoss:0.0000 | AUROC:0.9171\n",
      "\n",
      "Epoch: [267 | 1000] LR: 0.017804\n",
      "Train | 16/16 | Loss:0.1669 | MainLoss:0.1421 | Alpha:0.4480 | SPLoss:0.2487 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1214 | MainLoss:0.1214 | SPLoss:0.2493 | CLSLoss:0.0000 | AUROC:0.9899\n",
      "Test | 122/16 | Loss:0.4400 | MainLoss:0.4400 | SPLoss:0.2493 | CLSLoss:0.0000 | AUROC:0.9165\n",
      "\n",
      "Epoch: [268 | 1000] LR: 0.017785\n",
      "Train | 16/16 | Loss:0.1449 | MainLoss:0.1200 | Alpha:0.4531 | SPLoss:0.2495 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1251 | MainLoss:0.1251 | SPLoss:0.2502 | CLSLoss:0.0000 | AUROC:0.9899\n",
      "Test | 122/16 | Loss:0.4127 | MainLoss:0.4127 | SPLoss:0.2502 | CLSLoss:0.0000 | AUROC:0.9219\n",
      "\n",
      "Epoch: [269 | 1000] LR: 0.017765\n",
      "Train | 16/16 | Loss:0.1717 | MainLoss:0.1467 | Alpha:0.4478 | SPLoss:0.2503 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1244 | MainLoss:0.1244 | SPLoss:0.2507 | CLSLoss:0.0000 | AUROC:0.9900\n",
      "Test | 122/16 | Loss:0.4057 | MainLoss:0.4057 | SPLoss:0.2507 | CLSLoss:0.0000 | AUROC:0.9191\n",
      "\n",
      "Epoch: [270 | 1000] LR: 0.017745\n",
      "Train | 16/16 | Loss:0.1686 | MainLoss:0.1435 | Alpha:0.4488 | SPLoss:0.2511 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1268 | MainLoss:0.1268 | SPLoss:0.2517 | CLSLoss:0.0000 | AUROC:0.9902\n",
      "Test | 122/16 | Loss:0.3975 | MainLoss:0.3975 | SPLoss:0.2517 | CLSLoss:0.0000 | AUROC:0.9193\n",
      "\n",
      "Epoch: [271 | 1000] LR: 0.017725\n",
      "Train | 16/16 | Loss:0.1758 | MainLoss:0.1505 | Alpha:0.4467 | SPLoss:0.2529 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1199 | MainLoss:0.1199 | SPLoss:0.2523 | CLSLoss:0.0000 | AUROC:0.9900\n",
      "Test | 122/16 | Loss:0.4103 | MainLoss:0.4103 | SPLoss:0.2523 | CLSLoss:0.0000 | AUROC:0.9225\n",
      "\n",
      "Epoch: [272 | 1000] LR: 0.017705\n",
      "Train | 16/16 | Loss:0.1507 | MainLoss:0.1255 | Alpha:0.4513 | SPLoss:0.2518 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1241 | MainLoss:0.1241 | SPLoss:0.2544 | CLSLoss:0.0000 | AUROC:0.9899\n",
      "Test | 122/16 | Loss:0.3990 | MainLoss:0.3990 | SPLoss:0.2544 | CLSLoss:0.0000 | AUROC:0.9259\n",
      "\n",
      "Epoch: [273 | 1000] LR: 0.017685\n",
      "Train | 16/16 | Loss:0.1746 | MainLoss:0.1491 | Alpha:0.4464 | SPLoss:0.2553 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1257 | MainLoss:0.1257 | SPLoss:0.2563 | CLSLoss:0.0000 | AUROC:0.9902\n",
      "Test | 122/16 | Loss:0.4062 | MainLoss:0.4062 | SPLoss:0.2563 | CLSLoss:0.0000 | AUROC:0.9189\n",
      "\n",
      "Epoch: [274 | 1000] LR: 0.017665\n",
      "Train | 16/16 | Loss:0.1780 | MainLoss:0.1523 | Alpha:0.4451 | SPLoss:0.2575 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1225 | MainLoss:0.1225 | SPLoss:0.2573 | CLSLoss:0.0000 | AUROC:0.9901\n",
      "Test | 122/16 | Loss:0.4051 | MainLoss:0.4051 | SPLoss:0.2573 | CLSLoss:0.0000 | AUROC:0.9194\n",
      "\n",
      "Epoch: [275 | 1000] LR: 0.017645\n",
      "Train | 16/16 | Loss:0.1653 | MainLoss:0.1396 | Alpha:0.4495 | SPLoss:0.2572 | CLSLoss:0.0000 | AUROC:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 32/16 | Loss:0.1256 | MainLoss:0.1256 | SPLoss:0.2560 | CLSLoss:0.0000 | AUROC:0.9900\n",
      "Test | 122/16 | Loss:0.4180 | MainLoss:0.4180 | SPLoss:0.2560 | CLSLoss:0.0000 | AUROC:0.9159\n",
      "\n",
      "Epoch: [276 | 1000] LR: 0.017624\n",
      "Train | 16/16 | Loss:0.1581 | MainLoss:0.1324 | Alpha:0.4494 | SPLoss:0.2568 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1257 | MainLoss:0.1257 | SPLoss:0.2586 | CLSLoss:0.0000 | AUROC:0.9900\n",
      "Test | 122/16 | Loss:0.4278 | MainLoss:0.4278 | SPLoss:0.2586 | CLSLoss:0.0000 | AUROC:0.9158\n",
      "\n",
      "Epoch: [277 | 1000] LR: 0.017604\n",
      "Train | 16/16 | Loss:0.1579 | MainLoss:0.1319 | Alpha:0.4503 | SPLoss:0.2601 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1237 | MainLoss:0.1237 | SPLoss:0.2598 | CLSLoss:0.0000 | AUROC:0.9902\n",
      "Test | 122/16 | Loss:0.4134 | MainLoss:0.4134 | SPLoss:0.2598 | CLSLoss:0.0000 | AUROC:0.9178\n",
      "\n",
      "Epoch: [278 | 1000] LR: 0.017584\n",
      "Train | 16/16 | Loss:0.1598 | MainLoss:0.1338 | Alpha:0.4484 | SPLoss:0.2597 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1305 | MainLoss:0.1305 | SPLoss:0.2597 | CLSLoss:0.0000 | AUROC:0.9902\n",
      "Test | 122/16 | Loss:0.4223 | MainLoss:0.4223 | SPLoss:0.2597 | CLSLoss:0.0000 | AUROC:0.9149\n",
      "\n",
      "Epoch: [279 | 1000] LR: 0.017563\n",
      "Train | 16/16 | Loss:0.1679 | MainLoss:0.1419 | Alpha:0.4480 | SPLoss:0.2605 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1266 | MainLoss:0.1266 | SPLoss:0.2592 | CLSLoss:0.0000 | AUROC:0.9902\n",
      "Test | 122/16 | Loss:0.4231 | MainLoss:0.4231 | SPLoss:0.2592 | CLSLoss:0.0000 | AUROC:0.9139\n",
      "\n",
      "Epoch: [280 | 1000] LR: 0.017543\n",
      "Train | 16/16 | Loss:0.1675 | MainLoss:0.1415 | Alpha:0.4491 | SPLoss:0.2599 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1203 | MainLoss:0.1203 | SPLoss:0.2615 | CLSLoss:0.0000 | AUROC:0.9902\n",
      "Test | 122/16 | Loss:0.4432 | MainLoss:0.4432 | SPLoss:0.2615 | CLSLoss:0.0000 | AUROC:0.9180\n",
      "\n",
      "Epoch: [281 | 1000] LR: 0.017522\n",
      "Train | 16/16 | Loss:0.1702 | MainLoss:0.1441 | Alpha:0.4478 | SPLoss:0.2609 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1255 | MainLoss:0.1255 | SPLoss:0.2611 | CLSLoss:0.0000 | AUROC:0.9900\n",
      "Test | 122/16 | Loss:0.4046 | MainLoss:0.4046 | SPLoss:0.2611 | CLSLoss:0.0000 | AUROC:0.9182\n",
      "\n",
      "Epoch: [282 | 1000] LR: 0.017501\n",
      "Train | 16/16 | Loss:0.1650 | MainLoss:0.1387 | Alpha:0.4480 | SPLoss:0.2627 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1241 | MainLoss:0.1241 | SPLoss:0.2654 | CLSLoss:0.0000 | AUROC:0.9900\n",
      "Test | 122/16 | Loss:0.4289 | MainLoss:0.4289 | SPLoss:0.2654 | CLSLoss:0.0000 | AUROC:0.9151\n",
      "\n",
      "Epoch: [283 | 1000] LR: 0.017480\n",
      "Train | 16/16 | Loss:0.1639 | MainLoss:0.1374 | Alpha:0.4484 | SPLoss:0.2647 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1221 | MainLoss:0.1221 | SPLoss:0.2667 | CLSLoss:0.0000 | AUROC:0.9899\n",
      "Test | 122/16 | Loss:0.4276 | MainLoss:0.4276 | SPLoss:0.2667 | CLSLoss:0.0000 | AUROC:0.9201\n",
      "\n",
      "Epoch: [284 | 1000] LR: 0.017459\n",
      "Train | 16/16 | Loss:0.1540 | MainLoss:0.1272 | Alpha:0.4495 | SPLoss:0.2681 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1261 | MainLoss:0.1261 | SPLoss:0.2692 | CLSLoss:0.0000 | AUROC:0.9897\n",
      "Test | 122/16 | Loss:0.4053 | MainLoss:0.4053 | SPLoss:0.2692 | CLSLoss:0.0000 | AUROC:0.9211\n",
      "\n",
      "Epoch: [285 | 1000] LR: 0.017438\n",
      "Train | 16/16 | Loss:0.1599 | MainLoss:0.1329 | Alpha:0.4516 | SPLoss:0.2696 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1289 | MainLoss:0.1289 | SPLoss:0.2682 | CLSLoss:0.0000 | AUROC:0.9899\n",
      "Test | 122/16 | Loss:0.4180 | MainLoss:0.4180 | SPLoss:0.2682 | CLSLoss:0.0000 | AUROC:0.9147\n",
      "\n",
      "Epoch: [286 | 1000] LR: 0.017417\n",
      "Train | 16/16 | Loss:0.1669 | MainLoss:0.1399 | Alpha:0.4469 | SPLoss:0.2703 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1237 | MainLoss:0.1237 | SPLoss:0.2718 | CLSLoss:0.0000 | AUROC:0.9901\n",
      "Test | 122/16 | Loss:0.4085 | MainLoss:0.4085 | SPLoss:0.2718 | CLSLoss:0.0000 | AUROC:0.9213\n",
      "\n",
      "Epoch: [287 | 1000] LR: 0.017396\n",
      "Train | 16/16 | Loss:0.1665 | MainLoss:0.1393 | Alpha:0.4473 | SPLoss:0.2715 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1250 | MainLoss:0.1250 | SPLoss:0.2725 | CLSLoss:0.0000 | AUROC:0.9903\n",
      "Test | 122/16 | Loss:0.4154 | MainLoss:0.4154 | SPLoss:0.2725 | CLSLoss:0.0000 | AUROC:0.9188\n",
      "\n",
      "Epoch: [288 | 1000] LR: 0.017375\n",
      "Train | 16/16 | Loss:0.1674 | MainLoss:0.1401 | Alpha:0.4471 | SPLoss:0.2726 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1222 | MainLoss:0.1222 | SPLoss:0.2738 | CLSLoss:0.0000 | AUROC:0.9901\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.2738 | CLSLoss:0.0000 | AUROC:0.9215\n",
      "\n",
      "Epoch: [289 | 1000] LR: 0.017354\n",
      "Train | 16/16 | Loss:0.1692 | MainLoss:0.1418 | Alpha:0.4469 | SPLoss:0.2743 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1221 | MainLoss:0.1221 | SPLoss:0.2755 | CLSLoss:0.0000 | AUROC:0.9900\n",
      "Test | 122/16 | Loss:0.4177 | MainLoss:0.4177 | SPLoss:0.2755 | CLSLoss:0.0000 | AUROC:0.9255\n",
      "\n",
      "Epoch: [290 | 1000] LR: 0.017333\n",
      "Train | 16/16 | Loss:0.1620 | MainLoss:0.1346 | Alpha:0.4482 | SPLoss:0.2743 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1441 | MainLoss:0.1441 | SPLoss:0.2735 | CLSLoss:0.0000 | AUROC:0.9901\n",
      "Test | 122/16 | Loss:0.3968 | MainLoss:0.3968 | SPLoss:0.2735 | CLSLoss:0.0000 | AUROC:0.9187\n",
      "\n",
      "Epoch: [291 | 1000] LR: 0.017311\n",
      "Train | 16/16 | Loss:0.1676 | MainLoss:0.1402 | Alpha:0.4489 | SPLoss:0.2743 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1247 | MainLoss:0.1247 | SPLoss:0.2742 | CLSLoss:0.0000 | AUROC:0.9904\n",
      "Test | 122/16 | Loss:0.4099 | MainLoss:0.4099 | SPLoss:0.2742 | CLSLoss:0.0000 | AUROC:0.9204\n",
      "\n",
      "Epoch: [292 | 1000] LR: 0.017290\n",
      "Train | 16/16 | Loss:0.1635 | MainLoss:0.1361 | Alpha:0.4483 | SPLoss:0.2743 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1229 | MainLoss:0.1229 | SPLoss:0.2735 | CLSLoss:0.0000 | AUROC:0.9903\n",
      "Test | 122/16 | Loss:0.4036 | MainLoss:0.4036 | SPLoss:0.2735 | CLSLoss:0.0000 | AUROC:0.9248\n",
      "\n",
      "Epoch: [293 | 1000] LR: 0.017268\n",
      "Train | 16/16 | Loss:0.1627 | MainLoss:0.1351 | Alpha:0.4487 | SPLoss:0.2756 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1264 | MainLoss:0.1264 | SPLoss:0.2757 | CLSLoss:0.0000 | AUROC:0.9900\n",
      "Test | 122/16 | Loss:0.4060 | MainLoss:0.4060 | SPLoss:0.2757 | CLSLoss:0.0000 | AUROC:0.9200\n",
      "\n",
      "Epoch: [294 | 1000] LR: 0.017247\n",
      "Train | 16/16 | Loss:0.1622 | MainLoss:0.1347 | Alpha:0.4488 | SPLoss:0.2755 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1271 | MainLoss:0.1271 | SPLoss:0.2745 | CLSLoss:0.0000 | AUROC:0.9901\n",
      "Test | 122/16 | Loss:0.4005 | MainLoss:0.4005 | SPLoss:0.2745 | CLSLoss:0.0000 | AUROC:0.9229\n",
      "\n",
      "Epoch: [295 | 1000] LR: 0.017225\n",
      "Train | 16/16 | Loss:0.1703 | MainLoss:0.1427 | Alpha:0.4466 | SPLoss:0.2764 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1253 | MainLoss:0.1253 | SPLoss:0.2773 | CLSLoss:0.0000 | AUROC:0.9901\n",
      "Test | 122/16 | Loss:0.3909 | MainLoss:0.3909 | SPLoss:0.2773 | CLSLoss:0.0000 | AUROC:0.9231\n",
      "\n",
      "Epoch: [296 | 1000] LR: 0.017203\n",
      "Train | 16/16 | Loss:0.1753 | MainLoss:0.1476 | Alpha:0.4470 | SPLoss:0.2774 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1192 | MainLoss:0.1192 | SPLoss:0.2795 | CLSLoss:0.0000 | AUROC:0.9903\n",
      "Test | 122/16 | Loss:0.4264 | MainLoss:0.4264 | SPLoss:0.2795 | CLSLoss:0.0000 | AUROC:0.9256\n",
      "\n",
      "Epoch: [297 | 1000] LR: 0.017181\n",
      "Train | 16/16 | Loss:0.1614 | MainLoss:0.1336 | Alpha:0.4486 | SPLoss:0.2778 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1246 | MainLoss:0.1246 | SPLoss:0.2761 | CLSLoss:0.0000 | AUROC:0.9904\n",
      "Test | 122/16 | Loss:0.4274 | MainLoss:0.4274 | SPLoss:0.2761 | CLSLoss:0.0000 | AUROC:0.9156\n",
      "\n",
      "Epoch: [298 | 1000] LR: 0.017159\n",
      "Train | 16/16 | Loss:0.1549 | MainLoss:0.1273 | Alpha:0.4515 | SPLoss:0.2759 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1261 | MainLoss:0.1261 | SPLoss:0.2754 | CLSLoss:0.0000 | AUROC:0.9904\n",
      "Test | 122/16 | Loss:0.4121 | MainLoss:0.4121 | SPLoss:0.2754 | CLSLoss:0.0000 | AUROC:0.9203\n",
      "\n",
      "Epoch: [299 | 1000] LR: 0.017137\n",
      "Train | 16/16 | Loss:0.1742 | MainLoss:0.1464 | Alpha:0.4450 | SPLoss:0.2771 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1202 | MainLoss:0.1202 | SPLoss:0.2786 | CLSLoss:0.0000 | AUROC:0.9907\n",
      "Test | 122/16 | Loss:0.4257 | MainLoss:0.4257 | SPLoss:0.2786 | CLSLoss:0.0000 | AUROC:0.9208\n",
      "\n",
      "Epoch: [300 | 1000] LR: 0.017115\n",
      "Train | 16/16 | Loss:0.1691 | MainLoss:0.1412 | Alpha:0.4469 | SPLoss:0.2796 | CLSLoss:0.0000 | AUROC:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 32/16 | Loss:0.1265 | MainLoss:0.1265 | SPLoss:0.2807 | CLSLoss:0.0000 | AUROC:0.9904\n",
      "Test | 122/16 | Loss:0.3873 | MainLoss:0.3873 | SPLoss:0.2807 | CLSLoss:0.0000 | AUROC:0.9236\n",
      "\n",
      "Epoch: [301 | 1000] LR: 0.017093\n",
      "Train | 16/16 | Loss:0.1335 | MainLoss:0.1333 | Alpha:0.4681 | SPLoss:0.0017 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1214 | MainLoss:0.1214 | SPLoss:0.0029 | CLSLoss:0.0000 | AUROC:0.9903\n",
      "Test | 122/16 | Loss:0.3990 | MainLoss:0.3990 | SPLoss:0.0029 | CLSLoss:0.0000 | AUROC:0.9252\n",
      "\n",
      "Epoch: [302 | 1000] LR: 0.017071\n",
      "Train | 16/16 | Loss:0.1360 | MainLoss:0.1355 | Alpha:0.4666 | SPLoss:0.0050 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1233 | MainLoss:0.1233 | SPLoss:0.0069 | CLSLoss:0.0000 | AUROC:0.9906\n",
      "Test | 122/16 | Loss:0.4076 | MainLoss:0.4076 | SPLoss:0.0069 | CLSLoss:0.0000 | AUROC:0.9215\n",
      "\n",
      "Epoch: [303 | 1000] LR: 0.017049\n",
      "Train | 16/16 | Loss:0.1315 | MainLoss:0.1306 | Alpha:0.4685 | SPLoss:0.0088 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1195 | MainLoss:0.1195 | SPLoss:0.0106 | CLSLoss:0.0000 | AUROC:0.9908\n",
      "Test | 122/16 | Loss:0.4268 | MainLoss:0.4268 | SPLoss:0.0106 | CLSLoss:0.0000 | AUROC:0.9205\n",
      "\n",
      "Epoch: [304 | 1000] LR: 0.017026\n",
      "Train | 16/16 | Loss:0.1355 | MainLoss:0.1343 | Alpha:0.4674 | SPLoss:0.0121 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1179 | MainLoss:0.1179 | SPLoss:0.0139 | CLSLoss:0.0000 | AUROC:0.9908\n",
      "Test | 122/16 | Loss:0.4447 | MainLoss:0.4447 | SPLoss:0.0139 | CLSLoss:0.0000 | AUROC:0.9210\n",
      "\n",
      "Epoch: [305 | 1000] LR: 0.017004\n",
      "Train | 16/16 | Loss:0.1348 | MainLoss:0.1332 | Alpha:0.4669 | SPLoss:0.0152 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1189 | MainLoss:0.1189 | SPLoss:0.0167 | CLSLoss:0.0000 | AUROC:0.9911\n",
      "Test | 122/16 | Loss:0.4257 | MainLoss:0.4257 | SPLoss:0.0167 | CLSLoss:0.0000 | AUROC:0.9173\n",
      "\n",
      "Epoch: [306 | 1000] LR: 0.016982\n",
      "Train | 16/16 | Loss:0.1411 | MainLoss:0.1393 | Alpha:0.4658 | SPLoss:0.0178 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1249 | MainLoss:0.1249 | SPLoss:0.0190 | CLSLoss:0.0000 | AUROC:0.9912\n",
      "Test | 122/16 | Loss:0.3924 | MainLoss:0.3924 | SPLoss:0.0190 | CLSLoss:0.0000 | AUROC:0.9201\n",
      "\n",
      "Epoch: [307 | 1000] LR: 0.016959\n",
      "Train | 16/16 | Loss:0.1352 | MainLoss:0.1331 | Alpha:0.4656 | SPLoss:0.0209 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1166 | MainLoss:0.1166 | SPLoss:0.0225 | CLSLoss:0.0000 | AUROC:0.9910\n",
      "Test | 122/16 | Loss:0.4355 | MainLoss:0.4355 | SPLoss:0.0225 | CLSLoss:0.0000 | AUROC:0.9189\n",
      "\n",
      "Epoch: [308 | 1000] LR: 0.016937\n",
      "Train | 16/16 | Loss:0.1313 | MainLoss:0.1289 | Alpha:0.4663 | SPLoss:0.0238 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1202 | MainLoss:0.1202 | SPLoss:0.0250 | CLSLoss:0.0000 | AUROC:0.9914\n",
      "Test | 122/16 | Loss:0.4137 | MainLoss:0.4137 | SPLoss:0.0250 | CLSLoss:0.0000 | AUROC:0.9205\n",
      "\n",
      "Epoch: [309 | 1000] LR: 0.016914\n",
      "Train | 16/16 | Loss:0.1321 | MainLoss:0.1295 | Alpha:0.4662 | SPLoss:0.0265 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1140 | MainLoss:0.1140 | SPLoss:0.0290 | CLSLoss:0.0000 | AUROC:0.9913\n",
      "Test | 122/16 | Loss:0.4488 | MainLoss:0.4488 | SPLoss:0.0290 | CLSLoss:0.0000 | AUROC:0.9175\n",
      "\n",
      "Epoch: [310 | 1000] LR: 0.016891\n",
      "Train | 16/16 | Loss:0.1197 | MainLoss:0.1167 | Alpha:0.4698 | SPLoss:0.0305 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1161 | MainLoss:0.1161 | SPLoss:0.0320 | CLSLoss:0.0000 | AUROC:0.9916\n",
      "Test | 122/16 | Loss:0.4259 | MainLoss:0.4259 | SPLoss:0.0320 | CLSLoss:0.0000 | AUROC:0.9232\n",
      "\n",
      "Epoch: [311 | 1000] LR: 0.016868\n",
      "Train | 16/16 | Loss:0.1321 | MainLoss:0.1288 | Alpha:0.4662 | SPLoss:0.0334 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1146 | MainLoss:0.1146 | SPLoss:0.0343 | CLSLoss:0.0000 | AUROC:0.9912\n",
      "Test | 122/16 | Loss:0.4410 | MainLoss:0.4410 | SPLoss:0.0343 | CLSLoss:0.0000 | AUROC:0.9219\n",
      "\n",
      "Epoch: [312 | 1000] LR: 0.016845\n",
      "Train | 16/16 | Loss:0.1366 | MainLoss:0.1330 | Alpha:0.4655 | SPLoss:0.0357 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1127 | MainLoss:0.1127 | SPLoss:0.0370 | CLSLoss:0.0000 | AUROC:0.9916\n",
      "Test | 122/16 | Loss:0.4094 | MainLoss:0.4094 | SPLoss:0.0370 | CLSLoss:0.0000 | AUROC:0.9255\n",
      "\n",
      "Epoch: [313 | 1000] LR: 0.016823\n",
      "Train | 16/16 | Loss:0.1321 | MainLoss:0.1282 | Alpha:0.4669 | SPLoss:0.0385 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1197 | MainLoss:0.1197 | SPLoss:0.0401 | CLSLoss:0.0000 | AUROC:0.9918\n",
      "Test | 122/16 | Loss:0.3937 | MainLoss:0.3937 | SPLoss:0.0401 | CLSLoss:0.0000 | AUROC:0.9230\n",
      "\n",
      "Epoch: [314 | 1000] LR: 0.016800\n",
      "Train | 16/16 | Loss:0.1280 | MainLoss:0.1238 | Alpha:0.4678 | SPLoss:0.0416 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1190 | MainLoss:0.1190 | SPLoss:0.0428 | CLSLoss:0.0000 | AUROC:0.9914\n",
      "Test | 122/16 | Loss:0.4134 | MainLoss:0.4134 | SPLoss:0.0428 | CLSLoss:0.0000 | AUROC:0.9203\n",
      "\n",
      "Epoch: [315 | 1000] LR: 0.016776\n",
      "Train | 16/16 | Loss:0.1293 | MainLoss:0.1250 | Alpha:0.4674 | SPLoss:0.0436 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1137 | MainLoss:0.1137 | SPLoss:0.0455 | CLSLoss:0.0000 | AUROC:0.9916\n",
      "Test | 122/16 | Loss:0.4124 | MainLoss:0.4124 | SPLoss:0.0455 | CLSLoss:0.0000 | AUROC:0.9255\n",
      "\n",
      "Epoch: [316 | 1000] LR: 0.016753\n",
      "Train | 16/16 | Loss:0.1230 | MainLoss:0.1182 | Alpha:0.4677 | SPLoss:0.0472 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1185 | MainLoss:0.1185 | SPLoss:0.0484 | CLSLoss:0.0000 | AUROC:0.9916\n",
      "Test | 122/16 | Loss:0.4396 | MainLoss:0.4396 | SPLoss:0.0484 | CLSLoss:0.0000 | AUROC:0.9175\n",
      "\n",
      "Epoch: [317 | 1000] LR: 0.016730\n",
      "Train | 16/16 | Loss:0.1354 | MainLoss:0.1303 | Alpha:0.4638 | SPLoss:0.0507 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1157 | MainLoss:0.1157 | SPLoss:0.0524 | CLSLoss:0.0000 | AUROC:0.9916\n",
      "Test | 122/16 | Loss:0.4252 | MainLoss:0.4252 | SPLoss:0.0524 | CLSLoss:0.0000 | AUROC:0.9205\n",
      "\n",
      "Epoch: [318 | 1000] LR: 0.016707\n",
      "Train | 16/16 | Loss:0.1191 | MainLoss:0.1136 | Alpha:0.4676 | SPLoss:0.0543 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1192 | MainLoss:0.1192 | SPLoss:0.0553 | CLSLoss:0.0000 | AUROC:0.9914\n",
      "Test | 122/16 | Loss:0.4161 | MainLoss:0.4161 | SPLoss:0.0553 | CLSLoss:0.0000 | AUROC:0.9224\n",
      "\n",
      "Epoch: [319 | 1000] LR: 0.016684\n",
      "Train | 16/16 | Loss:0.1189 | MainLoss:0.1133 | Alpha:0.4688 | SPLoss:0.0563 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1191 | MainLoss:0.1191 | SPLoss:0.0571 | CLSLoss:0.0000 | AUROC:0.9914\n",
      "Test | 122/16 | Loss:0.4200 | MainLoss:0.4200 | SPLoss:0.0571 | CLSLoss:0.0000 | AUROC:0.9248\n",
      "\n",
      "Epoch: [320 | 1000] LR: 0.016660\n",
      "Train | 16/16 | Loss:0.1224 | MainLoss:0.1166 | Alpha:0.4678 | SPLoss:0.0584 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1165 | MainLoss:0.1165 | SPLoss:0.0600 | CLSLoss:0.0000 | AUROC:0.9917\n",
      "Test | 122/16 | Loss:0.4254 | MainLoss:0.4254 | SPLoss:0.0600 | CLSLoss:0.0000 | AUROC:0.9237\n",
      "\n",
      "Epoch: [321 | 1000] LR: 0.016637\n",
      "Train | 16/16 | Loss:0.1338 | MainLoss:0.1276 | Alpha:0.4663 | SPLoss:0.0617 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1124 | MainLoss:0.1124 | SPLoss:0.0638 | CLSLoss:0.0000 | AUROC:0.9920\n",
      "Test | 122/16 | Loss:0.4224 | MainLoss:0.4224 | SPLoss:0.0638 | CLSLoss:0.0000 | AUROC:0.9232\n",
      "\n",
      "Epoch: [322 | 1000] LR: 0.016613\n",
      "Train | 16/16 | Loss:0.1180 | MainLoss:0.1114 | Alpha:0.4685 | SPLoss:0.0652 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1203 | MainLoss:0.1203 | SPLoss:0.0668 | CLSLoss:0.0000 | AUROC:0.9917\n",
      "Test | 122/16 | Loss:0.4241 | MainLoss:0.4241 | SPLoss:0.0668 | CLSLoss:0.0000 | AUROC:0.9206\n",
      "\n",
      "Epoch: [323 | 1000] LR: 0.016590\n",
      "Train | 16/16 | Loss:0.1139 | MainLoss:0.1071 | Alpha:0.4690 | SPLoss:0.0685 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1189 | MainLoss:0.1189 | SPLoss:0.0703 | CLSLoss:0.0000 | AUROC:0.9914\n",
      "Test | 122/16 | Loss:0.4135 | MainLoss:0.4135 | SPLoss:0.0703 | CLSLoss:0.0000 | AUROC:0.9270\n",
      "\n",
      "Epoch: [324 | 1000] LR: 0.016566\n",
      "Train | 16/16 | Loss:0.1346 | MainLoss:0.1274 | Alpha:0.4646 | SPLoss:0.0720 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1139 | MainLoss:0.1139 | SPLoss:0.0732 | CLSLoss:0.0000 | AUROC:0.9915\n",
      "Test | 122/16 | Loss:0.3973 | MainLoss:0.3973 | SPLoss:0.0732 | CLSLoss:0.0000 | AUROC:0.9270\n",
      "\n",
      "Epoch: [325 | 1000] LR: 0.016542\n",
      "Train | 16/16 | Loss:0.1212 | MainLoss:0.1138 | Alpha:0.4679 | SPLoss:0.0745 | CLSLoss:0.0000 | AUROC:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 32/16 | Loss:0.1121 | MainLoss:0.1121 | SPLoss:0.0760 | CLSLoss:0.0000 | AUROC:0.9917\n",
      "Test | 122/16 | Loss:0.4180 | MainLoss:0.4180 | SPLoss:0.0760 | CLSLoss:0.0000 | AUROC:0.9256\n",
      "\n",
      "Epoch: [326 | 1000] LR: 0.016518\n",
      "Train | 16/16 | Loss:0.1234 | MainLoss:0.1157 | Alpha:0.4674 | SPLoss:0.0765 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1130 | MainLoss:0.1130 | SPLoss:0.0779 | CLSLoss:0.0000 | AUROC:0.9917\n",
      "Test | 122/16 | Loss:0.4033 | MainLoss:0.4033 | SPLoss:0.0779 | CLSLoss:0.0000 | AUROC:0.9270\n",
      "\n",
      "Epoch: [327 | 1000] LR: 0.016494\n",
      "Train | 16/16 | Loss:0.1327 | MainLoss:0.1248 | Alpha:0.4652 | SPLoss:0.0788 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1145 | MainLoss:0.1145 | SPLoss:0.0796 | CLSLoss:0.0000 | AUROC:0.9919\n",
      "Test | 122/16 | Loss:0.4055 | MainLoss:0.4055 | SPLoss:0.0796 | CLSLoss:0.0000 | AUROC:0.9251\n",
      "\n",
      "Epoch: [328 | 1000] LR: 0.016471\n",
      "Train | 16/16 | Loss:0.1301 | MainLoss:0.1219 | Alpha:0.4655 | SPLoss:0.0813 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1107 | MainLoss:0.1107 | SPLoss:0.0827 | CLSLoss:0.0000 | AUROC:0.9920\n",
      "Test | 122/16 | Loss:0.4250 | MainLoss:0.4250 | SPLoss:0.0827 | CLSLoss:0.0000 | AUROC:0.9244\n",
      "\n",
      "Epoch: [329 | 1000] LR: 0.016447\n",
      "Train | 16/16 | Loss:0.1312 | MainLoss:0.1228 | Alpha:0.4661 | SPLoss:0.0840 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1222 | MainLoss:0.1222 | SPLoss:0.0852 | CLSLoss:0.0000 | AUROC:0.9917\n",
      "Test | 122/16 | Loss:0.3861 | MainLoss:0.3861 | SPLoss:0.0852 | CLSLoss:0.0000 | AUROC:0.9251\n",
      "\n",
      "Epoch: [330 | 1000] LR: 0.016423\n",
      "Train | 16/16 | Loss:0.1357 | MainLoss:0.1269 | Alpha:0.4649 | SPLoss:0.0876 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1137 | MainLoss:0.1137 | SPLoss:0.0887 | CLSLoss:0.0000 | AUROC:0.9918\n",
      "Test | 122/16 | Loss:0.4117 | MainLoss:0.4117 | SPLoss:0.0887 | CLSLoss:0.0000 | AUROC:0.9211\n",
      "\n",
      "Epoch: [331 | 1000] LR: 0.016398\n",
      "Train | 16/16 | Loss:0.1182 | MainLoss:0.1092 | Alpha:0.4679 | SPLoss:0.0900 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1172 | MainLoss:0.1172 | SPLoss:0.0911 | CLSLoss:0.0000 | AUROC:0.9917\n",
      "Test | 122/16 | Loss:0.4122 | MainLoss:0.4122 | SPLoss:0.0911 | CLSLoss:0.0000 | AUROC:0.9244\n",
      "\n",
      "Epoch: [332 | 1000] LR: 0.016374\n",
      "Train | 16/16 | Loss:0.1237 | MainLoss:0.1145 | Alpha:0.4672 | SPLoss:0.0921 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1225 | MainLoss:0.1225 | SPLoss:0.0931 | CLSLoss:0.0000 | AUROC:0.9918\n",
      "Test | 122/16 | Loss:0.4040 | MainLoss:0.4040 | SPLoss:0.0931 | CLSLoss:0.0000 | AUROC:0.9237\n",
      "\n",
      "Epoch: [333 | 1000] LR: 0.016350\n",
      "Train | 16/16 | Loss:0.1241 | MainLoss:0.1144 | Alpha:0.4672 | SPLoss:0.0962 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1151 | MainLoss:0.1151 | SPLoss:0.0976 | CLSLoss:0.0000 | AUROC:0.9917\n",
      "Test | 122/16 | Loss:0.3730 | MainLoss:0.3730 | SPLoss:0.0976 | CLSLoss:0.0000 | AUROC:0.9376\n",
      "\n",
      "Epoch: [334 | 1000] LR: 0.016326\n",
      "Train | 16/16 | Loss:0.1270 | MainLoss:0.1172 | Alpha:0.4673 | SPLoss:0.0975 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1135 | MainLoss:0.1135 | SPLoss:0.0976 | CLSLoss:0.0000 | AUROC:0.9918\n",
      "Test | 122/16 | Loss:0.4321 | MainLoss:0.4321 | SPLoss:0.0976 | CLSLoss:0.0000 | AUROC:0.9282\n",
      "\n",
      "Epoch: [335 | 1000] LR: 0.016301\n",
      "Train | 16/16 | Loss:0.1282 | MainLoss:0.1183 | Alpha:0.4658 | SPLoss:0.0984 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1150 | MainLoss:0.1150 | SPLoss:0.0998 | CLSLoss:0.0000 | AUROC:0.9920\n",
      "Test | 122/16 | Loss:0.4219 | MainLoss:0.4219 | SPLoss:0.0998 | CLSLoss:0.0000 | AUROC:0.9263\n",
      "\n",
      "Epoch: [336 | 1000] LR: 0.016277\n",
      "Train | 16/16 | Loss:0.1276 | MainLoss:0.1174 | Alpha:0.4654 | SPLoss:0.1020 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1122 | MainLoss:0.1122 | SPLoss:0.1034 | CLSLoss:0.0000 | AUROC:0.9920\n",
      "Test | 122/16 | Loss:0.4252 | MainLoss:0.4252 | SPLoss:0.1034 | CLSLoss:0.0000 | AUROC:0.9273\n",
      "\n",
      "Epoch: [337 | 1000] LR: 0.016252\n",
      "Train | 16/16 | Loss:0.1338 | MainLoss:0.1234 | Alpha:0.4653 | SPLoss:0.1040 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1142 | MainLoss:0.1142 | SPLoss:0.1046 | CLSLoss:0.0000 | AUROC:0.9919\n",
      "Test | 122/16 | Loss:0.4240 | MainLoss:0.4240 | SPLoss:0.1046 | CLSLoss:0.0000 | AUROC:0.9233\n",
      "\n",
      "Epoch: [338 | 1000] LR: 0.016228\n",
      "Train | 16/16 | Loss:0.1210 | MainLoss:0.1104 | Alpha:0.4673 | SPLoss:0.1053 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1200 | MainLoss:0.1200 | SPLoss:0.1053 | CLSLoss:0.0000 | AUROC:0.9921\n",
      "Test | 122/16 | Loss:0.4180 | MainLoss:0.4180 | SPLoss:0.1053 | CLSLoss:0.0000 | AUROC:0.9243\n",
      "\n",
      "Epoch: [339 | 1000] LR: 0.016203\n",
      "Train | 16/16 | Loss:0.1259 | MainLoss:0.1152 | Alpha:0.4661 | SPLoss:0.1064 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1192 | MainLoss:0.1192 | SPLoss:0.1083 | CLSLoss:0.0000 | AUROC:0.9921\n",
      "Test | 122/16 | Loss:0.3914 | MainLoss:0.3914 | SPLoss:0.1083 | CLSLoss:0.0000 | AUROC:0.9282\n",
      "\n",
      "Epoch: [340 | 1000] LR: 0.016179\n",
      "Train | 16/16 | Loss:0.1313 | MainLoss:0.1203 | Alpha:0.4639 | SPLoss:0.1102 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1126 | MainLoss:0.1126 | SPLoss:0.1114 | CLSLoss:0.0000 | AUROC:0.9920\n",
      "Test | 122/16 | Loss:0.4520 | MainLoss:0.4520 | SPLoss:0.1114 | CLSLoss:0.0000 | AUROC:0.9230\n",
      "\n",
      "Epoch: [341 | 1000] LR: 0.016154\n",
      "Train | 16/16 | Loss:0.1192 | MainLoss:0.1081 | Alpha:0.4687 | SPLoss:0.1118 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1135 | MainLoss:0.1135 | SPLoss:0.1119 | CLSLoss:0.0000 | AUROC:0.9916\n",
      "Test | 122/16 | Loss:0.4420 | MainLoss:0.4420 | SPLoss:0.1119 | CLSLoss:0.0000 | AUROC:0.9282\n",
      "\n",
      "Epoch: [342 | 1000] LR: 0.016129\n",
      "Train | 16/16 | Loss:0.1357 | MainLoss:0.1245 | Alpha:0.4637 | SPLoss:0.1121 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1126 | MainLoss:0.1126 | SPLoss:0.1130 | CLSLoss:0.0000 | AUROC:0.9917\n",
      "Test | 122/16 | Loss:0.3881 | MainLoss:0.3881 | SPLoss:0.1130 | CLSLoss:0.0000 | AUROC:0.9284\n",
      "\n",
      "Epoch: [343 | 1000] LR: 0.016104\n",
      "Train | 16/16 | Loss:0.1254 | MainLoss:0.1141 | Alpha:0.4673 | SPLoss:0.1133 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1150 | MainLoss:0.1150 | SPLoss:0.1138 | CLSLoss:0.0000 | AUROC:0.9918\n",
      "Test | 122/16 | Loss:0.4059 | MainLoss:0.4059 | SPLoss:0.1138 | CLSLoss:0.0000 | AUROC:0.9294\n",
      "\n",
      "Epoch: [344 | 1000] LR: 0.016079\n",
      "Train | 16/16 | Loss:0.1303 | MainLoss:0.1189 | Alpha:0.4656 | SPLoss:0.1140 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1146 | MainLoss:0.1146 | SPLoss:0.1146 | CLSLoss:0.0000 | AUROC:0.9917\n",
      "Test | 122/16 | Loss:0.4285 | MainLoss:0.4285 | SPLoss:0.1146 | CLSLoss:0.0000 | AUROC:0.9274\n",
      "\n",
      "Epoch: [345 | 1000] LR: 0.016054\n",
      "Train | 16/16 | Loss:0.1251 | MainLoss:0.1135 | Alpha:0.4664 | SPLoss:0.1160 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1131 | MainLoss:0.1131 | SPLoss:0.1165 | CLSLoss:0.0000 | AUROC:0.9918\n",
      "Test | 122/16 | Loss:0.4298 | MainLoss:0.4298 | SPLoss:0.1165 | CLSLoss:0.0000 | AUROC:0.9268\n",
      "\n",
      "Epoch: [346 | 1000] LR: 0.016029\n",
      "Train | 16/16 | Loss:0.1377 | MainLoss:0.1261 | Alpha:0.4635 | SPLoss:0.1166 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1113 | MainLoss:0.1113 | SPLoss:0.1175 | CLSLoss:0.0000 | AUROC:0.9921\n",
      "Test | 122/16 | Loss:0.4015 | MainLoss:0.4015 | SPLoss:0.1175 | CLSLoss:0.0000 | AUROC:0.9320\n",
      "\n",
      "Epoch: [347 | 1000] LR: 0.016004\n",
      "Train | 16/16 | Loss:0.1273 | MainLoss:0.1155 | Alpha:0.4661 | SPLoss:0.1180 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1181 | MainLoss:0.1181 | SPLoss:0.1183 | CLSLoss:0.0000 | AUROC:0.9921\n",
      "Test | 122/16 | Loss:0.3810 | MainLoss:0.3810 | SPLoss:0.1183 | CLSLoss:0.0000 | AUROC:0.9252\n",
      "\n",
      "Epoch: [348 | 1000] LR: 0.015979\n",
      "Train | 16/16 | Loss:0.1189 | MainLoss:0.1070 | Alpha:0.4681 | SPLoss:0.1191 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1122 | MainLoss:0.1122 | SPLoss:0.1200 | CLSLoss:0.0000 | AUROC:0.9921\n",
      "Test | 122/16 | Loss:0.4223 | MainLoss:0.4223 | SPLoss:0.1200 | CLSLoss:0.0000 | AUROC:0.9237\n",
      "\n",
      "Epoch: [349 | 1000] LR: 0.015954\n",
      "Train | 16/16 | Loss:0.1187 | MainLoss:0.1067 | Alpha:0.4680 | SPLoss:0.1200 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1162 | MainLoss:0.1162 | SPLoss:0.1195 | CLSLoss:0.0000 | AUROC:0.9919\n",
      "Test | 122/16 | Loss:0.4482 | MainLoss:0.4482 | SPLoss:0.1195 | CLSLoss:0.0000 | AUROC:0.9169\n",
      "\n",
      "Epoch: [350 | 1000] LR: 0.015929\n",
      "Train | 16/16 | Loss:0.1236 | MainLoss:0.1115 | Alpha:0.4668 | SPLoss:0.1202 | CLSLoss:0.0000 | AUROC:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 32/16 | Loss:0.1200 | MainLoss:0.1200 | SPLoss:0.1204 | CLSLoss:0.0000 | AUROC:0.9918\n",
      "Test | 122/16 | Loss:0.4239 | MainLoss:0.4239 | SPLoss:0.1204 | CLSLoss:0.0000 | AUROC:0.9189\n",
      "\n",
      "Epoch: [351 | 1000] LR: 0.015903\n",
      "Train | 16/16 | Loss:0.1250 | MainLoss:0.1128 | Alpha:0.4669 | SPLoss:0.1215 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1109 | MainLoss:0.1109 | SPLoss:0.1228 | CLSLoss:0.0000 | AUROC:0.9919\n",
      "Test | 122/16 | Loss:0.4345 | MainLoss:0.4345 | SPLoss:0.1228 | CLSLoss:0.0000 | AUROC:0.9230\n",
      "\n",
      "Epoch: [352 | 1000] LR: 0.015878\n",
      "Train | 16/16 | Loss:0.1371 | MainLoss:0.1247 | Alpha:0.4637 | SPLoss:0.1243 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1151 | MainLoss:0.1151 | SPLoss:0.1252 | CLSLoss:0.0000 | AUROC:0.9922\n",
      "Test | 122/16 | Loss:0.4132 | MainLoss:0.4132 | SPLoss:0.1252 | CLSLoss:0.0000 | AUROC:0.9203\n",
      "\n",
      "Epoch: [353 | 1000] LR: 0.015852\n",
      "Train | 16/16 | Loss:0.1246 | MainLoss:0.1121 | Alpha:0.4664 | SPLoss:0.1251 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1153 | MainLoss:0.1153 | SPLoss:0.1252 | CLSLoss:0.0000 | AUROC:0.9925\n",
      "Test | 122/16 | Loss:0.4438 | MainLoss:0.4438 | SPLoss:0.1252 | CLSLoss:0.0000 | AUROC:0.9163\n",
      "\n",
      "Epoch: [354 | 1000] LR: 0.015827\n",
      "Train | 16/16 | Loss:0.1290 | MainLoss:0.1164 | Alpha:0.4662 | SPLoss:0.1258 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1088 | MainLoss:0.1088 | SPLoss:0.1262 | CLSLoss:0.0000 | AUROC:0.9922\n",
      "Test | 122/16 | Loss:0.4310 | MainLoss:0.4310 | SPLoss:0.1262 | CLSLoss:0.0000 | AUROC:0.9224\n",
      "\n",
      "Epoch: [355 | 1000] LR: 0.015801\n",
      "Train | 16/16 | Loss:0.1195 | MainLoss:0.1070 | Alpha:0.4682 | SPLoss:0.1259 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1228 | MainLoss:0.1228 | SPLoss:0.1261 | CLSLoss:0.0000 | AUROC:0.9921\n",
      "Test | 122/16 | Loss:0.4385 | MainLoss:0.4385 | SPLoss:0.1261 | CLSLoss:0.0000 | AUROC:0.9160\n",
      "\n",
      "Epoch: [356 | 1000] LR: 0.015776\n",
      "Train | 16/16 | Loss:0.1296 | MainLoss:0.1168 | Alpha:0.4646 | SPLoss:0.1275 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1165 | MainLoss:0.1165 | SPLoss:0.1288 | CLSLoss:0.0000 | AUROC:0.9920\n",
      "Test | 122/16 | Loss:0.4013 | MainLoss:0.4013 | SPLoss:0.1288 | CLSLoss:0.0000 | AUROC:0.9219\n",
      "\n",
      "Epoch: [357 | 1000] LR: 0.015750\n",
      "Train | 16/16 | Loss:0.1189 | MainLoss:0.1059 | Alpha:0.4679 | SPLoss:0.1293 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1109 | MainLoss:0.1109 | SPLoss:0.1289 | CLSLoss:0.0000 | AUROC:0.9922\n",
      "Test | 122/16 | Loss:0.3939 | MainLoss:0.3939 | SPLoss:0.1289 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [358 | 1000] LR: 0.015724\n",
      "Train | 16/16 | Loss:0.1237 | MainLoss:0.1107 | Alpha:0.4670 | SPLoss:0.1295 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1104 | MainLoss:0.1104 | SPLoss:0.1295 | CLSLoss:0.0000 | AUROC:0.9924\n",
      "Test | 122/16 | Loss:0.4000 | MainLoss:0.4000 | SPLoss:0.1295 | CLSLoss:0.0000 | AUROC:0.9288\n",
      "\n",
      "Epoch: [359 | 1000] LR: 0.015699\n",
      "Train | 16/16 | Loss:0.1213 | MainLoss:0.1083 | Alpha:0.4670 | SPLoss:0.1299 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1094 | MainLoss:0.1094 | SPLoss:0.1309 | CLSLoss:0.0000 | AUROC:0.9922\n",
      "Test | 122/16 | Loss:0.4304 | MainLoss:0.4304 | SPLoss:0.1309 | CLSLoss:0.0000 | AUROC:0.9291\n",
      "\n",
      "Epoch: [360 | 1000] LR: 0.015673\n",
      "Train | 16/16 | Loss:0.1256 | MainLoss:0.1125 | Alpha:0.4666 | SPLoss:0.1304 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1082 | MainLoss:0.1082 | SPLoss:0.1310 | CLSLoss:0.0000 | AUROC:0.9922\n",
      "Test | 122/16 | Loss:0.3876 | MainLoss:0.3876 | SPLoss:0.1310 | CLSLoss:0.0000 | AUROC:0.9321\n",
      "\n",
      "Epoch: [361 | 1000] LR: 0.015647\n",
      "Train | 16/16 | Loss:0.1291 | MainLoss:0.1159 | Alpha:0.4661 | SPLoss:0.1315 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1105 | MainLoss:0.1105 | SPLoss:0.1320 | CLSLoss:0.0000 | AUROC:0.9926\n",
      "Test | 122/16 | Loss:0.3889 | MainLoss:0.3889 | SPLoss:0.1320 | CLSLoss:0.0000 | AUROC:0.9265\n",
      "\n",
      "Epoch: [362 | 1000] LR: 0.015621\n",
      "Train | 16/16 | Loss:0.1302 | MainLoss:0.1171 | Alpha:0.4654 | SPLoss:0.1318 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1110 | MainLoss:0.1110 | SPLoss:0.1318 | CLSLoss:0.0000 | AUROC:0.9925\n",
      "Test | 122/16 | Loss:0.3992 | MainLoss:0.3992 | SPLoss:0.1318 | CLSLoss:0.0000 | AUROC:0.9249\n",
      "\n",
      "Epoch: [363 | 1000] LR: 0.015595\n",
      "Train | 16/16 | Loss:0.1363 | MainLoss:0.1230 | Alpha:0.4650 | SPLoss:0.1323 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1115 | MainLoss:0.1115 | SPLoss:0.1324 | CLSLoss:0.0000 | AUROC:0.9926\n",
      "Test | 122/16 | Loss:0.3927 | MainLoss:0.3927 | SPLoss:0.1324 | CLSLoss:0.0000 | AUROC:0.9243\n",
      "\n",
      "Epoch: [364 | 1000] LR: 0.015569\n",
      "Train | 16/16 | Loss:0.1321 | MainLoss:0.1188 | Alpha:0.4648 | SPLoss:0.1327 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1103 | MainLoss:0.1103 | SPLoss:0.1331 | CLSLoss:0.0000 | AUROC:0.9927\n",
      "Test | 122/16 | Loss:0.3788 | MainLoss:0.3788 | SPLoss:0.1331 | CLSLoss:0.0000 | AUROC:0.9302\n",
      "\n",
      "Epoch: [365 | 1000] LR: 0.015543\n",
      "Train | 16/16 | Loss:0.1285 | MainLoss:0.1151 | Alpha:0.4649 | SPLoss:0.1341 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1099 | MainLoss:0.1099 | SPLoss:0.1347 | CLSLoss:0.0000 | AUROC:0.9926\n",
      "Test | 122/16 | Loss:0.4217 | MainLoss:0.4217 | SPLoss:0.1347 | CLSLoss:0.0000 | AUROC:0.9225\n",
      "\n",
      "Epoch: [366 | 1000] LR: 0.015516\n",
      "Train | 16/16 | Loss:0.1256 | MainLoss:0.1120 | Alpha:0.4667 | SPLoss:0.1355 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1141 | MainLoss:0.1141 | SPLoss:0.1355 | CLSLoss:0.0000 | AUROC:0.9925\n",
      "Test | 122/16 | Loss:0.4013 | MainLoss:0.4013 | SPLoss:0.1355 | CLSLoss:0.0000 | AUROC:0.9246\n",
      "\n",
      "Epoch: [367 | 1000] LR: 0.015490\n",
      "Train | 16/16 | Loss:0.1202 | MainLoss:0.1065 | Alpha:0.4684 | SPLoss:0.1361 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1120 | MainLoss:0.1120 | SPLoss:0.1358 | CLSLoss:0.0000 | AUROC:0.9925\n",
      "Test | 122/16 | Loss:0.4230 | MainLoss:0.4230 | SPLoss:0.1358 | CLSLoss:0.0000 | AUROC:0.9235\n",
      "\n",
      "Epoch: [368 | 1000] LR: 0.015464\n",
      "Train | 16/16 | Loss:0.1299 | MainLoss:0.1163 | Alpha:0.4650 | SPLoss:0.1360 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1077 | MainLoss:0.1077 | SPLoss:0.1362 | CLSLoss:0.0000 | AUROC:0.9925\n",
      "Test | 122/16 | Loss:0.4397 | MainLoss:0.4397 | SPLoss:0.1362 | CLSLoss:0.0000 | AUROC:0.9309\n",
      "\n",
      "Epoch: [369 | 1000] LR: 0.015438\n",
      "Train | 16/16 | Loss:0.1116 | MainLoss:0.0980 | Alpha:0.4701 | SPLoss:0.1366 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1147 | MainLoss:0.1147 | SPLoss:0.1371 | CLSLoss:0.0000 | AUROC:0.9924\n",
      "Test | 122/16 | Loss:0.3835 | MainLoss:0.3835 | SPLoss:0.1371 | CLSLoss:0.0000 | AUROC:0.9311\n",
      "\n",
      "Epoch: [370 | 1000] LR: 0.015411\n",
      "Train | 16/16 | Loss:0.1375 | MainLoss:0.1236 | Alpha:0.4630 | SPLoss:0.1385 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1096 | MainLoss:0.1096 | SPLoss:0.1393 | CLSLoss:0.0000 | AUROC:0.9923\n",
      "Test | 122/16 | Loss:0.3965 | MainLoss:0.3965 | SPLoss:0.1393 | CLSLoss:0.0000 | AUROC:0.9250\n",
      "\n",
      "Epoch: [371 | 1000] LR: 0.015385\n",
      "Train | 16/16 | Loss:0.1319 | MainLoss:0.1179 | Alpha:0.4646 | SPLoss:0.1398 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1128 | MainLoss:0.1128 | SPLoss:0.1399 | CLSLoss:0.0000 | AUROC:0.9926\n",
      "Test | 122/16 | Loss:0.3918 | MainLoss:0.3918 | SPLoss:0.1399 | CLSLoss:0.0000 | AUROC:0.9266\n",
      "\n",
      "Epoch: [372 | 1000] LR: 0.015358\n",
      "Train | 16/16 | Loss:0.1344 | MainLoss:0.1204 | Alpha:0.4642 | SPLoss:0.1402 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1097 | MainLoss:0.1097 | SPLoss:0.1397 | CLSLoss:0.0000 | AUROC:0.9926\n",
      "Test | 122/16 | Loss:0.3983 | MainLoss:0.3983 | SPLoss:0.1397 | CLSLoss:0.0000 | AUROC:0.9250\n",
      "\n",
      "Epoch: [373 | 1000] LR: 0.015332\n",
      "Train | 16/16 | Loss:0.1210 | MainLoss:0.1071 | Alpha:0.4668 | SPLoss:0.1391 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1175 | MainLoss:0.1175 | SPLoss:0.1390 | CLSLoss:0.0000 | AUROC:0.9923\n",
      "Test | 122/16 | Loss:0.3807 | MainLoss:0.3807 | SPLoss:0.1390 | CLSLoss:0.0000 | AUROC:0.9300\n",
      "\n",
      "Epoch: [374 | 1000] LR: 0.015305\n",
      "Train | 16/16 | Loss:0.1324 | MainLoss:0.1184 | Alpha:0.4658 | SPLoss:0.1399 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1125 | MainLoss:0.1125 | SPLoss:0.1393 | CLSLoss:0.0000 | AUROC:0.9926\n",
      "Test | 122/16 | Loss:0.3848 | MainLoss:0.3848 | SPLoss:0.1393 | CLSLoss:0.0000 | AUROC:0.9299\n",
      "\n",
      "Epoch: [375 | 1000] LR: 0.015278\n",
      "Train | 16/16 | Loss:0.1186 | MainLoss:0.1045 | Alpha:0.4683 | SPLoss:0.1402 | CLSLoss:0.0000 | AUROC:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 32/16 | Loss:0.1217 | MainLoss:0.1217 | SPLoss:0.1408 | CLSLoss:0.0000 | AUROC:0.9925\n",
      "Test | 122/16 | Loss:0.3857 | MainLoss:0.3857 | SPLoss:0.1408 | CLSLoss:0.0000 | AUROC:0.9300\n",
      "\n",
      "Epoch: [376 | 1000] LR: 0.015252\n",
      "Train | 16/16 | Loss:0.1216 | MainLoss:0.1075 | Alpha:0.4669 | SPLoss:0.1411 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1101 | MainLoss:0.1101 | SPLoss:0.1413 | CLSLoss:0.0000 | AUROC:0.9924\n",
      "Test | 122/16 | Loss:0.4087 | MainLoss:0.4087 | SPLoss:0.1413 | CLSLoss:0.0000 | AUROC:0.9301\n",
      "\n",
      "Epoch: [377 | 1000] LR: 0.015225\n",
      "Train | 16/16 | Loss:0.1135 | MainLoss:0.0993 | Alpha:0.4691 | SPLoss:0.1415 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1104 | MainLoss:0.1104 | SPLoss:0.1415 | CLSLoss:0.0000 | AUROC:0.9924\n",
      "Test | 122/16 | Loss:0.4062 | MainLoss:0.4062 | SPLoss:0.1415 | CLSLoss:0.0000 | AUROC:0.9303\n",
      "\n",
      "Epoch: [378 | 1000] LR: 0.015198\n",
      "Train | 16/16 | Loss:0.1189 | MainLoss:0.1047 | Alpha:0.4680 | SPLoss:0.1419 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1154 | MainLoss:0.1154 | SPLoss:0.1419 | CLSLoss:0.0000 | AUROC:0.9924\n",
      "Test | 122/16 | Loss:0.3923 | MainLoss:0.3923 | SPLoss:0.1419 | CLSLoss:0.0000 | AUROC:0.9288\n",
      "\n",
      "Epoch: [379 | 1000] LR: 0.015171\n",
      "Train | 16/16 | Loss:0.1278 | MainLoss:0.1135 | Alpha:0.4658 | SPLoss:0.1425 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1134 | MainLoss:0.1134 | SPLoss:0.1424 | CLSLoss:0.0000 | AUROC:0.9922\n",
      "Test | 122/16 | Loss:0.3974 | MainLoss:0.3974 | SPLoss:0.1424 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [380 | 1000] LR: 0.015144\n",
      "Train | 16/16 | Loss:0.1258 | MainLoss:0.1116 | Alpha:0.4680 | SPLoss:0.1418 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1100 | MainLoss:0.1100 | SPLoss:0.1415 | CLSLoss:0.0000 | AUROC:0.9923\n",
      "Test | 122/16 | Loss:0.4259 | MainLoss:0.4259 | SPLoss:0.1415 | CLSLoss:0.0000 | AUROC:0.9257\n",
      "\n",
      "Epoch: [381 | 1000] LR: 0.015117\n",
      "Train | 16/16 | Loss:0.1133 | MainLoss:0.0991 | Alpha:0.4692 | SPLoss:0.1419 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1158 | MainLoss:0.1158 | SPLoss:0.1425 | CLSLoss:0.0000 | AUROC:0.9923\n",
      "Test | 122/16 | Loss:0.4184 | MainLoss:0.4184 | SPLoss:0.1425 | CLSLoss:0.0000 | AUROC:0.9240\n",
      "\n",
      "Epoch: [382 | 1000] LR: 0.015090\n",
      "Train | 16/16 | Loss:0.1087 | MainLoss:0.0943 | Alpha:0.4689 | SPLoss:0.1437 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1191 | MainLoss:0.1191 | SPLoss:0.1442 | CLSLoss:0.0000 | AUROC:0.9922\n",
      "Test | 122/16 | Loss:0.4071 | MainLoss:0.4071 | SPLoss:0.1442 | CLSLoss:0.0000 | AUROC:0.9278\n",
      "\n",
      "Epoch: [383 | 1000] LR: 0.015063\n",
      "Train | 16/16 | Loss:0.1245 | MainLoss:0.1101 | Alpha:0.4680 | SPLoss:0.1437 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1116 | MainLoss:0.1116 | SPLoss:0.1434 | CLSLoss:0.0000 | AUROC:0.9922\n",
      "Test | 122/16 | Loss:0.4206 | MainLoss:0.4206 | SPLoss:0.1434 | CLSLoss:0.0000 | AUROC:0.9285\n",
      "\n",
      "Epoch: [384 | 1000] LR: 0.015036\n",
      "Train | 16/16 | Loss:0.1290 | MainLoss:0.1146 | Alpha:0.4658 | SPLoss:0.1436 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1121 | MainLoss:0.1121 | SPLoss:0.1436 | CLSLoss:0.0000 | AUROC:0.9925\n",
      "Test | 122/16 | Loss:0.3947 | MainLoss:0.3947 | SPLoss:0.1436 | CLSLoss:0.0000 | AUROC:0.9262\n",
      "\n",
      "Epoch: [385 | 1000] LR: 0.015009\n",
      "Train | 16/16 | Loss:0.1250 | MainLoss:0.1106 | Alpha:0.4653 | SPLoss:0.1446 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1096 | MainLoss:0.1096 | SPLoss:0.1455 | CLSLoss:0.0000 | AUROC:0.9925\n",
      "Test | 122/16 | Loss:0.4016 | MainLoss:0.4016 | SPLoss:0.1455 | CLSLoss:0.0000 | AUROC:0.9300\n",
      "\n",
      "Epoch: [386 | 1000] LR: 0.014982\n",
      "Train | 16/16 | Loss:0.1198 | MainLoss:0.1053 | Alpha:0.4682 | SPLoss:0.1454 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1107 | MainLoss:0.1107 | SPLoss:0.1452 | CLSLoss:0.0000 | AUROC:0.9924\n",
      "Test | 122/16 | Loss:0.4147 | MainLoss:0.4147 | SPLoss:0.1452 | CLSLoss:0.0000 | AUROC:0.9278\n",
      "\n",
      "Epoch: [387 | 1000] LR: 0.014955\n",
      "Train | 16/16 | Loss:0.1296 | MainLoss:0.1152 | Alpha:0.4661 | SPLoss:0.1444 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1106 | MainLoss:0.1106 | SPLoss:0.1447 | CLSLoss:0.0000 | AUROC:0.9923\n",
      "Test | 122/16 | Loss:0.4187 | MainLoss:0.4187 | SPLoss:0.1447 | CLSLoss:0.0000 | AUROC:0.9228\n",
      "\n",
      "Epoch: [388 | 1000] LR: 0.014927\n",
      "Train | 16/16 | Loss:0.1144 | MainLoss:0.0999 | Alpha:0.4695 | SPLoss:0.1444 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1169 | MainLoss:0.1169 | SPLoss:0.1441 | CLSLoss:0.0000 | AUROC:0.9927\n",
      "Test | 122/16 | Loss:0.4244 | MainLoss:0.4244 | SPLoss:0.1441 | CLSLoss:0.0000 | AUROC:0.9196\n",
      "\n",
      "Epoch: [389 | 1000] LR: 0.014900\n",
      "Train | 16/16 | Loss:0.1361 | MainLoss:0.1216 | Alpha:0.4633 | SPLoss:0.1450 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1104 | MainLoss:0.1104 | SPLoss:0.1452 | CLSLoss:0.0000 | AUROC:0.9926\n",
      "Test | 122/16 | Loss:0.4047 | MainLoss:0.4047 | SPLoss:0.1452 | CLSLoss:0.0000 | AUROC:0.9243\n",
      "\n",
      "Epoch: [390 | 1000] LR: 0.014873\n",
      "Train | 16/16 | Loss:0.1278 | MainLoss:0.1132 | Alpha:0.4660 | SPLoss:0.1454 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1182 | MainLoss:0.1182 | SPLoss:0.1455 | CLSLoss:0.0000 | AUROC:0.9925\n",
      "Test | 122/16 | Loss:0.3997 | MainLoss:0.3997 | SPLoss:0.1455 | CLSLoss:0.0000 | AUROC:0.9248\n",
      "\n",
      "Epoch: [391 | 1000] LR: 0.014845\n",
      "Train | 16/16 | Loss:0.1351 | MainLoss:0.1204 | Alpha:0.4633 | SPLoss:0.1465 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1075 | MainLoss:0.1075 | SPLoss:0.1476 | CLSLoss:0.0000 | AUROC:0.9923\n",
      "Test | 122/16 | Loss:0.4244 | MainLoss:0.4244 | SPLoss:0.1476 | CLSLoss:0.0000 | AUROC:0.9256\n",
      "\n",
      "Epoch: [392 | 1000] LR: 0.014818\n",
      "Train | 16/16 | Loss:0.1188 | MainLoss:0.1040 | Alpha:0.4677 | SPLoss:0.1474 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1137 | MainLoss:0.1137 | SPLoss:0.1472 | CLSLoss:0.0000 | AUROC:0.9924\n",
      "Test | 122/16 | Loss:0.4257 | MainLoss:0.4257 | SPLoss:0.1472 | CLSLoss:0.0000 | AUROC:0.9218\n",
      "\n",
      "Epoch: [393 | 1000] LR: 0.014790\n",
      "Train | 16/16 | Loss:0.1185 | MainLoss:0.1038 | Alpha:0.4682 | SPLoss:0.1472 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1225 | MainLoss:0.1225 | SPLoss:0.1473 | CLSLoss:0.0000 | AUROC:0.9923\n",
      "Test | 122/16 | Loss:0.4043 | MainLoss:0.4043 | SPLoss:0.1473 | CLSLoss:0.0000 | AUROC:0.9250\n",
      "\n",
      "Epoch: [394 | 1000] LR: 0.014762\n",
      "Train | 16/16 | Loss:0.1160 | MainLoss:0.1012 | Alpha:0.4690 | SPLoss:0.1478 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1163 | MainLoss:0.1163 | SPLoss:0.1480 | CLSLoss:0.0000 | AUROC:0.9923\n",
      "Test | 122/16 | Loss:0.4195 | MainLoss:0.4195 | SPLoss:0.1480 | CLSLoss:0.0000 | AUROC:0.9234\n",
      "\n",
      "Epoch: [395 | 1000] LR: 0.014735\n",
      "Train | 16/16 | Loss:0.1201 | MainLoss:0.1053 | Alpha:0.4675 | SPLoss:0.1478 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1098 | MainLoss:0.1098 | SPLoss:0.1477 | CLSLoss:0.0000 | AUROC:0.9923\n",
      "Test | 122/16 | Loss:0.4303 | MainLoss:0.4303 | SPLoss:0.1477 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [396 | 1000] LR: 0.014707\n",
      "Train | 16/16 | Loss:0.1274 | MainLoss:0.1126 | Alpha:0.4663 | SPLoss:0.1474 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1143 | MainLoss:0.1143 | SPLoss:0.1477 | CLSLoss:0.0000 | AUROC:0.9923\n",
      "Test | 122/16 | Loss:0.4083 | MainLoss:0.4083 | SPLoss:0.1477 | CLSLoss:0.0000 | AUROC:0.9257\n",
      "\n",
      "Epoch: [397 | 1000] LR: 0.014679\n",
      "Train | 16/16 | Loss:0.1209 | MainLoss:0.1061 | Alpha:0.4669 | SPLoss:0.1481 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1119 | MainLoss:0.1119 | SPLoss:0.1483 | CLSLoss:0.0000 | AUROC:0.9921\n",
      "Test | 122/16 | Loss:0.4114 | MainLoss:0.4114 | SPLoss:0.1483 | CLSLoss:0.0000 | AUROC:0.9290\n",
      "\n",
      "Epoch: [398 | 1000] LR: 0.014652\n",
      "Train | 16/16 | Loss:0.1337 | MainLoss:0.1189 | Alpha:0.4650 | SPLoss:0.1486 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1114 | MainLoss:0.1114 | SPLoss:0.1482 | CLSLoss:0.0000 | AUROC:0.9924\n",
      "Test | 122/16 | Loss:0.4035 | MainLoss:0.4035 | SPLoss:0.1482 | CLSLoss:0.0000 | AUROC:0.9254\n",
      "\n",
      "Epoch: [399 | 1000] LR: 0.014624\n",
      "Train | 16/16 | Loss:0.1312 | MainLoss:0.1164 | Alpha:0.4655 | SPLoss:0.1486 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1123 | MainLoss:0.1123 | SPLoss:0.1494 | CLSLoss:0.0000 | AUROC:0.9922\n",
      "Test | 122/16 | Loss:0.4019 | MainLoss:0.4019 | SPLoss:0.1494 | CLSLoss:0.0000 | AUROC:0.9279\n",
      "\n",
      "Epoch: [400 | 1000] LR: 0.014596\n",
      "Train | 16/16 | Loss:0.1303 | MainLoss:0.1154 | Alpha:0.4652 | SPLoss:0.1495 | CLSLoss:0.0000 | AUROC:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 32/16 | Loss:0.1194 | MainLoss:0.1194 | SPLoss:0.1501 | CLSLoss:0.0000 | AUROC:0.9923\n",
      "Test | 122/16 | Loss:0.3785 | MainLoss:0.3785 | SPLoss:0.1501 | CLSLoss:0.0000 | AUROC:0.9299\n",
      "\n",
      "Epoch: [401 | 1000] LR: 0.001457\n",
      "Train | 16/16 | Loss:0.1128 | MainLoss:0.1128 | Alpha:0.4718 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1136 | MainLoss:0.1136 | SPLoss:0.0001 | CLSLoss:0.0000 | AUROC:0.9924\n",
      "Test | 122/16 | Loss:0.3894 | MainLoss:0.3894 | SPLoss:0.0001 | CLSLoss:0.0000 | AUROC:0.9308\n",
      "\n",
      "Epoch: [402 | 1000] LR: 0.001454\n",
      "Train | 16/16 | Loss:0.1172 | MainLoss:0.1172 | Alpha:0.4709 | SPLoss:0.0001 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1123 | MainLoss:0.1123 | SPLoss:0.0002 | CLSLoss:0.0000 | AUROC:0.9922\n",
      "Test | 122/16 | Loss:0.3932 | MainLoss:0.3932 | SPLoss:0.0002 | CLSLoss:0.0000 | AUROC:0.9306\n",
      "\n",
      "Epoch: [403 | 1000] LR: 0.001451\n",
      "Train | 16/16 | Loss:0.0898 | MainLoss:0.0898 | Alpha:0.4777 | SPLoss:0.0002 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1126 | MainLoss:0.1126 | SPLoss:0.0002 | CLSLoss:0.0000 | AUROC:0.9923\n",
      "Test | 122/16 | Loss:0.3978 | MainLoss:0.3978 | SPLoss:0.0002 | CLSLoss:0.0000 | AUROC:0.9300\n",
      "\n",
      "Epoch: [404 | 1000] LR: 0.001448\n",
      "Train | 16/16 | Loss:0.1040 | MainLoss:0.1040 | Alpha:0.4740 | SPLoss:0.0002 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1131 | MainLoss:0.1131 | SPLoss:0.0002 | CLSLoss:0.0000 | AUROC:0.9924\n",
      "Test | 122/16 | Loss:0.3988 | MainLoss:0.3988 | SPLoss:0.0002 | CLSLoss:0.0000 | AUROC:0.9303\n",
      "\n",
      "Epoch: [405 | 1000] LR: 0.001446\n",
      "Train | 16/16 | Loss:0.1105 | MainLoss:0.1105 | Alpha:0.4727 | SPLoss:0.0003 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1125 | MainLoss:0.1125 | SPLoss:0.0003 | CLSLoss:0.0000 | AUROC:0.9922\n",
      "Test | 122/16 | Loss:0.4003 | MainLoss:0.4003 | SPLoss:0.0003 | CLSLoss:0.0000 | AUROC:0.9306\n",
      "\n",
      "Epoch: [406 | 1000] LR: 0.001443\n",
      "Train | 16/16 | Loss:0.1030 | MainLoss:0.1030 | Alpha:0.4749 | SPLoss:0.0003 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1124 | MainLoss:0.1124 | SPLoss:0.0004 | CLSLoss:0.0000 | AUROC:0.9923\n",
      "Test | 122/16 | Loss:0.4008 | MainLoss:0.4008 | SPLoss:0.0004 | CLSLoss:0.0000 | AUROC:0.9308\n",
      "\n",
      "Epoch: [407 | 1000] LR: 0.001440\n",
      "Train | 16/16 | Loss:0.1048 | MainLoss:0.1048 | Alpha:0.4737 | SPLoss:0.0004 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1123 | MainLoss:0.1123 | SPLoss:0.0004 | CLSLoss:0.0000 | AUROC:0.9923\n",
      "Test | 122/16 | Loss:0.4026 | MainLoss:0.4026 | SPLoss:0.0004 | CLSLoss:0.0000 | AUROC:0.9304\n",
      "\n",
      "Epoch: [408 | 1000] LR: 0.001437\n",
      "Train | 16/16 | Loss:0.1025 | MainLoss:0.1025 | Alpha:0.4740 | SPLoss:0.0005 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1126 | MainLoss:0.1126 | SPLoss:0.0005 | CLSLoss:0.0000 | AUROC:0.9924\n",
      "Test | 122/16 | Loss:0.4023 | MainLoss:0.4023 | SPLoss:0.0005 | CLSLoss:0.0000 | AUROC:0.9311\n",
      "\n",
      "Epoch: [409 | 1000] LR: 0.001434\n",
      "Train | 16/16 | Loss:0.1072 | MainLoss:0.1071 | Alpha:0.4736 | SPLoss:0.0005 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1124 | MainLoss:0.1124 | SPLoss:0.0005 | CLSLoss:0.0000 | AUROC:0.9924\n",
      "Test | 122/16 | Loss:0.4031 | MainLoss:0.4031 | SPLoss:0.0005 | CLSLoss:0.0000 | AUROC:0.9303\n",
      "\n",
      "Epoch: [410 | 1000] LR: 0.001431\n",
      "Train | 16/16 | Loss:0.1187 | MainLoss:0.1186 | Alpha:0.4702 | SPLoss:0.0005 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1128 | MainLoss:0.1128 | SPLoss:0.0005 | CLSLoss:0.0000 | AUROC:0.9924\n",
      "Test | 122/16 | Loss:0.4025 | MainLoss:0.4025 | SPLoss:0.0005 | CLSLoss:0.0000 | AUROC:0.9300\n",
      "\n",
      "Epoch: [411 | 1000] LR: 0.001429\n",
      "Train | 16/16 | Loss:0.1042 | MainLoss:0.1042 | Alpha:0.4741 | SPLoss:0.0006 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1119 | MainLoss:0.1119 | SPLoss:0.0007 | CLSLoss:0.0000 | AUROC:0.9924\n",
      "Test | 122/16 | Loss:0.4086 | MainLoss:0.4086 | SPLoss:0.0007 | CLSLoss:0.0000 | AUROC:0.9292\n",
      "\n",
      "Epoch: [412 | 1000] LR: 0.001426\n",
      "Train | 16/16 | Loss:0.1138 | MainLoss:0.1138 | Alpha:0.4711 | SPLoss:0.0007 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1122 | MainLoss:0.1122 | SPLoss:0.0007 | CLSLoss:0.0000 | AUROC:0.9924\n",
      "Test | 122/16 | Loss:0.4033 | MainLoss:0.4033 | SPLoss:0.0007 | CLSLoss:0.0000 | AUROC:0.9293\n",
      "\n",
      "Epoch: [413 | 1000] LR: 0.001423\n",
      "Train | 16/16 | Loss:0.1049 | MainLoss:0.1049 | Alpha:0.4736 | SPLoss:0.0007 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1115 | MainLoss:0.1115 | SPLoss:0.0008 | CLSLoss:0.0000 | AUROC:0.9925\n",
      "Test | 122/16 | Loss:0.4049 | MainLoss:0.4049 | SPLoss:0.0008 | CLSLoss:0.0000 | AUROC:0.9289\n",
      "\n",
      "Epoch: [414 | 1000] LR: 0.001420\n",
      "Train | 16/16 | Loss:0.1142 | MainLoss:0.1141 | Alpha:0.4715 | SPLoss:0.0008 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1108 | MainLoss:0.1108 | SPLoss:0.0008 | CLSLoss:0.0000 | AUROC:0.9925\n",
      "Test | 122/16 | Loss:0.4065 | MainLoss:0.4065 | SPLoss:0.0008 | CLSLoss:0.0000 | AUROC:0.9290\n",
      "\n",
      "Epoch: [415 | 1000] LR: 0.001417\n",
      "Train | 16/16 | Loss:0.1072 | MainLoss:0.1071 | Alpha:0.4728 | SPLoss:0.0009 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1108 | MainLoss:0.1108 | SPLoss:0.0009 | CLSLoss:0.0000 | AUROC:0.9925\n",
      "Test | 122/16 | Loss:0.4039 | MainLoss:0.4039 | SPLoss:0.0009 | CLSLoss:0.0000 | AUROC:0.9292\n",
      "\n",
      "Epoch: [416 | 1000] LR: 0.001414\n",
      "Train | 16/16 | Loss:0.1097 | MainLoss:0.1097 | Alpha:0.4723 | SPLoss:0.0009 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1106 | MainLoss:0.1106 | SPLoss:0.0010 | CLSLoss:0.0000 | AUROC:0.9925\n",
      "Test | 122/16 | Loss:0.4072 | MainLoss:0.4072 | SPLoss:0.0010 | CLSLoss:0.0000 | AUROC:0.9294\n",
      "\n",
      "Epoch: [417 | 1000] LR: 0.001412\n",
      "Train | 16/16 | Loss:0.1102 | MainLoss:0.1101 | Alpha:0.4730 | SPLoss:0.0010 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1118 | MainLoss:0.1118 | SPLoss:0.0010 | CLSLoss:0.0000 | AUROC:0.9924\n",
      "Test | 122/16 | Loss:0.4002 | MainLoss:0.4002 | SPLoss:0.0010 | CLSLoss:0.0000 | AUROC:0.9289\n",
      "\n",
      "Epoch: [418 | 1000] LR: 0.001409\n",
      "Train | 16/16 | Loss:0.0965 | MainLoss:0.0964 | Alpha:0.4753 | SPLoss:0.0010 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1119 | MainLoss:0.1119 | SPLoss:0.0011 | CLSLoss:0.0000 | AUROC:0.9925\n",
      "Test | 122/16 | Loss:0.4013 | MainLoss:0.4013 | SPLoss:0.0011 | CLSLoss:0.0000 | AUROC:0.9288\n",
      "\n",
      "Epoch: [419 | 1000] LR: 0.001406\n",
      "Train | 16/16 | Loss:0.1081 | MainLoss:0.1080 | Alpha:0.4725 | SPLoss:0.0011 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1124 | MainLoss:0.1124 | SPLoss:0.0011 | CLSLoss:0.0000 | AUROC:0.9924\n",
      "Test | 122/16 | Loss:0.3997 | MainLoss:0.3997 | SPLoss:0.0011 | CLSLoss:0.0000 | AUROC:0.9289\n",
      "\n",
      "Epoch: [420 | 1000] LR: 0.001403\n",
      "Train | 16/16 | Loss:0.1053 | MainLoss:0.1051 | Alpha:0.4735 | SPLoss:0.0011 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1120 | MainLoss:0.1120 | SPLoss:0.0012 | CLSLoss:0.0000 | AUROC:0.9925\n",
      "Test | 122/16 | Loss:0.4019 | MainLoss:0.4019 | SPLoss:0.0012 | CLSLoss:0.0000 | AUROC:0.9291\n",
      "\n",
      "Epoch: [421 | 1000] LR: 0.001400\n",
      "Train | 16/16 | Loss:0.0930 | MainLoss:0.0928 | Alpha:0.4757 | SPLoss:0.0012 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1122 | MainLoss:0.1122 | SPLoss:0.0013 | CLSLoss:0.0000 | AUROC:0.9925\n",
      "Test | 122/16 | Loss:0.4087 | MainLoss:0.4087 | SPLoss:0.0013 | CLSLoss:0.0000 | AUROC:0.9284\n",
      "\n",
      "Epoch: [422 | 1000] LR: 0.001397\n",
      "Train | 16/16 | Loss:0.0985 | MainLoss:0.0984 | Alpha:0.4751 | SPLoss:0.0013 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1119 | MainLoss:0.1119 | SPLoss:0.0014 | CLSLoss:0.0000 | AUROC:0.9927\n",
      "Test | 122/16 | Loss:0.4110 | MainLoss:0.4110 | SPLoss:0.0014 | CLSLoss:0.0000 | AUROC:0.9283\n",
      "\n",
      "Epoch: [423 | 1000] LR: 0.001394\n",
      "Train | 16/16 | Loss:0.0925 | MainLoss:0.0924 | Alpha:0.4763 | SPLoss:0.0014 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1115 | MainLoss:0.1115 | SPLoss:0.0014 | CLSLoss:0.0000 | AUROC:0.9926\n",
      "Test | 122/16 | Loss:0.4136 | MainLoss:0.4136 | SPLoss:0.0014 | CLSLoss:0.0000 | AUROC:0.9285\n",
      "\n",
      "Epoch: [424 | 1000] LR: 0.001391\n",
      "Train | 16/16 | Loss:0.0955 | MainLoss:0.0953 | Alpha:0.4760 | SPLoss:0.0015 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1111 | MainLoss:0.1111 | SPLoss:0.0015 | CLSLoss:0.0000 | AUROC:0.9924\n",
      "Test | 122/16 | Loss:0.4168 | MainLoss:0.4168 | SPLoss:0.0015 | CLSLoss:0.0000 | AUROC:0.9292\n",
      "\n",
      "Epoch: [425 | 1000] LR: 0.001388\n",
      "Train | 16/16 | Loss:0.1048 | MainLoss:0.1047 | Alpha:0.4737 | SPLoss:0.0015 | CLSLoss:0.0000 | AUROC:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 32/16 | Loss:0.1116 | MainLoss:0.1116 | SPLoss:0.0015 | CLSLoss:0.0000 | AUROC:0.9925\n",
      "Test | 122/16 | Loss:0.4127 | MainLoss:0.4127 | SPLoss:0.0015 | CLSLoss:0.0000 | AUROC:0.9284\n",
      "\n",
      "Epoch: [426 | 1000] LR: 0.001386\n",
      "Train | 16/16 | Loss:0.0998 | MainLoss:0.0996 | Alpha:0.4746 | SPLoss:0.0016 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1113 | MainLoss:0.1113 | SPLoss:0.0016 | CLSLoss:0.0000 | AUROC:0.9925\n",
      "Test | 122/16 | Loss:0.4152 | MainLoss:0.4152 | SPLoss:0.0016 | CLSLoss:0.0000 | AUROC:0.9281\n",
      "\n",
      "Epoch: [427 | 1000] LR: 0.001383\n",
      "Train | 16/16 | Loss:0.1047 | MainLoss:0.1046 | Alpha:0.4729 | SPLoss:0.0017 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1108 | MainLoss:0.1108 | SPLoss:0.0017 | CLSLoss:0.0000 | AUROC:0.9927\n",
      "Test | 122/16 | Loss:0.4141 | MainLoss:0.4141 | SPLoss:0.0017 | CLSLoss:0.0000 | AUROC:0.9281\n",
      "\n",
      "Epoch: [428 | 1000] LR: 0.001380\n",
      "Train | 16/16 | Loss:0.1161 | MainLoss:0.1160 | Alpha:0.4708 | SPLoss:0.0017 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1109 | MainLoss:0.1109 | SPLoss:0.0017 | CLSLoss:0.0000 | AUROC:0.9927\n",
      "Test | 122/16 | Loss:0.4069 | MainLoss:0.4069 | SPLoss:0.0017 | CLSLoss:0.0000 | AUROC:0.9281\n",
      "\n",
      "Epoch: [429 | 1000] LR: 0.001377\n",
      "Train | 16/16 | Loss:0.1064 | MainLoss:0.1062 | Alpha:0.4727 | SPLoss:0.0018 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1113 | MainLoss:0.1113 | SPLoss:0.0018 | CLSLoss:0.0000 | AUROC:0.9926\n",
      "Test | 122/16 | Loss:0.4083 | MainLoss:0.4083 | SPLoss:0.0018 | CLSLoss:0.0000 | AUROC:0.9280\n",
      "\n",
      "Epoch: [430 | 1000] LR: 0.001374\n",
      "Train | 16/16 | Loss:0.0999 | MainLoss:0.0997 | Alpha:0.4754 | SPLoss:0.0018 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1112 | MainLoss:0.1112 | SPLoss:0.0019 | CLSLoss:0.0000 | AUROC:0.9926\n",
      "Test | 122/16 | Loss:0.4104 | MainLoss:0.4104 | SPLoss:0.0019 | CLSLoss:0.0000 | AUROC:0.9282\n",
      "\n",
      "Epoch: [431 | 1000] LR: 0.001371\n",
      "Train | 16/16 | Loss:0.1003 | MainLoss:0.1001 | Alpha:0.4740 | SPLoss:0.0019 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1106 | MainLoss:0.1106 | SPLoss:0.0020 | CLSLoss:0.0000 | AUROC:0.9927\n",
      "Test | 122/16 | Loss:0.4153 | MainLoss:0.4153 | SPLoss:0.0020 | CLSLoss:0.0000 | AUROC:0.9281\n",
      "\n",
      "Epoch: [432 | 1000] LR: 0.001368\n",
      "Train | 16/16 | Loss:0.1052 | MainLoss:0.1050 | Alpha:0.4729 | SPLoss:0.0021 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1103 | MainLoss:0.1103 | SPLoss:0.0021 | CLSLoss:0.0000 | AUROC:0.9927\n",
      "Test | 122/16 | Loss:0.4172 | MainLoss:0.4172 | SPLoss:0.0021 | CLSLoss:0.0000 | AUROC:0.9288\n",
      "\n",
      "Epoch: [433 | 1000] LR: 0.001365\n",
      "Train | 16/16 | Loss:0.0970 | MainLoss:0.0968 | Alpha:0.4748 | SPLoss:0.0021 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1103 | MainLoss:0.1103 | SPLoss:0.0022 | CLSLoss:0.0000 | AUROC:0.9926\n",
      "Test | 122/16 | Loss:0.4200 | MainLoss:0.4200 | SPLoss:0.0022 | CLSLoss:0.0000 | AUROC:0.9285\n",
      "\n",
      "Epoch: [434 | 1000] LR: 0.001362\n",
      "Train | 16/16 | Loss:0.1087 | MainLoss:0.1085 | Alpha:0.4721 | SPLoss:0.0023 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1101 | MainLoss:0.1101 | SPLoss:0.0023 | CLSLoss:0.0000 | AUROC:0.9925\n",
      "Test | 122/16 | Loss:0.4203 | MainLoss:0.4203 | SPLoss:0.0023 | CLSLoss:0.0000 | AUROC:0.9288\n",
      "\n",
      "Epoch: [435 | 1000] LR: 0.001359\n",
      "Train | 16/16 | Loss:0.0966 | MainLoss:0.0963 | Alpha:0.4753 | SPLoss:0.0023 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1106 | MainLoss:0.1106 | SPLoss:0.0023 | CLSLoss:0.0000 | AUROC:0.9927\n",
      "Test | 122/16 | Loss:0.4183 | MainLoss:0.4183 | SPLoss:0.0023 | CLSLoss:0.0000 | AUROC:0.9279\n",
      "\n",
      "Epoch: [436 | 1000] LR: 0.001356\n",
      "Train | 16/16 | Loss:0.0997 | MainLoss:0.0995 | Alpha:0.4742 | SPLoss:0.0024 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1104 | MainLoss:0.1104 | SPLoss:0.0024 | CLSLoss:0.0000 | AUROC:0.9926\n",
      "Test | 122/16 | Loss:0.4205 | MainLoss:0.4205 | SPLoss:0.0024 | CLSLoss:0.0000 | AUROC:0.9281\n",
      "\n",
      "Epoch: [437 | 1000] LR: 0.001353\n",
      "Train | 16/16 | Loss:0.1068 | MainLoss:0.1065 | Alpha:0.4729 | SPLoss:0.0025 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1105 | MainLoss:0.1105 | SPLoss:0.0025 | CLSLoss:0.0000 | AUROC:0.9926\n",
      "Test | 122/16 | Loss:0.4198 | MainLoss:0.4198 | SPLoss:0.0025 | CLSLoss:0.0000 | AUROC:0.9281\n",
      "\n",
      "Epoch: [438 | 1000] LR: 0.001351\n",
      "Train | 16/16 | Loss:0.0979 | MainLoss:0.0976 | Alpha:0.4750 | SPLoss:0.0025 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1106 | MainLoss:0.1106 | SPLoss:0.0025 | CLSLoss:0.0000 | AUROC:0.9924\n",
      "Test | 122/16 | Loss:0.4237 | MainLoss:0.4237 | SPLoss:0.0025 | CLSLoss:0.0000 | AUROC:0.9276\n",
      "\n",
      "Epoch: [439 | 1000] LR: 0.001348\n",
      "Train | 16/16 | Loss:0.1087 | MainLoss:0.1085 | Alpha:0.4722 | SPLoss:0.0026 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1098 | MainLoss:0.1098 | SPLoss:0.0027 | CLSLoss:0.0000 | AUROC:0.9925\n",
      "Test | 122/16 | Loss:0.4301 | MainLoss:0.4301 | SPLoss:0.0027 | CLSLoss:0.0000 | AUROC:0.9278\n",
      "\n",
      "Epoch: [440 | 1000] LR: 0.001345\n",
      "Train | 16/16 | Loss:0.1113 | MainLoss:0.1110 | Alpha:0.4713 | SPLoss:0.0027 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1098 | MainLoss:0.1098 | SPLoss:0.0027 | CLSLoss:0.0000 | AUROC:0.9927\n",
      "Test | 122/16 | Loss:0.4292 | MainLoss:0.4292 | SPLoss:0.0027 | CLSLoss:0.0000 | AUROC:0.9272\n",
      "\n",
      "Epoch: [441 | 1000] LR: 0.001342\n",
      "Train | 16/16 | Loss:0.1073 | MainLoss:0.1071 | Alpha:0.4732 | SPLoss:0.0027 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1101 | MainLoss:0.1101 | SPLoss:0.0028 | CLSLoss:0.0000 | AUROC:0.9928\n",
      "Test | 122/16 | Loss:0.4195 | MainLoss:0.4195 | SPLoss:0.0028 | CLSLoss:0.0000 | AUROC:0.9277\n",
      "\n",
      "Epoch: [442 | 1000] LR: 0.001339\n",
      "Train | 16/16 | Loss:0.1080 | MainLoss:0.1078 | Alpha:0.4718 | SPLoss:0.0028 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1101 | MainLoss:0.1101 | SPLoss:0.0029 | CLSLoss:0.0000 | AUROC:0.9926\n",
      "Test | 122/16 | Loss:0.4166 | MainLoss:0.4166 | SPLoss:0.0029 | CLSLoss:0.0000 | AUROC:0.9281\n",
      "\n",
      "Epoch: [443 | 1000] LR: 0.001336\n",
      "Train | 16/16 | Loss:0.1051 | MainLoss:0.1048 | Alpha:0.4734 | SPLoss:0.0029 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1113 | MainLoss:0.1113 | SPLoss:0.0029 | CLSLoss:0.0000 | AUROC:0.9926\n",
      "Test | 122/16 | Loss:0.4097 | MainLoss:0.4097 | SPLoss:0.0029 | CLSLoss:0.0000 | AUROC:0.9276\n",
      "\n",
      "Epoch: [444 | 1000] LR: 0.001333\n",
      "Train | 16/16 | Loss:0.1008 | MainLoss:0.1005 | Alpha:0.4736 | SPLoss:0.0029 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1108 | MainLoss:0.1108 | SPLoss:0.0030 | CLSLoss:0.0000 | AUROC:0.9926\n",
      "Test | 122/16 | Loss:0.4129 | MainLoss:0.4129 | SPLoss:0.0030 | CLSLoss:0.0000 | AUROC:0.9283\n",
      "\n",
      "Epoch: [445 | 1000] LR: 0.001330\n",
      "Train | 16/16 | Loss:0.1023 | MainLoss:0.1020 | Alpha:0.4736 | SPLoss:0.0031 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1107 | MainLoss:0.1107 | SPLoss:0.0031 | CLSLoss:0.0000 | AUROC:0.9928\n",
      "Test | 122/16 | Loss:0.4188 | MainLoss:0.4188 | SPLoss:0.0031 | CLSLoss:0.0000 | AUROC:0.9281\n",
      "\n",
      "Epoch: [446 | 1000] LR: 0.001327\n",
      "Train | 16/16 | Loss:0.1010 | MainLoss:0.1007 | Alpha:0.4746 | SPLoss:0.0031 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1106 | MainLoss:0.1106 | SPLoss:0.0032 | CLSLoss:0.0000 | AUROC:0.9928\n",
      "Test | 122/16 | Loss:0.4131 | MainLoss:0.4131 | SPLoss:0.0032 | CLSLoss:0.0000 | AUROC:0.9288\n",
      "\n",
      "Epoch: [447 | 1000] LR: 0.001324\n",
      "Train | 16/16 | Loss:0.0940 | MainLoss:0.0937 | Alpha:0.4760 | SPLoss:0.0032 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1106 | MainLoss:0.1106 | SPLoss:0.0033 | CLSLoss:0.0000 | AUROC:0.9927\n",
      "Test | 122/16 | Loss:0.4133 | MainLoss:0.4133 | SPLoss:0.0033 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [448 | 1000] LR: 0.001321\n",
      "Train | 16/16 | Loss:0.1089 | MainLoss:0.1086 | Alpha:0.4723 | SPLoss:0.0033 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1101 | MainLoss:0.1101 | SPLoss:0.0034 | CLSLoss:0.0000 | AUROC:0.9928\n",
      "Test | 122/16 | Loss:0.4152 | MainLoss:0.4152 | SPLoss:0.0034 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [449 | 1000] LR: 0.001318\n",
      "Train | 16/16 | Loss:0.1069 | MainLoss:0.1066 | Alpha:0.4725 | SPLoss:0.0034 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1097 | MainLoss:0.1097 | SPLoss:0.0035 | CLSLoss:0.0000 | AUROC:0.9928\n",
      "Test | 122/16 | Loss:0.4172 | MainLoss:0.4172 | SPLoss:0.0035 | CLSLoss:0.0000 | AUROC:0.9290\n",
      "\n",
      "Epoch: [450 | 1000] LR: 0.001315\n",
      "Train | 16/16 | Loss:0.0931 | MainLoss:0.0928 | Alpha:0.4761 | SPLoss:0.0035 | CLSLoss:0.0000 | AUROC:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 32/16 | Loss:0.1103 | MainLoss:0.1103 | SPLoss:0.0036 | CLSLoss:0.0000 | AUROC:0.9927\n",
      "Test | 122/16 | Loss:0.4171 | MainLoss:0.4171 | SPLoss:0.0036 | CLSLoss:0.0000 | AUROC:0.9284\n",
      "\n",
      "Epoch: [451 | 1000] LR: 0.001312\n",
      "Train | 16/16 | Loss:0.1131 | MainLoss:0.1127 | Alpha:0.4714 | SPLoss:0.0036 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1110 | MainLoss:0.1110 | SPLoss:0.0036 | CLSLoss:0.0000 | AUROC:0.9929\n",
      "Test | 122/16 | Loss:0.4101 | MainLoss:0.4101 | SPLoss:0.0036 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [452 | 1000] LR: 0.001309\n",
      "Train | 16/16 | Loss:0.1104 | MainLoss:0.1100 | Alpha:0.4728 | SPLoss:0.0037 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1109 | MainLoss:0.1109 | SPLoss:0.0037 | CLSLoss:0.0000 | AUROC:0.9928\n",
      "Test | 122/16 | Loss:0.4090 | MainLoss:0.4090 | SPLoss:0.0037 | CLSLoss:0.0000 | AUROC:0.9284\n",
      "\n",
      "Epoch: [453 | 1000] LR: 0.001306\n",
      "Train | 16/16 | Loss:0.1071 | MainLoss:0.1067 | Alpha:0.4730 | SPLoss:0.0038 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1105 | MainLoss:0.1105 | SPLoss:0.0038 | CLSLoss:0.0000 | AUROC:0.9926\n",
      "Test | 122/16 | Loss:0.4086 | MainLoss:0.4086 | SPLoss:0.0038 | CLSLoss:0.0000 | AUROC:0.9292\n",
      "\n",
      "Epoch: [454 | 1000] LR: 0.001303\n",
      "Train | 16/16 | Loss:0.0923 | MainLoss:0.0919 | Alpha:0.4758 | SPLoss:0.0039 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1102 | MainLoss:0.1102 | SPLoss:0.0039 | CLSLoss:0.0000 | AUROC:0.9928\n",
      "Test | 122/16 | Loss:0.4162 | MainLoss:0.4162 | SPLoss:0.0039 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [455 | 1000] LR: 0.001300\n",
      "Train | 16/16 | Loss:0.1033 | MainLoss:0.1029 | Alpha:0.4730 | SPLoss:0.0040 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1099 | MainLoss:0.1099 | SPLoss:0.0041 | CLSLoss:0.0000 | AUROC:0.9926\n",
      "Test | 122/16 | Loss:0.4205 | MainLoss:0.4205 | SPLoss:0.0041 | CLSLoss:0.0000 | AUROC:0.9288\n",
      "\n",
      "Epoch: [456 | 1000] LR: 0.001297\n",
      "Train | 16/16 | Loss:0.1086 | MainLoss:0.1082 | Alpha:0.4715 | SPLoss:0.0042 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1093 | MainLoss:0.1093 | SPLoss:0.0042 | CLSLoss:0.0000 | AUROC:0.9928\n",
      "Test | 122/16 | Loss:0.4197 | MainLoss:0.4197 | SPLoss:0.0042 | CLSLoss:0.0000 | AUROC:0.9291\n",
      "\n",
      "Epoch: [457 | 1000] LR: 0.001294\n",
      "Train | 16/16 | Loss:0.0989 | MainLoss:0.0985 | Alpha:0.4745 | SPLoss:0.0042 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1097 | MainLoss:0.1097 | SPLoss:0.0043 | CLSLoss:0.0000 | AUROC:0.9927\n",
      "Test | 122/16 | Loss:0.4209 | MainLoss:0.4209 | SPLoss:0.0043 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [458 | 1000] LR: 0.001291\n",
      "Train | 16/16 | Loss:0.0902 | MainLoss:0.0897 | Alpha:0.4768 | SPLoss:0.0043 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1101 | MainLoss:0.1101 | SPLoss:0.0044 | CLSLoss:0.0000 | AUROC:0.9927\n",
      "Test | 122/16 | Loss:0.4224 | MainLoss:0.4224 | SPLoss:0.0044 | CLSLoss:0.0000 | AUROC:0.9289\n",
      "\n",
      "Epoch: [459 | 1000] LR: 0.001288\n",
      "Train | 16/16 | Loss:0.0889 | MainLoss:0.0884 | Alpha:0.4766 | SPLoss:0.0044 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1105 | MainLoss:0.1105 | SPLoss:0.0044 | CLSLoss:0.0000 | AUROC:0.9927\n",
      "Test | 122/16 | Loss:0.4212 | MainLoss:0.4212 | SPLoss:0.0044 | CLSLoss:0.0000 | AUROC:0.9294\n",
      "\n",
      "Epoch: [460 | 1000] LR: 0.001285\n",
      "Train | 16/16 | Loss:0.1100 | MainLoss:0.1096 | Alpha:0.4721 | SPLoss:0.0045 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1111 | MainLoss:0.1111 | SPLoss:0.0045 | CLSLoss:0.0000 | AUROC:0.9927\n",
      "Test | 122/16 | Loss:0.4176 | MainLoss:0.4176 | SPLoss:0.0045 | CLSLoss:0.0000 | AUROC:0.9290\n",
      "\n",
      "Epoch: [461 | 1000] LR: 0.001282\n",
      "Train | 16/16 | Loss:0.1094 | MainLoss:0.1090 | Alpha:0.4725 | SPLoss:0.0045 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1107 | MainLoss:0.1107 | SPLoss:0.0045 | CLSLoss:0.0000 | AUROC:0.9928\n",
      "Test | 122/16 | Loss:0.4147 | MainLoss:0.4147 | SPLoss:0.0045 | CLSLoss:0.0000 | AUROC:0.9296\n",
      "\n",
      "Epoch: [462 | 1000] LR: 0.001279\n",
      "Train | 16/16 | Loss:0.0985 | MainLoss:0.0980 | Alpha:0.4751 | SPLoss:0.0046 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1109 | MainLoss:0.1109 | SPLoss:0.0046 | CLSLoss:0.0000 | AUROC:0.9928\n",
      "Test | 122/16 | Loss:0.4134 | MainLoss:0.4134 | SPLoss:0.0046 | CLSLoss:0.0000 | AUROC:0.9297\n",
      "\n",
      "Epoch: [463 | 1000] LR: 0.001276\n",
      "Train | 16/16 | Loss:0.1032 | MainLoss:0.1028 | Alpha:0.4738 | SPLoss:0.0046 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1112 | MainLoss:0.1112 | SPLoss:0.0047 | CLSLoss:0.0000 | AUROC:0.9927\n",
      "Test | 122/16 | Loss:0.4108 | MainLoss:0.4108 | SPLoss:0.0047 | CLSLoss:0.0000 | AUROC:0.9294\n",
      "\n",
      "Epoch: [464 | 1000] LR: 0.001273\n",
      "Train | 16/16 | Loss:0.0969 | MainLoss:0.0964 | Alpha:0.4744 | SPLoss:0.0048 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1105 | MainLoss:0.1105 | SPLoss:0.0048 | CLSLoss:0.0000 | AUROC:0.9929\n",
      "Test | 122/16 | Loss:0.4152 | MainLoss:0.4152 | SPLoss:0.0048 | CLSLoss:0.0000 | AUROC:0.9303\n",
      "\n",
      "Epoch: [465 | 1000] LR: 0.001270\n",
      "Train | 16/16 | Loss:0.1015 | MainLoss:0.1010 | Alpha:0.4732 | SPLoss:0.0049 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1104 | MainLoss:0.1104 | SPLoss:0.0049 | CLSLoss:0.0000 | AUROC:0.9928\n",
      "Test | 122/16 | Loss:0.4173 | MainLoss:0.4173 | SPLoss:0.0049 | CLSLoss:0.0000 | AUROC:0.9300\n",
      "\n",
      "Epoch: [466 | 1000] LR: 0.001267\n",
      "Train | 16/16 | Loss:0.1003 | MainLoss:0.0998 | Alpha:0.4736 | SPLoss:0.0050 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1115 | MainLoss:0.1115 | SPLoss:0.0050 | CLSLoss:0.0000 | AUROC:0.9928\n",
      "Test | 122/16 | Loss:0.4124 | MainLoss:0.4124 | SPLoss:0.0050 | CLSLoss:0.0000 | AUROC:0.9293\n",
      "\n",
      "Epoch: [467 | 1000] LR: 0.001264\n",
      "Train | 16/16 | Loss:0.1047 | MainLoss:0.1042 | Alpha:0.4732 | SPLoss:0.0050 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1111 | MainLoss:0.1111 | SPLoss:0.0051 | CLSLoss:0.0000 | AUROC:0.9926\n",
      "Test | 122/16 | Loss:0.4130 | MainLoss:0.4130 | SPLoss:0.0051 | CLSLoss:0.0000 | AUROC:0.9298\n",
      "\n",
      "Epoch: [468 | 1000] LR: 0.001261\n",
      "Train | 16/16 | Loss:0.1012 | MainLoss:0.1007 | Alpha:0.4735 | SPLoss:0.0051 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1112 | MainLoss:0.1112 | SPLoss:0.0052 | CLSLoss:0.0000 | AUROC:0.9929\n",
      "Test | 122/16 | Loss:0.4114 | MainLoss:0.4114 | SPLoss:0.0052 | CLSLoss:0.0000 | AUROC:0.9299\n",
      "\n",
      "Epoch: [469 | 1000] LR: 0.001258\n",
      "Train | 16/16 | Loss:0.1152 | MainLoss:0.1147 | Alpha:0.4709 | SPLoss:0.0052 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1113 | MainLoss:0.1113 | SPLoss:0.0052 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4075 | MainLoss:0.4075 | SPLoss:0.0052 | CLSLoss:0.0000 | AUROC:0.9301\n",
      "\n",
      "Epoch: [470 | 1000] LR: 0.001255\n",
      "Train | 16/16 | Loss:0.1143 | MainLoss:0.1137 | Alpha:0.4697 | SPLoss:0.0053 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1101 | MainLoss:0.1101 | SPLoss:0.0053 | CLSLoss:0.0000 | AUROC:0.9927\n",
      "Test | 122/16 | Loss:0.4105 | MainLoss:0.4105 | SPLoss:0.0053 | CLSLoss:0.0000 | AUROC:0.9307\n",
      "\n",
      "Epoch: [471 | 1000] LR: 0.001252\n",
      "Train | 16/16 | Loss:0.1035 | MainLoss:0.1030 | Alpha:0.4733 | SPLoss:0.0054 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1095 | MainLoss:0.1095 | SPLoss:0.0055 | CLSLoss:0.0000 | AUROC:0.9927\n",
      "Test | 122/16 | Loss:0.4169 | MainLoss:0.4169 | SPLoss:0.0055 | CLSLoss:0.0000 | AUROC:0.9298\n",
      "\n",
      "Epoch: [472 | 1000] LR: 0.001249\n",
      "Train | 16/16 | Loss:0.0977 | MainLoss:0.0971 | Alpha:0.4736 | SPLoss:0.0055 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1091 | MainLoss:0.1091 | SPLoss:0.0056 | CLSLoss:0.0000 | AUROC:0.9929\n",
      "Test | 122/16 | Loss:0.4231 | MainLoss:0.4231 | SPLoss:0.0056 | CLSLoss:0.0000 | AUROC:0.9308\n",
      "\n",
      "Epoch: [473 | 1000] LR: 0.001246\n",
      "Train | 16/16 | Loss:0.0986 | MainLoss:0.0980 | Alpha:0.4751 | SPLoss:0.0056 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1096 | MainLoss:0.1096 | SPLoss:0.0056 | CLSLoss:0.0000 | AUROC:0.9926\n",
      "Test | 122/16 | Loss:0.4187 | MainLoss:0.4187 | SPLoss:0.0056 | CLSLoss:0.0000 | AUROC:0.9304\n",
      "\n",
      "Epoch: [474 | 1000] LR: 0.001243\n",
      "Train | 16/16 | Loss:0.0994 | MainLoss:0.0988 | Alpha:0.4751 | SPLoss:0.0056 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1100 | MainLoss:0.1100 | SPLoss:0.0057 | CLSLoss:0.0000 | AUROC:0.9927\n",
      "Test | 122/16 | Loss:0.4142 | MainLoss:0.4142 | SPLoss:0.0057 | CLSLoss:0.0000 | AUROC:0.9302\n",
      "\n",
      "Epoch: [475 | 1000] LR: 0.001240\n",
      "Train | 16/16 | Loss:0.0948 | MainLoss:0.0942 | Alpha:0.4756 | SPLoss:0.0057 | CLSLoss:0.0000 | AUROC:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 32/16 | Loss:0.1097 | MainLoss:0.1097 | SPLoss:0.0058 | CLSLoss:0.0000 | AUROC:0.9928\n",
      "Test | 122/16 | Loss:0.4150 | MainLoss:0.4150 | SPLoss:0.0058 | CLSLoss:0.0000 | AUROC:0.9308\n",
      "\n",
      "Epoch: [476 | 1000] LR: 0.001236\n",
      "Train | 16/16 | Loss:0.1030 | MainLoss:0.1024 | Alpha:0.4733 | SPLoss:0.0058 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1098 | MainLoss:0.1098 | SPLoss:0.0059 | CLSLoss:0.0000 | AUROC:0.9926\n",
      "Test | 122/16 | Loss:0.4150 | MainLoss:0.4150 | SPLoss:0.0059 | CLSLoss:0.0000 | AUROC:0.9305\n",
      "\n",
      "Epoch: [477 | 1000] LR: 0.001233\n",
      "Train | 16/16 | Loss:0.1047 | MainLoss:0.1041 | Alpha:0.4731 | SPLoss:0.0059 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1102 | MainLoss:0.1102 | SPLoss:0.0060 | CLSLoss:0.0000 | AUROC:0.9928\n",
      "Test | 122/16 | Loss:0.4134 | MainLoss:0.4134 | SPLoss:0.0060 | CLSLoss:0.0000 | AUROC:0.9300\n",
      "\n",
      "Epoch: [478 | 1000] LR: 0.001230\n",
      "Train | 16/16 | Loss:0.0993 | MainLoss:0.0987 | Alpha:0.4740 | SPLoss:0.0060 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1104 | MainLoss:0.1104 | SPLoss:0.0060 | CLSLoss:0.0000 | AUROC:0.9928\n",
      "Test | 122/16 | Loss:0.4122 | MainLoss:0.4122 | SPLoss:0.0060 | CLSLoss:0.0000 | AUROC:0.9293\n",
      "\n",
      "Epoch: [479 | 1000] LR: 0.001227\n",
      "Train | 16/16 | Loss:0.1018 | MainLoss:0.1012 | Alpha:0.4730 | SPLoss:0.0061 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1099 | MainLoss:0.1099 | SPLoss:0.0061 | CLSLoss:0.0000 | AUROC:0.9926\n",
      "Test | 122/16 | Loss:0.4142 | MainLoss:0.4142 | SPLoss:0.0061 | CLSLoss:0.0000 | AUROC:0.9295\n",
      "\n",
      "Epoch: [480 | 1000] LR: 0.001224\n",
      "Train | 16/16 | Loss:0.0997 | MainLoss:0.0991 | Alpha:0.4736 | SPLoss:0.0062 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1090 | MainLoss:0.1090 | SPLoss:0.0063 | CLSLoss:0.0000 | AUROC:0.9928\n",
      "Test | 122/16 | Loss:0.4183 | MainLoss:0.4183 | SPLoss:0.0063 | CLSLoss:0.0000 | AUROC:0.9294\n",
      "\n",
      "Epoch: [481 | 1000] LR: 0.001221\n",
      "Train | 16/16 | Loss:0.1060 | MainLoss:0.1054 | Alpha:0.4728 | SPLoss:0.0063 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1094 | MainLoss:0.1094 | SPLoss:0.0063 | CLSLoss:0.0000 | AUROC:0.9929\n",
      "Test | 122/16 | Loss:0.4099 | MainLoss:0.4099 | SPLoss:0.0063 | CLSLoss:0.0000 | AUROC:0.9295\n",
      "\n",
      "Epoch: [482 | 1000] LR: 0.001218\n",
      "Train | 16/16 | Loss:0.0973 | MainLoss:0.0966 | Alpha:0.4749 | SPLoss:0.0063 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1092 | MainLoss:0.1092 | SPLoss:0.0064 | CLSLoss:0.0000 | AUROC:0.9928\n",
      "Test | 122/16 | Loss:0.4137 | MainLoss:0.4137 | SPLoss:0.0064 | CLSLoss:0.0000 | AUROC:0.9300\n",
      "\n",
      "Epoch: [483 | 1000] LR: 0.001215\n",
      "Train | 16/16 | Loss:0.0878 | MainLoss:0.0871 | Alpha:0.4767 | SPLoss:0.0064 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1096 | MainLoss:0.1096 | SPLoss:0.0065 | CLSLoss:0.0000 | AUROC:0.9927\n",
      "Test | 122/16 | Loss:0.4152 | MainLoss:0.4152 | SPLoss:0.0065 | CLSLoss:0.0000 | AUROC:0.9299\n",
      "\n",
      "Epoch: [484 | 1000] LR: 0.001212\n",
      "Train | 16/16 | Loss:0.1046 | MainLoss:0.1040 | Alpha:0.4724 | SPLoss:0.0066 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1087 | MainLoss:0.1087 | SPLoss:0.0066 | CLSLoss:0.0000 | AUROC:0.9927\n",
      "Test | 122/16 | Loss:0.4202 | MainLoss:0.4202 | SPLoss:0.0066 | CLSLoss:0.0000 | AUROC:0.9304\n",
      "\n",
      "Epoch: [485 | 1000] LR: 0.001209\n",
      "Train | 16/16 | Loss:0.0979 | MainLoss:0.0973 | Alpha:0.4748 | SPLoss:0.0066 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1100 | MainLoss:0.1100 | SPLoss:0.0067 | CLSLoss:0.0000 | AUROC:0.9927\n",
      "Test | 122/16 | Loss:0.4150 | MainLoss:0.4150 | SPLoss:0.0067 | CLSLoss:0.0000 | AUROC:0.9296\n",
      "\n",
      "Epoch: [486 | 1000] LR: 0.001206\n",
      "Train | 16/16 | Loss:0.0973 | MainLoss:0.0967 | Alpha:0.4744 | SPLoss:0.0067 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1096 | MainLoss:0.1096 | SPLoss:0.0068 | CLSLoss:0.0000 | AUROC:0.9928\n",
      "Test | 122/16 | Loss:0.4151 | MainLoss:0.4151 | SPLoss:0.0068 | CLSLoss:0.0000 | AUROC:0.9294\n",
      "\n",
      "Epoch: [487 | 1000] LR: 0.001203\n",
      "Train | 16/16 | Loss:0.0959 | MainLoss:0.0952 | Alpha:0.4740 | SPLoss:0.0068 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1092 | MainLoss:0.1092 | SPLoss:0.0069 | CLSLoss:0.0000 | AUROC:0.9929\n",
      "Test | 122/16 | Loss:0.4180 | MainLoss:0.4180 | SPLoss:0.0069 | CLSLoss:0.0000 | AUROC:0.9300\n",
      "\n",
      "Epoch: [488 | 1000] LR: 0.001200\n",
      "Train | 16/16 | Loss:0.1043 | MainLoss:0.1036 | Alpha:0.4729 | SPLoss:0.0070 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1091 | MainLoss:0.1091 | SPLoss:0.0070 | CLSLoss:0.0000 | AUROC:0.9928\n",
      "Test | 122/16 | Loss:0.4200 | MainLoss:0.4200 | SPLoss:0.0070 | CLSLoss:0.0000 | AUROC:0.9299\n",
      "\n",
      "Epoch: [489 | 1000] LR: 0.001197\n",
      "Train | 16/16 | Loss:0.0967 | MainLoss:0.0960 | Alpha:0.4748 | SPLoss:0.0071 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1094 | MainLoss:0.1094 | SPLoss:0.0071 | CLSLoss:0.0000 | AUROC:0.9928\n",
      "Test | 122/16 | Loss:0.4213 | MainLoss:0.4213 | SPLoss:0.0071 | CLSLoss:0.0000 | AUROC:0.9295\n",
      "\n",
      "Epoch: [490 | 1000] LR: 0.001194\n",
      "Train | 16/16 | Loss:0.0946 | MainLoss:0.0939 | Alpha:0.4742 | SPLoss:0.0072 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1094 | MainLoss:0.1094 | SPLoss:0.0073 | CLSLoss:0.0000 | AUROC:0.9928\n",
      "Test | 122/16 | Loss:0.4274 | MainLoss:0.4274 | SPLoss:0.0073 | CLSLoss:0.0000 | AUROC:0.9292\n",
      "\n",
      "Epoch: [491 | 1000] LR: 0.001190\n",
      "Train | 16/16 | Loss:0.0959 | MainLoss:0.0951 | Alpha:0.4749 | SPLoss:0.0073 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1103 | MainLoss:0.1103 | SPLoss:0.0073 | CLSLoss:0.0000 | AUROC:0.9929\n",
      "Test | 122/16 | Loss:0.4229 | MainLoss:0.4229 | SPLoss:0.0073 | CLSLoss:0.0000 | AUROC:0.9289\n",
      "\n",
      "Epoch: [492 | 1000] LR: 0.001187\n",
      "Train | 16/16 | Loss:0.0994 | MainLoss:0.0986 | Alpha:0.4738 | SPLoss:0.0073 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1096 | MainLoss:0.1096 | SPLoss:0.0074 | CLSLoss:0.0000 | AUROC:0.9928\n",
      "Test | 122/16 | Loss:0.4226 | MainLoss:0.4226 | SPLoss:0.0074 | CLSLoss:0.0000 | AUROC:0.9293\n",
      "\n",
      "Epoch: [493 | 1000] LR: 0.001184\n",
      "Train | 16/16 | Loss:0.0919 | MainLoss:0.0911 | Alpha:0.4742 | SPLoss:0.0074 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1097 | MainLoss:0.1097 | SPLoss:0.0075 | CLSLoss:0.0000 | AUROC:0.9929\n",
      "Test | 122/16 | Loss:0.4232 | MainLoss:0.4232 | SPLoss:0.0075 | CLSLoss:0.0000 | AUROC:0.9290\n",
      "\n",
      "Epoch: [494 | 1000] LR: 0.001181\n",
      "Train | 16/16 | Loss:0.0999 | MainLoss:0.0991 | Alpha:0.4729 | SPLoss:0.0075 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1096 | MainLoss:0.1096 | SPLoss:0.0076 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4263 | MainLoss:0.4263 | SPLoss:0.0076 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [495 | 1000] LR: 0.001178\n",
      "Train | 16/16 | Loss:0.1017 | MainLoss:0.1010 | Alpha:0.4731 | SPLoss:0.0076 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1095 | MainLoss:0.1095 | SPLoss:0.0077 | CLSLoss:0.0000 | AUROC:0.9929\n",
      "Test | 122/16 | Loss:0.4267 | MainLoss:0.4267 | SPLoss:0.0077 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [496 | 1000] LR: 0.001175\n",
      "Train | 16/16 | Loss:0.0948 | MainLoss:0.0940 | Alpha:0.4754 | SPLoss:0.0077 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1104 | MainLoss:0.1104 | SPLoss:0.0077 | CLSLoss:0.0000 | AUROC:0.9929\n",
      "Test | 122/16 | Loss:0.4225 | MainLoss:0.4225 | SPLoss:0.0077 | CLSLoss:0.0000 | AUROC:0.9281\n",
      "\n",
      "Epoch: [497 | 1000] LR: 0.001172\n",
      "Train | 16/16 | Loss:0.1063 | MainLoss:0.1055 | Alpha:0.4718 | SPLoss:0.0078 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1093 | MainLoss:0.1093 | SPLoss:0.0079 | CLSLoss:0.0000 | AUROC:0.9927\n",
      "Test | 122/16 | Loss:0.4292 | MainLoss:0.4292 | SPLoss:0.0079 | CLSLoss:0.0000 | AUROC:0.9281\n",
      "\n",
      "Epoch: [498 | 1000] LR: 0.001169\n",
      "Train | 16/16 | Loss:0.0944 | MainLoss:0.0936 | Alpha:0.4755 | SPLoss:0.0079 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1100 | MainLoss:0.1100 | SPLoss:0.0079 | CLSLoss:0.0000 | AUROC:0.9928\n",
      "Test | 122/16 | Loss:0.4267 | MainLoss:0.4267 | SPLoss:0.0079 | CLSLoss:0.0000 | AUROC:0.9275\n",
      "\n",
      "Epoch: [499 | 1000] LR: 0.001166\n",
      "Train | 16/16 | Loss:0.1060 | MainLoss:0.1052 | Alpha:0.4731 | SPLoss:0.0080 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1092 | MainLoss:0.1092 | SPLoss:0.0080 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4258 | MainLoss:0.4258 | SPLoss:0.0080 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [500 | 1000] LR: 0.001163\n",
      "Train | 16/16 | Loss:0.1091 | MainLoss:0.1083 | Alpha:0.4716 | SPLoss:0.0081 | CLSLoss:0.0000 | AUROC:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 32/16 | Loss:0.1096 | MainLoss:0.1096 | SPLoss:0.0081 | CLSLoss:0.0000 | AUROC:0.9928\n",
      "Test | 122/16 | Loss:0.4236 | MainLoss:0.4236 | SPLoss:0.0081 | CLSLoss:0.0000 | AUROC:0.9276\n",
      "\n",
      "Epoch: [501 | 1000] LR: 0.001160\n",
      "Train | 16/16 | Loss:0.1048 | MainLoss:0.1048 | Alpha:0.4745 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1110 | MainLoss:0.1110 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9929\n",
      "Test | 122/16 | Loss:0.4166 | MainLoss:0.4166 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9273\n",
      "\n",
      "Epoch: [502 | 1000] LR: 0.001156\n",
      "Train | 16/16 | Loss:0.0985 | MainLoss:0.0985 | Alpha:0.4766 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1098 | MainLoss:0.1098 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9928\n",
      "Test | 122/16 | Loss:0.4233 | MainLoss:0.4233 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9278\n",
      "\n",
      "Epoch: [503 | 1000] LR: 0.001153\n",
      "Train | 16/16 | Loss:0.0989 | MainLoss:0.0989 | Alpha:0.4772 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1103 | MainLoss:0.1103 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9929\n",
      "Test | 122/16 | Loss:0.4189 | MainLoss:0.4189 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9277\n",
      "\n",
      "Epoch: [504 | 1000] LR: 0.001150\n",
      "Train | 16/16 | Loss:0.0917 | MainLoss:0.0917 | Alpha:0.4777 | SPLoss:0.0001 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1111 | MainLoss:0.1111 | SPLoss:0.0001 | CLSLoss:0.0000 | AUROC:0.9926\n",
      "Test | 122/16 | Loss:0.4198 | MainLoss:0.4198 | SPLoss:0.0001 | CLSLoss:0.0000 | AUROC:0.9274\n",
      "\n",
      "Epoch: [505 | 1000] LR: 0.001147\n",
      "Train | 16/16 | Loss:0.0962 | MainLoss:0.0962 | Alpha:0.4774 | SPLoss:0.0001 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1114 | MainLoss:0.1114 | SPLoss:0.0001 | CLSLoss:0.0000 | AUROC:0.9927\n",
      "Test | 122/16 | Loss:0.4200 | MainLoss:0.4200 | SPLoss:0.0001 | CLSLoss:0.0000 | AUROC:0.9271\n",
      "\n",
      "Epoch: [506 | 1000] LR: 0.001144\n",
      "Train | 16/16 | Loss:0.1038 | MainLoss:0.1037 | Alpha:0.4757 | SPLoss:0.0001 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1101 | MainLoss:0.1101 | SPLoss:0.0001 | CLSLoss:0.0000 | AUROC:0.9929\n",
      "Test | 122/16 | Loss:0.4253 | MainLoss:0.4253 | SPLoss:0.0001 | CLSLoss:0.0000 | AUROC:0.9275\n",
      "\n",
      "Epoch: [507 | 1000] LR: 0.001141\n",
      "Train | 16/16 | Loss:0.1038 | MainLoss:0.1038 | Alpha:0.4751 | SPLoss:0.0001 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1094 | MainLoss:0.1094 | SPLoss:0.0001 | CLSLoss:0.0000 | AUROC:0.9928\n",
      "Test | 122/16 | Loss:0.4224 | MainLoss:0.4224 | SPLoss:0.0001 | CLSLoss:0.0000 | AUROC:0.9279\n",
      "\n",
      "Epoch: [508 | 1000] LR: 0.001138\n",
      "Train | 16/16 | Loss:0.1049 | MainLoss:0.1049 | Alpha:0.4748 | SPLoss:0.0001 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1091 | MainLoss:0.1091 | SPLoss:0.0001 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4233 | MainLoss:0.4233 | SPLoss:0.0001 | CLSLoss:0.0000 | AUROC:0.9278\n",
      "\n",
      "Epoch: [509 | 1000] LR: 0.001135\n",
      "Train | 16/16 | Loss:0.1075 | MainLoss:0.1075 | Alpha:0.4743 | SPLoss:0.0001 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1095 | MainLoss:0.1095 | SPLoss:0.0001 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4195 | MainLoss:0.4195 | SPLoss:0.0001 | CLSLoss:0.0000 | AUROC:0.9279\n",
      "\n",
      "Epoch: [510 | 1000] LR: 0.001132\n",
      "Train | 16/16 | Loss:0.0956 | MainLoss:0.0955 | Alpha:0.4765 | SPLoss:0.0002 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1094 | MainLoss:0.1094 | SPLoss:0.0002 | CLSLoss:0.0000 | AUROC:0.9929\n",
      "Test | 122/16 | Loss:0.4226 | MainLoss:0.4226 | SPLoss:0.0002 | CLSLoss:0.0000 | AUROC:0.9275\n",
      "\n",
      "Epoch: [511 | 1000] LR: 0.001128\n",
      "Train | 16/16 | Loss:0.0904 | MainLoss:0.0904 | Alpha:0.4787 | SPLoss:0.0002 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1090 | MainLoss:0.1090 | SPLoss:0.0002 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4265 | MainLoss:0.4265 | SPLoss:0.0002 | CLSLoss:0.0000 | AUROC:0.9278\n",
      "\n",
      "Epoch: [512 | 1000] LR: 0.001125\n",
      "Train | 16/16 | Loss:0.0931 | MainLoss:0.0931 | Alpha:0.4776 | SPLoss:0.0002 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1097 | MainLoss:0.1097 | SPLoss:0.0002 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4229 | MainLoss:0.4229 | SPLoss:0.0002 | CLSLoss:0.0000 | AUROC:0.9276\n",
      "\n",
      "Epoch: [513 | 1000] LR: 0.001122\n",
      "Train | 16/16 | Loss:0.0980 | MainLoss:0.0980 | Alpha:0.4764 | SPLoss:0.0002 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1094 | MainLoss:0.1094 | SPLoss:0.0002 | CLSLoss:0.0000 | AUROC:0.9928\n",
      "Test | 122/16 | Loss:0.4216 | MainLoss:0.4216 | SPLoss:0.0002 | CLSLoss:0.0000 | AUROC:0.9281\n",
      "\n",
      "Epoch: [514 | 1000] LR: 0.001119\n",
      "Train | 16/16 | Loss:0.0988 | MainLoss:0.0988 | Alpha:0.4761 | SPLoss:0.0002 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1094 | MainLoss:0.1094 | SPLoss:0.0002 | CLSLoss:0.0000 | AUROC:0.9928\n",
      "Test | 122/16 | Loss:0.4195 | MainLoss:0.4195 | SPLoss:0.0002 | CLSLoss:0.0000 | AUROC:0.9284\n",
      "\n",
      "Epoch: [515 | 1000] LR: 0.001116\n",
      "Train | 16/16 | Loss:0.1000 | MainLoss:0.0999 | Alpha:0.4766 | SPLoss:0.0003 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1092 | MainLoss:0.1092 | SPLoss:0.0003 | CLSLoss:0.0000 | AUROC:0.9929\n",
      "Test | 122/16 | Loss:0.4162 | MainLoss:0.4162 | SPLoss:0.0003 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [516 | 1000] LR: 0.001113\n",
      "Train | 16/16 | Loss:0.0909 | MainLoss:0.0909 | Alpha:0.4789 | SPLoss:0.0003 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1098 | MainLoss:0.1098 | SPLoss:0.0003 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4144 | MainLoss:0.4144 | SPLoss:0.0003 | CLSLoss:0.0000 | AUROC:0.9289\n",
      "\n",
      "Epoch: [517 | 1000] LR: 0.001110\n",
      "Train | 16/16 | Loss:0.0902 | MainLoss:0.0902 | Alpha:0.4786 | SPLoss:0.0003 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1099 | MainLoss:0.1099 | SPLoss:0.0003 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4148 | MainLoss:0.4148 | SPLoss:0.0003 | CLSLoss:0.0000 | AUROC:0.9292\n",
      "\n",
      "Epoch: [518 | 1000] LR: 0.001107\n",
      "Train | 16/16 | Loss:0.1002 | MainLoss:0.1001 | Alpha:0.4763 | SPLoss:0.0003 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1098 | MainLoss:0.1098 | SPLoss:0.0004 | CLSLoss:0.0000 | AUROC:0.9928\n",
      "Test | 122/16 | Loss:0.4133 | MainLoss:0.4133 | SPLoss:0.0004 | CLSLoss:0.0000 | AUROC:0.9290\n",
      "\n",
      "Epoch: [519 | 1000] LR: 0.001103\n",
      "Train | 16/16 | Loss:0.1046 | MainLoss:0.1045 | Alpha:0.4749 | SPLoss:0.0004 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1089 | MainLoss:0.1089 | SPLoss:0.0004 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4177 | MainLoss:0.4177 | SPLoss:0.0004 | CLSLoss:0.0000 | AUROC:0.9291\n",
      "\n",
      "Epoch: [520 | 1000] LR: 0.001100\n",
      "Train | 16/16 | Loss:0.0944 | MainLoss:0.0944 | Alpha:0.4769 | SPLoss:0.0004 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1086 | MainLoss:0.1086 | SPLoss:0.0004 | CLSLoss:0.0000 | AUROC:0.9928\n",
      "Test | 122/16 | Loss:0.4220 | MainLoss:0.4220 | SPLoss:0.0004 | CLSLoss:0.0000 | AUROC:0.9290\n",
      "\n",
      "Epoch: [521 | 1000] LR: 0.001097\n",
      "Train | 16/16 | Loss:0.0919 | MainLoss:0.0919 | Alpha:0.4784 | SPLoss:0.0004 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1086 | MainLoss:0.1086 | SPLoss:0.0005 | CLSLoss:0.0000 | AUROC:0.9929\n",
      "Test | 122/16 | Loss:0.4248 | MainLoss:0.4248 | SPLoss:0.0005 | CLSLoss:0.0000 | AUROC:0.9290\n",
      "\n",
      "Epoch: [522 | 1000] LR: 0.001094\n",
      "Train | 16/16 | Loss:0.0859 | MainLoss:0.0859 | Alpha:0.4803 | SPLoss:0.0005 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1092 | MainLoss:0.1092 | SPLoss:0.0005 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4262 | MainLoss:0.4262 | SPLoss:0.0005 | CLSLoss:0.0000 | AUROC:0.9282\n",
      "\n",
      "Epoch: [523 | 1000] LR: 0.001091\n",
      "Train | 16/16 | Loss:0.0965 | MainLoss:0.0964 | Alpha:0.4774 | SPLoss:0.0005 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1096 | MainLoss:0.1096 | SPLoss:0.0005 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4233 | MainLoss:0.4233 | SPLoss:0.0005 | CLSLoss:0.0000 | AUROC:0.9284\n",
      "\n",
      "Epoch: [524 | 1000] LR: 0.001088\n",
      "Train | 16/16 | Loss:0.0982 | MainLoss:0.0981 | Alpha:0.4765 | SPLoss:0.0005 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1098 | MainLoss:0.1098 | SPLoss:0.0005 | CLSLoss:0.0000 | AUROC:0.9927\n",
      "Test | 122/16 | Loss:0.4227 | MainLoss:0.4227 | SPLoss:0.0005 | CLSLoss:0.0000 | AUROC:0.9282\n",
      "\n",
      "Epoch: [525 | 1000] LR: 0.001085\n",
      "Train | 16/16 | Loss:0.1017 | MainLoss:0.1016 | Alpha:0.4749 | SPLoss:0.0005 | CLSLoss:0.0000 | AUROC:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 32/16 | Loss:0.1089 | MainLoss:0.1089 | SPLoss:0.0006 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4236 | MainLoss:0.4236 | SPLoss:0.0006 | CLSLoss:0.0000 | AUROC:0.9288\n",
      "\n",
      "Epoch: [526 | 1000] LR: 0.001082\n",
      "Train | 16/16 | Loss:0.1017 | MainLoss:0.1017 | Alpha:0.4763 | SPLoss:0.0006 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1095 | MainLoss:0.1095 | SPLoss:0.0006 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4194 | MainLoss:0.4194 | SPLoss:0.0006 | CLSLoss:0.0000 | AUROC:0.9283\n",
      "\n",
      "Epoch: [527 | 1000] LR: 0.001078\n",
      "Train | 16/16 | Loss:0.0941 | MainLoss:0.0941 | Alpha:0.4773 | SPLoss:0.0006 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1092 | MainLoss:0.1092 | SPLoss:0.0006 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4224 | MainLoss:0.4224 | SPLoss:0.0006 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [528 | 1000] LR: 0.001075\n",
      "Train | 16/16 | Loss:0.0969 | MainLoss:0.0969 | Alpha:0.4769 | SPLoss:0.0006 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1088 | MainLoss:0.1088 | SPLoss:0.0007 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4220 | MainLoss:0.4220 | SPLoss:0.0007 | CLSLoss:0.0000 | AUROC:0.9293\n",
      "\n",
      "Epoch: [529 | 1000] LR: 0.001072\n",
      "Train | 16/16 | Loss:0.0980 | MainLoss:0.0979 | Alpha:0.4763 | SPLoss:0.0007 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1096 | MainLoss:0.1096 | SPLoss:0.0007 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4141 | MainLoss:0.4141 | SPLoss:0.0007 | CLSLoss:0.0000 | AUROC:0.9294\n",
      "\n",
      "Epoch: [530 | 1000] LR: 0.001069\n",
      "Train | 16/16 | Loss:0.1013 | MainLoss:0.1012 | Alpha:0.4762 | SPLoss:0.0007 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1087 | MainLoss:0.1087 | SPLoss:0.0007 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4172 | MainLoss:0.4172 | SPLoss:0.0007 | CLSLoss:0.0000 | AUROC:0.9291\n",
      "\n",
      "Epoch: [531 | 1000] LR: 0.001066\n",
      "Train | 16/16 | Loss:0.0963 | MainLoss:0.0962 | Alpha:0.4771 | SPLoss:0.0007 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0008 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4174 | MainLoss:0.4174 | SPLoss:0.0008 | CLSLoss:0.0000 | AUROC:0.9300\n",
      "\n",
      "Epoch: [532 | 1000] LR: 0.001063\n",
      "Train | 16/16 | Loss:0.1014 | MainLoss:0.1013 | Alpha:0.4757 | SPLoss:0.0008 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0008 | CLSLoss:0.0000 | AUROC:0.9929\n",
      "Test | 122/16 | Loss:0.4162 | MainLoss:0.4162 | SPLoss:0.0008 | CLSLoss:0.0000 | AUROC:0.9300\n",
      "\n",
      "Epoch: [533 | 1000] LR: 0.001060\n",
      "Train | 16/16 | Loss:0.1052 | MainLoss:0.1051 | Alpha:0.4742 | SPLoss:0.0008 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1081 | MainLoss:0.1081 | SPLoss:0.0008 | CLSLoss:0.0000 | AUROC:0.9928\n",
      "Test | 122/16 | Loss:0.4163 | MainLoss:0.4163 | SPLoss:0.0008 | CLSLoss:0.0000 | AUROC:0.9304\n",
      "\n",
      "Epoch: [534 | 1000] LR: 0.001057\n",
      "Train | 16/16 | Loss:0.1044 | MainLoss:0.1043 | Alpha:0.4755 | SPLoss:0.0009 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0009 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4129 | MainLoss:0.4129 | SPLoss:0.0009 | CLSLoss:0.0000 | AUROC:0.9300\n",
      "\n",
      "Epoch: [535 | 1000] LR: 0.001053\n",
      "Train | 16/16 | Loss:0.0992 | MainLoss:0.0991 | Alpha:0.4769 | SPLoss:0.0009 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1086 | MainLoss:0.1086 | SPLoss:0.0009 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4172 | MainLoss:0.4172 | SPLoss:0.0009 | CLSLoss:0.0000 | AUROC:0.9292\n",
      "\n",
      "Epoch: [536 | 1000] LR: 0.001050\n",
      "Train | 16/16 | Loss:0.1196 | MainLoss:0.1195 | Alpha:0.4710 | SPLoss:0.0009 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1075 | MainLoss:0.1075 | SPLoss:0.0010 | CLSLoss:0.0000 | AUROC:0.9929\n",
      "Test | 122/16 | Loss:0.4161 | MainLoss:0.4161 | SPLoss:0.0010 | CLSLoss:0.0000 | AUROC:0.9298\n",
      "\n",
      "Epoch: [537 | 1000] LR: 0.001047\n",
      "Train | 16/16 | Loss:0.1085 | MainLoss:0.1084 | Alpha:0.4742 | SPLoss:0.0010 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1079 | MainLoss:0.1079 | SPLoss:0.0010 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4119 | MainLoss:0.4119 | SPLoss:0.0010 | CLSLoss:0.0000 | AUROC:0.9294\n",
      "\n",
      "Epoch: [538 | 1000] LR: 0.001044\n",
      "Train | 16/16 | Loss:0.1018 | MainLoss:0.1017 | Alpha:0.4755 | SPLoss:0.0010 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1076 | MainLoss:0.1076 | SPLoss:0.0010 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4154 | MainLoss:0.4154 | SPLoss:0.0010 | CLSLoss:0.0000 | AUROC:0.9293\n",
      "\n",
      "Epoch: [539 | 1000] LR: 0.001041\n",
      "Train | 16/16 | Loss:0.1007 | MainLoss:0.1006 | Alpha:0.4754 | SPLoss:0.0010 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1081 | MainLoss:0.1081 | SPLoss:0.0011 | CLSLoss:0.0000 | AUROC:0.9933\n",
      "Test | 122/16 | Loss:0.4095 | MainLoss:0.4095 | SPLoss:0.0011 | CLSLoss:0.0000 | AUROC:0.9292\n",
      "\n",
      "Epoch: [540 | 1000] LR: 0.001038\n",
      "Train | 16/16 | Loss:0.1030 | MainLoss:0.1029 | Alpha:0.4755 | SPLoss:0.0011 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0011 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4098 | MainLoss:0.4098 | SPLoss:0.0011 | CLSLoss:0.0000 | AUROC:0.9289\n",
      "\n",
      "Epoch: [541 | 1000] LR: 0.001035\n",
      "Train | 16/16 | Loss:0.1038 | MainLoss:0.1036 | Alpha:0.4744 | SPLoss:0.0011 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1094 | MainLoss:0.1094 | SPLoss:0.0012 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4063 | MainLoss:0.4063 | SPLoss:0.0012 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [542 | 1000] LR: 0.001031\n",
      "Train | 16/16 | Loss:0.0982 | MainLoss:0.0981 | Alpha:0.4765 | SPLoss:0.0012 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1083 | MainLoss:0.1083 | SPLoss:0.0012 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4108 | MainLoss:0.4108 | SPLoss:0.0012 | CLSLoss:0.0000 | AUROC:0.9299\n",
      "\n",
      "Epoch: [543 | 1000] LR: 0.001028\n",
      "Train | 16/16 | Loss:0.0861 | MainLoss:0.0860 | Alpha:0.4787 | SPLoss:0.0012 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1091 | MainLoss:0.1091 | SPLoss:0.0012 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4101 | MainLoss:0.4101 | SPLoss:0.0012 | CLSLoss:0.0000 | AUROC:0.9297\n",
      "\n",
      "Epoch: [544 | 1000] LR: 0.001025\n",
      "Train | 16/16 | Loss:0.1057 | MainLoss:0.1056 | Alpha:0.4753 | SPLoss:0.0013 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1087 | MainLoss:0.1087 | SPLoss:0.0013 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4143 | MainLoss:0.4143 | SPLoss:0.0013 | CLSLoss:0.0000 | AUROC:0.9296\n",
      "\n",
      "Epoch: [545 | 1000] LR: 0.001022\n",
      "Train | 16/16 | Loss:0.0973 | MainLoss:0.0971 | Alpha:0.4765 | SPLoss:0.0013 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1086 | MainLoss:0.1086 | SPLoss:0.0013 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4152 | MainLoss:0.4152 | SPLoss:0.0013 | CLSLoss:0.0000 | AUROC:0.9295\n",
      "\n",
      "Epoch: [546 | 1000] LR: 0.001019\n",
      "Train | 16/16 | Loss:0.0918 | MainLoss:0.0916 | Alpha:0.4777 | SPLoss:0.0013 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1083 | MainLoss:0.1083 | SPLoss:0.0013 | CLSLoss:0.0000 | AUROC:0.9929\n",
      "Test | 122/16 | Loss:0.4195 | MainLoss:0.4195 | SPLoss:0.0013 | CLSLoss:0.0000 | AUROC:0.9299\n",
      "\n",
      "Epoch: [547 | 1000] LR: 0.001016\n",
      "Train | 16/16 | Loss:0.0927 | MainLoss:0.0925 | Alpha:0.4780 | SPLoss:0.0014 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0014 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4216 | MainLoss:0.4216 | SPLoss:0.0014 | CLSLoss:0.0000 | AUROC:0.9291\n",
      "\n",
      "Epoch: [548 | 1000] LR: 0.001013\n",
      "Train | 16/16 | Loss:0.1043 | MainLoss:0.1042 | Alpha:0.4757 | SPLoss:0.0014 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1083 | MainLoss:0.1083 | SPLoss:0.0014 | CLSLoss:0.0000 | AUROC:0.9928\n",
      "Test | 122/16 | Loss:0.4213 | MainLoss:0.4213 | SPLoss:0.0014 | CLSLoss:0.0000 | AUROC:0.9292\n",
      "\n",
      "Epoch: [549 | 1000] LR: 0.001009\n",
      "Train | 16/16 | Loss:0.0883 | MainLoss:0.0882 | Alpha:0.4783 | SPLoss:0.0014 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1081 | MainLoss:0.1081 | SPLoss:0.0015 | CLSLoss:0.0000 | AUROC:0.9929\n",
      "Test | 122/16 | Loss:0.4230 | MainLoss:0.4230 | SPLoss:0.0015 | CLSLoss:0.0000 | AUROC:0.9294\n",
      "\n",
      "Epoch: [550 | 1000] LR: 0.001006\n",
      "Train | 16/16 | Loss:0.1075 | MainLoss:0.1074 | Alpha:0.4735 | SPLoss:0.0015 | CLSLoss:0.0000 | AUROC:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 32/16 | Loss:0.1080 | MainLoss:0.1080 | SPLoss:0.0015 | CLSLoss:0.0000 | AUROC:0.9929\n",
      "Test | 122/16 | Loss:0.4214 | MainLoss:0.4214 | SPLoss:0.0015 | CLSLoss:0.0000 | AUROC:0.9291\n",
      "\n",
      "Epoch: [551 | 1000] LR: 0.001003\n",
      "Train | 16/16 | Loss:0.1132 | MainLoss:0.1130 | Alpha:0.4726 | SPLoss:0.0015 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1079 | MainLoss:0.1079 | SPLoss:0.0016 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4180 | MainLoss:0.4180 | SPLoss:0.0016 | CLSLoss:0.0000 | AUROC:0.9289\n",
      "\n",
      "Epoch: [552 | 1000] LR: 0.001000\n",
      "Train | 16/16 | Loss:0.0964 | MainLoss:0.0963 | Alpha:0.4769 | SPLoss:0.0016 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1077 | MainLoss:0.1077 | SPLoss:0.0016 | CLSLoss:0.0000 | AUROC:0.9929\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0016 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [553 | 1000] LR: 0.000997\n",
      "Train | 16/16 | Loss:0.0937 | MainLoss:0.0935 | Alpha:0.4771 | SPLoss:0.0016 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1083 | MainLoss:0.1083 | SPLoss:0.0017 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4196 | MainLoss:0.4196 | SPLoss:0.0017 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [554 | 1000] LR: 0.000994\n",
      "Train | 16/16 | Loss:0.1016 | MainLoss:0.1014 | Alpha:0.4750 | SPLoss:0.0017 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0017 | CLSLoss:0.0000 | AUROC:0.9929\n",
      "Test | 122/16 | Loss:0.4181 | MainLoss:0.4181 | SPLoss:0.0017 | CLSLoss:0.0000 | AUROC:0.9289\n",
      "\n",
      "Epoch: [555 | 1000] LR: 0.000991\n",
      "Train | 16/16 | Loss:0.0983 | MainLoss:0.0982 | Alpha:0.4758 | SPLoss:0.0017 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1091 | MainLoss:0.1091 | SPLoss:0.0018 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4162 | MainLoss:0.4162 | SPLoss:0.0018 | CLSLoss:0.0000 | AUROC:0.9280\n",
      "\n",
      "Epoch: [556 | 1000] LR: 0.000987\n",
      "Train | 16/16 | Loss:0.0942 | MainLoss:0.0940 | Alpha:0.4775 | SPLoss:0.0018 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1090 | MainLoss:0.1090 | SPLoss:0.0018 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4162 | MainLoss:0.4162 | SPLoss:0.0018 | CLSLoss:0.0000 | AUROC:0.9284\n",
      "\n",
      "Epoch: [557 | 1000] LR: 0.000984\n",
      "Train | 16/16 | Loss:0.0979 | MainLoss:0.0977 | Alpha:0.4755 | SPLoss:0.0018 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1089 | MainLoss:0.1089 | SPLoss:0.0019 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4157 | MainLoss:0.4157 | SPLoss:0.0019 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [558 | 1000] LR: 0.000981\n",
      "Train | 16/16 | Loss:0.0978 | MainLoss:0.0976 | Alpha:0.4759 | SPLoss:0.0019 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1089 | MainLoss:0.1089 | SPLoss:0.0019 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4181 | MainLoss:0.4181 | SPLoss:0.0019 | CLSLoss:0.0000 | AUROC:0.9282\n",
      "\n",
      "Epoch: [559 | 1000] LR: 0.000978\n",
      "Train | 16/16 | Loss:0.1063 | MainLoss:0.1061 | Alpha:0.4739 | SPLoss:0.0019 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1093 | MainLoss:0.1093 | SPLoss:0.0020 | CLSLoss:0.0000 | AUROC:0.9929\n",
      "Test | 122/16 | Loss:0.4150 | MainLoss:0.4150 | SPLoss:0.0020 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [560 | 1000] LR: 0.000975\n",
      "Train | 16/16 | Loss:0.1056 | MainLoss:0.1054 | Alpha:0.4737 | SPLoss:0.0020 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1099 | MainLoss:0.1099 | SPLoss:0.0020 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4115 | MainLoss:0.4115 | SPLoss:0.0020 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [561 | 1000] LR: 0.000972\n",
      "Train | 16/16 | Loss:0.0899 | MainLoss:0.0897 | Alpha:0.4781 | SPLoss:0.0020 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1090 | MainLoss:0.1090 | SPLoss:0.0021 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4191 | MainLoss:0.4191 | SPLoss:0.0021 | CLSLoss:0.0000 | AUROC:0.9280\n",
      "\n",
      "Epoch: [562 | 1000] LR: 0.000969\n",
      "Train | 16/16 | Loss:0.0964 | MainLoss:0.0962 | Alpha:0.4767 | SPLoss:0.0021 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1093 | MainLoss:0.1093 | SPLoss:0.0021 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4181 | MainLoss:0.4181 | SPLoss:0.0021 | CLSLoss:0.0000 | AUROC:0.9279\n",
      "\n",
      "Epoch: [563 | 1000] LR: 0.000965\n",
      "Train | 16/16 | Loss:0.0930 | MainLoss:0.0928 | Alpha:0.4773 | SPLoss:0.0021 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1103 | MainLoss:0.1103 | SPLoss:0.0021 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4168 | MainLoss:0.4168 | SPLoss:0.0021 | CLSLoss:0.0000 | AUROC:0.9279\n",
      "\n",
      "Epoch: [564 | 1000] LR: 0.000962\n",
      "Train | 16/16 | Loss:0.1011 | MainLoss:0.1009 | Alpha:0.4748 | SPLoss:0.0022 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1099 | MainLoss:0.1099 | SPLoss:0.0022 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4177 | MainLoss:0.4177 | SPLoss:0.0022 | CLSLoss:0.0000 | AUROC:0.9280\n",
      "\n",
      "Epoch: [565 | 1000] LR: 0.000959\n",
      "Train | 16/16 | Loss:0.0948 | MainLoss:0.0946 | Alpha:0.4775 | SPLoss:0.0022 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1088 | MainLoss:0.1088 | SPLoss:0.0022 | CLSLoss:0.0000 | AUROC:0.9929\n",
      "Test | 122/16 | Loss:0.4220 | MainLoss:0.4220 | SPLoss:0.0022 | CLSLoss:0.0000 | AUROC:0.9285\n",
      "\n",
      "Epoch: [566 | 1000] LR: 0.000956\n",
      "Train | 16/16 | Loss:0.1037 | MainLoss:0.1035 | Alpha:0.4745 | SPLoss:0.0023 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1088 | MainLoss:0.1088 | SPLoss:0.0023 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0023 | CLSLoss:0.0000 | AUROC:0.9283\n",
      "\n",
      "Epoch: [567 | 1000] LR: 0.000953\n",
      "Train | 16/16 | Loss:0.0970 | MainLoss:0.0967 | Alpha:0.4768 | SPLoss:0.0023 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1093 | MainLoss:0.1093 | SPLoss:0.0023 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4189 | MainLoss:0.4189 | SPLoss:0.0023 | CLSLoss:0.0000 | AUROC:0.9280\n",
      "\n",
      "Epoch: [568 | 1000] LR: 0.000950\n",
      "Train | 16/16 | Loss:0.1008 | MainLoss:0.1006 | Alpha:0.4755 | SPLoss:0.0024 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1087 | MainLoss:0.1087 | SPLoss:0.0024 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4181 | MainLoss:0.4181 | SPLoss:0.0024 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [569 | 1000] LR: 0.000947\n",
      "Train | 16/16 | Loss:0.0967 | MainLoss:0.0965 | Alpha:0.4763 | SPLoss:0.0024 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1091 | MainLoss:0.1091 | SPLoss:0.0025 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4142 | MainLoss:0.4142 | SPLoss:0.0025 | CLSLoss:0.0000 | AUROC:0.9293\n",
      "\n",
      "Epoch: [570 | 1000] LR: 0.000943\n",
      "Train | 16/16 | Loss:0.0922 | MainLoss:0.0920 | Alpha:0.4773 | SPLoss:0.0025 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1094 | MainLoss:0.1094 | SPLoss:0.0025 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4167 | MainLoss:0.4167 | SPLoss:0.0025 | CLSLoss:0.0000 | AUROC:0.9290\n",
      "\n",
      "Epoch: [571 | 1000] LR: 0.000940\n",
      "Train | 16/16 | Loss:0.0907 | MainLoss:0.0905 | Alpha:0.4779 | SPLoss:0.0025 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1090 | MainLoss:0.1090 | SPLoss:0.0026 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4207 | MainLoss:0.4207 | SPLoss:0.0026 | CLSLoss:0.0000 | AUROC:0.9285\n",
      "\n",
      "Epoch: [572 | 1000] LR: 0.000937\n",
      "Train | 16/16 | Loss:0.0988 | MainLoss:0.0985 | Alpha:0.4764 | SPLoss:0.0026 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1086 | MainLoss:0.1086 | SPLoss:0.0026 | CLSLoss:0.0000 | AUROC:0.9929\n",
      "Test | 122/16 | Loss:0.4224 | MainLoss:0.4224 | SPLoss:0.0026 | CLSLoss:0.0000 | AUROC:0.9285\n",
      "\n",
      "Epoch: [573 | 1000] LR: 0.000934\n",
      "Train | 16/16 | Loss:0.1008 | MainLoss:0.1006 | Alpha:0.4758 | SPLoss:0.0026 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0027 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4222 | MainLoss:0.4222 | SPLoss:0.0027 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [574 | 1000] LR: 0.000931\n",
      "Train | 16/16 | Loss:0.1011 | MainLoss:0.1008 | Alpha:0.4750 | SPLoss:0.0027 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1087 | MainLoss:0.1087 | SPLoss:0.0027 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4188 | MainLoss:0.4188 | SPLoss:0.0027 | CLSLoss:0.0000 | AUROC:0.9285\n",
      "\n",
      "Epoch: [575 | 1000] LR: 0.000928\n",
      "Train | 16/16 | Loss:0.0872 | MainLoss:0.0869 | Alpha:0.4792 | SPLoss:0.0027 | CLSLoss:0.0000 | AUROC:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 32/16 | Loss:0.1089 | MainLoss:0.1089 | SPLoss:0.0028 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4176 | MainLoss:0.4176 | SPLoss:0.0028 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [576 | 1000] LR: 0.000925\n",
      "Train | 16/16 | Loss:0.0859 | MainLoss:0.0856 | Alpha:0.4785 | SPLoss:0.0028 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1088 | MainLoss:0.1088 | SPLoss:0.0028 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0028 | CLSLoss:0.0000 | AUROC:0.9288\n",
      "\n",
      "Epoch: [577 | 1000] LR: 0.000922\n",
      "Train | 16/16 | Loss:0.1016 | MainLoss:0.1013 | Alpha:0.4745 | SPLoss:0.0029 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1088 | MainLoss:0.1088 | SPLoss:0.0029 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4219 | MainLoss:0.4219 | SPLoss:0.0029 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [578 | 1000] LR: 0.000918\n",
      "Train | 16/16 | Loss:0.0906 | MainLoss:0.0903 | Alpha:0.4782 | SPLoss:0.0029 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1092 | MainLoss:0.1092 | SPLoss:0.0029 | CLSLoss:0.0000 | AUROC:0.9933\n",
      "Test | 122/16 | Loss:0.4241 | MainLoss:0.4241 | SPLoss:0.0029 | CLSLoss:0.0000 | AUROC:0.9280\n",
      "\n",
      "Epoch: [579 | 1000] LR: 0.000915\n",
      "Train | 16/16 | Loss:0.1015 | MainLoss:0.1012 | Alpha:0.4755 | SPLoss:0.0030 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1098 | MainLoss:0.1098 | SPLoss:0.0030 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4206 | MainLoss:0.4206 | SPLoss:0.0030 | CLSLoss:0.0000 | AUROC:0.9276\n",
      "\n",
      "Epoch: [580 | 1000] LR: 0.000912\n",
      "Train | 16/16 | Loss:0.0929 | MainLoss:0.0926 | Alpha:0.4776 | SPLoss:0.0030 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1097 | MainLoss:0.1097 | SPLoss:0.0031 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4212 | MainLoss:0.4212 | SPLoss:0.0031 | CLSLoss:0.0000 | AUROC:0.9279\n",
      "\n",
      "Epoch: [581 | 1000] LR: 0.000909\n",
      "Train | 16/16 | Loss:0.0876 | MainLoss:0.0873 | Alpha:0.4784 | SPLoss:0.0031 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1097 | MainLoss:0.1097 | SPLoss:0.0031 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4248 | MainLoss:0.4248 | SPLoss:0.0031 | CLSLoss:0.0000 | AUROC:0.9279\n",
      "\n",
      "Epoch: [582 | 1000] LR: 0.000906\n",
      "Train | 16/16 | Loss:0.1026 | MainLoss:0.1023 | Alpha:0.4745 | SPLoss:0.0031 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1096 | MainLoss:0.1096 | SPLoss:0.0031 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4227 | MainLoss:0.4227 | SPLoss:0.0031 | CLSLoss:0.0000 | AUROC:0.9281\n",
      "\n",
      "Epoch: [583 | 1000] LR: 0.000903\n",
      "Train | 16/16 | Loss:0.0993 | MainLoss:0.0990 | Alpha:0.4753 | SPLoss:0.0032 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1091 | MainLoss:0.1091 | SPLoss:0.0032 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4227 | MainLoss:0.4227 | SPLoss:0.0032 | CLSLoss:0.0000 | AUROC:0.9290\n",
      "\n",
      "Epoch: [584 | 1000] LR: 0.000900\n",
      "Train | 16/16 | Loss:0.1022 | MainLoss:0.1018 | Alpha:0.4760 | SPLoss:0.0032 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1091 | MainLoss:0.1091 | SPLoss:0.0033 | CLSLoss:0.0000 | AUROC:0.9933\n",
      "Test | 122/16 | Loss:0.4221 | MainLoss:0.4221 | SPLoss:0.0033 | CLSLoss:0.0000 | AUROC:0.9281\n",
      "\n",
      "Epoch: [585 | 1000] LR: 0.000897\n",
      "Train | 16/16 | Loss:0.1012 | MainLoss:0.1008 | Alpha:0.4757 | SPLoss:0.0033 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1092 | MainLoss:0.1092 | SPLoss:0.0033 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4215 | MainLoss:0.4215 | SPLoss:0.0033 | CLSLoss:0.0000 | AUROC:0.9278\n",
      "\n",
      "Epoch: [586 | 1000] LR: 0.000893\n",
      "Train | 16/16 | Loss:0.0895 | MainLoss:0.0892 | Alpha:0.4786 | SPLoss:0.0033 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1096 | MainLoss:0.1096 | SPLoss:0.0034 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4180 | MainLoss:0.4180 | SPLoss:0.0034 | CLSLoss:0.0000 | AUROC:0.9284\n",
      "\n",
      "Epoch: [587 | 1000] LR: 0.000890\n",
      "Train | 16/16 | Loss:0.0959 | MainLoss:0.0955 | Alpha:0.4760 | SPLoss:0.0034 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1095 | MainLoss:0.1095 | SPLoss:0.0034 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4192 | MainLoss:0.4192 | SPLoss:0.0034 | CLSLoss:0.0000 | AUROC:0.9288\n",
      "\n",
      "Epoch: [588 | 1000] LR: 0.000887\n",
      "Train | 16/16 | Loss:0.1016 | MainLoss:0.1012 | Alpha:0.4746 | SPLoss:0.0034 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1095 | MainLoss:0.1095 | SPLoss:0.0034 | CLSLoss:0.0000 | AUROC:0.9933\n",
      "Test | 122/16 | Loss:0.4204 | MainLoss:0.4204 | SPLoss:0.0034 | CLSLoss:0.0000 | AUROC:0.9280\n",
      "\n",
      "Epoch: [589 | 1000] LR: 0.000884\n",
      "Train | 16/16 | Loss:0.0933 | MainLoss:0.0930 | Alpha:0.4775 | SPLoss:0.0035 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1096 | MainLoss:0.1096 | SPLoss:0.0035 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4244 | MainLoss:0.4244 | SPLoss:0.0035 | CLSLoss:0.0000 | AUROC:0.9274\n",
      "\n",
      "Epoch: [590 | 1000] LR: 0.000881\n",
      "Train | 16/16 | Loss:0.0977 | MainLoss:0.0973 | Alpha:0.4766 | SPLoss:0.0035 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1095 | MainLoss:0.1095 | SPLoss:0.0035 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4242 | MainLoss:0.4242 | SPLoss:0.0035 | CLSLoss:0.0000 | AUROC:0.9278\n",
      "\n",
      "Epoch: [591 | 1000] LR: 0.000878\n",
      "Train | 16/16 | Loss:0.0936 | MainLoss:0.0932 | Alpha:0.4766 | SPLoss:0.0035 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1092 | MainLoss:0.1092 | SPLoss:0.0036 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4264 | MainLoss:0.4264 | SPLoss:0.0036 | CLSLoss:0.0000 | AUROC:0.9278\n",
      "\n",
      "Epoch: [592 | 1000] LR: 0.000875\n",
      "Train | 16/16 | Loss:0.1015 | MainLoss:0.1011 | Alpha:0.4750 | SPLoss:0.0036 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0036 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4272 | MainLoss:0.4272 | SPLoss:0.0036 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [593 | 1000] LR: 0.000872\n",
      "Train | 16/16 | Loss:0.1096 | MainLoss:0.1093 | Alpha:0.4730 | SPLoss:0.0036 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1081 | MainLoss:0.1081 | SPLoss:0.0037 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4224 | MainLoss:0.4224 | SPLoss:0.0037 | CLSLoss:0.0000 | AUROC:0.9284\n",
      "\n",
      "Epoch: [594 | 1000] LR: 0.000868\n",
      "Train | 16/16 | Loss:0.0869 | MainLoss:0.0866 | Alpha:0.4786 | SPLoss:0.0037 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1089 | MainLoss:0.1089 | SPLoss:0.0037 | CLSLoss:0.0000 | AUROC:0.9933\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0037 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [595 | 1000] LR: 0.000865\n",
      "Train | 16/16 | Loss:0.0973 | MainLoss:0.0969 | Alpha:0.4760 | SPLoss:0.0037 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1095 | MainLoss:0.1095 | SPLoss:0.0038 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4202 | MainLoss:0.4202 | SPLoss:0.0038 | CLSLoss:0.0000 | AUROC:0.9279\n",
      "\n",
      "Epoch: [596 | 1000] LR: 0.000862\n",
      "Train | 16/16 | Loss:0.0881 | MainLoss:0.0877 | Alpha:0.4783 | SPLoss:0.0038 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1094 | MainLoss:0.1094 | SPLoss:0.0038 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4229 | MainLoss:0.4229 | SPLoss:0.0038 | CLSLoss:0.0000 | AUROC:0.9280\n",
      "\n",
      "Epoch: [597 | 1000] LR: 0.000859\n",
      "Train | 16/16 | Loss:0.1023 | MainLoss:0.1019 | Alpha:0.4743 | SPLoss:0.0038 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1092 | MainLoss:0.1092 | SPLoss:0.0039 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4200 | MainLoss:0.4200 | SPLoss:0.0039 | CLSLoss:0.0000 | AUROC:0.9283\n",
      "\n",
      "Epoch: [598 | 1000] LR: 0.000856\n",
      "Train | 16/16 | Loss:0.0983 | MainLoss:0.0979 | Alpha:0.4763 | SPLoss:0.0039 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1093 | MainLoss:0.1093 | SPLoss:0.0039 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4187 | MainLoss:0.4187 | SPLoss:0.0039 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [599 | 1000] LR: 0.000853\n",
      "Train | 16/16 | Loss:0.1079 | MainLoss:0.1075 | Alpha:0.4734 | SPLoss:0.0039 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0040 | CLSLoss:0.0000 | AUROC:0.9934\n",
      "Test | 122/16 | Loss:0.4233 | MainLoss:0.4233 | SPLoss:0.0040 | CLSLoss:0.0000 | AUROC:0.9285\n",
      "\n",
      "Epoch: [600 | 1000] LR: 0.000850\n",
      "Train | 16/16 | Loss:0.0978 | MainLoss:0.0974 | Alpha:0.4759 | SPLoss:0.0040 | CLSLoss:0.0000 | AUROC:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0040 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4199 | MainLoss:0.4199 | SPLoss:0.0040 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [601 | 1000] LR: 0.000085\n",
      "Train | 16/16 | Loss:0.0795 | MainLoss:0.0795 | Alpha:0.4812 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4199 | MainLoss:0.4199 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [602 | 1000] LR: 0.000084\n",
      "Train | 16/16 | Loss:0.0998 | MainLoss:0.0998 | Alpha:0.4763 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [603 | 1000] LR: 0.000084\n",
      "Train | 16/16 | Loss:0.0881 | MainLoss:0.0881 | Alpha:0.4792 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [604 | 1000] LR: 0.000084\n",
      "Train | 16/16 | Loss:0.0954 | MainLoss:0.0954 | Alpha:0.4783 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1086 | MainLoss:0.1086 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4197 | MainLoss:0.4197 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9284\n",
      "\n",
      "Epoch: [605 | 1000] LR: 0.000083\n",
      "Train | 16/16 | Loss:0.0966 | MainLoss:0.0966 | Alpha:0.4781 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1086 | MainLoss:0.1086 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9929\n",
      "Test | 122/16 | Loss:0.4198 | MainLoss:0.4198 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [606 | 1000] LR: 0.000083\n",
      "Train | 16/16 | Loss:0.0863 | MainLoss:0.0863 | Alpha:0.4800 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1086 | MainLoss:0.1086 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4198 | MainLoss:0.4198 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9284\n",
      "\n",
      "Epoch: [607 | 1000] LR: 0.000083\n",
      "Train | 16/16 | Loss:0.0951 | MainLoss:0.0951 | Alpha:0.4780 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4198 | MainLoss:0.4198 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [608 | 1000] LR: 0.000082\n",
      "Train | 16/16 | Loss:0.0856 | MainLoss:0.0856 | Alpha:0.4796 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1086 | MainLoss:0.1086 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4197 | MainLoss:0.4197 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [609 | 1000] LR: 0.000082\n",
      "Train | 16/16 | Loss:0.1018 | MainLoss:0.1018 | Alpha:0.4756 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1086 | MainLoss:0.1086 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9929\n",
      "Test | 122/16 | Loss:0.4193 | MainLoss:0.4193 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9284\n",
      "\n",
      "Epoch: [610 | 1000] LR: 0.000082\n",
      "Train | 16/16 | Loss:0.0977 | MainLoss:0.0977 | Alpha:0.4765 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1086 | MainLoss:0.1086 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9929\n",
      "Test | 122/16 | Loss:0.4196 | MainLoss:0.4196 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9285\n",
      "\n",
      "Epoch: [611 | 1000] LR: 0.000082\n",
      "Train | 16/16 | Loss:0.0947 | MainLoss:0.0947 | Alpha:0.4775 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1086 | MainLoss:0.1086 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4199 | MainLoss:0.4199 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9288\n",
      "\n",
      "Epoch: [612 | 1000] LR: 0.000081\n",
      "Train | 16/16 | Loss:0.0935 | MainLoss:0.0935 | Alpha:0.4788 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1086 | MainLoss:0.1086 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9933\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9284\n",
      "\n",
      "Epoch: [613 | 1000] LR: 0.000081\n",
      "Train | 16/16 | Loss:0.0978 | MainLoss:0.0978 | Alpha:0.4772 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4204 | MainLoss:0.4204 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9284\n",
      "\n",
      "Epoch: [614 | 1000] LR: 0.000081\n",
      "Train | 16/16 | Loss:0.0923 | MainLoss:0.0923 | Alpha:0.4783 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4205 | MainLoss:0.4205 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9285\n",
      "\n",
      "Epoch: [615 | 1000] LR: 0.000080\n",
      "Train | 16/16 | Loss:0.0938 | MainLoss:0.0938 | Alpha:0.4771 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4206 | MainLoss:0.4206 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9282\n",
      "\n",
      "Epoch: [616 | 1000] LR: 0.000080\n",
      "Train | 16/16 | Loss:0.0975 | MainLoss:0.0975 | Alpha:0.4764 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9929\n",
      "Test | 122/16 | Loss:0.4200 | MainLoss:0.4200 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9281\n",
      "\n",
      "Epoch: [617 | 1000] LR: 0.000080\n",
      "Train | 16/16 | Loss:0.0913 | MainLoss:0.0913 | Alpha:0.4780 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4203 | MainLoss:0.4203 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9285\n",
      "\n",
      "Epoch: [618 | 1000] LR: 0.000079\n",
      "Train | 16/16 | Loss:0.0881 | MainLoss:0.0881 | Alpha:0.4793 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4203 | MainLoss:0.4203 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [619 | 1000] LR: 0.000079\n",
      "Train | 16/16 | Loss:0.0979 | MainLoss:0.0979 | Alpha:0.4766 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4203 | MainLoss:0.4203 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9284\n",
      "\n",
      "Epoch: [620 | 1000] LR: 0.000079\n",
      "Train | 16/16 | Loss:0.0920 | MainLoss:0.0920 | Alpha:0.4782 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9933\n",
      "Test | 122/16 | Loss:0.4202 | MainLoss:0.4202 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [621 | 1000] LR: 0.000078\n",
      "Train | 16/16 | Loss:0.0989 | MainLoss:0.0989 | Alpha:0.4756 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4199 | MainLoss:0.4199 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9281\n",
      "\n",
      "Epoch: [622 | 1000] LR: 0.000078\n",
      "Train | 16/16 | Loss:0.0923 | MainLoss:0.0923 | Alpha:0.4783 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4198 | MainLoss:0.4198 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9284\n",
      "\n",
      "Epoch: [623 | 1000] LR: 0.000078\n",
      "Train | 16/16 | Loss:0.0975 | MainLoss:0.0975 | Alpha:0.4768 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4199 | MainLoss:0.4199 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9283\n",
      "\n",
      "Epoch: [624 | 1000] LR: 0.000078\n",
      "Train | 16/16 | Loss:0.0960 | MainLoss:0.0960 | Alpha:0.4768 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4200 | MainLoss:0.4200 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9285\n",
      "\n",
      "Epoch: [625 | 1000] LR: 0.000077\n",
      "Train | 16/16 | Loss:0.0898 | MainLoss:0.0898 | Alpha:0.4787 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4200 | MainLoss:0.4200 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9283\n",
      "\n",
      "Epoch: [626 | 1000] LR: 0.000077\n",
      "Train | 16/16 | Loss:0.0920 | MainLoss:0.0920 | Alpha:0.4784 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4202 | MainLoss:0.4202 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [627 | 1000] LR: 0.000077\n",
      "Train | 16/16 | Loss:0.0918 | MainLoss:0.0918 | Alpha:0.4791 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9284\n",
      "\n",
      "Epoch: [628 | 1000] LR: 0.000076\n",
      "Train | 16/16 | Loss:0.0939 | MainLoss:0.0939 | Alpha:0.4776 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4199 | MainLoss:0.4199 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [629 | 1000] LR: 0.000076\n",
      "Train | 16/16 | Loss:0.0952 | MainLoss:0.0952 | Alpha:0.4777 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4199 | MainLoss:0.4199 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9290\n",
      "\n",
      "Epoch: [630 | 1000] LR: 0.000076\n",
      "Train | 16/16 | Loss:0.1035 | MainLoss:0.1035 | Alpha:0.4761 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4197 | MainLoss:0.4197 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9284\n",
      "\n",
      "Epoch: [631 | 1000] LR: 0.000075\n",
      "Train | 16/16 | Loss:0.0892 | MainLoss:0.0892 | Alpha:0.4785 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4196 | MainLoss:0.4196 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9282\n",
      "\n",
      "Epoch: [632 | 1000] LR: 0.000075\n",
      "Train | 16/16 | Loss:0.0962 | MainLoss:0.0962 | Alpha:0.4768 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9934\n",
      "Test | 122/16 | Loss:0.4195 | MainLoss:0.4195 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9285\n",
      "\n",
      "Epoch: [633 | 1000] LR: 0.000075\n",
      "Train | 16/16 | Loss:0.0929 | MainLoss:0.0929 | Alpha:0.4771 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4196 | MainLoss:0.4196 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9283\n",
      "\n",
      "Epoch: [634 | 1000] LR: 0.000075\n",
      "Train | 16/16 | Loss:0.0900 | MainLoss:0.0900 | Alpha:0.4787 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4198 | MainLoss:0.4198 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [635 | 1000] LR: 0.000074\n",
      "Train | 16/16 | Loss:0.1034 | MainLoss:0.1034 | Alpha:0.4760 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4199 | MainLoss:0.4199 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9285\n",
      "\n",
      "Epoch: [636 | 1000] LR: 0.000074\n",
      "Train | 16/16 | Loss:0.0907 | MainLoss:0.0907 | Alpha:0.4789 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4199 | MainLoss:0.4199 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9283\n",
      "\n",
      "Epoch: [637 | 1000] LR: 0.000074\n",
      "Train | 16/16 | Loss:0.0947 | MainLoss:0.0947 | Alpha:0.4768 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4200 | MainLoss:0.4200 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9284\n",
      "\n",
      "Epoch: [638 | 1000] LR: 0.000073\n",
      "Train | 16/16 | Loss:0.0954 | MainLoss:0.0954 | Alpha:0.4776 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4198 | MainLoss:0.4198 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9290\n",
      "\n",
      "Epoch: [639 | 1000] LR: 0.000073\n",
      "Train | 16/16 | Loss:0.1047 | MainLoss:0.1047 | Alpha:0.4747 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4197 | MainLoss:0.4197 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [640 | 1000] LR: 0.000073\n",
      "Train | 16/16 | Loss:0.0913 | MainLoss:0.0913 | Alpha:0.4783 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4196 | MainLoss:0.4196 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9285\n",
      "\n",
      "Epoch: [641 | 1000] LR: 0.000072\n",
      "Train | 16/16 | Loss:0.0920 | MainLoss:0.0920 | Alpha:0.4781 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4197 | MainLoss:0.4197 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9283\n",
      "\n",
      "Epoch: [642 | 1000] LR: 0.000072\n",
      "Train | 16/16 | Loss:0.0933 | MainLoss:0.0933 | Alpha:0.4777 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9933\n",
      "Test | 122/16 | Loss:0.4194 | MainLoss:0.4194 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [643 | 1000] LR: 0.000072\n",
      "Train | 16/16 | Loss:0.0997 | MainLoss:0.0997 | Alpha:0.4766 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4195 | MainLoss:0.4195 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [644 | 1000] LR: 0.000071\n",
      "Train | 16/16 | Loss:0.0793 | MainLoss:0.0793 | Alpha:0.4819 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4199 | MainLoss:0.4199 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9285\n",
      "\n",
      "Epoch: [645 | 1000] LR: 0.000071\n",
      "Train | 16/16 | Loss:0.0953 | MainLoss:0.0952 | Alpha:0.4766 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4202 | MainLoss:0.4202 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9285\n",
      "\n",
      "Epoch: [646 | 1000] LR: 0.000071\n",
      "Train | 16/16 | Loss:0.0898 | MainLoss:0.0898 | Alpha:0.4782 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9933\n",
      "Test | 122/16 | Loss:0.4202 | MainLoss:0.4202 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [647 | 1000] LR: 0.000071\n",
      "Train | 16/16 | Loss:0.0907 | MainLoss:0.0907 | Alpha:0.4782 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4203 | MainLoss:0.4203 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9284\n",
      "\n",
      "Epoch: [648 | 1000] LR: 0.000070\n",
      "Train | 16/16 | Loss:0.0946 | MainLoss:0.0946 | Alpha:0.4777 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4205 | MainLoss:0.4205 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [649 | 1000] LR: 0.000070\n",
      "Train | 16/16 | Loss:0.0913 | MainLoss:0.0913 | Alpha:0.4781 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4204 | MainLoss:0.4204 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9285\n",
      "\n",
      "Epoch: [650 | 1000] LR: 0.000070\n",
      "Train | 16/16 | Loss:0.1062 | MainLoss:0.1062 | Alpha:0.4743 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4202 | MainLoss:0.4202 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9283\n",
      "\n",
      "Epoch: [651 | 1000] LR: 0.000069\n",
      "Train | 16/16 | Loss:0.0991 | MainLoss:0.0991 | Alpha:0.4769 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9934\n",
      "Test | 122/16 | Loss:0.4204 | MainLoss:0.4204 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [652 | 1000] LR: 0.000069\n",
      "Train | 16/16 | Loss:0.0863 | MainLoss:0.0863 | Alpha:0.4792 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4204 | MainLoss:0.4204 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9283\n",
      "\n",
      "Epoch: [653 | 1000] LR: 0.000069\n",
      "Train | 16/16 | Loss:0.1020 | MainLoss:0.1020 | Alpha:0.4760 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9929\n",
      "Test | 122/16 | Loss:0.4202 | MainLoss:0.4202 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9285\n",
      "\n",
      "Epoch: [654 | 1000] LR: 0.000069\n",
      "Train | 16/16 | Loss:0.0979 | MainLoss:0.0979 | Alpha:0.4771 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4204 | MainLoss:0.4204 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9284\n",
      "\n",
      "Epoch: [655 | 1000] LR: 0.000068\n",
      "Train | 16/16 | Loss:0.0977 | MainLoss:0.0977 | Alpha:0.4777 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9934\n",
      "Test | 122/16 | Loss:0.4208 | MainLoss:0.4208 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9284\n",
      "\n",
      "Epoch: [656 | 1000] LR: 0.000068\n",
      "Train | 16/16 | Loss:0.0965 | MainLoss:0.0965 | Alpha:0.4776 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4206 | MainLoss:0.4206 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9284\n",
      "\n",
      "Epoch: [657 | 1000] LR: 0.000068\n",
      "Train | 16/16 | Loss:0.0935 | MainLoss:0.0935 | Alpha:0.4776 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4202 | MainLoss:0.4202 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9283\n",
      "\n",
      "Epoch: [658 | 1000] LR: 0.000067\n",
      "Train | 16/16 | Loss:0.0989 | MainLoss:0.0989 | Alpha:0.4772 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4199 | MainLoss:0.4199 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9284\n",
      "\n",
      "Epoch: [659 | 1000] LR: 0.000067\n",
      "Train | 16/16 | Loss:0.0991 | MainLoss:0.0991 | Alpha:0.4771 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4197 | MainLoss:0.4197 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9284\n",
      "\n",
      "Epoch: [660 | 1000] LR: 0.000067\n",
      "Train | 16/16 | Loss:0.0965 | MainLoss:0.0965 | Alpha:0.4772 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4200 | MainLoss:0.4200 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9285\n",
      "\n",
      "Epoch: [661 | 1000] LR: 0.000066\n",
      "Train | 16/16 | Loss:0.0905 | MainLoss:0.0905 | Alpha:0.4785 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9933\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [662 | 1000] LR: 0.000066\n",
      "Train | 16/16 | Loss:0.0938 | MainLoss:0.0938 | Alpha:0.4784 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4202 | MainLoss:0.4202 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9288\n",
      "\n",
      "Epoch: [663 | 1000] LR: 0.000066\n",
      "Train | 16/16 | Loss:0.0906 | MainLoss:0.0906 | Alpha:0.4780 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1083 | MainLoss:0.1083 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9934\n",
      "Test | 122/16 | Loss:0.4205 | MainLoss:0.4205 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9285\n",
      "\n",
      "Epoch: [664 | 1000] LR: 0.000066\n",
      "Train | 16/16 | Loss:0.0857 | MainLoss:0.0857 | Alpha:0.4794 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9934\n",
      "Test | 122/16 | Loss:0.4205 | MainLoss:0.4205 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9285\n",
      "\n",
      "Epoch: [665 | 1000] LR: 0.000065\n",
      "Train | 16/16 | Loss:0.0813 | MainLoss:0.0813 | Alpha:0.4808 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4206 | MainLoss:0.4206 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [666 | 1000] LR: 0.000065\n",
      "Train | 16/16 | Loss:0.0823 | MainLoss:0.0823 | Alpha:0.4804 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4209 | MainLoss:0.4209 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9289\n",
      "\n",
      "Epoch: [667 | 1000] LR: 0.000065\n",
      "Train | 16/16 | Loss:0.0962 | MainLoss:0.0962 | Alpha:0.4769 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4211 | MainLoss:0.4211 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [668 | 1000] LR: 0.000064\n",
      "Train | 16/16 | Loss:0.1006 | MainLoss:0.1006 | Alpha:0.4756 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9929\n",
      "Test | 122/16 | Loss:0.4207 | MainLoss:0.4207 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9288\n",
      "\n",
      "Epoch: [669 | 1000] LR: 0.000064\n",
      "Train | 16/16 | Loss:0.0824 | MainLoss:0.0824 | Alpha:0.4807 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4206 | MainLoss:0.4206 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [670 | 1000] LR: 0.000064\n",
      "Train | 16/16 | Loss:0.0933 | MainLoss:0.0933 | Alpha:0.4782 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4210 | MainLoss:0.4210 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [671 | 1000] LR: 0.000063\n",
      "Train | 16/16 | Loss:0.0928 | MainLoss:0.0928 | Alpha:0.4781 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9929\n",
      "Test | 122/16 | Loss:0.4207 | MainLoss:0.4207 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9283\n",
      "\n",
      "Epoch: [672 | 1000] LR: 0.000063\n",
      "Train | 16/16 | Loss:0.0937 | MainLoss:0.0937 | Alpha:0.4788 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4206 | MainLoss:0.4206 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9285\n",
      "\n",
      "Epoch: [673 | 1000] LR: 0.000063\n",
      "Train | 16/16 | Loss:0.0945 | MainLoss:0.0945 | Alpha:0.4773 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9933\n",
      "Test | 122/16 | Loss:0.4206 | MainLoss:0.4206 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9285\n",
      "\n",
      "Epoch: [674 | 1000] LR: 0.000063\n",
      "Train | 16/16 | Loss:0.1078 | MainLoss:0.1078 | Alpha:0.4743 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4210 | MainLoss:0.4210 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9285\n",
      "\n",
      "Epoch: [675 | 1000] LR: 0.000062\n",
      "Train | 16/16 | Loss:0.0906 | MainLoss:0.0906 | Alpha:0.4785 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4211 | MainLoss:0.4211 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [676 | 1000] LR: 0.000062\n",
      "Train | 16/16 | Loss:0.0829 | MainLoss:0.0829 | Alpha:0.4801 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4211 | MainLoss:0.4211 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9284\n",
      "\n",
      "Epoch: [677 | 1000] LR: 0.000062\n",
      "Train | 16/16 | Loss:0.0892 | MainLoss:0.0892 | Alpha:0.4789 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4213 | MainLoss:0.4213 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [678 | 1000] LR: 0.000061\n",
      "Train | 16/16 | Loss:0.0914 | MainLoss:0.0914 | Alpha:0.4794 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9929\n",
      "Test | 122/16 | Loss:0.4211 | MainLoss:0.4211 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9288\n",
      "\n",
      "Epoch: [679 | 1000] LR: 0.000061\n",
      "Train | 16/16 | Loss:0.1013 | MainLoss:0.1013 | Alpha:0.4760 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4210 | MainLoss:0.4210 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9285\n",
      "\n",
      "Epoch: [680 | 1000] LR: 0.000061\n",
      "Train | 16/16 | Loss:0.0846 | MainLoss:0.0846 | Alpha:0.4803 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4213 | MainLoss:0.4213 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [681 | 1000] LR: 0.000061\n",
      "Train | 16/16 | Loss:0.0978 | MainLoss:0.0978 | Alpha:0.4766 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4207 | MainLoss:0.4207 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [682 | 1000] LR: 0.000060\n",
      "Train | 16/16 | Loss:0.1110 | MainLoss:0.1110 | Alpha:0.4734 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4208 | MainLoss:0.4208 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9285\n",
      "\n",
      "Epoch: [683 | 1000] LR: 0.000060\n",
      "Train | 16/16 | Loss:0.1050 | MainLoss:0.1050 | Alpha:0.4753 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4208 | MainLoss:0.4208 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [684 | 1000] LR: 0.000060\n",
      "Train | 16/16 | Loss:0.0920 | MainLoss:0.0920 | Alpha:0.4784 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1083 | MainLoss:0.1083 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4210 | MainLoss:0.4210 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [685 | 1000] LR: 0.000059\n",
      "Train | 16/16 | Loss:0.0958 | MainLoss:0.0958 | Alpha:0.4771 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1083 | MainLoss:0.1083 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4211 | MainLoss:0.4211 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [686 | 1000] LR: 0.000059\n",
      "Train | 16/16 | Loss:0.0811 | MainLoss:0.0811 | Alpha:0.4811 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1083 | MainLoss:0.1083 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9933\n",
      "Test | 122/16 | Loss:0.4212 | MainLoss:0.4212 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [687 | 1000] LR: 0.000059\n",
      "Train | 16/16 | Loss:0.0803 | MainLoss:0.0803 | Alpha:0.4806 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4211 | MainLoss:0.4211 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [688 | 1000] LR: 0.000059\n",
      "Train | 16/16 | Loss:0.0895 | MainLoss:0.0895 | Alpha:0.4788 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9933\n",
      "Test | 122/16 | Loss:0.4210 | MainLoss:0.4210 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9290\n",
      "\n",
      "Epoch: [689 | 1000] LR: 0.000058\n",
      "Train | 16/16 | Loss:0.0986 | MainLoss:0.0986 | Alpha:0.4768 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4210 | MainLoss:0.4210 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9285\n",
      "\n",
      "Epoch: [690 | 1000] LR: 0.000058\n",
      "Train | 16/16 | Loss:0.0978 | MainLoss:0.0978 | Alpha:0.4764 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4209 | MainLoss:0.4209 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [691 | 1000] LR: 0.000058\n",
      "Train | 16/16 | Loss:0.0936 | MainLoss:0.0936 | Alpha:0.4779 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9929\n",
      "Test | 122/16 | Loss:0.4206 | MainLoss:0.4206 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9288\n",
      "\n",
      "Epoch: [692 | 1000] LR: 0.000057\n",
      "Train | 16/16 | Loss:0.0887 | MainLoss:0.0887 | Alpha:0.4787 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4207 | MainLoss:0.4207 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [693 | 1000] LR: 0.000057\n",
      "Train | 16/16 | Loss:0.0801 | MainLoss:0.0801 | Alpha:0.4808 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9933\n",
      "Test | 122/16 | Loss:0.4209 | MainLoss:0.4209 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9284\n",
      "\n",
      "Epoch: [694 | 1000] LR: 0.000057\n",
      "Train | 16/16 | Loss:0.0976 | MainLoss:0.0976 | Alpha:0.4772 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4208 | MainLoss:0.4208 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9289\n",
      "\n",
      "Epoch: [695 | 1000] LR: 0.000057\n",
      "Train | 16/16 | Loss:0.0920 | MainLoss:0.0920 | Alpha:0.4774 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9929\n",
      "Test | 122/16 | Loss:0.4208 | MainLoss:0.4208 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [696 | 1000] LR: 0.000056\n",
      "Train | 16/16 | Loss:0.0861 | MainLoss:0.0861 | Alpha:0.4797 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9933\n",
      "Test | 122/16 | Loss:0.4211 | MainLoss:0.4211 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9289\n",
      "\n",
      "Epoch: [697 | 1000] LR: 0.000056\n",
      "Train | 16/16 | Loss:0.0978 | MainLoss:0.0978 | Alpha:0.4768 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4213 | MainLoss:0.4213 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9288\n",
      "\n",
      "Epoch: [698 | 1000] LR: 0.000056\n",
      "Train | 16/16 | Loss:0.0980 | MainLoss:0.0980 | Alpha:0.4771 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4212 | MainLoss:0.4212 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9285\n",
      "\n",
      "Epoch: [699 | 1000] LR: 0.000055\n",
      "Train | 16/16 | Loss:0.1057 | MainLoss:0.1057 | Alpha:0.4747 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4210 | MainLoss:0.4210 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [700 | 1000] LR: 0.000055\n",
      "Train | 16/16 | Loss:0.0945 | MainLoss:0.0945 | Alpha:0.4779 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4210 | MainLoss:0.4210 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9289\n",
      "\n",
      "Epoch: [701 | 1000] LR: 0.000055\n",
      "Train | 16/16 | Loss:0.0943 | MainLoss:0.0943 | Alpha:0.4779 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4208 | MainLoss:0.4208 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [702 | 1000] LR: 0.000055\n",
      "Train | 16/16 | Loss:0.0978 | MainLoss:0.0978 | Alpha:0.4770 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9933\n",
      "Test | 122/16 | Loss:0.4206 | MainLoss:0.4206 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [703 | 1000] LR: 0.000054\n",
      "Train | 16/16 | Loss:0.0917 | MainLoss:0.0917 | Alpha:0.4785 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4206 | MainLoss:0.4206 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [704 | 1000] LR: 0.000054\n",
      "Train | 16/16 | Loss:0.0963 | MainLoss:0.0963 | Alpha:0.4770 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4204 | MainLoss:0.4204 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [705 | 1000] LR: 0.000054\n",
      "Train | 16/16 | Loss:0.1140 | MainLoss:0.1140 | Alpha:0.4727 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4203 | MainLoss:0.4203 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9289\n",
      "\n",
      "Epoch: [706 | 1000] LR: 0.000053\n",
      "Train | 16/16 | Loss:0.0979 | MainLoss:0.0979 | Alpha:0.4773 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4200 | MainLoss:0.4200 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [707 | 1000] LR: 0.000053\n",
      "Train | 16/16 | Loss:0.0858 | MainLoss:0.0858 | Alpha:0.4798 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [708 | 1000] LR: 0.000053\n",
      "Train | 16/16 | Loss:0.0904 | MainLoss:0.0904 | Alpha:0.4783 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4203 | MainLoss:0.4203 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9284\n",
      "\n",
      "Epoch: [709 | 1000] LR: 0.000053\n",
      "Train | 16/16 | Loss:0.0859 | MainLoss:0.0859 | Alpha:0.4791 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4205 | MainLoss:0.4205 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9284\n",
      "\n",
      "Epoch: [710 | 1000] LR: 0.000052\n",
      "Train | 16/16 | Loss:0.1053 | MainLoss:0.1053 | Alpha:0.4747 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4207 | MainLoss:0.4207 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9288\n",
      "\n",
      "Epoch: [711 | 1000] LR: 0.000052\n",
      "Train | 16/16 | Loss:0.0875 | MainLoss:0.0875 | Alpha:0.4800 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9933\n",
      "Test | 122/16 | Loss:0.4207 | MainLoss:0.4207 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [712 | 1000] LR: 0.000052\n",
      "Train | 16/16 | Loss:0.0933 | MainLoss:0.0933 | Alpha:0.4784 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4208 | MainLoss:0.4208 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9289\n",
      "\n",
      "Epoch: [713 | 1000] LR: 0.000052\n",
      "Train | 16/16 | Loss:0.0904 | MainLoss:0.0904 | Alpha:0.4788 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4208 | MainLoss:0.4208 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9288\n",
      "\n",
      "Epoch: [714 | 1000] LR: 0.000051\n",
      "Train | 16/16 | Loss:0.0990 | MainLoss:0.0990 | Alpha:0.4772 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4208 | MainLoss:0.4208 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9283\n",
      "\n",
      "Epoch: [715 | 1000] LR: 0.000051\n",
      "Train | 16/16 | Loss:0.1010 | MainLoss:0.1010 | Alpha:0.4760 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4208 | MainLoss:0.4208 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [716 | 1000] LR: 0.000051\n",
      "Train | 16/16 | Loss:0.0963 | MainLoss:0.0963 | Alpha:0.4771 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9929\n",
      "Test | 122/16 | Loss:0.4206 | MainLoss:0.4206 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9288\n",
      "\n",
      "Epoch: [717 | 1000] LR: 0.000050\n",
      "Train | 16/16 | Loss:0.0933 | MainLoss:0.0933 | Alpha:0.4778 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4206 | MainLoss:0.4206 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9288\n",
      "\n",
      "Epoch: [718 | 1000] LR: 0.000050\n",
      "Train | 16/16 | Loss:0.0954 | MainLoss:0.0954 | Alpha:0.4773 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4205 | MainLoss:0.4205 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [719 | 1000] LR: 0.000050\n",
      "Train | 16/16 | Loss:0.1105 | MainLoss:0.1105 | Alpha:0.4738 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4202 | MainLoss:0.4202 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [720 | 1000] LR: 0.000050\n",
      "Train | 16/16 | Loss:0.0895 | MainLoss:0.0895 | Alpha:0.4789 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9933\n",
      "Test | 122/16 | Loss:0.4204 | MainLoss:0.4204 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [721 | 1000] LR: 0.000049\n",
      "Train | 16/16 | Loss:0.0904 | MainLoss:0.0904 | Alpha:0.4786 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9933\n",
      "Test | 122/16 | Loss:0.4204 | MainLoss:0.4204 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9288\n",
      "\n",
      "Epoch: [722 | 1000] LR: 0.000049\n",
      "Train | 16/16 | Loss:0.0847 | MainLoss:0.0847 | Alpha:0.4795 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1083 | MainLoss:0.1083 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9933\n",
      "Test | 122/16 | Loss:0.4209 | MainLoss:0.4209 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9289\n",
      "\n",
      "Epoch: [723 | 1000] LR: 0.000049\n",
      "Train | 16/16 | Loss:0.0996 | MainLoss:0.0996 | Alpha:0.4772 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1083 | MainLoss:0.1083 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4206 | MainLoss:0.4206 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9288\n",
      "\n",
      "Epoch: [724 | 1000] LR: 0.000049\n",
      "Train | 16/16 | Loss:0.0931 | MainLoss:0.0931 | Alpha:0.4781 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4204 | MainLoss:0.4204 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9288\n",
      "\n",
      "Epoch: [725 | 1000] LR: 0.000048\n",
      "Train | 16/16 | Loss:0.1010 | MainLoss:0.1010 | Alpha:0.4758 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4206 | MainLoss:0.4206 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [726 | 1000] LR: 0.000048\n",
      "Train | 16/16 | Loss:0.1016 | MainLoss:0.1016 | Alpha:0.4754 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4207 | MainLoss:0.4207 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9288\n",
      "\n",
      "Epoch: [727 | 1000] LR: 0.000048\n",
      "Train | 16/16 | Loss:0.1056 | MainLoss:0.1056 | Alpha:0.4748 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4203 | MainLoss:0.4203 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [728 | 1000] LR: 0.000047\n",
      "Train | 16/16 | Loss:0.0975 | MainLoss:0.0975 | Alpha:0.4767 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4204 | MainLoss:0.4204 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [729 | 1000] LR: 0.000047\n",
      "Train | 16/16 | Loss:0.0918 | MainLoss:0.0918 | Alpha:0.4775 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4205 | MainLoss:0.4205 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9285\n",
      "\n",
      "Epoch: [730 | 1000] LR: 0.000047\n",
      "Train | 16/16 | Loss:0.1016 | MainLoss:0.1016 | Alpha:0.4760 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4205 | MainLoss:0.4205 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [731 | 1000] LR: 0.000047\n",
      "Train | 16/16 | Loss:0.0942 | MainLoss:0.0942 | Alpha:0.4779 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4203 | MainLoss:0.4203 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9285\n",
      "\n",
      "Epoch: [732 | 1000] LR: 0.000046\n",
      "Train | 16/16 | Loss:0.0959 | MainLoss:0.0959 | Alpha:0.4778 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4203 | MainLoss:0.4203 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [733 | 1000] LR: 0.000046\n",
      "Train | 16/16 | Loss:0.0966 | MainLoss:0.0966 | Alpha:0.4772 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4203 | MainLoss:0.4203 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9283\n",
      "\n",
      "Epoch: [734 | 1000] LR: 0.000046\n",
      "Train | 16/16 | Loss:0.0932 | MainLoss:0.0932 | Alpha:0.4783 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4204 | MainLoss:0.4204 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9284\n",
      "\n",
      "Epoch: [735 | 1000] LR: 0.000046\n",
      "Train | 16/16 | Loss:0.0970 | MainLoss:0.0970 | Alpha:0.4776 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4204 | MainLoss:0.4204 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [736 | 1000] LR: 0.000045\n",
      "Train | 16/16 | Loss:0.0923 | MainLoss:0.0923 | Alpha:0.4788 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4204 | MainLoss:0.4204 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [737 | 1000] LR: 0.000045\n",
      "Train | 16/16 | Loss:0.0874 | MainLoss:0.0874 | Alpha:0.4787 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4205 | MainLoss:0.4205 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9283\n",
      "\n",
      "Epoch: [738 | 1000] LR: 0.000045\n",
      "Train | 16/16 | Loss:0.0980 | MainLoss:0.0980 | Alpha:0.4764 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4205 | MainLoss:0.4205 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [739 | 1000] LR: 0.000045\n",
      "Train | 16/16 | Loss:0.0966 | MainLoss:0.0966 | Alpha:0.4772 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4204 | MainLoss:0.4204 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9288\n",
      "\n",
      "Epoch: [740 | 1000] LR: 0.000044\n",
      "Train | 16/16 | Loss:0.0981 | MainLoss:0.0981 | Alpha:0.4769 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4202 | MainLoss:0.4202 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9285\n",
      "\n",
      "Epoch: [741 | 1000] LR: 0.000044\n",
      "Train | 16/16 | Loss:0.1140 | MainLoss:0.1140 | Alpha:0.4727 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4203 | MainLoss:0.4203 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [742 | 1000] LR: 0.000044\n",
      "Train | 16/16 | Loss:0.0875 | MainLoss:0.0875 | Alpha:0.4789 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4204 | MainLoss:0.4204 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9283\n",
      "\n",
      "Epoch: [743 | 1000] LR: 0.000044\n",
      "Train | 16/16 | Loss:0.0922 | MainLoss:0.0922 | Alpha:0.4777 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4204 | MainLoss:0.4204 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [744 | 1000] LR: 0.000043\n",
      "Train | 16/16 | Loss:0.0949 | MainLoss:0.0949 | Alpha:0.4769 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9933\n",
      "Test | 122/16 | Loss:0.4205 | MainLoss:0.4205 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [745 | 1000] LR: 0.000043\n",
      "Train | 16/16 | Loss:0.0967 | MainLoss:0.0967 | Alpha:0.4764 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9933\n",
      "Test | 122/16 | Loss:0.4204 | MainLoss:0.4204 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9284\n",
      "\n",
      "Epoch: [746 | 1000] LR: 0.000043\n",
      "Train | 16/16 | Loss:0.0924 | MainLoss:0.0924 | Alpha:0.4777 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4205 | MainLoss:0.4205 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9285\n",
      "\n",
      "Epoch: [747 | 1000] LR: 0.000042\n",
      "Train | 16/16 | Loss:0.0836 | MainLoss:0.0836 | Alpha:0.4802 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4206 | MainLoss:0.4206 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [748 | 1000] LR: 0.000042\n",
      "Train | 16/16 | Loss:0.0821 | MainLoss:0.0821 | Alpha:0.4815 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4205 | MainLoss:0.4205 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9283\n",
      "\n",
      "Epoch: [749 | 1000] LR: 0.000042\n",
      "Train | 16/16 | Loss:0.1016 | MainLoss:0.1016 | Alpha:0.4764 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4205 | MainLoss:0.4205 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [750 | 1000] LR: 0.000042\n",
      "Train | 16/16 | Loss:0.0981 | MainLoss:0.0981 | Alpha:0.4764 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4206 | MainLoss:0.4206 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9289\n",
      "\n",
      "Epoch: [751 | 1000] LR: 0.000041\n",
      "Train | 16/16 | Loss:0.0990 | MainLoss:0.0990 | Alpha:0.4763 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9933\n",
      "Test | 122/16 | Loss:0.4207 | MainLoss:0.4207 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [752 | 1000] LR: 0.000041\n",
      "Train | 16/16 | Loss:0.0817 | MainLoss:0.0817 | Alpha:0.4806 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9929\n",
      "Test | 122/16 | Loss:0.4208 | MainLoss:0.4208 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [753 | 1000] LR: 0.000041\n",
      "Train | 16/16 | Loss:0.0932 | MainLoss:0.0932 | Alpha:0.4779 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4208 | MainLoss:0.4208 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [754 | 1000] LR: 0.000041\n",
      "Train | 16/16 | Loss:0.0923 | MainLoss:0.0923 | Alpha:0.4779 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4206 | MainLoss:0.4206 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [755 | 1000] LR: 0.000040\n",
      "Train | 16/16 | Loss:0.0980 | MainLoss:0.0980 | Alpha:0.4765 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4208 | MainLoss:0.4208 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9285\n",
      "\n",
      "Epoch: [756 | 1000] LR: 0.000040\n",
      "Train | 16/16 | Loss:0.0914 | MainLoss:0.0914 | Alpha:0.4792 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4209 | MainLoss:0.4209 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [757 | 1000] LR: 0.000040\n",
      "Train | 16/16 | Loss:0.1031 | MainLoss:0.1031 | Alpha:0.4761 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4208 | MainLoss:0.4208 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [758 | 1000] LR: 0.000040\n",
      "Train | 16/16 | Loss:0.0945 | MainLoss:0.0945 | Alpha:0.4775 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4207 | MainLoss:0.4207 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9285\n",
      "\n",
      "Epoch: [759 | 1000] LR: 0.000039\n",
      "Train | 16/16 | Loss:0.1038 | MainLoss:0.1038 | Alpha:0.4743 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9933\n",
      "Test | 122/16 | Loss:0.4208 | MainLoss:0.4208 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9285\n",
      "\n",
      "Epoch: [760 | 1000] LR: 0.000039\n",
      "Train | 16/16 | Loss:0.0889 | MainLoss:0.0889 | Alpha:0.4786 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4209 | MainLoss:0.4209 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [761 | 1000] LR: 0.000039\n",
      "Train | 16/16 | Loss:0.0993 | MainLoss:0.0993 | Alpha:0.4770 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4208 | MainLoss:0.4208 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9285\n",
      "\n",
      "Epoch: [762 | 1000] LR: 0.000039\n",
      "Train | 16/16 | Loss:0.0947 | MainLoss:0.0947 | Alpha:0.4776 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4208 | MainLoss:0.4208 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9285\n",
      "\n",
      "Epoch: [763 | 1000] LR: 0.000038\n",
      "Train | 16/16 | Loss:0.0855 | MainLoss:0.0855 | Alpha:0.4802 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9934\n",
      "Test | 122/16 | Loss:0.4209 | MainLoss:0.4209 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9285\n",
      "\n",
      "Epoch: [764 | 1000] LR: 0.000038\n",
      "Train | 16/16 | Loss:0.1037 | MainLoss:0.1037 | Alpha:0.4753 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9933\n",
      "Test | 122/16 | Loss:0.4207 | MainLoss:0.4207 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [765 | 1000] LR: 0.000038\n",
      "Train | 16/16 | Loss:0.0882 | MainLoss:0.0882 | Alpha:0.4793 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4208 | MainLoss:0.4208 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9285\n",
      "\n",
      "Epoch: [766 | 1000] LR: 0.000038\n",
      "Train | 16/16 | Loss:0.0923 | MainLoss:0.0923 | Alpha:0.4783 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9933\n",
      "Test | 122/16 | Loss:0.4206 | MainLoss:0.4206 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9288\n",
      "\n",
      "Epoch: [767 | 1000] LR: 0.000037\n",
      "Train | 16/16 | Loss:0.0959 | MainLoss:0.0959 | Alpha:0.4775 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4207 | MainLoss:0.4207 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9285\n",
      "\n",
      "Epoch: [768 | 1000] LR: 0.000037\n",
      "Train | 16/16 | Loss:0.0954 | MainLoss:0.0954 | Alpha:0.4771 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4207 | MainLoss:0.4207 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9284\n",
      "\n",
      "Epoch: [769 | 1000] LR: 0.000037\n",
      "Train | 16/16 | Loss:0.0951 | MainLoss:0.0951 | Alpha:0.4776 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4208 | MainLoss:0.4208 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9285\n",
      "\n",
      "Epoch: [770 | 1000] LR: 0.000037\n",
      "Train | 16/16 | Loss:0.0929 | MainLoss:0.0929 | Alpha:0.4778 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4207 | MainLoss:0.4207 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9288\n",
      "\n",
      "Epoch: [771 | 1000] LR: 0.000036\n",
      "Train | 16/16 | Loss:0.0977 | MainLoss:0.0977 | Alpha:0.4768 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4206 | MainLoss:0.4206 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [772 | 1000] LR: 0.000036\n",
      "Train | 16/16 | Loss:0.1028 | MainLoss:0.1028 | Alpha:0.4754 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4206 | MainLoss:0.4206 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9289\n",
      "\n",
      "Epoch: [773 | 1000] LR: 0.000036\n",
      "Train | 16/16 | Loss:0.0977 | MainLoss:0.0977 | Alpha:0.4776 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4206 | MainLoss:0.4206 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [774 | 1000] LR: 0.000036\n",
      "Train | 16/16 | Loss:0.1074 | MainLoss:0.1074 | Alpha:0.4742 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4204 | MainLoss:0.4204 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9285\n",
      "\n",
      "Epoch: [775 | 1000] LR: 0.000036\n",
      "Train | 16/16 | Loss:0.0907 | MainLoss:0.0907 | Alpha:0.4780 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4205 | MainLoss:0.4205 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9288\n",
      "\n",
      "Epoch: [776 | 1000] LR: 0.000035\n",
      "Train | 16/16 | Loss:0.1010 | MainLoss:0.1010 | Alpha:0.4764 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4205 | MainLoss:0.4205 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [777 | 1000] LR: 0.000035\n",
      "Train | 16/16 | Loss:0.1010 | MainLoss:0.1010 | Alpha:0.4761 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4204 | MainLoss:0.4204 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [778 | 1000] LR: 0.000035\n",
      "Train | 16/16 | Loss:0.0957 | MainLoss:0.0957 | Alpha:0.4771 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1084 | MainLoss:0.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4203 | MainLoss:0.4203 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9290\n",
      "\n",
      "Epoch: [779 | 1000] LR: 0.000035\n",
      "Train | 16/16 | Loss:0.0889 | MainLoss:0.0889 | Alpha:0.4787 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4202 | MainLoss:0.4202 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9289\n",
      "\n",
      "Epoch: [780 | 1000] LR: 0.000034\n",
      "Train | 16/16 | Loss:0.0903 | MainLoss:0.0903 | Alpha:0.4780 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9933\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9288\n",
      "\n",
      "Epoch: [781 | 1000] LR: 0.000034\n",
      "Train | 16/16 | Loss:0.0904 | MainLoss:0.0904 | Alpha:0.4789 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4198 | MainLoss:0.4198 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [782 | 1000] LR: 0.000034\n",
      "Train | 16/16 | Loss:0.0981 | MainLoss:0.0981 | Alpha:0.4768 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4199 | MainLoss:0.4199 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [783 | 1000] LR: 0.000034\n",
      "Train | 16/16 | Loss:0.0817 | MainLoss:0.0817 | Alpha:0.4807 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9288\n",
      "\n",
      "Epoch: [784 | 1000] LR: 0.000033\n",
      "Train | 16/16 | Loss:0.0937 | MainLoss:0.0937 | Alpha:0.4776 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9929\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9288\n",
      "\n",
      "Epoch: [785 | 1000] LR: 0.000033\n",
      "Train | 16/16 | Loss:0.1007 | MainLoss:0.1007 | Alpha:0.4760 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [786 | 1000] LR: 0.000033\n",
      "Train | 16/16 | Loss:0.0985 | MainLoss:0.0985 | Alpha:0.4774 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9933\n",
      "Test | 122/16 | Loss:0.4202 | MainLoss:0.4202 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9288\n",
      "\n",
      "Epoch: [787 | 1000] LR: 0.000033\n",
      "Train | 16/16 | Loss:0.0917 | MainLoss:0.0917 | Alpha:0.4783 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9933\n",
      "Test | 122/16 | Loss:0.4203 | MainLoss:0.4203 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [788 | 1000] LR: 0.000032\n",
      "Train | 16/16 | Loss:0.0906 | MainLoss:0.0906 | Alpha:0.4789 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4203 | MainLoss:0.4203 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9288\n",
      "\n",
      "Epoch: [789 | 1000] LR: 0.000032\n",
      "Train | 16/16 | Loss:0.0940 | MainLoss:0.0940 | Alpha:0.4780 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9933\n",
      "Test | 122/16 | Loss:0.4203 | MainLoss:0.4203 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9289\n",
      "\n",
      "Epoch: [790 | 1000] LR: 0.000032\n",
      "Train | 16/16 | Loss:0.0934 | MainLoss:0.0934 | Alpha:0.4780 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4202 | MainLoss:0.4202 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [791 | 1000] LR: 0.000032\n",
      "Train | 16/16 | Loss:0.0919 | MainLoss:0.0919 | Alpha:0.4790 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4202 | MainLoss:0.4202 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9285\n",
      "\n",
      "Epoch: [792 | 1000] LR: 0.000032\n",
      "Train | 16/16 | Loss:0.1052 | MainLoss:0.1052 | Alpha:0.4747 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9934\n",
      "Test | 122/16 | Loss:0.4202 | MainLoss:0.4202 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9284\n",
      "\n",
      "Epoch: [793 | 1000] LR: 0.000031\n",
      "Train | 16/16 | Loss:0.0934 | MainLoss:0.0934 | Alpha:0.4779 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4202 | MainLoss:0.4202 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [794 | 1000] LR: 0.000031\n",
      "Train | 16/16 | Loss:0.0938 | MainLoss:0.0938 | Alpha:0.4779 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4202 | MainLoss:0.4202 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [795 | 1000] LR: 0.000031\n",
      "Train | 16/16 | Loss:0.0955 | MainLoss:0.0955 | Alpha:0.4767 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4203 | MainLoss:0.4203 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9289\n",
      "\n",
      "Epoch: [796 | 1000] LR: 0.000031\n",
      "Train | 16/16 | Loss:0.0995 | MainLoss:0.0995 | Alpha:0.4763 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9288\n",
      "\n",
      "Epoch: [797 | 1000] LR: 0.000030\n",
      "Train | 16/16 | Loss:0.0909 | MainLoss:0.0909 | Alpha:0.4787 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9929\n",
      "Test | 122/16 | Loss:0.4202 | MainLoss:0.4202 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [798 | 1000] LR: 0.000030\n",
      "Train | 16/16 | Loss:0.1023 | MainLoss:0.1023 | Alpha:0.4761 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9933\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [799 | 1000] LR: 0.000030\n",
      "Train | 16/16 | Loss:0.1021 | MainLoss:0.1021 | Alpha:0.4761 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4200 | MainLoss:0.4200 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9283\n",
      "\n",
      "Epoch: [800 | 1000] LR: 0.000030\n",
      "Train | 16/16 | Loss:0.1045 | MainLoss:0.1045 | Alpha:0.4758 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9933\n",
      "Test | 122/16 | Loss:0.4199 | MainLoss:0.4199 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9288\n",
      "\n",
      "Epoch: [801 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.0927 | MainLoss:0.0927 | Alpha:0.4776 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9933\n",
      "Test | 122/16 | Loss:0.4199 | MainLoss:0.4199 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [802 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.0925 | MainLoss:0.0925 | Alpha:0.4781 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4199 | MainLoss:0.4199 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [803 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.0929 | MainLoss:0.0929 | Alpha:0.4779 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4199 | MainLoss:0.4199 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9283\n",
      "\n",
      "Epoch: [804 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.0988 | MainLoss:0.0988 | Alpha:0.4770 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4199 | MainLoss:0.4199 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [805 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.1017 | MainLoss:0.1017 | Alpha:0.4751 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4199 | MainLoss:0.4199 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [806 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.1084 | MainLoss:0.1084 | Alpha:0.4735 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4199 | MainLoss:0.4199 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9288\n",
      "\n",
      "Epoch: [807 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.0946 | MainLoss:0.0946 | Alpha:0.4777 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9933\n",
      "Test | 122/16 | Loss:0.4200 | MainLoss:0.4200 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [808 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.0904 | MainLoss:0.0904 | Alpha:0.4793 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9933\n",
      "Test | 122/16 | Loss:0.4200 | MainLoss:0.4200 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9285\n",
      "\n",
      "Epoch: [809 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.0832 | MainLoss:0.0832 | Alpha:0.4795 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4200 | MainLoss:0.4200 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [810 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.0878 | MainLoss:0.0878 | Alpha:0.4789 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4200 | MainLoss:0.4200 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9285\n",
      "\n",
      "Epoch: [811 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.0941 | MainLoss:0.0941 | Alpha:0.4779 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4200 | MainLoss:0.4200 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9285\n",
      "\n",
      "Epoch: [812 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.0926 | MainLoss:0.0926 | Alpha:0.4774 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4200 | MainLoss:0.4200 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9289\n",
      "\n",
      "Epoch: [813 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.0939 | MainLoss:0.0939 | Alpha:0.4779 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9933\n",
      "Test | 122/16 | Loss:0.4200 | MainLoss:0.4200 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [814 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.0949 | MainLoss:0.0949 | Alpha:0.4775 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9933\n",
      "Test | 122/16 | Loss:0.4200 | MainLoss:0.4200 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9285\n",
      "\n",
      "Epoch: [815 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.0885 | MainLoss:0.0885 | Alpha:0.4785 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9933\n",
      "Test | 122/16 | Loss:0.4200 | MainLoss:0.4200 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9285\n",
      "\n",
      "Epoch: [816 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.0964 | MainLoss:0.0964 | Alpha:0.4770 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4200 | MainLoss:0.4200 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [817 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.1003 | MainLoss:0.1003 | Alpha:0.4760 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4200 | MainLoss:0.4200 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [818 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.0981 | MainLoss:0.0981 | Alpha:0.4765 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9933\n",
      "Test | 122/16 | Loss:0.4200 | MainLoss:0.4200 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9291\n",
      "\n",
      "Epoch: [819 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.0903 | MainLoss:0.0903 | Alpha:0.4788 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4200 | MainLoss:0.4200 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9288\n",
      "\n",
      "Epoch: [820 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.0943 | MainLoss:0.0943 | Alpha:0.4781 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4200 | MainLoss:0.4200 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9285\n",
      "\n",
      "Epoch: [821 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.1026 | MainLoss:0.1026 | Alpha:0.4762 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4200 | MainLoss:0.4200 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9284\n",
      "\n",
      "Epoch: [822 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.1017 | MainLoss:0.1017 | Alpha:0.4761 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9934\n",
      "Test | 122/16 | Loss:0.4200 | MainLoss:0.4200 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [823 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.1014 | MainLoss:0.1014 | Alpha:0.4757 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4200 | MainLoss:0.4200 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9284\n",
      "\n",
      "Epoch: [824 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0965 | MainLoss:0.0965 | Alpha:0.4775 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4200 | MainLoss:0.4200 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [825 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0933 | MainLoss:0.0933 | Alpha:0.4781 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4200 | MainLoss:0.4200 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9285\n",
      "\n",
      "Epoch: [826 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0939 | MainLoss:0.0939 | Alpha:0.4774 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4200 | MainLoss:0.4200 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [827 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0913 | MainLoss:0.0913 | Alpha:0.4782 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4200 | MainLoss:0.4200 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9288\n",
      "\n",
      "Epoch: [828 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0963 | MainLoss:0.0963 | Alpha:0.4774 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4200 | MainLoss:0.4200 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [829 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0939 | MainLoss:0.0939 | Alpha:0.4780 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9933\n",
      "Test | 122/16 | Loss:0.4200 | MainLoss:0.4200 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9289\n",
      "\n",
      "Epoch: [830 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.1034 | MainLoss:0.1034 | Alpha:0.4752 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4200 | MainLoss:0.4200 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9288\n",
      "\n",
      "Epoch: [831 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0922 | MainLoss:0.0922 | Alpha:0.4784 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4200 | MainLoss:0.4200 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9288\n",
      "\n",
      "Epoch: [832 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0988 | MainLoss:0.0988 | Alpha:0.4763 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4200 | MainLoss:0.4200 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [833 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0940 | MainLoss:0.0940 | Alpha:0.4773 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4200 | MainLoss:0.4200 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9288\n",
      "\n",
      "Epoch: [834 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0909 | MainLoss:0.0909 | Alpha:0.4781 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4200 | MainLoss:0.4200 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [835 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0941 | MainLoss:0.0941 | Alpha:0.4774 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4200 | MainLoss:0.4200 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9284\n",
      "\n",
      "Epoch: [836 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0945 | MainLoss:0.0945 | Alpha:0.4778 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4200 | MainLoss:0.4200 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9288\n",
      "\n",
      "Epoch: [837 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0919 | MainLoss:0.0919 | Alpha:0.4784 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4200 | MainLoss:0.4200 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [838 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.1007 | MainLoss:0.1007 | Alpha:0.4764 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4200 | MainLoss:0.4200 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9285\n",
      "\n",
      "Epoch: [839 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0885 | MainLoss:0.0885 | Alpha:0.4795 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4200 | MainLoss:0.4200 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9283\n",
      "\n",
      "Epoch: [840 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.1007 | MainLoss:0.1007 | Alpha:0.4765 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4200 | MainLoss:0.4200 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [841 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.1114 | MainLoss:0.1114 | Alpha:0.4736 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4200 | MainLoss:0.4200 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9289\n",
      "\n",
      "Epoch: [842 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.1095 | MainLoss:0.1095 | Alpha:0.4732 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4200 | MainLoss:0.4200 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9288\n",
      "\n",
      "Epoch: [843 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0821 | MainLoss:0.0821 | Alpha:0.4803 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4200 | MainLoss:0.4200 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9285\n",
      "\n",
      "Epoch: [844 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0978 | MainLoss:0.0978 | Alpha:0.4770 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4200 | MainLoss:0.4200 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9283\n",
      "\n",
      "Epoch: [845 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0975 | MainLoss:0.0975 | Alpha:0.4770 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4200 | MainLoss:0.4200 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [846 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0813 | MainLoss:0.0813 | Alpha:0.4810 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4200 | MainLoss:0.4200 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [847 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.1011 | MainLoss:0.1011 | Alpha:0.4758 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9933\n",
      "Test | 122/16 | Loss:0.4200 | MainLoss:0.4200 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9288\n",
      "\n",
      "Epoch: [848 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0951 | MainLoss:0.0951 | Alpha:0.4769 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4200 | MainLoss:0.4200 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9284\n",
      "\n",
      "Epoch: [849 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0963 | MainLoss:0.0963 | Alpha:0.4771 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4200 | MainLoss:0.4200 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9288\n",
      "\n",
      "Epoch: [850 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0876 | MainLoss:0.0876 | Alpha:0.4793 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9933\n",
      "Test | 122/16 | Loss:0.4200 | MainLoss:0.4200 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [851 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0846 | MainLoss:0.0846 | Alpha:0.4807 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9933\n",
      "Test | 122/16 | Loss:0.4200 | MainLoss:0.4200 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9288\n",
      "\n",
      "Epoch: [852 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0839 | MainLoss:0.0839 | Alpha:0.4795 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4200 | MainLoss:0.4200 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9288\n",
      "\n",
      "Epoch: [853 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.1050 | MainLoss:0.1050 | Alpha:0.4753 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4200 | MainLoss:0.4200 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9288\n",
      "\n",
      "Epoch: [854 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.1074 | MainLoss:0.1074 | Alpha:0.4742 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4200 | MainLoss:0.4200 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [855 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0994 | MainLoss:0.0994 | Alpha:0.4766 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9933\n",
      "Test | 122/16 | Loss:0.4200 | MainLoss:0.4200 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [856 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0868 | MainLoss:0.0868 | Alpha:0.4790 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9933\n",
      "Test | 122/16 | Loss:0.4200 | MainLoss:0.4200 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [857 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0938 | MainLoss:0.0938 | Alpha:0.4770 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4200 | MainLoss:0.4200 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [858 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0918 | MainLoss:0.0918 | Alpha:0.4784 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4200 | MainLoss:0.4200 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9289\n",
      "\n",
      "Epoch: [859 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0901 | MainLoss:0.0901 | Alpha:0.4790 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4200 | MainLoss:0.4200 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9284\n",
      "\n",
      "Epoch: [860 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0882 | MainLoss:0.0882 | Alpha:0.4781 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [861 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0961 | MainLoss:0.0961 | Alpha:0.4772 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9929\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [862 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0986 | MainLoss:0.0986 | Alpha:0.4764 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [863 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0844 | MainLoss:0.0844 | Alpha:0.4799 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9288\n",
      "\n",
      "Epoch: [864 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0911 | MainLoss:0.0911 | Alpha:0.4780 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9285\n",
      "\n",
      "Epoch: [865 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.1081 | MainLoss:0.1081 | Alpha:0.4743 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4200 | MainLoss:0.4200 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [866 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0980 | MainLoss:0.0980 | Alpha:0.4767 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4200 | MainLoss:0.4200 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [867 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0883 | MainLoss:0.0883 | Alpha:0.4795 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9285\n",
      "\n",
      "Epoch: [868 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.1099 | MainLoss:0.1099 | Alpha:0.4740 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9285\n",
      "\n",
      "Epoch: [869 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0814 | MainLoss:0.0814 | Alpha:0.4808 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9285\n",
      "\n",
      "Epoch: [870 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0912 | MainLoss:0.0912 | Alpha:0.4777 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9933\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [871 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0952 | MainLoss:0.0952 | Alpha:0.4776 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [872 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.0983 | MainLoss:0.0983 | Alpha:0.4763 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9933\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9288\n",
      "\n",
      "Epoch: [873 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.1057 | MainLoss:0.1057 | Alpha:0.4738 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9933\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [874 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.1092 | MainLoss:0.1092 | Alpha:0.4744 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9285\n",
      "\n",
      "Epoch: [875 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.1002 | MainLoss:0.1002 | Alpha:0.4762 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9290\n",
      "\n",
      "Epoch: [876 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.1063 | MainLoss:0.1063 | Alpha:0.4749 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [877 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.1011 | MainLoss:0.1011 | Alpha:0.4759 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9933\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [878 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0989 | MainLoss:0.0989 | Alpha:0.4766 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9933\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9289\n",
      "\n",
      "Epoch: [879 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0980 | MainLoss:0.0980 | Alpha:0.4769 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9933\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9288\n",
      "\n",
      "Epoch: [880 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0949 | MainLoss:0.0949 | Alpha:0.4780 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9285\n",
      "\n",
      "Epoch: [881 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0934 | MainLoss:0.0934 | Alpha:0.4786 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [882 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0905 | MainLoss:0.0905 | Alpha:0.4790 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [883 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0918 | MainLoss:0.0918 | Alpha:0.4782 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [884 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0893 | MainLoss:0.0893 | Alpha:0.4789 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9284\n",
      "\n",
      "Epoch: [885 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.1066 | MainLoss:0.1066 | Alpha:0.4742 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [886 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0916 | MainLoss:0.0916 | Alpha:0.4784 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [887 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0994 | MainLoss:0.0994 | Alpha:0.4776 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [888 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0877 | MainLoss:0.0877 | Alpha:0.4793 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [889 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0932 | MainLoss:0.0932 | Alpha:0.4778 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9288\n",
      "\n",
      "Epoch: [890 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0995 | MainLoss:0.0995 | Alpha:0.4759 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [891 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0858 | MainLoss:0.0858 | Alpha:0.4801 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [892 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0870 | MainLoss:0.0870 | Alpha:0.4791 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [893 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0872 | MainLoss:0.0872 | Alpha:0.4796 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9284\n",
      "\n",
      "Epoch: [894 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.1041 | MainLoss:0.1041 | Alpha:0.4758 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [895 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0912 | MainLoss:0.0912 | Alpha:0.4791 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9290\n",
      "\n",
      "Epoch: [896 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0924 | MainLoss:0.0924 | Alpha:0.4781 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9933\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [897 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0930 | MainLoss:0.0930 | Alpha:0.4782 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [898 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0905 | MainLoss:0.0905 | Alpha:0.4782 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9288\n",
      "\n",
      "Epoch: [899 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0951 | MainLoss:0.0951 | Alpha:0.4773 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9289\n",
      "\n",
      "Epoch: [900 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0958 | MainLoss:0.0958 | Alpha:0.4779 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9284\n",
      "\n",
      "Epoch: [901 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.1093 | MainLoss:0.1093 | Alpha:0.4745 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [902 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0883 | MainLoss:0.0883 | Alpha:0.4789 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [903 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0927 | MainLoss:0.0927 | Alpha:0.4786 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9933\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9288\n",
      "\n",
      "Epoch: [904 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0969 | MainLoss:0.0969 | Alpha:0.4775 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [905 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0996 | MainLoss:0.0996 | Alpha:0.4770 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [906 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0882 | MainLoss:0.0882 | Alpha:0.4795 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [907 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0974 | MainLoss:0.0974 | Alpha:0.4771 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9289\n",
      "\n",
      "Epoch: [908 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0872 | MainLoss:0.0872 | Alpha:0.4794 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9288\n",
      "\n",
      "Epoch: [909 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0923 | MainLoss:0.0923 | Alpha:0.4785 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [910 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0907 | MainLoss:0.0907 | Alpha:0.4789 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [911 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.1023 | MainLoss:0.1023 | Alpha:0.4757 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9284\n",
      "\n",
      "Epoch: [912 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0973 | MainLoss:0.0973 | Alpha:0.4767 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9285\n",
      "\n",
      "Epoch: [913 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0900 | MainLoss:0.0900 | Alpha:0.4787 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9285\n",
      "\n",
      "Epoch: [914 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0964 | MainLoss:0.0964 | Alpha:0.4763 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [915 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.1029 | MainLoss:0.1029 | Alpha:0.4755 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9288\n",
      "\n",
      "Epoch: [916 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0860 | MainLoss:0.0860 | Alpha:0.4800 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9288\n",
      "\n",
      "Epoch: [917 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.1011 | MainLoss:0.1011 | Alpha:0.4763 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [918 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0928 | MainLoss:0.0928 | Alpha:0.4778 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9933\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9288\n",
      "\n",
      "Epoch: [919 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.1017 | MainLoss:0.1017 | Alpha:0.4767 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9933\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9289\n",
      "\n",
      "Epoch: [920 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.1125 | MainLoss:0.1125 | Alpha:0.4739 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [921 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.1015 | MainLoss:0.1015 | Alpha:0.4761 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9285\n",
      "\n",
      "Epoch: [922 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0983 | MainLoss:0.0983 | Alpha:0.4771 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [923 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0872 | MainLoss:0.0872 | Alpha:0.4797 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [924 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.1041 | MainLoss:0.1041 | Alpha:0.4760 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9934\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [925 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.1012 | MainLoss:0.1012 | Alpha:0.4762 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9284\n",
      "\n",
      "Epoch: [926 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0857 | MainLoss:0.0857 | Alpha:0.4797 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9284\n",
      "\n",
      "Epoch: [927 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0941 | MainLoss:0.0941 | Alpha:0.4779 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9285\n",
      "\n",
      "Epoch: [928 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0906 | MainLoss:0.0906 | Alpha:0.4794 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9933\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [929 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.1048 | MainLoss:0.1048 | Alpha:0.4753 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [930 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0969 | MainLoss:0.0969 | Alpha:0.4766 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9933\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9285\n",
      "\n",
      "Epoch: [931 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0844 | MainLoss:0.0844 | Alpha:0.4805 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9288\n",
      "\n",
      "Epoch: [932 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0866 | MainLoss:0.0866 | Alpha:0.4790 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9285\n",
      "\n",
      "Epoch: [933 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.1047 | MainLoss:0.1047 | Alpha:0.4761 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9289\n",
      "\n",
      "Epoch: [934 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0961 | MainLoss:0.0961 | Alpha:0.4776 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [935 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0916 | MainLoss:0.0916 | Alpha:0.4785 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [936 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0956 | MainLoss:0.0956 | Alpha:0.4773 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9933\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [937 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0875 | MainLoss:0.0875 | Alpha:0.4800 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9285\n",
      "\n",
      "Epoch: [938 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0944 | MainLoss:0.0944 | Alpha:0.4778 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9285\n",
      "\n",
      "Epoch: [939 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.1078 | MainLoss:0.1078 | Alpha:0.4755 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9933\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9288\n",
      "\n",
      "Epoch: [940 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0908 | MainLoss:0.0908 | Alpha:0.4784 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9288\n",
      "\n",
      "Epoch: [941 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0950 | MainLoss:0.0950 | Alpha:0.4774 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [942 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0881 | MainLoss:0.0881 | Alpha:0.4786 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9283\n",
      "\n",
      "Epoch: [943 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0860 | MainLoss:0.0860 | Alpha:0.4794 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [944 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0968 | MainLoss:0.0968 | Alpha:0.4773 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9285\n",
      "\n",
      "Epoch: [945 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0895 | MainLoss:0.0895 | Alpha:0.4780 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9933\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9285\n",
      "\n",
      "Epoch: [946 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0938 | MainLoss:0.0938 | Alpha:0.4773 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [947 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0932 | MainLoss:0.0932 | Alpha:0.4785 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9285\n",
      "\n",
      "Epoch: [948 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.1153 | MainLoss:0.1153 | Alpha:0.4730 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9285\n",
      "\n",
      "Epoch: [949 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0934 | MainLoss:0.0934 | Alpha:0.4773 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9285\n",
      "\n",
      "Epoch: [950 | 1000] LR: 0.000001\n",
      "Train | 16/16 | Loss:0.0844 | MainLoss:0.0844 | Alpha:0.4797 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9285\n",
      "\n",
      "Epoch: [951 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.1020 | MainLoss:0.1020 | Alpha:0.4762 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9933\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9288\n",
      "\n",
      "Epoch: [952 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0992 | MainLoss:0.0992 | Alpha:0.4763 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9933\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [953 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0996 | MainLoss:0.0996 | Alpha:0.4765 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9288\n",
      "\n",
      "Epoch: [954 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0905 | MainLoss:0.0905 | Alpha:0.4785 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9934\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9288\n",
      "\n",
      "Epoch: [955 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0971 | MainLoss:0.0971 | Alpha:0.4770 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9933\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9285\n",
      "\n",
      "Epoch: [956 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0978 | MainLoss:0.0978 | Alpha:0.4770 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9289\n",
      "\n",
      "Epoch: [957 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.1048 | MainLoss:0.1048 | Alpha:0.4750 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9933\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [958 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.1017 | MainLoss:0.1017 | Alpha:0.4753 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9290\n",
      "\n",
      "Epoch: [959 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0906 | MainLoss:0.0906 | Alpha:0.4789 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9933\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [960 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0923 | MainLoss:0.0923 | Alpha:0.4783 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9285\n",
      "\n",
      "Epoch: [961 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0849 | MainLoss:0.0849 | Alpha:0.4802 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9289\n",
      "\n",
      "Epoch: [962 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0950 | MainLoss:0.0950 | Alpha:0.4785 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9288\n",
      "\n",
      "Epoch: [963 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0990 | MainLoss:0.0990 | Alpha:0.4771 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [964 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0998 | MainLoss:0.0998 | Alpha:0.4763 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9285\n",
      "\n",
      "Epoch: [965 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0875 | MainLoss:0.0875 | Alpha:0.4794 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9935\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9285\n",
      "\n",
      "Epoch: [966 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0956 | MainLoss:0.0956 | Alpha:0.4772 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9933\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [967 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0973 | MainLoss:0.0973 | Alpha:0.4771 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9284\n",
      "\n",
      "Epoch: [968 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.1071 | MainLoss:0.1071 | Alpha:0.4750 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9288\n",
      "\n",
      "Epoch: [969 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0945 | MainLoss:0.0945 | Alpha:0.4776 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9933\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9288\n",
      "\n",
      "Epoch: [970 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0881 | MainLoss:0.0881 | Alpha:0.4789 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [971 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0950 | MainLoss:0.0950 | Alpha:0.4772 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [972 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0757 | MainLoss:0.0757 | Alpha:0.4816 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9285\n",
      "\n",
      "Epoch: [973 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.1028 | MainLoss:0.1028 | Alpha:0.4763 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9928\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9289\n",
      "\n",
      "Epoch: [974 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0966 | MainLoss:0.0966 | Alpha:0.4772 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9289\n",
      "\n",
      "Epoch: [975 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0865 | MainLoss:0.0865 | Alpha:0.4793 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [976 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0955 | MainLoss:0.0955 | Alpha:0.4774 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9288\n",
      "\n",
      "Epoch: [977 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0798 | MainLoss:0.0798 | Alpha:0.4814 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9933\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9284\n",
      "\n",
      "Epoch: [978 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0981 | MainLoss:0.0981 | Alpha:0.4767 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9284\n",
      "\n",
      "Epoch: [979 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0933 | MainLoss:0.0933 | Alpha:0.4782 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [980 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0972 | MainLoss:0.0972 | Alpha:0.4773 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [981 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0893 | MainLoss:0.0893 | Alpha:0.4785 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [982 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0951 | MainLoss:0.0951 | Alpha:0.4779 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [983 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0889 | MainLoss:0.0889 | Alpha:0.4796 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9285\n",
      "\n",
      "Epoch: [984 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0889 | MainLoss:0.0889 | Alpha:0.4792 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9284\n",
      "\n",
      "Epoch: [985 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.1104 | MainLoss:0.1104 | Alpha:0.4738 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [986 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.1011 | MainLoss:0.1011 | Alpha:0.4758 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9287\n",
      "\n",
      "Epoch: [987 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0987 | MainLoss:0.0987 | Alpha:0.4766 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [988 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0890 | MainLoss:0.0890 | Alpha:0.4789 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9934\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9289\n",
      "\n",
      "Epoch: [989 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0932 | MainLoss:0.0932 | Alpha:0.4784 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [990 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0889 | MainLoss:0.0889 | Alpha:0.4792 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9930\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9285\n",
      "\n",
      "Epoch: [991 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0874 | MainLoss:0.0874 | Alpha:0.4788 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9284\n",
      "\n",
      "Epoch: [992 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.1001 | MainLoss:0.1001 | Alpha:0.4768 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9933\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [993 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0971 | MainLoss:0.0971 | Alpha:0.4770 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9283\n",
      "\n",
      "Epoch: [994 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0925 | MainLoss:0.0925 | Alpha:0.4783 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9286\n",
      "\n",
      "Epoch: [995 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0901 | MainLoss:0.0901 | Alpha:0.4784 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9933\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9285\n",
      "\n",
      "Epoch: [996 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.1001 | MainLoss:0.1001 | Alpha:0.4767 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9933\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9288\n",
      "\n",
      "Epoch: [997 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0956 | MainLoss:0.0956 | Alpha:0.4776 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9288\n",
      "\n",
      "Epoch: [998 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0868 | MainLoss:0.0868 | Alpha:0.4793 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9934\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9288\n",
      "\n",
      "Epoch: [999 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0898 | MainLoss:0.0898 | Alpha:0.4783 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9931\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9289\n",
      "\n",
      "Epoch: [1000 | 1000] LR: 0.000000\n",
      "Train | 16/16 | Loss:0.0936 | MainLoss:0.0936 | Alpha:0.4773 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 32/16 | Loss:0.1085 | MainLoss:0.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9932\n",
      "Test | 122/16 | Loss:0.4201 | MainLoss:0.4201 | SPLoss:0.0000 | CLSLoss:0.0000 | AUROC:0.9287\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(start_epoch, epochs):\n",
    "    state['lr'] = optimizer.state_dict()['param_groups'][0]['lr']\n",
    "\n",
    "    print('\\nEpoch: [%d | %d] LR: %f' % (epoch + 1, epochs, state['lr']))\n",
    "    \n",
    "    train_loss, train_auroc = train(train_loader, teacher_model, student_model, criterion, optimizer, epoch, use_cuda)\n",
    "    test_loss, test_auroc = test(val_target_loader, student_model, criterion, epoch, use_cuda)\n",
    "    source_loss, source_auroc = test(val_source_loader, student_model, criterion, epoch, use_cuda)\n",
    "\n",
    "\n",
    "    logger.append([state['lr'], train_loss, test_loss,  source_loss, train_auroc, test_auroc, source_auroc])\n",
    "    is_best = test_auroc+source_auroc > best_acc\n",
    "    best_acc = max(test_auroc+source_auroc, best_acc)\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'state_dict' : student_model.state_dict(),\n",
    "        'best_acc': best_acc,\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    }, is_best, checkpoint=checkpoint)\n",
    "    scheduler_warmup.step()\n",
    "    scheduler.step()\n",
    "    \n",
    "    if (epoch+1)%500 == 0:\n",
    "        teacher_model.load_state_dict(student_model.state_dict())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
