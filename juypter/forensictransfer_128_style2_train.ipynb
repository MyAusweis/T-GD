{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "import os, shutil\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "# torch.autograd.set_detect_anomaly(True)\n",
    "import numpy as np\n",
    "# declare batch size for act function\n",
    "\n",
    "\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(0) \n",
    "\n",
    "batch_size = 1148"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU device 1: True\n"
     ]
    }
   ],
   "source": [
    "# GPU Device\n",
    "gpu_id = 1\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(\"GPU device %d:\" %(gpu_id), use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_dir = '/home/kim1'\n",
    "data_dir = '/media/data2/dataset/GAN_ImageData/StyleGAN2_256/'\n",
    "d_dir = home_dir+data_dir\n",
    "\n",
    "resume = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, checkpoint='checkpoint', filename='checkpoint.pth.tar'):\n",
    "    filepath = os.path.join(checkpoint, filename)\n",
    "    torch.save(state, filepath)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filepath, os.path.join(checkpoint, 'model_best.pth.tar'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = './log/style2/128/foresic/aug' # dir\n",
    "if not os.path.isdir(checkpoint):\n",
    "    os.makedirs(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoencoder part\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        #should change channel 3\n",
    "        self.conv_1_1 = nn.Conv2d(in_channels=3,out_channels=8,kernel_size=3,padding=1)\n",
    "        self.relu_1_2 = nn.ReLU(True)\n",
    "            \n",
    "        self.conv_2_1 = nn.Conv2d(in_channels=8,out_channels=16,kernel_size=3,stride=2,padding=1)\n",
    "        self.bn_2_2 = nn.BatchNorm2d(16)\n",
    "        self.relu_2_3 = nn.ReLU(True)\n",
    "        \n",
    "        self.conv_3_1 = nn.Conv2d(in_channels=16,out_channels=32,kernel_size=3,stride=2,padding=1)\n",
    "        self.bn_3_2 = nn.BatchNorm2d(32)\n",
    "        self.relu_3_3 = nn.ReLU(True)\n",
    "        \n",
    "        self.conv_4_1=nn.Conv2d(in_channels=32,out_channels=64,kernel_size=3,stride=2,padding=1)\n",
    "        self.bn_4_2=nn.BatchNorm2d(64)\n",
    "        self.relu_4_3=nn.ReLU(True)\n",
    "        \n",
    "        self.conv_5_1 = nn.Conv2d(in_channels=64,out_channels=128,kernel_size=3,stride=2,padding=1)\n",
    "        self.bn_5_2 =nn.BatchNorm2d(128)\n",
    "        self.relu_5_3 = nn.ReLU(True)\n",
    "        \n",
    "        ## decoder\n",
    "        self.upsample_6_1 = nn.Upsample(scale_factor=2,mode='nearest')\n",
    "        self.convtranspose_6_2 = nn.Conv2d(in_channels=128,out_channels=64,kernel_size=3,padding=1)\n",
    "        self.bn_6_3 = nn.BatchNorm2d(64)\n",
    "        self.relu_6_4 = nn.ReLU(True)\n",
    "        \n",
    "        self.upsample_7_1 = nn.Upsample(scale_factor=2,mode='nearest')\n",
    "        self.convtranspose_7_2 = nn.Conv2d(in_channels=64,out_channels=32,kernel_size=3,padding=1)\n",
    "        self.bn_7_3 = nn.BatchNorm2d(32)\n",
    "        self.relu_7_4 = nn.ReLU(True)\n",
    "        \n",
    "        self.upsample_8_1 = nn.Upsample(scale_factor=2,mode='nearest')\n",
    "        self.convtranspose_8_2 = nn.Conv2d(in_channels=32,out_channels=16,kernel_size=3,padding=1)\n",
    "        self.bn_8_3 = nn.BatchNorm2d(16)\n",
    "        self.relu_8_4 = nn.ReLU(True)\n",
    "        \n",
    "        self.upsample_9_1 = nn.Upsample(scale_factor=2,mode='nearest')\n",
    "        self.convtranspose_9_2 = nn.Conv2d(in_channels=16,out_channels=8,kernel_size=3,padding=1)\n",
    "        self.bn_9_3 = nn.BatchNorm2d(8)\n",
    "        self.relu_9_4 = nn.ReLU(True)\n",
    "        #should change channel 6\n",
    "        # 혹시 안되면\n",
    "        # self.conv_10_1 = nn.ConvTranspose2d(in_channels=8,out_channels=3,kernel_size=3,padding=1)\n",
    "        #이걸로 마지막 conv 계층을 바꿔주세요 \n",
    "        self.conv_10_1 = nn.Conv2d(in_channels=8,out_channels=3,kernel_size=3,padding=1)\n",
    "        self.tanh_10_2=nn.Tanh()\n",
    "        \n",
    "        # no masking no *0 or assign value zero not done .        \n",
    "        \n",
    "    def forward(self, x,label):\n",
    "        x1 = self.conv_1_1(x)\n",
    "        x2 = self.relu_1_2(x1)\n",
    "\n",
    "        x3 = self.conv_2_1(x2)\n",
    "        x4 = self.bn_2_2(x3)\n",
    "        x5 = self.relu_2_3(x4)\n",
    "\n",
    "        \n",
    "        x6 = self.conv_3_1(x5)\n",
    "        x7 = self.bn_3_2(x6)\n",
    "        x8 = self.relu_3_3(x7)\n",
    "\n",
    "        \n",
    "        x9 = self.conv_4_1(x8)\n",
    "        x10 = self.bn_4_2(x9)\n",
    "        x11 = self.relu_4_3(x10)\n",
    "\n",
    "        \n",
    "        x12 = self.conv_5_1(x11)\n",
    "        x13 = self.bn_5_2(x12)\n",
    "        x14 = self.relu_5_3(x13)\n",
    "        \n",
    "        act = x14.clone()\n",
    "        dep = x14.clone()\n",
    "\n",
    "        # Selection block setting zero values based on label\n",
    "        # [:64] -> fake data latent space \n",
    "        # [64:] -> real data latent space\n",
    "        # 0->fake 1 ->real\n",
    "        # 15 15\n",
    "        A = torch.nn.Parameter(torch.zeros(64,8,8))\n",
    "        for i in range(len(label)):\n",
    "            #real \n",
    "            if label[i].item():\n",
    "                #setting fake latent space into zero\n",
    "                dep[i,:64] = A\n",
    "            else:\n",
    "                dep[i,64:]=A\n",
    "                \n",
    "        x15 = self.upsample_6_1(dep) \n",
    "        x16 = self.convtranspose_6_2(x15)\n",
    "        x17 = self.bn_6_3(x16)\n",
    "        x18 = self.relu_6_4(x17) \n",
    "        x19 = self.upsample_7_1(x18)\n",
    "        x20 = self.convtranspose_7_2(x19)\n",
    "        x21 = self.bn_7_3(x20)\n",
    "        x22 = self.relu_7_4(x21)\n",
    "        x23 = self.upsample_8_1(x22)\n",
    "        x24 = self.convtranspose_8_2(x23)\n",
    "        x25 = self.bn_8_3(x24)\n",
    "        x26 = self.relu_8_4(x25)\n",
    "        x27 = self.upsample_9_1(x26)\n",
    "        x28 = self.convtranspose_9_2(x27) \n",
    "        x29 = self.bn_9_3(x28)\n",
    "        x30 = self.relu_9_4(x29)\n",
    "        x31 = self.conv_10_1(x30)\n",
    "        x32 = self.tanh_10_2(x31)\n",
    "\n",
    "        return  x32 , act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Autoencoder(\n",
       "  (conv_1_1): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu_1_2): ReLU(inplace=True)\n",
       "  (conv_2_1): Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (bn_2_2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu_2_3): ReLU(inplace=True)\n",
       "  (conv_3_1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (bn_3_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu_3_3): ReLU(inplace=True)\n",
       "  (conv_4_1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (bn_4_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu_4_3): ReLU(inplace=True)\n",
       "  (conv_5_1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (bn_5_2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu_5_3): ReLU(inplace=True)\n",
       "  (upsample_6_1): Upsample(scale_factor=2.0, mode=nearest)\n",
       "  (convtranspose_6_2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn_6_3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu_6_4): ReLU(inplace=True)\n",
       "  (upsample_7_1): Upsample(scale_factor=2.0, mode=nearest)\n",
       "  (convtranspose_7_2): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn_7_3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu_7_4): ReLU(inplace=True)\n",
       "  (upsample_8_1): Upsample(scale_factor=2.0, mode=nearest)\n",
       "  (convtranspose_8_2): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn_8_3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu_8_4): ReLU(inplace=True)\n",
       "  (upsample_9_1): Upsample(scale_factor=2.0, mode=nearest)\n",
       "  (convtranspose_9_2): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn_9_3): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu_9_4): ReLU(inplace=True)\n",
       "  (conv_10_1): Conv2d(8, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (tanh_10_2): Tanh()\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Autoencoder()\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate,eps=1e-7)\n",
    "\n",
    "#configuration\n",
    "\n",
    "num_epochs = 100\n",
    "criterion1 = nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "train_dir = os.path.join(d_dir, 'train')\n",
    "val_dir = os.path.join(d_dir, 'validation')\n",
    "\n",
    "train_data =torchvision.datasets.ImageFolder(root=train_dir,\n",
    "                                                transform = transforms.Compose([transforms.Resize((128 ,128 )),transforms.ToTensor()]))\n",
    "validation_dataset =torchvision.datasets.ImageFolder(root=val_dir,\n",
    "                                                transform = transforms.Compose([transforms.Resize((128 ,128 )),transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(dataset=train_data,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=8)\n",
    "\n",
    "validation_dataloader = torch.utils.data.DataLoader(dataset=validation_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader.classes : ['0', '1']\n",
      "validation_dataloader.classes : ['0', '1']\n",
      "train_dataloader.classes : {'0': 0, '1': 1}\n",
      "validation_dataloader.classes : {'0': 0, '1': 1}\n"
     ]
    }
   ],
   "source": [
    "print(\"train_dataloader.classes : %s\" % train_data.classes)\n",
    "print(\"validation_dataloader.classes : %s\" % validation_dataset.classes)\n",
    "print(\"train_dataloader.classes : %s\" % train_data.class_to_idx)\n",
    "print(\"validation_dataloader.classes : %s\" % validation_dataset.class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resume\n",
    "if resume:\n",
    "    print('==> Resuming from checkpoint..')\n",
    "    checkpoint = os.path.dirname(resume)\n",
    "#     checkpoint = torch.load(resume)\n",
    "    resume = torch.load(resume)\n",
    "    best_acc = 0\n",
    "    start_epoch = resume['epoch']\n",
    "    model.load_state_dict(resume['state_dict'])\n",
    "    optimizer.load_state_dict(resume['optimizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def act_loss_func(outputs, labels):\n",
    "    batch_size = outputs.size()[0]\n",
    "    loss_list = torch.zeros([batch_size])\n",
    "    loss_list = loss_list.to(device)\n",
    "    for i in range(batch_size):\n",
    "        #fake\n",
    "        total_loss =torch.zeros([1],dtype=torch.float32)\n",
    "        total_loss = total_loss.to(device)\n",
    "        #real\n",
    "        total_loss_1 =torch.zeros([1],dtype=torch.float32)\n",
    "        total_loss_1 = total_loss.to(device)\n",
    "        # real\n",
    "        if labels[i].item():\n",
    "            #fake\n",
    "            for latent_index in range(64):\n",
    "                temp= torch.sum(torch.abs(outputs[i,latent_index,:,:]))/225\n",
    "                total_loss = torch.sum(total_loss+temp)\n",
    "            #real\n",
    "            for latent_index in range(64,128):\n",
    "                temp1= torch.abs(1 -torch.sum(torch.abs(outputs[i,latent_index,:,:]))/225)\n",
    "                total_loss_1 = torch.sum(total_loss_1+temp1)\n",
    "        #fake\n",
    "        else:\n",
    "            #fake\n",
    "            for latent_index in range(64):\n",
    "                temp= torch.abs(1- torch.sum(torch.abs(outputs[i,latent_index,:,:]))/225)\n",
    "                total_loss = torch.sum(total_loss+temp)\n",
    "            #real\n",
    "            for latent_index in range(64,128):\n",
    "                temp1= torch.sum(torch.abs(outputs[i,latent_index,:,:]))/225\n",
    "                total_loss_1 = torch.sum(total_loss_1+temp1)\n",
    "        \n",
    "        loss_list[i]=total_loss+total_loss_1\n",
    "\n",
    "        \n",
    "    return torch.sum(loss_list)\n",
    "\n",
    "#%%\n",
    "\n",
    "# test\n",
    "def act_loss_test(outputs):\n",
    "    batch_size = outputs.size()[0]\n",
    "    answer = torch.zeros([batch_size,2])\n",
    "    answer.cuda()\n",
    "    for i in range(batch_size):\n",
    "        fake = torch.zeros([1], dtype=torch.float32).to(device)\n",
    "        real = torch.zeros([1], dtype=torch.float32).to(device)\n",
    "        # fake latent space\n",
    "        for latent_index in range(64):\n",
    "            fake = fake + torch.sum(torch.abs(outputs[i, latent_index]))\n",
    "        # real latent space\n",
    "        for latent_index in range(64, 128):\n",
    "            real = real + torch.sum(torch.abs(outputs[i, latent_index]))\n",
    "\n",
    "\n",
    "        answer[i][0] = fake.item() / (fake.item() + real.item())\n",
    "        answer[i][1] = real.item() / (fake.item() + real.item())\n",
    "        \n",
    "            \n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/100], loss:72406.6094\n",
      "epoch [1/100], loss:72008.9297\n",
      "epoch [1/100], loss:71767.9609\n",
      "epoch [1/100], loss:70226.1562\n",
      "epoch [1/100], loss:68655.2422\n",
      "epoch [1/100], loss:67822.5156\n",
      "epoch [1/100], loss:31248.3184\n",
      "validation loss is 463729.906250\n",
      "Test Accuracy 0.550256 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.96      0.10      0.19      3900\n",
      "        real       0.53      1.00      0.69      3900\n",
      "\n",
      "    accuracy                           0.55      7800\n",
      "   macro avg       0.75      0.55      0.44      7800\n",
      "weighted avg       0.75      0.55      0.44      7800\n",
      "\n",
      "epoch [2/100], loss:65817.2109\n",
      "epoch [2/100], loss:65288.6523\n",
      "epoch [2/100], loss:64222.1172\n",
      "epoch [2/100], loss:63577.9375\n",
      "epoch [2/100], loss:62620.9375\n",
      "epoch [2/100], loss:62029.6602\n",
      "epoch [2/100], loss:28762.8418\n",
      "validation loss is 419798.875000\n",
      "Test Accuracy 0.736923 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.66      1.00      0.79      3900\n",
      "        real       1.00      0.48      0.64      3900\n",
      "\n",
      "    accuracy                           0.74      7800\n",
      "   macro avg       0.83      0.74      0.72      7800\n",
      "weighted avg       0.83      0.74      0.72      7800\n",
      "\n",
      "epoch [3/100], loss:60961.5820\n",
      "epoch [3/100], loss:60210.1914\n",
      "epoch [3/100], loss:59321.1055\n",
      "epoch [3/100], loss:58629.1133\n",
      "epoch [3/100], loss:58041.0625\n",
      "epoch [3/100], loss:57603.6211\n",
      "epoch [3/100], loss:26438.1621\n",
      "validation loss is 442829.312500\n",
      "Test Accuracy 0.596026 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.55      1.00      0.71      3900\n",
      "        real       0.99      0.19      0.32      3900\n",
      "\n",
      "    accuracy                           0.60      7800\n",
      "   macro avg       0.77      0.60      0.52      7800\n",
      "weighted avg       0.77      0.60      0.52      7800\n",
      "\n",
      "epoch [4/100], loss:56192.4766\n",
      "epoch [4/100], loss:55289.6016\n",
      "epoch [4/100], loss:54994.7812\n",
      "epoch [4/100], loss:53981.7188\n",
      "epoch [4/100], loss:53165.0117\n",
      "epoch [4/100], loss:52624.5078\n",
      "epoch [4/100], loss:24540.7441\n",
      "validation loss is 513781.875000\n",
      "Test Accuracy 0.500000 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.50      1.00      0.67      3900\n",
      "        real       0.00      0.00      0.00      3900\n",
      "\n",
      "    accuracy                           0.50      7800\n",
      "   macro avg       0.25      0.50      0.33      7800\n",
      "weighted avg       0.25      0.50      0.33      7800\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kim1/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [5/100], loss:51629.5469\n",
      "epoch [5/100], loss:51016.4375\n",
      "epoch [5/100], loss:50423.9648\n",
      "epoch [5/100], loss:49838.2617\n",
      "epoch [5/100], loss:49349.2266\n",
      "epoch [5/100], loss:49165.0156\n",
      "epoch [5/100], loss:22698.8066\n",
      "validation loss is 446718.843750\n",
      "Test Accuracy 0.508333 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.50      1.00      0.67      3900\n",
      "        real       1.00      0.02      0.03      3900\n",
      "\n",
      "    accuracy                           0.51      7800\n",
      "   macro avg       0.75      0.51      0.35      7800\n",
      "weighted avg       0.75      0.51      0.35      7800\n",
      "\n",
      "epoch [6/100], loss:47909.9492\n",
      "epoch [6/100], loss:46936.6602\n",
      "epoch [6/100], loss:46649.9648\n",
      "epoch [6/100], loss:46109.3633\n",
      "epoch [6/100], loss:45378.2656\n",
      "epoch [6/100], loss:45166.9961\n",
      "epoch [6/100], loss:21362.7637\n",
      "validation loss is 449460.687500\n",
      "Test Accuracy 0.561026 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       1.00      0.12      0.22      3900\n",
      "        real       0.53      1.00      0.69      3900\n",
      "\n",
      "    accuracy                           0.56      7800\n",
      "   macro avg       0.77      0.56      0.46      7800\n",
      "weighted avg       0.77      0.56      0.46      7800\n",
      "\n",
      "epoch [7/100], loss:44236.4062\n",
      "epoch [7/100], loss:43186.6211\n",
      "epoch [7/100], loss:43261.1797\n",
      "epoch [7/100], loss:42609.6562\n",
      "epoch [7/100], loss:42289.6055\n",
      "epoch [7/100], loss:41250.9844\n",
      "epoch [7/100], loss:19561.0215\n",
      "validation loss is 581902.500000\n",
      "Test Accuracy 0.500000 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.50      1.00      0.67      3900\n",
      "        real       0.00      0.00      0.00      3900\n",
      "\n",
      "    accuracy                           0.50      7800\n",
      "   macro avg       0.25      0.50      0.33      7800\n",
      "weighted avg       0.25      0.50      0.33      7800\n",
      "\n",
      "epoch [8/100], loss:40708.6953\n",
      "epoch [8/100], loss:39897.4062\n",
      "epoch [8/100], loss:39996.3438\n",
      "epoch [8/100], loss:38990.2422\n",
      "epoch [8/100], loss:38460.1406\n",
      "epoch [8/100], loss:38216.1719\n",
      "epoch [8/100], loss:17697.8711\n",
      "validation loss is 481990.250000\n",
      "Test Accuracy 0.500897 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.50      1.00      0.67      3900\n",
      "        real       1.00      0.00      0.00      3900\n",
      "\n",
      "    accuracy                           0.50      7800\n",
      "   macro avg       0.75      0.50      0.34      7800\n",
      "weighted avg       0.75      0.50      0.34      7800\n",
      "\n",
      "epoch [9/100], loss:37343.7969\n",
      "epoch [9/100], loss:37106.1016\n",
      "epoch [9/100], loss:36968.5391\n",
      "epoch [9/100], loss:36582.5234\n",
      "epoch [9/100], loss:36224.3984\n",
      "epoch [9/100], loss:34853.5781\n",
      "epoch [9/100], loss:16607.6074\n",
      "validation loss is 654123.312500\n",
      "Test Accuracy 0.500000 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.50      1.00      0.67      3900\n",
      "        real       0.00      0.00      0.00      3900\n",
      "\n",
      "    accuracy                           0.50      7800\n",
      "   macro avg       0.25      0.50      0.33      7800\n",
      "weighted avg       0.25      0.50      0.33      7800\n",
      "\n",
      "epoch [10/100], loss:34250.4766\n",
      "epoch [10/100], loss:34079.8867\n",
      "epoch [10/100], loss:33909.2305\n",
      "epoch [10/100], loss:33368.4453\n",
      "epoch [10/100], loss:33200.2227\n",
      "epoch [10/100], loss:32952.6406\n",
      "epoch [10/100], loss:15309.5566\n",
      "validation loss is 587552.125000\n",
      "Test Accuracy 0.500000 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.00      0.00      0.00      3900\n",
      "        real       0.50      1.00      0.67      3900\n",
      "\n",
      "    accuracy                           0.50      7800\n",
      "   macro avg       0.25      0.50      0.33      7800\n",
      "weighted avg       0.25      0.50      0.33      7800\n",
      "\n",
      "epoch [11/100], loss:30986.4004\n",
      "epoch [11/100], loss:31332.5215\n",
      "epoch [11/100], loss:31375.3262\n",
      "epoch [11/100], loss:30374.6074\n",
      "epoch [11/100], loss:30561.2676\n",
      "epoch [11/100], loss:29954.2793\n",
      "epoch [11/100], loss:13815.5791\n",
      "validation loss is 429372.125000\n",
      "Test Accuracy 0.578205 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.54      1.00      0.70      3900\n",
      "        real       1.00      0.16      0.27      3900\n",
      "\n",
      "    accuracy                           0.58      7800\n",
      "   macro avg       0.77      0.58      0.49      7800\n",
      "weighted avg       0.77      0.58      0.49      7800\n",
      "\n",
      "epoch [12/100], loss:29334.3457\n",
      "epoch [12/100], loss:28788.4434\n",
      "epoch [12/100], loss:28811.5898\n",
      "epoch [12/100], loss:27780.7910\n",
      "epoch [12/100], loss:28130.9453\n",
      "epoch [12/100], loss:28076.9395\n",
      "epoch [12/100], loss:13318.6406\n",
      "validation loss is 592556.250000\n",
      "Test Accuracy 0.500769 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.50      1.00      0.67      3900\n",
      "        real       1.00      0.00      0.00      3900\n",
      "\n",
      "    accuracy                           0.50      7800\n",
      "   macro avg       0.75      0.50      0.34      7800\n",
      "weighted avg       0.75      0.50      0.34      7800\n",
      "\n",
      "epoch [13/100], loss:26619.4492\n",
      "epoch [13/100], loss:26808.1719\n",
      "epoch [13/100], loss:25612.6328\n",
      "epoch [13/100], loss:26074.0820\n",
      "epoch [13/100], loss:25536.5215\n",
      "epoch [13/100], loss:25682.1895\n",
      "epoch [13/100], loss:11874.2324\n",
      "validation loss is 339121.093750\n",
      "Test Accuracy 0.933077 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.93      0.93      0.93      3900\n",
      "        real       0.93      0.93      0.93      3900\n",
      "\n",
      "    accuracy                           0.93      7800\n",
      "   macro avg       0.93      0.93      0.93      7800\n",
      "weighted avg       0.93      0.93      0.93      7800\n",
      "\n",
      "epoch [14/100], loss:24840.2637\n",
      "epoch [14/100], loss:24628.4785\n",
      "epoch [14/100], loss:23410.7930\n",
      "epoch [14/100], loss:23987.5645\n",
      "epoch [14/100], loss:23676.1523\n",
      "epoch [14/100], loss:23175.7969\n",
      "epoch [14/100], loss:11036.8047\n",
      "validation loss is 586859.562500\n",
      "Test Accuracy 0.503205 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       1.00      0.01      0.01      3900\n",
      "        real       0.50      1.00      0.67      3900\n",
      "\n",
      "    accuracy                           0.50      7800\n",
      "   macro avg       0.75      0.50      0.34      7800\n",
      "weighted avg       0.75      0.50      0.34      7800\n",
      "\n",
      "epoch [15/100], loss:22929.9160\n",
      "epoch [15/100], loss:22554.3730\n",
      "epoch [15/100], loss:22199.9043\n",
      "epoch [15/100], loss:22392.0664\n",
      "epoch [15/100], loss:21916.9980\n",
      "epoch [15/100], loss:21323.9141\n",
      "epoch [15/100], loss:10422.2744\n",
      "validation loss is 324416.031250\n",
      "Test Accuracy 0.780513 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.70      0.98      0.82      3900\n",
      "        real       0.97      0.58      0.73      3900\n",
      "\n",
      "    accuracy                           0.78      7800\n",
      "   macro avg       0.83      0.78      0.77      7800\n",
      "weighted avg       0.83      0.78      0.77      7800\n",
      "\n",
      "epoch [16/100], loss:20955.3301\n",
      "epoch [16/100], loss:20908.9785\n",
      "epoch [16/100], loss:20323.1699\n",
      "epoch [16/100], loss:20855.0098\n",
      "epoch [16/100], loss:20668.7168\n",
      "epoch [16/100], loss:20005.1270\n",
      "epoch [16/100], loss:9331.5449\n",
      "validation loss is 400401.312500\n",
      "Test Accuracy 0.846538 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.79      0.95      0.86      3900\n",
      "        real       0.94      0.74      0.83      3900\n",
      "\n",
      "    accuracy                           0.85      7800\n",
      "   macro avg       0.86      0.85      0.84      7800\n",
      "weighted avg       0.86      0.85      0.84      7800\n",
      "\n",
      "epoch [17/100], loss:19376.0020\n",
      "epoch [17/100], loss:19044.8730\n",
      "epoch [17/100], loss:19027.3203\n",
      "epoch [17/100], loss:19415.6973\n",
      "epoch [17/100], loss:19399.2207\n",
      "epoch [17/100], loss:19276.7715\n",
      "epoch [17/100], loss:8702.8281\n",
      "validation loss is 386570.343750\n",
      "Test Accuracy 0.543205 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.52      1.00      0.69      3900\n",
      "        real       1.00      0.09      0.16      3900\n",
      "\n",
      "    accuracy                           0.54      7800\n",
      "   macro avg       0.76      0.54      0.42      7800\n",
      "weighted avg       0.76      0.54      0.42      7800\n",
      "\n",
      "epoch [18/100], loss:18771.2363\n",
      "epoch [18/100], loss:18146.3906\n",
      "epoch [18/100], loss:18116.0508\n",
      "epoch [18/100], loss:18787.5488\n",
      "epoch [18/100], loss:17524.3730\n",
      "epoch [18/100], loss:18636.2520\n",
      "epoch [18/100], loss:8123.0400\n",
      "validation loss is 411068.531250\n",
      "Test Accuracy 0.626026 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.57      0.99      0.73      3900\n",
      "        real       0.96      0.26      0.41      3900\n",
      "\n",
      "    accuracy                           0.63      7800\n",
      "   macro avg       0.76      0.63      0.57      7800\n",
      "weighted avg       0.76      0.63      0.57      7800\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [19/100], loss:18769.5859\n",
      "epoch [19/100], loss:17216.2402\n",
      "epoch [19/100], loss:17698.0098\n",
      "epoch [19/100], loss:17464.0586\n",
      "epoch [19/100], loss:17589.0996\n",
      "epoch [19/100], loss:17133.8828\n",
      "epoch [19/100], loss:8407.9570\n",
      "validation loss is 343585.812500\n",
      "Test Accuracy 0.734744 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.65      1.00      0.79      3900\n",
      "        real       0.99      0.47      0.64      3900\n",
      "\n",
      "    accuracy                           0.73      7800\n",
      "   macro avg       0.82      0.73      0.72      7800\n",
      "weighted avg       0.82      0.73      0.72      7800\n",
      "\n",
      "epoch [20/100], loss:16810.4199\n",
      "epoch [20/100], loss:17590.1719\n",
      "epoch [20/100], loss:16803.5918\n",
      "epoch [20/100], loss:17475.5723\n",
      "epoch [20/100], loss:17540.3027\n",
      "epoch [20/100], loss:17705.5840\n",
      "epoch [20/100], loss:8564.9854\n",
      "validation loss is 743945.875000\n",
      "Test Accuracy 0.500128 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.50      1.00      0.67      3900\n",
      "        real       1.00      0.00      0.00      3900\n",
      "\n",
      "    accuracy                           0.50      7800\n",
      "   macro avg       0.75      0.50      0.33      7800\n",
      "weighted avg       0.75      0.50      0.33      7800\n",
      "\n",
      "epoch [21/100], loss:16624.7402\n",
      "epoch [21/100], loss:16548.0293\n",
      "epoch [21/100], loss:16697.3926\n",
      "epoch [21/100], loss:17061.8984\n",
      "epoch [21/100], loss:16243.8916\n",
      "epoch [21/100], loss:16306.6904\n",
      "epoch [21/100], loss:7725.7983\n",
      "validation loss is 334328.687500\n",
      "Test Accuracy 0.955385 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.96      0.95      0.96      3900\n",
      "        real       0.95      0.96      0.96      3900\n",
      "\n",
      "    accuracy                           0.96      7800\n",
      "   macro avg       0.96      0.96      0.96      7800\n",
      "weighted avg       0.96      0.96      0.96      7800\n",
      "\n",
      "epoch [22/100], loss:16148.0342\n",
      "epoch [22/100], loss:16148.1338\n",
      "epoch [22/100], loss:16300.9629\n",
      "epoch [22/100], loss:16424.8340\n",
      "epoch [22/100], loss:16373.5674\n",
      "epoch [22/100], loss:15879.2598\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "import torchvision.utils as vutils\n",
    "from sklearn.metrics import classification_report\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "target_names = ['fake','real']\n",
    "loss_val =0\n",
    "for epoch in range(num_epochs):\n",
    "    model = model.train()\n",
    "    for _, (x,label) in enumerate(train_dataloader):\n",
    "        init = x\n",
    "        init= init.to(device)\n",
    "        x = x.view(x.size(),-1)\n",
    "        x = x.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output,act_data = model(x,label)\n",
    "        rec_loss = criterion1(output, init)\n",
    "        act_loss = act_loss_func(act_data, label)\n",
    "        loss = act_loss+0.1*rec_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (_+1) % 10 == 0:\n",
    "            print('epoch [{}/{}], loss:{:.4f}'.format(epoch + 1, num_epochs, loss.item()))\n",
    "        \n",
    "    print('epoch [{}/{}], loss:{:.4f}'.format(epoch + 1, num_epochs, loss.item()))\n",
    "\n",
    "#     vutils.save_image(x,'deepfake_%d_real_samples.png' % epoch,normalize=True)\n",
    "#     vutils.save_image(output,'deepfake_%d_generated_samples.png' % epoch,normalize=True)\n",
    "    \n",
    "    model = model.eval()\n",
    "    \n",
    "    pred= []\n",
    "    labels= []\n",
    "    correct =0\n",
    "    total =0\n",
    "    with torch.no_grad():\n",
    "        loss = 0\n",
    "        for _, (x,label) in enumerate(validation_dataloader):\n",
    "            init = x\n",
    "            init= init.to(device)\n",
    "            x = x.view(x.size(),-1)\n",
    "            x = x.to(device)\n",
    "            a= label.shape[0]\n",
    "            temp = torch.rand([a])\n",
    "            output,act_data = model(x,temp)\n",
    "            outputs  = act_loss_test(act_data)\n",
    "            \n",
    "            rec_loss = criterion1(output, init)\n",
    "            act_loss = act_loss_func(act_data, label)\n",
    "\n",
    "            loss += act_loss+0.1*rec_loss  \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            pred += predicted.tolist()\n",
    "            labels += label.tolist()\n",
    "            correct += (predicted == label).sum().item()\n",
    "            \n",
    "            \n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        print(\"validation loss is %f\" % loss)\n",
    "        temp =correct/len(validation_dataset)\n",
    "        print('Test Accuracy %f %%' % temp)\n",
    "        print(classification_report(labels, pred, target_names=target_names))\n",
    "        \n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'state_dict' : model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    }, is_best=True, checkpoint=checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL= Autoencoder()\n",
    "MODEL.load_state_dict(torch.load(\"stylegan90epoch_.pth\"))\n",
    "MODEL.cuda()\n",
    "MODEL.eval()\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "target_data_1 =torchvision.datasets.ImageFolder(root=r\"C:\\Users\\jonathan\\Desktop\\prj\\gan_detection\\PGGAN_128\\fine_tune\",\n",
    "                                                transform = transforms.Compose([transforms.Resize((128 ,128 )),transforms.ToTensor()]))\n",
    "target_data_2 =torchvision.datasets.ImageFolder(root=r\"C:\\Users\\jonathan\\Desktop\\prj\\gan_detection\\StyleGAN2_256\",\n",
    "                                                transform = transforms.Compose([transforms.Resize((128 ,128 )),transforms.ToTensor()]))\n",
    "\n",
    "\n",
    "zeroshot_data_1 = torch.utils.data.DataLoader(dataset=target_data_1,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "\n",
    "zeroshot_data_2 = torch.utils.data.DataLoader(dataset=target_data_2,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct= 0\n",
    "    loss = 0\n",
    "    pred= []\n",
    "    labels = []\n",
    "    for _, (x,label) in enumerate(zeroshot_data_1):\n",
    "        init = x\n",
    "        init= init.to(device)\n",
    "        x = x.view(x.size(),-1)\n",
    "        x = x.to(device)\n",
    "        a= label.shape[0]\n",
    "        temp = torch.rand([a])\n",
    "        output,act_data = MODEL(x,temp)\n",
    "        outputs  = act_loss_test(act_data)\n",
    "        \n",
    "        rec_loss = criterion1(output, init)\n",
    "        act_loss = act_loss_func(act_data, label)\n",
    "\n",
    "        loss += act_loss+0.1*rec_loss  \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        pred += predicted.tolist()\n",
    "        labels += label.tolist()\n",
    "        correct += (predicted == label).sum().item()\n",
    "        \n",
    "        \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    # print(\"PGGAN_128 loss is %f\" % loss)\n",
    "    temp =correct/len(zeroshot_data_1)\n",
    "    print('Test Accuracy %f %%' % temp)\n",
    "    print(classification_report(labels, pred, target_names=target_names))\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct= 0\n",
    "    loss = 0\n",
    "    pred= []\n",
    "    labels = []\n",
    "    for _, (x,label) in enumerate(zeroshot_data_2):\n",
    "        init = x\n",
    "        init= init.to(device)\n",
    "        x = x.view(x.size(),-1)\n",
    "        x = x.to(device)\n",
    "        a= label.shape[0]\n",
    "        temp = torch.rand([a])\n",
    "        output,act_data = MODEL(x,temp)\n",
    "        outputs  = act_loss_test(act_data)\n",
    "        \n",
    "        rec_loss = criterion1(output, init)\n",
    "        act_loss = act_loss_func(act_data, label)\n",
    "\n",
    "        loss += act_loss+0.1*rec_loss  \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        pred += predicted.tolist()\n",
    "        labels += label.tolist()\n",
    "        correct += (predicted == label).sum().item()\n",
    "        \n",
    "        \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    print(\"StyleGAN2 loss is %f\" % loss)\n",
    "    temp =correct/len(target_data_2)\n",
    "    print('Test Accuracy %f %%' % temp)\n",
    "    print(classification_report(labels, pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
