{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from model_pytorch import EfficientNet\n",
    "from utils import Bar,Logger, AverageMeter, accuracy, mkdir_p, savefig\n",
    "from warmup_scheduler import GradualWarmupScheduler\n",
    "\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "import collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = '/media/data2/dataset/GAN_ImageData/StyleGAN_256/'\n",
    "target_dir = '/media/data2/dataset/GAN_ImageData/PGGAN_128/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained = './log/style1/128/checkpoint.pth.tar'\n",
    "resume = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model_name = 'efficientnet-b0' # b0-b7 scale\n",
    "\n",
    "# Optimization\n",
    "num_classes = 2\n",
    "epochs = 5000\n",
    "start_epoch = 0\n",
    "train_batch = 32\n",
    "test_batch = 300\n",
    "lr = 0.01\n",
    "schedule = [1500, 3000]\n",
    "momentum = 0\n",
    "gamma = 0.1 # LR is multiplied by gamma on schedule\n",
    "\n",
    "# CheckPoint\n",
    "checkpoint = './log/style1/to_pggan/128/l2sp' # dir\n",
    "if not os.path.isdir(checkpoint):\n",
    "    os.mkdir(checkpoint)\n",
    "num_workers = 4\n",
    "\n",
    "# Seed\n",
    "manual_seed = 7\n",
    "random.seed(manual_seed)\n",
    "torch.cuda.manual_seed_all(manual_seed)\n",
    "\n",
    "# Image\n",
    "size = (128, 128)\n",
    "\n",
    "# sp\n",
    "alpha = 0.1\n",
    "beta = 0.1\n",
    "fc_name = 'fc.'\n",
    "\n",
    "best_acc = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {}\n",
    "state['num_classes'] = num_classes\n",
    "state['epochs'] = epochs\n",
    "state['start_epoch'] = start_epoch\n",
    "state['train_batch'] = train_batch\n",
    "state['test_batch'] = test_batch\n",
    "state['lr'] = lr\n",
    "state['schedule'] = schedule\n",
    "state['momentum'] = momentum\n",
    "state['gamma'] = gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU device 0: True\n"
     ]
    }
   ],
   "source": [
    "# GPU Device\n",
    "gpu_id = 0\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(\"GPU device %d:\" %(gpu_id), use_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join(target_dir, '100_shot_pggan')\n",
    "val_target_dir = os.path.join(target_dir, 'validation')\n",
    "val_source_dir = os.path.join(source_dir, 'validation')\n",
    "\n",
    "train_aug = transforms.Compose([\n",
    "    transforms.RandomAffine(degrees=2, translate=(0.02, 0.02), scale=(0.98, 1.02), shear=2, fillcolor=(124,117,104)),\n",
    "    transforms.Resize(size),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomErasing(p=0.3, scale=(0.02, 0.10), ratio=(0.3, 3.3), value=0, inplace=True),\n",
    "])\n",
    "val_aug = transforms.Compose([\n",
    "    transforms.Resize(size),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# pin_memory : cuda pin memeory use\n",
    "train_loader = DataLoader(datasets.ImageFolder(train_dir, transform=train_aug),\n",
    "                          batch_size=train_batch, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "val_target_loader = DataLoader(datasets.ImageFolder(val_target_dir, val_aug),\n",
    "                       batch_size=test_batch, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "val_source_loader = DataLoader(datasets.ImageFolder(val_source_dir, val_aug),\n",
    "                       batch_size=test_batch, shuffle=True, num_workers=num_workers, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> using pre-trained model './log/style1/128/checkpoint.pth.tar'\n"
     ]
    }
   ],
   "source": [
    "source_model = EfficientNet.from_name(model_name, num_classes=num_classes, override_params={'dropout_rate':0.0})\n",
    "model = EfficientNet.from_name(model_name, num_classes=num_classes, override_params={'dropout_rate':0.0})\n",
    "\n",
    "# Pre-trained\n",
    "if pretrained:\n",
    "    print(\"=> using pre-trained model '{}'\".format(pretrained))\n",
    "    source_model.load_state_dict(torch.load(pretrained)['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Total params: 4.01M\n"
     ]
    }
   ],
   "source": [
    "source_model.to('cuda')\n",
    "model.to('cuda')\n",
    "cudnn.benchmark = True\n",
    "print('    Total params: %.2fM' % (sum(p.numel() for p in model.parameters())/1000000.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EfficientNet(\n",
       "  (_conv_stem): Conv2dStaticSamePadding(\n",
       "    3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
       "    (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "  )\n",
       "  (_bn0): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "  (_blocks): ModuleList(\n",
       "    (0): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        32, 32, kernel_size=(3, 3), stride=[1, 1], groups=32, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        32, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        8, 32, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): GroupNorm(4, 16, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (1): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): GroupNorm(24, 96, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        96, 96, kernel_size=(3, 3), stride=[2, 2], groups=96, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): GroupNorm(24, 96, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        96, 4, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        4, 96, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): GroupNorm(6, 24, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (2): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): GroupNorm(36, 144, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): GroupNorm(36, 144, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): GroupNorm(6, 24, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (3): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): GroupNorm(36, 144, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        144, 144, kernel_size=(5, 5), stride=[2, 2], groups=144, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): GroupNorm(36, 144, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): GroupNorm(10, 40, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (4): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): GroupNorm(60, 240, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        240, 240, kernel_size=(5, 5), stride=(1, 1), groups=240, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): GroupNorm(60, 240, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): GroupNorm(10, 40, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (5): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): GroupNorm(60, 240, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        240, 240, kernel_size=(3, 3), stride=[2, 2], groups=240, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): GroupNorm(60, 240, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): GroupNorm(20, 80, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (6): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): GroupNorm(120, 480, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): GroupNorm(120, 480, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): GroupNorm(20, 80, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (7): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): GroupNorm(120, 480, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): GroupNorm(120, 480, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): GroupNorm(20, 80, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (8): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): GroupNorm(120, 480, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        480, 480, kernel_size=(5, 5), stride=[1, 1], groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): GroupNorm(120, 480, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): GroupNorm(28, 112, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (9): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): GroupNorm(168, 672, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): GroupNorm(168, 672, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): GroupNorm(28, 112, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (10): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): GroupNorm(168, 672, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): GroupNorm(168, 672, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): GroupNorm(28, 112, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (11): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): GroupNorm(168, 672, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5), stride=[2, 2], groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): GroupNorm(168, 672, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): GroupNorm(48, 192, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (12): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): GroupNorm(288, 1152, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): GroupNorm(288, 1152, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): GroupNorm(48, 192, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (13): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): GroupNorm(288, 1152, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): GroupNorm(288, 1152, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): GroupNorm(48, 192, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (14): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): GroupNorm(288, 1152, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): GroupNorm(288, 1152, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): GroupNorm(48, 192, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (15): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): GroupNorm(288, 1152, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(3, 3), stride=[1, 1], groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): GroupNorm(288, 1152, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): GroupNorm(80, 320, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "  )\n",
       "  (_conv_head): Conv2dStaticSamePadding(\n",
       "    320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "    (static_padding): Identity()\n",
       "  )\n",
       "  (_bn1): GroupNorm(320, 1280, eps=1e-05, affine=True)\n",
       "  (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n",
       "  (_dropout): Dropout(p=0.0, inplace=False)\n",
       "  (_fc): Linear(in_features=1280, out_features=2, bias=True)\n",
       "  (_swish): MemoryEfficientSwish()\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for param in source_model.parameters():\n",
    "    param.requires_grad = False\n",
    "source_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_model_weights = {}\n",
    "for name, param in source_model.named_parameters():\n",
    "    source_model_weights[name] = param.detach()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_cls(model):\n",
    "    l2_cls = torch.tensor(0.).cuda()\n",
    "    for name, param in model.named_parameters():\n",
    "        if name.startswith(fc_name):\n",
    "            l2_cls += 0.5 * torch.norm(param) ** 2\n",
    "    return l2_cls\n",
    "\n",
    "def reg_l2sp(model):\n",
    "    sp_loss = torch.tensor(0.).cuda()\n",
    "    for name, param in model.named_parameters():\n",
    "        if not name.startswith(fc_name):\n",
    "            sp_loss += 0.5 * torch.norm(param - source_model_weights[name]) ** 2\n",
    "    return sp_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "         ZeroPad2d-1          [-1, 3, 129, 129]               0\n",
      "Conv2dStaticSamePadding-2           [-1, 32, 64, 64]             864\n",
      "         GroupNorm-3           [-1, 32, 64, 64]              64\n",
      "MemoryEfficientSwish-4           [-1, 32, 64, 64]               0\n",
      "         ZeroPad2d-5           [-1, 32, 66, 66]               0\n",
      "Conv2dStaticSamePadding-6           [-1, 32, 64, 64]             288\n",
      "         GroupNorm-7           [-1, 32, 64, 64]              64\n",
      "MemoryEfficientSwish-8           [-1, 32, 64, 64]               0\n",
      "          Identity-9             [-1, 32, 1, 1]               0\n",
      "Conv2dStaticSamePadding-10              [-1, 8, 1, 1]             264\n",
      "MemoryEfficientSwish-11              [-1, 8, 1, 1]               0\n",
      "         Identity-12              [-1, 8, 1, 1]               0\n",
      "Conv2dStaticSamePadding-13             [-1, 32, 1, 1]             288\n",
      "         Identity-14           [-1, 32, 64, 64]               0\n",
      "Conv2dStaticSamePadding-15           [-1, 16, 64, 64]             512\n",
      "        GroupNorm-16           [-1, 16, 64, 64]              32\n",
      "      MBConvBlock-17           [-1, 16, 64, 64]               0\n",
      "         Identity-18           [-1, 16, 64, 64]               0\n",
      "Conv2dStaticSamePadding-19           [-1, 96, 64, 64]           1,536\n",
      "        GroupNorm-20           [-1, 96, 64, 64]             192\n",
      "MemoryEfficientSwish-21           [-1, 96, 64, 64]               0\n",
      "        ZeroPad2d-22           [-1, 96, 65, 65]               0\n",
      "Conv2dStaticSamePadding-23           [-1, 96, 32, 32]             864\n",
      "        GroupNorm-24           [-1, 96, 32, 32]             192\n",
      "MemoryEfficientSwish-25           [-1, 96, 32, 32]               0\n",
      "         Identity-26             [-1, 96, 1, 1]               0\n",
      "Conv2dStaticSamePadding-27              [-1, 4, 1, 1]             388\n",
      "MemoryEfficientSwish-28              [-1, 4, 1, 1]               0\n",
      "         Identity-29              [-1, 4, 1, 1]               0\n",
      "Conv2dStaticSamePadding-30             [-1, 96, 1, 1]             480\n",
      "         Identity-31           [-1, 96, 32, 32]               0\n",
      "Conv2dStaticSamePadding-32           [-1, 24, 32, 32]           2,304\n",
      "        GroupNorm-33           [-1, 24, 32, 32]              48\n",
      "      MBConvBlock-34           [-1, 24, 32, 32]               0\n",
      "         Identity-35           [-1, 24, 32, 32]               0\n",
      "Conv2dStaticSamePadding-36          [-1, 144, 32, 32]           3,456\n",
      "        GroupNorm-37          [-1, 144, 32, 32]             288\n",
      "MemoryEfficientSwish-38          [-1, 144, 32, 32]               0\n",
      "        ZeroPad2d-39          [-1, 144, 34, 34]               0\n",
      "Conv2dStaticSamePadding-40          [-1, 144, 32, 32]           1,296\n",
      "        GroupNorm-41          [-1, 144, 32, 32]             288\n",
      "MemoryEfficientSwish-42          [-1, 144, 32, 32]               0\n",
      "         Identity-43            [-1, 144, 1, 1]               0\n",
      "Conv2dStaticSamePadding-44              [-1, 6, 1, 1]             870\n",
      "MemoryEfficientSwish-45              [-1, 6, 1, 1]               0\n",
      "         Identity-46              [-1, 6, 1, 1]               0\n",
      "Conv2dStaticSamePadding-47            [-1, 144, 1, 1]           1,008\n",
      "         Identity-48          [-1, 144, 32, 32]               0\n",
      "Conv2dStaticSamePadding-49           [-1, 24, 32, 32]           3,456\n",
      "        GroupNorm-50           [-1, 24, 32, 32]              48\n",
      "      MBConvBlock-51           [-1, 24, 32, 32]               0\n",
      "         Identity-52           [-1, 24, 32, 32]               0\n",
      "Conv2dStaticSamePadding-53          [-1, 144, 32, 32]           3,456\n",
      "        GroupNorm-54          [-1, 144, 32, 32]             288\n",
      "MemoryEfficientSwish-55          [-1, 144, 32, 32]               0\n",
      "        ZeroPad2d-56          [-1, 144, 35, 35]               0\n",
      "Conv2dStaticSamePadding-57          [-1, 144, 16, 16]           3,600\n",
      "        GroupNorm-58          [-1, 144, 16, 16]             288\n",
      "MemoryEfficientSwish-59          [-1, 144, 16, 16]               0\n",
      "         Identity-60            [-1, 144, 1, 1]               0\n",
      "Conv2dStaticSamePadding-61              [-1, 6, 1, 1]             870\n",
      "MemoryEfficientSwish-62              [-1, 6, 1, 1]               0\n",
      "         Identity-63              [-1, 6, 1, 1]               0\n",
      "Conv2dStaticSamePadding-64            [-1, 144, 1, 1]           1,008\n",
      "         Identity-65          [-1, 144, 16, 16]               0\n",
      "Conv2dStaticSamePadding-66           [-1, 40, 16, 16]           5,760\n",
      "        GroupNorm-67           [-1, 40, 16, 16]              80\n",
      "      MBConvBlock-68           [-1, 40, 16, 16]               0\n",
      "         Identity-69           [-1, 40, 16, 16]               0\n",
      "Conv2dStaticSamePadding-70          [-1, 240, 16, 16]           9,600\n",
      "        GroupNorm-71          [-1, 240, 16, 16]             480\n",
      "MemoryEfficientSwish-72          [-1, 240, 16, 16]               0\n",
      "        ZeroPad2d-73          [-1, 240, 20, 20]               0\n",
      "Conv2dStaticSamePadding-74          [-1, 240, 16, 16]           6,000\n",
      "        GroupNorm-75          [-1, 240, 16, 16]             480\n",
      "MemoryEfficientSwish-76          [-1, 240, 16, 16]               0\n",
      "         Identity-77            [-1, 240, 1, 1]               0\n",
      "Conv2dStaticSamePadding-78             [-1, 10, 1, 1]           2,410\n",
      "MemoryEfficientSwish-79             [-1, 10, 1, 1]               0\n",
      "         Identity-80             [-1, 10, 1, 1]               0\n",
      "Conv2dStaticSamePadding-81            [-1, 240, 1, 1]           2,640\n",
      "         Identity-82          [-1, 240, 16, 16]               0\n",
      "Conv2dStaticSamePadding-83           [-1, 40, 16, 16]           9,600\n",
      "        GroupNorm-84           [-1, 40, 16, 16]              80\n",
      "      MBConvBlock-85           [-1, 40, 16, 16]               0\n",
      "         Identity-86           [-1, 40, 16, 16]               0\n",
      "Conv2dStaticSamePadding-87          [-1, 240, 16, 16]           9,600\n",
      "        GroupNorm-88          [-1, 240, 16, 16]             480\n",
      "MemoryEfficientSwish-89          [-1, 240, 16, 16]               0\n",
      "        ZeroPad2d-90          [-1, 240, 17, 17]               0\n",
      "Conv2dStaticSamePadding-91            [-1, 240, 8, 8]           2,160\n",
      "        GroupNorm-92            [-1, 240, 8, 8]             480\n",
      "MemoryEfficientSwish-93            [-1, 240, 8, 8]               0\n",
      "         Identity-94            [-1, 240, 1, 1]               0\n",
      "Conv2dStaticSamePadding-95             [-1, 10, 1, 1]           2,410\n",
      "MemoryEfficientSwish-96             [-1, 10, 1, 1]               0\n",
      "         Identity-97             [-1, 10, 1, 1]               0\n",
      "Conv2dStaticSamePadding-98            [-1, 240, 1, 1]           2,640\n",
      "         Identity-99            [-1, 240, 8, 8]               0\n",
      "Conv2dStaticSamePadding-100             [-1, 80, 8, 8]          19,200\n",
      "       GroupNorm-101             [-1, 80, 8, 8]             160\n",
      "     MBConvBlock-102             [-1, 80, 8, 8]               0\n",
      "        Identity-103             [-1, 80, 8, 8]               0\n",
      "Conv2dStaticSamePadding-104            [-1, 480, 8, 8]          38,400\n",
      "       GroupNorm-105            [-1, 480, 8, 8]             960\n",
      "MemoryEfficientSwish-106            [-1, 480, 8, 8]               0\n",
      "       ZeroPad2d-107          [-1, 480, 10, 10]               0\n",
      "Conv2dStaticSamePadding-108            [-1, 480, 8, 8]           4,320\n",
      "       GroupNorm-109            [-1, 480, 8, 8]             960\n",
      "MemoryEfficientSwish-110            [-1, 480, 8, 8]               0\n",
      "        Identity-111            [-1, 480, 1, 1]               0\n",
      "Conv2dStaticSamePadding-112             [-1, 20, 1, 1]           9,620\n",
      "MemoryEfficientSwish-113             [-1, 20, 1, 1]               0\n",
      "        Identity-114             [-1, 20, 1, 1]               0\n",
      "Conv2dStaticSamePadding-115            [-1, 480, 1, 1]          10,080\n",
      "        Identity-116            [-1, 480, 8, 8]               0\n",
      "Conv2dStaticSamePadding-117             [-1, 80, 8, 8]          38,400\n",
      "       GroupNorm-118             [-1, 80, 8, 8]             160\n",
      "     MBConvBlock-119             [-1, 80, 8, 8]               0\n",
      "        Identity-120             [-1, 80, 8, 8]               0\n",
      "Conv2dStaticSamePadding-121            [-1, 480, 8, 8]          38,400\n",
      "       GroupNorm-122            [-1, 480, 8, 8]             960\n",
      "MemoryEfficientSwish-123            [-1, 480, 8, 8]               0\n",
      "       ZeroPad2d-124          [-1, 480, 10, 10]               0\n",
      "Conv2dStaticSamePadding-125            [-1, 480, 8, 8]           4,320\n",
      "       GroupNorm-126            [-1, 480, 8, 8]             960\n",
      "MemoryEfficientSwish-127            [-1, 480, 8, 8]               0\n",
      "        Identity-128            [-1, 480, 1, 1]               0\n",
      "Conv2dStaticSamePadding-129             [-1, 20, 1, 1]           9,620\n",
      "MemoryEfficientSwish-130             [-1, 20, 1, 1]               0\n",
      "        Identity-131             [-1, 20, 1, 1]               0\n",
      "Conv2dStaticSamePadding-132            [-1, 480, 1, 1]          10,080\n",
      "        Identity-133            [-1, 480, 8, 8]               0\n",
      "Conv2dStaticSamePadding-134             [-1, 80, 8, 8]          38,400\n",
      "       GroupNorm-135             [-1, 80, 8, 8]             160\n",
      "     MBConvBlock-136             [-1, 80, 8, 8]               0\n",
      "        Identity-137             [-1, 80, 8, 8]               0\n",
      "Conv2dStaticSamePadding-138            [-1, 480, 8, 8]          38,400\n",
      "       GroupNorm-139            [-1, 480, 8, 8]             960\n",
      "MemoryEfficientSwish-140            [-1, 480, 8, 8]               0\n",
      "       ZeroPad2d-141          [-1, 480, 12, 12]               0\n",
      "Conv2dStaticSamePadding-142            [-1, 480, 8, 8]          12,000\n",
      "       GroupNorm-143            [-1, 480, 8, 8]             960\n",
      "MemoryEfficientSwish-144            [-1, 480, 8, 8]               0\n",
      "        Identity-145            [-1, 480, 1, 1]               0\n",
      "Conv2dStaticSamePadding-146             [-1, 20, 1, 1]           9,620\n",
      "MemoryEfficientSwish-147             [-1, 20, 1, 1]               0\n",
      "        Identity-148             [-1, 20, 1, 1]               0\n",
      "Conv2dStaticSamePadding-149            [-1, 480, 1, 1]          10,080\n",
      "        Identity-150            [-1, 480, 8, 8]               0\n",
      "Conv2dStaticSamePadding-151            [-1, 112, 8, 8]          53,760\n",
      "       GroupNorm-152            [-1, 112, 8, 8]             224\n",
      "     MBConvBlock-153            [-1, 112, 8, 8]               0\n",
      "        Identity-154            [-1, 112, 8, 8]               0\n",
      "Conv2dStaticSamePadding-155            [-1, 672, 8, 8]          75,264\n",
      "       GroupNorm-156            [-1, 672, 8, 8]           1,344\n",
      "MemoryEfficientSwish-157            [-1, 672, 8, 8]               0\n",
      "       ZeroPad2d-158          [-1, 672, 12, 12]               0\n",
      "Conv2dStaticSamePadding-159            [-1, 672, 8, 8]          16,800\n",
      "       GroupNorm-160            [-1, 672, 8, 8]           1,344\n",
      "MemoryEfficientSwish-161            [-1, 672, 8, 8]               0\n",
      "        Identity-162            [-1, 672, 1, 1]               0\n",
      "Conv2dStaticSamePadding-163             [-1, 28, 1, 1]          18,844\n",
      "MemoryEfficientSwish-164             [-1, 28, 1, 1]               0\n",
      "        Identity-165             [-1, 28, 1, 1]               0\n",
      "Conv2dStaticSamePadding-166            [-1, 672, 1, 1]          19,488\n",
      "        Identity-167            [-1, 672, 8, 8]               0\n",
      "Conv2dStaticSamePadding-168            [-1, 112, 8, 8]          75,264\n",
      "       GroupNorm-169            [-1, 112, 8, 8]             224\n",
      "     MBConvBlock-170            [-1, 112, 8, 8]               0\n",
      "        Identity-171            [-1, 112, 8, 8]               0\n",
      "Conv2dStaticSamePadding-172            [-1, 672, 8, 8]          75,264\n",
      "       GroupNorm-173            [-1, 672, 8, 8]           1,344\n",
      "MemoryEfficientSwish-174            [-1, 672, 8, 8]               0\n",
      "       ZeroPad2d-175          [-1, 672, 12, 12]               0\n",
      "Conv2dStaticSamePadding-176            [-1, 672, 8, 8]          16,800\n",
      "       GroupNorm-177            [-1, 672, 8, 8]           1,344\n",
      "MemoryEfficientSwish-178            [-1, 672, 8, 8]               0\n",
      "        Identity-179            [-1, 672, 1, 1]               0\n",
      "Conv2dStaticSamePadding-180             [-1, 28, 1, 1]          18,844\n",
      "MemoryEfficientSwish-181             [-1, 28, 1, 1]               0\n",
      "        Identity-182             [-1, 28, 1, 1]               0\n",
      "Conv2dStaticSamePadding-183            [-1, 672, 1, 1]          19,488\n",
      "        Identity-184            [-1, 672, 8, 8]               0\n",
      "Conv2dStaticSamePadding-185            [-1, 112, 8, 8]          75,264\n",
      "       GroupNorm-186            [-1, 112, 8, 8]             224\n",
      "     MBConvBlock-187            [-1, 112, 8, 8]               0\n",
      "        Identity-188            [-1, 112, 8, 8]               0\n",
      "Conv2dStaticSamePadding-189            [-1, 672, 8, 8]          75,264\n",
      "       GroupNorm-190            [-1, 672, 8, 8]           1,344\n",
      "MemoryEfficientSwish-191            [-1, 672, 8, 8]               0\n",
      "       ZeroPad2d-192          [-1, 672, 11, 11]               0\n",
      "Conv2dStaticSamePadding-193            [-1, 672, 4, 4]          16,800\n",
      "       GroupNorm-194            [-1, 672, 4, 4]           1,344\n",
      "MemoryEfficientSwish-195            [-1, 672, 4, 4]               0\n",
      "        Identity-196            [-1, 672, 1, 1]               0\n",
      "Conv2dStaticSamePadding-197             [-1, 28, 1, 1]          18,844\n",
      "MemoryEfficientSwish-198             [-1, 28, 1, 1]               0\n",
      "        Identity-199             [-1, 28, 1, 1]               0\n",
      "Conv2dStaticSamePadding-200            [-1, 672, 1, 1]          19,488\n",
      "        Identity-201            [-1, 672, 4, 4]               0\n",
      "Conv2dStaticSamePadding-202            [-1, 192, 4, 4]         129,024\n",
      "       GroupNorm-203            [-1, 192, 4, 4]             384\n",
      "     MBConvBlock-204            [-1, 192, 4, 4]               0\n",
      "        Identity-205            [-1, 192, 4, 4]               0\n",
      "Conv2dStaticSamePadding-206           [-1, 1152, 4, 4]         221,184\n",
      "       GroupNorm-207           [-1, 1152, 4, 4]           2,304\n",
      "MemoryEfficientSwish-208           [-1, 1152, 4, 4]               0\n",
      "       ZeroPad2d-209           [-1, 1152, 8, 8]               0\n",
      "Conv2dStaticSamePadding-210           [-1, 1152, 4, 4]          28,800\n",
      "       GroupNorm-211           [-1, 1152, 4, 4]           2,304\n",
      "MemoryEfficientSwish-212           [-1, 1152, 4, 4]               0\n",
      "        Identity-213           [-1, 1152, 1, 1]               0\n",
      "Conv2dStaticSamePadding-214             [-1, 48, 1, 1]          55,344\n",
      "MemoryEfficientSwish-215             [-1, 48, 1, 1]               0\n",
      "        Identity-216             [-1, 48, 1, 1]               0\n",
      "Conv2dStaticSamePadding-217           [-1, 1152, 1, 1]          56,448\n",
      "        Identity-218           [-1, 1152, 4, 4]               0\n",
      "Conv2dStaticSamePadding-219            [-1, 192, 4, 4]         221,184\n",
      "       GroupNorm-220            [-1, 192, 4, 4]             384\n",
      "     MBConvBlock-221            [-1, 192, 4, 4]               0\n",
      "        Identity-222            [-1, 192, 4, 4]               0\n",
      "Conv2dStaticSamePadding-223           [-1, 1152, 4, 4]         221,184\n",
      "       GroupNorm-224           [-1, 1152, 4, 4]           2,304\n",
      "MemoryEfficientSwish-225           [-1, 1152, 4, 4]               0\n",
      "       ZeroPad2d-226           [-1, 1152, 8, 8]               0\n",
      "Conv2dStaticSamePadding-227           [-1, 1152, 4, 4]          28,800\n",
      "       GroupNorm-228           [-1, 1152, 4, 4]           2,304\n",
      "MemoryEfficientSwish-229           [-1, 1152, 4, 4]               0\n",
      "        Identity-230           [-1, 1152, 1, 1]               0\n",
      "Conv2dStaticSamePadding-231             [-1, 48, 1, 1]          55,344\n",
      "MemoryEfficientSwish-232             [-1, 48, 1, 1]               0\n",
      "        Identity-233             [-1, 48, 1, 1]               0\n",
      "Conv2dStaticSamePadding-234           [-1, 1152, 1, 1]          56,448\n",
      "        Identity-235           [-1, 1152, 4, 4]               0\n",
      "Conv2dStaticSamePadding-236            [-1, 192, 4, 4]         221,184\n",
      "       GroupNorm-237            [-1, 192, 4, 4]             384\n",
      "     MBConvBlock-238            [-1, 192, 4, 4]               0\n",
      "        Identity-239            [-1, 192, 4, 4]               0\n",
      "Conv2dStaticSamePadding-240           [-1, 1152, 4, 4]         221,184\n",
      "       GroupNorm-241           [-1, 1152, 4, 4]           2,304\n",
      "MemoryEfficientSwish-242           [-1, 1152, 4, 4]               0\n",
      "       ZeroPad2d-243           [-1, 1152, 8, 8]               0\n",
      "Conv2dStaticSamePadding-244           [-1, 1152, 4, 4]          28,800\n",
      "       GroupNorm-245           [-1, 1152, 4, 4]           2,304\n",
      "MemoryEfficientSwish-246           [-1, 1152, 4, 4]               0\n",
      "        Identity-247           [-1, 1152, 1, 1]               0\n",
      "Conv2dStaticSamePadding-248             [-1, 48, 1, 1]          55,344\n",
      "MemoryEfficientSwish-249             [-1, 48, 1, 1]               0\n",
      "        Identity-250             [-1, 48, 1, 1]               0\n",
      "Conv2dStaticSamePadding-251           [-1, 1152, 1, 1]          56,448\n",
      "        Identity-252           [-1, 1152, 4, 4]               0\n",
      "Conv2dStaticSamePadding-253            [-1, 192, 4, 4]         221,184\n",
      "       GroupNorm-254            [-1, 192, 4, 4]             384\n",
      "     MBConvBlock-255            [-1, 192, 4, 4]               0\n",
      "        Identity-256            [-1, 192, 4, 4]               0\n",
      "Conv2dStaticSamePadding-257           [-1, 1152, 4, 4]         221,184\n",
      "       GroupNorm-258           [-1, 1152, 4, 4]           2,304\n",
      "MemoryEfficientSwish-259           [-1, 1152, 4, 4]               0\n",
      "       ZeroPad2d-260           [-1, 1152, 6, 6]               0\n",
      "Conv2dStaticSamePadding-261           [-1, 1152, 4, 4]          10,368\n",
      "       GroupNorm-262           [-1, 1152, 4, 4]           2,304\n",
      "MemoryEfficientSwish-263           [-1, 1152, 4, 4]               0\n",
      "        Identity-264           [-1, 1152, 1, 1]               0\n",
      "Conv2dStaticSamePadding-265             [-1, 48, 1, 1]          55,344\n",
      "MemoryEfficientSwish-266             [-1, 48, 1, 1]               0\n",
      "        Identity-267             [-1, 48, 1, 1]               0\n",
      "Conv2dStaticSamePadding-268           [-1, 1152, 1, 1]          56,448\n",
      "        Identity-269           [-1, 1152, 4, 4]               0\n",
      "Conv2dStaticSamePadding-270            [-1, 320, 4, 4]         368,640\n",
      "       GroupNorm-271            [-1, 320, 4, 4]             640\n",
      "     MBConvBlock-272            [-1, 320, 4, 4]               0\n",
      "        Identity-273            [-1, 320, 4, 4]               0\n",
      "Conv2dStaticSamePadding-274           [-1, 1280, 4, 4]         409,600\n",
      "       GroupNorm-275           [-1, 1280, 4, 4]           2,560\n",
      "MemoryEfficientSwish-276           [-1, 1280, 4, 4]               0\n",
      "AdaptiveAvgPool2d-277           [-1, 1280, 1, 1]               0\n",
      "         Dropout-278                 [-1, 1280]               0\n",
      "          Linear-279                    [-1, 2]           2,562\n",
      "================================================================\n",
      "Total params: 4,010,110\n",
      "Trainable params: 4,010,110\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.19\n",
      "Forward/backward pass size (MB): 71.49\n",
      "Params size (MB): 15.30\n",
      "Estimated Total Size (MB): 86.97\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, input_size=(3,128,128),device='cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = optim.SGD(filter(lambda p: p.requires_grad, model.parameters()), lr=lr, momentum=momentum)\n",
    "# optimizer = optim.Adam(model.parameters(), weight_decay=0)\n",
    "scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)\n",
    "scheduler_warmup = GradualWarmupScheduler(optimizer, multiplier=8, total_epoch=10, after_scheduler=scheduler_cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resume\n",
    "if resume:\n",
    "    print('==> Resuming from checkpoint..')\n",
    "    checkpoint = os.path.dirname(resume)\n",
    "#     checkpoint = torch.load(resume)\n",
    "    resume = torch.load(resume)\n",
    "    best_acc = resume['best_acc']\n",
    "    start_epoch = resume['epoch']\n",
    "    model.load_state_dict(resume['state_dict'])\n",
    "    optimizer.load_state_dict(resume['optimizer'])\n",
    "    logger = Logger(os.path.join(checkpoint, 'log.txt'), resume=True)\n",
    "else:\n",
    "    logger = Logger(os.path.join(checkpoint, 'log.txt'))\n",
    "    logger.set_names(['Learning Rate', 'Train Loss', 'Valid Loss', 'Train Acc.', 'Valid Acc.', 'Source Loss', 'Source ACC.'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch, use_cuda):\n",
    "    model.train()\n",
    "    torch.set_grad_enabled(True)\n",
    "    \n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    end = time.time()\n",
    "    \n",
    "    bar = Bar('Processing', max=len(train_loader))\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        batch_size = inputs.size(0)\n",
    "        if batch_size < train_batch:\n",
    "            continue\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "        inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "\n",
    "        # compute output\n",
    "        outputs = model(inputs)\n",
    "        loss_main = criterion(outputs, targets)\n",
    "        loss_cls = 0\n",
    "        loss_sp = 0\n",
    "        loss = loss_main + alpha*loss_sp + beta*loss_cls\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1 = accuracy(outputs.data, targets.data)\n",
    "        losses.update(loss.data.tolist(), inputs.size(0))\n",
    "        top1.update(prec1[0], inputs.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        # plot progress\n",
    "        bar.suffix  = '({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | Total: {total:} | ETA: {eta:} | Loss: {loss:.4f} | top1: {top1: .4f} '.format(\n",
    "                    batch=batch_idx + 1,\n",
    "                    size=len(train_loader),\n",
    "                    data=data_time.val,\n",
    "                    bt=batch_time.val,\n",
    "                    total=bar.elapsed_td,\n",
    "                    eta=bar.eta_td,\n",
    "                    loss=losses.avg,\n",
    "                    top1=top1.avg,\n",
    "                    )\n",
    "        bar.next()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('{batch}/{size} | Total:{total:} | ETA:{eta:} | Loss:{loss:} | top1:{tp1:}'.format(\n",
    "                 batch=batch_idx+1, size=len(train_loader), total=bar.elapsed_td, eta=bar.eta_td, loss=losses.avg, tp1=top1.avg))\n",
    "    print('{batch}/{size} | Total:{total:} | ETA:{eta:} | Loss:{loss:} | top1:{tp1:}'.format(\n",
    "                 batch=batch_idx+1, size=len(train_loader), total=bar.elapsed_td, eta=bar.eta_td, loss=losses.avg, tp1=top1.avg))\n",
    "    bar.finish()\n",
    "    return (losses.avg, top1.avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(val_loader, model, criterion, epoch, use_cuda):\n",
    "    global best_acc\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "    torch.set_grad_enabled(False)\n",
    "\n",
    "    end = time.time()\n",
    "    bar = Bar('Processing', max=len(val_loader))\n",
    "    for batch_idx, (inputs, targets) in enumerate(val_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "        inputs, targets = torch.autograd.Variable(inputs, volatile=True), torch.autograd.Variable(targets)\n",
    "\n",
    "        # compute output\n",
    "        outputs = model(inputs)\n",
    "        loss_main = criterion(outputs, targets)\n",
    "        loss_cls = 0\n",
    "        loss_sp = 0\n",
    "        loss = loss_main + alpha*loss_sp + beta*loss_cls\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1 = accuracy(outputs.data, targets.data)\n",
    "        losses.update(loss.data.tolist(), inputs.size(0))\n",
    "        top1.update(prec1[0], inputs.size(0))\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        # plot progress\n",
    "        bar.suffix  = '({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | Total: {total:} | ETA: {eta:} | Loss: {loss:} | top1: {top1:}'.format(\n",
    "                    batch=batch_idx + 1,\n",
    "                    size=len(val_loader),\n",
    "                    data=data_time.avg,\n",
    "                    bt=batch_time.avg,\n",
    "                    total=bar.elapsed_td,\n",
    "                    eta=bar.eta_td,\n",
    "                    loss=losses.avg,\n",
    "                    top1=top1.avg,)\n",
    "        bar.next()\n",
    "    print('{batch}/{size} | Total:{total:} | ETA:{eta:} | Loss:{loss:} | top1:{tp1:}'.format(\n",
    "         batch=batch_idx+1, size=len(val_loader), total=bar.elapsed_td, eta=bar.eta_td, loss=losses.avg, tp1=top1.avg))\n",
    "    bar.finish()\n",
    "    return (losses.avg, top1.avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, checkpoint='checkpoint', filename='checkpoint.pth.tar'):\n",
    "    filepath = os.path.join(checkpoint, filename)\n",
    "    torch.save(state, filepath)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filepath, os.path.join(checkpoint, 'model_best.pth.tar'))\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    global state\n",
    "    lr_set = [1, 1e-1, 1e-2, 1e-3, 1e-4, 1e-5]\n",
    "    lr_list = schedule.copy()\n",
    "    lr_list.append(epoch)\n",
    "    lr_list.sort()\n",
    "    idx = lr_list.index(epoch)\n",
    "    state['lr'] *= lr_set[idx]\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = state['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [1 | 5000] LR: 0.010000\n",
      "1/7 | Total:0:00:01 | ETA:0:00:09 | Loss:0.690214991569519 | top1:43.75\n",
      "7/7 | Total:0:00:02 | ETA:0:00:01 | Loss:0.6997587581475576 | top1:46.35416793823242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cutz/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:21: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107/107 | Total:0:00:15 | ETA:0:00:00 | Loss:0.6936262093971823 | top1:50.97196578979492\n",
      "26/26 | Total:0:00:16 | ETA:0:00:00 | Loss:0.6947475534219009 | top1:50.166664123535156\n",
      "\n",
      "Epoch: [2 | 5000] LR: 0.017000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:04 | Loss:0.688365638256073 | top1:56.25\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.6954130629698435 | top1:51.5625\n",
      "\n",
      "Epoch: [3 | 5000] LR: 0.017000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:05 | Loss:0.6820546388626099 | top1:59.375\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.6951670547326406 | top1:53.125\n",
      "\n",
      "Epoch: [4 | 5000] LR: 0.017000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:06 | Loss:0.6919676661491394 | top1:40.625\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.701008270184199 | top1:43.75\n",
      "\n",
      "Epoch: [5 | 5000] LR: 0.017000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:05 | Loss:0.7058060169219971 | top1:40.625\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.7032516598701477 | top1:48.4375\n",
      "\n",
      "Epoch: [6 | 5000] LR: 0.017000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:05 | Loss:0.7026092410087585 | top1:46.875\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.7107924123605093 | top1:51.04166793823242\n",
      "\n",
      "Epoch: [7 | 5000] LR: 0.017000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:05 | Loss:0.7431275248527527 | top1:40.625\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.708655854066213 | top1:46.875\n",
      "\n",
      "Epoch: [8 | 5000] LR: 0.017000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:05 | Loss:0.7049610614776611 | top1:50.0\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.7095093031724294 | top1:44.79166793823242\n",
      "\n",
      "Epoch: [9 | 5000] LR: 0.017000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:05 | Loss:0.6892287135124207 | top1:53.125\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.7009030977884928 | top1:49.47916793823242\n",
      "\n",
      "Epoch: [10 | 5000] LR: 0.017000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:05 | Loss:0.6972202658653259 | top1:56.25\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.6921068330605825 | top1:54.16666793823242\n",
      "\n",
      "Epoch: [11 | 5000] LR: 0.017000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:05 | Loss:0.681373655796051 | top1:56.25\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.6940588553746542 | top1:51.04166793823242\n",
      "\n",
      "Epoch: [12 | 5000] LR: 0.017000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:04 | Loss:0.6840282678604126 | top1:53.125\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.7178049286206564 | top1:44.270835876464844\n",
      "\n",
      "Epoch: [13 | 5000] LR: 0.017000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:06 | Loss:0.6926037669181824 | top1:43.75\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.7072625557581583 | top1:47.395835876464844\n",
      "\n",
      "Epoch: [14 | 5000] LR: 0.017000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:06 | Loss:0.7096268534660339 | top1:50.0\n",
      "7/7 | Total:0:00:02 | ETA:0:00:01 | Loss:0.7022355993588766 | top1:47.91666793823242\n",
      "\n",
      "Epoch: [15 | 5000] LR: 0.017000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:04 | Loss:0.6896008253097534 | top1:56.25\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.6887750029563904 | top1:51.5625\n",
      "\n",
      "Epoch: [16 | 5000] LR: 0.017000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:05 | Loss:0.7010279297828674 | top1:46.875\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.7046933770179749 | top1:46.875\n",
      "\n",
      "Epoch: [17 | 5000] LR: 0.017000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:05 | Loss:0.6950504183769226 | top1:46.875\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.6937135259310404 | top1:50.0\n",
      "\n",
      "Epoch: [18 | 5000] LR: 0.017000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:06 | Loss:0.6863277554512024 | top1:59.375\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.7079574167728424 | top1:51.5625\n",
      "\n",
      "Epoch: [19 | 5000] LR: 0.017000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:05 | Loss:0.6984883546829224 | top1:46.875\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.701440672079722 | top1:47.91666793823242\n",
      "\n",
      "Epoch: [20 | 5000] LR: 0.017000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:06 | Loss:0.6719109416007996 | top1:65.625\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.702576200167338 | top1:50.520835876464844\n",
      "\n",
      "Epoch: [21 | 5000] LR: 0.017000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:05 | Loss:0.7085602879524231 | top1:43.75\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.7008165021737417 | top1:47.91666793823242\n",
      "\n",
      "Epoch: [22 | 5000] LR: 0.017000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:04 | Loss:0.7076019644737244 | top1:43.75\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.7074602742989858 | top1:40.10416793823242\n",
      "\n",
      "Epoch: [23 | 5000] LR: 0.017000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:05 | Loss:0.7171657681465149 | top1:46.875\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.7018126249313354 | top1:44.79166793823242\n",
      "\n",
      "Epoch: [24 | 5000] LR: 0.017000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:04 | Loss:0.6820610165596008 | top1:62.5\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.6913514931996664 | top1:52.083335876464844\n",
      "\n",
      "Epoch: [25 | 5000] LR: 0.017000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:05 | Loss:0.7070778608322144 | top1:43.75\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.7098486622174581 | top1:42.708335876464844\n",
      "\n",
      "Epoch: [26 | 5000] LR: 0.017000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:05 | Loss:0.6916162371635437 | top1:56.25\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.6999427477518717 | top1:51.04166793823242\n",
      "\n",
      "Epoch: [27 | 5000] LR: 0.017000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:05 | Loss:0.7319621443748474 | top1:37.5\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.7098229030768076 | top1:49.47916793823242\n",
      "\n",
      "Epoch: [28 | 5000] LR: 0.017000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:04 | Loss:0.7037960886955261 | top1:37.5\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.6949616273244222 | top1:49.47916793823242\n",
      "\n",
      "Epoch: [29 | 5000] LR: 0.017000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:06 | Loss:0.7236979603767395 | top1:40.625\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.7095449070135752 | top1:44.270835876464844\n",
      "\n",
      "Epoch: [30 | 5000] LR: 0.017000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:05 | Loss:0.7046909332275391 | top1:43.75\n",
      "7/7 | Total:0:00:02 | ETA:0:00:01 | Loss:0.7060721615950266 | top1:45.833335876464844\n",
      "\n",
      "Epoch: [31 | 5000] LR: 0.017000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:06 | Loss:0.6857858896255493 | top1:50.0\n",
      "7/7 | Total:0:00:02 | ETA:0:00:01 | Loss:0.6931419571240743 | top1:51.04166793823242\n",
      "\n",
      "Epoch: [32 | 5000] LR: 0.017000\n",
      "1/7 | Total:0:00:01 | ETA:0:00:09 | Loss:0.7214227914810181 | top1:43.75\n",
      "7/7 | Total:0:00:02 | ETA:0:00:01 | Loss:0.7104331652323405 | top1:50.0\n",
      "\n",
      "Epoch: [33 | 5000] LR: 0.017000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:04 | Loss:0.6973580718040466 | top1:59.375\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.6976459821065267 | top1:52.083335876464844\n",
      "\n",
      "Epoch: [34 | 5000] LR: 0.017000\n",
      "1/7 | Total:0:00:01 | ETA:0:00:07 | Loss:0.7166227102279663 | top1:40.625\n",
      "7/7 | Total:0:00:02 | ETA:0:00:01 | Loss:0.7255580822626749 | top1:44.79166793823242\n",
      "\n",
      "Epoch: [35 | 5000] LR: 0.017000\n",
      "1/7 | Total:0:00:01 | ETA:0:00:07 | Loss:0.6903771758079529 | top1:56.25\n",
      "7/7 | Total:0:00:02 | ETA:0:00:01 | Loss:0.6987046400705973 | top1:50.520835876464844\n",
      "\n",
      "Epoch: [36 | 5000] LR: 0.017000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:05 | Loss:0.6933217644691467 | top1:53.125\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.696258544921875 | top1:51.5625\n",
      "\n",
      "Epoch: [37 | 5000] LR: 0.017000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:05 | Loss:0.6856171488761902 | top1:53.125\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.6971717973550161 | top1:47.395835876464844\n",
      "\n",
      "Epoch: [38 | 5000] LR: 0.017000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:06 | Loss:0.6970851421356201 | top1:50.0\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.6963717440764109 | top1:47.91666793823242\n",
      "\n",
      "Epoch: [39 | 5000] LR: 0.017000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:06 | Loss:0.6959875226020813 | top1:46.875\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.6963687737782797 | top1:50.0\n",
      "\n",
      "Epoch: [40 | 5000] LR: 0.017000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:05 | Loss:0.7240729928016663 | top1:37.5\n",
      "7/7 | Total:0:00:02 | ETA:0:00:01 | Loss:0.7193720440069834 | top1:46.35416793823242\n",
      "\n",
      "Epoch: [41 | 5000] LR: 0.017000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:04 | Loss:0.6911698579788208 | top1:56.25\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.7033740778764089 | top1:52.083335876464844\n",
      "\n",
      "Epoch: [42 | 5000] LR: 0.017000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:06 | Loss:0.6954755187034607 | top1:43.75\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.6973538796106974 | top1:47.91666793823242\n",
      "\n",
      "Epoch: [43 | 5000] LR: 0.017000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:05 | Loss:0.6882176399230957 | top1:53.125\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.6959250569343567 | top1:51.5625\n",
      "\n",
      "Epoch: [44 | 5000] LR: 0.017000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:04 | Loss:0.6789434552192688 | top1:62.5\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.7052596211433411 | top1:49.47916793823242\n",
      "\n",
      "Epoch: [45 | 5000] LR: 0.017000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/7 | Total:0:00:00 | ETA:0:00:04 | Loss:0.6915392279624939 | top1:59.375\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.7020840446154276 | top1:49.47916793823242\n",
      "\n",
      "Epoch: [46 | 5000] LR: 0.017000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:05 | Loss:0.697661817073822 | top1:50.0\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.754312127828598 | top1:43.22916793823242\n",
      "\n",
      "Epoch: [47 | 5000] LR: 0.017000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:05 | Loss:0.7079299092292786 | top1:40.625\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.7023384670416514 | top1:43.75\n",
      "\n",
      "Epoch: [48 | 5000] LR: 0.017000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:06 | Loss:0.6860573887825012 | top1:56.25\n",
      "7/7 | Total:0:00:02 | ETA:0:00:01 | Loss:0.6864157716433207 | top1:56.770835876464844\n",
      "\n",
      "Epoch: [49 | 5000] LR: 0.017000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:05 | Loss:0.7189685106277466 | top1:40.625\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.7041926681995392 | top1:48.958335876464844\n",
      "\n",
      "Epoch: [50 | 5000] LR: 0.017000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:05 | Loss:0.6956718564033508 | top1:50.0\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.6993870238463084 | top1:44.79166793823242\n",
      "\n",
      "Epoch: [51 | 5000] LR: 0.017000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:05 | Loss:0.7219592332839966 | top1:40.625\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.6997566322485606 | top1:47.395835876464844\n",
      "107/107 | Total:0:00:15 | ETA:0:00:00 | Loss:0.6984006361426595 | top1:50.068538665771484\n",
      "26/26 | Total:0:00:13 | ETA:0:00:00 | Loss:0.6994331226899073 | top1:50.025638580322266\n",
      "\n",
      "Epoch: [52 | 5000] LR: 0.024000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:05 | Loss:0.7011987566947937 | top1:46.875\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.7088873585065206 | top1:53.645835876464844\n",
      "\n",
      "Epoch: [53 | 5000] LR: 0.024000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:05 | Loss:0.6849908232688904 | top1:50.0\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.7059662044048309 | top1:47.395835876464844\n",
      "\n",
      "Epoch: [54 | 5000] LR: 0.024000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:05 | Loss:0.7946048974990845 | top1:40.625\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.7320180932680765 | top1:46.875\n",
      "\n",
      "Epoch: [55 | 5000] LR: 0.024000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:05 | Loss:0.6994509100914001 | top1:46.875\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.7003563245137533 | top1:50.0\n",
      "\n",
      "Epoch: [56 | 5000] LR: 0.024000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:05 | Loss:0.6929241418838501 | top1:34.375\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.7077110906442007 | top1:46.35416793823242\n",
      "\n",
      "Epoch: [57 | 5000] LR: 0.024000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:04 | Loss:0.6788259148597717 | top1:71.875\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.705828070640564 | top1:48.4375\n",
      "\n",
      "Epoch: [58 | 5000] LR: 0.024000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:05 | Loss:0.6960422992706299 | top1:53.125\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.7013749082883199 | top1:49.47916793823242\n",
      "\n",
      "Epoch: [59 | 5000] LR: 0.024000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:04 | Loss:0.6676287055015564 | top1:59.375\n",
      "7/7 | Total:0:00:02 | ETA:0:00:01 | Loss:0.7069010138511658 | top1:52.60416793823242\n",
      "\n",
      "Epoch: [60 | 5000] LR: 0.024000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:06 | Loss:0.7352536916732788 | top1:46.875\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.7203955352306366 | top1:44.79166793823242\n",
      "\n",
      "Epoch: [61 | 5000] LR: 0.024000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:06 | Loss:0.715762734413147 | top1:25.0\n",
      "7/7 | Total:0:00:02 | ETA:0:00:01 | Loss:0.7082657913366953 | top1:49.47916793823242\n",
      "\n",
      "Epoch: [62 | 5000] LR: 0.024000\n",
      "1/7 | Total:0:00:01 | ETA:0:00:07 | Loss:0.6809980273246765 | top1:59.375\n",
      "7/7 | Total:0:00:02 | ETA:0:00:01 | Loss:0.6920532087484995 | top1:56.25\n",
      "\n",
      "Epoch: [63 | 5000] LR: 0.024000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:04 | Loss:0.7222688794136047 | top1:46.875\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.7148600816726685 | top1:53.645835876464844\n",
      "\n",
      "Epoch: [64 | 5000] LR: 0.024000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:06 | Loss:0.6869255900382996 | top1:59.375\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.694832036892573 | top1:50.520835876464844\n",
      "\n",
      "Epoch: [65 | 5000] LR: 0.024000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:05 | Loss:0.7099486589431763 | top1:46.875\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.7058837215105692 | top1:50.0\n",
      "\n",
      "Epoch: [66 | 5000] LR: 0.024000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:06 | Loss:0.6709640622138977 | top1:62.5\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.693527489900589 | top1:52.083335876464844\n",
      "\n",
      "Epoch: [67 | 5000] LR: 0.024000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:05 | Loss:0.695026695728302 | top1:46.875\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.7098455627759298 | top1:46.875\n",
      "\n",
      "Epoch: [68 | 5000] LR: 0.024000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:05 | Loss:0.6622657775878906 | top1:59.375\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.7218442658583323 | top1:50.520835876464844\n",
      "\n",
      "Epoch: [69 | 5000] LR: 0.024000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:04 | Loss:0.6877667903900146 | top1:59.375\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.7144604325294495 | top1:48.958335876464844\n",
      "\n",
      "Epoch: [70 | 5000] LR: 0.024000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:06 | Loss:0.6838197112083435 | top1:59.375\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.712201863527298 | top1:51.04166793823242\n",
      "\n",
      "Epoch: [71 | 5000] LR: 0.024000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:04 | Loss:0.7211263179779053 | top1:50.0\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.7108127971490225 | top1:51.5625\n",
      "\n",
      "Epoch: [72 | 5000] LR: 0.024000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:05 | Loss:0.6895402073860168 | top1:59.375\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.7160687446594238 | top1:54.6875\n",
      "\n",
      "Epoch: [73 | 5000] LR: 0.024000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:04 | Loss:0.727990448474884 | top1:40.625\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.7053815921147665 | top1:47.91666793823242\n",
      "\n",
      "Epoch: [74 | 5000] LR: 0.024000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:06 | Loss:0.694660484790802 | top1:50.0\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.6987992723782858 | top1:48.958335876464844\n",
      "\n",
      "Epoch: [75 | 5000] LR: 0.024000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:05 | Loss:0.700727641582489 | top1:50.0\n",
      "7/7 | Total:0:00:02 | ETA:0:00:01 | Loss:0.7117274900277456 | top1:46.875\n",
      "\n",
      "Epoch: [76 | 5000] LR: 0.024000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:04 | Loss:0.7206287980079651 | top1:40.625\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.6984292169411978 | top1:52.60416793823242\n",
      "\n",
      "Epoch: [77 | 5000] LR: 0.024000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:05 | Loss:0.6623435616493225 | top1:62.5\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.7020101149876913 | top1:49.47916793823242\n",
      "\n",
      "Epoch: [78 | 5000] LR: 0.024000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:05 | Loss:0.6776869297027588 | top1:56.25\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.6888207892576853 | top1:51.04166793823242\n",
      "\n",
      "Epoch: [79 | 5000] LR: 0.024000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:04 | Loss:0.6854782104492188 | top1:40.625\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.6928435365358988 | top1:50.520835876464844\n",
      "\n",
      "Epoch: [80 | 5000] LR: 0.024000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:05 | Loss:0.6793872714042664 | top1:59.375\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.6920602023601532 | top1:53.645835876464844\n",
      "\n",
      "Epoch: [81 | 5000] LR: 0.024000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:04 | Loss:0.695458710193634 | top1:50.0\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.6972661713759104 | top1:52.083335876464844\n",
      "\n",
      "Epoch: [82 | 5000] LR: 0.024000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:06 | Loss:0.6744900345802307 | top1:62.5\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.69583131869634 | top1:54.16666793823242\n",
      "\n",
      "Epoch: [83 | 5000] LR: 0.024000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:04 | Loss:0.6871468424797058 | top1:53.125\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.7124618093172709 | top1:50.0\n",
      "\n",
      "Epoch: [84 | 5000] LR: 0.024000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:05 | Loss:0.7136795520782471 | top1:50.0\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.6972964306672415 | top1:50.520835876464844\n",
      "\n",
      "Epoch: [85 | 5000] LR: 0.024000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:04 | Loss:0.6703324913978577 | top1:59.375\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.6872211496035258 | top1:52.60416793823242\n",
      "\n",
      "Epoch: [86 | 5000] LR: 0.024000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:05 | Loss:0.805246889591217 | top1:40.625\n",
      "7/7 | Total:0:00:02 | ETA:0:00:01 | Loss:0.7048146625359853 | top1:53.125\n",
      "\n",
      "Epoch: [87 | 5000] LR: 0.024000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:05 | Loss:0.6941527128219604 | top1:56.25\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.6843374868233999 | top1:57.29166793823242\n",
      "\n",
      "Epoch: [88 | 5000] LR: 0.024000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/7 | Total:0:00:00 | ETA:0:00:05 | Loss:0.6678696274757385 | top1:62.5\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.6978679796059927 | top1:51.5625\n",
      "\n",
      "Epoch: [89 | 5000] LR: 0.024000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:05 | Loss:0.6843180656433105 | top1:56.25\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.6848803957303365 | top1:53.125\n",
      "\n",
      "Epoch: [90 | 5000] LR: 0.024000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:04 | Loss:0.6656951308250427 | top1:65.625\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.6902437607447306 | top1:59.375\n",
      "\n",
      "Epoch: [91 | 5000] LR: 0.024000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:05 | Loss:0.7362290620803833 | top1:50.0\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.6859979033470154 | top1:56.770835876464844\n",
      "\n",
      "Epoch: [92 | 5000] LR: 0.024000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:05 | Loss:0.7021825313568115 | top1:50.0\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.7007938722769419 | top1:53.645835876464844\n",
      "\n",
      "Epoch: [93 | 5000] LR: 0.024000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:05 | Loss:0.7430163025856018 | top1:40.625\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.7022456030050913 | top1:50.520835876464844\n",
      "\n",
      "Epoch: [94 | 5000] LR: 0.024000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:04 | Loss:0.6404673457145691 | top1:59.375\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.680384119351705 | top1:54.16666793823242\n",
      "\n",
      "Epoch: [95 | 5000] LR: 0.024000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:05 | Loss:0.6808846592903137 | top1:50.0\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.6712552110354105 | top1:55.72916793823242\n",
      "\n",
      "Epoch: [96 | 5000] LR: 0.024000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:06 | Loss:0.6400353312492371 | top1:68.75\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.6834809680779775 | top1:57.29166793823242\n",
      "\n",
      "Epoch: [97 | 5000] LR: 0.024000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:05 | Loss:0.6968368887901306 | top1:53.125\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.6804907321929932 | top1:60.9375\n",
      "\n",
      "Epoch: [98 | 5000] LR: 0.024000\n",
      "1/7 | Total:0:00:01 | ETA:0:00:07 | Loss:0.6537478566169739 | top1:68.75\n",
      "7/7 | Total:0:00:02 | ETA:0:00:01 | Loss:0.6701561510562897 | top1:58.85416793823242\n",
      "\n",
      "Epoch: [99 | 5000] LR: 0.024000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:05 | Loss:0.6833934783935547 | top1:50.0\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.6784993410110474 | top1:55.72916793823242\n",
      "\n",
      "Epoch: [100 | 5000] LR: 0.024000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:05 | Loss:0.6584702730178833 | top1:59.375\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.6828777392705282 | top1:58.85416793823242\n",
      "\n",
      "Epoch: [101 | 5000] LR: 0.024000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:04 | Loss:0.6814592480659485 | top1:56.25\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.6919357577959696 | top1:53.645835876464844\n",
      "107/107 | Total:0:00:14 | ETA:0:00:00 | Loss:0.733011114263089 | top1:50.01557922363281\n",
      "26/26 | Total:0:00:13 | ETA:0:00:00 | Loss:0.7954375675091376 | top1:50.0\n",
      "\n",
      "Epoch: [102 | 5000] LR: 0.031000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:04 | Loss:0.7512988448143005 | top1:53.125\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.6842879354953766 | top1:58.85416793823242\n",
      "\n",
      "Epoch: [103 | 5000] LR: 0.031000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:05 | Loss:0.696179986000061 | top1:56.25\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.6929840743541718 | top1:53.125\n",
      "\n",
      "Epoch: [104 | 5000] LR: 0.031000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:05 | Loss:0.6718478202819824 | top1:53.125\n",
      "7/7 | Total:0:00:02 | ETA:0:00:01 | Loss:0.7189796467622122 | top1:50.520835876464844\n",
      "\n",
      "Epoch: [105 | 5000] LR: 0.031000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:06 | Loss:0.6470781564712524 | top1:65.625\n",
      "7/7 | Total:0:00:02 | ETA:0:00:01 | Loss:0.6766831477483114 | top1:58.333335876464844\n",
      "\n",
      "Epoch: [106 | 5000] LR: 0.031000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:05 | Loss:0.6795111894607544 | top1:50.0\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.6640777488549551 | top1:56.25\n",
      "\n",
      "Epoch: [107 | 5000] LR: 0.031000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:05 | Loss:0.6759840846061707 | top1:59.375\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.7251021464665731 | top1:56.25\n",
      "\n",
      "Epoch: [108 | 5000] LR: 0.031000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:04 | Loss:0.6708694696426392 | top1:53.125\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.6885532140731812 | top1:52.60416793823242\n",
      "\n",
      "Epoch: [109 | 5000] LR: 0.031000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:04 | Loss:0.6732831597328186 | top1:65.625\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.7406197587649027 | top1:56.25\n",
      "\n",
      "Epoch: [110 | 5000] LR: 0.031000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:04 | Loss:0.6864538192749023 | top1:53.125\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.6808354953924814 | top1:55.72916793823242\n",
      "\n",
      "Epoch: [111 | 5000] LR: 0.031000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:05 | Loss:0.665507972240448 | top1:68.75\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.7351905902226766 | top1:53.125\n",
      "\n",
      "Epoch: [112 | 5000] LR: 0.031000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:04 | Loss:0.6991329789161682 | top1:50.0\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.724234402179718 | top1:47.91666793823242\n",
      "\n",
      "Epoch: [113 | 5000] LR: 0.031000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:06 | Loss:0.6214079260826111 | top1:65.625\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.6680896580219269 | top1:58.333335876464844\n",
      "\n",
      "Epoch: [114 | 5000] LR: 0.031000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:06 | Loss:0.6226549744606018 | top1:65.625\n",
      "7/7 | Total:0:00:02 | ETA:0:00:01 | Loss:0.6843221386273702 | top1:54.6875\n",
      "\n",
      "Epoch: [115 | 5000] LR: 0.031000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:05 | Loss:0.7071937322616577 | top1:50.0\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.7650294701258341 | top1:47.395835876464844\n",
      "\n",
      "Epoch: [116 | 5000] LR: 0.031000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:06 | Loss:0.7009466886520386 | top1:50.0\n",
      "7/7 | Total:0:00:02 | ETA:0:00:01 | Loss:0.7019150157769521 | top1:51.5625\n",
      "\n",
      "Epoch: [117 | 5000] LR: 0.031000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:05 | Loss:0.7231413125991821 | top1:40.625\n",
      "7/7 | Total:0:00:02 | ETA:0:00:01 | Loss:0.6919774413108826 | top1:53.645835876464844\n",
      "\n",
      "Epoch: [118 | 5000] LR: 0.031000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:06 | Loss:0.6765506863594055 | top1:59.375\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.6928713818391165 | top1:53.645835876464844\n",
      "\n",
      "Epoch: [119 | 5000] LR: 0.031000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:04 | Loss:0.6807939410209656 | top1:59.375\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.7279256880283356 | top1:47.91666793823242\n",
      "\n",
      "Epoch: [120 | 5000] LR: 0.031000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:06 | Loss:0.7513118982315063 | top1:53.125\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.7434596518675486 | top1:47.91666793823242\n",
      "\n",
      "Epoch: [121 | 5000] LR: 0.031000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:04 | Loss:0.8234735727310181 | top1:53.125\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.7128887971242269 | top1:53.125\n",
      "\n",
      "Epoch: [122 | 5000] LR: 0.031000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:05 | Loss:0.7253156900405884 | top1:53.125\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.7338972091674805 | top1:46.35416793823242\n",
      "\n",
      "Epoch: [123 | 5000] LR: 0.031000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:05 | Loss:0.7039450407028198 | top1:53.125\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.7076649268468221 | top1:50.0\n",
      "\n",
      "Epoch: [124 | 5000] LR: 0.031000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:04 | Loss:0.6880772709846497 | top1:50.0\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.7218460440635681 | top1:48.4375\n",
      "\n",
      "Epoch: [125 | 5000] LR: 0.031000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:05 | Loss:0.68861323595047 | top1:53.125\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.7216971317927042 | top1:50.520835876464844\n",
      "\n",
      "Epoch: [126 | 5000] LR: 0.031000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:06 | Loss:0.6825787425041199 | top1:62.5\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.7140441636244456 | top1:48.4375\n",
      "\n",
      "Epoch: [127 | 5000] LR: 0.031000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:04 | Loss:0.7346047759056091 | top1:53.125\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.7311856547991434 | top1:47.395835876464844\n",
      "\n",
      "Epoch: [128 | 5000] LR: 0.031000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:05 | Loss:0.698287844657898 | top1:50.0\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.6913262208302816 | top1:53.125\n",
      "\n",
      "Epoch: [129 | 5000] LR: 0.031000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:04 | Loss:0.6977290511131287 | top1:53.125\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.7013812561829885 | top1:48.4375\n",
      "\n",
      "Epoch: [130 | 5000] LR: 0.031000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:05 | Loss:0.6994245648384094 | top1:50.0\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.6990321775277456 | top1:53.645835876464844\n",
      "\n",
      "Epoch: [131 | 5000] LR: 0.031000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/7 | Total:0:00:00 | ETA:0:00:05 | Loss:0.6926020979881287 | top1:53.125\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.741538921991984 | top1:44.270835876464844\n",
      "\n",
      "Epoch: [132 | 5000] LR: 0.031000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:05 | Loss:0.7227537035942078 | top1:40.625\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.7101144194602966 | top1:50.520835876464844\n",
      "\n",
      "Epoch: [133 | 5000] LR: 0.031000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:04 | Loss:0.6905534863471985 | top1:50.0\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.6971700688203176 | top1:51.5625\n",
      "\n",
      "Epoch: [134 | 5000] LR: 0.031000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:04 | Loss:0.7338933944702148 | top1:37.5\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.7374282975991567 | top1:49.47916793823242\n",
      "\n",
      "Epoch: [135 | 5000] LR: 0.031000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:04 | Loss:0.7063362002372742 | top1:46.875\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.7364299496014913 | top1:46.35416793823242\n",
      "\n",
      "Epoch: [136 | 5000] LR: 0.031000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:05 | Loss:0.7168493270874023 | top1:53.125\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.74004265666008 | top1:47.91666793823242\n",
      "\n",
      "Epoch: [137 | 5000] LR: 0.031000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:05 | Loss:0.6969395279884338 | top1:50.0\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.692069798707962 | top1:52.60416793823242\n",
      "\n",
      "Epoch: [138 | 5000] LR: 0.031000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:05 | Loss:0.6948676705360413 | top1:50.0\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.7106962203979492 | top1:49.47916793823242\n",
      "\n",
      "Epoch: [139 | 5000] LR: 0.031000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:06 | Loss:0.6915954351425171 | top1:53.125\n",
      "7/7 | Total:0:00:02 | ETA:0:00:01 | Loss:0.7511376241842905 | top1:45.3125\n",
      "\n",
      "Epoch: [140 | 5000] LR: 0.031000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:06 | Loss:0.7978019714355469 | top1:50.0\n",
      "7/7 | Total:0:00:02 | ETA:0:00:01 | Loss:0.7154372235139211 | top1:50.520835876464844\n",
      "\n",
      "Epoch: [141 | 5000] LR: 0.031000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:05 | Loss:0.6828835606575012 | top1:56.25\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.6999003191788992 | top1:52.60416793823242\n",
      "\n",
      "Epoch: [142 | 5000] LR: 0.031000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:06 | Loss:0.7143559455871582 | top1:50.0\n",
      "7/7 | Total:0:00:02 | ETA:0:00:01 | Loss:0.7051449716091156 | top1:47.395835876464844\n",
      "\n",
      "Epoch: [143 | 5000] LR: 0.031000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:04 | Loss:0.7156291604042053 | top1:34.375\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.7150537768999735 | top1:48.958335876464844\n",
      "\n",
      "Epoch: [144 | 5000] LR: 0.031000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:05 | Loss:0.6757249236106873 | top1:65.625\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.6924584209918976 | top1:55.208335876464844\n",
      "\n",
      "Epoch: [145 | 5000] LR: 0.031000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:04 | Loss:0.6953243613243103 | top1:50.0\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.7056058446566263 | top1:50.0\n",
      "\n",
      "Epoch: [146 | 5000] LR: 0.031000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:04 | Loss:0.7379074692726135 | top1:43.75\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.7037784655888876 | top1:53.125\n",
      "\n",
      "Epoch: [147 | 5000] LR: 0.031000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:04 | Loss:0.7170067429542542 | top1:46.875\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.7123047411441803 | top1:48.958335876464844\n",
      "\n",
      "Epoch: [148 | 5000] LR: 0.031000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:05 | Loss:0.6874415874481201 | top1:53.125\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.7350086172421774 | top1:48.958335876464844\n",
      "\n",
      "Epoch: [149 | 5000] LR: 0.031000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:05 | Loss:0.699898362159729 | top1:46.875\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.7359155217806498 | top1:47.395835876464844\n",
      "\n",
      "Epoch: [150 | 5000] LR: 0.031000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:05 | Loss:0.6985681056976318 | top1:53.125\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.6932941178480784 | top1:55.72916793823242\n",
      "\n",
      "Epoch: [151 | 5000] LR: 0.031000\n",
      "1/7 | Total:0:00:00 | ETA:0:00:05 | Loss:0.6841126084327698 | top1:59.375\n",
      "7/7 | Total:0:00:01 | ETA:0:00:01 | Loss:0.695531169573466 | top1:54.16666793823242\n",
      "107/107 | Total:0:00:15 | ETA:0:00:00 | Loss:0.6826799445063154 | top1:54.772586822509766\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(start_epoch, epochs):\n",
    "    state['lr'] = optimizer.state_dict()['param_groups'][0]['lr']\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "    print('\\nEpoch: [%d | %d] LR: %f' % (epoch + 1, epochs, state['lr']))\n",
    "    \n",
    "    train_loss, train_acc = train(train_loader, model, criterion, optimizer, epoch, use_cuda)\n",
    "    \n",
    "    if epoch % 50 == 0:\n",
    "        test_loss, test_acc = test(val_target_loader, model, criterion, epoch, use_cuda)\n",
    "        source_loss, source_acc = test(val_source_loader, model, criterion, epoch, use_cuda)\n",
    "\n",
    "        logger.append([state['lr'], train_loss, test_loss, train_acc, test_acc, source_loss, source_acc])\n",
    "        scheduler_warmup.step()\n",
    "\n",
    "        is_best = test_acc > best_acc\n",
    "        best_acc = max(test_acc, best_acc)\n",
    "        save_checkpoint({\n",
    "            'epoch': epoch + 1,\n",
    "            'state_dict' : model.state_dict(),\n",
    "            'acc': test_acc,\n",
    "            'best_acc': best_acc,\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "        }, is_best, checkpoint=checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
