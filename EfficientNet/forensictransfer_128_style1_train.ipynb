{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "import os, shutil\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "# torch.autograd.set_detect_anomaly(True)\n",
    "import numpy as np\n",
    "# declare batch size for act function\n",
    "\n",
    "\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(0) \n",
    "\n",
    "batch_size = 1148"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU device 2: True\n"
     ]
    }
   ],
   "source": [
    "# GPU Device\n",
    "gpu_id = 2\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(\"GPU device %d:\" %(gpu_id), use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_dir = '/home/kim1'\n",
    "data_dir = '/media/data2/dataset/GAN_ImageData/StyleGAN_256/'\n",
    "d_dir = home_dir+data_dir\n",
    "\n",
    "resume = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, checkpoint='checkpoint', filename='checkpoint.pth.tar'):\n",
    "    filepath = os.path.join(checkpoint, filename)\n",
    "    torch.save(state, filepath)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filepath, os.path.join(checkpoint, 'model_best.pth.tar'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = './log/style1/128/foresic/aug' # dir\n",
    "if not os.path.isdir(checkpoint):\n",
    "    os.makedirs(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoencoder part\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        #should change channel 3\n",
    "        self.conv_1_1 = nn.Conv2d(in_channels=3,out_channels=8,kernel_size=3,padding=1)\n",
    "        self.relu_1_2 = nn.ReLU(True)\n",
    "            \n",
    "        self.conv_2_1 = nn.Conv2d(in_channels=8,out_channels=16,kernel_size=3,stride=2,padding=1)\n",
    "        self.bn_2_2 = nn.BatchNorm2d(16)\n",
    "        self.relu_2_3 = nn.ReLU(True)\n",
    "        \n",
    "        self.conv_3_1 = nn.Conv2d(in_channels=16,out_channels=32,kernel_size=3,stride=2,padding=1)\n",
    "        self.bn_3_2 = nn.BatchNorm2d(32)\n",
    "        self.relu_3_3 = nn.ReLU(True)\n",
    "        \n",
    "        self.conv_4_1=nn.Conv2d(in_channels=32,out_channels=64,kernel_size=3,stride=2,padding=1)\n",
    "        self.bn_4_2=nn.BatchNorm2d(64)\n",
    "        self.relu_4_3=nn.ReLU(True)\n",
    "        \n",
    "        self.conv_5_1 = nn.Conv2d(in_channels=64,out_channels=128,kernel_size=3,stride=2,padding=1)\n",
    "        self.bn_5_2 =nn.BatchNorm2d(128)\n",
    "        self.relu_5_3 = nn.ReLU(True)\n",
    "        \n",
    "        ## decoder\n",
    "        self.upsample_6_1 = nn.Upsample(scale_factor=2,mode='nearest')\n",
    "        self.convtranspose_6_2 = nn.Conv2d(in_channels=128,out_channels=64,kernel_size=3,padding=1)\n",
    "        self.bn_6_3 = nn.BatchNorm2d(64)\n",
    "        self.relu_6_4 = nn.ReLU(True)\n",
    "        \n",
    "        self.upsample_7_1 = nn.Upsample(scale_factor=2,mode='nearest')\n",
    "        self.convtranspose_7_2 = nn.Conv2d(in_channels=64,out_channels=32,kernel_size=3,padding=1)\n",
    "        self.bn_7_3 = nn.BatchNorm2d(32)\n",
    "        self.relu_7_4 = nn.ReLU(True)\n",
    "        \n",
    "        self.upsample_8_1 = nn.Upsample(scale_factor=2,mode='nearest')\n",
    "        self.convtranspose_8_2 = nn.Conv2d(in_channels=32,out_channels=16,kernel_size=3,padding=1)\n",
    "        self.bn_8_3 = nn.BatchNorm2d(16)\n",
    "        self.relu_8_4 = nn.ReLU(True)\n",
    "        \n",
    "        self.upsample_9_1 = nn.Upsample(scale_factor=2,mode='nearest')\n",
    "        self.convtranspose_9_2 = nn.Conv2d(in_channels=16,out_channels=8,kernel_size=3,padding=1)\n",
    "        self.bn_9_3 = nn.BatchNorm2d(8)\n",
    "        self.relu_9_4 = nn.ReLU(True)\n",
    "        #should change channel 6\n",
    "        # 혹시 안되면\n",
    "        # self.conv_10_1 = nn.ConvTranspose2d(in_channels=8,out_channels=3,kernel_size=3,padding=1)\n",
    "        #이걸로 마지막 conv 계층을 바꿔주세요 \n",
    "        self.conv_10_1 = nn.Conv2d(in_channels=8,out_channels=3,kernel_size=3,padding=1)\n",
    "        self.tanh_10_2=nn.Tanh()\n",
    "        \n",
    "        # no masking no *0 or assign value zero not done .        \n",
    "        \n",
    "    def forward(self, x,label):\n",
    "        x1 = self.conv_1_1(x)\n",
    "        x2 = self.relu_1_2(x1)\n",
    "\n",
    "        x3 = self.conv_2_1(x2)\n",
    "        x4 = self.bn_2_2(x3)\n",
    "        x5 = self.relu_2_3(x4)\n",
    "\n",
    "        \n",
    "        x6 = self.conv_3_1(x5)\n",
    "        x7 = self.bn_3_2(x6)\n",
    "        x8 = self.relu_3_3(x7)\n",
    "\n",
    "        \n",
    "        x9 = self.conv_4_1(x8)\n",
    "        x10 = self.bn_4_2(x9)\n",
    "        x11 = self.relu_4_3(x10)\n",
    "\n",
    "        \n",
    "        x12 = self.conv_5_1(x11)\n",
    "        x13 = self.bn_5_2(x12)\n",
    "        x14 = self.relu_5_3(x13)\n",
    "        \n",
    "        act = x14.clone()\n",
    "        dep = x14.clone()\n",
    "\n",
    "        # Selection block setting zero values based on label\n",
    "        # [:64] -> fake data latent space \n",
    "        # [64:] -> real data latent space\n",
    "        # 0->fake 1 ->real\n",
    "        # 15 15\n",
    "        A = torch.nn.Parameter(torch.zeros(64,8,8))\n",
    "        for i in range(len(label)):\n",
    "            #real \n",
    "            if label[i].item():\n",
    "                #setting fake latent space into zero\n",
    "                dep[i,:64] = A\n",
    "            else:\n",
    "                dep[i,64:]=A\n",
    "                \n",
    "        x15 = self.upsample_6_1(dep) \n",
    "        x16 = self.convtranspose_6_2(x15)\n",
    "        x17 = self.bn_6_3(x16)\n",
    "        x18 = self.relu_6_4(x17) \n",
    "        x19 = self.upsample_7_1(x18)\n",
    "        x20 = self.convtranspose_7_2(x19)\n",
    "        x21 = self.bn_7_3(x20)\n",
    "        x22 = self.relu_7_4(x21)\n",
    "        x23 = self.upsample_8_1(x22)\n",
    "        x24 = self.convtranspose_8_2(x23)\n",
    "        x25 = self.bn_8_3(x24)\n",
    "        x26 = self.relu_8_4(x25)\n",
    "        x27 = self.upsample_9_1(x26)\n",
    "        x28 = self.convtranspose_9_2(x27) \n",
    "        x29 = self.bn_9_3(x28)\n",
    "        x30 = self.relu_9_4(x29)\n",
    "        x31 = self.conv_10_1(x30)\n",
    "        x32 = self.tanh_10_2(x31)\n",
    "\n",
    "        return  x32 , act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Autoencoder(\n",
       "  (conv_1_1): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu_1_2): ReLU(inplace=True)\n",
       "  (conv_2_1): Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (bn_2_2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu_2_3): ReLU(inplace=True)\n",
       "  (conv_3_1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (bn_3_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu_3_3): ReLU(inplace=True)\n",
       "  (conv_4_1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (bn_4_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu_4_3): ReLU(inplace=True)\n",
       "  (conv_5_1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (bn_5_2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu_5_3): ReLU(inplace=True)\n",
       "  (upsample_6_1): Upsample(scale_factor=2.0, mode=nearest)\n",
       "  (convtranspose_6_2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn_6_3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu_6_4): ReLU(inplace=True)\n",
       "  (upsample_7_1): Upsample(scale_factor=2.0, mode=nearest)\n",
       "  (convtranspose_7_2): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn_7_3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu_7_4): ReLU(inplace=True)\n",
       "  (upsample_8_1): Upsample(scale_factor=2.0, mode=nearest)\n",
       "  (convtranspose_8_2): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn_8_3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu_8_4): ReLU(inplace=True)\n",
       "  (upsample_9_1): Upsample(scale_factor=2.0, mode=nearest)\n",
       "  (convtranspose_9_2): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn_9_3): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu_9_4): ReLU(inplace=True)\n",
       "  (conv_10_1): Conv2d(8, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (tanh_10_2): Tanh()\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Autoencoder()\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate,eps=1e-7)\n",
    "\n",
    "#configuration\n",
    "\n",
    "num_epochs = 100\n",
    "criterion1 = nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "train_dir = os.path.join(d_dir, 'train')\n",
    "val_dir = os.path.join(d_dir, 'validation')\n",
    "\n",
    "train_data =torchvision.datasets.ImageFolder(root=train_dir,\n",
    "                                                transform = transforms.Compose([transforms.Resize((128 ,128 )),transforms.ToTensor()]))\n",
    "validation_dataset =torchvision.datasets.ImageFolder(root=val_dir,\n",
    "                                                transform = transforms.Compose([transforms.Resize((128 ,128 )),transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(dataset=train_data,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=8)\n",
    "\n",
    "validation_dataloader = torch.utils.data.DataLoader(dataset=validation_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader.classes : ['0', '1']\n",
      "validation_dataloader.classes : ['0', '1']\n",
      "train_dataloader.classes : {'0': 0, '1': 1}\n",
      "validation_dataloader.classes : {'0': 0, '1': 1}\n"
     ]
    }
   ],
   "source": [
    "print(\"train_dataloader.classes : %s\" % train_data.classes)\n",
    "print(\"validation_dataloader.classes : %s\" % validation_dataset.classes)\n",
    "print(\"train_dataloader.classes : %s\" % train_data.class_to_idx)\n",
    "print(\"validation_dataloader.classes : %s\" % validation_dataset.class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resume\n",
    "if resume:\n",
    "    print('==> Resuming from checkpoint..')\n",
    "    checkpoint = os.path.dirname(resume)\n",
    "#     checkpoint = torch.load(resume)\n",
    "    resume = torch.load(resume)\n",
    "    best_acc = 0\n",
    "    start_epoch = resume['epoch']\n",
    "    model.load_state_dict(resume['state_dict'])\n",
    "    optimizer.load_state_dict(resume['optimizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def act_loss_func(outputs, labels):\n",
    "    batch_size = outputs.size()[0]\n",
    "    loss_list = torch.zeros([batch_size])\n",
    "    loss_list = loss_list.to(device)\n",
    "    for i in range(batch_size):\n",
    "        #fake\n",
    "        total_loss =torch.zeros([1],dtype=torch.float32)\n",
    "        total_loss = total_loss.to(device)\n",
    "        #real\n",
    "        total_loss_1 =torch.zeros([1],dtype=torch.float32)\n",
    "        total_loss_1 = total_loss.to(device)\n",
    "        # real\n",
    "        if labels[i].item():\n",
    "            #fake\n",
    "            for latent_index in range(64):\n",
    "                temp= torch.sum(torch.abs(outputs[i,latent_index,:,:]))/225\n",
    "                total_loss = torch.sum(total_loss+temp)\n",
    "            #real\n",
    "            for latent_index in range(64,128):\n",
    "                temp1= torch.abs(1 -torch.sum(torch.abs(outputs[i,latent_index,:,:]))/225)\n",
    "                total_loss_1 = torch.sum(total_loss_1+temp1)\n",
    "        #fake\n",
    "        else:\n",
    "            #fake\n",
    "            for latent_index in range(64):\n",
    "                temp= torch.abs(1- torch.sum(torch.abs(outputs[i,latent_index,:,:]))/225)\n",
    "                total_loss = torch.sum(total_loss+temp)\n",
    "            #real\n",
    "            for latent_index in range(64,128):\n",
    "                temp1= torch.sum(torch.abs(outputs[i,latent_index,:,:]))/225\n",
    "                total_loss_1 = torch.sum(total_loss_1+temp1)\n",
    "        \n",
    "        loss_list[i]=total_loss+total_loss_1\n",
    "\n",
    "        \n",
    "    return torch.sum(loss_list)\n",
    "\n",
    "#%%\n",
    "\n",
    "# test\n",
    "def act_loss_test(outputs):\n",
    "    batch_size = outputs.size()[0]\n",
    "    answer = torch.zeros([batch_size,2])\n",
    "    answer.cuda()\n",
    "    for i in range(batch_size):\n",
    "        fake = torch.zeros([1], dtype=torch.float32).to(device)\n",
    "        real = torch.zeros([1], dtype=torch.float32).to(device)\n",
    "        # fake latent space\n",
    "        for latent_index in range(64):\n",
    "            fake = fake + torch.sum(torch.abs(outputs[i, latent_index]))\n",
    "        # real latent space\n",
    "        for latent_index in range(64, 128):\n",
    "            real = real + torch.sum(torch.abs(outputs[i, latent_index]))\n",
    "\n",
    "\n",
    "        answer[i][0] = fake.item() / (fake.item() + real.item())\n",
    "        answer[i][1] = real.item() / (fake.item() + real.item())\n",
    "        \n",
    "            \n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/100], loss:72420.8906\n",
      "epoch [1/100], loss:71904.0938\n",
      "epoch [1/100], loss:70788.3984\n",
      "epoch [1/100], loss:69171.7734\n",
      "epoch [1/100], loss:67139.5078\n",
      "epoch [1/100], loss:63755.9453\n",
      "epoch [1/100], loss:63755.9453\n",
      "validation loss is 464347.906250\n",
      "Test Accuracy 0.601667 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.56      0.95      0.71      3900\n",
      "        real       0.84      0.25      0.39      3900\n",
      "\n",
      "    accuracy                           0.60      7800\n",
      "   macro avg       0.70      0.60      0.55      7800\n",
      "weighted avg       0.70      0.60      0.55      7800\n",
      "\n",
      "epoch [2/100], loss:65361.2031\n",
      "epoch [2/100], loss:64510.2617\n",
      "epoch [2/100], loss:63516.9414\n",
      "epoch [2/100], loss:63154.4766\n",
      "epoch [2/100], loss:62092.5156\n",
      "epoch [2/100], loss:59288.5156\n",
      "epoch [2/100], loss:59288.5156\n",
      "validation loss is 432121.750000\n",
      "Test Accuracy 0.548974 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.53      1.00      0.69      3900\n",
      "        real       1.00      0.10      0.18      3900\n",
      "\n",
      "    accuracy                           0.55      7800\n",
      "   macro avg       0.76      0.55      0.43      7800\n",
      "weighted avg       0.76      0.55      0.43      7800\n",
      "\n",
      "epoch [3/100], loss:60654.0156\n",
      "epoch [3/100], loss:59905.0742\n",
      "epoch [3/100], loss:59026.0742\n",
      "epoch [3/100], loss:58488.6914\n",
      "epoch [3/100], loss:57450.9414\n",
      "epoch [3/100], loss:54681.9766\n",
      "epoch [3/100], loss:54681.9766\n",
      "validation loss is 376333.812500\n",
      "Test Accuracy 0.949359 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.91      1.00      0.95      3900\n",
      "        real       1.00      0.90      0.95      3900\n",
      "\n",
      "    accuracy                           0.95      7800\n",
      "   macro avg       0.95      0.95      0.95      7800\n",
      "weighted avg       0.95      0.95      0.95      7800\n",
      "\n",
      "epoch [4/100], loss:55687.1797\n",
      "epoch [4/100], loss:55268.4766\n",
      "epoch [4/100], loss:54445.1602\n",
      "epoch [4/100], loss:53508.4922\n",
      "epoch [4/100], loss:53000.4844\n",
      "epoch [4/100], loss:50259.8555\n",
      "epoch [4/100], loss:50259.8555\n",
      "validation loss is 546635.500000\n",
      "Test Accuracy 0.500128 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.50      1.00      0.67      3900\n",
      "        real       1.00      0.00      0.00      3900\n",
      "\n",
      "    accuracy                           0.50      7800\n",
      "   macro avg       0.75      0.50      0.33      7800\n",
      "weighted avg       0.75      0.50      0.33      7800\n",
      "\n",
      "epoch [5/100], loss:51791.0547\n",
      "epoch [5/100], loss:51245.3984\n",
      "epoch [5/100], loss:50482.6992\n",
      "epoch [5/100], loss:49843.5117\n",
      "epoch [5/100], loss:49046.5234\n",
      "epoch [5/100], loss:47181.2422\n",
      "epoch [5/100], loss:47181.2422\n",
      "validation loss is 347453.312500\n",
      "Test Accuracy 0.840641 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       1.00      0.68      0.81      3900\n",
      "        real       0.76      1.00      0.86      3900\n",
      "\n",
      "    accuracy                           0.84      7800\n",
      "   macro avg       0.88      0.84      0.84      7800\n",
      "weighted avg       0.88      0.84      0.84      7800\n",
      "\n",
      "epoch [6/100], loss:48101.1523\n",
      "epoch [6/100], loss:47220.8242\n",
      "epoch [6/100], loss:46709.6523\n",
      "epoch [6/100], loss:46556.9336\n",
      "epoch [6/100], loss:45954.9023\n",
      "epoch [6/100], loss:43629.3320\n",
      "epoch [6/100], loss:43629.3320\n",
      "validation loss is 474769.375000\n",
      "Test Accuracy 0.675256 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.61      1.00      0.75      3900\n",
      "        real       0.99      0.35      0.52      3900\n",
      "\n",
      "    accuracy                           0.68      7800\n",
      "   macro avg       0.80      0.68      0.64      7800\n",
      "weighted avg       0.80      0.68      0.64      7800\n",
      "\n",
      "epoch [7/100], loss:44705.5664\n",
      "epoch [7/100], loss:44517.7891\n",
      "epoch [7/100], loss:43768.1680\n",
      "epoch [7/100], loss:43266.6523\n",
      "epoch [7/100], loss:42820.5156\n",
      "epoch [7/100], loss:41085.3320\n",
      "epoch [7/100], loss:41085.3320\n",
      "validation loss is 442695.062500\n",
      "Test Accuracy 0.791538 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.73      0.93      0.82      3900\n",
      "        real       0.91      0.65      0.76      3900\n",
      "\n",
      "    accuracy                           0.79      7800\n",
      "   macro avg       0.82      0.79      0.79      7800\n",
      "weighted avg       0.82      0.79      0.79      7800\n",
      "\n",
      "epoch [8/100], loss:41914.5742\n",
      "epoch [8/100], loss:41432.0625\n",
      "epoch [8/100], loss:40945.1094\n",
      "epoch [8/100], loss:40501.4805\n",
      "epoch [8/100], loss:39855.0586\n",
      "epoch [8/100], loss:37677.6133\n",
      "epoch [8/100], loss:37677.6133\n",
      "validation loss is 456017.937500\n",
      "Test Accuracy 0.520641 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.51      1.00      0.68      3900\n",
      "        real       0.99      0.04      0.08      3900\n",
      "\n",
      "    accuracy                           0.52      7800\n",
      "   macro avg       0.75      0.52      0.38      7800\n",
      "weighted avg       0.75      0.52      0.38      7800\n",
      "\n",
      "epoch [9/100], loss:38996.7656\n",
      "epoch [9/100], loss:38683.0156\n",
      "epoch [9/100], loss:37983.0586\n",
      "epoch [9/100], loss:37661.6172\n",
      "epoch [9/100], loss:37165.6602\n",
      "epoch [9/100], loss:35812.2461\n",
      "epoch [9/100], loss:35812.2461\n",
      "validation loss is 429929.343750\n",
      "Test Accuracy 0.508205 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.50      1.00      0.67      3900\n",
      "        real       1.00      0.02      0.03      3900\n",
      "\n",
      "    accuracy                           0.51      7800\n",
      "   macro avg       0.75      0.51      0.35      7800\n",
      "weighted avg       0.75      0.51      0.35      7800\n",
      "\n",
      "epoch [10/100], loss:36354.9609\n",
      "epoch [10/100], loss:35866.3672\n",
      "epoch [10/100], loss:35490.5234\n",
      "epoch [10/100], loss:35204.0273\n",
      "epoch [10/100], loss:34865.2695\n",
      "epoch [10/100], loss:33289.3516\n",
      "epoch [10/100], loss:33289.3516\n",
      "validation loss is 447037.750000\n",
      "Test Accuracy 0.501538 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       1.00      0.00      0.01      3900\n",
      "        real       0.50      1.00      0.67      3900\n",
      "\n",
      "    accuracy                           0.50      7800\n",
      "   macro avg       0.75      0.50      0.34      7800\n",
      "weighted avg       0.75      0.50      0.34      7800\n",
      "\n",
      "epoch [11/100], loss:33935.3164\n",
      "epoch [11/100], loss:33278.8320\n",
      "epoch [11/100], loss:33115.2734\n",
      "epoch [11/100], loss:32674.8906\n",
      "epoch [11/100], loss:32371.1133\n",
      "epoch [11/100], loss:31024.3691\n",
      "epoch [11/100], loss:31024.3691\n",
      "validation loss is 439806.281250\n",
      "Test Accuracy 0.805513 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.77      0.87      0.82      3900\n",
      "        real       0.85      0.74      0.79      3900\n",
      "\n",
      "    accuracy                           0.81      7800\n",
      "   macro avg       0.81      0.81      0.80      7800\n",
      "weighted avg       0.81      0.81      0.80      7800\n",
      "\n",
      "epoch [12/100], loss:31213.2129\n",
      "epoch [12/100], loss:30929.8379\n",
      "epoch [12/100], loss:30378.7559\n",
      "epoch [12/100], loss:30195.7051\n",
      "epoch [12/100], loss:29997.4883\n",
      "epoch [12/100], loss:28596.3008\n",
      "epoch [12/100], loss:28596.3008\n",
      "validation loss is 478941.937500\n",
      "Test Accuracy 0.510897 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.99      0.02      0.04      3900\n",
      "        real       0.51      1.00      0.67      3900\n",
      "\n",
      "    accuracy                           0.51      7800\n",
      "   macro avg       0.75      0.51      0.36      7800\n",
      "weighted avg       0.75      0.51      0.36      7800\n",
      "\n",
      "epoch [13/100], loss:29314.5781\n",
      "epoch [13/100], loss:29015.3105\n",
      "epoch [13/100], loss:28914.4629\n",
      "epoch [13/100], loss:28351.4316\n",
      "epoch [13/100], loss:28329.6348\n",
      "epoch [13/100], loss:26619.1582\n",
      "epoch [13/100], loss:26619.1582\n",
      "validation loss is 452734.937500\n",
      "Test Accuracy 0.500256 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       1.00      0.00      0.00      3900\n",
      "        real       0.50      1.00      0.67      3900\n",
      "\n",
      "    accuracy                           0.50      7800\n",
      "   macro avg       0.75      0.50      0.33      7800\n",
      "weighted avg       0.75      0.50      0.33      7800\n",
      "\n",
      "epoch [14/100], loss:26936.7520\n",
      "epoch [14/100], loss:27045.0879\n",
      "epoch [14/100], loss:26637.0898\n",
      "epoch [14/100], loss:26158.5723\n",
      "epoch [14/100], loss:25796.0840\n",
      "epoch [14/100], loss:25049.4727\n",
      "epoch [14/100], loss:25049.4727\n",
      "validation loss is 387063.437500\n",
      "Test Accuracy 0.967179 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.95      0.99      0.97      3900\n",
      "        real       0.99      0.95      0.97      3900\n",
      "\n",
      "    accuracy                           0.97      7800\n",
      "   macro avg       0.97      0.97      0.97      7800\n",
      "weighted avg       0.97      0.97      0.97      7800\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [15/100], loss:24898.7969\n",
      "epoch [15/100], loss:24918.6914\n",
      "epoch [15/100], loss:24888.8848\n",
      "epoch [15/100], loss:24935.7930\n",
      "epoch [15/100], loss:24338.6875\n",
      "epoch [15/100], loss:23207.0078\n",
      "epoch [15/100], loss:23207.0078\n",
      "validation loss is 403129.343750\n",
      "Test Accuracy 0.539487 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.52      1.00      0.68      3900\n",
      "        real       1.00      0.08      0.15      3900\n",
      "\n",
      "    accuracy                           0.54      7800\n",
      "   macro avg       0.76      0.54      0.42      7800\n",
      "weighted avg       0.76      0.54      0.42      7800\n",
      "\n",
      "epoch [16/100], loss:22916.5410\n",
      "epoch [16/100], loss:23053.3848\n",
      "epoch [16/100], loss:22535.1953\n",
      "epoch [16/100], loss:22831.4746\n",
      "epoch [16/100], loss:23036.9082\n",
      "epoch [16/100], loss:21767.6836\n",
      "epoch [16/100], loss:21767.6836\n",
      "validation loss is 422787.718750\n",
      "Test Accuracy 0.505256 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.50      1.00      0.67      3900\n",
      "        real       1.00      0.01      0.02      3900\n",
      "\n",
      "    accuracy                           0.51      7800\n",
      "   macro avg       0.75      0.51      0.34      7800\n",
      "weighted avg       0.75      0.51      0.34      7800\n",
      "\n",
      "epoch [17/100], loss:21875.4023\n",
      "epoch [17/100], loss:21651.7363\n",
      "epoch [17/100], loss:21268.7715\n",
      "epoch [17/100], loss:21625.7363\n",
      "epoch [17/100], loss:20908.3516\n",
      "epoch [17/100], loss:19738.9316\n",
      "epoch [17/100], loss:19738.9316\n",
      "validation loss is 351385.093750\n",
      "Test Accuracy 0.657564 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.59      1.00      0.74      3900\n",
      "        real       1.00      0.32      0.48      3900\n",
      "\n",
      "    accuracy                           0.66      7800\n",
      "   macro avg       0.80      0.66      0.61      7800\n",
      "weighted avg       0.80      0.66      0.61      7800\n",
      "\n",
      "epoch [18/100], loss:20861.5957\n",
      "epoch [18/100], loss:20105.3809\n",
      "epoch [18/100], loss:19984.5664\n",
      "epoch [18/100], loss:20056.1660\n",
      "epoch [18/100], loss:20083.8223\n",
      "epoch [18/100], loss:18691.0410\n",
      "epoch [18/100], loss:18691.0410\n",
      "validation loss is 345271.687500\n",
      "Test Accuracy 0.939872 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.90      0.99      0.94      3900\n",
      "        real       0.99      0.88      0.94      3900\n",
      "\n",
      "    accuracy                           0.94      7800\n",
      "   macro avg       0.95      0.94      0.94      7800\n",
      "weighted avg       0.95      0.94      0.94      7800\n",
      "\n",
      "epoch [19/100], loss:19231.6738\n",
      "epoch [19/100], loss:19337.8301\n",
      "epoch [19/100], loss:19221.6152\n",
      "epoch [19/100], loss:18738.9434\n",
      "epoch [19/100], loss:18876.7188\n",
      "epoch [19/100], loss:17657.7090\n",
      "epoch [19/100], loss:17657.7090\n",
      "validation loss is 428352.718750\n",
      "Test Accuracy 0.577051 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.95      0.16      0.28      3900\n",
      "        real       0.54      0.99      0.70      3900\n",
      "\n",
      "    accuracy                           0.58      7800\n",
      "   macro avg       0.74      0.58      0.49      7800\n",
      "weighted avg       0.74      0.58      0.49      7800\n",
      "\n",
      "epoch [20/100], loss:18440.4707\n",
      "epoch [20/100], loss:18584.7402\n",
      "epoch [20/100], loss:18074.2227\n",
      "epoch [20/100], loss:18347.3750\n",
      "epoch [20/100], loss:17579.2637\n",
      "epoch [20/100], loss:16690.0605\n",
      "epoch [20/100], loss:16690.0605\n",
      "validation loss is 1003070.312500\n",
      "Test Accuracy 0.500000 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.00      0.00      0.00      3900\n",
      "        real       0.50      1.00      0.67      3900\n",
      "\n",
      "    accuracy                           0.50      7800\n",
      "   macro avg       0.25      0.50      0.33      7800\n",
      "weighted avg       0.25      0.50      0.33      7800\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kim1/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [21/100], loss:17411.2598\n",
      "epoch [21/100], loss:17316.8965\n",
      "epoch [21/100], loss:17745.0527\n",
      "epoch [21/100], loss:17096.9824\n",
      "epoch [21/100], loss:17789.4141\n",
      "epoch [21/100], loss:16847.8301\n",
      "epoch [21/100], loss:16847.8301\n",
      "validation loss is 475030.187500\n",
      "Test Accuracy 0.500000 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.50      1.00      0.67      3900\n",
      "        real       0.00      0.00      0.00      3900\n",
      "\n",
      "    accuracy                           0.50      7800\n",
      "   macro avg       0.25      0.50      0.33      7800\n",
      "weighted avg       0.25      0.50      0.33      7800\n",
      "\n",
      "epoch [22/100], loss:16560.7070\n",
      "epoch [22/100], loss:17270.2871\n",
      "epoch [22/100], loss:16568.4062\n",
      "epoch [22/100], loss:17092.1680\n",
      "epoch [22/100], loss:16711.3965\n",
      "epoch [22/100], loss:16377.5420\n",
      "epoch [22/100], loss:16377.5420\n",
      "validation loss is 386330.187500\n",
      "Test Accuracy 0.937436 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.97      0.90      0.94      3900\n",
      "        real       0.91      0.97      0.94      3900\n",
      "\n",
      "    accuracy                           0.94      7800\n",
      "   macro avg       0.94      0.94      0.94      7800\n",
      "weighted avg       0.94      0.94      0.94      7800\n",
      "\n",
      "epoch [23/100], loss:16053.6123\n",
      "epoch [23/100], loss:16169.6113\n",
      "epoch [23/100], loss:16275.2793\n",
      "epoch [23/100], loss:16342.2656\n",
      "epoch [23/100], loss:16695.0742\n",
      "epoch [23/100], loss:15920.4219\n",
      "epoch [23/100], loss:15920.4219\n",
      "validation loss is 609293.375000\n",
      "Test Accuracy 0.500385 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       1.00      0.00      0.00      3900\n",
      "        real       0.50      1.00      0.67      3900\n",
      "\n",
      "    accuracy                           0.50      7800\n",
      "   macro avg       0.75      0.50      0.33      7800\n",
      "weighted avg       0.75      0.50      0.33      7800\n",
      "\n",
      "epoch [24/100], loss:15963.4414\n",
      "epoch [24/100], loss:16356.2520\n",
      "epoch [24/100], loss:15916.6787\n",
      "epoch [24/100], loss:15608.7461\n",
      "epoch [24/100], loss:15967.5703\n",
      "epoch [24/100], loss:15507.5879\n",
      "epoch [24/100], loss:15507.5879\n",
      "validation loss is 428700.750000\n",
      "Test Accuracy 0.501282 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.50      1.00      0.67      3900\n",
      "        real       1.00      0.00      0.01      3900\n",
      "\n",
      "    accuracy                           0.50      7800\n",
      "   macro avg       0.75      0.50      0.34      7800\n",
      "weighted avg       0.75      0.50      0.34      7800\n",
      "\n",
      "epoch [25/100], loss:15774.4023\n",
      "epoch [25/100], loss:16426.1367\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "import torchvision.utils as vutils\n",
    "from sklearn.metrics import classification_report\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "target_names = ['fake','real']\n",
    "loss_val =0\n",
    "for epoch in range(num_epochs):\n",
    "    model = model.train()\n",
    "    for _, (x,label) in enumerate(train_dataloader):\n",
    "        init = x\n",
    "        init= init.to(device)\n",
    "        x = x.view(x.size(),-1)\n",
    "        x = x.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output,act_data = model(x,label)\n",
    "        rec_loss = criterion1(output, init)\n",
    "        act_loss = act_loss_func(act_data, label)\n",
    "        loss = act_loss+0.1*rec_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (_+1) % 10 == 0:\n",
    "            print('epoch [{}/{}], loss:{:.4f}'.format(epoch + 1, num_epochs, loss.item()))\n",
    "        \n",
    "    print('epoch [{}/{}], loss:{:.4f}'.format(epoch + 1, num_epochs, loss.item()))\n",
    "\n",
    "#     vutils.save_image(x,'deepfake_%d_real_samples.png' % epoch,normalize=True)\n",
    "#     vutils.save_image(output,'deepfake_%d_generated_samples.png' % epoch,normalize=True)\n",
    "    \n",
    "    model = model.eval()\n",
    "    \n",
    "    pred= []\n",
    "    labels= []\n",
    "    correct =0\n",
    "    total =0\n",
    "    with torch.no_grad():\n",
    "        loss = 0\n",
    "        for _, (x,label) in enumerate(validation_dataloader):\n",
    "            init = x\n",
    "            init= init.to(device)\n",
    "            x = x.view(x.size(),-1)\n",
    "            x = x.to(device)\n",
    "            a= label.shape[0]\n",
    "            temp = torch.rand([a])\n",
    "            output,act_data = model(x,temp)\n",
    "            outputs  = act_loss_test(act_data)\n",
    "            \n",
    "            rec_loss = criterion1(output, init)\n",
    "            act_loss = act_loss_func(act_data, label)\n",
    "\n",
    "            loss += act_loss+0.1*rec_loss  \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            pred += predicted.tolist()\n",
    "            labels += label.tolist()\n",
    "            correct += (predicted == label).sum().item()\n",
    "            \n",
    "            \n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        print(\"validation loss is %f\" % loss)\n",
    "        temp =correct/len(validation_dataset)\n",
    "        print('Test Accuracy %f %%' % temp)\n",
    "        print(classification_report(labels, pred, target_names=target_names))\n",
    "        \n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'state_dict' : model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    }, is_best=True, checkpoint=checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL= Autoencoder()\n",
    "MODEL.load_state_dict(torch.load(\"stylegan90epoch_.pth\"))\n",
    "MODEL.cuda()\n",
    "MODEL.eval()\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "target_data_1 =torchvision.datasets.ImageFolder(root=r\"C:\\Users\\jonathan\\Desktop\\prj\\gan_detection\\PGGAN_128\\fine_tune\",\n",
    "                                                transform = transforms.Compose([transforms.Resize((128 ,128 )),transforms.ToTensor()]))\n",
    "target_data_2 =torchvision.datasets.ImageFolder(root=r\"C:\\Users\\jonathan\\Desktop\\prj\\gan_detection\\StyleGAN2_256\",\n",
    "                                                transform = transforms.Compose([transforms.Resize((128 ,128 )),transforms.ToTensor()]))\n",
    "\n",
    "\n",
    "zeroshot_data_1 = torch.utils.data.DataLoader(dataset=target_data_1,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "\n",
    "zeroshot_data_2 = torch.utils.data.DataLoader(dataset=target_data_2,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct= 0\n",
    "    loss = 0\n",
    "    pred= []\n",
    "    labels = []\n",
    "    for _, (x,label) in enumerate(zeroshot_data_1):\n",
    "        init = x\n",
    "        init= init.to(device)\n",
    "        x = x.view(x.size(),-1)\n",
    "        x = x.to(device)\n",
    "        a= label.shape[0]\n",
    "        temp = torch.rand([a])\n",
    "        output,act_data = MODEL(x,temp)\n",
    "        outputs  = act_loss_test(act_data)\n",
    "        \n",
    "        rec_loss = criterion1(output, init)\n",
    "        act_loss = act_loss_func(act_data, label)\n",
    "\n",
    "        loss += act_loss+0.1*rec_loss  \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        pred += predicted.tolist()\n",
    "        labels += label.tolist()\n",
    "        correct += (predicted == label).sum().item()\n",
    "        \n",
    "        \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    # print(\"PGGAN_128 loss is %f\" % loss)\n",
    "    temp =correct/len(zeroshot_data_1)\n",
    "    print('Test Accuracy %f %%' % temp)\n",
    "    print(classification_report(labels, pred, target_names=target_names))\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct= 0\n",
    "    loss = 0\n",
    "    pred= []\n",
    "    labels = []\n",
    "    for _, (x,label) in enumerate(zeroshot_data_2):\n",
    "        init = x\n",
    "        init= init.to(device)\n",
    "        x = x.view(x.size(),-1)\n",
    "        x = x.to(device)\n",
    "        a= label.shape[0]\n",
    "        temp = torch.rand([a])\n",
    "        output,act_data = MODEL(x,temp)\n",
    "        outputs  = act_loss_test(act_data)\n",
    "        \n",
    "        rec_loss = criterion1(output, init)\n",
    "        act_loss = act_loss_func(act_data, label)\n",
    "\n",
    "        loss += act_loss+0.1*rec_loss  \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        pred += predicted.tolist()\n",
    "        labels += label.tolist()\n",
    "        correct += (predicted == label).sum().item()\n",
    "        \n",
    "        \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    print(\"StyleGAN2 loss is %f\" % loss)\n",
    "    temp =correct/len(target_data_2)\n",
    "    print('Test Accuracy %f %%' % temp)\n",
    "    print(classification_report(labels, pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
