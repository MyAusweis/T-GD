{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import collections\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "\n",
    "from model_pytorch import EfficientNet\n",
    "from utils import Bar,Logger, AverageMeter, accuracy, mkdir_p, savefig\n",
    "from warmup_scheduler import GradualWarmupScheduler\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "import cv2\n",
    "\n",
    "from PIL import ImageFile, ImageOps\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU device 0: True\n"
     ]
    }
   ],
   "source": [
    "# GPU Device\n",
    "gpu_id = 0\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(\"GPU device %d:\" %(gpu_id), use_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = '/media/data2/dataset/GAN_ImageData/StyleGAN2_256/'\n",
    "target_dir = '/media/data2/dataset/GAN_ImageData/PGGAN_128/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained = './log/style2/128/b0/aug/checkpoint.pth.tar'\n",
    "resume = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model_name = 'efficientnet-b0' # b0-b7 scale\n",
    "\n",
    "# Optimization\n",
    "num_classes = 2\n",
    "epochs = 1000\n",
    "start_epoch = 0\n",
    "train_batch = 250\n",
    "test_batch = 250\n",
    "lr = 0.01\n",
    "schedule = [50, 250, 500, 750]\n",
    "momentum = 0.1\n",
    "gamma = 0.1 # LR is multiplied by gamma on schedule\n",
    "\n",
    "# CheckPoint\n",
    "checkpoint = './log/style2/128/b0/to_pggan/2000shot/general' # dir\n",
    "if not os.path.isdir(checkpoint):\n",
    "    os.makedirs(checkpoint)\n",
    "num_workers = 8\n",
    "\n",
    "# Seed\n",
    "manual_seed = 7\n",
    "random.seed(manual_seed)\n",
    "torch.cuda.manual_seed_all(manual_seed)\n",
    "\n",
    "# Image\n",
    "size = (128, 128)\n",
    "\n",
    "# cutmix\n",
    "cm_prob = 0.2\n",
    "cm_beta = 1.0\n",
    "\n",
    "# augmentation\n",
    "blur_prob = 0.2\n",
    "blog_sig = 0.5\n",
    "jpg_prob = 0.2\n",
    "\n",
    "best_acc = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {}\n",
    "state['num_classes'] = num_classes\n",
    "state['epochs'] = epochs\n",
    "state['start_epoch'] = start_epoch\n",
    "state['train_batch'] = train_batch\n",
    "state['test_batch'] = test_batch\n",
    "state['lr'] = lr\n",
    "state['schedule'] = schedule\n",
    "state['momentum'] = momentum\n",
    "state['gamma'] = gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_augment(img):\n",
    "    img = np.array(img)\n",
    "\n",
    "    if random.random() < blur_prob:\n",
    "        sig = np.random.uniform(0.0, 3.0)\n",
    "        gaussian_blur(img, sig)\n",
    "\n",
    "    if random.random() < jpg_prob:\n",
    "        qual = np.random.uniform(30.0, 100.0)\n",
    "        img = cv2_jpg(img, qual)\n",
    "\n",
    "    return Image.fromarray(img)\n",
    "\n",
    "\n",
    "def gaussian_blur(img, sigma):\n",
    "    gaussian_filter(img[:,:,0], output=img[:,:,0], sigma=sigma)\n",
    "    gaussian_filter(img[:,:,1], output=img[:,:,1], sigma=sigma)\n",
    "    gaussian_filter(img[:,:,2], output=img[:,:,2], sigma=sigma)\n",
    "\n",
    "\n",
    "def cv2_jpg(img, compress_val):\n",
    "    img_cv2 = img[:,:,::-1]\n",
    "    encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), compress_val]\n",
    "    result, encimg = cv2.imencode('.jpg', img_cv2, encode_param)\n",
    "    decimg = cv2.imdecode(encimg, 1)\n",
    "    return decimg[:,:,::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_bbox(size, lam):\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = np.int(W * cut_rat)\n",
    "    cut_h = np.int(H * cut_rat)\n",
    "\n",
    "    # uniform\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join(source_dir, 'pggan/2000_shot_only')\n",
    "val_target_dir = os.path.join(target_dir, 'validation')\n",
    "val_source_dir = os.path.join(source_dir, 'validation')\n",
    "\n",
    "train_aug = transforms.Compose([\n",
    "    transforms.Lambda(lambda img: data_augment(img)),\n",
    "    transforms.Resize(size),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "#     transforms.RandomErasing(p=0.3, scale=(0.02, 0.10), ratio=(0.3, 3.3), value=0, inplace=True),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "val_aug = transforms.Compose([\n",
    "    transforms.Resize(size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# pin_memory : cuda pin memeory use\n",
    "train_loader = DataLoader(datasets.ImageFolder(train_dir, transform=train_aug),\n",
    "                          batch_size=train_batch, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "val_target_loader = DataLoader(datasets.ImageFolder(val_target_dir, val_aug),\n",
    "                       batch_size=test_batch, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "val_source_loader = DataLoader(datasets.ImageFolder(val_source_dir, val_aug),\n",
    "                       batch_size=test_batch, shuffle=True, num_workers=num_workers, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> using pre-trained model './log/style2/128/b0/aug/checkpoint.pth.tar'\n"
     ]
    }
   ],
   "source": [
    "student_model = EfficientNet.from_name(model_name, num_classes=num_classes,\n",
    "                              override_params={'dropout_rate':0.2, 'drop_connect_rate':0.2})\n",
    "\n",
    "# Pre-trained\n",
    "if pretrained:\n",
    "    print(\"=> using pre-trained model '{}'\".format(pretrained))\n",
    "    student_model.load_state_dict(torch.load(pretrained)['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Total params: 4.01M\n"
     ]
    }
   ],
   "source": [
    "student_model.to('cuda')\n",
    "cudnn.benchmark = True\n",
    "print('    Total params: %.2fM' % (sum(p.numel() for p in student_model.parameters())/1000000.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, param in enumerate(student_model.parameters()):\n",
    "    param.reqiures_grad = False\n",
    "    if idx == 182:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = optim.SGD(student_model.parameters(), lr=lr, momentum=momentum)\n",
    "# optimizer = optim.Adam(student_model.parameters())\n",
    "scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)\n",
    "scheduler_warmup = GradualWarmupScheduler(optimizer, multiplier=4, total_epoch=10, after_scheduler=scheduler_cosine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resume\n",
    "if resume:\n",
    "    print('==> Resuming from checkpoint..')\n",
    "    checkpoint = os.path.dirname(resume)\n",
    "#     checkpoint = torch.load(resume)\n",
    "    resume = torch.load(resume)\n",
    "    best_acc = resume['best_acc']\n",
    "    start_epoch = resume['epoch']\n",
    "    student_model.load_state_dict(resume['state_dict'])\n",
    "    optimizer.load_state_dict(resume['optimizer'])\n",
    "    logger = Logger(os.path.join(checkpoint, 'log.txt'), resume=True)\n",
    "else:\n",
    "    logger = Logger(os.path.join(checkpoint, 'log.txt'))\n",
    "    logger.set_names(['Learning Rate', 'Train Loss', 'Valid Loss', 'Source Loss', 'Train Acc.', 'Valid Acc.', 'Source ACC.', 'Train AUROC', 'Valid AUROC', 'Source AUROC'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch, use_cuda):\n",
    "    model.train()\n",
    "    \n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    arc = AverageMeter()\n",
    "    end = time.time()\n",
    "    cls_losses = AverageMeter()\n",
    "    sp_losses = AverageMeter()\n",
    "    main_losses = AverageMeter()\n",
    "    \n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        batch_size = inputs.size(0)\n",
    "        if batch_size < train_batch:\n",
    "            continue\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            \n",
    "        r = np.random.rand(1)\n",
    "        if cm_beta > 0 and r < cm_prob:\n",
    "            \n",
    "            rand_index = torch.randperm(inputs.size()[0]).cuda()\n",
    "            tt= targets[rand_index]\n",
    "            boolean = targets==tt\n",
    "            rand_index = rand_index[boolean]\n",
    "            lam = np.random.beta(cm_beta, cm_beta)\n",
    "            bbx1, bby1, bbx2, bby2 = rand_bbox(inputs.size(), lam)\n",
    "            inputs[boolean, :, bbx1:bbx2, bby1:bby2] = inputs[rand_index, :, bbx1:bbx2, bby1:bby2]\n",
    "\n",
    "        # compute output\n",
    "        outputs = model(inputs)\n",
    "        loss_main = criterion(outputs, targets)\n",
    "        loss =  loss_main\n",
    "        loss_cls = 0\n",
    "        loss_sp = 0\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1 = accuracy(outputs.data, targets.data)\n",
    "#         auroc = roc_auc_score(targets.cpu().detach().numpy(), outputs.cpu().detach().numpy()[:,1])\n",
    "        losses.update(loss.data.tolist(), inputs.size(0))\n",
    "        top1.update(prec1[0], inputs.size(0))\n",
    "#         arc.update(auroc, inputs.size(0))\n",
    "        cls_losses.update(loss_cls, inputs.size(0))\n",
    "        sp_losses.update(loss_sp, inputs.size(0))\n",
    "        main_losses.update(loss_main.tolist(), inputs.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        \n",
    "#         if batch_idx % 100 == 0:\n",
    "#             print('{batch}/{size} | Loss:{loss:.4f} | MainLoss:{main:.4f} | SPLoss:{sp:.4f} | CLSLoss:{cls:.4f} | top1:{tp1:.4f} | AUROC:{ac:.4f}'.format(\n",
    "#                      batch=batch_idx+1, size=len(train_loader), loss=losses.avg, main=main_losses.avg, sp=sp_losses.avg, cls=cls_losses.avg, tp1=top1.avg, ac=arc.avg))\n",
    "    print('Train | {batch}/{size} | Loss:{loss:.4f} | MainLoss:{main:.4f} | SPLoss:{sp:.4f} | CLSLoss:{cls:.4f} | top1:{tp1:.4f} | AUROC:{ac:.4f}'.format(\n",
    "                     batch=batch_idx+1, size=len(train_loader), loss=losses.avg, main=main_losses.avg, sp=sp_losses.avg, cls=cls_losses.avg, tp1=top1.avg, ac=arc.avg))\n",
    "    return (losses.avg, top1.avg, arc.avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(val_loader, model, criterion, epoch, use_cuda):\n",
    "    global best_acc\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    arc = AverageMeter()\n",
    "    cls_losses = AverageMeter()\n",
    "    sp_losses = AverageMeter()\n",
    "    main_losses = AverageMeter()\n",
    "\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(val_loader):\n",
    "            # measure data loading time\n",
    "            data_time.update(time.time() - end)\n",
    "\n",
    "            if use_cuda:\n",
    "                inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "            # compute output\n",
    "            outputs = model(inputs)\n",
    "            loss_main = criterion(outputs, targets)\n",
    "            loss = loss_main\n",
    "            loss_cls = 0\n",
    "            loss_sp = 0\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            prec1 = accuracy(outputs.data, targets.data)\n",
    "            auroc = roc_auc_score(targets.cpu().detach().numpy(), outputs.cpu().detach().numpy()[:,1])\n",
    "            losses.update(loss.data.tolist(), inputs.size(0))\n",
    "            top1.update(prec1[0], inputs.size(0))\n",
    "            arc.update(auroc, inputs.size(0))\n",
    "            cls_losses.update(loss_cls, inputs.size(0))\n",
    "            sp_losses.update(loss_sp, inputs.size(0))\n",
    "            main_losses.update(loss_main.tolist(), inputs.size(0))\n",
    "\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "    print('Test | {batch}/{size} | Loss:{loss:.4f} | MainLoss:{main:.4f} | SPLoss:{sp:.4f} | CLSLoss:{cls:.4f} | top1:{tp1:.4f} | AUROC:{ac:.4f}'.format(\n",
    "                     batch=batch_idx+1, size=len(train_loader), loss=losses.avg, main=main_losses.avg, sp=sp_losses.avg, cls=cls_losses.avg, tp1=top1.avg, ac=arc.avg))\n",
    "    return (losses.avg, top1.avg, arc.avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, checkpoint='checkpoint', filename='checkpoint.pth.tar'):\n",
    "    filepath = os.path.join(checkpoint, filename)\n",
    "    torch.save(state, filepath)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filepath, os.path.join(checkpoint, 'model_best.pth.tar'))\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    global state\n",
    "    lr_set = [1, 1e-1, 1e-2, 1e-3, 1e-4, 1e-5]\n",
    "    lr_list = schedule.copy()\n",
    "    lr_list.append(epoch)\n",
    "    lr_list.sort()\n",
    "    idx = lr_list.index(epoch)\n",
    "    state['lr'] *= lr_set[idx]\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = state['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [1 | 1000] LR: 0.010000\n",
      "Train | 32/32 | Loss:1.0572 | MainLoss:1.0572 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:50.1419 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.6845 | MainLoss:0.6845 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:57.5140 | AUROC:0.5983\n",
      "Test | 32/32 | Loss:0.3525 | MainLoss:0.3525 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:74.2308 | AUROC:1.0000\n",
      "\n",
      "Epoch: [2 | 1000] LR: 0.013000\n",
      "Train | 32/32 | Loss:0.6912 | MainLoss:0.6912 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:53.0581 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.6668 | MainLoss:0.6668 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:63.3333 | AUROC:0.6885\n",
      "Test | 32/32 | Loss:0.3660 | MainLoss:0.3660 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:68.1282 | AUROC:0.9999\n",
      "\n",
      "Epoch: [3 | 1000] LR: 0.016000\n",
      "Train | 32/32 | Loss:0.6786 | MainLoss:0.6786 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:56.9935 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.6428 | MainLoss:0.6428 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:60.2492 | AUROC:0.8007\n",
      "Test | 32/32 | Loss:0.4942 | MainLoss:0.4942 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:52.6282 | AUROC:0.9986\n",
      "\n",
      "Epoch: [4 | 1000] LR: 0.019000\n",
      "Train | 32/32 | Loss:0.6403 | MainLoss:0.6403 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:65.6387 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.4422 | MainLoss:0.4422 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:89.5545 | AUROC:0.9642\n",
      "Test | 32/32 | Loss:0.4244 | MainLoss:0.4244 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:64.4872 | AUROC:0.9955\n",
      "\n",
      "Epoch: [5 | 1000] LR: 0.022000\n",
      "Train | 32/32 | Loss:0.5225 | MainLoss:0.5225 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:75.3548 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.2822 | MainLoss:0.2822 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:94.4829 | AUROC:0.9930\n",
      "Test | 32/32 | Loss:0.4630 | MainLoss:0.4630 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:62.1923 | AUROC:0.9613\n",
      "\n",
      "Epoch: [6 | 1000] LR: 0.025000\n",
      "Train | 32/32 | Loss:0.4717 | MainLoss:0.4717 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:77.9742 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.2401 | MainLoss:0.2401 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:97.2586 | AUROC:0.9962\n",
      "Test | 32/32 | Loss:0.5869 | MainLoss:0.5869 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:53.8718 | AUROC:0.8192\n",
      "\n",
      "Epoch: [7 | 1000] LR: 0.028000\n",
      "Train | 32/32 | Loss:0.4438 | MainLoss:0.4438 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:79.8194 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1879 | MainLoss:0.1879 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:98.2648 | AUROC:0.9978\n",
      "Test | 32/32 | Loss:0.7238 | MainLoss:0.7238 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:51.0128 | AUROC:0.6869\n",
      "\n",
      "Epoch: [8 | 1000] LR: 0.031000\n",
      "Train | 32/32 | Loss:0.4372 | MainLoss:0.4372 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:79.7419 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.2238 | MainLoss:0.2238 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:98.4455 | AUROC:0.9980\n",
      "Test | 32/32 | Loss:0.7166 | MainLoss:0.7166 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:42.8590 | AUROC:0.5907\n",
      "\n",
      "Epoch: [9 | 1000] LR: 0.034000\n",
      "Train | 32/32 | Loss:0.4382 | MainLoss:0.4382 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:79.9613 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.2012 | MainLoss:0.2012 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:98.6199 | AUROC:0.9984\n",
      "Test | 32/32 | Loss:0.7331 | MainLoss:0.7331 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:48.1282 | AUROC:0.5697\n",
      "\n",
      "Epoch: [10 | 1000] LR: 0.037000\n",
      "Train | 32/32 | Loss:0.4256 | MainLoss:0.4256 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:80.3355 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1778 | MainLoss:0.1778 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:98.8754 | AUROC:0.9989\n",
      "Test | 32/32 | Loss:0.8156 | MainLoss:0.8156 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:46.6538 | AUROC:0.4422\n",
      "\n",
      "Epoch: [11 | 1000] LR: 0.040000\n",
      "Train | 32/32 | Loss:0.4241 | MainLoss:0.4241 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:80.6194 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1905 | MainLoss:0.1905 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.0561 | AUROC:0.9991\n",
      "Test | 32/32 | Loss:0.8267 | MainLoss:0.8267 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:40.9872 | AUROC:0.3647\n",
      "\n",
      "Epoch: [12 | 1000] LR: 0.040000\n",
      "Train | 32/32 | Loss:0.4230 | MainLoss:0.4230 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:80.6839 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1570 | MainLoss:0.1570 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:98.9782 | AUROC:0.9994\n",
      "Test | 32/32 | Loss:0.9334 | MainLoss:0.9334 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:43.7821 | AUROC:0.2960\n",
      "\n",
      "Epoch: [13 | 1000] LR: 0.040000\n",
      "Train | 32/32 | Loss:0.4212 | MainLoss:0.4212 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:80.6065 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1461 | MainLoss:0.1461 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.1153 | AUROC:0.9995\n",
      "Test | 32/32 | Loss:0.9444 | MainLoss:0.9444 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:47.5769 | AUROC:0.2369\n",
      "\n",
      "Epoch: [14 | 1000] LR: 0.040000\n",
      "Train | 32/32 | Loss:0.4172 | MainLoss:0.4172 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:80.7871 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1362 | MainLoss:0.1362 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.2430 | AUROC:0.9995\n",
      "Test | 32/32 | Loss:0.9474 | MainLoss:0.9474 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:47.4231 | AUROC:0.2714\n",
      "\n",
      "Epoch: [15 | 1000] LR: 0.039999\n",
      "Train | 32/32 | Loss:0.4146 | MainLoss:0.4146 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:80.6710 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1707 | MainLoss:0.1707 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.2773 | AUROC:0.9996\n",
      "Test | 32/32 | Loss:0.8864 | MainLoss:0.8864 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:33.0256 | AUROC:0.3241\n",
      "\n",
      "Epoch: [16 | 1000] LR: 0.039998\n",
      "Train | 32/32 | Loss:0.4148 | MainLoss:0.4148 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:80.8129 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.2265 | MainLoss:0.2265 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.2679 | AUROC:0.9996\n",
      "Test | 32/32 | Loss:0.8207 | MainLoss:0.8207 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:24.7436 | AUROC:0.2754\n",
      "\n",
      "Epoch: [17 | 1000] LR: 0.039998\n",
      "Train | 32/32 | Loss:0.4137 | MainLoss:0.4137 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:80.9548 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1584 | MainLoss:0.1584 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.3925 | AUROC:0.9996\n",
      "Test | 32/32 | Loss:0.9208 | MainLoss:0.9208 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:39.1667 | AUROC:0.2245\n",
      "\n",
      "Epoch: [18 | 1000] LR: 0.039996\n",
      "Train | 32/32 | Loss:0.4123 | MainLoss:0.4123 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:80.9548 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1947 | MainLoss:0.1947 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.3364 | AUROC:0.9997\n",
      "Test | 32/32 | Loss:0.8872 | MainLoss:0.8872 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:25.0897 | AUROC:0.2347\n",
      "\n",
      "Epoch: [19 | 1000] LR: 0.039995\n",
      "Train | 32/32 | Loss:0.4104 | MainLoss:0.4104 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:80.8903 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1406 | MainLoss:0.1406 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.4611 | AUROC:0.9997\n",
      "Test | 32/32 | Loss:0.9809 | MainLoss:0.9809 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:33.6410 | AUROC:0.2200\n",
      "\n",
      "Epoch: [20 | 1000] LR: 0.039994\n",
      "Train | 32/32 | Loss:0.4105 | MainLoss:0.4105 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:80.6968 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1781 | MainLoss:0.1781 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.4299 | AUROC:0.9997\n",
      "Test | 32/32 | Loss:0.8852 | MainLoss:0.8852 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:30.2436 | AUROC:0.2427\n",
      "\n",
      "Epoch: [21 | 1000] LR: 0.039992\n",
      "Train | 32/32 | Loss:0.4056 | MainLoss:0.4056 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:81.5097 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1499 | MainLoss:0.1499 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.3738 | AUROC:0.9997\n",
      "Test | 32/32 | Loss:0.9134 | MainLoss:0.9134 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:37.6795 | AUROC:0.3009\n",
      "\n",
      "Epoch: [22 | 1000] LR: 0.039990\n",
      "Train | 32/32 | Loss:0.4115 | MainLoss:0.4115 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:80.8258 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1694 | MainLoss:0.1694 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.4579 | AUROC:0.9997\n",
      "Test | 32/32 | Loss:0.9012 | MainLoss:0.9012 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:31.5256 | AUROC:0.2407\n",
      "\n",
      "Epoch: [23 | 1000] LR: 0.039988\n",
      "Train | 32/32 | Loss:0.4030 | MainLoss:0.4030 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:81.1355 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1334 | MainLoss:0.1334 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.4953 | AUROC:0.9998\n",
      "Test | 32/32 | Loss:0.9483 | MainLoss:0.9483 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:45.2692 | AUROC:0.2510\n",
      "\n",
      "Epoch: [24 | 1000] LR: 0.039986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 32/32 | Loss:0.4028 | MainLoss:0.4028 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:81.3290 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1880 | MainLoss:0.1880 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.2150 | AUROC:0.9997\n",
      "Test | 32/32 | Loss:0.8693 | MainLoss:0.8693 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:27.0385 | AUROC:0.2929\n",
      "\n",
      "Epoch: [25 | 1000] LR: 0.039983\n",
      "Train | 32/32 | Loss:0.4053 | MainLoss:0.4053 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:81.1355 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1999 | MainLoss:0.1999 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.0903 | AUROC:0.9997\n",
      "Test | 32/32 | Loss:0.8377 | MainLoss:0.8377 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:28.1154 | AUROC:0.3043\n",
      "\n",
      "Epoch: [26 | 1000] LR: 0.039981\n",
      "Train | 32/32 | Loss:0.4061 | MainLoss:0.4061 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:81.1097 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1667 | MainLoss:0.1667 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.4735 | AUROC:0.9998\n",
      "Test | 32/32 | Loss:0.8798 | MainLoss:0.8798 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:36.8462 | AUROC:0.2721\n",
      "\n",
      "Epoch: [27 | 1000] LR: 0.039978\n",
      "Train | 32/32 | Loss:0.4017 | MainLoss:0.4017 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:81.4064 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1091 | MainLoss:0.1091 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.5047 | AUROC:0.9997\n",
      "Test | 32/32 | Loss:1.0072 | MainLoss:1.0072 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:49.0256 | AUROC:0.2685\n",
      "\n",
      "Epoch: [28 | 1000] LR: 0.039975\n",
      "Train | 32/32 | Loss:0.4046 | MainLoss:0.4046 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:80.9935 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1700 | MainLoss:0.1700 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.3115 | AUROC:0.9996\n",
      "Test | 32/32 | Loss:0.8577 | MainLoss:0.8577 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:35.3718 | AUROC:0.3512\n",
      "\n",
      "Epoch: [29 | 1000] LR: 0.039971\n",
      "Train | 32/32 | Loss:0.3924 | MainLoss:0.3924 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:81.8064 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.2401 | MainLoss:0.2401 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.4112 | AUROC:0.9989\n",
      "Test | 32/32 | Loss:0.7510 | MainLoss:0.7510 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:40.5897 | AUROC:0.5154\n",
      "\n",
      "Epoch: [30 | 1000] LR: 0.039968\n",
      "Train | 32/32 | Loss:0.4040 | MainLoss:0.4040 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:81.0581 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1308 | MainLoss:0.1308 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.4984 | AUROC:0.9996\n",
      "Test | 32/32 | Loss:0.9315 | MainLoss:0.9315 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:48.2436 | AUROC:0.2926\n",
      "\n",
      "Epoch: [31 | 1000] LR: 0.039964\n",
      "Train | 32/32 | Loss:0.3970 | MainLoss:0.3970 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:81.3806 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1818 | MainLoss:0.1818 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.0654 | AUROC:0.9996\n",
      "Test | 32/32 | Loss:0.8844 | MainLoss:0.8844 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:27.7051 | AUROC:0.3193\n",
      "\n",
      "Epoch: [32 | 1000] LR: 0.039961\n",
      "Train | 32/32 | Loss:0.3935 | MainLoss:0.3935 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:81.7290 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1476 | MainLoss:0.1476 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.2181 | AUROC:0.9996\n",
      "Test | 32/32 | Loss:0.9314 | MainLoss:0.9314 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:31.5897 | AUROC:0.3298\n",
      "\n",
      "Epoch: [33 | 1000] LR: 0.039956\n",
      "Train | 32/32 | Loss:0.3956 | MainLoss:0.3956 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:81.5355 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1463 | MainLoss:0.1463 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.4112 | AUROC:0.9996\n",
      "Test | 32/32 | Loss:0.9186 | MainLoss:0.9186 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:34.6282 | AUROC:0.3190\n",
      "\n",
      "Epoch: [34 | 1000] LR: 0.039952\n",
      "Train | 32/32 | Loss:0.3967 | MainLoss:0.3967 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:81.5742 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1530 | MainLoss:0.1530 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.2773 | AUROC:0.9996\n",
      "Test | 32/32 | Loss:0.9331 | MainLoss:0.9331 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:29.9487 | AUROC:0.3124\n",
      "\n",
      "Epoch: [35 | 1000] LR: 0.039948\n",
      "Train | 32/32 | Loss:0.3958 | MainLoss:0.3958 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:81.3032 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1823 | MainLoss:0.1823 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:98.8442 | AUROC:0.9994\n",
      "Test | 32/32 | Loss:0.8812 | MainLoss:0.8812 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:28.7308 | AUROC:0.3337\n",
      "\n",
      "Epoch: [36 | 1000] LR: 0.039943\n",
      "Train | 32/32 | Loss:0.3914 | MainLoss:0.3914 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:81.6645 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1633 | MainLoss:0.1633 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:98.6636 | AUROC:0.9993\n",
      "Test | 32/32 | Loss:0.9331 | MainLoss:0.9331 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:29.1026 | AUROC:0.3170\n",
      "\n",
      "Epoch: [37 | 1000] LR: 0.039938\n",
      "Train | 32/32 | Loss:0.3882 | MainLoss:0.3882 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:81.5226 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1302 | MainLoss:0.1302 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.3832 | AUROC:0.9996\n",
      "Test | 32/32 | Loss:0.9274 | MainLoss:0.9274 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:41.1538 | AUROC:0.3802\n",
      "\n",
      "Epoch: [38 | 1000] LR: 0.039933\n",
      "Train | 32/32 | Loss:0.3860 | MainLoss:0.3860 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:81.9355 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1830 | MainLoss:0.1830 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:98.2555 | AUROC:0.9994\n",
      "Test | 32/32 | Loss:0.7726 | MainLoss:0.7726 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:41.3974 | AUROC:0.5450\n",
      "\n",
      "Epoch: [39 | 1000] LR: 0.039928\n",
      "Train | 32/32 | Loss:0.3888 | MainLoss:0.3888 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:81.6516 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.2080 | MainLoss:0.2080 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.8505 | AUROC:0.9992\n",
      "Test | 32/32 | Loss:0.7477 | MainLoss:0.7477 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:43.2436 | AUROC:0.5485\n",
      "\n",
      "Epoch: [40 | 1000] LR: 0.039923\n",
      "Train | 32/32 | Loss:0.3862 | MainLoss:0.3862 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:81.7032 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1355 | MainLoss:0.1355 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:98.8069 | AUROC:0.9992\n",
      "Test | 32/32 | Loss:0.8538 | MainLoss:0.8538 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:47.3974 | AUROC:0.5578\n",
      "\n",
      "Epoch: [41 | 1000] LR: 0.039917\n",
      "Train | 32/32 | Loss:0.3891 | MainLoss:0.3891 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:81.7548 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1488 | MainLoss:0.1488 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.0405 | AUROC:0.9992\n",
      "Test | 32/32 | Loss:0.8701 | MainLoss:0.8701 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:38.6538 | AUROC:0.4345\n",
      "\n",
      "Epoch: [42 | 1000] LR: 0.039911\n",
      "Train | 32/32 | Loss:0.3781 | MainLoss:0.3781 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:82.1419 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1485 | MainLoss:0.1485 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:98.0748 | AUROC:0.9991\n",
      "Test | 32/32 | Loss:0.8149 | MainLoss:0.8149 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:47.0256 | AUROC:0.5924\n",
      "\n",
      "Epoch: [43 | 1000] LR: 0.039905\n",
      "Train | 32/32 | Loss:0.3809 | MainLoss:0.3809 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:81.7806 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1271 | MainLoss:0.1271 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.0000 | AUROC:0.9991\n",
      "Test | 32/32 | Loss:0.8833 | MainLoss:0.8833 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:44.8462 | AUROC:0.5381\n",
      "\n",
      "Epoch: [44 | 1000] LR: 0.039899\n",
      "Train | 32/32 | Loss:0.3770 | MainLoss:0.3770 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:82.0000 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1954 | MainLoss:0.1954 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:95.5203 | AUROC:0.9990\n",
      "Test | 32/32 | Loss:0.7322 | MainLoss:0.7322 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:48.5128 | AUROC:0.6167\n",
      "\n",
      "Epoch: [45 | 1000] LR: 0.039893\n",
      "Train | 32/32 | Loss:0.3753 | MainLoss:0.3753 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:82.3097 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1165 | MainLoss:0.1165 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.1090 | AUROC:0.9989\n",
      "Test | 32/32 | Loss:0.9352 | MainLoss:0.9352 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:45.1538 | AUROC:0.4821\n",
      "\n",
      "Epoch: [46 | 1000] LR: 0.039886\n",
      "Train | 32/32 | Loss:0.3769 | MainLoss:0.3769 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:82.4903 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1359 | MainLoss:0.1359 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:98.8162 | AUROC:0.9989\n",
      "Test | 32/32 | Loss:0.8553 | MainLoss:0.8553 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:44.7949 | AUROC:0.5387\n",
      "\n",
      "Epoch: [47 | 1000] LR: 0.039879\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 32/32 | Loss:0.3700 | MainLoss:0.3700 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:82.8000 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.2158 | MainLoss:0.2158 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:93.4829 | AUROC:0.9986\n",
      "Test | 32/32 | Loss:0.7472 | MainLoss:0.7472 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:49.3205 | AUROC:0.5943\n",
      "\n",
      "Epoch: [48 | 1000] LR: 0.039872\n",
      "Train | 32/32 | Loss:0.3730 | MainLoss:0.3730 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:82.9806 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1557 | MainLoss:0.1557 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:97.4704 | AUROC:0.9990\n",
      "Test | 32/32 | Loss:0.8335 | MainLoss:0.8335 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:43.1923 | AUROC:0.5306\n",
      "\n",
      "Epoch: [49 | 1000] LR: 0.039865\n",
      "Train | 32/32 | Loss:0.3705 | MainLoss:0.3705 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:82.6323 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1015 | MainLoss:0.1015 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:98.7788 | AUROC:0.9987\n",
      "Test | 32/32 | Loss:0.9737 | MainLoss:0.9737 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:45.3077 | AUROC:0.5248\n",
      "\n",
      "Epoch: [50 | 1000] LR: 0.039858\n",
      "Train | 32/32 | Loss:0.3695 | MainLoss:0.3695 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:82.4000 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1411 | MainLoss:0.1411 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:97.9284 | AUROC:0.9990\n",
      "Test | 32/32 | Loss:0.8411 | MainLoss:0.8411 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:44.8974 | AUROC:0.5488\n",
      "\n",
      "Epoch: [51 | 1000] LR: 0.039850\n",
      "Train | 32/32 | Loss:0.3580 | MainLoss:0.3580 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:83.5871 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1644 | MainLoss:0.1644 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:95.9284 | AUROC:0.9988\n",
      "Test | 32/32 | Loss:0.8454 | MainLoss:0.8454 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:46.2179 | AUROC:0.5456\n",
      "\n",
      "Epoch: [52 | 1000] LR: 0.003984\n",
      "Train | 32/32 | Loss:0.3527 | MainLoss:0.3527 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:83.5613 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1545 | MainLoss:0.1545 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.3520 | AUROC:0.9987\n",
      "Test | 32/32 | Loss:0.8643 | MainLoss:0.8643 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:44.3205 | AUROC:0.5227\n",
      "\n",
      "Epoch: [53 | 1000] LR: 0.003983\n",
      "Train | 32/32 | Loss:0.3476 | MainLoss:0.3476 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:83.9097 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1534 | MainLoss:0.1534 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.2523 | AUROC:0.9987\n",
      "Test | 32/32 | Loss:0.8736 | MainLoss:0.8736 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:43.7051 | AUROC:0.5146\n",
      "\n",
      "Epoch: [54 | 1000] LR: 0.003983\n",
      "Train | 32/32 | Loss:0.3518 | MainLoss:0.3518 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:83.4323 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1578 | MainLoss:0.1578 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:95.9346 | AUROC:0.9986\n",
      "Test | 32/32 | Loss:0.8647 | MainLoss:0.8647 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:44.6026 | AUROC:0.5250\n",
      "\n",
      "Epoch: [55 | 1000] LR: 0.003982\n",
      "Train | 32/32 | Loss:0.3477 | MainLoss:0.3477 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:83.8064 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1570 | MainLoss:0.1570 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:95.8692 | AUROC:0.9986\n",
      "Test | 32/32 | Loss:0.8799 | MainLoss:0.8799 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:43.8590 | AUROC:0.5133\n",
      "\n",
      "Epoch: [56 | 1000] LR: 0.003981\n",
      "Train | 32/32 | Loss:0.3487 | MainLoss:0.3487 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:83.8323 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1682 | MainLoss:0.1682 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:95.1433 | AUROC:0.9986\n",
      "Test | 32/32 | Loss:0.8777 | MainLoss:0.8777 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:44.0641 | AUROC:0.5059\n",
      "\n",
      "Epoch: [57 | 1000] LR: 0.003980\n",
      "Train | 32/32 | Loss:0.3498 | MainLoss:0.3498 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:83.5355 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1627 | MainLoss:0.1627 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:95.3614 | AUROC:0.9986\n",
      "Test | 32/32 | Loss:0.8777 | MainLoss:0.8777 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:44.2821 | AUROC:0.5150\n",
      "\n",
      "Epoch: [58 | 1000] LR: 0.003979\n",
      "Train | 32/32 | Loss:0.3485 | MainLoss:0.3485 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:83.8194 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1577 | MainLoss:0.1577 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:95.7041 | AUROC:0.9987\n",
      "Test | 32/32 | Loss:0.8941 | MainLoss:0.8941 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:43.5000 | AUROC:0.5020\n",
      "\n",
      "Epoch: [59 | 1000] LR: 0.003978\n",
      "Train | 32/32 | Loss:0.3510 | MainLoss:0.3510 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:83.6645 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1525 | MainLoss:0.1525 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.1402 | AUROC:0.9987\n",
      "Test | 32/32 | Loss:0.9064 | MainLoss:0.9064 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:42.0769 | AUROC:0.4847\n",
      "\n",
      "Epoch: [60 | 1000] LR: 0.003977\n",
      "Train | 32/32 | Loss:0.3443 | MainLoss:0.3443 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:84.0516 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1578 | MainLoss:0.1578 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:95.6417 | AUROC:0.9987\n",
      "Test | 32/32 | Loss:0.9086 | MainLoss:0.9086 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:42.7051 | AUROC:0.4892\n",
      "\n",
      "Epoch: [61 | 1000] LR: 0.003976\n",
      "Train | 32/32 | Loss:0.3476 | MainLoss:0.3476 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:83.7290 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1507 | MainLoss:0.1507 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:95.9595 | AUROC:0.9987\n",
      "Test | 32/32 | Loss:0.9137 | MainLoss:0.9137 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:43.0000 | AUROC:0.4954\n",
      "\n",
      "Epoch: [62 | 1000] LR: 0.003975\n",
      "Train | 32/32 | Loss:0.3407 | MainLoss:0.3407 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:84.6323 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1554 | MainLoss:0.1554 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:95.6386 | AUROC:0.9988\n",
      "Test | 32/32 | Loss:0.9164 | MainLoss:0.9164 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:43.0769 | AUROC:0.4914\n",
      "\n",
      "Epoch: [63 | 1000] LR: 0.003974\n",
      "Train | 32/32 | Loss:0.3468 | MainLoss:0.3468 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:83.7806 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1476 | MainLoss:0.1476 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.0717 | AUROC:0.9987\n",
      "Test | 32/32 | Loss:0.9208 | MainLoss:0.9208 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:42.5513 | AUROC:0.4913\n",
      "\n",
      "Epoch: [64 | 1000] LR: 0.003973\n",
      "Train | 32/32 | Loss:0.3474 | MainLoss:0.3474 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:83.8710 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1632 | MainLoss:0.1632 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:95.3271 | AUROC:0.9987\n",
      "Test | 32/32 | Loss:0.9010 | MainLoss:0.9010 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:43.3718 | AUROC:0.4947\n",
      "\n",
      "Epoch: [65 | 1000] LR: 0.003972\n",
      "Train | 32/32 | Loss:0.3458 | MainLoss:0.3458 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:84.2710 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1458 | MainLoss:0.1458 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.2025 | AUROC:0.9988\n",
      "Test | 32/32 | Loss:0.9382 | MainLoss:0.9382 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:41.6667 | AUROC:0.4765\n",
      "\n",
      "Epoch: [66 | 1000] LR: 0.003971\n",
      "Train | 32/32 | Loss:0.3465 | MainLoss:0.3465 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:83.7032 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1491 | MainLoss:0.1491 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.0125 | AUROC:0.9988\n",
      "Test | 32/32 | Loss:0.9303 | MainLoss:0.9303 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:42.0256 | AUROC:0.4815\n",
      "\n",
      "Epoch: [67 | 1000] LR: 0.003970\n",
      "Train | 32/32 | Loss:0.3447 | MainLoss:0.3447 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:83.9742 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1378 | MainLoss:0.1378 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.6542 | AUROC:0.9988\n",
      "Test | 32/32 | Loss:0.9576 | MainLoss:0.9576 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:40.5128 | AUROC:0.4579\n",
      "\n",
      "Epoch: [68 | 1000] LR: 0.003969\n",
      "Train | 32/32 | Loss:0.3383 | MainLoss:0.3383 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:84.0129 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1563 | MainLoss:0.1563 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:95.4611 | AUROC:0.9986\n",
      "Test | 32/32 | Loss:0.9266 | MainLoss:0.9266 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:42.6410 | AUROC:0.4840\n",
      "\n",
      "Epoch: [69 | 1000] LR: 0.003968\n",
      "Train | 32/32 | Loss:0.3398 | MainLoss:0.3398 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:84.0387 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1489 | MainLoss:0.1489 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:95.7632 | AUROC:0.9987\n",
      "Test | 32/32 | Loss:0.9329 | MainLoss:0.9329 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:43.0513 | AUROC:0.4914\n",
      "\n",
      "Epoch: [70 | 1000] LR: 0.003967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 32/32 | Loss:0.3447 | MainLoss:0.3447 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:84.0774 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1648 | MainLoss:0.1648 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:94.9377 | AUROC:0.9987\n",
      "Test | 32/32 | Loss:0.8931 | MainLoss:0.8931 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:44.7308 | AUROC:0.5088\n",
      "\n",
      "Epoch: [71 | 1000] LR: 0.003966\n",
      "Train | 32/32 | Loss:0.3455 | MainLoss:0.3455 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:83.9613 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1555 | MainLoss:0.1555 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:95.5327 | AUROC:0.9987\n",
      "Test | 32/32 | Loss:0.9133 | MainLoss:0.9133 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:42.9103 | AUROC:0.4902\n",
      "\n",
      "Epoch: [72 | 1000] LR: 0.003965\n",
      "Train | 32/32 | Loss:0.3430 | MainLoss:0.3430 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:84.0903 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1496 | MainLoss:0.1496 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:95.7975 | AUROC:0.9986\n",
      "Test | 32/32 | Loss:0.9314 | MainLoss:0.9314 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:42.0128 | AUROC:0.4786\n",
      "\n",
      "Epoch: [73 | 1000] LR: 0.003963\n",
      "Train | 32/32 | Loss:0.3387 | MainLoss:0.3387 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:84.4129 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1414 | MainLoss:0.1414 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.1184 | AUROC:0.9987\n",
      "Test | 32/32 | Loss:0.9493 | MainLoss:0.9493 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:41.9359 | AUROC:0.4782\n",
      "\n",
      "Epoch: [74 | 1000] LR: 0.003962\n",
      "Train | 32/32 | Loss:0.3418 | MainLoss:0.3418 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:84.2452 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1602 | MainLoss:0.1602 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:95.0592 | AUROC:0.9987\n",
      "Test | 32/32 | Loss:0.9145 | MainLoss:0.9145 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:43.8974 | AUROC:0.4918\n",
      "\n",
      "Epoch: [75 | 1000] LR: 0.003961\n",
      "Train | 32/32 | Loss:0.3447 | MainLoss:0.3447 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:83.7677 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1544 | MainLoss:0.1544 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:95.5763 | AUROC:0.9987\n",
      "Test | 32/32 | Loss:0.9284 | MainLoss:0.9284 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:42.1923 | AUROC:0.4719\n",
      "\n",
      "Epoch: [76 | 1000] LR: 0.003960\n",
      "Train | 32/32 | Loss:0.3395 | MainLoss:0.3395 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:84.5677 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1572 | MainLoss:0.1572 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:95.3956 | AUROC:0.9987\n",
      "Test | 32/32 | Loss:0.9211 | MainLoss:0.9211 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:42.8974 | AUROC:0.4809\n",
      "\n",
      "Epoch: [77 | 1000] LR: 0.003958\n",
      "Train | 32/32 | Loss:0.3413 | MainLoss:0.3413 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:84.4129 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1499 | MainLoss:0.1499 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:95.7913 | AUROC:0.9988\n",
      "Test | 32/32 | Loss:0.9436 | MainLoss:0.9436 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:41.4615 | AUROC:0.4625\n",
      "\n",
      "Epoch: [78 | 1000] LR: 0.003957\n",
      "Train | 32/32 | Loss:0.3439 | MainLoss:0.3439 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:83.9484 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1646 | MainLoss:0.1646 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:94.8255 | AUROC:0.9988\n",
      "Test | 32/32 | Loss:0.9356 | MainLoss:0.9356 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:42.5897 | AUROC:0.4686\n",
      "\n",
      "Epoch: [79 | 1000] LR: 0.003956\n",
      "Train | 32/32 | Loss:0.3424 | MainLoss:0.3424 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:84.0516 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1568 | MainLoss:0.1568 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:95.4143 | AUROC:0.9988\n",
      "Test | 32/32 | Loss:0.9410 | MainLoss:0.9410 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:41.4615 | AUROC:0.4594\n",
      "\n",
      "Epoch: [80 | 1000] LR: 0.003955\n",
      "Train | 32/32 | Loss:0.3440 | MainLoss:0.3440 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:83.8452 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1668 | MainLoss:0.1668 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:94.8162 | AUROC:0.9987\n",
      "Test | 32/32 | Loss:0.9260 | MainLoss:0.9260 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:42.1282 | AUROC:0.4621\n",
      "\n",
      "Epoch: [81 | 1000] LR: 0.003953\n",
      "Train | 32/32 | Loss:0.3445 | MainLoss:0.3445 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:84.1161 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1348 | MainLoss:0.1348 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.8006 | AUROC:0.9988\n",
      "Test | 32/32 | Loss:0.9916 | MainLoss:0.9916 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:38.0513 | AUROC:0.4152\n",
      "\n",
      "Epoch: [82 | 1000] LR: 0.003952\n",
      "Train | 32/32 | Loss:0.3375 | MainLoss:0.3375 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:84.2839 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1404 | MainLoss:0.1404 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.2461 | AUROC:0.9987\n",
      "Test | 32/32 | Loss:0.9777 | MainLoss:0.9777 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:39.6282 | AUROC:0.4354\n",
      "\n",
      "Epoch: [83 | 1000] LR: 0.003950\n",
      "Train | 32/32 | Loss:0.3396 | MainLoss:0.3396 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:84.6839 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1615 | MainLoss:0.1615 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:94.8910 | AUROC:0.9989\n",
      "Test | 32/32 | Loss:0.9533 | MainLoss:0.9533 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:41.9615 | AUROC:0.4578\n",
      "\n",
      "Epoch: [84 | 1000] LR: 0.003949\n",
      "Train | 32/32 | Loss:0.3375 | MainLoss:0.3375 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:84.3097 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1401 | MainLoss:0.1401 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.1526 | AUROC:0.9988\n",
      "Test | 32/32 | Loss:0.9966 | MainLoss:0.9966 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:39.3718 | AUROC:0.4286\n",
      "\n",
      "Epoch: [85 | 1000] LR: 0.003948\n",
      "Train | 32/32 | Loss:0.3375 | MainLoss:0.3375 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:84.3484 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1416 | MainLoss:0.1416 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.1153 | AUROC:0.9987\n",
      "Test | 32/32 | Loss:0.9861 | MainLoss:0.9861 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:39.6795 | AUROC:0.4334\n",
      "\n",
      "Epoch: [86 | 1000] LR: 0.003946\n",
      "Train | 32/32 | Loss:0.3387 | MainLoss:0.3387 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:84.5161 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1397 | MainLoss:0.1397 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.2866 | AUROC:0.9988\n",
      "Test | 32/32 | Loss:0.9970 | MainLoss:0.9970 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:38.8333 | AUROC:0.4210\n",
      "\n",
      "Epoch: [87 | 1000] LR: 0.003945\n",
      "Train | 32/32 | Loss:0.3379 | MainLoss:0.3379 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:84.0387 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1506 | MainLoss:0.1506 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:95.6168 | AUROC:0.9989\n",
      "Test | 32/32 | Loss:0.9907 | MainLoss:0.9907 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:39.5897 | AUROC:0.4228\n",
      "\n",
      "Epoch: [88 | 1000] LR: 0.003943\n",
      "Train | 32/32 | Loss:0.3352 | MainLoss:0.3352 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:84.6452 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1453 | MainLoss:0.1453 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:95.8629 | AUROC:0.9988\n",
      "Test | 32/32 | Loss:1.0005 | MainLoss:1.0005 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:38.9487 | AUROC:0.4191\n",
      "\n",
      "Epoch: [89 | 1000] LR: 0.003942\n",
      "Train | 32/32 | Loss:0.3363 | MainLoss:0.3363 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:84.9161 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1524 | MainLoss:0.1524 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:95.3925 | AUROC:0.9986\n",
      "Test | 32/32 | Loss:0.9902 | MainLoss:0.9902 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:39.7821 | AUROC:0.4254\n",
      "\n",
      "Epoch: [90 | 1000] LR: 0.003940\n",
      "Train | 32/32 | Loss:0.3358 | MainLoss:0.3358 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:84.6323 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1611 | MainLoss:0.1611 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:94.8069 | AUROC:0.9985\n",
      "Test | 32/32 | Loss:0.9822 | MainLoss:0.9822 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:40.2821 | AUROC:0.4280\n",
      "\n",
      "Epoch: [91 | 1000] LR: 0.003939\n",
      "Train | 32/32 | Loss:0.3379 | MainLoss:0.3379 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:84.5677 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1421 | MainLoss:0.1421 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:95.9315 | AUROC:0.9985\n",
      "Test | 32/32 | Loss:1.0041 | MainLoss:1.0041 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:38.6154 | AUROC:0.4145\n",
      "\n",
      "Epoch: [92 | 1000] LR: 0.003937\n",
      "Train | 32/32 | Loss:0.3311 | MainLoss:0.3311 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:84.7871 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1419 | MainLoss:0.1419 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:95.8411 | AUROC:0.9987\n",
      "Test | 32/32 | Loss:1.0223 | MainLoss:1.0223 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:39.1282 | AUROC:0.4175\n",
      "\n",
      "Epoch: [93 | 1000] LR: 0.003936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 32/32 | Loss:0.3337 | MainLoss:0.3337 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:84.7613 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1476 | MainLoss:0.1476 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:95.5389 | AUROC:0.9987\n",
      "Test | 32/32 | Loss:1.0029 | MainLoss:1.0029 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:39.7821 | AUROC:0.4236\n",
      "\n",
      "Epoch: [94 | 1000] LR: 0.003934\n",
      "Train | 32/32 | Loss:0.3344 | MainLoss:0.3344 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:84.8903 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1395 | MainLoss:0.1395 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.0093 | AUROC:0.9988\n",
      "Test | 32/32 | Loss:1.0192 | MainLoss:1.0192 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:38.8718 | AUROC:0.4152\n",
      "\n",
      "Epoch: [95 | 1000] LR: 0.003932\n",
      "Train | 32/32 | Loss:0.3322 | MainLoss:0.3322 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:84.6710 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1662 | MainLoss:0.1662 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:94.4237 | AUROC:0.9986\n",
      "Test | 32/32 | Loss:0.9680 | MainLoss:0.9680 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:41.3333 | AUROC:0.4410\n",
      "\n",
      "Epoch: [96 | 1000] LR: 0.003931\n",
      "Train | 32/32 | Loss:0.3406 | MainLoss:0.3406 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:84.2710 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1606 | MainLoss:0.1606 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:94.9751 | AUROC:0.9987\n",
      "Test | 32/32 | Loss:0.9614 | MainLoss:0.9614 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:40.7821 | AUROC:0.4339\n",
      "\n",
      "Epoch: [97 | 1000] LR: 0.003929\n",
      "Train | 32/32 | Loss:0.3425 | MainLoss:0.3425 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:84.4129 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1499 | MainLoss:0.1499 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:95.6573 | AUROC:0.9985\n",
      "Test | 32/32 | Loss:0.9873 | MainLoss:0.9873 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:38.7949 | AUROC:0.4116\n",
      "\n",
      "Epoch: [98 | 1000] LR: 0.003927\n",
      "Train | 32/32 | Loss:0.3369 | MainLoss:0.3369 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:84.5935 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1521 | MainLoss:0.1521 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:95.3863 | AUROC:0.9986\n",
      "Test | 32/32 | Loss:1.0144 | MainLoss:1.0144 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:38.3590 | AUROC:0.3976\n",
      "\n",
      "Epoch: [99 | 1000] LR: 0.003926\n",
      "Train | 32/32 | Loss:0.3314 | MainLoss:0.3314 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:84.7355 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1522 | MainLoss:0.1522 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:95.3178 | AUROC:0.9987\n",
      "Test | 32/32 | Loss:1.0093 | MainLoss:1.0093 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:38.7821 | AUROC:0.4051\n",
      "\n",
      "Epoch: [100 | 1000] LR: 0.003924\n",
      "Train | 32/32 | Loss:0.3369 | MainLoss:0.3369 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:84.6839 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1564 | MainLoss:0.1564 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:95.1028 | AUROC:0.9989\n",
      "Test | 32/32 | Loss:1.0075 | MainLoss:1.0075 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:39.4615 | AUROC:0.4144\n",
      "\n",
      "Epoch: [101 | 1000] LR: 0.003922\n",
      "Train | 32/32 | Loss:0.3326 | MainLoss:0.3326 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:84.8129 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1485 | MainLoss:0.1485 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:95.5763 | AUROC:0.9988\n",
      "Test | 32/32 | Loss:1.0185 | MainLoss:1.0185 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:38.5128 | AUROC:0.4036\n",
      "\n",
      "Epoch: [102 | 1000] LR: 0.003921\n",
      "Train | 32/32 | Loss:0.3368 | MainLoss:0.3368 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:84.5677 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1574 | MainLoss:0.1574 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:95.0187 | AUROC:0.9987\n",
      "Test | 32/32 | Loss:1.0023 | MainLoss:1.0023 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:39.2051 | AUROC:0.4066\n",
      "\n",
      "Epoch: [103 | 1000] LR: 0.003919\n",
      "Train | 32/32 | Loss:0.3293 | MainLoss:0.3293 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:85.2129 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1561 | MainLoss:0.1561 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:94.8567 | AUROC:0.9986\n",
      "Test | 32/32 | Loss:1.0069 | MainLoss:1.0069 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:40.0256 | AUROC:0.4202\n",
      "\n",
      "Epoch: [104 | 1000] LR: 0.003917\n",
      "Train | 32/32 | Loss:0.3308 | MainLoss:0.3308 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:84.8258 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1531 | MainLoss:0.1531 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:95.0031 | AUROC:0.9987\n",
      "Test | 32/32 | Loss:1.0287 | MainLoss:1.0287 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:39.4103 | AUROC:0.4089\n",
      "\n",
      "Epoch: [105 | 1000] LR: 0.003915\n",
      "Train | 32/32 | Loss:0.3292 | MainLoss:0.3292 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:85.0581 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1549 | MainLoss:0.1549 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:94.9969 | AUROC:0.9987\n",
      "Test | 32/32 | Loss:1.0432 | MainLoss:1.0432 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:38.5769 | AUROC:0.3958\n",
      "\n",
      "Epoch: [106 | 1000] LR: 0.003913\n",
      "Train | 32/32 | Loss:0.3280 | MainLoss:0.3280 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:85.0581 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1591 | MainLoss:0.1591 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:94.7944 | AUROC:0.9988\n",
      "Test | 32/32 | Loss:1.0400 | MainLoss:1.0400 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:39.1795 | AUROC:0.4040\n",
      "\n",
      "Epoch: [107 | 1000] LR: 0.003912\n",
      "Train | 32/32 | Loss:0.3283 | MainLoss:0.3283 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:85.0839 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1375 | MainLoss:0.1375 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:95.9564 | AUROC:0.9988\n",
      "Test | 32/32 | Loss:1.0895 | MainLoss:1.0895 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:36.2949 | AUROC:0.3686\n",
      "\n",
      "Epoch: [108 | 1000] LR: 0.003910\n",
      "Train | 32/32 | Loss:0.3324 | MainLoss:0.3324 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:84.7613 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1523 | MainLoss:0.1523 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:95.2243 | AUROC:0.9988\n",
      "Test | 32/32 | Loss:1.0656 | MainLoss:1.0656 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:37.1538 | AUROC:0.3758\n",
      "\n",
      "Epoch: [109 | 1000] LR: 0.003908\n",
      "Train | 32/32 | Loss:0.3304 | MainLoss:0.3304 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:84.9806 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1579 | MainLoss:0.1579 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:94.9190 | AUROC:0.9987\n",
      "Test | 32/32 | Loss:1.0469 | MainLoss:1.0469 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:37.2564 | AUROC:0.3751\n",
      "\n",
      "Epoch: [110 | 1000] LR: 0.003906\n",
      "Train | 32/32 | Loss:0.3295 | MainLoss:0.3295 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:85.3161 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1480 | MainLoss:0.1480 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:95.4299 | AUROC:0.9988\n",
      "Test | 32/32 | Loss:1.0613 | MainLoss:1.0613 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:36.9103 | AUROC:0.3739\n",
      "\n",
      "Epoch: [111 | 1000] LR: 0.003904\n",
      "Train | 32/32 | Loss:0.3273 | MainLoss:0.3273 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:84.9419 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1434 | MainLoss:0.1434 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:95.5545 | AUROC:0.9987\n",
      "Test | 32/32 | Loss:1.0647 | MainLoss:1.0647 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:37.0513 | AUROC:0.3792\n",
      "\n",
      "Epoch: [112 | 1000] LR: 0.003902\n",
      "Train | 32/32 | Loss:0.3225 | MainLoss:0.3225 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:85.2645 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1532 | MainLoss:0.1532 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:94.9221 | AUROC:0.9988\n",
      "Test | 32/32 | Loss:1.0551 | MainLoss:1.0551 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:38.4615 | AUROC:0.3942\n",
      "\n",
      "Epoch: [113 | 1000] LR: 0.003900\n",
      "Train | 32/32 | Loss:0.3263 | MainLoss:0.3263 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:85.0064 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1484 | MainLoss:0.1484 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:95.2960 | AUROC:0.9987\n",
      "Test | 32/32 | Loss:1.0587 | MainLoss:1.0587 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:37.5769 | AUROC:0.3841\n",
      "\n",
      "Epoch: [114 | 1000] LR: 0.003898\n",
      "Train | 32/32 | Loss:0.3271 | MainLoss:0.3271 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:85.1871 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1549 | MainLoss:0.1549 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:94.8661 | AUROC:0.9986\n",
      "Test | 32/32 | Loss:1.0511 | MainLoss:1.0511 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:37.3462 | AUROC:0.3798\n",
      "\n",
      "Epoch: [115 | 1000] LR: 0.003896\n",
      "Train | 32/32 | Loss:0.3303 | MainLoss:0.3303 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:85.0839 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1495 | MainLoss:0.1495 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:95.2960 | AUROC:0.9987\n",
      "Test | 32/32 | Loss:1.0307 | MainLoss:1.0307 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:38.0769 | AUROC:0.3953\n",
      "\n",
      "Epoch: [116 | 1000] LR: 0.003894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 32/32 | Loss:0.3278 | MainLoss:0.3278 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:85.0194 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1488 | MainLoss:0.1488 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:95.2430 | AUROC:0.9987\n",
      "Test | 32/32 | Loss:1.0302 | MainLoss:1.0302 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:38.6154 | AUROC:0.4008\n",
      "\n",
      "Epoch: [117 | 1000] LR: 0.003892\n",
      "Train | 32/32 | Loss:0.3241 | MainLoss:0.3241 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:85.1355 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1628 | MainLoss:0.1628 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:94.3427 | AUROC:0.9986\n",
      "Test | 32/32 | Loss:1.0292 | MainLoss:1.0292 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:39.3077 | AUROC:0.4078\n",
      "\n",
      "Epoch: [118 | 1000] LR: 0.003890\n",
      "Train | 32/32 | Loss:0.3304 | MainLoss:0.3304 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:85.1613 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1624 | MainLoss:0.1624 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:94.4704 | AUROC:0.9986\n",
      "Test | 32/32 | Loss:1.0186 | MainLoss:1.0186 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:39.3590 | AUROC:0.4064\n",
      "\n",
      "Epoch: [119 | 1000] LR: 0.003888\n",
      "Train | 32/32 | Loss:0.3250 | MainLoss:0.3250 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:85.3290 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1463 | MainLoss:0.1463 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:95.3738 | AUROC:0.9988\n",
      "Test | 32/32 | Loss:1.0691 | MainLoss:1.0691 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:37.3333 | AUROC:0.3797\n",
      "\n",
      "Epoch: [120 | 1000] LR: 0.003886\n",
      "Train | 32/32 | Loss:0.3241 | MainLoss:0.3241 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:85.1871 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1419 | MainLoss:0.1419 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:95.6012 | AUROC:0.9989\n",
      "Test | 32/32 | Loss:1.0820 | MainLoss:1.0820 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:36.5385 | AUROC:0.3707\n",
      "\n",
      "Epoch: [121 | 1000] LR: 0.003884\n",
      "Train | 32/32 | Loss:0.3245 | MainLoss:0.3245 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:85.3161 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1577 | MainLoss:0.1577 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:94.6044 | AUROC:0.9987\n",
      "Test | 32/32 | Loss:1.0387 | MainLoss:1.0387 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:39.0897 | AUROC:0.4022\n",
      "\n",
      "Epoch: [122 | 1000] LR: 0.003882\n",
      "Train | 32/32 | Loss:0.3266 | MainLoss:0.3266 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:85.4323 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1392 | MainLoss:0.1392 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:95.7913 | AUROC:0.9989\n",
      "Test | 32/32 | Loss:1.0899 | MainLoss:1.0899 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:36.2564 | AUROC:0.3673\n",
      "\n",
      "Epoch: [123 | 1000] LR: 0.003880\n",
      "Train | 32/32 | Loss:0.3283 | MainLoss:0.3283 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:85.2516 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1523 | MainLoss:0.1523 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:95.0997 | AUROC:0.9987\n",
      "Test | 32/32 | Loss:1.0776 | MainLoss:1.0776 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:36.0769 | AUROC:0.3607\n",
      "\n",
      "Epoch: [124 | 1000] LR: 0.003877\n",
      "Train | 32/32 | Loss:0.3286 | MainLoss:0.3286 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:85.1742 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1584 | MainLoss:0.1584 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:94.6293 | AUROC:0.9987\n",
      "Test | 32/32 | Loss:1.0658 | MainLoss:1.0658 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:37.6410 | AUROC:0.3810\n",
      "\n",
      "Epoch: [125 | 1000] LR: 0.003875\n",
      "Train | 32/32 | Loss:0.3239 | MainLoss:0.3239 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:85.8581 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1520 | MainLoss:0.1520 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:94.9626 | AUROC:0.9986\n",
      "Test | 32/32 | Loss:1.0682 | MainLoss:1.0682 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:37.0256 | AUROC:0.3773\n",
      "\n",
      "Epoch: [126 | 1000] LR: 0.003873\n",
      "Train | 32/32 | Loss:0.3250 | MainLoss:0.3250 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:85.2387 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1507 | MainLoss:0.1507 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:95.0187 | AUROC:0.9986\n",
      "Test | 32/32 | Loss:1.0663 | MainLoss:1.0663 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:36.9872 | AUROC:0.3761\n",
      "\n",
      "Epoch: [127 | 1000] LR: 0.003871\n",
      "Train | 32/32 | Loss:0.3218 | MainLoss:0.3218 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:85.1355 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1439 | MainLoss:0.1439 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:95.3583 | AUROC:0.9986\n",
      "Test | 32/32 | Loss:1.0787 | MainLoss:1.0787 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:36.9615 | AUROC:0.3757\n",
      "\n",
      "Epoch: [128 | 1000] LR: 0.003869\n",
      "Train | 32/32 | Loss:0.3203 | MainLoss:0.3203 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:85.5871 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1634 | MainLoss:0.1634 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:94.2337 | AUROC:0.9986\n",
      "Test | 32/32 | Loss:1.0625 | MainLoss:1.0625 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:38.3077 | AUROC:0.3881\n",
      "\n",
      "Epoch: [129 | 1000] LR: 0.003866\n",
      "Train | 32/32 | Loss:0.3247 | MainLoss:0.3247 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:85.2903 | AUROC:0.0000\n",
      "Test | 129/32 | Loss:0.1298 | MainLoss:0.1298 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.0779 | AUROC:0.9985\n",
      "Test | 32/32 | Loss:1.1385 | MainLoss:1.1385 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:35.1154 | AUROC:0.3512\n",
      "\n",
      "Epoch: [130 | 1000] LR: 0.003864\n",
      "Train | 32/32 | Loss:0.3213 | MainLoss:0.3213 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:85.5613 | AUROC:0.0000\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(start_epoch, epochs):\n",
    "    state['lr'] = optimizer.state_dict()['param_groups'][0]['lr']\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "    print('\\nEpoch: [%d | %d] LR: %f' % (epoch + 1, epochs, state['lr']))\n",
    "    \n",
    "    train_loss, train_acc, train_auroc = train(train_loader, student_model, criterion, optimizer, epoch, use_cuda)\n",
    "    test_loss, test_acc, test_auroc = test(val_target_loader, student_model, criterion, epoch, use_cuda)\n",
    "    source_loss, source_acc, source_auroc = test(val_source_loader, student_model, criterion, epoch, use_cuda)\n",
    "\n",
    "\n",
    "    logger.append([state['lr'], train_loss, test_loss,  source_loss, train_acc, test_acc,source_acc, train_auroc, test_auroc, source_auroc])\n",
    "    is_best = test_acc > best_acc\n",
    "    best_acc = max(test_acc, best_acc)\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'state_dict' : student_model.state_dict(),\n",
    "        'acc': test_acc,\n",
    "        'best_acc': best_acc,\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    }, is_best, checkpoint=checkpoint)\n",
    "    scheduler_warmup.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
