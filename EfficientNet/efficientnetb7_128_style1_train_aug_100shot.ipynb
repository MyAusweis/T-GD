{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import collections\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "\n",
    "from model_pytorch import EfficientNet\n",
    "from utils import Bar,Logger, AverageMeter, accuracy, mkdir_p, savefig\n",
    "from warmup_scheduler import GradualWarmupScheduler\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "import cv2\n",
    "\n",
    "from PIL import ImageFile, ImageOps\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU device 3: True\n"
     ]
    }
   ],
   "source": [
    "# GPU Device\n",
    "gpu_id = 3\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(\"GPU device %d:\" %(gpu_id), use_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/media/data2/dataset/GAN_ImageData/StyleGAN_256/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained = ''\n",
    "resume = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model_name = 'efficientnet-b7' # b0-b7 scale\n",
    "\n",
    "# Optimization\n",
    "num_classes = 2\n",
    "epochs = 400\n",
    "start_epoch = 0\n",
    "train_batch = 4\n",
    "test_batch = 256\n",
    "lr = 0.04\n",
    "schedule = [75, 150, 225]\n",
    "momentum = 0.9\n",
    "gamma = 0.1 # LR is multiplied by gamma on schedule\n",
    "\n",
    "# CheckPoint\n",
    "checkpoint = './log/style1/128/b7/100shot' # dir\n",
    "if not os.path.isdir(checkpoint):\n",
    "    os.makedirs(checkpoint)\n",
    "num_workers = 8\n",
    "\n",
    "# Image\n",
    "ex_size = (140, 140)\n",
    "size = (128, 128)\n",
    "\n",
    "# Seed\n",
    "manual_seed = 7\n",
    "random.seed(manual_seed)\n",
    "torch.cuda.manual_seed_all(manual_seed)\n",
    "\n",
    "# cutmix\n",
    "cm_prob = 0.01\n",
    "cm_prob_init = 0.99\n",
    "cm_prob_low = 0.01\n",
    "cm_beta = 1.0\n",
    "\n",
    "# augmentation\n",
    "blur_prob = 0.5\n",
    "blog_sig = 0.5\n",
    "jpg_prob = 0.5\n",
    "\n",
    "best_acc = 0\n",
    "best_acc = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {}\n",
    "state['num_classes'] = num_classes\n",
    "state['epochs'] = epochs\n",
    "state['start_epoch'] = start_epoch\n",
    "state['train_batch'] = train_batch\n",
    "state['test_batch'] = test_batch\n",
    "state['lr'] = lr\n",
    "state['schedule'] = schedule\n",
    "state['momentum'] = momentum\n",
    "state['gamma'] = gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_augment(img):\n",
    "    img = np.array(img)\n",
    "\n",
    "    if random.random() < blur_prob:\n",
    "        sig = np.random.uniform(0.0, 3.0)\n",
    "        gaussian_blur(img, sig)\n",
    "\n",
    "    if random.random() < jpg_prob:\n",
    "        qual = np.random.uniform(30.0, 100.0)\n",
    "        img = cv2_jpg(img, qual)\n",
    "\n",
    "    return Image.fromarray(img)\n",
    "\n",
    "\n",
    "def gaussian_blur(img, sigma):\n",
    "    gaussian_filter(img[:,:,0], output=img[:,:,0], sigma=sigma)\n",
    "    gaussian_filter(img[:,:,1], output=img[:,:,1], sigma=sigma)\n",
    "    gaussian_filter(img[:,:,2], output=img[:,:,2], sigma=sigma)\n",
    "\n",
    "\n",
    "def cv2_jpg(img, compress_val):\n",
    "    img_cv2 = img[:,:,::-1]\n",
    "    encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), compress_val]\n",
    "    result, encimg = cv2.imencode('.jpg', img_cv2, encode_param)\n",
    "    decimg = cv2.imdecode(encimg, 1)\n",
    "    return decimg[:,:,::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_bbox(size, lam):\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = np.int(W * cut_rat)\n",
    "    cut_h = np.int(H * cut_rat)\n",
    "\n",
    "    # uniform\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join(data_dir, '100_shot')\n",
    "val_dir = os.path.join(data_dir, 'validation')    \n",
    "train_aug = transforms.Compose([\n",
    "    transforms.Lambda(lambda img: data_augment(img)),\n",
    "    transforms.Resize(ex_size),\n",
    "    transforms.RandomCrop(size),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "#     transforms.RandomErasing(p=0.3, scale=(0.02, 0.10), ratio=(0.3, 3.3), value=0, inplace=True),\n",
    "])\n",
    "\n",
    "val_aug = transforms.Compose([\n",
    "    transforms.Resize(ex_size),\n",
    "    transforms.CenterCrop(size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# pin_memory : cuda pin memeory use\n",
    "train_loader = DataLoader(datasets.ImageFolder(train_dir, transform=train_aug),\n",
    "                          batch_size=train_batch, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "val_loader = DataLoader(datasets.ImageFolder(val_dir, val_aug),\n",
    "                       batch_size=test_batch, shuffle=True, num_workers=num_workers, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EfficientNet.from_name(model_name, num_classes=num_classes)\n",
    "#                               override_params={'dropout_rate':0.2, 'drop_connect_rate':0.2})\n",
    "\n",
    "# Pre-trained\n",
    "if pretrained:\n",
    "    print(\"=> using pre-trained model '{}'\".format(pretrained))\n",
    "    model.load_state_dict(torch.load(pretrained)['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.named_parameters of EfficientNet(\n",
       "  (_conv_stem): Conv2dStaticSamePadding(\n",
       "    3, 64, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
       "    (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "  )\n",
       "  (_gn0): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "  (_blocks): ModuleList(\n",
       "    (0): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        64, 64, kernel_size=(3, 3), stride=[1, 1], groups=64, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        64, 16, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        16, 64, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (1): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        32, 32, kernel_size=(3, 3), stride=(1, 1), groups=32, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        32, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        8, 32, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (2): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        32, 32, kernel_size=(3, 3), stride=(1, 1), groups=32, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        32, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        8, 32, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (3): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        32, 32, kernel_size=(3, 3), stride=(1, 1), groups=32, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        32, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        8, 32, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (4): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 192, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        192, 192, kernel_size=(3, 3), stride=[2, 2], groups=192, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 192, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 48, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (5): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 288, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        288, 288, kernel_size=(3, 3), stride=(1, 1), groups=288, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 288, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        288, 12, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        12, 288, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 48, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (6): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 288, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        288, 288, kernel_size=(3, 3), stride=(1, 1), groups=288, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 288, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        288, 12, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        12, 288, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 48, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (7): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 288, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        288, 288, kernel_size=(3, 3), stride=(1, 1), groups=288, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 288, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        288, 12, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        12, 288, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 48, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (8): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 288, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        288, 288, kernel_size=(3, 3), stride=(1, 1), groups=288, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 288, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        288, 12, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        12, 288, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 48, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (9): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 288, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        288, 288, kernel_size=(3, 3), stride=(1, 1), groups=288, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 288, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        288, 12, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        12, 288, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 48, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (10): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 288, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        288, 288, kernel_size=(3, 3), stride=(1, 1), groups=288, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 288, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        288, 12, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        12, 288, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 48, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (11): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 288, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        288, 288, kernel_size=(5, 5), stride=[2, 2], groups=288, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 288, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        288, 12, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        12, 288, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        288, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 80, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (12): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 480, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        480, 480, kernel_size=(5, 5), stride=(1, 1), groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 480, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 80, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (13): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 480, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        480, 480, kernel_size=(5, 5), stride=(1, 1), groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 480, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 80, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (14): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 480, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        480, 480, kernel_size=(5, 5), stride=(1, 1), groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 480, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 80, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (15): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 480, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        480, 480, kernel_size=(5, 5), stride=(1, 1), groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 480, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 80, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (16): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 480, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        480, 480, kernel_size=(5, 5), stride=(1, 1), groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 480, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 80, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (17): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 480, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        480, 480, kernel_size=(5, 5), stride=(1, 1), groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 480, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 80, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (18): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 480, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        480, 480, kernel_size=(3, 3), stride=[2, 2], groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 480, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        480, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 160, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (19): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 960, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        960, 960, kernel_size=(3, 3), stride=(1, 1), groups=960, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 960, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 160, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (20): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 960, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        960, 960, kernel_size=(3, 3), stride=(1, 1), groups=960, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 960, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 160, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (21): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 960, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        960, 960, kernel_size=(3, 3), stride=(1, 1), groups=960, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 960, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 160, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (22): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 960, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        960, 960, kernel_size=(3, 3), stride=(1, 1), groups=960, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 960, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 160, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (23): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 960, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        960, 960, kernel_size=(3, 3), stride=(1, 1), groups=960, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 960, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 160, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (24): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 960, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        960, 960, kernel_size=(3, 3), stride=(1, 1), groups=960, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 960, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 160, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (25): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 960, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        960, 960, kernel_size=(3, 3), stride=(1, 1), groups=960, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 960, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 160, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (26): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 960, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        960, 960, kernel_size=(3, 3), stride=(1, 1), groups=960, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 960, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 160, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (27): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 960, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        960, 960, kernel_size=(3, 3), stride=(1, 1), groups=960, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 960, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 160, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (28): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 960, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        960, 960, kernel_size=(5, 5), stride=[1, 1], groups=960, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 960, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        960, 224, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 224, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (29): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 1344, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1344, 1344, kernel_size=(5, 5), stride=(1, 1), groups=1344, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 1344, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1344, 56, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        56, 1344, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 224, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (30): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 1344, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1344, 1344, kernel_size=(5, 5), stride=(1, 1), groups=1344, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 1344, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1344, 56, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        56, 1344, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 224, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (31): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 1344, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1344, 1344, kernel_size=(5, 5), stride=(1, 1), groups=1344, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 1344, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1344, 56, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        56, 1344, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 224, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (32): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 1344, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1344, 1344, kernel_size=(5, 5), stride=(1, 1), groups=1344, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 1344, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1344, 56, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        56, 1344, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 224, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (33): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 1344, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1344, 1344, kernel_size=(5, 5), stride=(1, 1), groups=1344, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 1344, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1344, 56, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        56, 1344, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 224, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (34): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 1344, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1344, 1344, kernel_size=(5, 5), stride=(1, 1), groups=1344, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 1344, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1344, 56, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        56, 1344, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 224, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (35): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 1344, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1344, 1344, kernel_size=(5, 5), stride=(1, 1), groups=1344, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 1344, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1344, 56, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        56, 1344, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 224, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (36): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 1344, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1344, 1344, kernel_size=(5, 5), stride=(1, 1), groups=1344, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 1344, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1344, 56, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        56, 1344, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 224, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (37): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 1344, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1344, 1344, kernel_size=(5, 5), stride=(1, 1), groups=1344, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 1344, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1344, 56, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        56, 1344, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 224, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (38): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 1344, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1344, 1344, kernel_size=(5, 5), stride=[2, 2], groups=1344, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 1344, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1344, 56, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        56, 1344, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1344, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 384, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (39): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 2304, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        2304, 2304, kernel_size=(5, 5), stride=(1, 1), groups=2304, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 2304, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        2304, 96, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        96, 2304, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 384, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (40): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 2304, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        2304, 2304, kernel_size=(5, 5), stride=(1, 1), groups=2304, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 2304, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        2304, 96, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        96, 2304, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 384, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (41): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 2304, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        2304, 2304, kernel_size=(5, 5), stride=(1, 1), groups=2304, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 2304, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        2304, 96, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        96, 2304, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 384, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (42): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 2304, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        2304, 2304, kernel_size=(5, 5), stride=(1, 1), groups=2304, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 2304, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        2304, 96, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        96, 2304, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 384, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (43): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 2304, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        2304, 2304, kernel_size=(5, 5), stride=(1, 1), groups=2304, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 2304, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        2304, 96, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        96, 2304, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 384, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (44): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 2304, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        2304, 2304, kernel_size=(5, 5), stride=(1, 1), groups=2304, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 2304, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        2304, 96, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        96, 2304, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 384, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (45): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 2304, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        2304, 2304, kernel_size=(5, 5), stride=(1, 1), groups=2304, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 2304, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        2304, 96, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        96, 2304, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 384, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (46): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 2304, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        2304, 2304, kernel_size=(5, 5), stride=(1, 1), groups=2304, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 2304, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        2304, 96, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        96, 2304, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 384, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (47): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 2304, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        2304, 2304, kernel_size=(5, 5), stride=(1, 1), groups=2304, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 2304, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        2304, 96, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        96, 2304, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 384, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (48): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 2304, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        2304, 2304, kernel_size=(5, 5), stride=(1, 1), groups=2304, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 2304, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        2304, 96, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        96, 2304, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 384, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (49): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 2304, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        2304, 2304, kernel_size=(5, 5), stride=(1, 1), groups=2304, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 2304, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        2304, 96, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        96, 2304, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 384, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (50): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 2304, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        2304, 2304, kernel_size=(5, 5), stride=(1, 1), groups=2304, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 2304, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        2304, 96, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        96, 2304, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 384, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (51): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 2304, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        2304, 2304, kernel_size=(3, 3), stride=[1, 1], groups=2304, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 2304, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        2304, 96, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        96, 2304, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        2304, 640, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 640, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (52): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 3840, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        3840, 3840, kernel_size=(3, 3), stride=(1, 1), groups=3840, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 3840, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        3840, 160, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        160, 3840, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 640, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (53): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 3840, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        3840, 3840, kernel_size=(3, 3), stride=(1, 1), groups=3840, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 3840, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        3840, 160, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        160, 3840, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 640, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (54): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 3840, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        3840, 3840, kernel_size=(3, 3), stride=(1, 1), groups=3840, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 3840, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        3840, 160, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        160, 3840, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 640, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "  )\n",
       "  (_conv_head): Conv2dStaticSamePadding(\n",
       "    640, 2560, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "    (static_padding): Identity()\n",
       "  )\n",
       "  (_gn1): GroupNorm(8, 2560, eps=1e-05, affine=True)\n",
       "  (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n",
       "  (_dropout): Dropout(p=0.5, inplace=False)\n",
       "  (_fc): Linear(in_features=2560, out_features=2, bias=True)\n",
       "  (_swish): MemoryEfficientSwish()\n",
       ")>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.named_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Total params: 63.79M\n"
     ]
    }
   ],
   "source": [
    "model.to('cuda')\n",
    "cudnn.benchmark = True\n",
    "print('    Total params: %.2fM' % (sum(p.numel() for p in model.parameters())/1000000.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=1e-4)\n",
    "# optimizer = optim.Adam(model.parameters(), weight_decay=1e-4)\n",
    "scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)\n",
    "scheduler_warmup = GradualWarmupScheduler(optimizer, multiplier=8, total_epoch=10, after_scheduler=scheduler_cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resume\n",
    "if resume:\n",
    "    print('==> Resuming from checkpoint..')\n",
    "    checkpoint = os.path.dirname(resume)\n",
    "#     checkpoint = torch.load(resume)\n",
    "    resume = torch.load(resume)\n",
    "    best_acc = resume['best_acc']\n",
    "    start_epoch = resume['epoch']\n",
    "    model.load_state_dict(resume['state_dict'])\n",
    "    optimizer.load_state_dict(resume['optimizer'])\n",
    "    logger = Logger(os.path.join(checkpoint, 'log.txt'), resume=True)\n",
    "else:\n",
    "    logger = Logger(os.path.join(checkpoint, 'log.txt'))\n",
    "    logger.set_names(['Learning Rate', 'Train Loss', 'Valid Loss', 'Train Acc.', 'Valid Acc.', 'Train AUROC.', 'Valid AUROC.'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch, use_cuda):\n",
    "    model.train()\n",
    "    \n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    arc = AverageMeter()\n",
    "    end = time.time()\n",
    "    \n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        batch_size = inputs.size(0)\n",
    "        if batch_size < train_batch:\n",
    "            continue\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            \n",
    "        r = np.random.rand(1)\n",
    "        if cm_beta > 0 and r < cm_prob:\n",
    "            \n",
    "            rand_index = torch.randperm(inputs.size()[0]).cuda()\n",
    "            tt= targets[rand_index]\n",
    "            boolean = targets==tt\n",
    "            rand_index = rand_index[boolean]\n",
    "            lam = np.random.beta(cm_beta, cm_beta)\n",
    "            bbx1, bby1, bbx2, bby2 = rand_bbox(inputs.size(), lam)\n",
    "            inputs[boolean, :, bbx1:bbx2, bby1:bby2] = inputs[rand_index, :, bbx1:bbx2, bby1:bby2]\n",
    "\n",
    "        # compute output\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1 = accuracy(outputs.data, targets.data)\n",
    "#         auroc = roc_auc_score(targets.cpu().detach().numpy(), outputs.cpu().detach().numpy()[:,1])\n",
    "        losses.update(loss.data.tolist(), inputs.size(0))\n",
    "        top1.update(prec1[0], inputs.size(0))\n",
    "#         arc.update(auroc, inputs.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        \n",
    "#         if batch_idx % 100 == 0:\n",
    "#             print('{batch}/{size} | Loss:{loss:.4f} | top1:{tp1:.4f} | AUROC:{ac:.4f}'.format(\n",
    "#                      batch=batch_idx+1, size=len(train_loader), loss=losses.avg, tp1=top1.avg, ac=arc.avg))\n",
    "    print('{batch}/{size} | Loss:{loss:.4f} | top1:{tp1:.4f} | AUROC:{ac:.4f}'.format(\n",
    "                     batch=batch_idx+1, size=len(train_loader), loss=losses.avg, tp1=top1.avg, ac=arc.avg))\n",
    "    return (losses.avg, top1.avg, arc.avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(val_loader, model, criterion, epoch, use_cuda):\n",
    "    global best_acc\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    arc = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(val_loader):\n",
    "            # measure data loading time\n",
    "            data_time.update(time.time() - end)\n",
    "\n",
    "            if use_cuda:\n",
    "                inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "            # compute output\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            prec1 = accuracy(outputs.data, targets.data)\n",
    "            auroc = roc_auc_score(targets.cpu().detach().numpy(), outputs.cpu().detach().numpy()[:,1])\n",
    "            losses.update(loss.data.tolist(), inputs.size(0))\n",
    "            top1.update(prec1[0], inputs.size(0))\n",
    "            arc.update(auroc, inputs.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "    print('{batch}/{size} | Loss:{loss:.4f} | top1:{tp1:.4f} | AUROC:{ac:.4f}'.format(\n",
    "         batch=batch_idx+1, size=len(val_loader), loss=losses.avg, tp1=top1.avg, ac=arc.avg))\n",
    "    return (losses.avg, top1.avg, arc.avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, checkpoint='checkpoint', filename='checkpoint.pth.tar'):\n",
    "    filepath = os.path.join(checkpoint, filename)\n",
    "    torch.save(state, filepath)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filepath, os.path.join(checkpoint, 'model_best.pth.tar'))\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    global state\n",
    "    lr_set = [1, 1e-1, 1e-2, 1e-3, 1e-4, 1e-5]\n",
    "    lr_list = schedule.copy()\n",
    "    lr_list.append(epoch)\n",
    "    lr_list.sort()\n",
    "    idx = lr_list.index(epoch)\n",
    "    state['lr'] *= lr_set[idx]\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = state['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [1 | 400] LR: 0.040000\n",
      "50/50 | Loss:10.1488 | top1:52.0000 | AUROC:0.0000\n",
      "31/31 | Loss:18.2650 | top1:50.0000 | AUROC:0.5150\n",
      "\n",
      "Epoch: [2 | 400] LR: 0.068000\n",
      "50/50 | Loss:17.6463 | top1:52.0000 | AUROC:0.0000\n",
      "31/31 | Loss:10.0804 | top1:50.0000 | AUROC:0.5104\n",
      "\n",
      "Epoch: [3 | 400] LR: 0.096000\n",
      "50/50 | Loss:11.3045 | top1:49.5000 | AUROC:0.0000\n",
      "31/31 | Loss:6.2548 | top1:50.0000 | AUROC:0.4716\n",
      "\n",
      "Epoch: [4 | 400] LR: 0.124000\n",
      "50/50 | Loss:7.0780 | top1:43.5000 | AUROC:0.0000\n",
      "31/31 | Loss:5.3753 | top1:50.0000 | AUROC:0.4587\n",
      "\n",
      "Epoch: [5 | 400] LR: 0.152000\n",
      "50/50 | Loss:7.8161 | top1:45.5000 | AUROC:0.0000\n",
      "31/31 | Loss:6.0753 | top1:50.0000 | AUROC:0.5085\n",
      "\n",
      "Epoch: [6 | 400] LR: 0.180000\n",
      "50/50 | Loss:10.4310 | top1:49.5000 | AUROC:0.0000\n",
      "31/31 | Loss:7.1525 | top1:50.0000 | AUROC:0.5183\n",
      "\n",
      "Epoch: [7 | 400] LR: 0.208000\n",
      "50/50 | Loss:21.4719 | top1:50.0000 | AUROC:0.0000\n",
      "31/31 | Loss:2.3592 | top1:50.0000 | AUROC:0.4746\n",
      "\n",
      "Epoch: [8 | 400] LR: 0.236000\n",
      "50/50 | Loss:31.9497 | top1:51.5000 | AUROC:0.0000\n",
      "31/31 | Loss:20.0303 | top1:50.0000 | AUROC:0.5245\n",
      "\n",
      "Epoch: [9 | 400] LR: 0.264000\n",
      "50/50 | Loss:42.1574 | top1:54.5000 | AUROC:0.0000\n",
      "31/31 | Loss:54.1221 | top1:50.0000 | AUROC:0.4827\n",
      "\n",
      "Epoch: [10 | 400] LR: 0.292000\n",
      "50/50 | Loss:51.8632 | top1:57.5000 | AUROC:0.0000\n",
      "31/31 | Loss:117.3462 | top1:50.0000 | AUROC:0.4956\n",
      "\n",
      "Epoch: [11 | 400] LR: 0.320000\n",
      "50/50 | Loss:82.3567 | top1:50.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.8330 | top1:50.1410 | AUROC:0.4879\n",
      "\n",
      "Epoch: [12 | 400] LR: 0.320000\n",
      "50/50 | Loss:87.2076 | top1:47.0000 | AUROC:0.0000\n",
      "31/31 | Loss:12.6737 | top1:50.0513 | AUROC:0.5373\n",
      "\n",
      "Epoch: [13 | 400] LR: 0.319995\n",
      "50/50 | Loss:66.2995 | top1:49.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.8411 | top1:49.9744 | AUROC:0.4647\n",
      "\n",
      "Epoch: [14 | 400] LR: 0.319980\n",
      "50/50 | Loss:33.2652 | top1:51.5000 | AUROC:0.0000\n",
      "31/31 | Loss:39.5278 | top1:50.0000 | AUROC:0.5318\n",
      "\n",
      "Epoch: [15 | 400] LR: 0.319956\n",
      "50/50 | Loss:34.0419 | top1:44.0000 | AUROC:0.0000\n",
      "31/31 | Loss:5.8684 | top1:50.0000 | AUROC:0.5353\n",
      "\n",
      "Epoch: [16 | 400] LR: 0.319921\n",
      "50/50 | Loss:17.0295 | top1:52.5000 | AUROC:0.0000\n",
      "31/31 | Loss:13.0887 | top1:50.0000 | AUROC:0.4905\n",
      "\n",
      "Epoch: [17 | 400] LR: 0.319877\n",
      "50/50 | Loss:9.8461 | top1:49.5000 | AUROC:0.0000\n",
      "31/31 | Loss:2.6525 | top1:50.0000 | AUROC:0.4697\n",
      "\n",
      "Epoch: [18 | 400] LR: 0.319822\n",
      "50/50 | Loss:5.5182 | top1:50.0000 | AUROC:0.0000\n",
      "31/31 | Loss:1.3862 | top1:50.0000 | AUROC:0.5319\n",
      "\n",
      "Epoch: [19 | 400] LR: 0.319758\n",
      "50/50 | Loss:3.9453 | top1:40.5000 | AUROC:0.0000\n",
      "31/31 | Loss:3.7124 | top1:50.0000 | AUROC:0.5184\n",
      "\n",
      "Epoch: [20 | 400] LR: 0.319684\n",
      "50/50 | Loss:3.2289 | top1:52.0000 | AUROC:0.0000\n",
      "31/31 | Loss:2.1260 | top1:50.0000 | AUROC:0.4670\n",
      "\n",
      "Epoch: [21 | 400] LR: 0.319600\n",
      "50/50 | Loss:3.1949 | top1:45.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.8395 | top1:50.0000 | AUROC:0.5185\n",
      "\n",
      "Epoch: [22 | 400] LR: 0.319507\n",
      "50/50 | Loss:2.3838 | top1:49.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.7171 | top1:50.0000 | AUROC:0.5175\n",
      "\n",
      "Epoch: [23 | 400] LR: 0.319403\n",
      "50/50 | Loss:1.8559 | top1:49.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.7391 | top1:50.0000 | AUROC:0.4769\n",
      "\n",
      "Epoch: [24 | 400] LR: 0.319290\n",
      "50/50 | Loss:2.0332 | top1:54.5000 | AUROC:0.0000\n",
      "31/31 | Loss:1.8925 | top1:50.0000 | AUROC:0.4792\n",
      "\n",
      "Epoch: [25 | 400] LR: 0.319167\n",
      "50/50 | Loss:1.7232 | top1:48.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.9281 | top1:50.0000 | AUROC:0.5254\n",
      "\n",
      "Epoch: [26 | 400] LR: 0.319034\n",
      "50/50 | Loss:1.2393 | top1:46.0000 | AUROC:0.0000\n",
      "31/31 | Loss:2.0845 | top1:50.0000 | AUROC:0.5230\n",
      "\n",
      "Epoch: [27 | 400] LR: 0.318891\n",
      "50/50 | Loss:1.5475 | top1:52.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.7145 | top1:50.0000 | AUROC:0.5241\n",
      "\n",
      "Epoch: [28 | 400] LR: 0.318738\n",
      "50/50 | Loss:1.4198 | top1:54.0000 | AUROC:0.0000\n",
      "31/31 | Loss:2.0321 | top1:50.0000 | AUROC:0.5174\n",
      "\n",
      "Epoch: [29 | 400] LR: 0.318576\n",
      "50/50 | Loss:1.5152 | top1:53.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.7979 | top1:50.0000 | AUROC:0.4820\n",
      "\n",
      "Epoch: [30 | 400] LR: 0.318404\n",
      "50/50 | Loss:1.2771 | top1:40.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.8417 | top1:50.0000 | AUROC:0.5224\n",
      "\n",
      "Epoch: [31 | 400] LR: 0.318222\n",
      "50/50 | Loss:1.2537 | top1:55.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.8524 | top1:50.0000 | AUROC:0.5204\n",
      "\n",
      "Epoch: [32 | 400] LR: 0.318030\n",
      "50/50 | Loss:1.4113 | top1:45.0000 | AUROC:0.0000\n",
      "31/31 | Loss:1.7769 | top1:50.0000 | AUROC:0.4715\n",
      "\n",
      "Epoch: [33 | 400] LR: 0.317829\n",
      "50/50 | Loss:1.9724 | top1:50.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.8773 | top1:50.0000 | AUROC:0.5249\n",
      "\n",
      "Epoch: [34 | 400] LR: 0.317617\n",
      "50/50 | Loss:1.1899 | top1:50.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.7013 | top1:50.0000 | AUROC:0.4775\n",
      "\n",
      "Epoch: [35 | 400] LR: 0.317397\n",
      "50/50 | Loss:1.3028 | top1:45.5000 | AUROC:0.0000\n",
      "31/31 | Loss:1.7932 | top1:50.0000 | AUROC:0.4754\n",
      "\n",
      "Epoch: [36 | 400] LR: 0.317166\n",
      "50/50 | Loss:1.6240 | top1:49.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.8353 | top1:50.0000 | AUROC:0.5221\n",
      "\n",
      "Epoch: [37 | 400] LR: 0.316926\n",
      "50/50 | Loss:1.0930 | top1:51.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6950 | top1:49.0897 | AUROC:0.4754\n",
      "\n",
      "Epoch: [38 | 400] LR: 0.316676\n",
      "50/50 | Loss:1.3046 | top1:38.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.7555 | top1:50.0000 | AUROC:0.4349\n",
      "\n",
      "Epoch: [39 | 400] LR: 0.316416\n",
      "50/50 | Loss:1.2589 | top1:51.5000 | AUROC:0.0000\n",
      "31/31 | Loss:1.8060 | top1:50.0000 | AUROC:0.5036\n",
      "\n",
      "Epoch: [40 | 400] LR: 0.316147\n",
      "50/50 | Loss:1.1697 | top1:42.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.8505 | top1:50.0000 | AUROC:0.5186\n",
      "\n",
      "Epoch: [41 | 400] LR: 0.315868\n",
      "50/50 | Loss:1.3672 | top1:44.5000 | AUROC:0.0000\n",
      "31/31 | Loss:1.0302 | top1:50.0000 | AUROC:0.4739\n",
      "\n",
      "Epoch: [42 | 400] LR: 0.315579\n",
      "50/50 | Loss:1.5574 | top1:46.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.7154 | top1:50.0000 | AUROC:0.5185\n",
      "\n",
      "Epoch: [43 | 400] LR: 0.315281\n",
      "50/50 | Loss:1.1799 | top1:48.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.7892 | top1:50.0000 | AUROC:0.5114\n",
      "\n",
      "Epoch: [44 | 400] LR: 0.314973\n",
      "50/50 | Loss:1.2074 | top1:46.5000 | AUROC:0.0000\n",
      "31/31 | Loss:1.5852 | top1:50.0000 | AUROC:0.4966\n",
      "\n",
      "Epoch: [45 | 400] LR: 0.314656\n",
      "50/50 | Loss:1.5387 | top1:49.0000 | AUROC:0.0000\n",
      "31/31 | Loss:1.2359 | top1:50.0000 | AUROC:0.4857\n",
      "\n",
      "Epoch: [46 | 400] LR: 0.314329\n",
      "50/50 | Loss:1.6249 | top1:49.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.7359 | top1:50.0000 | AUROC:0.4892\n",
      "\n",
      "Epoch: [47 | 400] LR: 0.313993\n",
      "50/50 | Loss:1.2483 | top1:47.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.7042 | top1:50.0000 | AUROC:0.4994\n",
      "\n",
      "Epoch: [48 | 400] LR: 0.313647\n",
      "50/50 | Loss:1.2107 | top1:49.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.7928 | top1:50.0000 | AUROC:0.4871\n",
      "\n",
      "Epoch: [49 | 400] LR: 0.313292\n",
      "50/50 | Loss:1.7237 | top1:50.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.7434 | top1:50.0000 | AUROC:0.5068\n",
      "\n",
      "Epoch: [50 | 400] LR: 0.312927\n",
      "50/50 | Loss:1.8301 | top1:53.0000 | AUROC:0.0000\n",
      "31/31 | Loss:1.5964 | top1:50.0000 | AUROC:0.4849\n",
      "\n",
      "Epoch: [51 | 400] LR: 0.312553\n",
      "50/50 | Loss:1.8154 | top1:51.5000 | AUROC:0.0000\n",
      "31/31 | Loss:2.0542 | top1:50.0000 | AUROC:0.5040\n",
      "\n",
      "Epoch: [52 | 400] LR: 0.312169\n",
      "50/50 | Loss:1.0709 | top1:52.0000 | AUROC:0.0000\n",
      "31/31 | Loss:1.5842 | top1:50.0000 | AUROC:0.5048\n",
      "\n",
      "Epoch: [53 | 400] LR: 0.311776\n",
      "50/50 | Loss:1.1316 | top1:46.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.7296 | top1:50.0000 | AUROC:0.4777\n",
      "\n",
      "Epoch: [54 | 400] LR: 0.311374\n",
      "50/50 | Loss:1.1165 | top1:49.5000 | AUROC:0.0000\n",
      "31/31 | Loss:1.1512 | top1:50.0000 | AUROC:0.4964\n",
      "\n",
      "Epoch: [55 | 400] LR: 0.310962\n",
      "50/50 | Loss:1.3886 | top1:44.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.8162 | top1:50.0000 | AUROC:0.4858\n",
      "\n",
      "Epoch: [56 | 400] LR: 0.310541\n",
      "50/50 | Loss:1.0991 | top1:56.0000 | AUROC:0.0000\n",
      "31/31 | Loss:2.8711 | top1:50.0000 | AUROC:0.5264\n",
      "\n",
      "Epoch: [57 | 400] LR: 0.310111\n",
      "50/50 | Loss:2.0044 | top1:49.5000 | AUROC:0.0000\n",
      "31/31 | Loss:2.0330 | top1:50.0000 | AUROC:0.5181\n",
      "\n",
      "Epoch: [58 | 400] LR: 0.309671\n",
      "50/50 | Loss:1.1675 | top1:49.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.7583 | top1:50.0000 | AUROC:0.5109\n",
      "\n",
      "Epoch: [59 | 400] LR: 0.309222\n",
      "50/50 | Loss:1.0322 | top1:49.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.8094 | top1:50.0000 | AUROC:0.4924\n",
      "\n",
      "Epoch: [60 | 400] LR: 0.308764\n",
      "50/50 | Loss:1.1938 | top1:48.5000 | AUROC:0.0000\n",
      "31/31 | Loss:1.8805 | top1:50.0000 | AUROC:0.4717\n",
      "\n",
      "Epoch: [61 | 400] LR: 0.308297\n",
      "50/50 | Loss:1.3360 | top1:49.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.8228 | top1:50.0000 | AUROC:0.4622\n",
      "\n",
      "Epoch: [62 | 400] LR: 0.307821\n",
      "50/50 | Loss:1.9679 | top1:57.0000 | AUROC:0.0000\n",
      "31/31 | Loss:1.6567 | top1:50.0000 | AUROC:0.5042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [63 | 400] LR: 0.307335\n",
      "50/50 | Loss:1.3437 | top1:51.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.8280 | top1:50.0000 | AUROC:0.5190\n",
      "\n",
      "Epoch: [64 | 400] LR: 0.306841\n",
      "50/50 | Loss:1.0495 | top1:50.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.9802 | top1:50.0000 | AUROC:0.5068\n",
      "\n",
      "Epoch: [65 | 400] LR: 0.306337\n",
      "50/50 | Loss:1.1566 | top1:51.0000 | AUROC:0.0000\n",
      "31/31 | Loss:1.1383 | top1:50.0000 | AUROC:0.4988\n",
      "\n",
      "Epoch: [66 | 400] LR: 0.305825\n",
      "50/50 | Loss:1.4619 | top1:44.0000 | AUROC:0.0000\n",
      "31/31 | Loss:1.1535 | top1:50.0000 | AUROC:0.5059\n",
      "\n",
      "Epoch: [67 | 400] LR: 0.305303\n",
      "50/50 | Loss:2.1896 | top1:48.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.8108 | top1:50.0000 | AUROC:0.4722\n",
      "\n",
      "Epoch: [68 | 400] LR: 0.304772\n",
      "50/50 | Loss:1.2716 | top1:51.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.9357 | top1:50.0000 | AUROC:0.4522\n",
      "\n",
      "Epoch: [69 | 400] LR: 0.304233\n",
      "50/50 | Loss:1.5071 | top1:44.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.7014 | top1:50.0000 | AUROC:0.5047\n",
      "\n",
      "Epoch: [70 | 400] LR: 0.303684\n",
      "50/50 | Loss:1.3790 | top1:55.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.8034 | top1:50.0000 | AUROC:0.5031\n",
      "\n",
      "Epoch: [71 | 400] LR: 0.303127\n",
      "50/50 | Loss:1.3238 | top1:50.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.8894 | top1:50.0000 | AUROC:0.5014\n",
      "\n",
      "Epoch: [72 | 400] LR: 0.302561\n",
      "50/50 | Loss:1.9614 | top1:49.5000 | AUROC:0.0000\n",
      "31/31 | Loss:1.6075 | top1:50.0000 | AUROC:0.4762\n",
      "\n",
      "Epoch: [73 | 400] LR: 0.301986\n",
      "50/50 | Loss:1.6147 | top1:54.0000 | AUROC:0.0000\n",
      "31/31 | Loss:2.6260 | top1:50.0000 | AUROC:0.4888\n",
      "\n",
      "Epoch: [74 | 400] LR: 0.301403\n",
      "50/50 | Loss:1.3909 | top1:53.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.7954 | top1:50.0000 | AUROC:0.4892\n",
      "\n",
      "Epoch: [75 | 400] LR: 0.300810\n",
      "50/50 | Loss:1.2047 | top1:52.5000 | AUROC:0.0000\n",
      "31/31 | Loss:1.0603 | top1:50.0000 | AUROC:0.4540\n",
      "\n",
      "Epoch: [76 | 400] LR: 0.300209\n",
      "50/50 | Loss:1.2193 | top1:54.5000 | AUROC:0.0000\n",
      "31/31 | Loss:1.3430 | top1:50.0000 | AUROC:0.4897\n",
      "\n",
      "Epoch: [77 | 400] LR: 0.029960\n",
      "50/50 | Loss:1.2246 | top1:50.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.7057 | top1:50.0000 | AUROC:0.4965\n",
      "\n",
      "Epoch: [78 | 400] LR: 0.029898\n",
      "50/50 | Loss:0.9704 | top1:49.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.8064 | top1:50.0000 | AUROC:0.5034\n",
      "\n",
      "Epoch: [79 | 400] LR: 0.029835\n",
      "50/50 | Loss:1.0683 | top1:43.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.7119 | top1:50.0000 | AUROC:0.5000\n",
      "\n",
      "Epoch: [80 | 400] LR: 0.029772\n",
      "50/50 | Loss:0.9508 | top1:48.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.7156 | top1:50.0000 | AUROC:0.5004\n",
      "\n",
      "Epoch: [81 | 400] LR: 0.029707\n",
      "50/50 | Loss:0.9367 | top1:53.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.7055 | top1:50.0000 | AUROC:0.4987\n",
      "\n",
      "Epoch: [82 | 400] LR: 0.029642\n",
      "50/50 | Loss:0.8574 | top1:55.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.8185 | top1:50.0000 | AUROC:0.5048\n",
      "\n",
      "Epoch: [83 | 400] LR: 0.029576\n",
      "50/50 | Loss:0.9988 | top1:44.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.7397 | top1:50.0000 | AUROC:0.4948\n",
      "\n",
      "Epoch: [84 | 400] LR: 0.029509\n",
      "50/50 | Loss:0.8468 | top1:47.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6945 | top1:50.0000 | AUROC:0.4922\n",
      "\n",
      "Epoch: [85 | 400] LR: 0.029441\n",
      "50/50 | Loss:0.9798 | top1:43.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6936 | top1:50.0000 | AUROC:0.4923\n",
      "\n",
      "Epoch: [86 | 400] LR: 0.029373\n",
      "50/50 | Loss:0.9008 | top1:51.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.8103 | top1:50.0000 | AUROC:0.4936\n",
      "\n",
      "Epoch: [87 | 400] LR: 0.029304\n",
      "50/50 | Loss:0.8912 | top1:47.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.7093 | top1:50.0000 | AUROC:0.4910\n",
      "\n",
      "Epoch: [88 | 400] LR: 0.029233\n",
      "50/50 | Loss:0.8916 | top1:50.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.7403 | top1:50.0000 | AUROC:0.5009\n",
      "\n",
      "Epoch: [89 | 400] LR: 0.029162\n",
      "50/50 | Loss:0.8603 | top1:44.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6984 | top1:50.0000 | AUROC:0.4982\n",
      "\n",
      "Epoch: [90 | 400] LR: 0.029090\n",
      "50/50 | Loss:0.8529 | top1:48.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.7597 | top1:50.0000 | AUROC:0.5003\n",
      "\n",
      "Epoch: [91 | 400] LR: 0.029018\n",
      "50/50 | Loss:0.8811 | top1:50.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6977 | top1:50.0000 | AUROC:0.4956\n",
      "\n",
      "Epoch: [92 | 400] LR: 0.028944\n",
      "50/50 | Loss:0.8606 | top1:48.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.7338 | top1:50.0000 | AUROC:0.4963\n",
      "\n",
      "Epoch: [93 | 400] LR: 0.028870\n",
      "50/50 | Loss:0.8783 | top1:48.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.7181 | top1:50.0000 | AUROC:0.4920\n",
      "\n",
      "Epoch: [94 | 400] LR: 0.028795\n",
      "50/50 | Loss:0.8227 | top1:53.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.7236 | top1:50.0000 | AUROC:0.4835\n",
      "\n",
      "Epoch: [95 | 400] LR: 0.028719\n",
      "50/50 | Loss:0.8081 | top1:52.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.7224 | top1:50.0000 | AUROC:0.4841\n",
      "\n",
      "Epoch: [96 | 400] LR: 0.028642\n",
      "50/50 | Loss:0.8889 | top1:46.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4867\n",
      "\n",
      "Epoch: [97 | 400] LR: 0.028565\n",
      "50/50 | Loss:0.8424 | top1:49.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.7042 | top1:50.0000 | AUROC:0.4881\n",
      "\n",
      "Epoch: [98 | 400] LR: 0.028487\n",
      "50/50 | Loss:0.8730 | top1:53.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.8828 | top1:50.0000 | AUROC:0.4998\n",
      "\n",
      "Epoch: [99 | 400] LR: 0.028408\n",
      "50/50 | Loss:0.9048 | top1:48.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.7235 | top1:50.0000 | AUROC:0.4928\n",
      "\n",
      "Epoch: [100 | 400] LR: 0.028328\n",
      "50/50 | Loss:0.7993 | top1:50.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.8088 | top1:50.0000 | AUROC:0.4977\n",
      "\n",
      "Epoch: [101 | 400] LR: 0.028248\n",
      "50/50 | Loss:0.8579 | top1:53.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6986 | top1:50.0000 | AUROC:0.4892\n",
      "\n",
      "Epoch: [102 | 400] LR: 0.028166\n",
      "50/50 | Loss:0.8897 | top1:48.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.7157 | top1:50.0000 | AUROC:0.4897\n",
      "\n",
      "Epoch: [103 | 400] LR: 0.028085\n",
      "50/50 | Loss:0.8862 | top1:44.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6934 | top1:50.0000 | AUROC:0.4879\n",
      "\n",
      "Epoch: [104 | 400] LR: 0.028002\n",
      "50/50 | Loss:0.8266 | top1:53.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.9262 | top1:50.0000 | AUROC:0.4840\n",
      "\n",
      "Epoch: [105 | 400] LR: 0.027918\n",
      "50/50 | Loss:0.8810 | top1:52.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.7419 | top1:50.0000 | AUROC:0.4854\n",
      "\n",
      "Epoch: [106 | 400] LR: 0.027834\n",
      "50/50 | Loss:0.8233 | top1:51.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.7163 | top1:50.0000 | AUROC:0.4818\n",
      "\n",
      "Epoch: [107 | 400] LR: 0.027749\n",
      "50/50 | Loss:0.8778 | top1:51.5000 | AUROC:0.0000\n",
      "31/31 | Loss:1.0326 | top1:50.0000 | AUROC:0.4925\n",
      "\n",
      "Epoch: [108 | 400] LR: 0.027663\n",
      "50/50 | Loss:0.9561 | top1:44.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.7406 | top1:50.0000 | AUROC:0.4801\n",
      "\n",
      "Epoch: [109 | 400] LR: 0.027577\n",
      "50/50 | Loss:0.8616 | top1:47.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6961 | top1:50.0000 | AUROC:0.4810\n",
      "\n",
      "Epoch: [110 | 400] LR: 0.027490\n",
      "50/50 | Loss:0.8164 | top1:51.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6991 | top1:50.0000 | AUROC:0.4811\n",
      "\n",
      "Epoch: [111 | 400] LR: 0.027402\n",
      "50/50 | Loss:0.8496 | top1:52.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.7095 | top1:50.0000 | AUROC:0.4864\n",
      "\n",
      "Epoch: [112 | 400] LR: 0.027314\n",
      "50/50 | Loss:0.8795 | top1:42.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6986 | top1:50.0000 | AUROC:0.4810\n",
      "\n",
      "Epoch: [113 | 400] LR: 0.027225\n",
      "50/50 | Loss:0.8858 | top1:46.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6941 | top1:50.0000 | AUROC:0.4766\n",
      "\n",
      "Epoch: [114 | 400] LR: 0.027135\n",
      "50/50 | Loss:0.8486 | top1:52.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.7607 | top1:50.0000 | AUROC:0.4745\n",
      "\n",
      "Epoch: [115 | 400] LR: 0.027044\n",
      "50/50 | Loss:0.8588 | top1:48.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6933 | top1:50.0000 | AUROC:0.4747\n",
      "\n",
      "Epoch: [116 | 400] LR: 0.026953\n",
      "50/50 | Loss:0.8353 | top1:54.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.7729 | top1:50.0000 | AUROC:0.4886\n",
      "\n",
      "Epoch: [117 | 400] LR: 0.026861\n",
      "50/50 | Loss:0.8060 | top1:50.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.7360 | top1:50.0000 | AUROC:0.4776\n",
      "\n",
      "Epoch: [118 | 400] LR: 0.026768\n",
      "50/50 | Loss:0.8913 | top1:45.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6993 | top1:50.0000 | AUROC:0.4720\n",
      "\n",
      "Epoch: [119 | 400] LR: 0.026675\n",
      "50/50 | Loss:0.8054 | top1:48.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.7622 | top1:50.0000 | AUROC:0.4767\n",
      "\n",
      "Epoch: [120 | 400] LR: 0.026581\n",
      "50/50 | Loss:0.8510 | top1:48.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.7043 | top1:50.0000 | AUROC:0.4741\n",
      "\n",
      "Epoch: [121 | 400] LR: 0.026486\n",
      "50/50 | Loss:0.7858 | top1:50.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6987 | top1:50.0000 | AUROC:0.4711\n",
      "\n",
      "Epoch: [122 | 400] LR: 0.026391\n",
      "50/50 | Loss:0.8981 | top1:47.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.7050 | top1:50.0000 | AUROC:0.4745\n",
      "\n",
      "Epoch: [123 | 400] LR: 0.026295\n",
      "50/50 | Loss:0.9129 | top1:48.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.7351 | top1:50.0000 | AUROC:0.4727\n",
      "\n",
      "Epoch: [124 | 400] LR: 0.026199\n",
      "50/50 | Loss:0.8128 | top1:46.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.7133 | top1:50.0000 | AUROC:0.4818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [125 | 400] LR: 0.026102\n",
      "50/50 | Loss:0.7980 | top1:52.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.7545 | top1:50.0000 | AUROC:0.4756\n",
      "\n",
      "Epoch: [126 | 400] LR: 0.026004\n",
      "50/50 | Loss:0.8624 | top1:49.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.7102 | top1:50.0000 | AUROC:0.4779\n",
      "\n",
      "Epoch: [127 | 400] LR: 0.025906\n",
      "50/50 | Loss:0.8132 | top1:50.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.7567 | top1:50.0000 | AUROC:0.4756\n",
      "\n",
      "Epoch: [128 | 400] LR: 0.025807\n",
      "50/50 | Loss:0.8526 | top1:48.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.7261 | top1:50.0000 | AUROC:0.4823\n",
      "\n",
      "Epoch: [129 | 400] LR: 0.025707\n",
      "50/50 | Loss:0.7820 | top1:52.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6938 | top1:50.0000 | AUROC:0.4828\n",
      "\n",
      "Epoch: [130 | 400] LR: 0.025607\n",
      "50/50 | Loss:0.8653 | top1:49.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.7318 | top1:50.0000 | AUROC:0.4837\n",
      "\n",
      "Epoch: [131 | 400] LR: 0.025506\n",
      "50/50 | Loss:0.7907 | top1:53.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6993 | top1:50.0000 | AUROC:0.4842\n",
      "\n",
      "Epoch: [132 | 400] LR: 0.025405\n",
      "50/50 | Loss:0.7940 | top1:53.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.7218 | top1:50.0000 | AUROC:0.4799\n",
      "\n",
      "Epoch: [133 | 400] LR: 0.025303\n",
      "50/50 | Loss:0.8326 | top1:48.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6982 | top1:50.0000 | AUROC:0.4761\n",
      "\n",
      "Epoch: [134 | 400] LR: 0.025200\n",
      "50/50 | Loss:0.8226 | top1:46.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6988 | top1:50.0000 | AUROC:0.4771\n",
      "\n",
      "Epoch: [135 | 400] LR: 0.025097\n",
      "50/50 | Loss:0.8432 | top1:50.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.7121 | top1:50.0000 | AUROC:0.4733\n",
      "\n",
      "Epoch: [136 | 400] LR: 0.024993\n",
      "50/50 | Loss:0.8576 | top1:49.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6978 | top1:50.0000 | AUROC:0.4790\n",
      "\n",
      "Epoch: [137 | 400] LR: 0.024889\n",
      "50/50 | Loss:0.8248 | top1:54.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.7058 | top1:50.0000 | AUROC:0.4862\n",
      "\n",
      "Epoch: [138 | 400] LR: 0.024784\n",
      "50/50 | Loss:0.8136 | top1:51.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.7119 | top1:50.0000 | AUROC:0.4891\n",
      "\n",
      "Epoch: [139 | 400] LR: 0.024679\n",
      "50/50 | Loss:0.8240 | top1:48.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.7124 | top1:50.0000 | AUROC:0.4836\n",
      "\n",
      "Epoch: [140 | 400] LR: 0.024573\n",
      "50/50 | Loss:0.8638 | top1:42.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6935 | top1:50.0000 | AUROC:0.4815\n",
      "\n",
      "Epoch: [141 | 400] LR: 0.024467\n",
      "50/50 | Loss:0.8161 | top1:52.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.7869 | top1:50.0000 | AUROC:0.4909\n",
      "\n",
      "Epoch: [142 | 400] LR: 0.024360\n",
      "50/50 | Loss:0.8162 | top1:49.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4833\n",
      "\n",
      "Epoch: [143 | 400] LR: 0.024253\n",
      "50/50 | Loss:0.7441 | top1:57.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.7101 | top1:50.0000 | AUROC:0.4843\n",
      "\n",
      "Epoch: [144 | 400] LR: 0.024145\n",
      "50/50 | Loss:0.8519 | top1:51.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.7663 | top1:50.0000 | AUROC:0.4954\n",
      "\n",
      "Epoch: [145 | 400] LR: 0.024036\n",
      "50/50 | Loss:0.8690 | top1:49.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6958 | top1:50.0000 | AUROC:0.4856\n",
      "\n",
      "Epoch: [146 | 400] LR: 0.023927\n",
      "50/50 | Loss:0.8405 | top1:50.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6954 | top1:50.0000 | AUROC:0.4840\n",
      "\n",
      "Epoch: [147 | 400] LR: 0.023818\n",
      "50/50 | Loss:0.7921 | top1:49.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.7123 | top1:50.0000 | AUROC:0.4890\n",
      "\n",
      "Epoch: [148 | 400] LR: 0.023708\n",
      "50/50 | Loss:0.7892 | top1:49.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.7034 | top1:50.0000 | AUROC:0.4850\n",
      "\n",
      "Epoch: [149 | 400] LR: 0.023598\n",
      "50/50 | Loss:0.8378 | top1:47.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6991 | top1:50.0000 | AUROC:0.4773\n",
      "\n",
      "Epoch: [150 | 400] LR: 0.023487\n",
      "50/50 | Loss:0.8106 | top1:51.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.8247 | top1:50.0000 | AUROC:0.4742\n",
      "\n",
      "Epoch: [151 | 400] LR: 0.023376\n",
      "50/50 | Loss:0.8341 | top1:52.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6962 | top1:50.0000 | AUROC:0.4755\n",
      "\n",
      "Epoch: [152 | 400] LR: 0.002326\n",
      "50/50 | Loss:0.8319 | top1:47.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6933 | top1:50.0000 | AUROC:0.4744\n",
      "\n",
      "Epoch: [153 | 400] LR: 0.002315\n",
      "50/50 | Loss:0.7338 | top1:58.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4746\n",
      "\n",
      "Epoch: [154 | 400] LR: 0.002304\n",
      "50/50 | Loss:0.7837 | top1:49.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6940 | top1:50.0000 | AUROC:0.4749\n",
      "\n",
      "Epoch: [155 | 400] LR: 0.002293\n",
      "50/50 | Loss:0.7898 | top1:51.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6934 | top1:50.0000 | AUROC:0.4747\n",
      "\n",
      "Epoch: [156 | 400] LR: 0.002281\n",
      "50/50 | Loss:0.7921 | top1:51.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6940 | top1:50.0000 | AUROC:0.4753\n",
      "\n",
      "Epoch: [157 | 400] LR: 0.002270\n",
      "50/50 | Loss:0.8322 | top1:45.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6936 | top1:50.0000 | AUROC:0.4753\n",
      "\n",
      "Epoch: [158 | 400] LR: 0.002258\n",
      "50/50 | Loss:0.8626 | top1:48.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4743\n",
      "\n",
      "Epoch: [159 | 400] LR: 0.002247\n",
      "50/50 | Loss:0.8364 | top1:45.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4765\n",
      "\n",
      "Epoch: [160 | 400] LR: 0.002235\n",
      "50/50 | Loss:0.7938 | top1:50.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4772\n",
      "\n",
      "Epoch: [161 | 400] LR: 0.002224\n",
      "50/50 | Loss:0.7559 | top1:53.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4752\n",
      "\n",
      "Epoch: [162 | 400] LR: 0.002212\n",
      "50/50 | Loss:0.8032 | top1:52.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6933 | top1:50.0000 | AUROC:0.4752\n",
      "\n",
      "Epoch: [163 | 400] LR: 0.002201\n",
      "50/50 | Loss:0.7929 | top1:48.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4751\n",
      "\n",
      "Epoch: [164 | 400] LR: 0.002189\n",
      "50/50 | Loss:0.7940 | top1:54.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6939 | top1:50.0000 | AUROC:0.4751\n",
      "\n",
      "Epoch: [165 | 400] LR: 0.002177\n",
      "50/50 | Loss:0.7954 | top1:47.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6970 | top1:50.0000 | AUROC:0.4744\n",
      "\n",
      "Epoch: [166 | 400] LR: 0.002166\n",
      "50/50 | Loss:0.8204 | top1:49.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6933 | top1:50.0000 | AUROC:0.4740\n",
      "\n",
      "Epoch: [167 | 400] LR: 0.002154\n",
      "50/50 | Loss:0.8308 | top1:46.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6936 | top1:50.0000 | AUROC:0.4741\n",
      "\n",
      "Epoch: [168 | 400] LR: 0.002142\n",
      "50/50 | Loss:0.7945 | top1:49.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6943 | top1:50.0000 | AUROC:0.4741\n",
      "\n",
      "Epoch: [169 | 400] LR: 0.002130\n",
      "50/50 | Loss:0.8248 | top1:46.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6956 | top1:50.0000 | AUROC:0.4741\n",
      "\n",
      "Epoch: [170 | 400] LR: 0.002118\n",
      "50/50 | Loss:0.7999 | top1:49.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6933 | top1:50.0000 | AUROC:0.4749\n",
      "\n",
      "Epoch: [171 | 400] LR: 0.002106\n",
      "50/50 | Loss:0.8621 | top1:45.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6936 | top1:50.0000 | AUROC:0.4731\n",
      "\n",
      "Epoch: [172 | 400] LR: 0.002094\n",
      "50/50 | Loss:0.7671 | top1:56.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4743\n",
      "\n",
      "Epoch: [173 | 400] LR: 0.002082\n",
      "50/50 | Loss:0.7675 | top1:53.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6937 | top1:50.0000 | AUROC:0.4749\n",
      "\n",
      "Epoch: [174 | 400] LR: 0.002070\n",
      "50/50 | Loss:0.8569 | top1:50.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6941 | top1:50.0000 | AUROC:0.4747\n",
      "\n",
      "Epoch: [175 | 400] LR: 0.002058\n",
      "50/50 | Loss:0.8361 | top1:46.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6946 | top1:50.0000 | AUROC:0.4730\n",
      "\n",
      "Epoch: [176 | 400] LR: 0.002046\n",
      "50/50 | Loss:0.8079 | top1:46.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6949 | top1:50.0000 | AUROC:0.4734\n",
      "\n",
      "Epoch: [177 | 400] LR: 0.002034\n",
      "50/50 | Loss:0.8171 | top1:46.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:49.9744 | AUROC:0.4731\n",
      "\n",
      "Epoch: [178 | 400] LR: 0.002022\n",
      "50/50 | Loss:0.8375 | top1:43.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6942 | top1:50.0000 | AUROC:0.4729\n",
      "\n",
      "Epoch: [179 | 400] LR: 0.002010\n",
      "50/50 | Loss:0.8261 | top1:49.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4720\n",
      "\n",
      "Epoch: [180 | 400] LR: 0.001998\n",
      "50/50 | Loss:0.8326 | top1:47.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4722\n",
      "\n",
      "Epoch: [181 | 400] LR: 0.001986\n",
      "50/50 | Loss:0.8195 | top1:47.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6961 | top1:50.0000 | AUROC:0.4734\n",
      "\n",
      "Epoch: [182 | 400] LR: 0.001974\n",
      "50/50 | Loss:0.7600 | top1:48.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6938 | top1:50.0000 | AUROC:0.4729\n",
      "\n",
      "Epoch: [183 | 400] LR: 0.001961\n",
      "50/50 | Loss:0.7104 | top1:58.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6950 | top1:50.0000 | AUROC:0.4723\n",
      "\n",
      "Epoch: [184 | 400] LR: 0.001949\n",
      "50/50 | Loss:0.7784 | top1:54.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6935 | top1:50.0000 | AUROC:0.4730\n",
      "\n",
      "Epoch: [185 | 400] LR: 0.001937\n",
      "50/50 | Loss:0.7903 | top1:48.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6943 | top1:50.0000 | AUROC:0.4733\n",
      "\n",
      "Epoch: [186 | 400] LR: 0.001924\n",
      "50/50 | Loss:0.8100 | top1:49.5000 | AUROC:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4718\n",
      "\n",
      "Epoch: [187 | 400] LR: 0.001912\n",
      "50/50 | Loss:0.7868 | top1:51.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6935 | top1:50.0000 | AUROC:0.4724\n",
      "\n",
      "Epoch: [188 | 400] LR: 0.001900\n",
      "50/50 | Loss:0.7802 | top1:49.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4732\n",
      "\n",
      "Epoch: [189 | 400] LR: 0.001887\n",
      "50/50 | Loss:0.7885 | top1:47.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4741\n",
      "\n",
      "Epoch: [190 | 400] LR: 0.001875\n",
      "50/50 | Loss:0.8018 | top1:50.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6957 | top1:50.0000 | AUROC:0.4734\n",
      "\n",
      "Epoch: [191 | 400] LR: 0.001863\n",
      "50/50 | Loss:0.8179 | top1:47.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6956 | top1:50.0000 | AUROC:0.4715\n",
      "\n",
      "Epoch: [192 | 400] LR: 0.001850\n",
      "50/50 | Loss:0.8382 | top1:47.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.7013 | top1:50.0000 | AUROC:0.4751\n",
      "\n",
      "Epoch: [193 | 400] LR: 0.001838\n",
      "50/50 | Loss:0.8281 | top1:48.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6934 | top1:50.0000 | AUROC:0.4737\n",
      "\n",
      "Epoch: [194 | 400] LR: 0.001825\n",
      "50/50 | Loss:0.8617 | top1:42.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6942 | top1:50.0000 | AUROC:0.4727\n",
      "\n",
      "Epoch: [195 | 400] LR: 0.001813\n",
      "50/50 | Loss:0.7845 | top1:49.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6950 | top1:50.0000 | AUROC:0.4743\n",
      "\n",
      "Epoch: [196 | 400] LR: 0.001801\n",
      "50/50 | Loss:0.8031 | top1:47.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0128 | AUROC:0.4750\n",
      "\n",
      "Epoch: [197 | 400] LR: 0.001788\n",
      "50/50 | Loss:0.7633 | top1:53.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6938 | top1:50.0000 | AUROC:0.4747\n",
      "\n",
      "Epoch: [198 | 400] LR: 0.001776\n",
      "50/50 | Loss:0.7981 | top1:51.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4744\n",
      "\n",
      "Epoch: [199 | 400] LR: 0.001763\n",
      "50/50 | Loss:0.8402 | top1:42.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6935 | top1:50.0000 | AUROC:0.4745\n",
      "\n",
      "Epoch: [200 | 400] LR: 0.001751\n",
      "50/50 | Loss:0.7496 | top1:54.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6938 | top1:50.0000 | AUROC:0.4727\n",
      "\n",
      "Epoch: [201 | 400] LR: 0.001738\n",
      "50/50 | Loss:0.7679 | top1:54.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6933 | top1:50.0000 | AUROC:0.4745\n",
      "\n",
      "Epoch: [202 | 400] LR: 0.001726\n",
      "50/50 | Loss:0.7581 | top1:52.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6934 | top1:50.0000 | AUROC:0.4732\n",
      "\n",
      "Epoch: [203 | 400] LR: 0.001713\n",
      "50/50 | Loss:0.8377 | top1:48.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6938 | top1:50.0000 | AUROC:0.4733\n",
      "\n",
      "Epoch: [204 | 400] LR: 0.001700\n",
      "50/50 | Loss:0.7374 | top1:52.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6953 | top1:50.0000 | AUROC:0.4746\n",
      "\n",
      "Epoch: [205 | 400] LR: 0.001688\n",
      "50/50 | Loss:0.7831 | top1:48.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6944 | top1:50.0000 | AUROC:0.4726\n",
      "\n",
      "Epoch: [206 | 400] LR: 0.001675\n",
      "50/50 | Loss:0.7953 | top1:53.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4735\n",
      "\n",
      "Epoch: [207 | 400] LR: 0.001663\n",
      "50/50 | Loss:0.8340 | top1:47.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6933 | top1:50.0000 | AUROC:0.4733\n",
      "\n",
      "Epoch: [208 | 400] LR: 0.001650\n",
      "50/50 | Loss:0.8220 | top1:47.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6956 | top1:50.0000 | AUROC:0.4739\n",
      "\n",
      "Epoch: [209 | 400] LR: 0.001638\n",
      "50/50 | Loss:0.7537 | top1:55.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4727\n",
      "\n",
      "Epoch: [210 | 400] LR: 0.001625\n",
      "50/50 | Loss:0.8522 | top1:45.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:49.9872 | AUROC:0.4725\n",
      "\n",
      "Epoch: [211 | 400] LR: 0.001613\n",
      "50/50 | Loss:0.8009 | top1:51.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6937 | top1:50.0000 | AUROC:0.4730\n",
      "\n",
      "Epoch: [212 | 400] LR: 0.001600\n",
      "50/50 | Loss:0.7951 | top1:52.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6939 | top1:50.0000 | AUROC:0.4735\n",
      "\n",
      "Epoch: [213 | 400] LR: 0.001587\n",
      "50/50 | Loss:0.7710 | top1:50.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6938 | top1:50.0000 | AUROC:0.4719\n",
      "\n",
      "Epoch: [214 | 400] LR: 0.001575\n",
      "50/50 | Loss:0.7429 | top1:57.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6937 | top1:50.0000 | AUROC:0.4733\n",
      "\n",
      "Epoch: [215 | 400] LR: 0.001562\n",
      "50/50 | Loss:0.7699 | top1:52.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4727\n",
      "\n",
      "Epoch: [216 | 400] LR: 0.001550\n",
      "50/50 | Loss:0.7926 | top1:53.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6934 | top1:50.0000 | AUROC:0.4686\n",
      "\n",
      "Epoch: [217 | 400] LR: 0.001537\n",
      "50/50 | Loss:0.8264 | top1:51.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6934 | top1:50.0000 | AUROC:0.4664\n",
      "\n",
      "Epoch: [218 | 400] LR: 0.001525\n",
      "50/50 | Loss:0.8372 | top1:43.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6947 | top1:50.0000 | AUROC:0.4683\n",
      "\n",
      "Epoch: [219 | 400] LR: 0.001512\n",
      "50/50 | Loss:0.7506 | top1:57.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6960 | top1:50.0000 | AUROC:0.4692\n",
      "\n",
      "Epoch: [220 | 400] LR: 0.001500\n",
      "50/50 | Loss:0.7798 | top1:50.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6955 | top1:50.0000 | AUROC:0.4672\n",
      "\n",
      "Epoch: [221 | 400] LR: 0.001487\n",
      "50/50 | Loss:0.7393 | top1:52.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4669\n",
      "\n",
      "Epoch: [222 | 400] LR: 0.001474\n",
      "50/50 | Loss:0.8638 | top1:45.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6964 | top1:50.0000 | AUROC:0.4697\n",
      "\n",
      "Epoch: [223 | 400] LR: 0.001462\n",
      "50/50 | Loss:0.7994 | top1:47.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6934 | top1:50.0000 | AUROC:0.4685\n",
      "\n",
      "Epoch: [224 | 400] LR: 0.001449\n",
      "50/50 | Loss:0.7919 | top1:49.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6939 | top1:50.0000 | AUROC:0.4694\n",
      "\n",
      "Epoch: [225 | 400] LR: 0.001437\n",
      "50/50 | Loss:0.7906 | top1:52.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6933 | top1:50.0000 | AUROC:0.4692\n",
      "\n",
      "Epoch: [226 | 400] LR: 0.001424\n",
      "50/50 | Loss:0.7602 | top1:52.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6945 | top1:50.0000 | AUROC:0.4689\n",
      "\n",
      "Epoch: [227 | 400] LR: 0.000141\n",
      "50/50 | Loss:0.7691 | top1:48.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6943 | top1:50.0000 | AUROC:0.4684\n",
      "\n",
      "Epoch: [228 | 400] LR: 0.000140\n",
      "50/50 | Loss:0.8675 | top1:44.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6942 | top1:50.0000 | AUROC:0.4692\n",
      "\n",
      "Epoch: [229 | 400] LR: 0.000139\n",
      "50/50 | Loss:0.8044 | top1:48.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6940 | top1:50.0000 | AUROC:0.4688\n",
      "\n",
      "Epoch: [230 | 400] LR: 0.000137\n",
      "50/50 | Loss:0.8203 | top1:49.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6939 | top1:50.0000 | AUROC:0.4680\n",
      "\n",
      "Epoch: [231 | 400] LR: 0.000136\n",
      "50/50 | Loss:0.8283 | top1:46.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6935 | top1:50.0000 | AUROC:0.4684\n",
      "\n",
      "Epoch: [232 | 400] LR: 0.000135\n",
      "50/50 | Loss:0.8384 | top1:49.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6935 | top1:50.0000 | AUROC:0.4688\n",
      "\n",
      "Epoch: [233 | 400] LR: 0.000134\n",
      "50/50 | Loss:0.8227 | top1:46.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6933 | top1:50.0000 | AUROC:0.4695\n",
      "\n",
      "Epoch: [234 | 400] LR: 0.000132\n",
      "50/50 | Loss:0.7582 | top1:52.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6933 | top1:50.0000 | AUROC:0.4700\n",
      "\n",
      "Epoch: [235 | 400] LR: 0.000131\n",
      "50/50 | Loss:0.8014 | top1:49.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6933 | top1:50.0000 | AUROC:0.4687\n",
      "\n",
      "Epoch: [236 | 400] LR: 0.000130\n",
      "50/50 | Loss:0.8165 | top1:49.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4687\n",
      "\n",
      "Epoch: [237 | 400] LR: 0.000129\n",
      "50/50 | Loss:0.7873 | top1:51.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4690\n",
      "\n",
      "Epoch: [238 | 400] LR: 0.000128\n",
      "50/50 | Loss:0.7824 | top1:48.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4688\n",
      "\n",
      "Epoch: [239 | 400] LR: 0.000126\n",
      "50/50 | Loss:0.8146 | top1:51.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6933 | top1:50.0000 | AUROC:0.4700\n",
      "\n",
      "Epoch: [240 | 400] LR: 0.000125\n",
      "50/50 | Loss:0.7597 | top1:52.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4686\n",
      "\n",
      "Epoch: [241 | 400] LR: 0.000124\n",
      "50/50 | Loss:0.8176 | top1:47.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4697\n",
      "\n",
      "Epoch: [242 | 400] LR: 0.000123\n",
      "50/50 | Loss:0.8137 | top1:50.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4693\n",
      "\n",
      "Epoch: [243 | 400] LR: 0.000121\n",
      "50/50 | Loss:0.7959 | top1:51.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6933 | top1:50.0000 | AUROC:0.4686\n",
      "\n",
      "Epoch: [244 | 400] LR: 0.000120\n",
      "50/50 | Loss:0.8381 | top1:49.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4688\n",
      "\n",
      "Epoch: [245 | 400] LR: 0.000119\n",
      "50/50 | Loss:0.7974 | top1:51.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6933 | top1:50.0000 | AUROC:0.4684\n",
      "\n",
      "Epoch: [246 | 400] LR: 0.000118\n",
      "50/50 | Loss:0.7588 | top1:52.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6933 | top1:50.0000 | AUROC:0.4684\n",
      "\n",
      "Epoch: [247 | 400] LR: 0.000117\n",
      "50/50 | Loss:0.7268 | top1:57.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4684\n",
      "\n",
      "Epoch: [248 | 400] LR: 0.000115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 | Loss:0.7709 | top1:49.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:49.8462 | AUROC:0.4687\n",
      "\n",
      "Epoch: [249 | 400] LR: 0.000114\n",
      "50/50 | Loss:0.8390 | top1:48.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:49.3462 | AUROC:0.4691\n",
      "\n",
      "Epoch: [250 | 400] LR: 0.000113\n",
      "50/50 | Loss:0.7835 | top1:52.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4685\n",
      "\n",
      "Epoch: [251 | 400] LR: 0.000112\n",
      "50/50 | Loss:0.8263 | top1:42.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:49.8974 | AUROC:0.4693\n",
      "\n",
      "Epoch: [252 | 400] LR: 0.000111\n",
      "50/50 | Loss:0.7339 | top1:54.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:49.7436 | AUROC:0.4698\n",
      "\n",
      "Epoch: [253 | 400] LR: 0.000109\n",
      "50/50 | Loss:0.8147 | top1:51.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4699\n",
      "\n",
      "Epoch: [254 | 400] LR: 0.000108\n",
      "50/50 | Loss:0.7283 | top1:55.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4685\n",
      "\n",
      "Epoch: [255 | 400] LR: 0.000107\n",
      "50/50 | Loss:0.7722 | top1:51.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4699\n",
      "\n",
      "Epoch: [256 | 400] LR: 0.000106\n",
      "50/50 | Loss:0.7615 | top1:50.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4690\n",
      "\n",
      "Epoch: [257 | 400] LR: 0.000105\n",
      "50/50 | Loss:0.7808 | top1:51.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4696\n",
      "\n",
      "Epoch: [258 | 400] LR: 0.000103\n",
      "50/50 | Loss:0.8145 | top1:46.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4692\n",
      "\n",
      "Epoch: [259 | 400] LR: 0.000102\n",
      "50/50 | Loss:0.8122 | top1:48.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4691\n",
      "\n",
      "Epoch: [260 | 400] LR: 0.000101\n",
      "50/50 | Loss:0.7766 | top1:47.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4683\n",
      "\n",
      "Epoch: [261 | 400] LR: 0.000100\n",
      "50/50 | Loss:0.8207 | top1:44.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:49.9744 | AUROC:0.4682\n",
      "\n",
      "Epoch: [262 | 400] LR: 0.000099\n",
      "50/50 | Loss:0.8086 | top1:48.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:49.9744 | AUROC:0.4694\n",
      "\n",
      "Epoch: [263 | 400] LR: 0.000098\n",
      "50/50 | Loss:0.8880 | top1:38.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4682\n",
      "\n",
      "Epoch: [264 | 400] LR: 0.000096\n",
      "50/50 | Loss:0.7627 | top1:52.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4691\n",
      "\n",
      "Epoch: [265 | 400] LR: 0.000095\n",
      "50/50 | Loss:0.8107 | top1:50.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4681\n",
      "\n",
      "Epoch: [266 | 400] LR: 0.000094\n",
      "50/50 | Loss:0.7436 | top1:54.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4692\n",
      "\n",
      "Epoch: [267 | 400] LR: 0.000093\n",
      "50/50 | Loss:0.8119 | top1:50.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4680\n",
      "\n",
      "Epoch: [268 | 400] LR: 0.000092\n",
      "50/50 | Loss:0.7395 | top1:53.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4690\n",
      "\n",
      "Epoch: [269 | 400] LR: 0.000091\n",
      "50/50 | Loss:0.8880 | top1:41.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4706\n",
      "\n",
      "Epoch: [270 | 400] LR: 0.000090\n",
      "50/50 | Loss:0.7556 | top1:55.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6933 | top1:50.0000 | AUROC:0.4691\n",
      "\n",
      "Epoch: [271 | 400] LR: 0.000088\n",
      "50/50 | Loss:0.7913 | top1:50.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4693\n",
      "\n",
      "Epoch: [272 | 400] LR: 0.000087\n",
      "50/50 | Loss:0.8243 | top1:45.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4682\n",
      "\n",
      "Epoch: [273 | 400] LR: 0.000086\n",
      "50/50 | Loss:0.8065 | top1:49.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4691\n",
      "\n",
      "Epoch: [274 | 400] LR: 0.000085\n",
      "50/50 | Loss:0.7481 | top1:52.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4689\n",
      "\n",
      "Epoch: [275 | 400] LR: 0.000084\n",
      "50/50 | Loss:0.8160 | top1:50.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4684\n",
      "\n",
      "Epoch: [276 | 400] LR: 0.000083\n",
      "50/50 | Loss:0.8054 | top1:51.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:49.3974 | AUROC:0.4694\n",
      "\n",
      "Epoch: [277 | 400] LR: 0.000082\n",
      "50/50 | Loss:0.7763 | top1:51.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4689\n",
      "\n",
      "Epoch: [278 | 400] LR: 0.000081\n",
      "50/50 | Loss:0.8118 | top1:50.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4681\n",
      "\n",
      "Epoch: [279 | 400] LR: 0.000080\n",
      "50/50 | Loss:0.8172 | top1:46.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4681\n",
      "\n",
      "Epoch: [280 | 400] LR: 0.000079\n",
      "50/50 | Loss:0.8069 | top1:46.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4693\n",
      "\n",
      "Epoch: [281 | 400] LR: 0.000077\n",
      "50/50 | Loss:0.7743 | top1:55.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4677\n",
      "\n",
      "Epoch: [282 | 400] LR: 0.000076\n",
      "50/50 | Loss:0.7516 | top1:55.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4682\n",
      "\n",
      "Epoch: [283 | 400] LR: 0.000075\n",
      "50/50 | Loss:0.8001 | top1:49.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4697\n",
      "\n",
      "Epoch: [284 | 400] LR: 0.000074\n",
      "50/50 | Loss:0.8036 | top1:51.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4701\n",
      "\n",
      "Epoch: [285 | 400] LR: 0.000073\n",
      "50/50 | Loss:0.7965 | top1:54.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4689\n",
      "\n",
      "Epoch: [286 | 400] LR: 0.000072\n",
      "50/50 | Loss:0.8090 | top1:48.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4691\n",
      "\n",
      "Epoch: [287 | 400] LR: 0.000071\n",
      "50/50 | Loss:0.7883 | top1:50.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4685\n",
      "\n",
      "Epoch: [288 | 400] LR: 0.000070\n",
      "50/50 | Loss:0.8018 | top1:52.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4671\n",
      "\n",
      "Epoch: [289 | 400] LR: 0.000069\n",
      "50/50 | Loss:0.8179 | top1:48.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4686\n",
      "\n",
      "Epoch: [290 | 400] LR: 0.000068\n",
      "50/50 | Loss:0.7777 | top1:52.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4689\n",
      "\n",
      "Epoch: [291 | 400] LR: 0.000067\n",
      "50/50 | Loss:0.8212 | top1:50.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4686\n",
      "\n",
      "Epoch: [292 | 400] LR: 0.000066\n",
      "50/50 | Loss:0.8614 | top1:48.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4693\n",
      "\n",
      "Epoch: [293 | 400] LR: 0.000065\n",
      "50/50 | Loss:0.7724 | top1:56.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4688\n",
      "\n",
      "Epoch: [294 | 400] LR: 0.000064\n",
      "50/50 | Loss:0.7760 | top1:48.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4687\n",
      "\n",
      "Epoch: [295 | 400] LR: 0.000063\n",
      "50/50 | Loss:0.8445 | top1:46.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4679\n",
      "\n",
      "Epoch: [296 | 400] LR: 0.000062\n",
      "50/50 | Loss:0.8127 | top1:48.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4690\n",
      "\n",
      "Epoch: [297 | 400] LR: 0.000061\n",
      "50/50 | Loss:0.8279 | top1:48.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4683\n",
      "\n",
      "Epoch: [298 | 400] LR: 0.000060\n",
      "50/50 | Loss:0.7859 | top1:49.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4678\n",
      "\n",
      "Epoch: [299 | 400] LR: 0.000059\n",
      "50/50 | Loss:0.7861 | top1:54.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4691\n",
      "\n",
      "Epoch: [300 | 400] LR: 0.000058\n",
      "50/50 | Loss:0.7730 | top1:52.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4671\n",
      "\n",
      "Epoch: [301 | 400] LR: 0.000057\n",
      "50/50 | Loss:0.7849 | top1:50.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4694\n",
      "\n",
      "Epoch: [302 | 400] LR: 0.000056\n",
      "50/50 | Loss:0.7795 | top1:49.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4689\n",
      "\n",
      "Epoch: [303 | 400] LR: 0.000055\n",
      "50/50 | Loss:0.8092 | top1:47.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4683\n",
      "\n",
      "Epoch: [304 | 400] LR: 0.000054\n",
      "50/50 | Loss:0.7807 | top1:51.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6933 | top1:50.0000 | AUROC:0.4692\n",
      "\n",
      "Epoch: [305 | 400] LR: 0.000053\n",
      "50/50 | Loss:0.8452 | top1:46.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4686\n",
      "\n",
      "Epoch: [306 | 400] LR: 0.000052\n",
      "50/50 | Loss:0.7505 | top1:49.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4683\n",
      "\n",
      "Epoch: [307 | 400] LR: 0.000051\n",
      "50/50 | Loss:0.8336 | top1:47.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4681\n",
      "\n",
      "Epoch: [308 | 400] LR: 0.000050\n",
      "50/50 | Loss:0.8111 | top1:53.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4674\n",
      "\n",
      "Epoch: [309 | 400] LR: 0.000050\n",
      "50/50 | Loss:0.7776 | top1:50.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [310 | 400] LR: 0.000049\n",
      "50/50 | Loss:0.7616 | top1:51.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4690\n",
      "\n",
      "Epoch: [311 | 400] LR: 0.000048\n",
      "50/50 | Loss:0.8327 | top1:49.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4691\n",
      "\n",
      "Epoch: [312 | 400] LR: 0.000047\n",
      "50/50 | Loss:0.8513 | top1:45.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4684\n",
      "\n",
      "Epoch: [313 | 400] LR: 0.000046\n",
      "50/50 | Loss:0.8023 | top1:46.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4692\n",
      "\n",
      "Epoch: [314 | 400] LR: 0.000045\n",
      "50/50 | Loss:0.8155 | top1:46.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4693\n",
      "\n",
      "Epoch: [315 | 400] LR: 0.000044\n",
      "50/50 | Loss:0.7749 | top1:48.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4681\n",
      "\n",
      "Epoch: [316 | 400] LR: 0.000043\n",
      "50/50 | Loss:0.8222 | top1:46.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4691\n",
      "\n",
      "Epoch: [317 | 400] LR: 0.000043\n",
      "50/50 | Loss:0.7974 | top1:51.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4678\n",
      "\n",
      "Epoch: [318 | 400] LR: 0.000042\n",
      "50/50 | Loss:0.7640 | top1:51.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4694\n",
      "\n",
      "Epoch: [319 | 400] LR: 0.000041\n",
      "50/50 | Loss:0.8025 | top1:51.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4693\n",
      "\n",
      "Epoch: [320 | 400] LR: 0.000040\n",
      "50/50 | Loss:0.8194 | top1:45.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4687\n",
      "\n",
      "Epoch: [321 | 400] LR: 0.000039\n",
      "50/50 | Loss:0.7915 | top1:53.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4693\n",
      "\n",
      "Epoch: [322 | 400] LR: 0.000038\n",
      "50/50 | Loss:0.7278 | top1:53.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4688\n",
      "\n",
      "Epoch: [323 | 400] LR: 0.000038\n",
      "50/50 | Loss:0.7938 | top1:49.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4681\n",
      "\n",
      "Epoch: [324 | 400] LR: 0.000037\n",
      "50/50 | Loss:0.8323 | top1:48.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4683\n",
      "\n",
      "Epoch: [325 | 400] LR: 0.000036\n",
      "50/50 | Loss:0.7409 | top1:55.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4689\n",
      "\n",
      "Epoch: [326 | 400] LR: 0.000035\n",
      "50/50 | Loss:0.7670 | top1:53.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4700\n",
      "\n",
      "Epoch: [327 | 400] LR: 0.000034\n",
      "50/50 | Loss:0.7848 | top1:49.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4680\n",
      "\n",
      "Epoch: [328 | 400] LR: 0.000034\n",
      "50/50 | Loss:0.7806 | top1:53.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4690\n",
      "\n",
      "Epoch: [329 | 400] LR: 0.000033\n",
      "50/50 | Loss:0.8158 | top1:51.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4684\n",
      "\n",
      "Epoch: [330 | 400] LR: 0.000032\n",
      "50/50 | Loss:0.7371 | top1:57.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4688\n",
      "\n",
      "Epoch: [331 | 400] LR: 0.000031\n",
      "50/50 | Loss:0.8188 | top1:48.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4690\n",
      "\n",
      "Epoch: [332 | 400] LR: 0.000031\n",
      "50/50 | Loss:0.7296 | top1:51.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4685\n",
      "\n",
      "Epoch: [333 | 400] LR: 0.000030\n",
      "50/50 | Loss:0.8320 | top1:53.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4691\n",
      "\n",
      "Epoch: [334 | 400] LR: 0.000029\n",
      "50/50 | Loss:0.8051 | top1:51.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4701\n",
      "\n",
      "Epoch: [335 | 400] LR: 0.000028\n",
      "50/50 | Loss:0.8069 | top1:47.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4686\n",
      "\n",
      "Epoch: [336 | 400] LR: 0.000028\n",
      "50/50 | Loss:0.8500 | top1:46.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4687\n",
      "\n",
      "Epoch: [337 | 400] LR: 0.000027\n",
      "50/50 | Loss:0.7475 | top1:57.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4695\n",
      "\n",
      "Epoch: [338 | 400] LR: 0.000026\n",
      "50/50 | Loss:0.7685 | top1:54.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4687\n",
      "\n",
      "Epoch: [339 | 400] LR: 0.000026\n",
      "50/50 | Loss:0.7546 | top1:52.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4682\n",
      "\n",
      "Epoch: [340 | 400] LR: 0.000025\n",
      "50/50 | Loss:0.7849 | top1:55.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4692\n",
      "\n",
      "Epoch: [341 | 400] LR: 0.000024\n",
      "50/50 | Loss:0.7862 | top1:50.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4700\n",
      "\n",
      "Epoch: [342 | 400] LR: 0.000024\n",
      "50/50 | Loss:0.8280 | top1:47.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4684\n",
      "\n",
      "Epoch: [343 | 400] LR: 0.000023\n",
      "50/50 | Loss:0.8091 | top1:50.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4688\n",
      "\n",
      "Epoch: [344 | 400] LR: 0.000022\n",
      "50/50 | Loss:0.8457 | top1:44.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4686\n",
      "\n",
      "Epoch: [345 | 400] LR: 0.000022\n",
      "50/50 | Loss:0.7841 | top1:52.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4683\n",
      "\n",
      "Epoch: [346 | 400] LR: 0.000021\n",
      "50/50 | Loss:0.7657 | top1:52.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4695\n",
      "\n",
      "Epoch: [347 | 400] LR: 0.000020\n",
      "50/50 | Loss:0.7950 | top1:50.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4685\n",
      "\n",
      "Epoch: [348 | 400] LR: 0.000020\n",
      "50/50 | Loss:0.7553 | top1:52.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4689\n",
      "\n",
      "Epoch: [349 | 400] LR: 0.000019\n",
      "50/50 | Loss:0.8193 | top1:45.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4693\n",
      "\n",
      "Epoch: [350 | 400] LR: 0.000019\n",
      "50/50 | Loss:0.7579 | top1:54.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4685\n",
      "\n",
      "Epoch: [351 | 400] LR: 0.000018\n",
      "50/50 | Loss:0.7471 | top1:51.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4686\n",
      "\n",
      "Epoch: [352 | 400] LR: 0.000017\n",
      "50/50 | Loss:0.7859 | top1:50.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4689\n",
      "\n",
      "Epoch: [353 | 400] LR: 0.000017\n",
      "50/50 | Loss:0.8460 | top1:46.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4687\n",
      "\n",
      "Epoch: [354 | 400] LR: 0.000016\n",
      "50/50 | Loss:0.7898 | top1:51.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4696\n",
      "\n",
      "Epoch: [355 | 400] LR: 0.000016\n",
      "50/50 | Loss:0.7638 | top1:50.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4688\n",
      "\n",
      "Epoch: [356 | 400] LR: 0.000015\n",
      "50/50 | Loss:0.7813 | top1:52.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4681\n",
      "\n",
      "Epoch: [357 | 400] LR: 0.000015\n",
      "50/50 | Loss:0.7556 | top1:55.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4689\n",
      "\n",
      "Epoch: [358 | 400] LR: 0.000014\n",
      "50/50 | Loss:0.7903 | top1:50.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4679\n",
      "\n",
      "Epoch: [359 | 400] LR: 0.000014\n",
      "50/50 | Loss:0.7825 | top1:48.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4696\n",
      "\n",
      "Epoch: [360 | 400] LR: 0.000013\n",
      "50/50 | Loss:0.7631 | top1:51.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4690\n",
      "\n",
      "Epoch: [361 | 400] LR: 0.000013\n",
      "50/50 | Loss:0.8033 | top1:48.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4693\n",
      "\n",
      "Epoch: [362 | 400] LR: 0.000012\n",
      "50/50 | Loss:0.7939 | top1:49.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4684\n",
      "\n",
      "Epoch: [363 | 400] LR: 0.000012\n",
      "50/50 | Loss:0.7628 | top1:54.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4699\n",
      "\n",
      "Epoch: [364 | 400] LR: 0.000011\n",
      "50/50 | Loss:0.8323 | top1:49.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4690\n",
      "\n",
      "Epoch: [365 | 400] LR: 0.000011\n",
      "50/50 | Loss:0.7906 | top1:47.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4688\n",
      "\n",
      "Epoch: [366 | 400] LR: 0.000010\n",
      "50/50 | Loss:0.7954 | top1:49.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4678\n",
      "\n",
      "Epoch: [367 | 400] LR: 0.000010\n",
      "50/50 | Loss:0.8064 | top1:46.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4687\n",
      "\n",
      "Epoch: [368 | 400] LR: 0.000009\n",
      "50/50 | Loss:0.7311 | top1:54.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4700\n",
      "\n",
      "Epoch: [369 | 400] LR: 0.000009\n",
      "50/50 | Loss:0.8160 | top1:50.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4679\n",
      "\n",
      "Epoch: [370 | 400] LR: 0.000009\n",
      "50/50 | Loss:0.8426 | top1:46.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4686\n",
      "\n",
      "Epoch: [371 | 400] LR: 0.000008\n",
      "50/50 | Loss:0.7894 | top1:49.5000 | AUROC:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4687\n",
      "\n",
      "Epoch: [372 | 400] LR: 0.000008\n",
      "50/50 | Loss:0.8612 | top1:48.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4692\n",
      "\n",
      "Epoch: [373 | 400] LR: 0.000007\n",
      "50/50 | Loss:0.7703 | top1:56.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4687\n",
      "\n",
      "Epoch: [374 | 400] LR: 0.000007\n",
      "50/50 | Loss:0.8352 | top1:43.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4691\n",
      "\n",
      "Epoch: [375 | 400] LR: 0.000007\n",
      "50/50 | Loss:0.7275 | top1:55.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4700\n",
      "\n",
      "Epoch: [376 | 400] LR: 0.000006\n",
      "50/50 | Loss:0.8317 | top1:46.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4690\n",
      "\n",
      "Epoch: [377 | 400] LR: 0.000006\n",
      "50/50 | Loss:0.7978 | top1:49.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4685\n",
      "\n",
      "Epoch: [378 | 400] LR: 0.000006\n",
      "50/50 | Loss:0.8440 | top1:47.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4695\n",
      "\n",
      "Epoch: [379 | 400] LR: 0.000005\n",
      "50/50 | Loss:0.7876 | top1:48.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4691\n",
      "\n",
      "Epoch: [380 | 400] LR: 0.000005\n",
      "50/50 | Loss:0.7789 | top1:50.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4692\n",
      "\n",
      "Epoch: [381 | 400] LR: 0.000005\n",
      "50/50 | Loss:0.8227 | top1:49.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4687\n",
      "\n",
      "Epoch: [382 | 400] LR: 0.000004\n",
      "50/50 | Loss:0.7788 | top1:52.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4687\n",
      "\n",
      "Epoch: [383 | 400] LR: 0.000004\n",
      "50/50 | Loss:0.7724 | top1:52.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4707\n",
      "\n",
      "Epoch: [384 | 400] LR: 0.000004\n",
      "50/50 | Loss:0.7814 | top1:49.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4692\n",
      "\n",
      "Epoch: [385 | 400] LR: 0.000004\n",
      "50/50 | Loss:0.8050 | top1:51.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4678\n",
      "\n",
      "Epoch: [386 | 400] LR: 0.000003\n",
      "50/50 | Loss:0.7969 | top1:52.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4691\n",
      "\n",
      "Epoch: [387 | 400] LR: 0.000003\n",
      "50/50 | Loss:0.7904 | top1:48.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4689\n",
      "\n",
      "Epoch: [388 | 400] LR: 0.000003\n",
      "50/50 | Loss:0.7869 | top1:53.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4689\n",
      "\n",
      "Epoch: [389 | 400] LR: 0.000003\n",
      "50/50 | Loss:0.8007 | top1:52.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4694\n",
      "\n",
      "Epoch: [390 | 400] LR: 0.000002\n",
      "50/50 | Loss:0.8452 | top1:41.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4695\n",
      "\n",
      "Epoch: [391 | 400] LR: 0.000002\n",
      "50/50 | Loss:0.8319 | top1:43.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4692\n",
      "\n",
      "Epoch: [392 | 400] LR: 0.000002\n",
      "50/50 | Loss:0.7194 | top1:57.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4696\n",
      "\n",
      "Epoch: [393 | 400] LR: 0.000002\n",
      "50/50 | Loss:0.7856 | top1:46.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4687\n",
      "\n",
      "Epoch: [394 | 400] LR: 0.000002\n",
      "50/50 | Loss:0.7613 | top1:53.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4697\n",
      "\n",
      "Epoch: [395 | 400] LR: 0.000001\n",
      "50/50 | Loss:0.7887 | top1:52.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4691\n",
      "\n",
      "Epoch: [396 | 400] LR: 0.000001\n",
      "50/50 | Loss:0.8276 | top1:44.5000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4688\n",
      "\n",
      "Epoch: [397 | 400] LR: 0.000001\n",
      "50/50 | Loss:0.7956 | top1:51.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4684\n",
      "\n",
      "Epoch: [398 | 400] LR: 0.000001\n",
      "50/50 | Loss:0.8298 | top1:44.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4693\n",
      "\n",
      "Epoch: [399 | 400] LR: 0.000001\n",
      "50/50 | Loss:0.8134 | top1:48.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4691\n",
      "\n",
      "Epoch: [400 | 400] LR: 0.000001\n",
      "50/50 | Loss:0.8188 | top1:49.0000 | AUROC:0.0000\n",
      "31/31 | Loss:0.6932 | top1:50.0000 | AUROC:0.4690\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(start_epoch, epochs):\n",
    "    state['lr'] = optimizer.state_dict()['param_groups'][0]['lr']\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "    print('\\nEpoch: [%d | %d] LR: %f' % (epoch + 1, epochs, state['lr']))\n",
    "    \n",
    "    train_loss, train_acc, train_auroc = train(train_loader, model, criterion, optimizer, epoch, use_cuda)\n",
    "    test_loss, test_acc, test_auroc = test(val_loader, model, criterion, epoch, use_cuda)\n",
    "    \n",
    "    logger.append([state['lr'], train_loss, test_loss, train_acc, test_acc, train_auroc, test_auroc])\n",
    "    scheduler_warmup.step()\n",
    "\n",
    "    is_best = test_acc > best_acc\n",
    "    best_acc = max(test_acc, best_acc)\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'state_dict' : model.state_dict(),\n",
    "        'acc': test_acc,\n",
    "        'best_acc': best_acc,\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    }, is_best, checkpoint=checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
