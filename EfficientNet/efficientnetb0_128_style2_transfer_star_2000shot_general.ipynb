{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import collections\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "\n",
    "from model_pytorch import EfficientNet\n",
    "from utils import Bar,Logger, AverageMeter, accuracy, mkdir_p, savefig\n",
    "from warmup_scheduler import GradualWarmupScheduler\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "import cv2\n",
    "\n",
    "from PIL import ImageFile, ImageOps\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU device 0: True\n"
     ]
    }
   ],
   "source": [
    "# GPU Device\n",
    "gpu_id = 0\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(\"GPU device %d:\" %(gpu_id), use_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = '/media/data2/dataset/GAN_ImageData/StyleGAN2_256/'\n",
    "target_dir = '/media/data2/dataset/GAN_ImageData/StarGAN_128/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained = './log/style2/128/b0/aug/checkpoint.pth.tar'\n",
    "resume = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model_name = 'efficientnet-b0' # b0-b7 scale\n",
    "\n",
    "# Optimization\n",
    "num_classes = 2\n",
    "epochs = 1000\n",
    "start_epoch = 0\n",
    "train_batch = 500\n",
    "test_batch = 500\n",
    "lr = 0.01\n",
    "schedule = [50, 250, 500, 750]\n",
    "momentum = 0.1\n",
    "gamma = 0.1 # LR is multiplied by gamma on schedule\n",
    "\n",
    "# CheckPoint\n",
    "checkpoint = './log/style2/128/b0/to_star/2000shot/general' # dir\n",
    "if not os.path.isdir(checkpoint):\n",
    "    os.makedirs(checkpoint)\n",
    "num_workers = 8\n",
    "\n",
    "# Seed\n",
    "manual_seed = 7\n",
    "random.seed(manual_seed)\n",
    "torch.cuda.manual_seed_all(manual_seed)\n",
    "\n",
    "# Image\n",
    "size = (128, 128)\n",
    "\n",
    "# cutmix\n",
    "cm_prob = 0.2\n",
    "cm_beta = 1.0\n",
    "\n",
    "# augmentation\n",
    "blur_prob = 0.2\n",
    "blog_sig = 0.5\n",
    "jpg_prob = 0.2\n",
    "\n",
    "best_acc = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {}\n",
    "state['num_classes'] = num_classes\n",
    "state['epochs'] = epochs\n",
    "state['start_epoch'] = start_epoch\n",
    "state['train_batch'] = train_batch\n",
    "state['test_batch'] = test_batch\n",
    "state['lr'] = lr\n",
    "state['schedule'] = schedule\n",
    "state['momentum'] = momentum\n",
    "state['gamma'] = gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_augment(img):\n",
    "    img = np.array(img)\n",
    "\n",
    "    if random.random() < blur_prob:\n",
    "        sig = np.random.uniform(0.0, 3.0)\n",
    "        gaussian_blur(img, sig)\n",
    "\n",
    "    if random.random() < jpg_prob:\n",
    "        qual = np.random.uniform(30.0, 100.0)\n",
    "        img = cv2_jpg(img, qual)\n",
    "\n",
    "    return Image.fromarray(img)\n",
    "\n",
    "\n",
    "def gaussian_blur(img, sigma):\n",
    "    gaussian_filter(img[:,:,0], output=img[:,:,0], sigma=sigma)\n",
    "    gaussian_filter(img[:,:,1], output=img[:,:,1], sigma=sigma)\n",
    "    gaussian_filter(img[:,:,2], output=img[:,:,2], sigma=sigma)\n",
    "\n",
    "\n",
    "def cv2_jpg(img, compress_val):\n",
    "    img_cv2 = img[:,:,::-1]\n",
    "    encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), compress_val]\n",
    "    result, encimg = cv2.imencode('.jpg', img_cv2, encode_param)\n",
    "    decimg = cv2.imdecode(encimg, 1)\n",
    "    return decimg[:,:,::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_bbox(size, lam):\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = np.int(W * cut_rat)\n",
    "    cut_h = np.int(H * cut_rat)\n",
    "\n",
    "    # uniform\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join(source_dir, 'star/2000_shot_only')\n",
    "val_target_dir = os.path.join(target_dir, 'validation')\n",
    "val_source_dir = os.path.join(source_dir, 'validation')\n",
    "\n",
    "train_aug = transforms.Compose([\n",
    "    transforms.Lambda(lambda img: data_augment(img)),\n",
    "    transforms.Resize(size),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "#     transforms.RandomErasing(p=0.3, scale=(0.02, 0.10), ratio=(0.3, 3.3), value=0, inplace=True),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "val_aug = transforms.Compose([\n",
    "    transforms.Resize(size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# pin_memory : cuda pin memeory use\n",
    "train_loader = DataLoader(datasets.ImageFolder(train_dir, transform=train_aug),\n",
    "                          batch_size=train_batch, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "val_target_loader = DataLoader(datasets.ImageFolder(val_target_dir, val_aug),\n",
    "                       batch_size=test_batch, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "val_source_loader = DataLoader(datasets.ImageFolder(val_source_dir, val_aug),\n",
    "                       batch_size=test_batch, shuffle=True, num_workers=num_workers, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> using pre-trained model './log/style2/128/b0/aug/checkpoint.pth.tar'\n"
     ]
    }
   ],
   "source": [
    "student_model = EfficientNet.from_name(model_name, num_classes=num_classes,\n",
    "                              override_params={'dropout_rate':0.2, 'drop_connect_rate':0.2})\n",
    "\n",
    "# Pre-trained\n",
    "if pretrained:\n",
    "    print(\"=> using pre-trained model '{}'\".format(pretrained))\n",
    "    student_model.load_state_dict(torch.load(pretrained)['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Total params: 4.01M\n"
     ]
    }
   ],
   "source": [
    "student_model.to('cuda')\n",
    "cudnn.benchmark = True\n",
    "print('    Total params: %.2fM' % (sum(p.numel() for p in student_model.parameters())/1000000.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, param in enumerate(student_model.parameters()):\n",
    "    param.reqiures_grad = False\n",
    "    if idx == 182:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "# optimizer = optim.SGD(student_model.parameters(), lr=lr, momentum=momentum)\n",
    "optimizer = optim.Adam(student_model.parameters())\n",
    "scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)\n",
    "scheduler_warmup = GradualWarmupScheduler(optimizer, multiplier=4, total_epoch=10, after_scheduler=scheduler_cosine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resume\n",
    "if resume:\n",
    "    print('==> Resuming from checkpoint..')\n",
    "    checkpoint = os.path.dirname(resume)\n",
    "#     checkpoint = torch.load(resume)\n",
    "    resume = torch.load(resume)\n",
    "    best_acc = resume['best_acc']\n",
    "    start_epoch = resume['epoch']\n",
    "    student_model.load_state_dict(resume['state_dict'])\n",
    "    optimizer.load_state_dict(resume['optimizer'])\n",
    "    logger = Logger(os.path.join(checkpoint, 'log.txt'), resume=True)\n",
    "else:\n",
    "    logger = Logger(os.path.join(checkpoint, 'log.txt'))\n",
    "    logger.set_names(['Learning Rate', 'Train Loss', 'Valid Loss', 'Source Loss', 'Train Acc.', 'Valid Acc.', 'Source ACC.', 'Train AUROC', 'Valid AUROC', 'Source AUROC'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch, use_cuda):\n",
    "    model.train()\n",
    "    \n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    arc = AverageMeter()\n",
    "    end = time.time()\n",
    "    cls_losses = AverageMeter()\n",
    "    sp_losses = AverageMeter()\n",
    "    main_losses = AverageMeter()\n",
    "    \n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        batch_size = inputs.size(0)\n",
    "        if batch_size < train_batch:\n",
    "            continue\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            \n",
    "        r = np.random.rand(1)\n",
    "        if cm_beta > 0 and r < cm_prob:\n",
    "            \n",
    "            rand_index = torch.randperm(inputs.size()[0]).cuda()\n",
    "            tt= targets[rand_index]\n",
    "            boolean = targets==tt\n",
    "            rand_index = rand_index[boolean]\n",
    "            lam = np.random.beta(cm_beta, cm_beta)\n",
    "            bbx1, bby1, bbx2, bby2 = rand_bbox(inputs.size(), lam)\n",
    "            inputs[boolean, :, bbx1:bbx2, bby1:bby2] = inputs[rand_index, :, bbx1:bbx2, bby1:bby2]\n",
    "\n",
    "        # compute output\n",
    "        outputs = model(inputs)\n",
    "        loss_main = criterion(outputs, targets)\n",
    "        loss =  loss_main\n",
    "        loss_cls = 0\n",
    "        loss_sp = 0\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1 = accuracy(outputs.data, targets.data)\n",
    "#         auroc = roc_auc_score(targets.cpu().detach().numpy(), outputs.cpu().detach().numpy()[:,1])\n",
    "        losses.update(loss.data.tolist(), inputs.size(0))\n",
    "        top1.update(prec1[0], inputs.size(0))\n",
    "#         arc.update(auroc, inputs.size(0))\n",
    "        cls_losses.update(loss_cls, inputs.size(0))\n",
    "        sp_losses.update(loss_sp, inputs.size(0))\n",
    "        main_losses.update(loss_main.tolist(), inputs.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        \n",
    "#         if batch_idx % 100 == 0:\n",
    "#             print('{batch}/{size} | Loss:{loss:.4f} | MainLoss:{main:.4f} | SPLoss:{sp:.4f} | CLSLoss:{cls:.4f} | top1:{tp1:.4f} | AUROC:{ac:.4f}'.format(\n",
    "#                      batch=batch_idx+1, size=len(train_loader), loss=losses.avg, main=main_losses.avg, sp=sp_losses.avg, cls=cls_losses.avg, tp1=top1.avg, ac=arc.avg))\n",
    "    print('Train | {batch}/{size} | Loss:{loss:.4f} | MainLoss:{main:.4f} | SPLoss:{sp:.4f} | CLSLoss:{cls:.4f} | top1:{tp1:.4f} | AUROC:{ac:.4f}'.format(\n",
    "                     batch=batch_idx+1, size=len(train_loader), loss=losses.avg, main=main_losses.avg, sp=sp_losses.avg, cls=cls_losses.avg, tp1=top1.avg, ac=arc.avg))\n",
    "    return (losses.avg, top1.avg, arc.avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(val_loader, model, criterion, epoch, use_cuda):\n",
    "    global best_acc\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    arc = AverageMeter()\n",
    "    cls_losses = AverageMeter()\n",
    "    sp_losses = AverageMeter()\n",
    "    main_losses = AverageMeter()\n",
    "\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(val_loader):\n",
    "            # measure data loading time\n",
    "            data_time.update(time.time() - end)\n",
    "\n",
    "            if use_cuda:\n",
    "                inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "            # compute output\n",
    "            outputs = model(inputs)\n",
    "            loss_main = criterion(outputs, targets)\n",
    "            loss = loss_main\n",
    "            loss_cls = 0\n",
    "            loss_sp = 0\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            prec1 = accuracy(outputs.data, targets.data)\n",
    "            auroc = roc_auc_score(targets.cpu().detach().numpy(), outputs.cpu().detach().numpy()[:,1])\n",
    "            losses.update(loss.data.tolist(), inputs.size(0))\n",
    "            top1.update(prec1[0], inputs.size(0))\n",
    "            arc.update(auroc, inputs.size(0))\n",
    "            cls_losses.update(loss_cls, inputs.size(0))\n",
    "            sp_losses.update(loss_sp, inputs.size(0))\n",
    "            main_losses.update(loss_main.tolist(), inputs.size(0))\n",
    "\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "    print('Test | {batch}/{size} | Loss:{loss:.4f} | MainLoss:{main:.4f} | SPLoss:{sp:.4f} | CLSLoss:{cls:.4f} | top1:{tp1:.4f} | AUROC:{ac:.4f}'.format(\n",
    "                     batch=batch_idx+1, size=len(train_loader), loss=losses.avg, main=main_losses.avg, sp=sp_losses.avg, cls=cls_losses.avg, tp1=top1.avg, ac=arc.avg))\n",
    "    return (losses.avg, top1.avg, arc.avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, checkpoint='checkpoint', filename='checkpoint.pth.tar'):\n",
    "    filepath = os.path.join(checkpoint, filename)\n",
    "    torch.save(state, filepath)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filepath, os.path.join(checkpoint, 'model_best.pth.tar'))\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    global state\n",
    "    lr_set = [1, 1e-1, 1e-2, 1e-3, 1e-4, 1e-5]\n",
    "    lr_list = schedule.copy()\n",
    "    lr_list.append(epoch)\n",
    "    lr_list.sort()\n",
    "    idx = lr_list.index(epoch)\n",
    "    state['lr'] *= lr_set[idx]\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = state['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [1 | 1000] LR: 0.001000\n",
      "Train | 8/8 | Loss:1.2232 | MainLoss:1.2232 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:50.6500 | AUROC:0.0000\n",
      "Test | 62/8 | Loss:0.6940 | MainLoss:0.6940 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:50.1474 | AUROC:0.5007\n",
      "Test | 16/8 | Loss:0.6039 | MainLoss:0.6039 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:52.2821 | AUROC:0.9217\n",
      "\n",
      "Epoch: [2 | 1000] LR: 0.001300\n",
      "Train | 8/8 | Loss:0.6958 | MainLoss:0.6958 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:49.0500 | AUROC:0.0000\n",
      "Test | 62/8 | Loss:0.6936 | MainLoss:0.6936 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:49.9836 | AUROC:0.5004\n",
      "Test | 16/8 | Loss:0.7238 | MainLoss:0.7238 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:44.1410 | AUROC:0.0373\n",
      "\n",
      "Epoch: [3 | 1000] LR: 0.001600\n",
      "Train | 8/8 | Loss:0.6964 | MainLoss:0.6964 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:49.7750 | AUROC:0.0000\n",
      "Test | 62/8 | Loss:0.6984 | MainLoss:0.6984 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:50.0000 | AUROC:0.4976\n",
      "Test | 16/8 | Loss:0.7158 | MainLoss:0.7158 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:50.0000 | AUROC:0.1144\n",
      "\n",
      "Epoch: [4 | 1000] LR: 0.001900\n",
      "Train | 8/8 | Loss:0.6950 | MainLoss:0.6950 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:49.8500 | AUROC:0.0000\n",
      "Test | 62/8 | Loss:0.6935 | MainLoss:0.6935 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:50.1802 | AUROC:0.5019\n",
      "Test | 16/8 | Loss:0.7137 | MainLoss:0.7137 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:13.8462 | AUROC:0.0471\n",
      "\n",
      "Epoch: [5 | 1000] LR: 0.002200\n",
      "Train | 8/8 | Loss:0.6943 | MainLoss:0.6943 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:50.0250 | AUROC:0.0000\n",
      "Test | 62/8 | Loss:0.6958 | MainLoss:0.6958 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:50.0000 | AUROC:0.5039\n",
      "Test | 16/8 | Loss:0.7167 | MainLoss:0.7167 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:50.0000 | AUROC:0.0451\n",
      "\n",
      "Epoch: [6 | 1000] LR: 0.002500\n",
      "Train | 8/8 | Loss:0.6953 | MainLoss:0.6953 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:48.8000 | AUROC:0.0000\n",
      "Test | 62/8 | Loss:0.6931 | MainLoss:0.6931 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:50.4063 | AUROC:0.5078\n",
      "Test | 16/8 | Loss:0.7135 | MainLoss:0.7135 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:41.3462 | AUROC:0.0395\n",
      "\n",
      "Epoch: [7 | 1000] LR: 0.002800\n",
      "Train | 8/8 | Loss:0.6940 | MainLoss:0.6940 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:49.1250 | AUROC:0.0000\n",
      "Test | 62/8 | Loss:0.6931 | MainLoss:0.6931 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:50.2425 | AUROC:0.5102\n",
      "Test | 16/8 | Loss:0.7143 | MainLoss:0.7143 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:12.5256 | AUROC:0.0345\n",
      "\n",
      "Epoch: [8 | 1000] LR: 0.003100\n",
      "Train | 8/8 | Loss:0.6934 | MainLoss:0.6934 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:50.2500 | AUROC:0.0000\n",
      "Test | 62/8 | Loss:0.6930 | MainLoss:0.6930 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:50.8585 | AUROC:0.5133\n",
      "Test | 16/8 | Loss:0.7151 | MainLoss:0.7151 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:20.4231 | AUROC:0.0388\n",
      "\n",
      "Epoch: [9 | 1000] LR: 0.003400\n",
      "Train | 8/8 | Loss:0.6948 | MainLoss:0.6948 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:49.9500 | AUROC:0.0000\n",
      "Test | 62/8 | Loss:0.6934 | MainLoss:0.6934 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:49.9640 | AUROC:0.5179\n",
      "Test | 16/8 | Loss:0.7180 | MainLoss:0.7180 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:49.9359 | AUROC:0.0429\n",
      "\n",
      "Epoch: [10 | 1000] LR: 0.003700\n",
      "Train | 8/8 | Loss:0.6934 | MainLoss:0.6934 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:51.1000 | AUROC:0.0000\n",
      "Test | 62/8 | Loss:0.6932 | MainLoss:0.6932 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:50.2654 | AUROC:0.5209\n",
      "Test | 16/8 | Loss:0.7199 | MainLoss:0.7199 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:11.7564 | AUROC:0.0386\n",
      "\n",
      "Epoch: [11 | 1000] LR: 0.004000\n",
      "Train | 8/8 | Loss:0.6931 | MainLoss:0.6931 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:50.6750 | AUROC:0.0000\n",
      "Test | 62/8 | Loss:0.6930 | MainLoss:0.6930 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:50.3997 | AUROC:0.5253\n",
      "Test | 16/8 | Loss:0.7162 | MainLoss:0.7162 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:17.0128 | AUROC:0.0780\n",
      "\n",
      "Epoch: [12 | 1000] LR: 0.004000\n",
      "Train | 8/8 | Loss:0.6924 | MainLoss:0.6924 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:51.1750 | AUROC:0.0000\n",
      "Test | 62/8 | Loss:0.6940 | MainLoss:0.6940 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:50.2851 | AUROC:0.5292\n",
      "Test | 16/8 | Loss:0.7226 | MainLoss:0.7226 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:49.3333 | AUROC:0.1416\n",
      "\n",
      "Epoch: [13 | 1000] LR: 0.004000\n",
      "Train | 8/8 | Loss:0.6915 | MainLoss:0.6915 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:51.5250 | AUROC:0.0000\n",
      "Test | 62/8 | Loss:0.6916 | MainLoss:0.6916 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:52.1134 | AUROC:0.5386\n",
      "Test | 16/8 | Loss:0.7375 | MainLoss:0.7375 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:21.6667 | AUROC:0.1273\n",
      "\n",
      "Epoch: [14 | 1000] LR: 0.004000\n",
      "Train | 8/8 | Loss:0.6881 | MainLoss:0.6881 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:54.0750 | AUROC:0.0000\n",
      "Test | 62/8 | Loss:0.7016 | MainLoss:0.7016 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:51.3237 | AUROC:0.5435\n",
      "Test | 16/8 | Loss:0.7064 | MainLoss:0.7064 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:46.6538 | AUROC:0.5208\n",
      "\n",
      "Epoch: [15 | 1000] LR: 0.004000\n",
      "Train | 8/8 | Loss:0.6809 | MainLoss:0.6809 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:56.5500 | AUROC:0.0000\n",
      "Test | 62/8 | Loss:0.6861 | MainLoss:0.6861 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:54.9214 | AUROC:0.5686\n",
      "Test | 16/8 | Loss:0.7367 | MainLoss:0.7367 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:34.9103 | AUROC:0.3351\n",
      "\n",
      "Epoch: [16 | 1000] LR: 0.004000\n",
      "Train | 8/8 | Loss:0.6782 | MainLoss:0.6782 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:57.0500 | AUROC:0.0000\n",
      "Test | 62/8 | Loss:0.6877 | MainLoss:0.6877 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:54.9083 | AUROC:0.5720\n",
      "Test | 16/8 | Loss:0.7350 | MainLoss:0.7350 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:40.4872 | AUROC:0.3754\n",
      "\n",
      "Epoch: [17 | 1000] LR: 0.004000\n",
      "Train | 8/8 | Loss:0.6688 | MainLoss:0.6688 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:58.8750 | AUROC:0.0000\n",
      "Test | 62/8 | Loss:0.6841 | MainLoss:0.6841 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:56.1959 | AUROC:0.5939\n",
      "Test | 16/8 | Loss:0.7493 | MainLoss:0.7493 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:42.6538 | AUROC:0.4074\n",
      "\n",
      "Epoch: [18 | 1000] LR: 0.004000\n",
      "Train | 8/8 | Loss:0.6562 | MainLoss:0.6562 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:61.0250 | AUROC:0.0000\n",
      "Test | 62/8 | Loss:0.7042 | MainLoss:0.7042 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:54.5806 | AUROC:0.6157\n",
      "Test | 16/8 | Loss:0.7878 | MainLoss:0.7878 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:45.0385 | AUROC:0.3630\n",
      "\n",
      "Epoch: [19 | 1000] LR: 0.004000\n",
      "Train | 8/8 | Loss:0.6456 | MainLoss:0.6456 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:62.0000 | AUROC:0.0000\n",
      "Test | 62/8 | Loss:0.6624 | MainLoss:0.6624 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:60.3899 | AUROC:0.6473\n",
      "Test | 16/8 | Loss:0.7769 | MainLoss:0.7769 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:43.9359 | AUROC:0.4165\n",
      "\n",
      "Epoch: [20 | 1000] LR: 0.003999\n",
      "Train | 8/8 | Loss:0.6427 | MainLoss:0.6427 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:63.0250 | AUROC:0.0000\n",
      "Test | 62/8 | Loss:0.6602 | MainLoss:0.6602 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:60.4980 | AUROC:0.6627\n",
      "Test | 16/8 | Loss:0.7705 | MainLoss:0.7705 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:43.1923 | AUROC:0.3990\n",
      "\n",
      "Epoch: [21 | 1000] LR: 0.003999\n",
      "Train | 8/8 | Loss:0.6202 | MainLoss:0.6202 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:66.2750 | AUROC:0.0000\n",
      "Test | 62/8 | Loss:0.6541 | MainLoss:0.6541 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:62.3198 | AUROC:0.6792\n",
      "Test | 16/8 | Loss:0.8172 | MainLoss:0.8172 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:44.9744 | AUROC:0.4178\n",
      "\n",
      "Epoch: [22 | 1000] LR: 0.003999\n",
      "Train | 8/8 | Loss:0.5974 | MainLoss:0.5974 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:68.9000 | AUROC:0.0000\n",
      "Test | 62/8 | Loss:0.6202 | MainLoss:0.6202 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:66.2549 | AUROC:0.7188\n",
      "Test | 16/8 | Loss:0.9083 | MainLoss:0.9083 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:44.2179 | AUROC:0.3947\n",
      "\n",
      "Epoch: [23 | 1000] LR: 0.003999\n",
      "Train | 8/8 | Loss:0.5482 | MainLoss:0.5482 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:73.0250 | AUROC:0.0000\n",
      "Test | 62/8 | Loss:0.5988 | MainLoss:0.5988 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:68.3683 | AUROC:0.7477\n",
      "Test | 16/8 | Loss:0.9271 | MainLoss:0.9271 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:46.4359 | AUROC:0.4350\n",
      "\n",
      "Epoch: [24 | 1000] LR: 0.003999\n",
      "Train | 8/8 | Loss:0.5823 | MainLoss:0.5823 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:71.3000 | AUROC:0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 62/8 | Loss:0.6276 | MainLoss:0.6276 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:65.3899 | AUROC:0.7246\n",
      "Test | 16/8 | Loss:0.8206 | MainLoss:0.8206 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:45.1026 | AUROC:0.4372\n",
      "\n",
      "Epoch: [25 | 1000] LR: 0.003998\n",
      "Train | 8/8 | Loss:0.5407 | MainLoss:0.5407 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:73.2750 | AUROC:0.0000\n",
      "Test | 62/8 | Loss:0.6237 | MainLoss:0.6237 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:67.0970 | AUROC:0.7716\n",
      "Test | 16/8 | Loss:0.9210 | MainLoss:0.9210 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:43.9487 | AUROC:0.4089\n",
      "\n",
      "Epoch: [26 | 1000] LR: 0.003998\n",
      "Train | 8/8 | Loss:0.5525 | MainLoss:0.5525 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:72.5250 | AUROC:0.0000\n",
      "Test | 62/8 | Loss:0.5774 | MainLoss:0.5774 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:69.9115 | AUROC:0.7718\n",
      "Test | 16/8 | Loss:0.8874 | MainLoss:0.8874 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:44.5769 | AUROC:0.4253\n",
      "\n",
      "Epoch: [27 | 1000] LR: 0.003998\n",
      "Train | 8/8 | Loss:0.5039 | MainLoss:0.5039 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:76.2250 | AUROC:0.0000\n",
      "Test | 62/8 | Loss:0.5557 | MainLoss:0.5557 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:71.9561 | AUROC:0.7930\n",
      "Test | 16/8 | Loss:0.9697 | MainLoss:0.9697 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:44.6923 | AUROC:0.4189\n",
      "\n",
      "Epoch: [28 | 1000] LR: 0.003997\n",
      "Train | 8/8 | Loss:0.4798 | MainLoss:0.4798 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:76.9250 | AUROC:0.0000\n",
      "Test | 62/8 | Loss:0.5763 | MainLoss:0.5763 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:70.3670 | AUROC:0.7943\n",
      "Test | 16/8 | Loss:1.0279 | MainLoss:1.0279 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:48.4872 | AUROC:0.4709\n",
      "\n",
      "Epoch: [29 | 1000] LR: 0.003997\n",
      "Train | 8/8 | Loss:0.5026 | MainLoss:0.5026 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:76.1000 | AUROC:0.0000\n",
      "Test | 62/8 | Loss:0.5883 | MainLoss:0.5883 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:69.8296 | AUROC:0.7990\n",
      "Test | 16/8 | Loss:1.0332 | MainLoss:1.0332 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:47.6538 | AUROC:0.4563\n",
      "\n",
      "Epoch: [30 | 1000] LR: 0.003997\n",
      "Train | 8/8 | Loss:0.4777 | MainLoss:0.4777 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:77.6250 | AUROC:0.0000\n",
      "Test | 62/8 | Loss:0.5741 | MainLoss:0.5741 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:71.5531 | AUROC:0.7911\n",
      "Test | 16/8 | Loss:1.0367 | MainLoss:1.0367 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:47.2308 | AUROC:0.4441\n",
      "\n",
      "Epoch: [31 | 1000] LR: 0.003996\n",
      "Train | 8/8 | Loss:0.4433 | MainLoss:0.4433 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:79.9000 | AUROC:0.0000\n",
      "Test | 62/8 | Loss:0.5243 | MainLoss:0.5243 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:73.8598 | AUROC:0.8184\n",
      "Test | 16/8 | Loss:0.9842 | MainLoss:0.9842 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:48.6538 | AUROC:0.4702\n",
      "\n",
      "Epoch: [32 | 1000] LR: 0.003996\n",
      "Train | 8/8 | Loss:0.4083 | MainLoss:0.4083 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:81.5250 | AUROC:0.0000\n",
      "Test | 62/8 | Loss:0.5234 | MainLoss:0.5234 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:75.6225 | AUROC:0.8364\n",
      "Test | 16/8 | Loss:1.2397 | MainLoss:1.2397 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:46.0000 | AUROC:0.4131\n",
      "\n",
      "Epoch: [33 | 1000] LR: 0.003996\n",
      "Train | 8/8 | Loss:0.3805 | MainLoss:0.3805 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:83.1000 | AUROC:0.0000\n",
      "Test | 62/8 | Loss:0.5491 | MainLoss:0.5491 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:74.7182 | AUROC:0.8318\n",
      "Test | 16/8 | Loss:1.2696 | MainLoss:1.2696 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:47.9487 | AUROC:0.4398\n",
      "\n",
      "Epoch: [34 | 1000] LR: 0.003995\n",
      "Train | 8/8 | Loss:0.4440 | MainLoss:0.4440 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:78.7000 | AUROC:0.0000\n",
      "Test | 62/8 | Loss:0.5219 | MainLoss:0.5219 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:74.6298 | AUROC:0.8266\n",
      "Test | 16/8 | Loss:1.0783 | MainLoss:1.0783 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:47.7308 | AUROC:0.4350\n",
      "\n",
      "Epoch: [35 | 1000] LR: 0.003995\n",
      "Train | 8/8 | Loss:0.3979 | MainLoss:0.3979 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:81.6500 | AUROC:0.0000\n",
      "Test | 62/8 | Loss:0.5176 | MainLoss:0.5176 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:75.4489 | AUROC:0.8424\n",
      "Test | 16/8 | Loss:1.1550 | MainLoss:1.1550 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:45.8590 | AUROC:0.4255\n",
      "\n",
      "Epoch: [36 | 1000] LR: 0.003994\n",
      "Train | 8/8 | Loss:0.3521 | MainLoss:0.3521 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:84.2250 | AUROC:0.0000\n",
      "Test | 62/8 | Loss:0.5383 | MainLoss:0.5383 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:76.3630 | AUROC:0.8428\n",
      "Test | 16/8 | Loss:1.3036 | MainLoss:1.3036 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:48.5641 | AUROC:0.4587\n",
      "\n",
      "Epoch: [37 | 1000] LR: 0.003994\n",
      "Train | 8/8 | Loss:0.3600 | MainLoss:0.3600 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:83.8250 | AUROC:0.0000\n",
      "Test | 62/8 | Loss:0.4948 | MainLoss:0.4948 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:77.5721 | AUROC:0.8566\n",
      "Test | 16/8 | Loss:1.2503 | MainLoss:1.2503 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:49.4744 | AUROC:0.4916\n",
      "\n",
      "Epoch: [38 | 1000] LR: 0.003993\n",
      "Train | 8/8 | Loss:0.3375 | MainLoss:0.3375 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:84.7500 | AUROC:0.0000\n",
      "Test | 62/8 | Loss:0.5224 | MainLoss:0.5224 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:77.2379 | AUROC:0.8530\n",
      "Test | 16/8 | Loss:1.3216 | MainLoss:1.3216 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:49.0641 | AUROC:0.4809\n",
      "\n",
      "Epoch: [39 | 1000] LR: 0.003993\n",
      "Train | 8/8 | Loss:0.3085 | MainLoss:0.3085 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:86.6000 | AUROC:0.0000\n",
      "Test | 62/8 | Loss:0.7047 | MainLoss:0.7047 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:73.3585 | AUROC:0.8713\n",
      "Test | 16/8 | Loss:1.2903 | MainLoss:1.2903 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:47.7949 | AUROC:0.4700\n",
      "\n",
      "Epoch: [40 | 1000] LR: 0.003992\n",
      "Train | 8/8 | Loss:0.4245 | MainLoss:0.4245 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:80.3750 | AUROC:0.0000\n",
      "Test | 62/8 | Loss:0.5260 | MainLoss:0.5260 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:74.9246 | AUROC:0.8349\n",
      "Test | 16/8 | Loss:1.0646 | MainLoss:1.0646 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:47.9231 | AUROC:0.4682\n",
      "\n",
      "Epoch: [41 | 1000] LR: 0.003992\n",
      "Train | 8/8 | Loss:0.3499 | MainLoss:0.3499 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:85.0500 | AUROC:0.0000\n",
      "Test | 62/8 | Loss:0.5030 | MainLoss:0.5030 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:77.3657 | AUROC:0.8533\n",
      "Test | 16/8 | Loss:1.1933 | MainLoss:1.1933 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:49.8333 | AUROC:0.4936\n",
      "\n",
      "Epoch: [42 | 1000] LR: 0.003991\n",
      "Train | 8/8 | Loss:0.3302 | MainLoss:0.3302 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:85.3750 | AUROC:0.0000\n",
      "Test | 62/8 | Loss:0.5065 | MainLoss:0.5065 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:78.3159 | AUROC:0.8660\n",
      "Test | 16/8 | Loss:1.3879 | MainLoss:1.3879 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:47.7179 | AUROC:0.4544\n",
      "\n",
      "Epoch: [43 | 1000] LR: 0.003991\n",
      "Train | 8/8 | Loss:0.3129 | MainLoss:0.3129 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:85.7000 | AUROC:0.0000\n",
      "Test | 62/8 | Loss:0.5269 | MainLoss:0.5269 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:77.4738 | AUROC:0.8575\n",
      "Test | 16/8 | Loss:1.4146 | MainLoss:1.4146 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:47.4103 | AUROC:0.4520\n",
      "\n",
      "Epoch: [44 | 1000] LR: 0.003990\n",
      "Train | 8/8 | Loss:0.3064 | MainLoss:0.3064 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:86.1500 | AUROC:0.0000\n",
      "Test | 62/8 | Loss:0.5613 | MainLoss:0.5613 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:76.7792 | AUROC:0.8706\n",
      "Test | 16/8 | Loss:1.3472 | MainLoss:1.3472 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:48.7308 | AUROC:0.4719\n",
      "\n",
      "Epoch: [45 | 1000] LR: 0.003989\n",
      "Train | 8/8 | Loss:0.3088 | MainLoss:0.3088 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:86.4250 | AUROC:0.0000\n",
      "Test | 62/8 | Loss:0.5025 | MainLoss:0.5025 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:78.6468 | AUROC:0.8716\n",
      "Test | 16/8 | Loss:1.3275 | MainLoss:1.3275 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:48.8205 | AUROC:0.4798\n",
      "\n",
      "Epoch: [46 | 1000] LR: 0.003989\n",
      "Train | 8/8 | Loss:0.2793 | MainLoss:0.2793 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:87.8750 | AUROC:0.0000\n",
      "Test | 62/8 | Loss:0.5148 | MainLoss:0.5148 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:79.0990 | AUROC:0.8739\n",
      "Test | 16/8 | Loss:1.4998 | MainLoss:1.4998 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:49.5641 | AUROC:0.4839\n",
      "\n",
      "Epoch: [47 | 1000] LR: 0.003988\n",
      "Train | 8/8 | Loss:0.2798 | MainLoss:0.2798 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:87.3250 | AUROC:0.0000\n",
      "Test | 62/8 | Loss:0.5119 | MainLoss:0.5119 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:77.9391 | AUROC:0.8747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test | 16/8 | Loss:1.5180 | MainLoss:1.5180 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:49.3718 | AUROC:0.4860\n",
      "\n",
      "Epoch: [48 | 1000] LR: 0.003987\n",
      "Train | 8/8 | Loss:0.2713 | MainLoss:0.2713 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:88.4250 | AUROC:0.0000\n",
      "Test | 62/8 | Loss:0.5881 | MainLoss:0.5881 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:78.4207 | AUROC:0.8752\n",
      "Test | 16/8 | Loss:1.9331 | MainLoss:1.9331 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:48.7179 | AUROC:0.4553\n",
      "\n",
      "Epoch: [49 | 1000] LR: 0.003987\n",
      "Train | 8/8 | Loss:0.3227 | MainLoss:0.3227 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:85.9500 | AUROC:0.0000\n",
      "Test | 62/8 | Loss:0.5346 | MainLoss:0.5346 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:76.0616 | AUROC:0.8558\n",
      "Test | 16/8 | Loss:1.3711 | MainLoss:1.3711 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:48.8462 | AUROC:0.4657\n",
      "\n",
      "Epoch: [50 | 1000] LR: 0.003986\n",
      "Train | 8/8 | Loss:0.2885 | MainLoss:0.2885 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:87.5500 | AUROC:0.0000\n",
      "Test | 62/8 | Loss:0.5145 | MainLoss:0.5145 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:78.5223 | AUROC:0.8683\n",
      "Test | 16/8 | Loss:1.4024 | MainLoss:1.4024 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:47.2692 | AUROC:0.4463\n",
      "\n",
      "Epoch: [51 | 1000] LR: 0.003985\n",
      "Train | 8/8 | Loss:0.2698 | MainLoss:0.2698 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:88.2000 | AUROC:0.0000\n",
      "Test | 62/8 | Loss:0.5371 | MainLoss:0.5371 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:77.9620 | AUROC:0.8774\n",
      "Test | 16/8 | Loss:1.4669 | MainLoss:1.4669 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:45.4487 | AUROC:0.4283\n",
      "\n",
      "Epoch: [52 | 1000] LR: 0.000398\n",
      "Train | 8/8 | Loss:0.2593 | MainLoss:0.2593 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:88.6750 | AUROC:0.0000\n",
      "Test | 62/8 | Loss:0.4915 | MainLoss:0.4915 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:79.5708 | AUROC:0.8796\n",
      "Test | 16/8 | Loss:1.6575 | MainLoss:1.6575 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:46.8846 | AUROC:0.4285\n",
      "\n",
      "Epoch: [53 | 1000] LR: 0.000398\n",
      "Train | 8/8 | Loss:0.2420 | MainLoss:0.2420 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:90.0000 | AUROC:0.0000\n",
      "Test | 62/8 | Loss:0.5051 | MainLoss:0.5051 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:79.7903 | AUROC:0.8838\n",
      "Test | 16/8 | Loss:1.6075 | MainLoss:1.6075 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:46.3333 | AUROC:0.4324\n",
      "\n",
      "Epoch: [54 | 1000] LR: 0.000398\n",
      "Train | 8/8 | Loss:0.2380 | MainLoss:0.2380 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:90.4250 | AUROC:0.0000\n",
      "Test | 62/8 | Loss:0.4966 | MainLoss:0.4966 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:80.1671 | AUROC:0.8847\n",
      "Test | 16/8 | Loss:1.7284 | MainLoss:1.7284 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:46.9744 | AUROC:0.4377\n",
      "\n",
      "Epoch: [55 | 1000] LR: 0.000398\n",
      "Train | 8/8 | Loss:0.2133 | MainLoss:0.2133 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:91.7250 | AUROC:0.0000\n",
      "Test | 62/8 | Loss:0.5048 | MainLoss:0.5048 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:80.3670 | AUROC:0.8867\n",
      "Test | 16/8 | Loss:1.6858 | MainLoss:1.6858 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:46.6795 | AUROC:0.4390\n",
      "\n",
      "Epoch: [56 | 1000] LR: 0.000398\n",
      "Train | 8/8 | Loss:0.2054 | MainLoss:0.2054 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:91.1000 | AUROC:0.0000\n",
      "Test | 62/8 | Loss:0.5146 | MainLoss:0.5146 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:80.4751 | AUROC:0.8862\n",
      "Test | 16/8 | Loss:1.7553 | MainLoss:1.7553 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:46.9103 | AUROC:0.4394\n",
      "\n",
      "Epoch: [57 | 1000] LR: 0.000398\n",
      "Train | 8/8 | Loss:0.2067 | MainLoss:0.2067 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:90.9750 | AUROC:0.0000\n",
      "Test | 62/8 | Loss:0.5238 | MainLoss:0.5238 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:80.4751 | AUROC:0.8863\n",
      "Test | 16/8 | Loss:1.7545 | MainLoss:1.7545 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:46.9615 | AUROC:0.4439\n",
      "\n",
      "Epoch: [58 | 1000] LR: 0.000398\n",
      "Train | 8/8 | Loss:0.1813 | MainLoss:0.1813 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:92.9000 | AUROC:0.0000\n",
      "Test | 62/8 | Loss:0.5373 | MainLoss:0.5373 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:80.3342 | AUROC:0.8848\n",
      "Test | 16/8 | Loss:1.7761 | MainLoss:1.7761 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:46.9615 | AUROC:0.4468\n",
      "\n",
      "Epoch: [59 | 1000] LR: 0.000398\n",
      "Train | 8/8 | Loss:0.2020 | MainLoss:0.2020 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:91.6750 | AUROC:0.0000\n",
      "Test | 62/8 | Loss:0.5371 | MainLoss:0.5371 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:80.2949 | AUROC:0.8833\n",
      "Test | 16/8 | Loss:1.8008 | MainLoss:1.8008 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:47.2564 | AUROC:0.4468\n",
      "\n",
      "Epoch: [60 | 1000] LR: 0.000398\n",
      "Train | 8/8 | Loss:0.1863 | MainLoss:0.1863 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:92.7000 | AUROC:0.0000\n",
      "Test | 62/8 | Loss:0.5613 | MainLoss:0.5613 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:80.0262 | AUROC:0.8842\n",
      "Test | 16/8 | Loss:1.7682 | MainLoss:1.7682 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:47.2692 | AUROC:0.4495\n",
      "\n",
      "Epoch: [61 | 1000] LR: 0.000398\n",
      "Train | 8/8 | Loss:0.2160 | MainLoss:0.2160 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:91.6750 | AUROC:0.0000\n",
      "Test | 62/8 | Loss:0.5401 | MainLoss:0.5401 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:80.1114 | AUROC:0.8823\n",
      "Test | 16/8 | Loss:1.8107 | MainLoss:1.8107 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:47.4359 | AUROC:0.4491\n",
      "\n",
      "Epoch: [62 | 1000] LR: 0.000398\n",
      "Train | 8/8 | Loss:0.1880 | MainLoss:0.1880 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:92.5250 | AUROC:0.0000\n",
      "Test | 62/8 | Loss:0.5416 | MainLoss:0.5416 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:80.2097 | AUROC:0.8834\n",
      "Test | 16/8 | Loss:1.8448 | MainLoss:1.8448 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:47.1410 | AUROC:0.4484\n",
      "\n",
      "Epoch: [63 | 1000] LR: 0.000397\n",
      "Train | 8/8 | Loss:0.1765 | MainLoss:0.1765 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:92.9500 | AUROC:0.0000\n",
      "Test | 62/8 | Loss:0.5650 | MainLoss:0.5650 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:80.1278 | AUROC:0.8853\n",
      "Test | 16/8 | Loss:1.8296 | MainLoss:1.8296 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:47.1667 | AUROC:0.4482\n",
      "\n",
      "Epoch: [64 | 1000] LR: 0.000397\n",
      "Train | 8/8 | Loss:0.1701 | MainLoss:0.1701 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:93.5500 | AUROC:0.0000\n",
      "Test | 62/8 | Loss:0.5633 | MainLoss:0.5633 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:80.2064 | AUROC:0.8828\n",
      "Test | 16/8 | Loss:1.9253 | MainLoss:1.9253 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:47.2949 | AUROC:0.4496\n",
      "\n",
      "Epoch: [65 | 1000] LR: 0.000397\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(start_epoch, epochs):\n",
    "    state['lr'] = optimizer.state_dict()['param_groups'][0]['lr']\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "    print('\\nEpoch: [%d | %d] LR: %f' % (epoch + 1, epochs, state['lr']))\n",
    "    \n",
    "    train_loss, train_acc, train_auroc = train(train_loader, student_model, criterion, optimizer, epoch, use_cuda)\n",
    "    test_loss, test_acc, test_auroc = test(val_target_loader, student_model, criterion, epoch, use_cuda)\n",
    "    source_loss, source_acc, source_auroc = test(val_source_loader, student_model, criterion, epoch, use_cuda)\n",
    "\n",
    "\n",
    "    logger.append([state['lr'], train_loss, test_loss,  source_loss, train_acc, test_acc,source_acc, train_auroc, test_auroc, source_auroc])\n",
    "    is_best = test_acc > best_acc\n",
    "    best_acc = max(test_acc, best_acc)\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'state_dict' : student_model.state_dict(),\n",
    "        'acc': test_acc,\n",
    "        'best_acc': best_acc,\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    }, is_best, checkpoint=checkpoint)\n",
    "    scheduler_warmup.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
