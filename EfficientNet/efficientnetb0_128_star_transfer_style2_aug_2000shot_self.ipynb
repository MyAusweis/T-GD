{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import collections\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "\n",
    "from model_pytorch import EfficientNet\n",
    "from utils import Bar,Logger, AverageMeter, accuracy, mkdir_p, savefig\n",
    "from warmup_scheduler import GradualWarmupScheduler\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "import cv2\n",
    "\n",
    "from PIL import ImageFile, ImageOps\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU device 2: True\n"
     ]
    }
   ],
   "source": [
    "# GPU Device\n",
    "gpu_id = 2\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(\"GPU device %d:\" %(gpu_id), use_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = '/media/data2/dataset/GAN_ImageData/StarGAN_128/'\n",
    "target_dir = '/media/data2/dataset/GAN_ImageData/StyleGAN2_256/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained = './log/star/128/b0/aug/checkpoint.pth.tar'\n",
    "resume = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model_name = 'efficientnet-b0' # b0-b7 scale\n",
    "\n",
    "# Optimization\n",
    "num_classes = 2\n",
    "epochs = 1000\n",
    "start_epoch = 0\n",
    "train_batch = 250\n",
    "test_batch = 250\n",
    "lr = 0.04\n",
    "schedule = [50, 250, 500, 750]\n",
    "momentum = 0.1\n",
    "gamma = 0.1 # LR is multiplied by gamma on schedule\n",
    "\n",
    "# CheckPoint\n",
    "checkpoint = './log/star/128/b0/to_style2/2000shot/self' # dir\n",
    "if not os.path.isdir(checkpoint):\n",
    "    os.makedirs(checkpoint)\n",
    "num_workers = 8\n",
    "\n",
    "# Seed\n",
    "manual_seed = 7\n",
    "random.seed(manual_seed)\n",
    "torch.cuda.manual_seed_all(manual_seed)\n",
    "\n",
    "# Image\n",
    "size = (128, 128)\n",
    "\n",
    "# cutmix\n",
    "cm_prob = 0.5\n",
    "cm_beta = 1.0\n",
    "\n",
    "# augmentation\n",
    "blur_prob = 0.5\n",
    "blog_sig = 0.5\n",
    "jpg_prob = 0.5\n",
    "\n",
    "best_acc = 0\n",
    "\n",
    "# sp\n",
    "sp_alpha = 0.1\n",
    "sp_beta = 0.1\n",
    "fc_name = '_fc.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {}\n",
    "state['num_classes'] = num_classes\n",
    "state['epochs'] = epochs\n",
    "state['start_epoch'] = start_epoch\n",
    "state['train_batch'] = train_batch\n",
    "state['test_batch'] = test_batch\n",
    "state['lr'] = lr\n",
    "state['schedule'] = schedule\n",
    "state['momentum'] = momentum\n",
    "state['gamma'] = gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_augment(img):\n",
    "    img = np.array(img)\n",
    "\n",
    "    if random.random() < blur_prob:\n",
    "        sig = np.random.uniform(0.0, 3.0)\n",
    "        gaussian_blur(img, sig)\n",
    "\n",
    "    if random.random() < jpg_prob:\n",
    "        qual = np.random.uniform(30.0, 100.0)\n",
    "        img = cv2_jpg(img, qual)\n",
    "\n",
    "    return Image.fromarray(img)\n",
    "\n",
    "\n",
    "def gaussian_blur(img, sigma):\n",
    "    gaussian_filter(img[:,:,0], output=img[:,:,0], sigma=sigma)\n",
    "    gaussian_filter(img[:,:,1], output=img[:,:,1], sigma=sigma)\n",
    "    gaussian_filter(img[:,:,2], output=img[:,:,2], sigma=sigma)\n",
    "\n",
    "\n",
    "def cv2_jpg(img, compress_val):\n",
    "    img_cv2 = img[:,:,::-1]\n",
    "    encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), compress_val]\n",
    "    result, encimg = cv2.imencode('.jpg', img_cv2, encode_param)\n",
    "    decimg = cv2.imdecode(encimg, 1)\n",
    "    return decimg[:,:,::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_bbox(size, lam):\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = np.int(W * cut_rat)\n",
    "    cut_h = np.int(H * cut_rat)\n",
    "\n",
    "    # uniform\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join(source_dir, 'style2/2000_shot_only')\n",
    "val_target_dir = os.path.join(target_dir, 'validation')\n",
    "val_source_dir = os.path.join(source_dir, 'validation')\n",
    "\n",
    "train_aug = transforms.Compose([\n",
    "    transforms.Lambda(lambda img: data_augment(img)),\n",
    "    transforms.Resize(size),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "val_aug = transforms.Compose([\n",
    "    transforms.Resize(size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# pin_memory : cuda pin memeory use\n",
    "train_loader = DataLoader(datasets.ImageFolder(train_dir, transform=train_aug),\n",
    "                          batch_size=train_batch, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "val_target_loader = DataLoader(datasets.ImageFolder(val_target_dir, val_aug),\n",
    "                       batch_size=test_batch, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "val_source_loader = DataLoader(datasets.ImageFolder(val_source_dir, val_aug),\n",
    "                       batch_size=test_batch, shuffle=True, num_workers=num_workers, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> using pre-trained model './log/star/128/b0/aug/checkpoint.pth.tar'\n"
     ]
    }
   ],
   "source": [
    "teacher_model = EfficientNet.from_name(model_name, num_classes=num_classes,\n",
    "                              override_params={'dropout_rate':0.2, 'drop_connect_rate':0.2})\n",
    "student_model = EfficientNet.from_name(model_name, num_classes=num_classes,\n",
    "                              override_params={'dropout_rate':0.2, 'drop_connect_rate':0.2})\n",
    "\n",
    "# Pre-trained\n",
    "if pretrained:\n",
    "    print(\"=> using pre-trained model '{}'\".format(pretrained))\n",
    "    teacher_model.load_state_dict(torch.load(pretrained)['state_dict'])\n",
    "    student_model.load_state_dict(torch.load(pretrained)['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Total params: 4.01M\n"
     ]
    }
   ],
   "source": [
    "teacher_model.to('cuda')\n",
    "student_model.to('cuda')\n",
    "cudnn.benchmark = True\n",
    "print('    Total params: %.2fM' % (sum(p.numel() for p in teacher_model.parameters())/1000000.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = optim.SGD(student_model.parameters(), lr=lr, momentum=momentum)\n",
    "# optimizer = optim.Adam(student_model.parameters())\n",
    "scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)\n",
    "scheduler_warmup = GradualWarmupScheduler(optimizer, multiplier=4, total_epoch=10, after_scheduler=scheduler_cosine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resume\n",
    "if resume:\n",
    "    print('==> Resuming from checkpoint..')\n",
    "    checkpoint = os.path.dirname(resume)\n",
    "#     checkpoint = torch.load(resume)\n",
    "    resume = torch.load(resume)\n",
    "    best_acc = resume['best_acc']\n",
    "    start_epoch = resume['epoch']\n",
    "    student_model.load_state_dict(resume['state_dict'])\n",
    "    optimizer.load_state_dict(resume['optimizer'])\n",
    "    logger = Logger(os.path.join(checkpoint, 'log.txt'), resume=True)\n",
    "else:\n",
    "    logger = Logger(os.path.join(checkpoint, 'log.txt'))\n",
    "    logger.set_names(['Learning Rate', 'Train Loss', 'Valid Loss', 'Source Loss', 'Train Acc.', 'Valid Acc.', 'Source ACC.', 'Train AUROC', 'Valid AUROC', 'Source AUROC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EfficientNet(\n",
       "  (_conv_stem): Conv2dStaticSamePadding(\n",
       "    3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
       "    (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "  )\n",
       "  (_gn0): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "  (_blocks): ModuleList(\n",
       "    (0): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        32, 32, kernel_size=(3, 3), stride=[1, 1], groups=32, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        32, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        8, 32, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 16, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (1): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 96, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        96, 96, kernel_size=(3, 3), stride=[2, 2], groups=96, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 96, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        96, 4, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        4, 96, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 24, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (2): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 144, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 144, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 24, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (3): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 144, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        144, 144, kernel_size=(5, 5), stride=[2, 2], groups=144, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 144, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 40, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (4): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 240, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        240, 240, kernel_size=(5, 5), stride=(1, 1), groups=240, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 240, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 40, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (5): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 240, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        240, 240, kernel_size=(3, 3), stride=[2, 2], groups=240, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 240, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 80, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (6): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 480, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 480, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 80, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (7): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 480, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 480, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 80, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (8): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 480, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        480, 480, kernel_size=(5, 5), stride=[1, 1], groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 480, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 112, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (9): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 672, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 672, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 112, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (10): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 672, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 672, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 112, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (11): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 672, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5), stride=[2, 2], groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 672, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 192, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (12): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 1152, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 1152, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 192, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (13): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 1152, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 1152, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 192, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (14): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 1152, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 1152, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 192, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (15): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 1152, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(3, 3), stride=[1, 1], groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 1152, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 320, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "  )\n",
       "  (_conv_head): Conv2dStaticSamePadding(\n",
       "    320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "    (static_padding): Identity()\n",
       "  )\n",
       "  (_gn1): GroupNorm(8, 1280, eps=1e-05, affine=True)\n",
       "  (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n",
       "  (_dropout): Dropout(p=0.2, inplace=False)\n",
       "  (_fc): Linear(in_features=1280, out_features=2, bias=True)\n",
       "  (_swish): MemoryEfficientSwish()\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for param in teacher_model.parameters():\n",
    "    param.requires_grad = False\n",
    "teacher_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_model_weights = {}\n",
    "for name, param in teacher_model.named_parameters():\n",
    "    teacher_model_weights[name] = param.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_cls(model):\n",
    "    l2_cls = torch.tensor(0.).cuda()\n",
    "    for name, param in model.named_parameters():\n",
    "        if name.startswith(fc_name):\n",
    "            l2_cls += 0.5 * torch.norm(param) ** 2\n",
    "    return l2_cls\n",
    "\n",
    "def reg_l2sp(model):\n",
    "    sp_loss = torch.tensor(0.).cuda()\n",
    "    for name, param in model.named_parameters():\n",
    "        if not name.startswith(fc_name):\n",
    "            sp_loss += 0.5 * torch.norm(param - teacher_model_weights[name]) ** 2\n",
    "    return sp_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, teacher_model, student_model, criterion, optimizer, epoch, use_cuda):\n",
    "    teacher_model.eval()\n",
    "    student_model.train()\n",
    "    \n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    arc = AverageMeter()\n",
    "    end = time.time()\n",
    "    cls_losses = AverageMeter()\n",
    "    sp_losses = AverageMeter()\n",
    "    main_losses = AverageMeter()\n",
    "    alpha = AverageMeter()\n",
    "    \n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        batch_size = inputs.size(0)\n",
    "        if batch_size < train_batch:\n",
    "            continue\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            \n",
    "        r = np.random.rand(1)\n",
    "        if cm_beta > 0 and r < cm_prob:\n",
    "            \n",
    "            rand_index = torch.randperm(inputs.size()[0]).cuda()\n",
    "            tt= targets[rand_index]\n",
    "            boolean = targets==tt\n",
    "            rand_index = rand_index[boolean]\n",
    "            lam = np.random.beta(cm_beta, cm_beta)\n",
    "            bbx1, bby1, bbx2, bby2 = rand_bbox(inputs.size(), lam)\n",
    "            inputs[boolean, :, bbx1:bbx2, bby1:bby2] = inputs[rand_index, :, bbx1:bbx2, bby1:bby2]\n",
    "\n",
    "        # compute output\n",
    "        with torch.no_grad():\n",
    "            teacher_outputs = teacher_model(inputs)\n",
    "            teacher_loss = criterion(teacher_outputs, targets)\n",
    "            sp_alpha = 0\n",
    "            sigmoid = nn.Sigmoid()\n",
    "            sp_alpha += sigmoid(-teacher_loss)\n",
    "        \n",
    "        outputs = student_model(inputs)\n",
    "        loss_main = criterion(outputs, targets)\n",
    "        loss_cls = 0\n",
    "        loss_sp = 0\n",
    "        loss_cls = reg_cls(student_model)\n",
    "        loss_sp = reg_l2sp(student_model)\n",
    "        loss =  loss_main + sp_alpha*loss_sp + loss_cls\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1 = accuracy(outputs.data, targets.data)\n",
    "        losses.update(loss.data.tolist(), inputs.size(0))\n",
    "        top1.update(prec1[0], inputs.size(0))\n",
    "        cls_losses.update(loss_cls, inputs.size(0))\n",
    "        sp_losses.update(loss_sp, inputs.size(0))\n",
    "        main_losses.update(loss_main.tolist(), inputs.size(0))\n",
    "        alpha.update(sp_alpha, inputs.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        \n",
    "#         if batch_idx % 100 == 0:\n",
    "#             print('{batch}/{size} | Loss:{loss:.4f} | MainLoss:{main:.4f} | SPLoss:{sp:.4f} | CLSLoss:{cls:.4f} | top1:{tp1:.4f} | AUROC:{ac:.4f}'.format(\n",
    "#                      batch=batch_idx+1, size=len(train_loader), loss=losses.avg, main=main_losses.avg, sp=sp_losses.avg, cls=cls_losses.avg, tp1=top1.avg, ac=arc.avg))\n",
    "    print('Train | {batch}/{size} | Loss:{loss:.4f} | MainLoss:{main:.4f} | Alpha:{alp:.4f} | SPLoss:{sp:.4f} | CLSLoss:{cls:.4f} | top1:{tp1:.4f} | AUROC:{ac:.4f}'.format(\n",
    "                     batch=batch_idx+1, size=len(train_loader), loss=losses.avg, main=main_losses.avg, alp=alpha.avg, sp=sp_losses.avg, cls=cls_losses.avg, tp1=top1.avg, ac=arc.avg))\n",
    "    return (losses.avg, top1.avg, arc.avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(val_loader, model, criterion, epoch, use_cuda):\n",
    "    global best_acc\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    arc = AverageMeter()\n",
    "    cls_losses = AverageMeter()\n",
    "    sp_losses = AverageMeter()\n",
    "    main_losses = AverageMeter()\n",
    "\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(val_loader):\n",
    "            # measure data loading time\n",
    "            data_time.update(time.time() - end)\n",
    "\n",
    "            if use_cuda:\n",
    "                inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "            # compute output\n",
    "            outputs = model(inputs)\n",
    "            loss_main = criterion(outputs, targets)\n",
    "            loss_cls = 0\n",
    "            loss_sp = 0\n",
    "            loss_cls = reg_cls(model)\n",
    "            loss_sp = reg_l2sp(model)\n",
    "            loss = loss_main + 0*loss_sp + 0*loss_cls\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            prec1 = accuracy(outputs.data, targets.data)\n",
    "            auroc = roc_auc_score(targets.cpu().detach().numpy(), outputs.cpu().detach().numpy()[:,1])\n",
    "            losses.update(loss.data.tolist(), inputs.size(0))\n",
    "            top1.update(prec1[0], inputs.size(0))\n",
    "            arc.update(auroc, inputs.size(0))\n",
    "            cls_losses.update(loss_cls, inputs.size(0))\n",
    "            sp_losses.update(loss_sp, inputs.size(0))\n",
    "            main_losses.update(loss_main.tolist(), inputs.size(0))\n",
    "\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "    print('Test | {batch}/{size} | Loss:{loss:.4f} | MainLoss:{main:.4f} | SPLoss:{sp:.4f} | CLSLoss:{cls:.4f} | top1:{tp1:.4f} | AUROC:{ac:.4f}'.format(\n",
    "                     batch=batch_idx+1, size=len(train_loader), loss=losses.avg, main=main_losses.avg, sp=sp_losses.avg, cls=cls_losses.avg, tp1=top1.avg, ac=arc.avg))\n",
    "    return (losses.avg, top1.avg, arc.avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, checkpoint='checkpoint', filename='checkpoint.pth.tar'):\n",
    "    filepath = os.path.join(checkpoint, filename)\n",
    "    torch.save(state, filepath)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filepath, os.path.join(checkpoint, 'model_best.pth.tar'))\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    global state\n",
    "    lr_set = [1, 1e-1, 1e-2, 1e-3, 1e-4, 1e-5]\n",
    "    lr_list = schedule.copy()\n",
    "    lr_list.append(epoch)\n",
    "    lr_list.sort()\n",
    "    idx = lr_list.index(epoch)\n",
    "    state['lr'] *= lr_set[idx]\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = state['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [1 | 1000] LR: 0.040000\n",
      "Train | 16/16 | Loss:2.0930 | MainLoss:0.9990 | Alpha:0.0494 | SPLoss:0.5048 | CLSLoss:1.0687 | top1:50.4000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6891 | MainLoss:0.6891 | SPLoss:0.5587 | CLSLoss:0.4621 | top1:53.0513 | AUROC:0.5569\n",
      "Test | 123/16 | Loss:0.5445 | MainLoss:0.5445 | SPLoss:0.5587 | CLSLoss:0.4621 | top1:81.8644 | AUROC:0.9887\n",
      "\n",
      "Epoch: [2 | 1000] LR: 0.052000\n",
      "Train | 16/16 | Loss:0.9196 | MainLoss:0.6921 | Alpha:0.3336 | SPLoss:0.0002 | CLSLoss:0.2274 | top1:51.8933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6903 | MainLoss:0.6903 | SPLoss:0.0004 | CLSLoss:0.0768 | top1:54.4615 | AUROC:0.5679\n",
      "Test | 123/16 | Loss:0.6242 | MainLoss:0.6242 | SPLoss:0.0004 | CLSLoss:0.0768 | top1:76.8676 | AUROC:0.9882\n",
      "\n",
      "Epoch: [3 | 1000] LR: 0.064000\n",
      "Train | 16/16 | Loss:0.7253 | MainLoss:0.6919 | Alpha:0.3337 | SPLoss:0.0001 | CLSLoss:0.0334 | top1:53.6000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6919 | MainLoss:0.6919 | SPLoss:0.0001 | CLSLoss:0.0086 | top1:54.7051 | AUROC:0.5742\n",
      "Test | 123/16 | Loss:0.6680 | MainLoss:0.6680 | SPLoss:0.0001 | CLSLoss:0.0086 | top1:77.7752 | AUROC:0.9874\n",
      "\n",
      "Epoch: [4 | 1000] LR: 0.076000\n",
      "Train | 16/16 | Loss:0.6962 | MainLoss:0.6928 | Alpha:0.3335 | SPLoss:0.0000 | CLSLoss:0.0034 | top1:52.2400 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6928 | MainLoss:0.6928 | SPLoss:0.0000 | CLSLoss:0.0007 | top1:55.1923 | AUROC:0.5755\n",
      "Test | 123/16 | Loss:0.6857 | MainLoss:0.6857 | SPLoss:0.0000 | CLSLoss:0.0007 | top1:69.5610 | AUROC:0.9869\n",
      "\n",
      "Epoch: [5 | 1000] LR: 0.088000\n",
      "Train | 16/16 | Loss:0.6934 | MainLoss:0.6930 | Alpha:0.3334 | SPLoss:0.0000 | CLSLoss:0.0003 | top1:50.6400 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6930 | MainLoss:0.6930 | SPLoss:0.0000 | CLSLoss:0.0001 | top1:50.0256 | AUROC:0.5769\n",
      "Test | 123/16 | Loss:0.6906 | MainLoss:0.6906 | SPLoss:0.0000 | CLSLoss:0.0001 | top1:72.6737 | AUROC:0.9868\n",
      "\n",
      "Epoch: [6 | 1000] LR: 0.100000\n",
      "Train | 16/16 | Loss:0.6932 | MainLoss:0.6932 | Alpha:0.3334 | SPLoss:0.0000 | CLSLoss:0.0001 | top1:48.9333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6931 | MainLoss:0.6931 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:53.6538 | AUROC:0.5768\n",
      "Test | 123/16 | Loss:0.6914 | MainLoss:0.6914 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:59.5151 | AUROC:0.9869\n",
      "\n",
      "Epoch: [7 | 1000] LR: 0.112000\n",
      "Train | 16/16 | Loss:0.6932 | MainLoss:0.6932 | Alpha:0.3333 | SPLoss:0.0000 | CLSLoss:0.0001 | top1:49.4933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6931 | MainLoss:0.6931 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:55.0897 | AUROC:0.5778\n",
      "Test | 123/16 | Loss:0.6916 | MainLoss:0.6916 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:64.1514 | AUROC:0.9866\n",
      "\n",
      "Epoch: [8 | 1000] LR: 0.124000\n",
      "Train | 16/16 | Loss:0.6933 | MainLoss:0.6933 | Alpha:0.3333 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:47.8400 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6931 | MainLoss:0.6931 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:51.9359 | AUROC:0.5779\n",
      "Test | 123/16 | Loss:0.6914 | MainLoss:0.6914 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:92.5131 | AUROC:0.9868\n",
      "\n",
      "Epoch: [9 | 1000] LR: 0.136000\n",
      "Train | 16/16 | Loss:0.6931 | MainLoss:0.6931 | Alpha:0.3333 | SPLoss:0.0000 | CLSLoss:0.0001 | top1:50.7467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6931 | MainLoss:0.6931 | SPLoss:0.0000 | CLSLoss:0.0001 | top1:50.0000 | AUROC:0.5788\n",
      "Test | 123/16 | Loss:0.6915 | MainLoss:0.6915 | SPLoss:0.0000 | CLSLoss:0.0001 | top1:50.0000 | AUROC:0.9865\n",
      "\n",
      "Epoch: [10 | 1000] LR: 0.148000\n",
      "Train | 16/16 | Loss:0.6933 | MainLoss:0.6932 | Alpha:0.3333 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:49.2000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6931 | MainLoss:0.6931 | SPLoss:0.0000 | CLSLoss:0.0001 | top1:50.0000 | AUROC:0.5783\n",
      "Test | 123/16 | Loss:0.6916 | MainLoss:0.6916 | SPLoss:0.0000 | CLSLoss:0.0001 | top1:50.0066 | AUROC:0.9865\n",
      "\n",
      "Epoch: [11 | 1000] LR: 0.160000\n",
      "Train | 16/16 | Loss:0.6932 | MainLoss:0.6930 | Alpha:0.3333 | SPLoss:0.0000 | CLSLoss:0.0002 | top1:51.0667 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6931 | MainLoss:0.6931 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:50.8462 | AUROC:0.5784\n",
      "Test | 123/16 | Loss:0.6916 | MainLoss:0.6916 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:93.9810 | AUROC:0.9865\n",
      "\n",
      "Epoch: [12 | 1000] LR: 0.160000\n",
      "Train | 16/16 | Loss:0.6932 | MainLoss:0.6932 | Alpha:0.3333 | SPLoss:0.0000 | CLSLoss:0.0001 | top1:50.0800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6931 | MainLoss:0.6931 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:50.0897 | AUROC:0.5791\n",
      "Test | 123/16 | Loss:0.6918 | MainLoss:0.6918 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:79.0793 | AUROC:0.9864\n",
      "\n",
      "Epoch: [13 | 1000] LR: 0.160000\n",
      "Train | 16/16 | Loss:0.6932 | MainLoss:0.6932 | Alpha:0.3333 | SPLoss:0.0000 | CLSLoss:0.0001 | top1:49.8400 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6932 | MainLoss:0.6932 | SPLoss:0.0000 | CLSLoss:0.0003 | top1:50.0000 | AUROC:0.5796\n",
      "Test | 123/16 | Loss:0.6915 | MainLoss:0.6915 | SPLoss:0.0000 | CLSLoss:0.0003 | top1:50.0000 | AUROC:0.9863\n",
      "\n",
      "Epoch: [14 | 1000] LR: 0.159998\n",
      "Train | 16/16 | Loss:0.6933 | MainLoss:0.6932 | Alpha:0.3333 | SPLoss:0.0000 | CLSLoss:0.0001 | top1:51.0667 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6931 | MainLoss:0.6931 | SPLoss:0.0000 | CLSLoss:0.0001 | top1:50.0000 | AUROC:0.5797\n",
      "Test | 123/16 | Loss:0.6918 | MainLoss:0.6918 | SPLoss:0.0000 | CLSLoss:0.0001 | top1:50.0000 | AUROC:0.9862\n",
      "\n",
      "Epoch: [15 | 1000] LR: 0.159996\n",
      "Train | 16/16 | Loss:0.6933 | MainLoss:0.6932 | Alpha:0.3333 | SPLoss:0.0000 | CLSLoss:0.0001 | top1:49.7067 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6931 | MainLoss:0.6931 | SPLoss:0.0000 | CLSLoss:0.0001 | top1:50.0000 | AUROC:0.5797\n",
      "Test | 123/16 | Loss:0.6913 | MainLoss:0.6913 | SPLoss:0.0000 | CLSLoss:0.0001 | top1:50.0000 | AUROC:0.9860\n",
      "\n",
      "Epoch: [16 | 1000] LR: 0.159994\n",
      "Train | 16/16 | Loss:0.6932 | MainLoss:0.6932 | Alpha:0.3333 | SPLoss:0.0000 | CLSLoss:0.0001 | top1:50.2667 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6931 | MainLoss:0.6931 | SPLoss:0.0000 | CLSLoss:0.0001 | top1:50.0000 | AUROC:0.5807\n",
      "Test | 123/16 | Loss:0.6917 | MainLoss:0.6917 | SPLoss:0.0000 | CLSLoss:0.0001 | top1:50.0000 | AUROC:0.9860\n",
      "\n",
      "Epoch: [17 | 1000] LR: 0.159990\n",
      "Train | 16/16 | Loss:0.6933 | MainLoss:0.6932 | Alpha:0.3333 | SPLoss:0.0000 | CLSLoss:0.0001 | top1:49.2533 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6931 | MainLoss:0.6931 | SPLoss:0.0000 | CLSLoss:0.0001 | top1:50.0000 | AUROC:0.5802\n",
      "Test | 123/16 | Loss:0.6915 | MainLoss:0.6915 | SPLoss:0.0000 | CLSLoss:0.0001 | top1:50.0000 | AUROC:0.9858\n",
      "\n",
      "Epoch: [18 | 1000] LR: 0.159986\n",
      "Train | 16/16 | Loss:0.6932 | MainLoss:0.6932 | Alpha:0.3334 | SPLoss:0.0000 | CLSLoss:0.0001 | top1:50.4533 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6931 | MainLoss:0.6931 | SPLoss:0.0000 | CLSLoss:0.0001 | top1:50.0000 | AUROC:0.5825\n",
      "Test | 123/16 | Loss:0.6919 | MainLoss:0.6919 | SPLoss:0.0000 | CLSLoss:0.0001 | top1:50.0000 | AUROC:0.9857\n",
      "\n",
      "Epoch: [19 | 1000] LR: 0.159981\n",
      "Train | 16/16 | Loss:0.6932 | MainLoss:0.6932 | Alpha:0.3333 | SPLoss:0.0000 | CLSLoss:0.0001 | top1:49.5733 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6931 | MainLoss:0.6931 | SPLoss:0.0000 | CLSLoss:0.0002 | top1:50.0000 | AUROC:0.5807\n",
      "Test | 123/16 | Loss:0.6915 | MainLoss:0.6915 | SPLoss:0.0000 | CLSLoss:0.0002 | top1:50.0000 | AUROC:0.9857\n",
      "\n",
      "Epoch: [20 | 1000] LR: 0.159975\n",
      "Train | 16/16 | Loss:0.6932 | MainLoss:0.6931 | Alpha:0.3333 | SPLoss:0.0000 | CLSLoss:0.0001 | top1:50.3200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6931 | MainLoss:0.6931 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:50.0385 | AUROC:0.5814\n",
      "Test | 123/16 | Loss:0.6915 | MainLoss:0.6915 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:74.5675 | AUROC:0.9856\n",
      "\n",
      "Epoch: [21 | 1000] LR: 0.159968\n",
      "Train | 16/16 | Loss:0.6933 | MainLoss:0.6933 | Alpha:0.3333 | SPLoss:0.0000 | CLSLoss:0.0001 | top1:50.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6930 | MainLoss:0.6930 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:53.6923 | AUROC:0.5834\n",
      "Test | 123/16 | Loss:0.6913 | MainLoss:0.6913 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:87.6900 | AUROC:0.9852\n",
      "\n",
      "Epoch: [22 | 1000] LR: 0.159961\n",
      "Train | 16/16 | Loss:0.6932 | MainLoss:0.6931 | Alpha:0.3334 | SPLoss:0.0000 | CLSLoss:0.0001 | top1:50.0800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6930 | MainLoss:0.6930 | SPLoss:0.0000 | CLSLoss:0.0001 | top1:50.0000 | AUROC:0.5841\n",
      "Test | 123/16 | Loss:0.6910 | MainLoss:0.6910 | SPLoss:0.0000 | CLSLoss:0.0001 | top1:50.0000 | AUROC:0.9852\n",
      "\n",
      "Epoch: [23 | 1000] LR: 0.159952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 16/16 | Loss:0.6932 | MainLoss:0.6932 | Alpha:0.3334 | SPLoss:0.0000 | CLSLoss:0.0001 | top1:49.8933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6930 | MainLoss:0.6930 | SPLoss:0.0000 | CLSLoss:0.0001 | top1:50.1667 | AUROC:0.5837\n",
      "Test | 123/16 | Loss:0.6911 | MainLoss:0.6911 | SPLoss:0.0000 | CLSLoss:0.0001 | top1:79.5904 | AUROC:0.9849\n",
      "\n",
      "Epoch: [24 | 1000] LR: 0.159943\n",
      "Train | 16/16 | Loss:0.6932 | MainLoss:0.6931 | Alpha:0.3334 | SPLoss:0.0000 | CLSLoss:0.0001 | top1:50.1600 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6930 | MainLoss:0.6930 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:50.6154 | AUROC:0.5859\n",
      "Test | 123/16 | Loss:0.6913 | MainLoss:0.6913 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:91.8480 | AUROC:0.9848\n",
      "\n",
      "Epoch: [25 | 1000] LR: 0.159933\n",
      "Train | 16/16 | Loss:0.6932 | MainLoss:0.6932 | Alpha:0.3333 | SPLoss:0.0000 | CLSLoss:0.0001 | top1:50.0533 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6930 | MainLoss:0.6930 | SPLoss:0.0000 | CLSLoss:0.0001 | top1:50.0897 | AUROC:0.5847\n",
      "Test | 123/16 | Loss:0.6910 | MainLoss:0.6910 | SPLoss:0.0000 | CLSLoss:0.0001 | top1:50.3997 | AUROC:0.9845\n",
      "\n",
      "Epoch: [26 | 1000] LR: 0.159923\n",
      "Train | 16/16 | Loss:0.6933 | MainLoss:0.6932 | Alpha:0.3334 | SPLoss:0.0000 | CLSLoss:0.0001 | top1:50.1867 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6930 | MainLoss:0.6930 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:51.4744 | AUROC:0.5863\n",
      "Test | 123/16 | Loss:0.6912 | MainLoss:0.6912 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:53.6959 | AUROC:0.9845\n",
      "\n",
      "Epoch: [27 | 1000] LR: 0.159911\n",
      "Train | 16/16 | Loss:0.6932 | MainLoss:0.6931 | Alpha:0.3334 | SPLoss:0.0000 | CLSLoss:0.0001 | top1:50.1067 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6931 | MainLoss:0.6931 | SPLoss:0.0000 | CLSLoss:0.0001 | top1:50.0000 | AUROC:0.5863\n",
      "Test | 123/16 | Loss:0.6914 | MainLoss:0.6914 | SPLoss:0.0000 | CLSLoss:0.0001 | top1:50.0000 | AUROC:0.9840\n",
      "\n",
      "Epoch: [28 | 1000] LR: 0.159899\n",
      "Train | 16/16 | Loss:0.6931 | MainLoss:0.6930 | Alpha:0.3333 | SPLoss:0.0000 | CLSLoss:0.0001 | top1:51.4133 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6931 | MainLoss:0.6931 | SPLoss:0.0000 | CLSLoss:0.0002 | top1:50.0000 | AUROC:0.5867\n",
      "Test | 123/16 | Loss:0.6913 | MainLoss:0.6913 | SPLoss:0.0000 | CLSLoss:0.0002 | top1:50.0000 | AUROC:0.9839\n",
      "\n",
      "Epoch: [29 | 1000] LR: 0.159886\n",
      "Train | 16/16 | Loss:0.6934 | MainLoss:0.6933 | Alpha:0.3333 | SPLoss:0.0000 | CLSLoss:0.0001 | top1:49.6000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6930 | MainLoss:0.6930 | SPLoss:0.0000 | CLSLoss:0.0001 | top1:50.0000 | AUROC:0.5869\n",
      "Test | 123/16 | Loss:0.6910 | MainLoss:0.6910 | SPLoss:0.0000 | CLSLoss:0.0001 | top1:50.0000 | AUROC:0.9838\n",
      "\n",
      "Epoch: [30 | 1000] LR: 0.159872\n",
      "Train | 16/16 | Loss:0.6933 | MainLoss:0.6932 | Alpha:0.3334 | SPLoss:0.0000 | CLSLoss:0.0001 | top1:50.7467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6930 | MainLoss:0.6930 | SPLoss:0.0000 | CLSLoss:0.0001 | top1:50.2179 | AUROC:0.5887\n",
      "Test | 123/16 | Loss:0.6907 | MainLoss:0.6907 | SPLoss:0.0000 | CLSLoss:0.0001 | top1:78.4895 | AUROC:0.9834\n",
      "\n",
      "Epoch: [31 | 1000] LR: 0.159858\n",
      "Train | 16/16 | Loss:0.6932 | MainLoss:0.6931 | Alpha:0.3334 | SPLoss:0.0000 | CLSLoss:0.0001 | top1:50.4000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6930 | MainLoss:0.6930 | SPLoss:0.0000 | CLSLoss:0.0001 | top1:50.4231 | AUROC:0.5891\n",
      "Test | 123/16 | Loss:0.6910 | MainLoss:0.6910 | SPLoss:0.0000 | CLSLoss:0.0001 | top1:51.2811 | AUROC:0.9831\n",
      "\n",
      "Epoch: [32 | 1000] LR: 0.159842\n",
      "Train | 16/16 | Loss:0.6932 | MainLoss:0.6930 | Alpha:0.3334 | SPLoss:0.0000 | CLSLoss:0.0002 | top1:51.4667 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6930 | MainLoss:0.6930 | SPLoss:0.0000 | CLSLoss:0.0002 | top1:50.0000 | AUROC:0.5884\n",
      "Test | 123/16 | Loss:0.6908 | MainLoss:0.6908 | SPLoss:0.0000 | CLSLoss:0.0002 | top1:50.0000 | AUROC:0.9828\n",
      "\n",
      "Epoch: [33 | 1000] LR: 0.159826\n",
      "Train | 16/16 | Loss:0.6933 | MainLoss:0.6931 | Alpha:0.3334 | SPLoss:0.0000 | CLSLoss:0.0002 | top1:49.8933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6930 | MainLoss:0.6930 | SPLoss:0.0000 | CLSLoss:0.0001 | top1:50.0000 | AUROC:0.5909\n",
      "Test | 123/16 | Loss:0.6910 | MainLoss:0.6910 | SPLoss:0.0000 | CLSLoss:0.0001 | top1:51.3073 | AUROC:0.9824\n",
      "\n",
      "Epoch: [34 | 1000] LR: 0.159809\n",
      "Train | 16/16 | Loss:0.6933 | MainLoss:0.6932 | Alpha:0.3334 | SPLoss:0.0000 | CLSLoss:0.0001 | top1:49.1467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6930 | MainLoss:0.6930 | SPLoss:0.0000 | CLSLoss:0.0001 | top1:50.1282 | AUROC:0.5923\n",
      "Test | 123/16 | Loss:0.6906 | MainLoss:0.6906 | SPLoss:0.0000 | CLSLoss:0.0001 | top1:72.9030 | AUROC:0.9822\n",
      "\n",
      "Epoch: [35 | 1000] LR: 0.159791\n",
      "Train | 16/16 | Loss:0.6931 | MainLoss:0.6930 | Alpha:0.3334 | SPLoss:0.0000 | CLSLoss:0.0001 | top1:50.0533 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6930 | MainLoss:0.6930 | SPLoss:0.0000 | CLSLoss:0.0002 | top1:50.0000 | AUROC:0.5918\n",
      "Test | 123/16 | Loss:0.6906 | MainLoss:0.6906 | SPLoss:0.0000 | CLSLoss:0.0002 | top1:50.0033 | AUROC:0.9818\n",
      "\n",
      "Epoch: [36 | 1000] LR: 0.159773\n",
      "Train | 16/16 | Loss:0.6932 | MainLoss:0.6931 | Alpha:0.3334 | SPLoss:0.0000 | CLSLoss:0.0001 | top1:50.4000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6930 | MainLoss:0.6930 | SPLoss:0.0000 | CLSLoss:0.0001 | top1:50.0000 | AUROC:0.5926\n",
      "Test | 123/16 | Loss:0.6911 | MainLoss:0.6911 | SPLoss:0.0000 | CLSLoss:0.0001 | top1:50.0000 | AUROC:0.9814\n",
      "\n",
      "Epoch: [37 | 1000] LR: 0.159753\n",
      "Train | 16/16 | Loss:0.6931 | MainLoss:0.6931 | Alpha:0.3334 | SPLoss:0.0000 | CLSLoss:0.0001 | top1:51.0400 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6930 | MainLoss:0.6930 | SPLoss:0.0000 | CLSLoss:0.0001 | top1:50.0000 | AUROC:0.5939\n",
      "Test | 123/16 | Loss:0.6914 | MainLoss:0.6914 | SPLoss:0.0000 | CLSLoss:0.0001 | top1:50.0000 | AUROC:0.9809\n",
      "\n",
      "Epoch: [38 | 1000] LR: 0.159733\n",
      "Train | 16/16 | Loss:0.6932 | MainLoss:0.6931 | Alpha:0.3333 | SPLoss:0.0000 | CLSLoss:0.0001 | top1:50.6133 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6930 | MainLoss:0.6930 | SPLoss:0.0000 | CLSLoss:0.0001 | top1:52.5385 | AUROC:0.5936\n",
      "Test | 123/16 | Loss:0.6910 | MainLoss:0.6910 | SPLoss:0.0000 | CLSLoss:0.0001 | top1:92.2805 | AUROC:0.9808\n",
      "\n",
      "Epoch: [39 | 1000] LR: 0.159712\n",
      "Train | 16/16 | Loss:0.6932 | MainLoss:0.6931 | Alpha:0.3334 | SPLoss:0.0000 | CLSLoss:0.0001 | top1:49.7600 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6930 | MainLoss:0.6930 | SPLoss:0.0000 | CLSLoss:0.0002 | top1:50.0000 | AUROC:0.5949\n",
      "Test | 123/16 | Loss:0.6907 | MainLoss:0.6907 | SPLoss:0.0000 | CLSLoss:0.0002 | top1:50.0328 | AUROC:0.9801\n",
      "\n",
      "Epoch: [40 | 1000] LR: 0.159691\n",
      "Train | 16/16 | Loss:0.6930 | MainLoss:0.6927 | Alpha:0.3334 | SPLoss:0.0000 | CLSLoss:0.0003 | top1:51.8667 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6930 | MainLoss:0.6930 | SPLoss:0.0000 | CLSLoss:0.0003 | top1:50.0000 | AUROC:0.5961\n",
      "Test | 123/16 | Loss:0.6902 | MainLoss:0.6902 | SPLoss:0.0000 | CLSLoss:0.0003 | top1:50.0000 | AUROC:0.9791\n",
      "\n",
      "Epoch: [41 | 1000] LR: 0.159668\n",
      "Train | 16/16 | Loss:0.6932 | MainLoss:0.6931 | Alpha:0.3333 | SPLoss:0.0000 | CLSLoss:0.0001 | top1:51.7600 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6929 | MainLoss:0.6929 | SPLoss:0.0000 | CLSLoss:0.0001 | top1:54.0000 | AUROC:0.5964\n",
      "Test | 123/16 | Loss:0.6906 | MainLoss:0.6906 | SPLoss:0.0000 | CLSLoss:0.0001 | top1:59.4332 | AUROC:0.9785\n",
      "\n",
      "Epoch: [42 | 1000] LR: 0.159645\n",
      "Train | 16/16 | Loss:0.6932 | MainLoss:0.6931 | Alpha:0.3334 | SPLoss:0.0000 | CLSLoss:0.0001 | top1:50.2400 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6929 | MainLoss:0.6929 | SPLoss:0.0000 | CLSLoss:0.0001 | top1:50.0000 | AUROC:0.5985\n",
      "Test | 123/16 | Loss:0.6906 | MainLoss:0.6906 | SPLoss:0.0000 | CLSLoss:0.0001 | top1:50.0000 | AUROC:0.9777\n",
      "\n",
      "Epoch: [43 | 1000] LR: 0.159621\n",
      "Train | 16/16 | Loss:0.6931 | MainLoss:0.6929 | Alpha:0.3334 | SPLoss:0.0000 | CLSLoss:0.0002 | top1:51.3867 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6929 | MainLoss:0.6929 | SPLoss:0.0000 | CLSLoss:0.0001 | top1:54.1538 | AUROC:0.5984\n",
      "Test | 123/16 | Loss:0.6902 | MainLoss:0.6902 | SPLoss:0.0000 | CLSLoss:0.0001 | top1:88.6501 | AUROC:0.9767\n",
      "\n",
      "Epoch: [44 | 1000] LR: 0.159596\n",
      "Train | 16/16 | Loss:0.6931 | MainLoss:0.6930 | Alpha:0.3334 | SPLoss:0.0000 | CLSLoss:0.0001 | top1:51.2267 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6928 | MainLoss:0.6928 | SPLoss:0.0000 | CLSLoss:0.0001 | top1:50.3974 | AUROC:0.6004\n",
      "Test | 123/16 | Loss:0.6901 | MainLoss:0.6901 | SPLoss:0.0000 | CLSLoss:0.0001 | top1:51.2549 | AUROC:0.9752\n",
      "\n",
      "Epoch: [45 | 1000] LR: 0.159570\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 16/16 | Loss:0.6931 | MainLoss:0.6930 | Alpha:0.3334 | SPLoss:0.0000 | CLSLoss:0.0001 | top1:49.9200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6928 | MainLoss:0.6928 | SPLoss:0.0000 | CLSLoss:0.0002 | top1:51.6667 | AUROC:0.6019\n",
      "Test | 123/16 | Loss:0.6897 | MainLoss:0.6897 | SPLoss:0.0000 | CLSLoss:0.0002 | top1:91.3499 | AUROC:0.9735\n",
      "\n",
      "Epoch: [46 | 1000] LR: 0.159544\n",
      "Train | 16/16 | Loss:0.6932 | MainLoss:0.6930 | Alpha:0.3334 | SPLoss:0.0000 | CLSLoss:0.0002 | top1:50.9600 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6928 | MainLoss:0.6928 | SPLoss:0.0000 | CLSLoss:0.0001 | top1:56.4103 | AUROC:0.6034\n",
      "Test | 123/16 | Loss:0.6898 | MainLoss:0.6898 | SPLoss:0.0000 | CLSLoss:0.0001 | top1:80.8388 | AUROC:0.9719\n",
      "\n",
      "Epoch: [47 | 1000] LR: 0.159517\n",
      "Train | 16/16 | Loss:0.6932 | MainLoss:0.6930 | Alpha:0.3334 | SPLoss:0.0000 | CLSLoss:0.0002 | top1:50.6400 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6927 | MainLoss:0.6927 | SPLoss:0.0000 | CLSLoss:0.0002 | top1:51.8205 | AUROC:0.6044\n",
      "Test | 123/16 | Loss:0.6894 | MainLoss:0.6894 | SPLoss:0.0000 | CLSLoss:0.0002 | top1:90.6455 | AUROC:0.9697\n",
      "\n",
      "Epoch: [48 | 1000] LR: 0.159489\n",
      "Train | 16/16 | Loss:0.6930 | MainLoss:0.6928 | Alpha:0.3334 | SPLoss:0.0000 | CLSLoss:0.0002 | top1:50.8000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6927 | MainLoss:0.6927 | SPLoss:0.0000 | CLSLoss:0.0002 | top1:56.6923 | AUROC:0.6072\n",
      "Test | 123/16 | Loss:0.6895 | MainLoss:0.6895 | SPLoss:0.0000 | CLSLoss:0.0002 | top1:66.5400 | AUROC:0.9678\n",
      "\n",
      "Epoch: [49 | 1000] LR: 0.159460\n",
      "Train | 16/16 | Loss:0.6931 | MainLoss:0.6929 | Alpha:0.3334 | SPLoss:0.0000 | CLSLoss:0.0002 | top1:52.0533 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6926 | MainLoss:0.6926 | SPLoss:0.0000 | CLSLoss:0.0003 | top1:51.6410 | AUROC:0.6088\n",
      "Test | 123/16 | Loss:0.6890 | MainLoss:0.6890 | SPLoss:0.0000 | CLSLoss:0.0003 | top1:88.3060 | AUROC:0.9651\n",
      "\n",
      "Epoch: [50 | 1000] LR: 0.159431\n",
      "Train | 16/16 | Loss:0.6932 | MainLoss:0.6929 | Alpha:0.3334 | SPLoss:0.0000 | CLSLoss:0.0003 | top1:51.6267 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6926 | MainLoss:0.6926 | SPLoss:0.0000 | CLSLoss:0.0002 | top1:57.8846 | AUROC:0.6105\n",
      "Test | 123/16 | Loss:0.6894 | MainLoss:0.6894 | SPLoss:0.0000 | CLSLoss:0.0002 | top1:75.1442 | AUROC:0.9612\n",
      "\n",
      "Epoch: [51 | 1000] LR: 0.159400\n",
      "Train | 16/16 | Loss:0.6930 | MainLoss:0.6926 | Alpha:0.3334 | SPLoss:0.0000 | CLSLoss:0.0003 | top1:52.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6924 | MainLoss:0.6924 | SPLoss:0.0000 | CLSLoss:0.0003 | top1:57.0769 | AUROC:0.6123\n",
      "Test | 123/16 | Loss:0.6882 | MainLoss:0.6882 | SPLoss:0.0000 | CLSLoss:0.0003 | top1:81.5138 | AUROC:0.9560\n",
      "\n",
      "Epoch: [52 | 1000] LR: 0.015937\n",
      "Train | 16/16 | Loss:0.6929 | MainLoss:0.6926 | Alpha:0.3335 | SPLoss:0.0000 | CLSLoss:0.0003 | top1:55.7067 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6924 | MainLoss:0.6924 | SPLoss:0.0000 | CLSLoss:0.0003 | top1:58.0256 | AUROC:0.6122\n",
      "Test | 123/16 | Loss:0.6883 | MainLoss:0.6883 | SPLoss:0.0000 | CLSLoss:0.0003 | top1:77.2477 | AUROC:0.9550\n",
      "\n",
      "Epoch: [53 | 1000] LR: 0.015934\n",
      "Train | 16/16 | Loss:0.6929 | MainLoss:0.6926 | Alpha:0.3334 | SPLoss:0.0000 | CLSLoss:0.0003 | top1:55.0667 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6924 | MainLoss:0.6924 | SPLoss:0.0000 | CLSLoss:0.0003 | top1:58.0641 | AUROC:0.6138\n",
      "Test | 123/16 | Loss:0.6884 | MainLoss:0.6884 | SPLoss:0.0000 | CLSLoss:0.0003 | top1:76.1894 | AUROC:0.9540\n",
      "\n",
      "Epoch: [54 | 1000] LR: 0.015930\n",
      "Train | 16/16 | Loss:0.6929 | MainLoss:0.6926 | Alpha:0.3335 | SPLoss:0.0000 | CLSLoss:0.0003 | top1:56.1600 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6924 | MainLoss:0.6924 | SPLoss:0.0000 | CLSLoss:0.0003 | top1:57.7949 | AUROC:0.6141\n",
      "Test | 123/16 | Loss:0.6884 | MainLoss:0.6884 | SPLoss:0.0000 | CLSLoss:0.0003 | top1:72.1658 | AUROC:0.9536\n",
      "\n",
      "Epoch: [55 | 1000] LR: 0.015927\n",
      "Train | 16/16 | Loss:0.6929 | MainLoss:0.6926 | Alpha:0.3335 | SPLoss:0.0000 | CLSLoss:0.0003 | top1:55.1200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6924 | MainLoss:0.6924 | SPLoss:0.0000 | CLSLoss:0.0003 | top1:57.7564 | AUROC:0.6148\n",
      "Test | 123/16 | Loss:0.6885 | MainLoss:0.6885 | SPLoss:0.0000 | CLSLoss:0.0003 | top1:72.3820 | AUROC:0.9530\n",
      "\n",
      "Epoch: [56 | 1000] LR: 0.015924\n",
      "Train | 16/16 | Loss:0.6929 | MainLoss:0.6926 | Alpha:0.3335 | SPLoss:0.0000 | CLSLoss:0.0003 | top1:55.7333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6924 | MainLoss:0.6924 | SPLoss:0.0000 | CLSLoss:0.0003 | top1:58.1538 | AUROC:0.6142\n",
      "Test | 123/16 | Loss:0.6885 | MainLoss:0.6885 | SPLoss:0.0000 | CLSLoss:0.0003 | top1:75.3506 | AUROC:0.9520\n",
      "\n",
      "Epoch: [57 | 1000] LR: 0.015920\n",
      "Train | 16/16 | Loss:0.6930 | MainLoss:0.6927 | Alpha:0.3334 | SPLoss:0.0000 | CLSLoss:0.0003 | top1:54.5333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6924 | MainLoss:0.6924 | SPLoss:0.0000 | CLSLoss:0.0003 | top1:57.9872 | AUROC:0.6157\n",
      "Test | 123/16 | Loss:0.6887 | MainLoss:0.6887 | SPLoss:0.0000 | CLSLoss:0.0003 | top1:74.2235 | AUROC:0.9511\n",
      "\n",
      "Epoch: [58 | 1000] LR: 0.015917\n",
      "Train | 16/16 | Loss:0.6930 | MainLoss:0.6927 | Alpha:0.3334 | SPLoss:0.0000 | CLSLoss:0.0002 | top1:54.2933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6925 | MainLoss:0.6925 | SPLoss:0.0000 | CLSLoss:0.0002 | top1:58.1026 | AUROC:0.6155\n",
      "Test | 123/16 | Loss:0.6889 | MainLoss:0.6889 | SPLoss:0.0000 | CLSLoss:0.0002 | top1:75.6684 | AUROC:0.9510\n",
      "\n",
      "Epoch: [59 | 1000] LR: 0.015913\n",
      "Train | 16/16 | Loss:0.6929 | MainLoss:0.6927 | Alpha:0.3334 | SPLoss:0.0000 | CLSLoss:0.0002 | top1:55.3067 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6924 | MainLoss:0.6924 | SPLoss:0.0000 | CLSLoss:0.0002 | top1:58.1538 | AUROC:0.6159\n",
      "Test | 123/16 | Loss:0.6889 | MainLoss:0.6889 | SPLoss:0.0000 | CLSLoss:0.0002 | top1:75.1278 | AUROC:0.9506\n",
      "\n",
      "Epoch: [60 | 1000] LR: 0.015909\n",
      "Train | 16/16 | Loss:0.6929 | MainLoss:0.6926 | Alpha:0.3335 | SPLoss:0.0000 | CLSLoss:0.0002 | top1:56.5067 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6924 | MainLoss:0.6924 | SPLoss:0.0000 | CLSLoss:0.0002 | top1:58.0513 | AUROC:0.6158\n",
      "Test | 123/16 | Loss:0.6887 | MainLoss:0.6887 | SPLoss:0.0000 | CLSLoss:0.0002 | top1:74.0334 | AUROC:0.9495\n",
      "\n",
      "Epoch: [61 | 1000] LR: 0.015905\n",
      "Train | 16/16 | Loss:0.6929 | MainLoss:0.6926 | Alpha:0.3335 | SPLoss:0.0000 | CLSLoss:0.0003 | top1:55.7067 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6924 | MainLoss:0.6924 | SPLoss:0.0000 | CLSLoss:0.0003 | top1:57.8974 | AUROC:0.6163\n",
      "Test | 123/16 | Loss:0.6886 | MainLoss:0.6886 | SPLoss:0.0000 | CLSLoss:0.0003 | top1:73.1127 | AUROC:0.9488\n",
      "\n",
      "Epoch: [62 | 1000] LR: 0.015902\n",
      "Train | 16/16 | Loss:0.6927 | MainLoss:0.6925 | Alpha:0.3335 | SPLoss:0.0000 | CLSLoss:0.0003 | top1:56.1867 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6923 | MainLoss:0.6923 | SPLoss:0.0000 | CLSLoss:0.0003 | top1:57.8846 | AUROC:0.6162\n",
      "Test | 123/16 | Loss:0.6883 | MainLoss:0.6883 | SPLoss:0.0000 | CLSLoss:0.0003 | top1:71.1566 | AUROC:0.9479\n",
      "\n",
      "Epoch: [63 | 1000] LR: 0.015898\n",
      "Train | 16/16 | Loss:0.6929 | MainLoss:0.6926 | Alpha:0.3335 | SPLoss:0.0000 | CLSLoss:0.0003 | top1:56.5600 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6923 | MainLoss:0.6923 | SPLoss:0.0000 | CLSLoss:0.0003 | top1:58.0128 | AUROC:0.6160\n",
      "Test | 123/16 | Loss:0.6883 | MainLoss:0.6883 | SPLoss:0.0000 | CLSLoss:0.0003 | top1:73.1586 | AUROC:0.9470\n",
      "\n",
      "Epoch: [64 | 1000] LR: 0.015893\n",
      "Train | 16/16 | Loss:0.6929 | MainLoss:0.6926 | Alpha:0.3335 | SPLoss:0.0000 | CLSLoss:0.0003 | top1:54.4533 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6923 | MainLoss:0.6923 | SPLoss:0.0000 | CLSLoss:0.0003 | top1:57.4231 | AUROC:0.6165\n",
      "Test | 123/16 | Loss:0.6884 | MainLoss:0.6884 | SPLoss:0.0000 | CLSLoss:0.0003 | top1:67.4705 | AUROC:0.9461\n",
      "\n",
      "Epoch: [65 | 1000] LR: 0.015889\n",
      "Train | 16/16 | Loss:0.6928 | MainLoss:0.6924 | Alpha:0.3335 | SPLoss:0.0000 | CLSLoss:0.0003 | top1:55.5733 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6923 | MainLoss:0.6923 | SPLoss:0.0000 | CLSLoss:0.0003 | top1:57.8333 | AUROC:0.6172\n",
      "Test | 123/16 | Loss:0.6882 | MainLoss:0.6882 | SPLoss:0.0000 | CLSLoss:0.0003 | top1:69.8198 | AUROC:0.9447\n",
      "\n",
      "Epoch: [66 | 1000] LR: 0.015885\n",
      "Train | 16/16 | Loss:0.6928 | MainLoss:0.6925 | Alpha:0.3335 | SPLoss:0.0000 | CLSLoss:0.0003 | top1:55.2533 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6923 | MainLoss:0.6923 | SPLoss:0.0000 | CLSLoss:0.0003 | top1:58.0256 | AUROC:0.6177\n",
      "Test | 123/16 | Loss:0.6881 | MainLoss:0.6881 | SPLoss:0.0000 | CLSLoss:0.0003 | top1:69.2038 | AUROC:0.9436\n",
      "\n",
      "Epoch: [67 | 1000] LR: 0.015881\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 16/16 | Loss:0.6928 | MainLoss:0.6925 | Alpha:0.3335 | SPLoss:0.0000 | CLSLoss:0.0003 | top1:55.5200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6922 | MainLoss:0.6922 | SPLoss:0.0000 | CLSLoss:0.0003 | top1:57.3718 | AUROC:0.6184\n",
      "Test | 123/16 | Loss:0.6881 | MainLoss:0.6881 | SPLoss:0.0000 | CLSLoss:0.0003 | top1:67.2051 | AUROC:0.9422\n",
      "\n",
      "Epoch: [68 | 1000] LR: 0.015877\n",
      "Train | 16/16 | Loss:0.6928 | MainLoss:0.6924 | Alpha:0.3335 | SPLoss:0.0000 | CLSLoss:0.0003 | top1:55.0133 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6922 | MainLoss:0.6922 | SPLoss:0.0000 | CLSLoss:0.0003 | top1:56.9103 | AUROC:0.6172\n",
      "Test | 123/16 | Loss:0.6880 | MainLoss:0.6880 | SPLoss:0.0000 | CLSLoss:0.0003 | top1:65.9928 | AUROC:0.9411\n",
      "\n",
      "Epoch: [69 | 1000] LR: 0.015872\n",
      "Train | 16/16 | Loss:0.6928 | MainLoss:0.6925 | Alpha:0.3335 | SPLoss:0.0000 | CLSLoss:0.0003 | top1:55.0133 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6922 | MainLoss:0.6922 | SPLoss:0.0000 | CLSLoss:0.0003 | top1:57.9231 | AUROC:0.6191\n",
      "Test | 123/16 | Loss:0.6881 | MainLoss:0.6881 | SPLoss:0.0000 | CLSLoss:0.0003 | top1:69.8427 | AUROC:0.9404\n",
      "\n",
      "Epoch: [70 | 1000] LR: 0.015868\n",
      "Train | 16/16 | Loss:0.6927 | MainLoss:0.6924 | Alpha:0.3335 | SPLoss:0.0000 | CLSLoss:0.0003 | top1:55.6267 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6921 | MainLoss:0.6921 | SPLoss:0.0000 | CLSLoss:0.0004 | top1:57.3077 | AUROC:0.6194\n",
      "Test | 123/16 | Loss:0.6879 | MainLoss:0.6879 | SPLoss:0.0000 | CLSLoss:0.0004 | top1:66.9004 | AUROC:0.9385\n",
      "\n",
      "Epoch: [71 | 1000] LR: 0.015863\n",
      "Train | 16/16 | Loss:0.6928 | MainLoss:0.6925 | Alpha:0.3335 | SPLoss:0.0000 | CLSLoss:0.0004 | top1:54.7733 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6921 | MainLoss:0.6921 | SPLoss:0.0000 | CLSLoss:0.0004 | top1:57.4359 | AUROC:0.6199\n",
      "Test | 123/16 | Loss:0.6879 | MainLoss:0.6879 | SPLoss:0.0000 | CLSLoss:0.0004 | top1:67.2182 | AUROC:0.9369\n",
      "\n",
      "Epoch: [72 | 1000] LR: 0.015858\n",
      "Train | 16/16 | Loss:0.6928 | MainLoss:0.6924 | Alpha:0.3335 | SPLoss:0.0000 | CLSLoss:0.0004 | top1:55.0667 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6921 | MainLoss:0.6921 | SPLoss:0.0000 | CLSLoss:0.0004 | top1:58.2051 | AUROC:0.6199\n",
      "Test | 123/16 | Loss:0.6880 | MainLoss:0.6880 | SPLoss:0.0000 | CLSLoss:0.0004 | top1:69.0138 | AUROC:0.9354\n",
      "\n",
      "Epoch: [73 | 1000] LR: 0.015854\n",
      "Train | 16/16 | Loss:0.6927 | MainLoss:0.6923 | Alpha:0.3335 | SPLoss:0.0000 | CLSLoss:0.0004 | top1:56.0800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6921 | MainLoss:0.6921 | SPLoss:0.0000 | CLSLoss:0.0004 | top1:58.0000 | AUROC:0.6200\n",
      "Test | 123/16 | Loss:0.6878 | MainLoss:0.6878 | SPLoss:0.0000 | CLSLoss:0.0004 | top1:69.9115 | AUROC:0.9336\n",
      "\n",
      "Epoch: [74 | 1000] LR: 0.015849\n",
      "Train | 16/16 | Loss:0.6928 | MainLoss:0.6924 | Alpha:0.3335 | SPLoss:0.0000 | CLSLoss:0.0004 | top1:55.8133 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6921 | MainLoss:0.6921 | SPLoss:0.0000 | CLSLoss:0.0004 | top1:57.7820 | AUROC:0.6209\n",
      "Test | 123/16 | Loss:0.6877 | MainLoss:0.6877 | SPLoss:0.0000 | CLSLoss:0.0004 | top1:67.7654 | AUROC:0.9322\n",
      "\n",
      "Epoch: [75 | 1000] LR: 0.015844\n",
      "Train | 16/16 | Loss:0.6926 | MainLoss:0.6922 | Alpha:0.3335 | SPLoss:0.0000 | CLSLoss:0.0004 | top1:54.4000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6920 | MainLoss:0.6920 | SPLoss:0.0000 | CLSLoss:0.0004 | top1:57.0385 | AUROC:0.6218\n",
      "Test | 123/16 | Loss:0.6876 | MainLoss:0.6876 | SPLoss:0.0000 | CLSLoss:0.0004 | top1:65.8781 | AUROC:0.9298\n",
      "\n",
      "Epoch: [76 | 1000] LR: 0.015839\n",
      "Train | 16/16 | Loss:0.6927 | MainLoss:0.6923 | Alpha:0.3335 | SPLoss:0.0000 | CLSLoss:0.0004 | top1:54.5333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6920 | MainLoss:0.6920 | SPLoss:0.0000 | CLSLoss:0.0004 | top1:57.9615 | AUROC:0.6207\n",
      "Test | 123/16 | Loss:0.6876 | MainLoss:0.6876 | SPLoss:0.0000 | CLSLoss:0.0004 | top1:68.1848 | AUROC:0.9291\n",
      "\n",
      "Epoch: [77 | 1000] LR: 0.015834\n",
      "Train | 16/16 | Loss:0.6928 | MainLoss:0.6924 | Alpha:0.3335 | SPLoss:0.0000 | CLSLoss:0.0004 | top1:55.1467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6920 | MainLoss:0.6920 | SPLoss:0.0000 | CLSLoss:0.0004 | top1:58.1538 | AUROC:0.6226\n",
      "Test | 123/16 | Loss:0.6877 | MainLoss:0.6877 | SPLoss:0.0000 | CLSLoss:0.0004 | top1:69.8820 | AUROC:0.9278\n",
      "\n",
      "Epoch: [78 | 1000] LR: 0.015829\n",
      "Train | 16/16 | Loss:0.6927 | MainLoss:0.6923 | Alpha:0.3335 | SPLoss:0.0000 | CLSLoss:0.0004 | top1:56.7467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6920 | MainLoss:0.6920 | SPLoss:0.0000 | CLSLoss:0.0004 | top1:57.3718 | AUROC:0.6227\n",
      "Test | 123/16 | Loss:0.6877 | MainLoss:0.6877 | SPLoss:0.0000 | CLSLoss:0.0004 | top1:67.2346 | AUROC:0.9260\n",
      "\n",
      "Epoch: [79 | 1000] LR: 0.015823\n",
      "Train | 16/16 | Loss:0.6927 | MainLoss:0.6922 | Alpha:0.3335 | SPLoss:0.0000 | CLSLoss:0.0004 | top1:55.7067 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6919 | MainLoss:0.6919 | SPLoss:0.0000 | CLSLoss:0.0004 | top1:57.6667 | AUROC:0.6241\n",
      "Test | 123/16 | Loss:0.6876 | MainLoss:0.6876 | SPLoss:0.0000 | CLSLoss:0.0004 | top1:67.5360 | AUROC:0.9242\n",
      "\n",
      "Epoch: [80 | 1000] LR: 0.015818\n",
      "Train | 16/16 | Loss:0.6927 | MainLoss:0.6922 | Alpha:0.3335 | SPLoss:0.0000 | CLSLoss:0.0004 | top1:54.8267 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6919 | MainLoss:0.6919 | SPLoss:0.0000 | CLSLoss:0.0004 | top1:58.1026 | AUROC:0.6234\n",
      "Test | 123/16 | Loss:0.6875 | MainLoss:0.6875 | SPLoss:0.0000 | CLSLoss:0.0004 | top1:68.4764 | AUROC:0.9225\n",
      "\n",
      "Epoch: [81 | 1000] LR: 0.015813\n",
      "Train | 16/16 | Loss:0.6925 | MainLoss:0.6920 | Alpha:0.3336 | SPLoss:0.0000 | CLSLoss:0.0005 | top1:55.4400 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6918 | MainLoss:0.6918 | SPLoss:0.0000 | CLSLoss:0.0005 | top1:58.1026 | AUROC:0.6248\n",
      "Test | 123/16 | Loss:0.6872 | MainLoss:0.6872 | SPLoss:0.0000 | CLSLoss:0.0005 | top1:68.1389 | AUROC:0.9197\n",
      "\n",
      "Epoch: [82 | 1000] LR: 0.015807\n",
      "Train | 16/16 | Loss:0.6928 | MainLoss:0.6923 | Alpha:0.3335 | SPLoss:0.0000 | CLSLoss:0.0005 | top1:53.9200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6918 | MainLoss:0.6918 | SPLoss:0.0000 | CLSLoss:0.0005 | top1:57.9103 | AUROC:0.6249\n",
      "Test | 123/16 | Loss:0.6874 | MainLoss:0.6874 | SPLoss:0.0000 | CLSLoss:0.0005 | top1:67.8244 | AUROC:0.9176\n",
      "\n",
      "Epoch: [83 | 1000] LR: 0.015802\n",
      "Train | 16/16 | Loss:0.6926 | MainLoss:0.6921 | Alpha:0.3336 | SPLoss:0.0000 | CLSLoss:0.0005 | top1:56.4533 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6918 | MainLoss:0.6918 | SPLoss:0.0000 | CLSLoss:0.0005 | top1:57.7564 | AUROC:0.6246\n",
      "Test | 123/16 | Loss:0.6873 | MainLoss:0.6873 | SPLoss:0.0000 | CLSLoss:0.0005 | top1:67.5295 | AUROC:0.9150\n",
      "\n",
      "Epoch: [84 | 1000] LR: 0.015796\n",
      "Train | 16/16 | Loss:0.6925 | MainLoss:0.6920 | Alpha:0.3336 | SPLoss:0.0000 | CLSLoss:0.0005 | top1:57.0933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6917 | MainLoss:0.6917 | SPLoss:0.0000 | CLSLoss:0.0005 | top1:57.4744 | AUROC:0.6256\n",
      "Test | 123/16 | Loss:0.6871 | MainLoss:0.6871 | SPLoss:0.0000 | CLSLoss:0.0005 | top1:67.0708 | AUROC:0.9126\n",
      "\n",
      "Epoch: [85 | 1000] LR: 0.015791\n",
      "Train | 16/16 | Loss:0.6926 | MainLoss:0.6921 | Alpha:0.3336 | SPLoss:0.0000 | CLSLoss:0.0005 | top1:56.4533 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6917 | MainLoss:0.6917 | SPLoss:0.0000 | CLSLoss:0.0005 | top1:57.9359 | AUROC:0.6261\n",
      "Test | 123/16 | Loss:0.6871 | MainLoss:0.6871 | SPLoss:0.0000 | CLSLoss:0.0005 | top1:67.8080 | AUROC:0.9105\n",
      "\n",
      "Epoch: [86 | 1000] LR: 0.015785\n",
      "Train | 16/16 | Loss:0.6925 | MainLoss:0.6919 | Alpha:0.3336 | SPLoss:0.0000 | CLSLoss:0.0005 | top1:56.1333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6916 | MainLoss:0.6916 | SPLoss:0.0000 | CLSLoss:0.0005 | top1:57.7179 | AUROC:0.6259\n",
      "Test | 123/16 | Loss:0.6869 | MainLoss:0.6869 | SPLoss:0.0000 | CLSLoss:0.0005 | top1:67.2281 | AUROC:0.9075\n",
      "\n",
      "Epoch: [87 | 1000] LR: 0.015779\n",
      "Train | 16/16 | Loss:0.6927 | MainLoss:0.6922 | Alpha:0.3336 | SPLoss:0.0000 | CLSLoss:0.0005 | top1:54.5867 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6916 | MainLoss:0.6916 | SPLoss:0.0000 | CLSLoss:0.0005 | top1:58.4103 | AUROC:0.6275\n",
      "Test | 123/16 | Loss:0.6871 | MainLoss:0.6871 | SPLoss:0.0000 | CLSLoss:0.0005 | top1:68.8958 | AUROC:0.9062\n",
      "\n",
      "Epoch: [88 | 1000] LR: 0.015773\n",
      "Train | 16/16 | Loss:0.6927 | MainLoss:0.6922 | Alpha:0.3336 | SPLoss:0.0000 | CLSLoss:0.0005 | top1:55.1467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6917 | MainLoss:0.6917 | SPLoss:0.0000 | CLSLoss:0.0005 | top1:58.2949 | AUROC:0.6277\n",
      "Test | 123/16 | Loss:0.6873 | MainLoss:0.6873 | SPLoss:0.0000 | CLSLoss:0.0005 | top1:68.2831 | AUROC:0.9029\n",
      "\n",
      "Epoch: [89 | 1000] LR: 0.015767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 16/16 | Loss:0.6926 | MainLoss:0.6921 | Alpha:0.3336 | SPLoss:0.0000 | CLSLoss:0.0005 | top1:56.0533 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6916 | MainLoss:0.6916 | SPLoss:0.0000 | CLSLoss:0.0005 | top1:58.3846 | AUROC:0.6280\n",
      "Test | 123/16 | Loss:0.6872 | MainLoss:0.6872 | SPLoss:0.0000 | CLSLoss:0.0005 | top1:68.4568 | AUROC:0.9013\n",
      "\n",
      "Epoch: [90 | 1000] LR: 0.015761\n",
      "Train | 16/16 | Loss:0.6924 | MainLoss:0.6918 | Alpha:0.3336 | SPLoss:0.0000 | CLSLoss:0.0005 | top1:55.8400 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6915 | MainLoss:0.6915 | SPLoss:0.0000 | CLSLoss:0.0006 | top1:58.2949 | AUROC:0.6267\n",
      "Test | 123/16 | Loss:0.6869 | MainLoss:0.6869 | SPLoss:0.0000 | CLSLoss:0.0006 | top1:68.1389 | AUROC:0.8973\n",
      "\n",
      "Epoch: [91 | 1000] LR: 0.015755\n",
      "Train | 16/16 | Loss:0.6925 | MainLoss:0.6919 | Alpha:0.3336 | SPLoss:0.0000 | CLSLoss:0.0006 | top1:55.3333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6915 | MainLoss:0.6915 | SPLoss:0.0000 | CLSLoss:0.0006 | top1:58.1667 | AUROC:0.6287\n",
      "Test | 123/16 | Loss:0.6868 | MainLoss:0.6868 | SPLoss:0.0000 | CLSLoss:0.0006 | top1:67.8571 | AUROC:0.8954\n",
      "\n",
      "Epoch: [92 | 1000] LR: 0.015749\n",
      "Train | 16/16 | Loss:0.6924 | MainLoss:0.6918 | Alpha:0.3336 | SPLoss:0.0000 | CLSLoss:0.0006 | top1:57.4667 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6914 | MainLoss:0.6914 | SPLoss:0.0000 | CLSLoss:0.0006 | top1:58.2949 | AUROC:0.6293\n",
      "Test | 123/16 | Loss:0.6867 | MainLoss:0.6867 | SPLoss:0.0000 | CLSLoss:0.0006 | top1:68.0046 | AUROC:0.8919\n",
      "\n",
      "Epoch: [93 | 1000] LR: 0.015742\n",
      "Train | 16/16 | Loss:0.6923 | MainLoss:0.6917 | Alpha:0.3337 | SPLoss:0.0000 | CLSLoss:0.0006 | top1:55.7600 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6913 | MainLoss:0.6913 | SPLoss:0.0000 | CLSLoss:0.0006 | top1:58.0513 | AUROC:0.6302\n",
      "Test | 123/16 | Loss:0.6865 | MainLoss:0.6865 | SPLoss:0.0000 | CLSLoss:0.0006 | top1:67.0642 | AUROC:0.8857\n",
      "\n",
      "Epoch: [94 | 1000] LR: 0.015736\n",
      "Train | 16/16 | Loss:0.6924 | MainLoss:0.6917 | Alpha:0.3337 | SPLoss:0.0000 | CLSLoss:0.0007 | top1:56.9600 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6912 | MainLoss:0.6912 | SPLoss:0.0000 | CLSLoss:0.0007 | top1:58.1410 | AUROC:0.6298\n",
      "Test | 123/16 | Loss:0.6865 | MainLoss:0.6865 | SPLoss:0.0000 | CLSLoss:0.0007 | top1:67.4607 | AUROC:0.8826\n",
      "\n",
      "Epoch: [95 | 1000] LR: 0.015730\n",
      "Train | 16/16 | Loss:0.6921 | MainLoss:0.6914 | Alpha:0.3337 | SPLoss:0.0000 | CLSLoss:0.0007 | top1:57.1200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6911 | MainLoss:0.6911 | SPLoss:0.0000 | CLSLoss:0.0007 | top1:57.5000 | AUROC:0.6301\n",
      "Test | 123/16 | Loss:0.6861 | MainLoss:0.6861 | SPLoss:0.0000 | CLSLoss:0.0007 | top1:65.7110 | AUROC:0.8771\n",
      "\n",
      "Epoch: [96 | 1000] LR: 0.015723\n",
      "Train | 16/16 | Loss:0.6926 | MainLoss:0.6918 | Alpha:0.3336 | SPLoss:0.0000 | CLSLoss:0.0007 | top1:56.0267 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6911 | MainLoss:0.6911 | SPLoss:0.0000 | CLSLoss:0.0007 | top1:57.5128 | AUROC:0.6317\n",
      "Test | 123/16 | Loss:0.6864 | MainLoss:0.6864 | SPLoss:0.0000 | CLSLoss:0.0007 | top1:65.5570 | AUROC:0.8736\n",
      "\n",
      "Epoch: [97 | 1000] LR: 0.015716\n",
      "Train | 16/16 | Loss:0.6922 | MainLoss:0.6915 | Alpha:0.3337 | SPLoss:0.0000 | CLSLoss:0.0007 | top1:56.2933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6910 | MainLoss:0.6910 | SPLoss:0.0000 | CLSLoss:0.0007 | top1:57.8718 | AUROC:0.6323\n",
      "Test | 123/16 | Loss:0.6863 | MainLoss:0.6863 | SPLoss:0.0000 | CLSLoss:0.0007 | top1:66.2713 | AUROC:0.8663\n",
      "\n",
      "Epoch: [98 | 1000] LR: 0.015710\n",
      "Train | 16/16 | Loss:0.6923 | MainLoss:0.6915 | Alpha:0.3337 | SPLoss:0.0000 | CLSLoss:0.0008 | top1:54.6133 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6910 | MainLoss:0.6910 | SPLoss:0.0000 | CLSLoss:0.0007 | top1:57.9359 | AUROC:0.6313\n",
      "Test | 123/16 | Loss:0.6863 | MainLoss:0.6863 | SPLoss:0.0000 | CLSLoss:0.0007 | top1:66.3532 | AUROC:0.8610\n",
      "\n",
      "Epoch: [99 | 1000] LR: 0.015703\n",
      "Train | 16/16 | Loss:0.6923 | MainLoss:0.6916 | Alpha:0.3337 | SPLoss:0.0000 | CLSLoss:0.0007 | top1:55.9467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6909 | MainLoss:0.6909 | SPLoss:0.0000 | CLSLoss:0.0008 | top1:58.0769 | AUROC:0.6333\n",
      "Test | 123/16 | Loss:0.6862 | MainLoss:0.6862 | SPLoss:0.0000 | CLSLoss:0.0008 | top1:66.4482 | AUROC:0.8572\n",
      "\n",
      "Epoch: [100 | 1000] LR: 0.015696\n",
      "Train | 16/16 | Loss:0.6922 | MainLoss:0.6915 | Alpha:0.3337 | SPLoss:0.0000 | CLSLoss:0.0008 | top1:56.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6908 | MainLoss:0.6908 | SPLoss:0.0000 | CLSLoss:0.0008 | top1:57.9615 | AUROC:0.6338\n",
      "Test | 123/16 | Loss:0.6861 | MainLoss:0.6861 | SPLoss:0.0000 | CLSLoss:0.0008 | top1:66.0845 | AUROC:0.8538\n",
      "\n",
      "Epoch: [101 | 1000] LR: 0.015689\n",
      "Train | 16/16 | Loss:0.6918 | MainLoss:0.6910 | Alpha:0.3338 | SPLoss:0.0000 | CLSLoss:0.0008 | top1:55.9200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6906 | MainLoss:0.6906 | SPLoss:0.0000 | CLSLoss:0.0009 | top1:57.1282 | AUROC:0.6339\n",
      "Test | 123/16 | Loss:0.6856 | MainLoss:0.6856 | SPLoss:0.0000 | CLSLoss:0.0009 | top1:64.8657 | AUROC:0.8500\n",
      "\n",
      "Epoch: [102 | 1000] LR: 0.015682\n",
      "Train | 16/16 | Loss:0.6924 | MainLoss:0.6915 | Alpha:0.3337 | SPLoss:0.0000 | CLSLoss:0.0009 | top1:54.9867 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6906 | MainLoss:0.6906 | SPLoss:0.0000 | CLSLoss:0.0008 | top1:57.9872 | AUROC:0.6343\n",
      "Test | 123/16 | Loss:0.6859 | MainLoss:0.6859 | SPLoss:0.0000 | CLSLoss:0.0008 | top1:65.8814 | AUROC:0.8440\n",
      "\n",
      "Epoch: [103 | 1000] LR: 0.015675\n",
      "Train | 16/16 | Loss:0.6919 | MainLoss:0.6910 | Alpha:0.3338 | SPLoss:0.0000 | CLSLoss:0.0009 | top1:55.9733 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6904 | MainLoss:0.6904 | SPLoss:0.0000 | CLSLoss:0.0009 | top1:57.4103 | AUROC:0.6355\n",
      "Test | 123/16 | Loss:0.6856 | MainLoss:0.6856 | SPLoss:0.0000 | CLSLoss:0.0009 | top1:65.0524 | AUROC:0.8365\n",
      "\n",
      "Epoch: [104 | 1000] LR: 0.015668\n",
      "Train | 16/16 | Loss:0.6920 | MainLoss:0.6910 | Alpha:0.3338 | SPLoss:0.0000 | CLSLoss:0.0010 | top1:54.8000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6903 | MainLoss:0.6903 | SPLoss:0.0000 | CLSLoss:0.0010 | top1:58.0256 | AUROC:0.6360\n",
      "Test | 123/16 | Loss:0.6855 | MainLoss:0.6855 | SPLoss:0.0000 | CLSLoss:0.0010 | top1:65.8585 | AUROC:0.8328\n",
      "\n",
      "Epoch: [105 | 1000] LR: 0.015661\n",
      "Train | 16/16 | Loss:0.6919 | MainLoss:0.6909 | Alpha:0.3338 | SPLoss:0.0000 | CLSLoss:0.0010 | top1:54.6933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6902 | MainLoss:0.6902 | SPLoss:0.0000 | CLSLoss:0.0010 | top1:58.2179 | AUROC:0.6359\n",
      "Test | 123/16 | Loss:0.6853 | MainLoss:0.6853 | SPLoss:0.0000 | CLSLoss:0.0010 | top1:66.2582 | AUROC:0.8280\n",
      "\n",
      "Epoch: [106 | 1000] LR: 0.015654\n",
      "Train | 16/16 | Loss:0.6920 | MainLoss:0.6910 | Alpha:0.3338 | SPLoss:0.0000 | CLSLoss:0.0010 | top1:55.3600 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6901 | MainLoss:0.6901 | SPLoss:0.0000 | CLSLoss:0.0010 | top1:58.0513 | AUROC:0.6360\n",
      "Test | 123/16 | Loss:0.6853 | MainLoss:0.6853 | SPLoss:0.0000 | CLSLoss:0.0010 | top1:65.9142 | AUROC:0.8211\n",
      "\n",
      "Epoch: [107 | 1000] LR: 0.015646\n",
      "Train | 16/16 | Loss:0.6916 | MainLoss:0.6906 | Alpha:0.3339 | SPLoss:0.0000 | CLSLoss:0.0010 | top1:56.5067 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6899 | MainLoss:0.6899 | SPLoss:0.0000 | CLSLoss:0.0011 | top1:57.7436 | AUROC:0.6373\n",
      "Test | 123/16 | Loss:0.6849 | MainLoss:0.6849 | SPLoss:0.0000 | CLSLoss:0.0011 | top1:65.3637 | AUROC:0.8165\n",
      "\n",
      "Epoch: [108 | 1000] LR: 0.015639\n",
      "Train | 16/16 | Loss:0.6918 | MainLoss:0.6907 | Alpha:0.3339 | SPLoss:0.0000 | CLSLoss:0.0011 | top1:55.5467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6897 | MainLoss:0.6897 | SPLoss:0.0000 | CLSLoss:0.0011 | top1:57.4872 | AUROC:0.6380\n",
      "Test | 123/16 | Loss:0.6847 | MainLoss:0.6847 | SPLoss:0.0000 | CLSLoss:0.0011 | top1:64.9246 | AUROC:0.8123\n",
      "\n",
      "Epoch: [109 | 1000] LR: 0.015631\n",
      "Train | 16/16 | Loss:0.6915 | MainLoss:0.6904 | Alpha:0.3340 | SPLoss:0.0000 | CLSLoss:0.0012 | top1:55.9733 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6895 | MainLoss:0.6895 | SPLoss:0.0000 | CLSLoss:0.0012 | top1:57.6410 | AUROC:0.6396\n",
      "Test | 123/16 | Loss:0.6844 | MainLoss:0.6844 | SPLoss:0.0000 | CLSLoss:0.0012 | top1:65.0852 | AUROC:0.8055\n",
      "\n",
      "Epoch: [110 | 1000] LR: 0.015624\n",
      "Train | 16/16 | Loss:0.6910 | MainLoss:0.6898 | Alpha:0.3341 | SPLoss:0.0000 | CLSLoss:0.0012 | top1:56.2933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6891 | MainLoss:0.6891 | SPLoss:0.0000 | CLSLoss:0.0014 | top1:57.2179 | AUROC:0.6406\n",
      "Test | 123/16 | Loss:0.6840 | MainLoss:0.6840 | SPLoss:0.0000 | CLSLoss:0.0014 | top1:64.2104 | AUROC:0.7924\n",
      "\n",
      "Epoch: [111 | 1000] LR: 0.015616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 16/16 | Loss:0.6912 | MainLoss:0.6898 | Alpha:0.3341 | SPLoss:0.0000 | CLSLoss:0.0013 | top1:56.4533 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6888 | MainLoss:0.6888 | SPLoss:0.0000 | CLSLoss:0.0015 | top1:57.8077 | AUROC:0.6398\n",
      "Test | 123/16 | Loss:0.6834 | MainLoss:0.6834 | SPLoss:0.0000 | CLSLoss:0.0015 | top1:65.0983 | AUROC:0.7887\n",
      "\n",
      "Epoch: [112 | 1000] LR: 0.015608\n",
      "Train | 16/16 | Loss:0.6913 | MainLoss:0.6898 | Alpha:0.3341 | SPLoss:0.0000 | CLSLoss:0.0015 | top1:55.7600 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6885 | MainLoss:0.6885 | SPLoss:0.0000 | CLSLoss:0.0015 | top1:57.9615 | AUROC:0.6416\n",
      "Test | 123/16 | Loss:0.6831 | MainLoss:0.6831 | SPLoss:0.0000 | CLSLoss:0.0015 | top1:65.7438 | AUROC:0.7849\n",
      "\n",
      "Epoch: [113 | 1000] LR: 0.015601\n",
      "Train | 16/16 | Loss:0.6912 | MainLoss:0.6896 | Alpha:0.3341 | SPLoss:0.0000 | CLSLoss:0.0016 | top1:55.3867 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6883 | MainLoss:0.6883 | SPLoss:0.0000 | CLSLoss:0.0015 | top1:58.1667 | AUROC:0.6419\n",
      "Test | 123/16 | Loss:0.6832 | MainLoss:0.6832 | SPLoss:0.0000 | CLSLoss:0.0015 | top1:66.1894 | AUROC:0.7748\n",
      "\n",
      "Epoch: [114 | 1000] LR: 0.015593\n",
      "Train | 16/16 | Loss:0.6908 | MainLoss:0.6892 | Alpha:0.3342 | SPLoss:0.0000 | CLSLoss:0.0015 | top1:56.5333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6879 | MainLoss:0.6879 | SPLoss:0.0000 | CLSLoss:0.0016 | top1:58.2436 | AUROC:0.6420\n",
      "Test | 123/16 | Loss:0.6829 | MainLoss:0.6829 | SPLoss:0.0000 | CLSLoss:0.0016 | top1:66.1009 | AUROC:0.7617\n",
      "\n",
      "Epoch: [115 | 1000] LR: 0.015585\n",
      "Train | 16/16 | Loss:0.6906 | MainLoss:0.6890 | Alpha:0.3343 | SPLoss:0.0000 | CLSLoss:0.0016 | top1:56.4000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6874 | MainLoss:0.6874 | SPLoss:0.0000 | CLSLoss:0.0017 | top1:58.2949 | AUROC:0.6443\n",
      "Test | 123/16 | Loss:0.6822 | MainLoss:0.6822 | SPLoss:0.0000 | CLSLoss:0.0017 | top1:66.4187 | AUROC:0.7604\n",
      "\n",
      "Epoch: [116 | 1000] LR: 0.015577\n",
      "Train | 16/16 | Loss:0.6907 | MainLoss:0.6890 | Alpha:0.3343 | SPLoss:0.0000 | CLSLoss:0.0017 | top1:56.2400 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6870 | MainLoss:0.6870 | SPLoss:0.0000 | CLSLoss:0.0017 | top1:59.2436 | AUROC:0.6448\n",
      "Test | 123/16 | Loss:0.6810 | MainLoss:0.6810 | SPLoss:0.0000 | CLSLoss:0.0017 | top1:67.9030 | AUROC:0.7690\n",
      "\n",
      "Epoch: [117 | 1000] LR: 0.015569\n",
      "Train | 16/16 | Loss:0.6900 | MainLoss:0.6883 | Alpha:0.3344 | SPLoss:0.0000 | CLSLoss:0.0017 | top1:56.8800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6860 | MainLoss:0.6860 | SPLoss:0.0001 | CLSLoss:0.0020 | top1:58.6410 | AUROC:0.6477\n",
      "Test | 123/16 | Loss:0.6792 | MainLoss:0.6792 | SPLoss:0.0001 | CLSLoss:0.0020 | top1:67.1265 | AUROC:0.7702\n",
      "\n",
      "Epoch: [118 | 1000] LR: 0.015561\n",
      "Train | 16/16 | Loss:0.6895 | MainLoss:0.6874 | Alpha:0.3346 | SPLoss:0.0000 | CLSLoss:0.0021 | top1:56.2133 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6851 | MainLoss:0.6851 | SPLoss:0.0001 | CLSLoss:0.0021 | top1:58.7949 | AUROC:0.6489\n",
      "Test | 123/16 | Loss:0.6774 | MainLoss:0.6774 | SPLoss:0.0001 | CLSLoss:0.0021 | top1:67.1298 | AUROC:0.7718\n",
      "\n",
      "Epoch: [119 | 1000] LR: 0.015552\n",
      "Train | 16/16 | Loss:0.6882 | MainLoss:0.6860 | Alpha:0.3348 | SPLoss:0.0000 | CLSLoss:0.0022 | top1:57.2533 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6835 | MainLoss:0.6835 | SPLoss:0.0001 | CLSLoss:0.0025 | top1:58.6923 | AUROC:0.6512\n",
      "Test | 123/16 | Loss:0.6736 | MainLoss:0.6736 | SPLoss:0.0001 | CLSLoss:0.0025 | top1:66.6809 | AUROC:0.7783\n",
      "\n",
      "Epoch: [120 | 1000] LR: 0.015544\n",
      "Train | 16/16 | Loss:0.6887 | MainLoss:0.6861 | Alpha:0.3349 | SPLoss:0.0000 | CLSLoss:0.0026 | top1:56.5867 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6828 | MainLoss:0.6828 | SPLoss:0.0001 | CLSLoss:0.0025 | top1:59.2564 | AUROC:0.6550\n",
      "Test | 123/16 | Loss:0.6715 | MainLoss:0.6715 | SPLoss:0.0001 | CLSLoss:0.0025 | top1:68.0374 | AUROC:0.7883\n",
      "\n",
      "Epoch: [121 | 1000] LR: 0.015536\n",
      "Train | 16/16 | Loss:0.6877 | MainLoss:0.6851 | Alpha:0.3351 | SPLoss:0.0000 | CLSLoss:0.0025 | top1:56.9867 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6817 | MainLoss:0.6817 | SPLoss:0.0001 | CLSLoss:0.0028 | top1:59.4103 | AUROC:0.6564\n",
      "Test | 123/16 | Loss:0.6694 | MainLoss:0.6694 | SPLoss:0.0001 | CLSLoss:0.0028 | top1:68.2700 | AUROC:0.7856\n",
      "\n",
      "Epoch: [122 | 1000] LR: 0.015527\n",
      "Train | 16/16 | Loss:0.6861 | MainLoss:0.6832 | Alpha:0.3355 | SPLoss:0.0000 | CLSLoss:0.0029 | top1:57.7867 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6803 | MainLoss:0.6803 | SPLoss:0.0001 | CLSLoss:0.0032 | top1:59.7564 | AUROC:0.6598\n",
      "Test | 123/16 | Loss:0.6663 | MainLoss:0.6663 | SPLoss:0.0001 | CLSLoss:0.0032 | top1:69.1022 | AUROC:0.7896\n",
      "\n",
      "Epoch: [123 | 1000] LR: 0.015518\n",
      "Train | 16/16 | Loss:0.6864 | MainLoss:0.6832 | Alpha:0.3356 | SPLoss:0.0000 | CLSLoss:0.0033 | top1:58.5067 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6793 | MainLoss:0.6793 | SPLoss:0.0001 | CLSLoss:0.0034 | top1:60.7308 | AUROC:0.6616\n",
      "Test | 123/16 | Loss:0.6648 | MainLoss:0.6648 | SPLoss:0.0001 | CLSLoss:0.0034 | top1:70.9076 | AUROC:0.7901\n",
      "\n",
      "Epoch: [124 | 1000] LR: 0.015510\n",
      "Train | 16/16 | Loss:0.6854 | MainLoss:0.6819 | Alpha:0.3359 | SPLoss:0.0000 | CLSLoss:0.0035 | top1:58.0267 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6783 | MainLoss:0.6783 | SPLoss:0.0001 | CLSLoss:0.0037 | top1:61.2692 | AUROC:0.6642\n",
      "Test | 123/16 | Loss:0.6640 | MainLoss:0.6640 | SPLoss:0.0001 | CLSLoss:0.0037 | top1:72.3362 | AUROC:0.7889\n",
      "\n",
      "Epoch: [125 | 1000] LR: 0.015501\n",
      "Train | 16/16 | Loss:0.6862 | MainLoss:0.6826 | Alpha:0.3358 | SPLoss:0.0000 | CLSLoss:0.0036 | top1:58.9067 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6776 | MainLoss:0.6776 | SPLoss:0.0001 | CLSLoss:0.0037 | top1:61.5769 | AUROC:0.6687\n",
      "Test | 123/16 | Loss:0.6621 | MainLoss:0.6621 | SPLoss:0.0001 | CLSLoss:0.0037 | top1:73.1684 | AUROC:0.7958\n",
      "\n",
      "Epoch: [126 | 1000] LR: 0.015492\n",
      "Train | 16/16 | Loss:0.6834 | MainLoss:0.6793 | Alpha:0.3363 | SPLoss:0.0000 | CLSLoss:0.0041 | top1:59.3600 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6764 | MainLoss:0.6764 | SPLoss:0.0001 | CLSLoss:0.0041 | top1:62.4103 | AUROC:0.6726\n",
      "Test | 123/16 | Loss:0.6586 | MainLoss:0.6586 | SPLoss:0.0001 | CLSLoss:0.0041 | top1:75.3899 | AUROC:0.8151\n",
      "\n",
      "Epoch: [127 | 1000] LR: 0.015484\n",
      "Train | 16/16 | Loss:0.6846 | MainLoss:0.6804 | Alpha:0.3362 | SPLoss:0.0000 | CLSLoss:0.0042 | top1:58.3733 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6756 | MainLoss:0.6756 | SPLoss:0.0001 | CLSLoss:0.0042 | top1:62.6282 | AUROC:0.6766\n",
      "Test | 123/16 | Loss:0.6585 | MainLoss:0.6585 | SPLoss:0.0001 | CLSLoss:0.0042 | top1:75.4063 | AUROC:0.8100\n",
      "\n",
      "Epoch: [128 | 1000] LR: 0.015475\n",
      "Train | 16/16 | Loss:0.6831 | MainLoss:0.6787 | Alpha:0.3366 | SPLoss:0.0000 | CLSLoss:0.0044 | top1:59.9200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6742 | MainLoss:0.6742 | SPLoss:0.0001 | CLSLoss:0.0046 | top1:62.8846 | AUROC:0.6781\n",
      "Test | 123/16 | Loss:0.6574 | MainLoss:0.6574 | SPLoss:0.0001 | CLSLoss:0.0046 | top1:74.8591 | AUROC:0.8018\n",
      "\n",
      "Epoch: [129 | 1000] LR: 0.015466\n",
      "Train | 16/16 | Loss:0.6826 | MainLoss:0.6778 | Alpha:0.3367 | SPLoss:0.0000 | CLSLoss:0.0048 | top1:60.3200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6730 | MainLoss:0.6730 | SPLoss:0.0001 | CLSLoss:0.0048 | top1:63.1667 | AUROC:0.6801\n",
      "Test | 123/16 | Loss:0.6562 | MainLoss:0.6562 | SPLoss:0.0001 | CLSLoss:0.0048 | top1:74.7281 | AUROC:0.7956\n",
      "\n",
      "Epoch: [130 | 1000] LR: 0.015457\n",
      "Train | 16/16 | Loss:0.6793 | MainLoss:0.6743 | Alpha:0.3374 | SPLoss:0.0001 | CLSLoss:0.0050 | top1:61.5733 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6709 | MainLoss:0.6709 | SPLoss:0.0001 | CLSLoss:0.0057 | top1:62.6282 | AUROC:0.6844\n",
      "Test | 123/16 | Loss:0.6528 | MainLoss:0.6528 | SPLoss:0.0001 | CLSLoss:0.0057 | top1:73.4109 | AUROC:0.7909\n",
      "\n",
      "Epoch: [131 | 1000] LR: 0.015447\n",
      "Train | 16/16 | Loss:0.6813 | MainLoss:0.6757 | Alpha:0.3373 | SPLoss:0.0001 | CLSLoss:0.0056 | top1:61.1733 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6698 | MainLoss:0.6698 | SPLoss:0.0001 | CLSLoss:0.0056 | top1:63.5641 | AUROC:0.6886\n",
      "Test | 123/16 | Loss:0.6506 | MainLoss:0.6506 | SPLoss:0.0001 | CLSLoss:0.0056 | top1:74.7543 | AUROC:0.8022\n",
      "\n",
      "Epoch: [132 | 1000] LR: 0.015438\n",
      "Train | 16/16 | Loss:0.6802 | MainLoss:0.6744 | Alpha:0.3375 | SPLoss:0.0001 | CLSLoss:0.0058 | top1:60.9067 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6689 | MainLoss:0.6689 | SPLoss:0.0002 | CLSLoss:0.0058 | top1:63.8718 | AUROC:0.6927\n",
      "Test | 123/16 | Loss:0.6509 | MainLoss:0.6509 | SPLoss:0.0002 | CLSLoss:0.0058 | top1:76.4024 | AUROC:0.8062\n",
      "\n",
      "Epoch: [133 | 1000] LR: 0.015429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 16/16 | Loss:0.6785 | MainLoss:0.6726 | Alpha:0.3380 | SPLoss:0.0001 | CLSLoss:0.0059 | top1:62.0267 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6670 | MainLoss:0.6670 | SPLoss:0.0002 | CLSLoss:0.0062 | top1:64.3462 | AUROC:0.6963\n",
      "Test | 123/16 | Loss:0.6491 | MainLoss:0.6491 | SPLoss:0.0002 | CLSLoss:0.0062 | top1:76.0157 | AUROC:0.8018\n",
      "\n",
      "Epoch: [134 | 1000] LR: 0.015420\n",
      "Train | 16/16 | Loss:0.6798 | MainLoss:0.6736 | Alpha:0.3378 | SPLoss:0.0001 | CLSLoss:0.0062 | top1:61.5467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6661 | MainLoss:0.6661 | SPLoss:0.0002 | CLSLoss:0.0061 | top1:64.6154 | AUROC:0.6997\n",
      "Test | 123/16 | Loss:0.6478 | MainLoss:0.6478 | SPLoss:0.0002 | CLSLoss:0.0061 | top1:76.0223 | AUROC:0.8047\n",
      "\n",
      "Epoch: [135 | 1000] LR: 0.015410\n",
      "Train | 16/16 | Loss:0.6782 | MainLoss:0.6719 | Alpha:0.3383 | SPLoss:0.0001 | CLSLoss:0.0063 | top1:62.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6648 | MainLoss:0.6648 | SPLoss:0.0002 | CLSLoss:0.0062 | top1:64.9615 | AUROC:0.7053\n",
      "Test | 123/16 | Loss:0.6461 | MainLoss:0.6461 | SPLoss:0.0002 | CLSLoss:0.0062 | top1:75.9731 | AUROC:0.8082\n",
      "\n",
      "Epoch: [136 | 1000] LR: 0.015401\n",
      "Train | 16/16 | Loss:0.6743 | MainLoss:0.6676 | Alpha:0.3390 | SPLoss:0.0001 | CLSLoss:0.0067 | top1:62.5867 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6623 | MainLoss:0.6623 | SPLoss:0.0002 | CLSLoss:0.0071 | top1:65.3205 | AUROC:0.7085\n",
      "Test | 123/16 | Loss:0.6411 | MainLoss:0.6411 | SPLoss:0.0002 | CLSLoss:0.0071 | top1:77.4312 | AUROC:0.8199\n",
      "\n",
      "Epoch: [137 | 1000] LR: 0.015391\n",
      "Train | 16/16 | Loss:0.6731 | MainLoss:0.6656 | Alpha:0.3394 | SPLoss:0.0001 | CLSLoss:0.0075 | top1:63.7867 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6603 | MainLoss:0.6603 | SPLoss:0.0002 | CLSLoss:0.0076 | top1:65.7179 | AUROC:0.7129\n",
      "Test | 123/16 | Loss:0.6432 | MainLoss:0.6432 | SPLoss:0.0002 | CLSLoss:0.0076 | top1:76.7562 | AUROC:0.8067\n",
      "\n",
      "Epoch: [138 | 1000] LR: 0.015381\n",
      "Train | 16/16 | Loss:0.6717 | MainLoss:0.6640 | Alpha:0.3397 | SPLoss:0.0001 | CLSLoss:0.0077 | top1:63.2000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6581 | MainLoss:0.6581 | SPLoss:0.0002 | CLSLoss:0.0082 | top1:66.1538 | AUROC:0.7172\n",
      "Test | 123/16 | Loss:0.6404 | MainLoss:0.6404 | SPLoss:0.0002 | CLSLoss:0.0082 | top1:77.4738 | AUROC:0.8119\n",
      "\n",
      "Epoch: [139 | 1000] LR: 0.015372\n",
      "Train | 16/16 | Loss:0.6729 | MainLoss:0.6644 | Alpha:0.3398 | SPLoss:0.0001 | CLSLoss:0.0084 | top1:63.9200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6565 | MainLoss:0.6565 | SPLoss:0.0003 | CLSLoss:0.0083 | top1:66.6667 | AUROC:0.7220\n",
      "Test | 123/16 | Loss:0.6396 | MainLoss:0.6396 | SPLoss:0.0003 | CLSLoss:0.0083 | top1:77.4017 | AUROC:0.8123\n",
      "\n",
      "Epoch: [140 | 1000] LR: 0.015362\n",
      "Train | 16/16 | Loss:0.6701 | MainLoss:0.6616 | Alpha:0.3407 | SPLoss:0.0001 | CLSLoss:0.0085 | top1:64.0267 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6542 | MainLoss:0.6542 | SPLoss:0.0003 | CLSLoss:0.0089 | top1:66.8846 | AUROC:0.7259\n",
      "Test | 123/16 | Loss:0.6386 | MainLoss:0.6386 | SPLoss:0.0003 | CLSLoss:0.0089 | top1:77.2903 | AUROC:0.8101\n",
      "\n",
      "Epoch: [141 | 1000] LR: 0.015352\n",
      "Train | 16/16 | Loss:0.6700 | MainLoss:0.6611 | Alpha:0.3408 | SPLoss:0.0001 | CLSLoss:0.0089 | top1:64.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6528 | MainLoss:0.6528 | SPLoss:0.0003 | CLSLoss:0.0091 | top1:67.1923 | AUROC:0.7286\n",
      "Test | 123/16 | Loss:0.6382 | MainLoss:0.6382 | SPLoss:0.0003 | CLSLoss:0.0091 | top1:77.3132 | AUROC:0.8143\n",
      "\n",
      "Epoch: [142 | 1000] LR: 0.015342\n",
      "Train | 16/16 | Loss:0.6697 | MainLoss:0.6605 | Alpha:0.3406 | SPLoss:0.0001 | CLSLoss:0.0091 | top1:64.5333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6507 | MainLoss:0.6507 | SPLoss:0.0003 | CLSLoss:0.0093 | top1:67.6923 | AUROC:0.7313\n",
      "Test | 123/16 | Loss:0.6355 | MainLoss:0.6355 | SPLoss:0.0003 | CLSLoss:0.0093 | top1:76.9823 | AUROC:0.8110\n",
      "\n",
      "Epoch: [143 | 1000] LR: 0.015332\n",
      "Train | 16/16 | Loss:0.6677 | MainLoss:0.6583 | Alpha:0.3416 | SPLoss:0.0001 | CLSLoss:0.0094 | top1:65.3333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6483 | MainLoss:0.6483 | SPLoss:0.0003 | CLSLoss:0.0094 | top1:68.0000 | AUROC:0.7374\n",
      "Test | 123/16 | Loss:0.6325 | MainLoss:0.6325 | SPLoss:0.0003 | CLSLoss:0.0094 | top1:76.6547 | AUROC:0.8124\n",
      "\n",
      "Epoch: [144 | 1000] LR: 0.015322\n",
      "Train | 16/16 | Loss:0.6619 | MainLoss:0.6519 | Alpha:0.3425 | SPLoss:0.0002 | CLSLoss:0.0100 | top1:66.5867 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6449 | MainLoss:0.6449 | SPLoss:0.0004 | CLSLoss:0.0104 | top1:68.3462 | AUROC:0.7420\n",
      "Test | 123/16 | Loss:0.6304 | MainLoss:0.6304 | SPLoss:0.0004 | CLSLoss:0.0104 | top1:76.7693 | AUROC:0.8164\n",
      "\n",
      "Epoch: [145 | 1000] LR: 0.015312\n",
      "Train | 16/16 | Loss:0.6624 | MainLoss:0.6514 | Alpha:0.3430 | SPLoss:0.0002 | CLSLoss:0.0109 | top1:65.8133 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6444 | MainLoss:0.6444 | SPLoss:0.0004 | CLSLoss:0.0106 | top1:68.4744 | AUROC:0.7464\n",
      "Test | 123/16 | Loss:0.6322 | MainLoss:0.6322 | SPLoss:0.0004 | CLSLoss:0.0106 | top1:75.5243 | AUROC:0.8242\n",
      "\n",
      "Epoch: [146 | 1000] LR: 0.015302\n",
      "Train | 16/16 | Loss:0.6652 | MainLoss:0.6545 | Alpha:0.3419 | SPLoss:0.0002 | CLSLoss:0.0106 | top1:65.4667 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6409 | MainLoss:0.6409 | SPLoss:0.0004 | CLSLoss:0.0105 | top1:69.1667 | AUROC:0.7510\n",
      "Test | 123/16 | Loss:0.6300 | MainLoss:0.6300 | SPLoss:0.0004 | CLSLoss:0.0105 | top1:75.9862 | AUROC:0.8144\n",
      "\n",
      "Epoch: [147 | 1000] LR: 0.015291\n",
      "Train | 16/16 | Loss:0.6579 | MainLoss:0.6468 | Alpha:0.3436 | SPLoss:0.0002 | CLSLoss:0.0110 | top1:65.6533 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6397 | MainLoss:0.6397 | SPLoss:0.0005 | CLSLoss:0.0119 | top1:68.9231 | AUROC:0.7528\n",
      "Test | 123/16 | Loss:0.6303 | MainLoss:0.6303 | SPLoss:0.0005 | CLSLoss:0.0119 | top1:74.8165 | AUROC:0.8257\n",
      "\n",
      "Epoch: [148 | 1000] LR: 0.015281\n",
      "Train | 16/16 | Loss:0.6564 | MainLoss:0.6445 | Alpha:0.3443 | SPLoss:0.0002 | CLSLoss:0.0119 | top1:66.8000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6348 | MainLoss:0.6348 | SPLoss:0.0007 | CLSLoss:0.0128 | top1:69.5000 | AUROC:0.7579\n",
      "Test | 123/16 | Loss:0.6225 | MainLoss:0.6225 | SPLoss:0.0007 | CLSLoss:0.0128 | top1:75.8093 | AUROC:0.8102\n",
      "\n",
      "Epoch: [149 | 1000] LR: 0.015270\n",
      "Train | 16/16 | Loss:0.6598 | MainLoss:0.6473 | Alpha:0.3437 | SPLoss:0.0003 | CLSLoss:0.0125 | top1:66.0533 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6321 | MainLoss:0.6321 | SPLoss:0.0005 | CLSLoss:0.0123 | top1:70.3333 | AUROC:0.7629\n",
      "Test | 123/16 | Loss:0.6183 | MainLoss:0.6183 | SPLoss:0.0005 | CLSLoss:0.0123 | top1:75.8421 | AUROC:0.8321\n",
      "\n",
      "Epoch: [150 | 1000] LR: 0.015260\n",
      "Train | 16/16 | Loss:0.6557 | MainLoss:0.6428 | Alpha:0.3449 | SPLoss:0.0002 | CLSLoss:0.0129 | top1:66.1333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6340 | MainLoss:0.6340 | SPLoss:0.0006 | CLSLoss:0.0129 | top1:69.5128 | AUROC:0.7652\n",
      "Test | 123/16 | Loss:0.6224 | MainLoss:0.6224 | SPLoss:0.0006 | CLSLoss:0.0129 | top1:74.2398 | AUROC:0.8373\n",
      "\n",
      "Epoch: [151 | 1000] LR: 0.015249\n",
      "Train | 16/16 | Loss:0.6496 | MainLoss:0.6362 | Alpha:0.3457 | SPLoss:0.0002 | CLSLoss:0.0133 | top1:68.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6263 | MainLoss:0.6263 | SPLoss:0.0006 | CLSLoss:0.0141 | top1:70.8205 | AUROC:0.7682\n",
      "Test | 123/16 | Loss:0.6243 | MainLoss:0.6243 | SPLoss:0.0006 | CLSLoss:0.0141 | top1:73.8041 | AUROC:0.8135\n",
      "\n",
      "Epoch: [152 | 1000] LR: 0.015239\n",
      "Train | 16/16 | Loss:0.6512 | MainLoss:0.6368 | Alpha:0.3463 | SPLoss:0.0003 | CLSLoss:0.0143 | top1:67.3333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6281 | MainLoss:0.6281 | SPLoss:0.0009 | CLSLoss:0.0137 | top1:70.0385 | AUROC:0.7733\n",
      "Test | 123/16 | Loss:0.6055 | MainLoss:0.6055 | SPLoss:0.0009 | CLSLoss:0.0137 | top1:76.4319 | AUROC:0.8573\n",
      "\n",
      "Epoch: [153 | 1000] LR: 0.015228\n",
      "Train | 16/16 | Loss:0.6469 | MainLoss:0.6327 | Alpha:0.3464 | SPLoss:0.0003 | CLSLoss:0.0141 | top1:67.9467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6199 | MainLoss:0.6199 | SPLoss:0.0007 | CLSLoss:0.0147 | top1:71.4744 | AUROC:0.7778\n",
      "Test | 123/16 | Loss:0.6129 | MainLoss:0.6129 | SPLoss:0.0007 | CLSLoss:0.0147 | top1:75.1016 | AUROC:0.8324\n",
      "\n",
      "Epoch: [154 | 1000] LR: 0.015217\n",
      "Train | 16/16 | Loss:0.6424 | MainLoss:0.6270 | Alpha:0.3485 | SPLoss:0.0003 | CLSLoss:0.0153 | top1:68.9333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6152 | MainLoss:0.6152 | SPLoss:0.0007 | CLSLoss:0.0157 | top1:71.9231 | AUROC:0.7842\n",
      "Test | 123/16 | Loss:0.5999 | MainLoss:0.5999 | SPLoss:0.0007 | CLSLoss:0.0157 | top1:76.5596 | AUROC:0.8440\n",
      "\n",
      "Epoch: [155 | 1000] LR: 0.015206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 16/16 | Loss:0.6424 | MainLoss:0.6262 | Alpha:0.3491 | SPLoss:0.0004 | CLSLoss:0.0160 | top1:69.6000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6149 | MainLoss:0.6149 | SPLoss:0.0008 | CLSLoss:0.0160 | top1:71.4487 | AUROC:0.7844\n",
      "Test | 123/16 | Loss:0.6105 | MainLoss:0.6105 | SPLoss:0.0008 | CLSLoss:0.0160 | top1:74.1743 | AUROC:0.8395\n",
      "\n",
      "Epoch: [156 | 1000] LR: 0.015195\n",
      "Train | 16/16 | Loss:0.6340 | MainLoss:0.6174 | Alpha:0.3499 | SPLoss:0.0003 | CLSLoss:0.0165 | top1:70.2400 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6119 | MainLoss:0.6119 | SPLoss:0.0009 | CLSLoss:0.0175 | top1:72.0000 | AUROC:0.7882\n",
      "Test | 123/16 | Loss:0.6150 | MainLoss:0.6150 | SPLoss:0.0009 | CLSLoss:0.0175 | top1:73.8762 | AUROC:0.8085\n",
      "\n",
      "Epoch: [157 | 1000] LR: 0.015184\n",
      "Train | 16/16 | Loss:0.6404 | MainLoss:0.6230 | Alpha:0.3490 | SPLoss:0.0006 | CLSLoss:0.0172 | top1:69.0400 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6071 | MainLoss:0.6071 | SPLoss:0.0010 | CLSLoss:0.0170 | top1:72.3077 | AUROC:0.7911\n",
      "Test | 123/16 | Loss:0.6010 | MainLoss:0.6010 | SPLoss:0.0010 | CLSLoss:0.0170 | top1:74.2267 | AUROC:0.8415\n",
      "\n",
      "Epoch: [158 | 1000] LR: 0.015173\n",
      "Train | 16/16 | Loss:0.6336 | MainLoss:0.6163 | Alpha:0.3509 | SPLoss:0.0003 | CLSLoss:0.0171 | top1:70.1333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.6027 | MainLoss:0.6027 | SPLoss:0.0008 | CLSLoss:0.0179 | top1:72.9359 | AUROC:0.7937\n",
      "Test | 123/16 | Loss:0.6049 | MainLoss:0.6049 | SPLoss:0.0008 | CLSLoss:0.0179 | top1:73.9515 | AUROC:0.8238\n",
      "\n",
      "Epoch: [159 | 1000] LR: 0.015162\n",
      "Train | 16/16 | Loss:0.6231 | MainLoss:0.6044 | Alpha:0.3531 | SPLoss:0.0005 | CLSLoss:0.0185 | top1:71.4933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.5970 | MainLoss:0.5970 | SPLoss:0.0010 | CLSLoss:0.0197 | top1:73.1410 | AUROC:0.7964\n",
      "Test | 123/16 | Loss:0.6128 | MainLoss:0.6128 | SPLoss:0.0010 | CLSLoss:0.0197 | top1:71.5170 | AUROC:0.8176\n",
      "\n",
      "Epoch: [160 | 1000] LR: 0.015151\n",
      "Train | 16/16 | Loss:0.6249 | MainLoss:0.6048 | Alpha:0.3539 | SPLoss:0.0005 | CLSLoss:0.0198 | top1:70.6933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.5952 | MainLoss:0.5952 | SPLoss:0.0010 | CLSLoss:0.0202 | top1:73.2692 | AUROC:0.8000\n",
      "Test | 123/16 | Loss:0.6106 | MainLoss:0.6106 | SPLoss:0.0010 | CLSLoss:0.0202 | top1:72.9030 | AUROC:0.8032\n",
      "\n",
      "Epoch: [161 | 1000] LR: 0.015139\n",
      "Train | 16/16 | Loss:0.6184 | MainLoss:0.5975 | Alpha:0.3540 | SPLoss:0.0008 | CLSLoss:0.0206 | top1:71.6267 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.5870 | MainLoss:0.5870 | SPLoss:0.0017 | CLSLoss:0.0211 | top1:73.4487 | AUROC:0.8054\n",
      "Test | 123/16 | Loss:0.6011 | MainLoss:0.6011 | SPLoss:0.0017 | CLSLoss:0.0211 | top1:71.6481 | AUROC:0.8167\n",
      "\n",
      "Epoch: [162 | 1000] LR: 0.015128\n",
      "Train | 16/16 | Loss:0.6147 | MainLoss:0.5936 | Alpha:0.3551 | SPLoss:0.0009 | CLSLoss:0.0207 | top1:71.0400 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.5720 | MainLoss:0.5720 | SPLoss:0.0018 | CLSLoss:0.0204 | top1:73.2179 | AUROC:0.8053\n",
      "Test | 123/16 | Loss:0.5817 | MainLoss:0.5817 | SPLoss:0.0018 | CLSLoss:0.0204 | top1:71.6874 | AUROC:0.8391\n",
      "\n",
      "Epoch: [163 | 1000] LR: 0.015117\n",
      "Train | 16/16 | Loss:0.6091 | MainLoss:0.5878 | Alpha:0.3588 | SPLoss:0.0007 | CLSLoss:0.0210 | top1:70.9333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.5697 | MainLoss:0.5697 | SPLoss:0.0013 | CLSLoss:0.0200 | top1:73.7436 | AUROC:0.8114\n",
      "Test | 123/16 | Loss:0.5850 | MainLoss:0.5850 | SPLoss:0.0013 | CLSLoss:0.0200 | top1:71.7759 | AUROC:0.8359\n",
      "\n",
      "Epoch: [164 | 1000] LR: 0.015105\n",
      "Train | 16/16 | Loss:0.5988 | MainLoss:0.5780 | Alpha:0.3598 | SPLoss:0.0008 | CLSLoss:0.0206 | top1:72.3200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.5617 | MainLoss:0.5617 | SPLoss:0.0015 | CLSLoss:0.0211 | top1:74.5769 | AUROC:0.8211\n",
      "Test | 123/16 | Loss:0.5892 | MainLoss:0.5892 | SPLoss:0.0015 | CLSLoss:0.0211 | top1:72.3591 | AUROC:0.8204\n",
      "\n",
      "Epoch: [165 | 1000] LR: 0.015094\n",
      "Train | 16/16 | Loss:0.6015 | MainLoss:0.5805 | Alpha:0.3611 | SPLoss:0.0008 | CLSLoss:0.0207 | top1:72.2667 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.5627 | MainLoss:0.5627 | SPLoss:0.0016 | CLSLoss:0.0215 | top1:75.2179 | AUROC:0.8279\n",
      "Test | 123/16 | Loss:0.5769 | MainLoss:0.5769 | SPLoss:0.0016 | CLSLoss:0.0215 | top1:74.0891 | AUROC:0.8277\n",
      "\n",
      "Epoch: [166 | 1000] LR: 0.015082\n",
      "Train | 16/16 | Loss:0.6031 | MainLoss:0.5814 | Alpha:0.3598 | SPLoss:0.0009 | CLSLoss:0.0213 | top1:72.6667 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.5540 | MainLoss:0.5540 | SPLoss:0.0014 | CLSLoss:0.0213 | top1:75.6923 | AUROC:0.8351\n",
      "Test | 123/16 | Loss:0.5700 | MainLoss:0.5700 | SPLoss:0.0014 | CLSLoss:0.0213 | top1:74.1514 | AUROC:0.8371\n",
      "\n",
      "Epoch: [167 | 1000] LR: 0.015070\n",
      "Train | 16/16 | Loss:0.5939 | MainLoss:0.5723 | Alpha:0.3608 | SPLoss:0.0007 | CLSLoss:0.0214 | top1:72.7467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.5567 | MainLoss:0.5567 | SPLoss:0.0016 | CLSLoss:0.0220 | top1:74.1154 | AUROC:0.8391\n",
      "Test | 123/16 | Loss:0.5625 | MainLoss:0.5625 | SPLoss:0.0016 | CLSLoss:0.0220 | top1:73.1651 | AUROC:0.8639\n",
      "\n",
      "Epoch: [168 | 1000] LR: 0.015058\n",
      "Train | 16/16 | Loss:0.5872 | MainLoss:0.5636 | Alpha:0.3615 | SPLoss:0.0009 | CLSLoss:0.0232 | top1:73.3600 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.5578 | MainLoss:0.5578 | SPLoss:0.0016 | CLSLoss:0.0233 | top1:73.5385 | AUROC:0.8430\n",
      "Test | 123/16 | Loss:0.5717 | MainLoss:0.5717 | SPLoss:0.0016 | CLSLoss:0.0233 | top1:71.8087 | AUROC:0.8649\n",
      "\n",
      "Epoch: [169 | 1000] LR: 0.015046\n",
      "Train | 16/16 | Loss:0.5817 | MainLoss:0.5575 | Alpha:0.3612 | SPLoss:0.0008 | CLSLoss:0.0239 | top1:73.4667 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.5399 | MainLoss:0.5399 | SPLoss:0.0021 | CLSLoss:0.0246 | top1:76.6923 | AUROC:0.8498\n",
      "Test | 123/16 | Loss:0.5545 | MainLoss:0.5545 | SPLoss:0.0021 | CLSLoss:0.0246 | top1:75.8650 | AUROC:0.8427\n",
      "\n",
      "Epoch: [170 | 1000] LR: 0.015035\n",
      "Train | 16/16 | Loss:0.5859 | MainLoss:0.5615 | Alpha:0.3649 | SPLoss:0.0008 | CLSLoss:0.0241 | top1:73.9200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.5300 | MainLoss:0.5300 | SPLoss:0.0014 | CLSLoss:0.0236 | top1:77.0128 | AUROC:0.8527\n",
      "Test | 123/16 | Loss:0.5538 | MainLoss:0.5538 | SPLoss:0.0014 | CLSLoss:0.0236 | top1:74.4397 | AUROC:0.8549\n",
      "\n",
      "Epoch: [171 | 1000] LR: 0.015023\n",
      "Train | 16/16 | Loss:0.5756 | MainLoss:0.5509 | Alpha:0.3674 | SPLoss:0.0008 | CLSLoss:0.0244 | top1:74.7467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.5304 | MainLoss:0.5304 | SPLoss:0.0015 | CLSLoss:0.0248 | top1:77.2949 | AUROC:0.8579\n",
      "Test | 123/16 | Loss:0.5405 | MainLoss:0.5405 | SPLoss:0.0015 | CLSLoss:0.0248 | top1:76.8644 | AUROC:0.8567\n",
      "\n",
      "Epoch: [172 | 1000] LR: 0.015010\n",
      "Train | 16/16 | Loss:0.5762 | MainLoss:0.5514 | Alpha:0.3663 | SPLoss:0.0006 | CLSLoss:0.0246 | top1:75.4933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.5200 | MainLoss:0.5200 | SPLoss:0.0013 | CLSLoss:0.0251 | top1:77.7051 | AUROC:0.8615\n",
      "Test | 123/16 | Loss:0.5407 | MainLoss:0.5407 | SPLoss:0.0013 | CLSLoss:0.0251 | top1:75.7208 | AUROC:0.8616\n",
      "\n",
      "Epoch: [173 | 1000] LR: 0.014998\n",
      "Train | 16/16 | Loss:0.5596 | MainLoss:0.5328 | Alpha:0.3716 | SPLoss:0.0008 | CLSLoss:0.0265 | top1:76.9867 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.5202 | MainLoss:0.5202 | SPLoss:0.0019 | CLSLoss:0.0266 | top1:77.1667 | AUROC:0.8631\n",
      "Test | 123/16 | Loss:0.5406 | MainLoss:0.5406 | SPLoss:0.0019 | CLSLoss:0.0266 | top1:74.7641 | AUROC:0.8755\n",
      "\n",
      "Epoch: [174 | 1000] LR: 0.014986\n",
      "Train | 16/16 | Loss:0.5534 | MainLoss:0.5253 | Alpha:0.3722 | SPLoss:0.0008 | CLSLoss:0.0278 | top1:76.7467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.5112 | MainLoss:0.5112 | SPLoss:0.0017 | CLSLoss:0.0291 | top1:78.2308 | AUROC:0.8681\n",
      "Test | 123/16 | Loss:0.5297 | MainLoss:0.5297 | SPLoss:0.0017 | CLSLoss:0.0291 | top1:76.4613 | AUROC:0.8714\n",
      "\n",
      "Epoch: [175 | 1000] LR: 0.014974\n",
      "Train | 16/16 | Loss:0.5577 | MainLoss:0.5279 | Alpha:0.3728 | SPLoss:0.0007 | CLSLoss:0.0296 | top1:76.1867 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.5218 | MainLoss:0.5218 | SPLoss:0.0016 | CLSLoss:0.0298 | top1:78.3077 | AUROC:0.8688\n",
      "Test | 123/16 | Loss:0.5401 | MainLoss:0.5401 | SPLoss:0.0016 | CLSLoss:0.0298 | top1:76.6252 | AUROC:0.8533\n",
      "\n",
      "Epoch: [176 | 1000] LR: 0.014961\n",
      "Train | 16/16 | Loss:0.5591 | MainLoss:0.5297 | Alpha:0.3692 | SPLoss:0.0009 | CLSLoss:0.0290 | top1:76.2400 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.5046 | MainLoss:0.5046 | SPLoss:0.0013 | CLSLoss:0.0301 | top1:78.8462 | AUROC:0.8705\n",
      "Test | 123/16 | Loss:0.5300 | MainLoss:0.5300 | SPLoss:0.0013 | CLSLoss:0.0301 | top1:76.5039 | AUROC:0.8632\n",
      "\n",
      "Epoch: [177 | 1000] LR: 0.014949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 16/16 | Loss:0.5524 | MainLoss:0.5225 | Alpha:0.3751 | SPLoss:0.0008 | CLSLoss:0.0296 | top1:77.0133 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.5156 | MainLoss:0.5156 | SPLoss:0.0015 | CLSLoss:0.0303 | top1:78.7308 | AUROC:0.8756\n",
      "Test | 123/16 | Loss:0.5308 | MainLoss:0.5308 | SPLoss:0.0015 | CLSLoss:0.0303 | top1:77.3657 | AUROC:0.8599\n",
      "\n",
      "Epoch: [178 | 1000] LR: 0.014937\n",
      "Train | 16/16 | Loss:0.5476 | MainLoss:0.5171 | Alpha:0.3714 | SPLoss:0.0010 | CLSLoss:0.0302 | top1:77.6800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.4944 | MainLoss:0.4944 | SPLoss:0.0016 | CLSLoss:0.0299 | top1:79.8205 | AUROC:0.8798\n",
      "Test | 123/16 | Loss:0.5210 | MainLoss:0.5210 | SPLoss:0.0016 | CLSLoss:0.0299 | top1:77.4738 | AUROC:0.8751\n",
      "\n",
      "Epoch: [179 | 1000] LR: 0.014924\n",
      "Train | 16/16 | Loss:0.5385 | MainLoss:0.5070 | Alpha:0.3768 | SPLoss:0.0007 | CLSLoss:0.0312 | top1:77.9200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.4870 | MainLoss:0.4870 | SPLoss:0.0013 | CLSLoss:0.0319 | top1:80.0256 | AUROC:0.8836\n",
      "Test | 123/16 | Loss:0.5131 | MainLoss:0.5131 | SPLoss:0.0013 | CLSLoss:0.0319 | top1:77.7163 | AUROC:0.8830\n",
      "\n",
      "Epoch: [180 | 1000] LR: 0.014911\n",
      "Train | 16/16 | Loss:0.5347 | MainLoss:0.5018 | Alpha:0.3790 | SPLoss:0.0008 | CLSLoss:0.0325 | top1:78.2667 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.4922 | MainLoss:0.4922 | SPLoss:0.0017 | CLSLoss:0.0326 | top1:79.6923 | AUROC:0.8873\n",
      "Test | 123/16 | Loss:0.5414 | MainLoss:0.5414 | SPLoss:0.0017 | CLSLoss:0.0326 | top1:74.1612 | AUROC:0.8785\n",
      "\n",
      "Epoch: [181 | 1000] LR: 0.014899\n",
      "Train | 16/16 | Loss:0.5348 | MainLoss:0.5020 | Alpha:0.3767 | SPLoss:0.0008 | CLSLoss:0.0326 | top1:78.8000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.4763 | MainLoss:0.4763 | SPLoss:0.0013 | CLSLoss:0.0331 | top1:80.8333 | AUROC:0.8902\n",
      "Test | 123/16 | Loss:0.5194 | MainLoss:0.5194 | SPLoss:0.0013 | CLSLoss:0.0331 | top1:76.7890 | AUROC:0.8724\n",
      "\n",
      "Epoch: [182 | 1000] LR: 0.014886\n",
      "Train | 16/16 | Loss:0.5209 | MainLoss:0.4869 | Alpha:0.3827 | SPLoss:0.0007 | CLSLoss:0.0337 | top1:79.4933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.4772 | MainLoss:0.4772 | SPLoss:0.0013 | CLSLoss:0.0350 | top1:81.0641 | AUROC:0.8898\n",
      "Test | 123/16 | Loss:0.5266 | MainLoss:0.5266 | SPLoss:0.0013 | CLSLoss:0.0350 | top1:76.6415 | AUROC:0.8579\n",
      "\n",
      "Epoch: [183 | 1000] LR: 0.014873\n",
      "Train | 16/16 | Loss:0.5233 | MainLoss:0.4882 | Alpha:0.3820 | SPLoss:0.0007 | CLSLoss:0.0348 | top1:79.3867 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.4712 | MainLoss:0.4712 | SPLoss:0.0016 | CLSLoss:0.0351 | top1:80.7692 | AUROC:0.8974\n",
      "Test | 123/16 | Loss:0.5260 | MainLoss:0.5260 | SPLoss:0.0016 | CLSLoss:0.0351 | top1:74.9607 | AUROC:0.8837\n",
      "\n",
      "Epoch: [184 | 1000] LR: 0.014860\n",
      "Train | 16/16 | Loss:0.5215 | MainLoss:0.4860 | Alpha:0.3805 | SPLoss:0.0006 | CLSLoss:0.0352 | top1:79.2800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.4674 | MainLoss:0.4674 | SPLoss:0.0013 | CLSLoss:0.0357 | top1:80.6667 | AUROC:0.8944\n",
      "Test | 123/16 | Loss:0.5205 | MainLoss:0.5205 | SPLoss:0.0013 | CLSLoss:0.0357 | top1:75.6160 | AUROC:0.8839\n",
      "\n",
      "Epoch: [185 | 1000] LR: 0.014847\n",
      "Train | 16/16 | Loss:0.5209 | MainLoss:0.4850 | Alpha:0.3818 | SPLoss:0.0006 | CLSLoss:0.0356 | top1:79.5467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.4579 | MainLoss:0.4579 | SPLoss:0.0012 | CLSLoss:0.0358 | top1:82.0000 | AUROC:0.9003\n",
      "Test | 123/16 | Loss:0.5094 | MainLoss:0.5094 | SPLoss:0.0012 | CLSLoss:0.0358 | top1:77.1920 | AUROC:0.8818\n",
      "\n",
      "Epoch: [186 | 1000] LR: 0.014834\n",
      "Train | 16/16 | Loss:0.5239 | MainLoss:0.4886 | Alpha:0.3834 | SPLoss:0.0007 | CLSLoss:0.0351 | top1:79.0933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.4549 | MainLoss:0.4549 | SPLoss:0.0012 | CLSLoss:0.0359 | top1:82.3846 | AUROC:0.9044\n",
      "Test | 123/16 | Loss:0.5101 | MainLoss:0.5101 | SPLoss:0.0012 | CLSLoss:0.0359 | top1:77.1494 | AUROC:0.8817\n",
      "\n",
      "Epoch: [187 | 1000] LR: 0.014821\n",
      "Train | 16/16 | Loss:0.5090 | MainLoss:0.4721 | Alpha:0.3851 | SPLoss:0.0008 | CLSLoss:0.0367 | top1:80.5600 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.4755 | MainLoss:0.4755 | SPLoss:0.0020 | CLSLoss:0.0371 | top1:79.7692 | AUROC:0.9070\n",
      "Test | 123/16 | Loss:0.5461 | MainLoss:0.5461 | SPLoss:0.0020 | CLSLoss:0.0371 | top1:72.3296 | AUROC:0.8945\n",
      "\n",
      "Epoch: [188 | 1000] LR: 0.014808\n",
      "Train | 16/16 | Loss:0.5212 | MainLoss:0.4843 | Alpha:0.3787 | SPLoss:0.0012 | CLSLoss:0.0364 | top1:80.7733 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.4478 | MainLoss:0.4478 | SPLoss:0.0020 | CLSLoss:0.0359 | top1:83.0897 | AUROC:0.9083\n",
      "Test | 123/16 | Loss:0.5126 | MainLoss:0.5126 | SPLoss:0.0020 | CLSLoss:0.0359 | top1:77.0544 | AUROC:0.8718\n",
      "\n",
      "Epoch: [189 | 1000] LR: 0.014795\n",
      "Train | 16/16 | Loss:0.5050 | MainLoss:0.4685 | Alpha:0.3871 | SPLoss:0.0008 | CLSLoss:0.0362 | top1:80.7733 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.4774 | MainLoss:0.4774 | SPLoss:0.0022 | CLSLoss:0.0363 | top1:79.3333 | AUROC:0.9085\n",
      "Test | 123/16 | Loss:0.5663 | MainLoss:0.5663 | SPLoss:0.0022 | CLSLoss:0.0363 | top1:69.8493 | AUROC:0.8841\n",
      "\n",
      "Epoch: [190 | 1000] LR: 0.014781\n",
      "Train | 16/16 | Loss:0.4953 | MainLoss:0.4577 | Alpha:0.3795 | SPLoss:0.0011 | CLSLoss:0.0372 | top1:80.5333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.4269 | MainLoss:0.4269 | SPLoss:0.0021 | CLSLoss:0.0381 | top1:83.4487 | AUROC:0.9148\n",
      "Test | 123/16 | Loss:0.5071 | MainLoss:0.5071 | SPLoss:0.0021 | CLSLoss:0.0381 | top1:76.3368 | AUROC:0.8728\n",
      "\n",
      "Epoch: [191 | 1000] LR: 0.014768\n",
      "Train | 16/16 | Loss:0.4836 | MainLoss:0.4442 | Alpha:0.3918 | SPLoss:0.0007 | CLSLoss:0.0391 | top1:81.7333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.4211 | MainLoss:0.4211 | SPLoss:0.0015 | CLSLoss:0.0392 | top1:83.4487 | AUROC:0.9170\n",
      "Test | 123/16 | Loss:0.5100 | MainLoss:0.5100 | SPLoss:0.0015 | CLSLoss:0.0392 | top1:75.6881 | AUROC:0.8747\n",
      "\n",
      "Epoch: [192 | 1000] LR: 0.014755\n",
      "Train | 16/16 | Loss:0.4792 | MainLoss:0.4394 | Alpha:0.3935 | SPLoss:0.0008 | CLSLoss:0.0395 | top1:81.9733 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.4157 | MainLoss:0.4157 | SPLoss:0.0015 | CLSLoss:0.0395 | top1:83.7564 | AUROC:0.9165\n",
      "Test | 123/16 | Loss:0.5215 | MainLoss:0.5215 | SPLoss:0.0015 | CLSLoss:0.0395 | top1:74.8591 | AUROC:0.8621\n",
      "\n",
      "Epoch: [193 | 1000] LR: 0.014741\n",
      "Train | 16/16 | Loss:0.4721 | MainLoss:0.4323 | Alpha:0.3970 | SPLoss:0.0009 | CLSLoss:0.0395 | top1:82.7467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.4124 | MainLoss:0.4124 | SPLoss:0.0019 | CLSLoss:0.0400 | top1:83.3718 | AUROC:0.9199\n",
      "Test | 123/16 | Loss:0.5325 | MainLoss:0.5325 | SPLoss:0.0019 | CLSLoss:0.0400 | top1:73.0111 | AUROC:0.8660\n",
      "\n",
      "Epoch: [194 | 1000] LR: 0.014728\n",
      "Train | 16/16 | Loss:0.4778 | MainLoss:0.4375 | Alpha:0.3940 | SPLoss:0.0010 | CLSLoss:0.0399 | top1:81.9200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.4097 | MainLoss:0.4097 | SPLoss:0.0020 | CLSLoss:0.0395 | top1:84.1282 | AUROC:0.9216\n",
      "Test | 123/16 | Loss:0.5009 | MainLoss:0.5009 | SPLoss:0.0020 | CLSLoss:0.0395 | top1:76.7071 | AUROC:0.8651\n",
      "\n",
      "Epoch: [195 | 1000] LR: 0.014714\n",
      "Train | 16/16 | Loss:0.4688 | MainLoss:0.4290 | Alpha:0.3970 | SPLoss:0.0010 | CLSLoss:0.0394 | top1:82.2933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.4016 | MainLoss:0.4016 | SPLoss:0.0018 | CLSLoss:0.0406 | top1:84.2821 | AUROC:0.9210\n",
      "Test | 123/16 | Loss:0.5145 | MainLoss:0.5145 | SPLoss:0.0018 | CLSLoss:0.0406 | top1:75.2621 | AUROC:0.8597\n",
      "\n",
      "Epoch: [196 | 1000] LR: 0.014700\n",
      "Train | 16/16 | Loss:0.4587 | MainLoss:0.4180 | Alpha:0.3977 | SPLoss:0.0008 | CLSLoss:0.0403 | top1:82.8800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3992 | MainLoss:0.3992 | SPLoss:0.0017 | CLSLoss:0.0398 | top1:84.5769 | AUROC:0.9250\n",
      "Test | 123/16 | Loss:0.4973 | MainLoss:0.4973 | SPLoss:0.0017 | CLSLoss:0.0398 | top1:76.8054 | AUROC:0.8619\n",
      "\n",
      "Epoch: [197 | 1000] LR: 0.014686\n",
      "Train | 16/16 | Loss:0.4422 | MainLoss:0.4018 | Alpha:0.3998 | SPLoss:0.0009 | CLSLoss:0.0400 | top1:84.4267 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3869 | MainLoss:0.3869 | SPLoss:0.0019 | CLSLoss:0.0400 | top1:85.2308 | AUROC:0.9277\n",
      "Test | 123/16 | Loss:0.5070 | MainLoss:0.5070 | SPLoss:0.0019 | CLSLoss:0.0400 | top1:75.6651 | AUROC:0.8588\n",
      "\n",
      "Epoch: [198 | 1000] LR: 0.014673\n",
      "Train | 16/16 | Loss:0.4616 | MainLoss:0.4224 | Alpha:0.3993 | SPLoss:0.0010 | CLSLoss:0.0388 | top1:82.1867 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3870 | MainLoss:0.3870 | SPLoss:0.0017 | CLSLoss:0.0381 | top1:85.1154 | AUROC:0.9300\n",
      "Test | 123/16 | Loss:0.4943 | MainLoss:0.4943 | SPLoss:0.0017 | CLSLoss:0.0381 | top1:76.6841 | AUROC:0.8658\n",
      "\n",
      "Epoch: [199 | 1000] LR: 0.014659\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 16/16 | Loss:0.4436 | MainLoss:0.4041 | Alpha:0.4041 | SPLoss:0.0010 | CLSLoss:0.0391 | top1:83.7333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3868 | MainLoss:0.3868 | SPLoss:0.0021 | CLSLoss:0.0381 | top1:84.8205 | AUROC:0.9320\n",
      "Test | 123/16 | Loss:0.5282 | MainLoss:0.5282 | SPLoss:0.0021 | CLSLoss:0.0381 | top1:73.1422 | AUROC:0.8758\n",
      "\n",
      "Epoch: [200 | 1000] LR: 0.014645\n",
      "Train | 16/16 | Loss:0.4423 | MainLoss:0.4033 | Alpha:0.4004 | SPLoss:0.0010 | CLSLoss:0.0386 | top1:84.0800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3748 | MainLoss:0.3748 | SPLoss:0.0018 | CLSLoss:0.0381 | top1:85.2949 | AUROC:0.9330\n",
      "Test | 123/16 | Loss:0.5304 | MainLoss:0.5304 | SPLoss:0.0018 | CLSLoss:0.0381 | top1:73.3355 | AUROC:0.8675\n",
      "\n",
      "Epoch: [201 | 1000] LR: 0.014631\n",
      "Train | 16/16 | Loss:0.4457 | MainLoss:0.4071 | Alpha:0.4038 | SPLoss:0.0010 | CLSLoss:0.0381 | top1:83.4667 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3714 | MainLoss:0.3714 | SPLoss:0.0019 | CLSLoss:0.0372 | top1:85.6538 | AUROC:0.9335\n",
      "Test | 123/16 | Loss:0.5233 | MainLoss:0.5233 | SPLoss:0.0019 | CLSLoss:0.0372 | top1:73.8893 | AUROC:0.8644\n",
      "\n",
      "Epoch: [202 | 1000] LR: 0.014617\n",
      "Train | 16/16 | Loss:0.4352 | MainLoss:0.3971 | Alpha:0.4065 | SPLoss:0.0009 | CLSLoss:0.0378 | top1:84.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3633 | MainLoss:0.3633 | SPLoss:0.0018 | CLSLoss:0.0381 | top1:86.1667 | AUROC:0.9368\n",
      "Test | 123/16 | Loss:0.5092 | MainLoss:0.5092 | SPLoss:0.0018 | CLSLoss:0.0381 | top1:75.1540 | AUROC:0.8637\n",
      "\n",
      "Epoch: [203 | 1000] LR: 0.014602\n",
      "Train | 16/16 | Loss:0.4184 | MainLoss:0.3789 | Alpha:0.4083 | SPLoss:0.0009 | CLSLoss:0.0391 | top1:85.3600 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3645 | MainLoss:0.3645 | SPLoss:0.0019 | CLSLoss:0.0402 | top1:86.4487 | AUROC:0.9386\n",
      "Test | 123/16 | Loss:0.4978 | MainLoss:0.4978 | SPLoss:0.0019 | CLSLoss:0.0402 | top1:76.1468 | AUROC:0.8643\n",
      "\n",
      "Epoch: [204 | 1000] LR: 0.014588\n",
      "Train | 16/16 | Loss:0.4344 | MainLoss:0.3949 | Alpha:0.4063 | SPLoss:0.0012 | CLSLoss:0.0390 | top1:84.0267 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3738 | MainLoss:0.3738 | SPLoss:0.0026 | CLSLoss:0.0392 | top1:84.6667 | AUROC:0.9391\n",
      "Test | 123/16 | Loss:0.5817 | MainLoss:0.5817 | SPLoss:0.0026 | CLSLoss:0.0392 | top1:69.1612 | AUROC:0.8704\n",
      "\n",
      "Epoch: [205 | 1000] LR: 0.014574\n",
      "Train | 16/16 | Loss:0.4338 | MainLoss:0.3948 | Alpha:0.4010 | SPLoss:0.0011 | CLSLoss:0.0386 | top1:84.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3492 | MainLoss:0.3492 | SPLoss:0.0022 | CLSLoss:0.0375 | top1:86.7436 | AUROC:0.9426\n",
      "Test | 123/16 | Loss:0.5121 | MainLoss:0.5121 | SPLoss:0.0022 | CLSLoss:0.0375 | top1:75.1474 | AUROC:0.8648\n",
      "\n",
      "Epoch: [206 | 1000] LR: 0.014560\n",
      "Train | 16/16 | Loss:0.4325 | MainLoss:0.3952 | Alpha:0.4097 | SPLoss:0.0010 | CLSLoss:0.0369 | top1:84.3467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3590 | MainLoss:0.3590 | SPLoss:0.0018 | CLSLoss:0.0368 | top1:86.0641 | AUROC:0.9430\n",
      "Test | 123/16 | Loss:0.5546 | MainLoss:0.5546 | SPLoss:0.0018 | CLSLoss:0.0368 | top1:71.3696 | AUROC:0.8743\n",
      "\n",
      "Epoch: [207 | 1000] LR: 0.014545\n",
      "Train | 16/16 | Loss:0.4137 | MainLoss:0.3756 | Alpha:0.4060 | SPLoss:0.0010 | CLSLoss:0.0377 | top1:84.9600 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3540 | MainLoss:0.3540 | SPLoss:0.0020 | CLSLoss:0.0370 | top1:86.6795 | AUROC:0.9406\n",
      "Test | 123/16 | Loss:0.5208 | MainLoss:0.5208 | SPLoss:0.0020 | CLSLoss:0.0370 | top1:74.3152 | AUROC:0.8505\n",
      "\n",
      "Epoch: [208 | 1000] LR: 0.014531\n",
      "Train | 16/16 | Loss:0.4160 | MainLoss:0.3775 | Alpha:0.4102 | SPLoss:0.0011 | CLSLoss:0.0380 | top1:85.0133 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3428 | MainLoss:0.3428 | SPLoss:0.0021 | CLSLoss:0.0385 | top1:86.7821 | AUROC:0.9445\n",
      "Test | 123/16 | Loss:0.5460 | MainLoss:0.5460 | SPLoss:0.0021 | CLSLoss:0.0385 | top1:72.3820 | AUROC:0.8711\n",
      "\n",
      "Epoch: [209 | 1000] LR: 0.014516\n",
      "Train | 16/16 | Loss:0.4090 | MainLoss:0.3701 | Alpha:0.4120 | SPLoss:0.0010 | CLSLoss:0.0385 | top1:85.2800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3386 | MainLoss:0.3386 | SPLoss:0.0021 | CLSLoss:0.0376 | top1:87.2949 | AUROC:0.9458\n",
      "Test | 123/16 | Loss:0.5084 | MainLoss:0.5084 | SPLoss:0.0021 | CLSLoss:0.0376 | top1:75.3014 | AUROC:0.8658\n",
      "\n",
      "Epoch: [210 | 1000] LR: 0.014502\n",
      "Train | 16/16 | Loss:0.3922 | MainLoss:0.3535 | Alpha:0.4168 | SPLoss:0.0009 | CLSLoss:0.0384 | top1:86.5867 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3391 | MainLoss:0.3391 | SPLoss:0.0017 | CLSLoss:0.0394 | top1:87.1923 | AUROC:0.9464\n",
      "Test | 123/16 | Loss:0.5054 | MainLoss:0.5054 | SPLoss:0.0017 | CLSLoss:0.0394 | top1:75.8945 | AUROC:0.8599\n",
      "\n",
      "Epoch: [211 | 1000] LR: 0.014487\n",
      "Train | 16/16 | Loss:0.3882 | MainLoss:0.3485 | Alpha:0.4137 | SPLoss:0.0010 | CLSLoss:0.0392 | top1:86.6933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3227 | MainLoss:0.3227 | SPLoss:0.0020 | CLSLoss:0.0396 | top1:87.7564 | AUROC:0.9498\n",
      "Test | 123/16 | Loss:0.5196 | MainLoss:0.5196 | SPLoss:0.0020 | CLSLoss:0.0396 | top1:74.6953 | AUROC:0.8739\n",
      "\n",
      "Epoch: [212 | 1000] LR: 0.014472\n",
      "Train | 16/16 | Loss:0.3829 | MainLoss:0.3431 | Alpha:0.4184 | SPLoss:0.0010 | CLSLoss:0.0394 | top1:86.9600 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3206 | MainLoss:0.3206 | SPLoss:0.0018 | CLSLoss:0.0400 | top1:87.8205 | AUROC:0.9505\n",
      "Test | 123/16 | Loss:0.5370 | MainLoss:0.5370 | SPLoss:0.0018 | CLSLoss:0.0400 | top1:73.6435 | AUROC:0.8716\n",
      "\n",
      "Epoch: [213 | 1000] LR: 0.014457\n",
      "Train | 16/16 | Loss:0.3806 | MainLoss:0.3403 | Alpha:0.4184 | SPLoss:0.0011 | CLSLoss:0.0398 | top1:86.8800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3165 | MainLoss:0.3165 | SPLoss:0.0019 | CLSLoss:0.0390 | top1:88.1923 | AUROC:0.9520\n",
      "Test | 123/16 | Loss:0.5224 | MainLoss:0.5224 | SPLoss:0.0019 | CLSLoss:0.0390 | top1:74.5216 | AUROC:0.8677\n",
      "\n",
      "Epoch: [214 | 1000] LR: 0.014442\n",
      "Train | 16/16 | Loss:0.3916 | MainLoss:0.3525 | Alpha:0.4209 | SPLoss:0.0010 | CLSLoss:0.0387 | top1:85.7600 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3229 | MainLoss:0.3229 | SPLoss:0.0021 | CLSLoss:0.0372 | top1:88.0000 | AUROC:0.9524\n",
      "Test | 123/16 | Loss:0.5323 | MainLoss:0.5323 | SPLoss:0.0021 | CLSLoss:0.0372 | top1:73.0898 | AUROC:0.8742\n",
      "\n",
      "Epoch: [215 | 1000] LR: 0.014428\n",
      "Train | 16/16 | Loss:0.3778 | MainLoss:0.3387 | Alpha:0.4157 | SPLoss:0.0010 | CLSLoss:0.0387 | top1:86.9067 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3420 | MainLoss:0.3420 | SPLoss:0.0023 | CLSLoss:0.0379 | top1:86.7564 | AUROC:0.9512\n",
      "Test | 123/16 | Loss:0.5055 | MainLoss:0.5055 | SPLoss:0.0023 | CLSLoss:0.0379 | top1:76.0518 | AUROC:0.8455\n",
      "\n",
      "Epoch: [216 | 1000] LR: 0.014413\n",
      "Train | 16/16 | Loss:0.3588 | MainLoss:0.3193 | Alpha:0.4185 | SPLoss:0.0010 | CLSLoss:0.0390 | top1:88.5333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3099 | MainLoss:0.3099 | SPLoss:0.0021 | CLSLoss:0.0401 | top1:88.4487 | AUROC:0.9531\n",
      "Test | 123/16 | Loss:0.5398 | MainLoss:0.5398 | SPLoss:0.0021 | CLSLoss:0.0401 | top1:73.8073 | AUROC:0.8556\n",
      "\n",
      "Epoch: [217 | 1000] LR: 0.014397\n",
      "Train | 16/16 | Loss:0.3790 | MainLoss:0.3398 | Alpha:0.4210 | SPLoss:0.0010 | CLSLoss:0.0388 | top1:86.9867 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3241 | MainLoss:0.3241 | SPLoss:0.0017 | CLSLoss:0.0387 | top1:87.8974 | AUROC:0.9539\n",
      "Test | 123/16 | Loss:0.5089 | MainLoss:0.5089 | SPLoss:0.0017 | CLSLoss:0.0387 | top1:75.4620 | AUROC:0.8551\n",
      "\n",
      "Epoch: [218 | 1000] LR: 0.014382\n",
      "Train | 16/16 | Loss:0.3739 | MainLoss:0.3351 | Alpha:0.4204 | SPLoss:0.0011 | CLSLoss:0.0384 | top1:87.1200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3018 | MainLoss:0.3018 | SPLoss:0.0020 | CLSLoss:0.0384 | top1:88.7564 | AUROC:0.9557\n",
      "Test | 123/16 | Loss:0.5631 | MainLoss:0.5631 | SPLoss:0.0020 | CLSLoss:0.0384 | top1:71.8414 | AUROC:0.8635\n",
      "\n",
      "Epoch: [219 | 1000] LR: 0.014367\n",
      "Train | 16/16 | Loss:0.3794 | MainLoss:0.3416 | Alpha:0.4209 | SPLoss:0.0010 | CLSLoss:0.0374 | top1:86.8800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.3018 | MainLoss:0.3018 | SPLoss:0.0019 | CLSLoss:0.0369 | top1:88.7949 | AUROC:0.9564\n",
      "Test | 123/16 | Loss:0.5755 | MainLoss:0.5755 | SPLoss:0.0019 | CLSLoss:0.0369 | top1:71.0485 | AUROC:0.8668\n",
      "\n",
      "Epoch: [220 | 1000] LR: 0.014352\n",
      "Train | 16/16 | Loss:0.3604 | MainLoss:0.3218 | Alpha:0.4244 | SPLoss:0.0009 | CLSLoss:0.0382 | top1:87.5467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2946 | MainLoss:0.2946 | SPLoss:0.0015 | CLSLoss:0.0378 | top1:89.1667 | AUROC:0.9580\n",
      "Test | 123/16 | Loss:0.5587 | MainLoss:0.5587 | SPLoss:0.0015 | CLSLoss:0.0378 | top1:71.6383 | AUROC:0.8650\n",
      "\n",
      "Epoch: [221 | 1000] LR: 0.014337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 16/16 | Loss:0.3556 | MainLoss:0.3167 | Alpha:0.4237 | SPLoss:0.0008 | CLSLoss:0.0386 | top1:88.4000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2983 | MainLoss:0.2983 | SPLoss:0.0016 | CLSLoss:0.0386 | top1:88.6667 | AUROC:0.9602\n",
      "Test | 123/16 | Loss:0.5900 | MainLoss:0.5900 | SPLoss:0.0016 | CLSLoss:0.0386 | top1:70.2392 | AUROC:0.8773\n",
      "\n",
      "Epoch: [222 | 1000] LR: 0.014321\n",
      "Train | 16/16 | Loss:0.3592 | MainLoss:0.3205 | Alpha:0.4223 | SPLoss:0.0011 | CLSLoss:0.0382 | top1:87.8933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2849 | MainLoss:0.2849 | SPLoss:0.0017 | CLSLoss:0.0394 | top1:89.5385 | AUROC:0.9604\n",
      "Test | 123/16 | Loss:0.5645 | MainLoss:0.5645 | SPLoss:0.0017 | CLSLoss:0.0394 | top1:72.4115 | AUROC:0.8719\n",
      "\n",
      "Epoch: [223 | 1000] LR: 0.014306\n",
      "Train | 16/16 | Loss:0.3561 | MainLoss:0.3167 | Alpha:0.4257 | SPLoss:0.0010 | CLSLoss:0.0390 | top1:87.4667 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2835 | MainLoss:0.2835 | SPLoss:0.0019 | CLSLoss:0.0385 | top1:89.7308 | AUROC:0.9609\n",
      "Test | 123/16 | Loss:0.5207 | MainLoss:0.5207 | SPLoss:0.0019 | CLSLoss:0.0385 | top1:74.2071 | AUROC:0.8733\n",
      "\n",
      "Epoch: [224 | 1000] LR: 0.014290\n",
      "Train | 16/16 | Loss:0.3333 | MainLoss:0.2932 | Alpha:0.4298 | SPLoss:0.0010 | CLSLoss:0.0398 | top1:89.2533 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2828 | MainLoss:0.2828 | SPLoss:0.0018 | CLSLoss:0.0405 | top1:89.6795 | AUROC:0.9601\n",
      "Test | 123/16 | Loss:0.5588 | MainLoss:0.5588 | SPLoss:0.0018 | CLSLoss:0.0405 | top1:73.3224 | AUROC:0.8656\n",
      "\n",
      "Epoch: [225 | 1000] LR: 0.014275\n",
      "Train | 16/16 | Loss:0.3306 | MainLoss:0.2900 | Alpha:0.4329 | SPLoss:0.0011 | CLSLoss:0.0401 | top1:89.4133 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2869 | MainLoss:0.2869 | SPLoss:0.0019 | CLSLoss:0.0400 | top1:89.4487 | AUROC:0.9614\n",
      "Test | 123/16 | Loss:0.5269 | MainLoss:0.5269 | SPLoss:0.0019 | CLSLoss:0.0400 | top1:74.7117 | AUROC:0.8612\n",
      "\n",
      "Epoch: [226 | 1000] LR: 0.014259\n",
      "Train | 16/16 | Loss:0.3502 | MainLoss:0.3111 | Alpha:0.4272 | SPLoss:0.0010 | CLSLoss:0.0387 | top1:88.4000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2750 | MainLoss:0.2750 | SPLoss:0.0019 | CLSLoss:0.0389 | top1:90.0897 | AUROC:0.9624\n",
      "Test | 123/16 | Loss:0.5622 | MainLoss:0.5622 | SPLoss:0.0019 | CLSLoss:0.0389 | top1:72.2084 | AUROC:0.8687\n",
      "\n",
      "Epoch: [227 | 1000] LR: 0.014243\n",
      "Train | 16/16 | Loss:0.3202 | MainLoss:0.2799 | Alpha:0.4345 | SPLoss:0.0009 | CLSLoss:0.0399 | top1:89.9733 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2770 | MainLoss:0.2770 | SPLoss:0.0018 | CLSLoss:0.0392 | top1:89.8462 | AUROC:0.9628\n",
      "Test | 123/16 | Loss:0.5808 | MainLoss:0.5808 | SPLoss:0.0018 | CLSLoss:0.0392 | top1:71.8611 | AUROC:0.8769\n",
      "\n",
      "Epoch: [228 | 1000] LR: 0.014228\n",
      "Train | 16/16 | Loss:0.3344 | MainLoss:0.2954 | Alpha:0.4304 | SPLoss:0.0011 | CLSLoss:0.0385 | top1:88.7467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2732 | MainLoss:0.2732 | SPLoss:0.0019 | CLSLoss:0.0385 | top1:90.1026 | AUROC:0.9640\n",
      "Test | 123/16 | Loss:0.5231 | MainLoss:0.5231 | SPLoss:0.0019 | CLSLoss:0.0385 | top1:74.9771 | AUROC:0.8685\n",
      "\n",
      "Epoch: [229 | 1000] LR: 0.014212\n",
      "Train | 16/16 | Loss:0.3287 | MainLoss:0.2899 | Alpha:0.4315 | SPLoss:0.0009 | CLSLoss:0.0384 | top1:89.6000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2670 | MainLoss:0.2670 | SPLoss:0.0016 | CLSLoss:0.0381 | top1:90.5513 | AUROC:0.9655\n",
      "Test | 123/16 | Loss:0.5403 | MainLoss:0.5403 | SPLoss:0.0016 | CLSLoss:0.0381 | top1:74.1776 | AUROC:0.8675\n",
      "\n",
      "Epoch: [230 | 1000] LR: 0.014196\n",
      "Train | 16/16 | Loss:0.3207 | MainLoss:0.2815 | Alpha:0.4350 | SPLoss:0.0010 | CLSLoss:0.0388 | top1:89.6800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2848 | MainLoss:0.2848 | SPLoss:0.0022 | CLSLoss:0.0376 | top1:89.2564 | AUROC:0.9664\n",
      "Test | 123/16 | Loss:0.6151 | MainLoss:0.6151 | SPLoss:0.0022 | CLSLoss:0.0376 | top1:68.5714 | AUROC:0.8808\n",
      "\n",
      "Epoch: [231 | 1000] LR: 0.014180\n",
      "Train | 16/16 | Loss:0.3188 | MainLoss:0.2794 | Alpha:0.4257 | SPLoss:0.0011 | CLSLoss:0.0389 | top1:89.6533 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2902 | MainLoss:0.2902 | SPLoss:0.0027 | CLSLoss:0.0383 | top1:89.1410 | AUROC:0.9658\n",
      "Test | 123/16 | Loss:0.5070 | MainLoss:0.5070 | SPLoss:0.0027 | CLSLoss:0.0383 | top1:75.9011 | AUROC:0.8532\n",
      "\n",
      "Epoch: [232 | 1000] LR: 0.014164\n",
      "Train | 16/16 | Loss:0.3337 | MainLoss:0.2954 | Alpha:0.4257 | SPLoss:0.0012 | CLSLoss:0.0377 | top1:88.7733 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2607 | MainLoss:0.2607 | SPLoss:0.0018 | CLSLoss:0.0384 | top1:90.7308 | AUROC:0.9666\n",
      "Test | 123/16 | Loss:0.5677 | MainLoss:0.5677 | SPLoss:0.0018 | CLSLoss:0.0384 | top1:72.5426 | AUROC:0.8542\n",
      "\n",
      "Epoch: [233 | 1000] LR: 0.014148\n",
      "Train | 16/16 | Loss:0.3213 | MainLoss:0.2823 | Alpha:0.4338 | SPLoss:0.0010 | CLSLoss:0.0385 | top1:89.9200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2591 | MainLoss:0.2591 | SPLoss:0.0022 | CLSLoss:0.0373 | top1:90.8077 | AUROC:0.9670\n",
      "Test | 123/16 | Loss:0.5688 | MainLoss:0.5688 | SPLoss:0.0022 | CLSLoss:0.0373 | top1:72.2346 | AUROC:0.8575\n",
      "\n",
      "Epoch: [234 | 1000] LR: 0.014132\n",
      "Train | 16/16 | Loss:0.3295 | MainLoss:0.2921 | Alpha:0.4323 | SPLoss:0.0010 | CLSLoss:0.0369 | top1:89.2000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2576 | MainLoss:0.2576 | SPLoss:0.0019 | CLSLoss:0.0370 | top1:90.8974 | AUROC:0.9675\n",
      "Test | 123/16 | Loss:0.5579 | MainLoss:0.5579 | SPLoss:0.0019 | CLSLoss:0.0370 | top1:72.9227 | AUROC:0.8604\n",
      "\n",
      "Epoch: [235 | 1000] LR: 0.014116\n",
      "Train | 16/16 | Loss:0.3069 | MainLoss:0.2684 | Alpha:0.4358 | SPLoss:0.0010 | CLSLoss:0.0381 | top1:90.2933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2691 | MainLoss:0.2691 | SPLoss:0.0019 | CLSLoss:0.0384 | top1:90.2308 | AUROC:0.9674\n",
      "Test | 123/16 | Loss:0.5478 | MainLoss:0.5478 | SPLoss:0.0019 | CLSLoss:0.0384 | top1:73.5813 | AUROC:0.8481\n",
      "\n",
      "Epoch: [236 | 1000] LR: 0.014100\n",
      "Train | 16/16 | Loss:0.3041 | MainLoss:0.2656 | Alpha:0.4326 | SPLoss:0.0010 | CLSLoss:0.0381 | top1:90.4533 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2534 | MainLoss:0.2534 | SPLoss:0.0021 | CLSLoss:0.0391 | top1:90.7821 | AUROC:0.9702\n",
      "Test | 123/16 | Loss:0.6712 | MainLoss:0.6712 | SPLoss:0.0021 | CLSLoss:0.0391 | top1:67.5983 | AUROC:0.8605\n",
      "\n",
      "Epoch: [237 | 1000] LR: 0.014083\n",
      "Train | 16/16 | Loss:0.2957 | MainLoss:0.2562 | Alpha:0.4372 | SPLoss:0.0009 | CLSLoss:0.0391 | top1:90.9067 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2447 | MainLoss:0.2447 | SPLoss:0.0016 | CLSLoss:0.0390 | top1:91.2692 | AUROC:0.9707\n",
      "Test | 123/16 | Loss:0.6127 | MainLoss:0.6127 | SPLoss:0.0016 | CLSLoss:0.0390 | top1:69.7346 | AUROC:0.8642\n",
      "\n",
      "Epoch: [238 | 1000] LR: 0.014067\n",
      "Train | 16/16 | Loss:0.2877 | MainLoss:0.2477 | Alpha:0.4395 | SPLoss:0.0010 | CLSLoss:0.0396 | top1:90.7733 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2573 | MainLoss:0.2573 | SPLoss:0.0023 | CLSLoss:0.0405 | top1:90.6154 | AUROC:0.9677\n",
      "Test | 123/16 | Loss:0.5801 | MainLoss:0.5801 | SPLoss:0.0023 | CLSLoss:0.0405 | top1:72.8768 | AUROC:0.8485\n",
      "\n",
      "Epoch: [239 | 1000] LR: 0.014050\n",
      "Train | 16/16 | Loss:0.3022 | MainLoss:0.2621 | Alpha:0.4383 | SPLoss:0.0011 | CLSLoss:0.0396 | top1:90.6133 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2454 | MainLoss:0.2454 | SPLoss:0.0021 | CLSLoss:0.0372 | top1:91.3974 | AUROC:0.9712\n",
      "Test | 123/16 | Loss:0.6069 | MainLoss:0.6069 | SPLoss:0.0021 | CLSLoss:0.0372 | top1:69.8755 | AUROC:0.8677\n",
      "\n",
      "Epoch: [240 | 1000] LR: 0.014034\n",
      "Train | 16/16 | Loss:0.2944 | MainLoss:0.2559 | Alpha:0.4380 | SPLoss:0.0009 | CLSLoss:0.0381 | top1:90.7200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2449 | MainLoss:0.2449 | SPLoss:0.0018 | CLSLoss:0.0385 | top1:91.2949 | AUROC:0.9701\n",
      "Test | 123/16 | Loss:0.5700 | MainLoss:0.5700 | SPLoss:0.0018 | CLSLoss:0.0385 | top1:72.1756 | AUROC:0.8523\n",
      "\n",
      "Epoch: [241 | 1000] LR: 0.014017\n",
      "Train | 16/16 | Loss:0.3091 | MainLoss:0.2707 | Alpha:0.4390 | SPLoss:0.0010 | CLSLoss:0.0380 | top1:89.9733 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2420 | MainLoss:0.2420 | SPLoss:0.0019 | CLSLoss:0.0372 | top1:91.7179 | AUROC:0.9708\n",
      "Test | 123/16 | Loss:0.5735 | MainLoss:0.5735 | SPLoss:0.0019 | CLSLoss:0.0372 | top1:71.3139 | AUROC:0.8543\n",
      "\n",
      "Epoch: [242 | 1000] LR: 0.014001\n",
      "Train | 16/16 | Loss:0.2939 | MainLoss:0.2558 | Alpha:0.4399 | SPLoss:0.0010 | CLSLoss:0.0376 | top1:90.8267 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2371 | MainLoss:0.2371 | SPLoss:0.0019 | CLSLoss:0.0384 | top1:91.6282 | AUROC:0.9712\n",
      "Test | 123/16 | Loss:0.6087 | MainLoss:0.6087 | SPLoss:0.0019 | CLSLoss:0.0384 | top1:71.4319 | AUROC:0.8489\n",
      "\n",
      "Epoch: [243 | 1000] LR: 0.013984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 16/16 | Loss:0.2899 | MainLoss:0.2516 | Alpha:0.4426 | SPLoss:0.0010 | CLSLoss:0.0378 | top1:91.0933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2350 | MainLoss:0.2350 | SPLoss:0.0019 | CLSLoss:0.0375 | top1:91.8718 | AUROC:0.9722\n",
      "Test | 123/16 | Loss:0.5991 | MainLoss:0.5991 | SPLoss:0.0019 | CLSLoss:0.0375 | top1:70.9371 | AUROC:0.8723\n",
      "\n",
      "Epoch: [244 | 1000] LR: 0.013968\n",
      "Train | 16/16 | Loss:0.3029 | MainLoss:0.2655 | Alpha:0.4394 | SPLoss:0.0009 | CLSLoss:0.0370 | top1:89.8400 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2319 | MainLoss:0.2319 | SPLoss:0.0015 | CLSLoss:0.0375 | top1:91.9359 | AUROC:0.9726\n",
      "Test | 123/16 | Loss:0.5951 | MainLoss:0.5951 | SPLoss:0.0015 | CLSLoss:0.0375 | top1:70.9273 | AUROC:0.8708\n",
      "\n",
      "Epoch: [245 | 1000] LR: 0.013951\n",
      "Train | 16/16 | Loss:0.2939 | MainLoss:0.2560 | Alpha:0.4412 | SPLoss:0.0010 | CLSLoss:0.0374 | top1:90.3733 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2498 | MainLoss:0.2498 | SPLoss:0.0017 | CLSLoss:0.0374 | top1:90.8974 | AUROC:0.9735\n",
      "Test | 123/16 | Loss:0.6390 | MainLoss:0.6390 | SPLoss:0.0017 | CLSLoss:0.0374 | top1:67.5491 | AUROC:0.8747\n",
      "\n",
      "Epoch: [246 | 1000] LR: 0.013934\n",
      "Train | 16/16 | Loss:0.2849 | MainLoss:0.2462 | Alpha:0.4358 | SPLoss:0.0012 | CLSLoss:0.0381 | top1:91.5200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2462 | MainLoss:0.2462 | SPLoss:0.0017 | CLSLoss:0.0374 | top1:91.0000 | AUROC:0.9733\n",
      "Test | 123/16 | Loss:0.7159 | MainLoss:0.7159 | SPLoss:0.0017 | CLSLoss:0.0374 | top1:66.1468 | AUROC:0.8663\n",
      "\n",
      "Epoch: [247 | 1000] LR: 0.013917\n",
      "Train | 16/16 | Loss:0.2864 | MainLoss:0.2489 | Alpha:0.4362 | SPLoss:0.0011 | CLSLoss:0.0370 | top1:91.2267 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2317 | MainLoss:0.2317 | SPLoss:0.0016 | CLSLoss:0.0381 | top1:91.8333 | AUROC:0.9736\n",
      "Test | 123/16 | Loss:0.6933 | MainLoss:0.6933 | SPLoss:0.0016 | CLSLoss:0.0381 | top1:67.7621 | AUROC:0.8570\n",
      "\n",
      "Epoch: [248 | 1000] LR: 0.013900\n",
      "Train | 16/16 | Loss:0.2886 | MainLoss:0.2505 | Alpha:0.4395 | SPLoss:0.0010 | CLSLoss:0.0376 | top1:91.1733 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2272 | MainLoss:0.2272 | SPLoss:0.0015 | CLSLoss:0.0384 | top1:92.1026 | AUROC:0.9739\n",
      "Test | 123/16 | Loss:0.5974 | MainLoss:0.5974 | SPLoss:0.0015 | CLSLoss:0.0384 | top1:70.8879 | AUROC:0.8480\n",
      "\n",
      "Epoch: [249 | 1000] LR: 0.013883\n",
      "Train | 16/16 | Loss:0.2824 | MainLoss:0.2439 | Alpha:0.4452 | SPLoss:0.0009 | CLSLoss:0.0381 | top1:91.3333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2210 | MainLoss:0.2210 | SPLoss:0.0016 | CLSLoss:0.0381 | top1:92.4615 | AUROC:0.9747\n",
      "Test | 123/16 | Loss:0.6273 | MainLoss:0.6273 | SPLoss:0.0016 | CLSLoss:0.0381 | top1:69.8755 | AUROC:0.8501\n",
      "\n",
      "Epoch: [250 | 1000] LR: 0.013866\n",
      "Train | 16/16 | Loss:0.2777 | MainLoss:0.2395 | Alpha:0.4436 | SPLoss:0.0009 | CLSLoss:0.0378 | top1:91.3600 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2177 | MainLoss:0.2177 | SPLoss:0.0018 | CLSLoss:0.0387 | top1:92.5385 | AUROC:0.9752\n",
      "Test | 123/16 | Loss:0.6097 | MainLoss:0.6097 | SPLoss:0.0018 | CLSLoss:0.0387 | top1:71.2647 | AUROC:0.8505\n",
      "\n",
      "Epoch: [251 | 1000] LR: 0.013849\n",
      "Train | 16/16 | Loss:0.2813 | MainLoss:0.2426 | Alpha:0.4437 | SPLoss:0.0010 | CLSLoss:0.0382 | top1:91.2800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2285 | MainLoss:0.2285 | SPLoss:0.0020 | CLSLoss:0.0375 | top1:91.8846 | AUROC:0.9684\n",
      "Test | 123/16 | Loss:0.7350 | MainLoss:0.7350 | SPLoss:0.0020 | CLSLoss:0.0375 | top1:66.9430 | AUROC:0.8258\n",
      "\n",
      "Epoch: [252 | 1000] LR: 0.001383\n",
      "Train | 16/16 | Loss:0.2638 | MainLoss:0.2262 | Alpha:0.4419 | SPLoss:0.0001 | CLSLoss:0.0375 | top1:92.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2178 | MainLoss:0.2178 | SPLoss:0.0002 | CLSLoss:0.0376 | top1:92.7564 | AUROC:0.9755\n",
      "Test | 123/16 | Loss:0.6230 | MainLoss:0.6230 | SPLoss:0.0002 | CLSLoss:0.0376 | top1:70.4096 | AUROC:0.8510\n",
      "\n",
      "Epoch: [253 | 1000] LR: 0.001381\n",
      "Train | 16/16 | Loss:0.2792 | MainLoss:0.2417 | Alpha:0.4417 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:91.0933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2187 | MainLoss:0.2187 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:92.4231 | AUROC:0.9754\n",
      "Test | 123/16 | Loss:0.5974 | MainLoss:0.5974 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:71.0845 | AUROC:0.8504\n",
      "\n",
      "Epoch: [254 | 1000] LR: 0.001380\n",
      "Train | 16/16 | Loss:0.2712 | MainLoss:0.2339 | Alpha:0.4442 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:91.7600 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2157 | MainLoss:0.2157 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:92.7821 | AUROC:0.9762\n",
      "Test | 123/16 | Loss:0.6086 | MainLoss:0.6086 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:70.4292 | AUROC:0.8527\n",
      "\n",
      "Epoch: [255 | 1000] LR: 0.001378\n",
      "Train | 16/16 | Loss:0.2677 | MainLoss:0.2303 | Alpha:0.4452 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:92.1067 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2147 | MainLoss:0.2147 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:92.8077 | AUROC:0.9758\n",
      "Test | 123/16 | Loss:0.6126 | MainLoss:0.6126 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:70.3539 | AUROC:0.8527\n",
      "\n",
      "Epoch: [256 | 1000] LR: 0.001376\n",
      "Train | 16/16 | Loss:0.2659 | MainLoss:0.2283 | Alpha:0.4462 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:92.0800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2163 | MainLoss:0.2163 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:92.6282 | AUROC:0.9764\n",
      "Test | 123/16 | Loss:0.5955 | MainLoss:0.5955 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:71.0616 | AUROC:0.8517\n",
      "\n",
      "Epoch: [257 | 1000] LR: 0.001375\n",
      "Train | 16/16 | Loss:0.2707 | MainLoss:0.2331 | Alpha:0.4459 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:92.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2139 | MainLoss:0.2139 | SPLoss:0.0000 | CLSLoss:0.0377 | top1:92.7949 | AUROC:0.9766\n",
      "Test | 123/16 | Loss:0.6170 | MainLoss:0.6170 | SPLoss:0.0000 | CLSLoss:0.0377 | top1:70.1933 | AUROC:0.8525\n",
      "\n",
      "Epoch: [258 | 1000] LR: 0.001373\n",
      "Train | 16/16 | Loss:0.2681 | MainLoss:0.2304 | Alpha:0.4459 | SPLoss:0.0000 | CLSLoss:0.0377 | top1:91.9200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2146 | MainLoss:0.2146 | SPLoss:0.0000 | CLSLoss:0.0377 | top1:92.7692 | AUROC:0.9767\n",
      "Test | 123/16 | Loss:0.6042 | MainLoss:0.6042 | SPLoss:0.0000 | CLSLoss:0.0377 | top1:70.7176 | AUROC:0.8518\n",
      "\n",
      "Epoch: [259 | 1000] LR: 0.001371\n",
      "Train | 16/16 | Loss:0.2490 | MainLoss:0.2112 | Alpha:0.4500 | SPLoss:0.0000 | CLSLoss:0.0378 | top1:92.7467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2149 | MainLoss:0.2149 | SPLoss:0.0000 | CLSLoss:0.0380 | top1:92.7179 | AUROC:0.9760\n",
      "Test | 123/16 | Loss:0.6128 | MainLoss:0.6128 | SPLoss:0.0000 | CLSLoss:0.0380 | top1:70.7831 | AUROC:0.8492\n",
      "\n",
      "Epoch: [260 | 1000] LR: 0.001369\n",
      "Train | 16/16 | Loss:0.2593 | MainLoss:0.2212 | Alpha:0.4485 | SPLoss:0.0000 | CLSLoss:0.0381 | top1:92.4533 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2137 | MainLoss:0.2137 | SPLoss:0.0000 | CLSLoss:0.0381 | top1:92.7564 | AUROC:0.9765\n",
      "Test | 123/16 | Loss:0.6134 | MainLoss:0.6134 | SPLoss:0.0000 | CLSLoss:0.0381 | top1:70.7634 | AUROC:0.8492\n",
      "\n",
      "Epoch: [261 | 1000] LR: 0.001367\n",
      "Train | 16/16 | Loss:0.2549 | MainLoss:0.2167 | Alpha:0.4488 | SPLoss:0.0000 | CLSLoss:0.0381 | top1:92.8533 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2128 | MainLoss:0.2128 | SPLoss:0.0000 | CLSLoss:0.0382 | top1:92.9103 | AUROC:0.9766\n",
      "Test | 123/16 | Loss:0.6258 | MainLoss:0.6258 | SPLoss:0.0000 | CLSLoss:0.0382 | top1:70.2490 | AUROC:0.8480\n",
      "\n",
      "Epoch: [262 | 1000] LR: 0.001366\n",
      "Train | 16/16 | Loss:0.2507 | MainLoss:0.2123 | Alpha:0.4500 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:92.9067 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2142 | MainLoss:0.2142 | SPLoss:0.0000 | CLSLoss:0.0384 | top1:92.7179 | AUROC:0.9760\n",
      "Test | 123/16 | Loss:0.6253 | MainLoss:0.6253 | SPLoss:0.0000 | CLSLoss:0.0384 | top1:70.5701 | AUROC:0.8449\n",
      "\n",
      "Epoch: [263 | 1000] LR: 0.001364\n",
      "Train | 16/16 | Loss:0.2630 | MainLoss:0.2246 | Alpha:0.4477 | SPLoss:0.0000 | CLSLoss:0.0384 | top1:92.0267 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2153 | MainLoss:0.2153 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:92.5641 | AUROC:0.9767\n",
      "Test | 123/16 | Loss:0.6007 | MainLoss:0.6007 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:71.0190 | AUROC:0.8480\n",
      "\n",
      "Epoch: [264 | 1000] LR: 0.001362\n",
      "Train | 16/16 | Loss:0.2802 | MainLoss:0.2420 | Alpha:0.4423 | SPLoss:0.0000 | CLSLoss:0.0382 | top1:91.3067 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2122 | MainLoss:0.2122 | SPLoss:0.0000 | CLSLoss:0.0380 | top1:92.9231 | AUROC:0.9771\n",
      "Test | 123/16 | Loss:0.6207 | MainLoss:0.6207 | SPLoss:0.0000 | CLSLoss:0.0380 | top1:70.0950 | AUROC:0.8492\n",
      "\n",
      "Epoch: [265 | 1000] LR: 0.001360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 16/16 | Loss:0.2631 | MainLoss:0.2251 | Alpha:0.4471 | SPLoss:0.0000 | CLSLoss:0.0381 | top1:92.4800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2131 | MainLoss:0.2131 | SPLoss:0.0000 | CLSLoss:0.0380 | top1:92.7692 | AUROC:0.9769\n",
      "Test | 123/16 | Loss:0.6149 | MainLoss:0.6149 | SPLoss:0.0000 | CLSLoss:0.0380 | top1:70.4161 | AUROC:0.8489\n",
      "\n",
      "Epoch: [266 | 1000] LR: 0.001359\n",
      "Train | 16/16 | Loss:0.2606 | MainLoss:0.2226 | Alpha:0.4472 | SPLoss:0.0000 | CLSLoss:0.0380 | top1:92.1867 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2106 | MainLoss:0.2106 | SPLoss:0.0000 | CLSLoss:0.0382 | top1:92.8846 | AUROC:0.9770\n",
      "Test | 123/16 | Loss:0.6386 | MainLoss:0.6386 | SPLoss:0.0000 | CLSLoss:0.0382 | top1:69.6625 | AUROC:0.8472\n",
      "\n",
      "Epoch: [267 | 1000] LR: 0.001357\n",
      "Train | 16/16 | Loss:0.2536 | MainLoss:0.2153 | Alpha:0.4484 | SPLoss:0.0000 | CLSLoss:0.0382 | top1:92.5067 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2120 | MainLoss:0.2120 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:92.8590 | AUROC:0.9771\n",
      "Test | 123/16 | Loss:0.6230 | MainLoss:0.6230 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:70.3080 | AUROC:0.8458\n",
      "\n",
      "Epoch: [268 | 1000] LR: 0.001355\n",
      "Train | 16/16 | Loss:0.2662 | MainLoss:0.2279 | Alpha:0.4460 | SPLoss:0.0000 | CLSLoss:0.0382 | top1:92.0533 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2109 | MainLoss:0.2109 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:92.9487 | AUROC:0.9768\n",
      "Test | 123/16 | Loss:0.6371 | MainLoss:0.6371 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:69.8624 | AUROC:0.8445\n",
      "\n",
      "Epoch: [269 | 1000] LR: 0.001353\n",
      "Train | 16/16 | Loss:0.2627 | MainLoss:0.2245 | Alpha:0.4467 | SPLoss:0.0000 | CLSLoss:0.0382 | top1:92.2133 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2132 | MainLoss:0.2132 | SPLoss:0.0000 | CLSLoss:0.0382 | top1:92.7051 | AUROC:0.9765\n",
      "Test | 123/16 | Loss:0.6117 | MainLoss:0.6117 | SPLoss:0.0000 | CLSLoss:0.0382 | top1:70.9076 | AUROC:0.8470\n",
      "\n",
      "Epoch: [270 | 1000] LR: 0.001351\n",
      "Train | 16/16 | Loss:0.2526 | MainLoss:0.2143 | Alpha:0.4486 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:92.4533 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2105 | MainLoss:0.2105 | SPLoss:0.0000 | CLSLoss:0.0384 | top1:92.9615 | AUROC:0.9770\n",
      "Test | 123/16 | Loss:0.6298 | MainLoss:0.6298 | SPLoss:0.0000 | CLSLoss:0.0384 | top1:70.1114 | AUROC:0.8465\n",
      "\n",
      "Epoch: [271 | 1000] LR: 0.001349\n",
      "Train | 16/16 | Loss:0.2443 | MainLoss:0.2058 | Alpha:0.4510 | SPLoss:0.0000 | CLSLoss:0.0385 | top1:93.0933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2103 | MainLoss:0.2103 | SPLoss:0.0000 | CLSLoss:0.0386 | top1:92.9487 | AUROC:0.9764\n",
      "Test | 123/16 | Loss:0.6418 | MainLoss:0.6418 | SPLoss:0.0000 | CLSLoss:0.0386 | top1:70.1212 | AUROC:0.8422\n",
      "\n",
      "Epoch: [272 | 1000] LR: 0.001348\n",
      "Train | 16/16 | Loss:0.2497 | MainLoss:0.2111 | Alpha:0.4504 | SPLoss:0.0000 | CLSLoss:0.0386 | top1:93.0400 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2097 | MainLoss:0.2097 | SPLoss:0.0000 | CLSLoss:0.0387 | top1:92.9231 | AUROC:0.9762\n",
      "Test | 123/16 | Loss:0.6420 | MainLoss:0.6420 | SPLoss:0.0000 | CLSLoss:0.0387 | top1:70.0590 | AUROC:0.8444\n",
      "\n",
      "Epoch: [273 | 1000] LR: 0.001346\n",
      "Train | 16/16 | Loss:0.2617 | MainLoss:0.2231 | Alpha:0.4471 | SPLoss:0.0000 | CLSLoss:0.0386 | top1:92.0800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2098 | MainLoss:0.2098 | SPLoss:0.0000 | CLSLoss:0.0387 | top1:92.9231 | AUROC:0.9767\n",
      "Test | 123/16 | Loss:0.6383 | MainLoss:0.6383 | SPLoss:0.0000 | CLSLoss:0.0387 | top1:70.1507 | AUROC:0.8445\n",
      "\n",
      "Epoch: [274 | 1000] LR: 0.001344\n",
      "Train | 16/16 | Loss:0.2618 | MainLoss:0.2232 | Alpha:0.4471 | SPLoss:0.0000 | CLSLoss:0.0386 | top1:92.4000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2098 | MainLoss:0.2098 | SPLoss:0.0000 | CLSLoss:0.0385 | top1:92.9231 | AUROC:0.9776\n",
      "Test | 123/16 | Loss:0.6206 | MainLoss:0.6206 | SPLoss:0.0000 | CLSLoss:0.0385 | top1:70.5537 | AUROC:0.8486\n",
      "\n",
      "Epoch: [275 | 1000] LR: 0.001342\n",
      "Train | 16/16 | Loss:0.2617 | MainLoss:0.2233 | Alpha:0.4480 | SPLoss:0.0000 | CLSLoss:0.0384 | top1:92.1333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2092 | MainLoss:0.2092 | SPLoss:0.0000 | CLSLoss:0.0384 | top1:92.9615 | AUROC:0.9774\n",
      "Test | 123/16 | Loss:0.6242 | MainLoss:0.6242 | SPLoss:0.0000 | CLSLoss:0.0384 | top1:70.3670 | AUROC:0.8476\n",
      "\n",
      "Epoch: [276 | 1000] LR: 0.001340\n",
      "Train | 16/16 | Loss:0.2434 | MainLoss:0.2047 | Alpha:0.4516 | SPLoss:0.0000 | CLSLoss:0.0386 | top1:93.1200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2116 | MainLoss:0.2116 | SPLoss:0.0000 | CLSLoss:0.0388 | top1:92.7179 | AUROC:0.9772\n",
      "Test | 123/16 | Loss:0.6136 | MainLoss:0.6136 | SPLoss:0.0000 | CLSLoss:0.0388 | top1:71.2418 | AUROC:0.8467\n",
      "\n",
      "Epoch: [277 | 1000] LR: 0.001338\n",
      "Train | 16/16 | Loss:0.2555 | MainLoss:0.2168 | Alpha:0.4491 | SPLoss:0.0000 | CLSLoss:0.0387 | top1:92.2667 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2081 | MainLoss:0.2081 | SPLoss:0.0000 | CLSLoss:0.0387 | top1:92.9872 | AUROC:0.9772\n",
      "Test | 123/16 | Loss:0.6336 | MainLoss:0.6336 | SPLoss:0.0000 | CLSLoss:0.0387 | top1:70.1933 | AUROC:0.8475\n",
      "\n",
      "Epoch: [278 | 1000] LR: 0.001337\n",
      "Train | 16/16 | Loss:0.2544 | MainLoss:0.2158 | Alpha:0.4491 | SPLoss:0.0000 | CLSLoss:0.0386 | top1:92.3467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2075 | MainLoss:0.2075 | SPLoss:0.0000 | CLSLoss:0.0388 | top1:93.0000 | AUROC:0.9780\n",
      "Test | 123/16 | Loss:0.6258 | MainLoss:0.6258 | SPLoss:0.0000 | CLSLoss:0.0388 | top1:70.2982 | AUROC:0.8491\n",
      "\n",
      "Epoch: [279 | 1000] LR: 0.001335\n",
      "Train | 16/16 | Loss:0.2520 | MainLoss:0.2132 | Alpha:0.4488 | SPLoss:0.0000 | CLSLoss:0.0389 | top1:92.5867 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2109 | MainLoss:0.2109 | SPLoss:0.0000 | CLSLoss:0.0388 | top1:92.7692 | AUROC:0.9776\n",
      "Test | 123/16 | Loss:0.6087 | MainLoss:0.6087 | SPLoss:0.0000 | CLSLoss:0.0388 | top1:71.2222 | AUROC:0.8477\n",
      "\n",
      "Epoch: [280 | 1000] LR: 0.001333\n",
      "Train | 16/16 | Loss:0.2659 | MainLoss:0.2273 | Alpha:0.4459 | SPLoss:0.0000 | CLSLoss:0.0386 | top1:91.4933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2077 | MainLoss:0.2077 | SPLoss:0.0000 | CLSLoss:0.0386 | top1:93.0641 | AUROC:0.9776\n",
      "Test | 123/16 | Loss:0.6110 | MainLoss:0.6110 | SPLoss:0.0000 | CLSLoss:0.0386 | top1:70.6422 | AUROC:0.8510\n",
      "\n",
      "Epoch: [281 | 1000] LR: 0.001331\n",
      "Train | 16/16 | Loss:0.2496 | MainLoss:0.2109 | Alpha:0.4499 | SPLoss:0.0000 | CLSLoss:0.0387 | top1:93.0667 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2073 | MainLoss:0.2073 | SPLoss:0.0000 | CLSLoss:0.0387 | top1:93.0128 | AUROC:0.9772\n",
      "Test | 123/16 | Loss:0.6344 | MainLoss:0.6344 | SPLoss:0.0000 | CLSLoss:0.0387 | top1:70.2752 | AUROC:0.8450\n",
      "\n",
      "Epoch: [282 | 1000] LR: 0.001329\n",
      "Train | 16/16 | Loss:0.2642 | MainLoss:0.2256 | Alpha:0.4460 | SPLoss:0.0000 | CLSLoss:0.0386 | top1:92.3467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2084 | MainLoss:0.2084 | SPLoss:0.0000 | CLSLoss:0.0386 | top1:92.8974 | AUROC:0.9781\n",
      "Test | 123/16 | Loss:0.6123 | MainLoss:0.6123 | SPLoss:0.0000 | CLSLoss:0.0386 | top1:70.8060 | AUROC:0.8492\n",
      "\n",
      "Epoch: [283 | 1000] LR: 0.001327\n",
      "Train | 16/16 | Loss:0.2554 | MainLoss:0.2168 | Alpha:0.4493 | SPLoss:0.0000 | CLSLoss:0.0386 | top1:92.4267 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2071 | MainLoss:0.2071 | SPLoss:0.0000 | CLSLoss:0.0386 | top1:93.0769 | AUROC:0.9776\n",
      "Test | 123/16 | Loss:0.6215 | MainLoss:0.6215 | SPLoss:0.0000 | CLSLoss:0.0386 | top1:70.2851 | AUROC:0.8482\n",
      "\n",
      "Epoch: [284 | 1000] LR: 0.001325\n",
      "Train | 16/16 | Loss:0.2492 | MainLoss:0.2106 | Alpha:0.4503 | SPLoss:0.0000 | CLSLoss:0.0387 | top1:92.6133 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2087 | MainLoss:0.2087 | SPLoss:0.0000 | CLSLoss:0.0388 | top1:92.9359 | AUROC:0.9781\n",
      "Test | 123/16 | Loss:0.6111 | MainLoss:0.6111 | SPLoss:0.0000 | CLSLoss:0.0388 | top1:70.7110 | AUROC:0.8472\n",
      "\n",
      "Epoch: [285 | 1000] LR: 0.001323\n",
      "Train | 16/16 | Loss:0.2562 | MainLoss:0.2173 | Alpha:0.4482 | SPLoss:0.0000 | CLSLoss:0.0388 | top1:92.8000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2063 | MainLoss:0.2063 | SPLoss:0.0000 | CLSLoss:0.0388 | top1:93.0128 | AUROC:0.9778\n",
      "Test | 123/16 | Loss:0.6303 | MainLoss:0.6303 | SPLoss:0.0000 | CLSLoss:0.0388 | top1:70.0000 | AUROC:0.8487\n",
      "\n",
      "Epoch: [286 | 1000] LR: 0.001321\n",
      "Train | 16/16 | Loss:0.2542 | MainLoss:0.2155 | Alpha:0.4501 | SPLoss:0.0000 | CLSLoss:0.0387 | top1:92.4800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2080 | MainLoss:0.2080 | SPLoss:0.0000 | CLSLoss:0.0387 | top1:92.9487 | AUROC:0.9774\n",
      "Test | 123/16 | Loss:0.6239 | MainLoss:0.6239 | SPLoss:0.0000 | CLSLoss:0.0387 | top1:70.6062 | AUROC:0.8449\n",
      "\n",
      "Epoch: [287 | 1000] LR: 0.001320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 16/16 | Loss:0.2508 | MainLoss:0.2121 | Alpha:0.4506 | SPLoss:0.0000 | CLSLoss:0.0387 | top1:92.8533 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2055 | MainLoss:0.2055 | SPLoss:0.0000 | CLSLoss:0.0388 | top1:93.0641 | AUROC:0.9778\n",
      "Test | 123/16 | Loss:0.6398 | MainLoss:0.6398 | SPLoss:0.0000 | CLSLoss:0.0388 | top1:69.8362 | AUROC:0.8450\n",
      "\n",
      "Epoch: [288 | 1000] LR: 0.001318\n",
      "Train | 16/16 | Loss:0.2436 | MainLoss:0.2047 | Alpha:0.4520 | SPLoss:0.0000 | CLSLoss:0.0389 | top1:93.2800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2051 | MainLoss:0.2051 | SPLoss:0.0000 | CLSLoss:0.0389 | top1:93.0897 | AUROC:0.9781\n",
      "Test | 123/16 | Loss:0.6506 | MainLoss:0.6506 | SPLoss:0.0000 | CLSLoss:0.0389 | top1:69.3873 | AUROC:0.8457\n",
      "\n",
      "Epoch: [289 | 1000] LR: 0.001316\n",
      "Train | 16/16 | Loss:0.2473 | MainLoss:0.2084 | Alpha:0.4510 | SPLoss:0.0000 | CLSLoss:0.0389 | top1:92.7200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2048 | MainLoss:0.2048 | SPLoss:0.0000 | CLSLoss:0.0389 | top1:93.1026 | AUROC:0.9781\n",
      "Test | 123/16 | Loss:0.6448 | MainLoss:0.6448 | SPLoss:0.0000 | CLSLoss:0.0389 | top1:69.4463 | AUROC:0.8475\n",
      "\n",
      "Epoch: [290 | 1000] LR: 0.001314\n",
      "Train | 16/16 | Loss:0.2533 | MainLoss:0.2143 | Alpha:0.4496 | SPLoss:0.0000 | CLSLoss:0.0389 | top1:92.6667 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2056 | MainLoss:0.2056 | SPLoss:0.0000 | CLSLoss:0.0389 | top1:93.1154 | AUROC:0.9777\n",
      "Test | 123/16 | Loss:0.6414 | MainLoss:0.6414 | SPLoss:0.0000 | CLSLoss:0.0389 | top1:69.6429 | AUROC:0.8451\n",
      "\n",
      "Epoch: [291 | 1000] LR: 0.001312\n",
      "Train | 16/16 | Loss:0.2578 | MainLoss:0.2190 | Alpha:0.4491 | SPLoss:0.0000 | CLSLoss:0.0388 | top1:92.2933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2053 | MainLoss:0.2053 | SPLoss:0.0000 | CLSLoss:0.0387 | top1:93.1154 | AUROC:0.9785\n",
      "Test | 123/16 | Loss:0.6281 | MainLoss:0.6281 | SPLoss:0.0000 | CLSLoss:0.0387 | top1:69.7969 | AUROC:0.8485\n",
      "\n",
      "Epoch: [292 | 1000] LR: 0.001310\n",
      "Train | 16/16 | Loss:0.2527 | MainLoss:0.2139 | Alpha:0.4502 | SPLoss:0.0000 | CLSLoss:0.0388 | top1:92.5333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2042 | MainLoss:0.2042 | SPLoss:0.0000 | CLSLoss:0.0387 | top1:93.1410 | AUROC:0.9785\n",
      "Test | 123/16 | Loss:0.6333 | MainLoss:0.6333 | SPLoss:0.0000 | CLSLoss:0.0387 | top1:69.3971 | AUROC:0.8492\n",
      "\n",
      "Epoch: [293 | 1000] LR: 0.001308\n",
      "Train | 16/16 | Loss:0.2470 | MainLoss:0.2082 | Alpha:0.4504 | SPLoss:0.0000 | CLSLoss:0.0388 | top1:92.9067 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2044 | MainLoss:0.2044 | SPLoss:0.0000 | CLSLoss:0.0388 | top1:93.1282 | AUROC:0.9779\n",
      "Test | 123/16 | Loss:0.6460 | MainLoss:0.6460 | SPLoss:0.0000 | CLSLoss:0.0388 | top1:69.4201 | AUROC:0.8435\n",
      "\n",
      "Epoch: [294 | 1000] LR: 0.001306\n",
      "Train | 16/16 | Loss:0.2448 | MainLoss:0.2059 | Alpha:0.4514 | SPLoss:0.0000 | CLSLoss:0.0388 | top1:92.9600 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2039 | MainLoss:0.2039 | SPLoss:0.0000 | CLSLoss:0.0389 | top1:93.1282 | AUROC:0.9784\n",
      "Test | 123/16 | Loss:0.6444 | MainLoss:0.6444 | SPLoss:0.0000 | CLSLoss:0.0389 | top1:69.4004 | AUROC:0.8449\n",
      "\n",
      "Epoch: [295 | 1000] LR: 0.001304\n",
      "Train | 16/16 | Loss:0.2522 | MainLoss:0.2133 | Alpha:0.4497 | SPLoss:0.0000 | CLSLoss:0.0389 | top1:93.0933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2058 | MainLoss:0.2058 | SPLoss:0.0000 | CLSLoss:0.0388 | top1:92.9487 | AUROC:0.9782\n",
      "Test | 123/16 | Loss:0.6331 | MainLoss:0.6331 | SPLoss:0.0000 | CLSLoss:0.0388 | top1:70.1835 | AUROC:0.8427\n",
      "\n",
      "Epoch: [296 | 1000] LR: 0.001302\n",
      "Train | 16/16 | Loss:0.2533 | MainLoss:0.2146 | Alpha:0.4494 | SPLoss:0.0000 | CLSLoss:0.0387 | top1:92.5867 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2052 | MainLoss:0.2052 | SPLoss:0.0000 | CLSLoss:0.0388 | top1:93.0128 | AUROC:0.9780\n",
      "Test | 123/16 | Loss:0.6360 | MainLoss:0.6360 | SPLoss:0.0000 | CLSLoss:0.0388 | top1:70.0754 | AUROC:0.8424\n",
      "\n",
      "Epoch: [297 | 1000] LR: 0.001300\n",
      "Train | 16/16 | Loss:0.2629 | MainLoss:0.2241 | Alpha:0.4473 | SPLoss:0.0000 | CLSLoss:0.0387 | top1:92.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2033 | MainLoss:0.2033 | SPLoss:0.0000 | CLSLoss:0.0385 | top1:93.1026 | AUROC:0.9792\n",
      "Test | 123/16 | Loss:0.6357 | MainLoss:0.6357 | SPLoss:0.0000 | CLSLoss:0.0385 | top1:69.3414 | AUROC:0.8460\n",
      "\n",
      "Epoch: [298 | 1000] LR: 0.001298\n",
      "Train | 16/16 | Loss:0.2471 | MainLoss:0.2085 | Alpha:0.4508 | SPLoss:0.0000 | CLSLoss:0.0386 | top1:92.6933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2040 | MainLoss:0.2040 | SPLoss:0.0000 | CLSLoss:0.0386 | top1:93.1154 | AUROC:0.9788\n",
      "Test | 123/16 | Loss:0.6335 | MainLoss:0.6335 | SPLoss:0.0000 | CLSLoss:0.0386 | top1:69.7772 | AUROC:0.8435\n",
      "\n",
      "Epoch: [299 | 1000] LR: 0.001296\n",
      "Train | 16/16 | Loss:0.2622 | MainLoss:0.2236 | Alpha:0.4472 | SPLoss:0.0000 | CLSLoss:0.0386 | top1:92.3200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2036 | MainLoss:0.2036 | SPLoss:0.0000 | CLSLoss:0.0385 | top1:93.0897 | AUROC:0.9788\n",
      "Test | 123/16 | Loss:0.6290 | MainLoss:0.6290 | SPLoss:0.0000 | CLSLoss:0.0385 | top1:69.6723 | AUROC:0.8443\n",
      "\n",
      "Epoch: [300 | 1000] LR: 0.001294\n",
      "Train | 16/16 | Loss:0.2457 | MainLoss:0.2071 | Alpha:0.4516 | SPLoss:0.0000 | CLSLoss:0.0386 | top1:93.0667 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2034 | MainLoss:0.2034 | SPLoss:0.0000 | CLSLoss:0.0386 | top1:93.0769 | AUROC:0.9786\n",
      "Test | 123/16 | Loss:0.6426 | MainLoss:0.6426 | SPLoss:0.0000 | CLSLoss:0.0386 | top1:69.7805 | AUROC:0.8393\n",
      "\n",
      "Epoch: [301 | 1000] LR: 0.001292\n",
      "Train | 16/16 | Loss:0.2521 | MainLoss:0.2135 | Alpha:0.4507 | SPLoss:0.0000 | CLSLoss:0.0386 | top1:92.7467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2027 | MainLoss:0.2027 | SPLoss:0.0000 | CLSLoss:0.0386 | top1:93.1410 | AUROC:0.9784\n",
      "Test | 123/16 | Loss:0.6530 | MainLoss:0.6530 | SPLoss:0.0000 | CLSLoss:0.0386 | top1:69.3611 | AUROC:0.8384\n",
      "\n",
      "Epoch: [302 | 1000] LR: 0.001290\n",
      "Train | 16/16 | Loss:0.2490 | MainLoss:0.2103 | Alpha:0.4508 | SPLoss:0.0000 | CLSLoss:0.0387 | top1:92.5333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2036 | MainLoss:0.2036 | SPLoss:0.0000 | CLSLoss:0.0387 | top1:93.1154 | AUROC:0.9787\n",
      "Test | 123/16 | Loss:0.6415 | MainLoss:0.6415 | SPLoss:0.0000 | CLSLoss:0.0387 | top1:69.8526 | AUROC:0.8403\n",
      "\n",
      "Epoch: [303 | 1000] LR: 0.001288\n",
      "Train | 16/16 | Loss:0.2512 | MainLoss:0.2126 | Alpha:0.4506 | SPLoss:0.0000 | CLSLoss:0.0387 | top1:92.4800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2050 | MainLoss:0.2050 | SPLoss:0.0000 | CLSLoss:0.0387 | top1:92.9872 | AUROC:0.9789\n",
      "Test | 123/16 | Loss:0.6170 | MainLoss:0.6170 | SPLoss:0.0000 | CLSLoss:0.0387 | top1:70.6389 | AUROC:0.8450\n",
      "\n",
      "Epoch: [304 | 1000] LR: 0.001286\n",
      "Train | 16/16 | Loss:0.2384 | MainLoss:0.1997 | Alpha:0.4526 | SPLoss:0.0000 | CLSLoss:0.0387 | top1:93.2000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2026 | MainLoss:0.2026 | SPLoss:0.0000 | CLSLoss:0.0389 | top1:93.1667 | AUROC:0.9783\n",
      "Test | 123/16 | Loss:0.6507 | MainLoss:0.6507 | SPLoss:0.0000 | CLSLoss:0.0389 | top1:69.6199 | AUROC:0.8391\n",
      "\n",
      "Epoch: [305 | 1000] LR: 0.001284\n",
      "Train | 16/16 | Loss:0.2417 | MainLoss:0.2028 | Alpha:0.4519 | SPLoss:0.0000 | CLSLoss:0.0389 | top1:93.0133 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2026 | MainLoss:0.2026 | SPLoss:0.0000 | CLSLoss:0.0389 | top1:93.1667 | AUROC:0.9778\n",
      "Test | 123/16 | Loss:0.6533 | MainLoss:0.6533 | SPLoss:0.0000 | CLSLoss:0.0389 | top1:69.6199 | AUROC:0.8393\n",
      "\n",
      "Epoch: [306 | 1000] LR: 0.001282\n",
      "Train | 16/16 | Loss:0.2428 | MainLoss:0.2039 | Alpha:0.4513 | SPLoss:0.0000 | CLSLoss:0.0388 | top1:93.0667 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2031 | MainLoss:0.2031 | SPLoss:0.0000 | CLSLoss:0.0389 | top1:93.1795 | AUROC:0.9780\n",
      "Test | 123/16 | Loss:0.6591 | MainLoss:0.6591 | SPLoss:0.0000 | CLSLoss:0.0389 | top1:69.6396 | AUROC:0.8370\n",
      "\n",
      "Epoch: [307 | 1000] LR: 0.001280\n",
      "Train | 16/16 | Loss:0.2411 | MainLoss:0.2023 | Alpha:0.4530 | SPLoss:0.0000 | CLSLoss:0.0388 | top1:92.7200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2058 | MainLoss:0.2058 | SPLoss:0.0000 | CLSLoss:0.0388 | top1:93.0128 | AUROC:0.9781\n",
      "Test | 123/16 | Loss:0.6360 | MainLoss:0.6360 | SPLoss:0.0000 | CLSLoss:0.0388 | top1:70.4686 | AUROC:0.8400\n",
      "\n",
      "Epoch: [308 | 1000] LR: 0.001278\n",
      "Train | 16/16 | Loss:0.2541 | MainLoss:0.2154 | Alpha:0.4485 | SPLoss:0.0000 | CLSLoss:0.0387 | top1:92.2933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2014 | MainLoss:0.2014 | SPLoss:0.0000 | CLSLoss:0.0387 | top1:93.1667 | AUROC:0.9787\n",
      "Test | 123/16 | Loss:0.6559 | MainLoss:0.6559 | SPLoss:0.0000 | CLSLoss:0.0387 | top1:69.1252 | AUROC:0.8429\n",
      "\n",
      "Epoch: [309 | 1000] LR: 0.001276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 16/16 | Loss:0.2571 | MainLoss:0.2186 | Alpha:0.4482 | SPLoss:0.0000 | CLSLoss:0.0386 | top1:92.2933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2040 | MainLoss:0.2040 | SPLoss:0.0000 | CLSLoss:0.0385 | top1:93.1282 | AUROC:0.9788\n",
      "Test | 123/16 | Loss:0.6247 | MainLoss:0.6247 | SPLoss:0.0000 | CLSLoss:0.0385 | top1:70.1573 | AUROC:0.8442\n",
      "\n",
      "Epoch: [310 | 1000] LR: 0.001274\n",
      "Train | 16/16 | Loss:0.2463 | MainLoss:0.2079 | Alpha:0.4513 | SPLoss:0.0000 | CLSLoss:0.0385 | top1:93.2000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2018 | MainLoss:0.2018 | SPLoss:0.0000 | CLSLoss:0.0386 | top1:93.2436 | AUROC:0.9789\n",
      "Test | 123/16 | Loss:0.6487 | MainLoss:0.6487 | SPLoss:0.0000 | CLSLoss:0.0386 | top1:69.4135 | AUROC:0.8422\n",
      "\n",
      "Epoch: [311 | 1000] LR: 0.001272\n",
      "Train | 16/16 | Loss:0.2365 | MainLoss:0.1979 | Alpha:0.4532 | SPLoss:0.0000 | CLSLoss:0.0386 | top1:93.0133 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2010 | MainLoss:0.2010 | SPLoss:0.0000 | CLSLoss:0.0388 | top1:93.2692 | AUROC:0.9781\n",
      "Test | 123/16 | Loss:0.6673 | MainLoss:0.6673 | SPLoss:0.0000 | CLSLoss:0.0388 | top1:69.0039 | AUROC:0.8375\n",
      "\n",
      "Epoch: [312 | 1000] LR: 0.001270\n",
      "Train | 16/16 | Loss:0.2401 | MainLoss:0.2014 | Alpha:0.4528 | SPLoss:0.0000 | CLSLoss:0.0387 | top1:93.1467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2018 | MainLoss:0.2018 | SPLoss:0.0000 | CLSLoss:0.0388 | top1:93.1923 | AUROC:0.9789\n",
      "Test | 123/16 | Loss:0.6461 | MainLoss:0.6461 | SPLoss:0.0000 | CLSLoss:0.0388 | top1:69.5577 | AUROC:0.8424\n",
      "\n",
      "Epoch: [313 | 1000] LR: 0.001268\n",
      "Train | 16/16 | Loss:0.2372 | MainLoss:0.1984 | Alpha:0.4537 | SPLoss:0.0000 | CLSLoss:0.0388 | top1:93.0133 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2016 | MainLoss:0.2016 | SPLoss:0.0000 | CLSLoss:0.0389 | top1:93.1795 | AUROC:0.9791\n",
      "Test | 123/16 | Loss:0.6461 | MainLoss:0.6461 | SPLoss:0.0000 | CLSLoss:0.0389 | top1:69.5282 | AUROC:0.8415\n",
      "\n",
      "Epoch: [314 | 1000] LR: 0.001266\n",
      "Train | 16/16 | Loss:0.2484 | MainLoss:0.2096 | Alpha:0.4511 | SPLoss:0.0000 | CLSLoss:0.0388 | top1:92.6133 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2008 | MainLoss:0.2008 | SPLoss:0.0000 | CLSLoss:0.0388 | top1:93.2436 | AUROC:0.9786\n",
      "Test | 123/16 | Loss:0.6563 | MainLoss:0.6563 | SPLoss:0.0000 | CLSLoss:0.0388 | top1:69.1415 | AUROC:0.8405\n",
      "\n",
      "Epoch: [315 | 1000] LR: 0.001264\n",
      "Train | 16/16 | Loss:0.2407 | MainLoss:0.2019 | Alpha:0.4528 | SPLoss:0.0000 | CLSLoss:0.0389 | top1:92.9600 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2010 | MainLoss:0.2010 | SPLoss:0.0000 | CLSLoss:0.0389 | top1:93.2821 | AUROC:0.9783\n",
      "Test | 123/16 | Loss:0.6561 | MainLoss:0.6561 | SPLoss:0.0000 | CLSLoss:0.0389 | top1:69.4070 | AUROC:0.8376\n",
      "\n",
      "Epoch: [316 | 1000] LR: 0.001262\n",
      "Train | 16/16 | Loss:0.2466 | MainLoss:0.2077 | Alpha:0.4517 | SPLoss:0.0000 | CLSLoss:0.0388 | top1:92.9867 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2001 | MainLoss:0.2001 | SPLoss:0.0000 | CLSLoss:0.0388 | top1:93.2692 | AUROC:0.9790\n",
      "Test | 123/16 | Loss:0.6621 | MainLoss:0.6621 | SPLoss:0.0000 | CLSLoss:0.0388 | top1:69.1153 | AUROC:0.8378\n",
      "\n",
      "Epoch: [317 | 1000] LR: 0.001260\n",
      "Train | 16/16 | Loss:0.2373 | MainLoss:0.1985 | Alpha:0.4537 | SPLoss:0.0000 | CLSLoss:0.0389 | top1:93.0933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2030 | MainLoss:0.2030 | SPLoss:0.0000 | CLSLoss:0.0389 | top1:93.2179 | AUROC:0.9790\n",
      "Test | 123/16 | Loss:0.6450 | MainLoss:0.6450 | SPLoss:0.0000 | CLSLoss:0.0389 | top1:70.1573 | AUROC:0.8370\n",
      "\n",
      "Epoch: [318 | 1000] LR: 0.001258\n",
      "Train | 16/16 | Loss:0.2414 | MainLoss:0.2024 | Alpha:0.4527 | SPLoss:0.0000 | CLSLoss:0.0389 | top1:92.6933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2014 | MainLoss:0.2014 | SPLoss:0.0000 | CLSLoss:0.0389 | top1:93.2564 | AUROC:0.9797\n",
      "Test | 123/16 | Loss:0.6337 | MainLoss:0.6337 | SPLoss:0.0000 | CLSLoss:0.0389 | top1:70.0360 | AUROC:0.8431\n",
      "\n",
      "Epoch: [319 | 1000] LR: 0.001256\n",
      "Train | 16/16 | Loss:0.2320 | MainLoss:0.1930 | Alpha:0.4540 | SPLoss:0.0000 | CLSLoss:0.0390 | top1:93.3333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2031 | MainLoss:0.2031 | SPLoss:0.0000 | CLSLoss:0.0391 | top1:93.1667 | AUROC:0.9785\n",
      "Test | 123/16 | Loss:0.6482 | MainLoss:0.6482 | SPLoss:0.0000 | CLSLoss:0.0391 | top1:70.1933 | AUROC:0.8347\n",
      "\n",
      "Epoch: [320 | 1000] LR: 0.001254\n",
      "Train | 16/16 | Loss:0.2526 | MainLoss:0.2136 | Alpha:0.4504 | SPLoss:0.0000 | CLSLoss:0.0390 | top1:92.5867 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1995 | MainLoss:0.1995 | SPLoss:0.0000 | CLSLoss:0.0389 | top1:93.2308 | AUROC:0.9794\n",
      "Test | 123/16 | Loss:0.6527 | MainLoss:0.6527 | SPLoss:0.0000 | CLSLoss:0.0389 | top1:69.4659 | AUROC:0.8407\n",
      "\n",
      "Epoch: [321 | 1000] LR: 0.001252\n",
      "Train | 16/16 | Loss:0.2592 | MainLoss:0.2204 | Alpha:0.4483 | SPLoss:0.0000 | CLSLoss:0.0388 | top1:92.1067 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2010 | MainLoss:0.2010 | SPLoss:0.0000 | CLSLoss:0.0386 | top1:93.2564 | AUROC:0.9797\n",
      "Test | 123/16 | Loss:0.6305 | MainLoss:0.6305 | SPLoss:0.0000 | CLSLoss:0.0386 | top1:70.0426 | AUROC:0.8443\n",
      "\n",
      "Epoch: [322 | 1000] LR: 0.001250\n",
      "Train | 16/16 | Loss:0.2371 | MainLoss:0.1985 | Alpha:0.4532 | SPLoss:0.0000 | CLSLoss:0.0387 | top1:93.3067 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2012 | MainLoss:0.2012 | SPLoss:0.0000 | CLSLoss:0.0387 | top1:93.2051 | AUROC:0.9793\n",
      "Test | 123/16 | Loss:0.6473 | MainLoss:0.6473 | SPLoss:0.0000 | CLSLoss:0.0387 | top1:70.0688 | AUROC:0.8357\n",
      "\n",
      "Epoch: [323 | 1000] LR: 0.001248\n",
      "Train | 16/16 | Loss:0.2543 | MainLoss:0.2156 | Alpha:0.4492 | SPLoss:0.0000 | CLSLoss:0.0386 | top1:92.5333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2007 | MainLoss:0.2007 | SPLoss:0.0000 | CLSLoss:0.0385 | top1:93.2692 | AUROC:0.9795\n",
      "Test | 123/16 | Loss:0.6290 | MainLoss:0.6290 | SPLoss:0.0000 | CLSLoss:0.0385 | top1:69.9214 | AUROC:0.8443\n",
      "\n",
      "Epoch: [324 | 1000] LR: 0.001246\n",
      "Train | 16/16 | Loss:0.2423 | MainLoss:0.2037 | Alpha:0.4519 | SPLoss:0.0000 | CLSLoss:0.0386 | top1:92.8000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1981 | MainLoss:0.1981 | SPLoss:0.0000 | CLSLoss:0.0385 | top1:93.2949 | AUROC:0.9796\n",
      "Test | 123/16 | Loss:0.6454 | MainLoss:0.6454 | SPLoss:0.0000 | CLSLoss:0.0385 | top1:69.2497 | AUROC:0.8446\n",
      "\n",
      "Epoch: [325 | 1000] LR: 0.001243\n",
      "Train | 16/16 | Loss:0.2401 | MainLoss:0.2016 | Alpha:0.4515 | SPLoss:0.0000 | CLSLoss:0.0385 | top1:93.0400 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1981 | MainLoss:0.1981 | SPLoss:0.0000 | CLSLoss:0.0386 | top1:93.3718 | AUROC:0.9785\n",
      "Test | 123/16 | Loss:0.6727 | MainLoss:0.6727 | SPLoss:0.0000 | CLSLoss:0.0386 | top1:69.0629 | AUROC:0.8318\n",
      "\n",
      "Epoch: [326 | 1000] LR: 0.001241\n",
      "Train | 16/16 | Loss:0.2449 | MainLoss:0.2064 | Alpha:0.4513 | SPLoss:0.0000 | CLSLoss:0.0385 | top1:92.8267 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1988 | MainLoss:0.1988 | SPLoss:0.0000 | CLSLoss:0.0385 | top1:93.2692 | AUROC:0.9787\n",
      "Test | 123/16 | Loss:0.6681 | MainLoss:0.6681 | SPLoss:0.0000 | CLSLoss:0.0385 | top1:69.1121 | AUROC:0.8325\n",
      "\n",
      "Epoch: [327 | 1000] LR: 0.001239\n",
      "Train | 16/16 | Loss:0.2394 | MainLoss:0.2009 | Alpha:0.4530 | SPLoss:0.0000 | CLSLoss:0.0385 | top1:93.0933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1997 | MainLoss:0.1997 | SPLoss:0.0000 | CLSLoss:0.0385 | top1:93.3205 | AUROC:0.9798\n",
      "Test | 123/16 | Loss:0.6460 | MainLoss:0.6460 | SPLoss:0.0000 | CLSLoss:0.0385 | top1:69.6035 | AUROC:0.8400\n",
      "\n",
      "Epoch: [328 | 1000] LR: 0.001237\n",
      "Train | 16/16 | Loss:0.2436 | MainLoss:0.2051 | Alpha:0.4510 | SPLoss:0.0000 | CLSLoss:0.0385 | top1:92.8533 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1989 | MainLoss:0.1989 | SPLoss:0.0000 | CLSLoss:0.0384 | top1:93.3077 | AUROC:0.9794\n",
      "Test | 123/16 | Loss:0.6499 | MainLoss:0.6499 | SPLoss:0.0000 | CLSLoss:0.0384 | top1:69.4659 | AUROC:0.8390\n",
      "\n",
      "Epoch: [329 | 1000] LR: 0.001235\n",
      "Train | 16/16 | Loss:0.2495 | MainLoss:0.2111 | Alpha:0.4506 | SPLoss:0.0000 | CLSLoss:0.0384 | top1:92.4533 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1988 | MainLoss:0.1988 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:93.3333 | AUROC:0.9803\n",
      "Test | 123/16 | Loss:0.6463 | MainLoss:0.6463 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:69.4332 | AUROC:0.8396\n",
      "\n",
      "Epoch: [330 | 1000] LR: 0.001233\n",
      "Train | 16/16 | Loss:0.2321 | MainLoss:0.1936 | Alpha:0.4540 | SPLoss:0.0000 | CLSLoss:0.0385 | top1:93.4133 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2003 | MainLoss:0.2003 | SPLoss:0.0000 | CLSLoss:0.0385 | top1:93.2436 | AUROC:0.9797\n",
      "Test | 123/16 | Loss:0.6405 | MainLoss:0.6405 | SPLoss:0.0000 | CLSLoss:0.0385 | top1:69.7149 | AUROC:0.8394\n",
      "\n",
      "Epoch: [331 | 1000] LR: 0.001231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 16/16 | Loss:0.2476 | MainLoss:0.2093 | Alpha:0.4500 | SPLoss:0.0000 | CLSLoss:0.0384 | top1:92.3467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1972 | MainLoss:0.1972 | SPLoss:0.0000 | CLSLoss:0.0384 | top1:93.3718 | AUROC:0.9799\n",
      "Test | 123/16 | Loss:0.6525 | MainLoss:0.6525 | SPLoss:0.0000 | CLSLoss:0.0384 | top1:69.0269 | AUROC:0.8385\n",
      "\n",
      "Epoch: [332 | 1000] LR: 0.001229\n",
      "Train | 16/16 | Loss:0.2396 | MainLoss:0.2011 | Alpha:0.4527 | SPLoss:0.0000 | CLSLoss:0.0384 | top1:93.0667 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1980 | MainLoss:0.1980 | SPLoss:0.0000 | CLSLoss:0.0385 | top1:93.3077 | AUROC:0.9796\n",
      "Test | 123/16 | Loss:0.6568 | MainLoss:0.6568 | SPLoss:0.0000 | CLSLoss:0.0385 | top1:69.4594 | AUROC:0.8322\n",
      "\n",
      "Epoch: [333 | 1000] LR: 0.001227\n",
      "Train | 16/16 | Loss:0.2476 | MainLoss:0.2092 | Alpha:0.4510 | SPLoss:0.0000 | CLSLoss:0.0384 | top1:92.7200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1970 | MainLoss:0.1970 | SPLoss:0.0000 | CLSLoss:0.0385 | top1:93.3974 | AUROC:0.9804\n",
      "Test | 123/16 | Loss:0.6564 | MainLoss:0.6564 | SPLoss:0.0000 | CLSLoss:0.0385 | top1:69.1219 | AUROC:0.8355\n",
      "\n",
      "Epoch: [334 | 1000] LR: 0.001224\n",
      "Train | 16/16 | Loss:0.2394 | MainLoss:0.2009 | Alpha:0.4542 | SPLoss:0.0000 | CLSLoss:0.0385 | top1:93.0933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1977 | MainLoss:0.1977 | SPLoss:0.0000 | CLSLoss:0.0385 | top1:93.3077 | AUROC:0.9800\n",
      "Test | 123/16 | Loss:0.6502 | MainLoss:0.6502 | SPLoss:0.0000 | CLSLoss:0.0385 | top1:69.3349 | AUROC:0.8365\n",
      "\n",
      "Epoch: [335 | 1000] LR: 0.001222\n",
      "Train | 16/16 | Loss:0.2350 | MainLoss:0.1965 | Alpha:0.4538 | SPLoss:0.0000 | CLSLoss:0.0385 | top1:93.1733 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1978 | MainLoss:0.1978 | SPLoss:0.0000 | CLSLoss:0.0386 | top1:93.3205 | AUROC:0.9797\n",
      "Test | 123/16 | Loss:0.6553 | MainLoss:0.6553 | SPLoss:0.0000 | CLSLoss:0.0386 | top1:69.4299 | AUROC:0.8327\n",
      "\n",
      "Epoch: [336 | 1000] LR: 0.001220\n",
      "Train | 16/16 | Loss:0.2520 | MainLoss:0.2135 | Alpha:0.4507 | SPLoss:0.0000 | CLSLoss:0.0386 | top1:92.7467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.2010 | MainLoss:0.2010 | SPLoss:0.0000 | CLSLoss:0.0385 | top1:93.1410 | AUROC:0.9792\n",
      "Test | 123/16 | Loss:0.6418 | MainLoss:0.6418 | SPLoss:0.0000 | CLSLoss:0.0385 | top1:69.9640 | AUROC:0.8320\n",
      "\n",
      "Epoch: [337 | 1000] LR: 0.001218\n",
      "Train | 16/16 | Loss:0.2462 | MainLoss:0.2077 | Alpha:0.4512 | SPLoss:0.0000 | CLSLoss:0.0385 | top1:92.5067 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1994 | MainLoss:0.1994 | SPLoss:0.0000 | CLSLoss:0.0385 | top1:93.2949 | AUROC:0.9802\n",
      "Test | 123/16 | Loss:0.6368 | MainLoss:0.6368 | SPLoss:0.0000 | CLSLoss:0.0385 | top1:69.7379 | AUROC:0.8366\n",
      "\n",
      "Epoch: [338 | 1000] LR: 0.001216\n",
      "Train | 16/16 | Loss:0.2377 | MainLoss:0.1992 | Alpha:0.4524 | SPLoss:0.0000 | CLSLoss:0.0385 | top1:93.1200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1952 | MainLoss:0.1952 | SPLoss:0.0000 | CLSLoss:0.0386 | top1:93.4103 | AUROC:0.9796\n",
      "Test | 123/16 | Loss:0.6801 | MainLoss:0.6801 | SPLoss:0.0000 | CLSLoss:0.0386 | top1:68.5616 | AUROC:0.8297\n",
      "\n",
      "Epoch: [339 | 1000] LR: 0.001214\n",
      "Train | 16/16 | Loss:0.2596 | MainLoss:0.2212 | Alpha:0.4485 | SPLoss:0.0000 | CLSLoss:0.0384 | top1:92.4267 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1972 | MainLoss:0.1972 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:93.3333 | AUROC:0.9803\n",
      "Test | 123/16 | Loss:0.6397 | MainLoss:0.6397 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:69.6789 | AUROC:0.8360\n",
      "\n",
      "Epoch: [340 | 1000] LR: 0.001212\n",
      "Train | 16/16 | Loss:0.2365 | MainLoss:0.1982 | Alpha:0.4540 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:93.4400 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1951 | MainLoss:0.1951 | SPLoss:0.0000 | CLSLoss:0.0384 | top1:93.3846 | AUROC:0.9772\n",
      "Test | 123/16 | Loss:0.6999 | MainLoss:0.6999 | SPLoss:0.0000 | CLSLoss:0.0384 | top1:68.6566 | AUROC:0.8154\n",
      "\n",
      "Epoch: [341 | 1000] LR: 0.001209\n",
      "Train | 16/16 | Loss:0.2435 | MainLoss:0.2052 | Alpha:0.4516 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:93.2000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1960 | MainLoss:0.1960 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:93.3333 | AUROC:0.9799\n",
      "Test | 123/16 | Loss:0.6585 | MainLoss:0.6585 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:69.6691 | AUROC:0.8330\n",
      "\n",
      "Epoch: [342 | 1000] LR: 0.001207\n",
      "Train | 16/16 | Loss:0.2401 | MainLoss:0.2017 | Alpha:0.4530 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:93.1733 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1950 | MainLoss:0.1950 | SPLoss:0.0000 | CLSLoss:0.0384 | top1:93.4231 | AUROC:0.9803\n",
      "Test | 123/16 | Loss:0.6618 | MainLoss:0.6618 | SPLoss:0.0000 | CLSLoss:0.0384 | top1:69.4364 | AUROC:0.8377\n",
      "\n",
      "Epoch: [343 | 1000] LR: 0.001205\n",
      "Train | 16/16 | Loss:0.2383 | MainLoss:0.1999 | Alpha:0.4532 | SPLoss:0.0000 | CLSLoss:0.0384 | top1:93.2533 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1959 | MainLoss:0.1959 | SPLoss:0.0000 | CLSLoss:0.0384 | top1:93.3205 | AUROC:0.9801\n",
      "Test | 123/16 | Loss:0.6545 | MainLoss:0.6545 | SPLoss:0.0000 | CLSLoss:0.0384 | top1:69.7018 | AUROC:0.8365\n",
      "\n",
      "Epoch: [344 | 1000] LR: 0.001203\n",
      "Train | 16/16 | Loss:0.2507 | MainLoss:0.2124 | Alpha:0.4498 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:92.4000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1974 | MainLoss:0.1974 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:93.2949 | AUROC:0.9807\n",
      "Test | 123/16 | Loss:0.6297 | MainLoss:0.6297 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:70.2195 | AUROC:0.8406\n",
      "\n",
      "Epoch: [345 | 1000] LR: 0.001201\n",
      "Train | 16/16 | Loss:0.2352 | MainLoss:0.1969 | Alpha:0.4540 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:93.5467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1955 | MainLoss:0.1955 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:93.3205 | AUROC:0.9803\n",
      "Test | 123/16 | Loss:0.6470 | MainLoss:0.6470 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:69.8231 | AUROC:0.8343\n",
      "\n",
      "Epoch: [346 | 1000] LR: 0.001199\n",
      "Train | 16/16 | Loss:0.2533 | MainLoss:0.2151 | Alpha:0.4491 | SPLoss:0.0000 | CLSLoss:0.0382 | top1:92.4800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1960 | MainLoss:0.1960 | SPLoss:0.0000 | CLSLoss:0.0382 | top1:93.3205 | AUROC:0.9804\n",
      "Test | 123/16 | Loss:0.6444 | MainLoss:0.6444 | SPLoss:0.0000 | CLSLoss:0.0382 | top1:69.8165 | AUROC:0.8372\n",
      "\n",
      "Epoch: [347 | 1000] LR: 0.001196\n",
      "Train | 16/16 | Loss:0.2453 | MainLoss:0.2071 | Alpha:0.4520 | SPLoss:0.0000 | CLSLoss:0.0382 | top1:92.7200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1940 | MainLoss:0.1940 | SPLoss:0.0000 | CLSLoss:0.0381 | top1:93.4359 | AUROC:0.9803\n",
      "Test | 123/16 | Loss:0.6616 | MainLoss:0.6616 | SPLoss:0.0000 | CLSLoss:0.0381 | top1:69.1383 | AUROC:0.8365\n",
      "\n",
      "Epoch: [348 | 1000] LR: 0.001194\n",
      "Train | 16/16 | Loss:0.2452 | MainLoss:0.2071 | Alpha:0.4507 | SPLoss:0.0000 | CLSLoss:0.0381 | top1:92.9333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1949 | MainLoss:0.1949 | SPLoss:0.0000 | CLSLoss:0.0381 | top1:93.3974 | AUROC:0.9807\n",
      "Test | 123/16 | Loss:0.6532 | MainLoss:0.6532 | SPLoss:0.0000 | CLSLoss:0.0381 | top1:69.6199 | AUROC:0.8361\n",
      "\n",
      "Epoch: [349 | 1000] LR: 0.001192\n",
      "Train | 16/16 | Loss:0.2433 | MainLoss:0.2052 | Alpha:0.4516 | SPLoss:0.0000 | CLSLoss:0.0381 | top1:93.2800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1933 | MainLoss:0.1933 | SPLoss:0.0000 | CLSLoss:0.0381 | top1:93.4487 | AUROC:0.9807\n",
      "Test | 123/16 | Loss:0.6747 | MainLoss:0.6747 | SPLoss:0.0000 | CLSLoss:0.0381 | top1:68.7680 | AUROC:0.8354\n",
      "\n",
      "Epoch: [350 | 1000] LR: 0.001190\n",
      "Train | 16/16 | Loss:0.2386 | MainLoss:0.2006 | Alpha:0.4533 | SPLoss:0.0000 | CLSLoss:0.0381 | top1:93.1200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1954 | MainLoss:0.1954 | SPLoss:0.0000 | CLSLoss:0.0382 | top1:93.4103 | AUROC:0.9801\n",
      "Test | 123/16 | Loss:0.6601 | MainLoss:0.6601 | SPLoss:0.0000 | CLSLoss:0.0382 | top1:69.4659 | AUROC:0.8330\n",
      "\n",
      "Epoch: [351 | 1000] LR: 0.001188\n",
      "Train | 16/16 | Loss:0.2374 | MainLoss:0.1992 | Alpha:0.4532 | SPLoss:0.0000 | CLSLoss:0.0382 | top1:93.3067 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1939 | MainLoss:0.1939 | SPLoss:0.0000 | CLSLoss:0.0382 | top1:93.4615 | AUROC:0.9801\n",
      "Test | 123/16 | Loss:0.6739 | MainLoss:0.6739 | SPLoss:0.0000 | CLSLoss:0.0382 | top1:69.1448 | AUROC:0.8308\n",
      "\n",
      "Epoch: [352 | 1000] LR: 0.001185\n",
      "Train | 16/16 | Loss:0.2395 | MainLoss:0.2013 | Alpha:0.4532 | SPLoss:0.0000 | CLSLoss:0.0382 | top1:92.9067 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1935 | MainLoss:0.1935 | SPLoss:0.0000 | CLSLoss:0.0382 | top1:93.4487 | AUROC:0.9806\n",
      "Test | 123/16 | Loss:0.6595 | MainLoss:0.6595 | SPLoss:0.0000 | CLSLoss:0.0382 | top1:68.9515 | AUROC:0.8402\n",
      "\n",
      "Epoch: [353 | 1000] LR: 0.001183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 16/16 | Loss:0.2348 | MainLoss:0.1965 | Alpha:0.4542 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:93.2000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1942 | MainLoss:0.1942 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:93.4359 | AUROC:0.9803\n",
      "Test | 123/16 | Loss:0.6627 | MainLoss:0.6627 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:69.3742 | AUROC:0.8345\n",
      "\n",
      "Epoch: [354 | 1000] LR: 0.001181\n",
      "Train | 16/16 | Loss:0.2299 | MainLoss:0.1915 | Alpha:0.4541 | SPLoss:0.0000 | CLSLoss:0.0384 | top1:93.3600 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1979 | MainLoss:0.1979 | SPLoss:0.0000 | CLSLoss:0.0384 | top1:93.3077 | AUROC:0.9801\n",
      "Test | 123/16 | Loss:0.6445 | MainLoss:0.6445 | SPLoss:0.0000 | CLSLoss:0.0384 | top1:70.3899 | AUROC:0.8317\n",
      "\n",
      "Epoch: [355 | 1000] LR: 0.001179\n",
      "Train | 16/16 | Loss:0.2460 | MainLoss:0.2076 | Alpha:0.4514 | SPLoss:0.0000 | CLSLoss:0.0384 | top1:92.6667 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1926 | MainLoss:0.1926 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:93.5000 | AUROC:0.9816\n",
      "Test | 123/16 | Loss:0.6477 | MainLoss:0.6477 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:69.0760 | AUROC:0.8440\n",
      "\n",
      "Epoch: [356 | 1000] LR: 0.001177\n",
      "Train | 16/16 | Loss:0.2337 | MainLoss:0.1953 | Alpha:0.4543 | SPLoss:0.0000 | CLSLoss:0.0384 | top1:93.5200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1966 | MainLoss:0.1966 | SPLoss:0.0000 | CLSLoss:0.0385 | top1:93.2949 | AUROC:0.9804\n",
      "Test | 123/16 | Loss:0.6319 | MainLoss:0.6319 | SPLoss:0.0000 | CLSLoss:0.0385 | top1:70.2720 | AUROC:0.8402\n",
      "\n",
      "Epoch: [357 | 1000] LR: 0.001174\n",
      "Train | 16/16 | Loss:0.2350 | MainLoss:0.1965 | Alpha:0.4531 | SPLoss:0.0000 | CLSLoss:0.0385 | top1:93.3600 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1934 | MainLoss:0.1934 | SPLoss:0.0000 | CLSLoss:0.0386 | top1:93.4872 | AUROC:0.9798\n",
      "Test | 123/16 | Loss:0.6658 | MainLoss:0.6658 | SPLoss:0.0000 | CLSLoss:0.0386 | top1:69.4987 | AUROC:0.8300\n",
      "\n",
      "Epoch: [358 | 1000] LR: 0.001172\n",
      "Train | 16/16 | Loss:0.2378 | MainLoss:0.1993 | Alpha:0.4540 | SPLoss:0.0000 | CLSLoss:0.0385 | top1:93.1733 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1963 | MainLoss:0.1963 | SPLoss:0.0000 | CLSLoss:0.0386 | top1:93.2821 | AUROC:0.9799\n",
      "Test | 123/16 | Loss:0.6465 | MainLoss:0.6465 | SPLoss:0.0000 | CLSLoss:0.0386 | top1:69.9672 | AUROC:0.8335\n",
      "\n",
      "Epoch: [359 | 1000] LR: 0.001170\n",
      "Train | 16/16 | Loss:0.2382 | MainLoss:0.1998 | Alpha:0.4523 | SPLoss:0.0000 | CLSLoss:0.0385 | top1:93.2267 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1934 | MainLoss:0.1934 | SPLoss:0.0000 | CLSLoss:0.0386 | top1:93.4359 | AUROC:0.9800\n",
      "Test | 123/16 | Loss:0.6582 | MainLoss:0.6582 | SPLoss:0.0000 | CLSLoss:0.0386 | top1:69.4102 | AUROC:0.8351\n",
      "\n",
      "Epoch: [360 | 1000] LR: 0.001168\n",
      "Train | 16/16 | Loss:0.2358 | MainLoss:0.1972 | Alpha:0.4537 | SPLoss:0.0000 | CLSLoss:0.0386 | top1:93.0133 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1943 | MainLoss:0.1943 | SPLoss:0.0000 | CLSLoss:0.0386 | top1:93.3590 | AUROC:0.9805\n",
      "Test | 123/16 | Loss:0.6515 | MainLoss:0.6515 | SPLoss:0.0000 | CLSLoss:0.0386 | top1:69.6330 | AUROC:0.8341\n",
      "\n",
      "Epoch: [361 | 1000] LR: 0.001165\n",
      "Train | 16/16 | Loss:0.2433 | MainLoss:0.2048 | Alpha:0.4522 | SPLoss:0.0000 | CLSLoss:0.0385 | top1:92.8800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1922 | MainLoss:0.1922 | SPLoss:0.0000 | CLSLoss:0.0385 | top1:93.5000 | AUROC:0.9802\n",
      "Test | 123/16 | Loss:0.6702 | MainLoss:0.6702 | SPLoss:0.0000 | CLSLoss:0.0385 | top1:69.0072 | AUROC:0.8323\n",
      "\n",
      "Epoch: [362 | 1000] LR: 0.001163\n",
      "Train | 16/16 | Loss:0.2490 | MainLoss:0.2106 | Alpha:0.4524 | SPLoss:0.0000 | CLSLoss:0.0384 | top1:92.5600 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1927 | MainLoss:0.1927 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:93.4615 | AUROC:0.9810\n",
      "Test | 123/16 | Loss:0.6540 | MainLoss:0.6540 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:69.2661 | AUROC:0.8349\n",
      "\n",
      "Epoch: [363 | 1000] LR: 0.001161\n",
      "Train | 16/16 | Loss:0.2459 | MainLoss:0.2076 | Alpha:0.4522 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:92.8800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1922 | MainLoss:0.1922 | SPLoss:0.0000 | CLSLoss:0.0382 | top1:93.4103 | AUROC:0.9805\n",
      "Test | 123/16 | Loss:0.6629 | MainLoss:0.6629 | SPLoss:0.0000 | CLSLoss:0.0382 | top1:69.1547 | AUROC:0.8318\n",
      "\n",
      "Epoch: [364 | 1000] LR: 0.001159\n",
      "Train | 16/16 | Loss:0.2297 | MainLoss:0.1914 | Alpha:0.4560 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:93.3600 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1915 | MainLoss:0.1915 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:93.5385 | AUROC:0.9802\n",
      "Test | 123/16 | Loss:0.6829 | MainLoss:0.6829 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:68.7451 | AUROC:0.8260\n",
      "\n",
      "Epoch: [365 | 1000] LR: 0.001156\n",
      "Train | 16/16 | Loss:0.2311 | MainLoss:0.1927 | Alpha:0.4550 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:93.9733 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1934 | MainLoss:0.1934 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:93.4231 | AUROC:0.9805\n",
      "Test | 123/16 | Loss:0.6629 | MainLoss:0.6629 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:69.4692 | AUROC:0.8323\n",
      "\n",
      "Epoch: [366 | 1000] LR: 0.001154\n",
      "Train | 16/16 | Loss:0.2232 | MainLoss:0.1848 | Alpha:0.4559 | SPLoss:0.0000 | CLSLoss:0.0384 | top1:93.7067 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1939 | MainLoss:0.1939 | SPLoss:0.0000 | CLSLoss:0.0384 | top1:93.3974 | AUROC:0.9806\n",
      "Test | 123/16 | Loss:0.6619 | MainLoss:0.6619 | SPLoss:0.0000 | CLSLoss:0.0384 | top1:69.4495 | AUROC:0.8344\n",
      "\n",
      "Epoch: [367 | 1000] LR: 0.001152\n",
      "Train | 16/16 | Loss:0.2417 | MainLoss:0.2033 | Alpha:0.4518 | SPLoss:0.0000 | CLSLoss:0.0384 | top1:92.8533 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1947 | MainLoss:0.1947 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:93.4231 | AUROC:0.9812\n",
      "Test | 123/16 | Loss:0.6485 | MainLoss:0.6485 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:69.7608 | AUROC:0.8372\n",
      "\n",
      "Epoch: [368 | 1000] LR: 0.001150\n",
      "Train | 16/16 | Loss:0.2281 | MainLoss:0.1897 | Alpha:0.4554 | SPLoss:0.0000 | CLSLoss:0.0384 | top1:93.7333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1964 | MainLoss:0.1964 | SPLoss:0.0000 | CLSLoss:0.0384 | top1:93.3974 | AUROC:0.9806\n",
      "Test | 123/16 | Loss:0.6509 | MainLoss:0.6509 | SPLoss:0.0000 | CLSLoss:0.0384 | top1:70.0983 | AUROC:0.8323\n",
      "\n",
      "Epoch: [369 | 1000] LR: 0.001147\n",
      "Train | 16/16 | Loss:0.2297 | MainLoss:0.1912 | Alpha:0.4549 | SPLoss:0.0000 | CLSLoss:0.0384 | top1:93.2533 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1909 | MainLoss:0.1909 | SPLoss:0.0000 | CLSLoss:0.0384 | top1:93.4872 | AUROC:0.9807\n",
      "Test | 123/16 | Loss:0.6727 | MainLoss:0.6727 | SPLoss:0.0000 | CLSLoss:0.0384 | top1:69.0400 | AUROC:0.8334\n",
      "\n",
      "Epoch: [370 | 1000] LR: 0.001145\n",
      "Train | 16/16 | Loss:0.2327 | MainLoss:0.1943 | Alpha:0.4547 | SPLoss:0.0000 | CLSLoss:0.0384 | top1:93.1467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1924 | MainLoss:0.1924 | SPLoss:0.0000 | CLSLoss:0.0385 | top1:93.3974 | AUROC:0.9805\n",
      "Test | 123/16 | Loss:0.6576 | MainLoss:0.6576 | SPLoss:0.0000 | CLSLoss:0.0385 | top1:69.2464 | AUROC:0.8362\n",
      "\n",
      "Epoch: [371 | 1000] LR: 0.001143\n",
      "Train | 16/16 | Loss:0.2500 | MainLoss:0.2115 | Alpha:0.4512 | SPLoss:0.0000 | CLSLoss:0.0384 | top1:92.7200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1903 | MainLoss:0.1903 | SPLoss:0.0000 | CLSLoss:0.0382 | top1:93.5128 | AUROC:0.9816\n",
      "Test | 123/16 | Loss:0.6525 | MainLoss:0.6525 | SPLoss:0.0000 | CLSLoss:0.0382 | top1:68.8303 | AUROC:0.8402\n",
      "\n",
      "Epoch: [372 | 1000] LR: 0.001141\n",
      "Train | 16/16 | Loss:0.2315 | MainLoss:0.1932 | Alpha:0.4549 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:93.4133 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1932 | MainLoss:0.1932 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:93.4872 | AUROC:0.9811\n",
      "Test | 123/16 | Loss:0.6478 | MainLoss:0.6478 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:69.5020 | AUROC:0.8346\n",
      "\n",
      "Epoch: [373 | 1000] LR: 0.001138\n",
      "Train | 16/16 | Loss:0.2396 | MainLoss:0.2014 | Alpha:0.4532 | SPLoss:0.0000 | CLSLoss:0.0382 | top1:92.4000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1911 | MainLoss:0.1911 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:93.4103 | AUROC:0.9804\n",
      "Test | 123/16 | Loss:0.6748 | MainLoss:0.6748 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:69.1350 | AUROC:0.8234\n",
      "\n",
      "Epoch: [374 | 1000] LR: 0.001136\n",
      "Train | 16/16 | Loss:0.2377 | MainLoss:0.1994 | Alpha:0.4545 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:93.3333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1914 | MainLoss:0.1914 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:93.4103 | AUROC:0.9809\n",
      "Test | 123/16 | Loss:0.6696 | MainLoss:0.6696 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:69.3807 | AUROC:0.8266\n",
      "\n",
      "Epoch: [375 | 1000] LR: 0.001134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 16/16 | Loss:0.2331 | MainLoss:0.1948 | Alpha:0.4528 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:93.0133 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1904 | MainLoss:0.1904 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:93.4615 | AUROC:0.9813\n",
      "Test | 123/16 | Loss:0.6574 | MainLoss:0.6574 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:69.3021 | AUROC:0.8330\n",
      "\n",
      "Epoch: [376 | 1000] LR: 0.001132\n",
      "Train | 16/16 | Loss:0.2215 | MainLoss:0.1830 | Alpha:0.4570 | SPLoss:0.0000 | CLSLoss:0.0385 | top1:94.0800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1916 | MainLoss:0.1916 | SPLoss:0.0000 | CLSLoss:0.0385 | top1:93.4487 | AUROC:0.9811\n",
      "Test | 123/16 | Loss:0.6656 | MainLoss:0.6656 | SPLoss:0.0000 | CLSLoss:0.0385 | top1:69.5347 | AUROC:0.8329\n",
      "\n",
      "Epoch: [377 | 1000] LR: 0.001129\n",
      "Train | 16/16 | Loss:0.2208 | MainLoss:0.1822 | Alpha:0.4568 | SPLoss:0.0000 | CLSLoss:0.0386 | top1:94.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1931 | MainLoss:0.1931 | SPLoss:0.0000 | CLSLoss:0.0387 | top1:93.4872 | AUROC:0.9807\n",
      "Test | 123/16 | Loss:0.6702 | MainLoss:0.6702 | SPLoss:0.0000 | CLSLoss:0.0387 | top1:69.8067 | AUROC:0.8271\n",
      "\n",
      "Epoch: [378 | 1000] LR: 0.001127\n",
      "Train | 16/16 | Loss:0.2317 | MainLoss:0.1930 | Alpha:0.4546 | SPLoss:0.0000 | CLSLoss:0.0387 | top1:93.7333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1882 | MainLoss:0.1882 | SPLoss:0.0000 | CLSLoss:0.0386 | top1:93.6667 | AUROC:0.9815\n",
      "Test | 123/16 | Loss:0.6961 | MainLoss:0.6961 | SPLoss:0.0000 | CLSLoss:0.0386 | top1:68.4338 | AUROC:0.8349\n",
      "\n",
      "Epoch: [379 | 1000] LR: 0.001125\n",
      "Train | 16/16 | Loss:0.2324 | MainLoss:0.1937 | Alpha:0.4544 | SPLoss:0.0000 | CLSLoss:0.0387 | top1:93.4400 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1914 | MainLoss:0.1914 | SPLoss:0.0000 | CLSLoss:0.0386 | top1:93.5385 | AUROC:0.9811\n",
      "Test | 123/16 | Loss:0.6652 | MainLoss:0.6652 | SPLoss:0.0000 | CLSLoss:0.0386 | top1:69.2464 | AUROC:0.8352\n",
      "\n",
      "Epoch: [380 | 1000] LR: 0.001122\n",
      "Train | 16/16 | Loss:0.2295 | MainLoss:0.1909 | Alpha:0.4548 | SPLoss:0.0000 | CLSLoss:0.0386 | top1:93.5467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1884 | MainLoss:0.1884 | SPLoss:0.0000 | CLSLoss:0.0386 | top1:93.6282 | AUROC:0.9807\n",
      "Test | 123/16 | Loss:0.7052 | MainLoss:0.7052 | SPLoss:0.0000 | CLSLoss:0.0386 | top1:68.4305 | AUROC:0.8271\n",
      "\n",
      "Epoch: [381 | 1000] LR: 0.001120\n",
      "Train | 16/16 | Loss:0.2241 | MainLoss:0.1855 | Alpha:0.4563 | SPLoss:0.0000 | CLSLoss:0.0386 | top1:94.1067 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1903 | MainLoss:0.1903 | SPLoss:0.0000 | CLSLoss:0.0386 | top1:93.4872 | AUROC:0.9810\n",
      "Test | 123/16 | Loss:0.6799 | MainLoss:0.6799 | SPLoss:0.0000 | CLSLoss:0.0386 | top1:69.1022 | AUROC:0.8338\n",
      "\n",
      "Epoch: [382 | 1000] LR: 0.001118\n",
      "Train | 16/16 | Loss:0.2321 | MainLoss:0.1935 | Alpha:0.4541 | SPLoss:0.0000 | CLSLoss:0.0386 | top1:93.0933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1886 | MainLoss:0.1886 | SPLoss:0.0000 | CLSLoss:0.0386 | top1:93.4872 | AUROC:0.9815\n",
      "Test | 123/16 | Loss:0.6785 | MainLoss:0.6785 | SPLoss:0.0000 | CLSLoss:0.0386 | top1:68.8401 | AUROC:0.8341\n",
      "\n",
      "Epoch: [383 | 1000] LR: 0.001115\n",
      "Train | 16/16 | Loss:0.2249 | MainLoss:0.1863 | Alpha:0.4568 | SPLoss:0.0000 | CLSLoss:0.0387 | top1:94.0800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1914 | MainLoss:0.1914 | SPLoss:0.0000 | CLSLoss:0.0387 | top1:93.4872 | AUROC:0.9802\n",
      "Test | 123/16 | Loss:0.6871 | MainLoss:0.6871 | SPLoss:0.0000 | CLSLoss:0.0387 | top1:69.4397 | AUROC:0.8237\n",
      "\n",
      "Epoch: [384 | 1000] LR: 0.001113\n",
      "Train | 16/16 | Loss:0.2186 | MainLoss:0.1799 | Alpha:0.4576 | SPLoss:0.0000 | CLSLoss:0.0387 | top1:93.9467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1907 | MainLoss:0.1907 | SPLoss:0.0000 | CLSLoss:0.0387 | top1:93.5128 | AUROC:0.9811\n",
      "Test | 123/16 | Loss:0.6774 | MainLoss:0.6774 | SPLoss:0.0000 | CLSLoss:0.0387 | top1:69.2955 | AUROC:0.8334\n",
      "\n",
      "Epoch: [385 | 1000] LR: 0.001111\n",
      "Train | 16/16 | Loss:0.2477 | MainLoss:0.2090 | Alpha:0.4507 | SPLoss:0.0000 | CLSLoss:0.0386 | top1:92.4800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1889 | MainLoss:0.1889 | SPLoss:0.0000 | CLSLoss:0.0384 | top1:93.5000 | AUROC:0.9819\n",
      "Test | 123/16 | Loss:0.6533 | MainLoss:0.6533 | SPLoss:0.0000 | CLSLoss:0.0384 | top1:68.9450 | AUROC:0.8423\n",
      "\n",
      "Epoch: [386 | 1000] LR: 0.001108\n",
      "Train | 16/16 | Loss:0.2277 | MainLoss:0.1892 | Alpha:0.4548 | SPLoss:0.0000 | CLSLoss:0.0385 | top1:93.6800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1936 | MainLoss:0.1936 | SPLoss:0.0000 | CLSLoss:0.0385 | top1:93.5385 | AUROC:0.9813\n",
      "Test | 123/16 | Loss:0.6512 | MainLoss:0.6512 | SPLoss:0.0000 | CLSLoss:0.0385 | top1:69.9410 | AUROC:0.8347\n",
      "\n",
      "Epoch: [387 | 1000] LR: 0.001106\n",
      "Train | 16/16 | Loss:0.2301 | MainLoss:0.1916 | Alpha:0.4551 | SPLoss:0.0000 | CLSLoss:0.0385 | top1:93.6000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1887 | MainLoss:0.1887 | SPLoss:0.0000 | CLSLoss:0.0385 | top1:93.5128 | AUROC:0.9807\n",
      "Test | 123/16 | Loss:0.6921 | MainLoss:0.6921 | SPLoss:0.0000 | CLSLoss:0.0385 | top1:68.7615 | AUROC:0.8259\n",
      "\n",
      "Epoch: [388 | 1000] LR: 0.001104\n",
      "Train | 16/16 | Loss:0.2323 | MainLoss:0.1938 | Alpha:0.4540 | SPLoss:0.0000 | CLSLoss:0.0385 | top1:93.6000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1871 | MainLoss:0.1871 | SPLoss:0.0000 | CLSLoss:0.0385 | top1:93.7436 | AUROC:0.9812\n",
      "Test | 123/16 | Loss:0.7285 | MainLoss:0.7285 | SPLoss:0.0000 | CLSLoss:0.0385 | top1:67.6409 | AUROC:0.8274\n",
      "\n",
      "Epoch: [389 | 1000] LR: 0.001101\n",
      "Train | 16/16 | Loss:0.2183 | MainLoss:0.1798 | Alpha:0.4568 | SPLoss:0.0000 | CLSLoss:0.0385 | top1:94.0267 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1889 | MainLoss:0.1889 | SPLoss:0.0000 | CLSLoss:0.0386 | top1:93.5769 | AUROC:0.9802\n",
      "Test | 123/16 | Loss:0.7106 | MainLoss:0.7106 | SPLoss:0.0000 | CLSLoss:0.0386 | top1:68.7418 | AUROC:0.8222\n",
      "\n",
      "Epoch: [390 | 1000] LR: 0.001099\n",
      "Train | 16/16 | Loss:0.2359 | MainLoss:0.1975 | Alpha:0.4534 | SPLoss:0.0000 | CLSLoss:0.0384 | top1:93.3600 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1882 | MainLoss:0.1882 | SPLoss:0.0000 | CLSLoss:0.0384 | top1:93.6026 | AUROC:0.9809\n",
      "Test | 123/16 | Loss:0.6863 | MainLoss:0.6863 | SPLoss:0.0000 | CLSLoss:0.0384 | top1:68.8565 | AUROC:0.8352\n",
      "\n",
      "Epoch: [391 | 1000] LR: 0.001097\n",
      "Train | 16/16 | Loss:0.2321 | MainLoss:0.1938 | Alpha:0.4547 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:93.4667 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1871 | MainLoss:0.1871 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:93.6026 | AUROC:0.9821\n",
      "Test | 123/16 | Loss:0.6824 | MainLoss:0.6824 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:68.7877 | AUROC:0.8384\n",
      "\n",
      "Epoch: [392 | 1000] LR: 0.001094\n",
      "Train | 16/16 | Loss:0.2311 | MainLoss:0.1928 | Alpha:0.4547 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:93.4667 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1880 | MainLoss:0.1880 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:93.6282 | AUROC:0.9809\n",
      "Test | 123/16 | Loss:0.6798 | MainLoss:0.6798 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:69.2955 | AUROC:0.8302\n",
      "\n",
      "Epoch: [393 | 1000] LR: 0.001092\n",
      "Train | 16/16 | Loss:0.2246 | MainLoss:0.1864 | Alpha:0.4559 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:93.5200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1868 | MainLoss:0.1868 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:93.5641 | AUROC:0.9811\n",
      "Test | 123/16 | Loss:0.6954 | MainLoss:0.6954 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:68.8139 | AUROC:0.8273\n",
      "\n",
      "Epoch: [394 | 1000] LR: 0.001090\n",
      "Train | 16/16 | Loss:0.2230 | MainLoss:0.1847 | Alpha:0.4572 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:94.1867 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1872 | MainLoss:0.1872 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:93.6410 | AUROC:0.9816\n",
      "Test | 123/16 | Loss:0.6821 | MainLoss:0.6821 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:68.8860 | AUROC:0.8352\n",
      "\n",
      "Epoch: [395 | 1000] LR: 0.001087\n",
      "Train | 16/16 | Loss:0.2345 | MainLoss:0.1962 | Alpha:0.4547 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:92.9067 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1860 | MainLoss:0.1860 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:93.6538 | AUROC:0.9816\n",
      "Test | 123/16 | Loss:0.6788 | MainLoss:0.6788 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:68.6861 | AUROC:0.8371\n",
      "\n",
      "Epoch: [396 | 1000] LR: 0.001085\n",
      "Train | 16/16 | Loss:0.2295 | MainLoss:0.1912 | Alpha:0.4555 | SPLoss:0.0000 | CLSLoss:0.0384 | top1:93.6800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1863 | MainLoss:0.1863 | SPLoss:0.0000 | CLSLoss:0.0384 | top1:93.6154 | AUROC:0.9815\n",
      "Test | 123/16 | Loss:0.6741 | MainLoss:0.6741 | SPLoss:0.0000 | CLSLoss:0.0384 | top1:68.8565 | AUROC:0.8384\n",
      "\n",
      "Epoch: [397 | 1000] LR: 0.001083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 16/16 | Loss:0.2274 | MainLoss:0.1890 | Alpha:0.4564 | SPLoss:0.0000 | CLSLoss:0.0384 | top1:93.4133 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1883 | MainLoss:0.1883 | SPLoss:0.0000 | CLSLoss:0.0385 | top1:93.5769 | AUROC:0.9821\n",
      "Test | 123/16 | Loss:0.6496 | MainLoss:0.6496 | SPLoss:0.0000 | CLSLoss:0.0385 | top1:69.5937 | AUROC:0.8401\n",
      "\n",
      "Epoch: [398 | 1000] LR: 0.001080\n",
      "Train | 16/16 | Loss:0.2410 | MainLoss:0.2026 | Alpha:0.4527 | SPLoss:0.0000 | CLSLoss:0.0384 | top1:93.1733 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1878 | MainLoss:0.1878 | SPLoss:0.0000 | CLSLoss:0.0382 | top1:93.5769 | AUROC:0.9817\n",
      "Test | 123/16 | Loss:0.6721 | MainLoss:0.6721 | SPLoss:0.0000 | CLSLoss:0.0382 | top1:69.3447 | AUROC:0.8336\n",
      "\n",
      "Epoch: [399 | 1000] LR: 0.001078\n",
      "Train | 16/16 | Loss:0.2315 | MainLoss:0.1933 | Alpha:0.4551 | SPLoss:0.0000 | CLSLoss:0.0382 | top1:93.4400 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1874 | MainLoss:0.1874 | SPLoss:0.0000 | CLSLoss:0.0382 | top1:93.6667 | AUROC:0.9815\n",
      "Test | 123/16 | Loss:0.6806 | MainLoss:0.6806 | SPLoss:0.0000 | CLSLoss:0.0382 | top1:69.0760 | AUROC:0.8315\n",
      "\n",
      "Epoch: [400 | 1000] LR: 0.001076\n",
      "Train | 16/16 | Loss:0.2216 | MainLoss:0.1834 | Alpha:0.4576 | SPLoss:0.0000 | CLSLoss:0.0382 | top1:93.8133 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1880 | MainLoss:0.1880 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:93.5641 | AUROC:0.9818\n",
      "Test | 123/16 | Loss:0.6630 | MainLoss:0.6630 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:69.4430 | AUROC:0.8356\n",
      "\n",
      "Epoch: [401 | 1000] LR: 0.001073\n",
      "Train | 16/16 | Loss:0.2283 | MainLoss:0.1901 | Alpha:0.4551 | SPLoss:0.0000 | CLSLoss:0.0382 | top1:93.4400 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1862 | MainLoss:0.1862 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:93.6795 | AUROC:0.9819\n",
      "Test | 123/16 | Loss:0.6660 | MainLoss:0.6660 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:68.9679 | AUROC:0.8408\n",
      "\n",
      "Epoch: [402 | 1000] LR: 0.001071\n",
      "Train | 16/16 | Loss:0.2218 | MainLoss:0.1834 | Alpha:0.4576 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:94.1067 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1852 | MainLoss:0.1852 | SPLoss:0.0000 | CLSLoss:0.0384 | top1:93.7308 | AUROC:0.9818\n",
      "Test | 123/16 | Loss:0.6914 | MainLoss:0.6914 | SPLoss:0.0000 | CLSLoss:0.0384 | top1:68.6468 | AUROC:0.8350\n",
      "\n",
      "Epoch: [403 | 1000] LR: 0.001069\n",
      "Train | 16/16 | Loss:0.2162 | MainLoss:0.1777 | Alpha:0.4576 | SPLoss:0.0000 | CLSLoss:0.0385 | top1:94.0533 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1872 | MainLoss:0.1872 | SPLoss:0.0000 | CLSLoss:0.0385 | top1:93.6667 | AUROC:0.9812\n",
      "Test | 123/16 | Loss:0.6815 | MainLoss:0.6815 | SPLoss:0.0000 | CLSLoss:0.0385 | top1:69.1579 | AUROC:0.8305\n",
      "\n",
      "Epoch: [404 | 1000] LR: 0.001066\n",
      "Train | 16/16 | Loss:0.2298 | MainLoss:0.1913 | Alpha:0.4559 | SPLoss:0.0000 | CLSLoss:0.0385 | top1:93.2000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1859 | MainLoss:0.1859 | SPLoss:0.0000 | CLSLoss:0.0385 | top1:93.6795 | AUROC:0.9817\n",
      "Test | 123/16 | Loss:0.6920 | MainLoss:0.6920 | SPLoss:0.0000 | CLSLoss:0.0385 | top1:68.6206 | AUROC:0.8348\n",
      "\n",
      "Epoch: [405 | 1000] LR: 0.001064\n",
      "Train | 16/16 | Loss:0.2319 | MainLoss:0.1935 | Alpha:0.4553 | SPLoss:0.0000 | CLSLoss:0.0384 | top1:93.2267 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1879 | MainLoss:0.1879 | SPLoss:0.0000 | CLSLoss:0.0384 | top1:93.5897 | AUROC:0.9821\n",
      "Test | 123/16 | Loss:0.6627 | MainLoss:0.6627 | SPLoss:0.0000 | CLSLoss:0.0384 | top1:69.1252 | AUROC:0.8393\n",
      "\n",
      "Epoch: [406 | 1000] LR: 0.001062\n",
      "Train | 16/16 | Loss:0.2387 | MainLoss:0.2004 | Alpha:0.4525 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:92.7200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1859 | MainLoss:0.1859 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:93.6923 | AUROC:0.9823\n",
      "Test | 123/16 | Loss:0.6679 | MainLoss:0.6679 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:68.8762 | AUROC:0.8393\n",
      "\n",
      "Epoch: [407 | 1000] LR: 0.001059\n",
      "Train | 16/16 | Loss:0.2350 | MainLoss:0.1967 | Alpha:0.4543 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:92.9600 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1852 | MainLoss:0.1852 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:93.7179 | AUROC:0.9820\n",
      "Test | 123/16 | Loss:0.6841 | MainLoss:0.6841 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:68.4830 | AUROC:0.8350\n",
      "\n",
      "Epoch: [408 | 1000] LR: 0.001057\n",
      "Train | 16/16 | Loss:0.2261 | MainLoss:0.1878 | Alpha:0.4561 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:93.8400 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1869 | MainLoss:0.1869 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:93.5769 | AUROC:0.9818\n",
      "Test | 123/16 | Loss:0.6760 | MainLoss:0.6760 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:69.0400 | AUROC:0.8324\n",
      "\n",
      "Epoch: [409 | 1000] LR: 0.001054\n",
      "Train | 16/16 | Loss:0.2385 | MainLoss:0.2002 | Alpha:0.4534 | SPLoss:0.0000 | CLSLoss:0.0382 | top1:93.3067 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1870 | MainLoss:0.1870 | SPLoss:0.0000 | CLSLoss:0.0382 | top1:93.5641 | AUROC:0.9824\n",
      "Test | 123/16 | Loss:0.6515 | MainLoss:0.6515 | SPLoss:0.0000 | CLSLoss:0.0382 | top1:69.2136 | AUROC:0.8400\n",
      "\n",
      "Epoch: [410 | 1000] LR: 0.001052\n",
      "Train | 16/16 | Loss:0.2240 | MainLoss:0.1857 | Alpha:0.4566 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:93.4133 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1851 | MainLoss:0.1851 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:93.7564 | AUROC:0.9816\n",
      "Test | 123/16 | Loss:0.6894 | MainLoss:0.6894 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:68.7385 | AUROC:0.8270\n",
      "\n",
      "Epoch: [411 | 1000] LR: 0.001050\n",
      "Train | 16/16 | Loss:0.2275 | MainLoss:0.1892 | Alpha:0.4553 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:93.6533 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1864 | MainLoss:0.1864 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:93.6538 | AUROC:0.9820\n",
      "Test | 123/16 | Loss:0.6732 | MainLoss:0.6732 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:68.9155 | AUROC:0.8336\n",
      "\n",
      "Epoch: [412 | 1000] LR: 0.001047\n",
      "Train | 16/16 | Loss:0.2301 | MainLoss:0.1918 | Alpha:0.4545 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:93.5467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1860 | MainLoss:0.1860 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:93.6923 | AUROC:0.9815\n",
      "Test | 123/16 | Loss:0.6922 | MainLoss:0.6922 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:68.7353 | AUROC:0.8291\n",
      "\n",
      "Epoch: [413 | 1000] LR: 0.001045\n",
      "Train | 16/16 | Loss:0.2227 | MainLoss:0.1845 | Alpha:0.4567 | SPLoss:0.0000 | CLSLoss:0.0382 | top1:93.7600 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1866 | MainLoss:0.1866 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:93.6410 | AUROC:0.9811\n",
      "Test | 123/16 | Loss:0.6937 | MainLoss:0.6937 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:68.8630 | AUROC:0.8239\n",
      "\n",
      "Epoch: [414 | 1000] LR: 0.001042\n",
      "Train | 16/16 | Loss:0.2239 | MainLoss:0.1855 | Alpha:0.4563 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:93.7333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1842 | MainLoss:0.1842 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:93.8077 | AUROC:0.9822\n",
      "Test | 123/16 | Loss:0.6897 | MainLoss:0.6897 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:68.3093 | AUROC:0.8338\n",
      "\n",
      "Epoch: [415 | 1000] LR: 0.001040\n",
      "Train | 16/16 | Loss:0.2177 | MainLoss:0.1794 | Alpha:0.4588 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:94.0800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1865 | MainLoss:0.1865 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:93.6667 | AUROC:0.9821\n",
      "Test | 123/16 | Loss:0.6825 | MainLoss:0.6825 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:68.8368 | AUROC:0.8320\n",
      "\n",
      "Epoch: [416 | 1000] LR: 0.001038\n",
      "Train | 16/16 | Loss:0.2154 | MainLoss:0.1770 | Alpha:0.4584 | SPLoss:0.0000 | CLSLoss:0.0384 | top1:93.9200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1832 | MainLoss:0.1832 | SPLoss:0.0000 | CLSLoss:0.0384 | top1:93.7821 | AUROC:0.9816\n",
      "Test | 123/16 | Loss:0.7337 | MainLoss:0.7337 | SPLoss:0.0000 | CLSLoss:0.0384 | top1:67.3460 | AUROC:0.8247\n",
      "\n",
      "Epoch: [417 | 1000] LR: 0.001035\n",
      "Train | 16/16 | Loss:0.2213 | MainLoss:0.1829 | Alpha:0.4576 | SPLoss:0.0000 | CLSLoss:0.0384 | top1:94.4000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1838 | MainLoss:0.1838 | SPLoss:0.0000 | CLSLoss:0.0384 | top1:93.7821 | AUROC:0.9822\n",
      "Test | 123/16 | Loss:0.7088 | MainLoss:0.7088 | SPLoss:0.0000 | CLSLoss:0.0384 | top1:68.3290 | AUROC:0.8318\n",
      "\n",
      "Epoch: [418 | 1000] LR: 0.001033\n",
      "Train | 16/16 | Loss:0.2253 | MainLoss:0.1870 | Alpha:0.4565 | SPLoss:0.0000 | CLSLoss:0.0384 | top1:93.8667 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1844 | MainLoss:0.1844 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:93.7308 | AUROC:0.9826\n",
      "Test | 123/16 | Loss:0.6899 | MainLoss:0.6899 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:68.3748 | AUROC:0.8355\n",
      "\n",
      "Epoch: [419 | 1000] LR: 0.001030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 16/16 | Loss:0.2289 | MainLoss:0.1907 | Alpha:0.4554 | SPLoss:0.0000 | CLSLoss:0.0382 | top1:93.5467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1847 | MainLoss:0.1847 | SPLoss:0.0000 | CLSLoss:0.0382 | top1:93.7692 | AUROC:0.9815\n",
      "Test | 123/16 | Loss:0.7199 | MainLoss:0.7199 | SPLoss:0.0000 | CLSLoss:0.0382 | top1:68.3847 | AUROC:0.8186\n",
      "\n",
      "Epoch: [420 | 1000] LR: 0.001028\n",
      "Train | 16/16 | Loss:0.2262 | MainLoss:0.1880 | Alpha:0.4557 | SPLoss:0.0000 | CLSLoss:0.0382 | top1:93.3600 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1856 | MainLoss:0.1856 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:93.6795 | AUROC:0.9818\n",
      "Test | 123/16 | Loss:0.6922 | MainLoss:0.6922 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:68.8532 | AUROC:0.8264\n",
      "\n",
      "Epoch: [421 | 1000] LR: 0.001026\n",
      "Train | 16/16 | Loss:0.2181 | MainLoss:0.1798 | Alpha:0.4577 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:93.8933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1839 | MainLoss:0.1839 | SPLoss:0.0000 | CLSLoss:0.0384 | top1:93.7821 | AUROC:0.9812\n",
      "Test | 123/16 | Loss:0.7147 | MainLoss:0.7147 | SPLoss:0.0000 | CLSLoss:0.0384 | top1:68.3716 | AUROC:0.8232\n",
      "\n",
      "Epoch: [422 | 1000] LR: 0.001023\n",
      "Train | 16/16 | Loss:0.2430 | MainLoss:0.2048 | Alpha:0.4525 | SPLoss:0.0000 | CLSLoss:0.0382 | top1:92.6667 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1864 | MainLoss:0.1864 | SPLoss:0.0000 | CLSLoss:0.0381 | top1:93.7308 | AUROC:0.9827\n",
      "Test | 123/16 | Loss:0.6529 | MainLoss:0.6529 | SPLoss:0.0000 | CLSLoss:0.0381 | top1:69.1022 | AUROC:0.8394\n",
      "\n",
      "Epoch: [423 | 1000] LR: 0.001021\n",
      "Train | 16/16 | Loss:0.2240 | MainLoss:0.1859 | Alpha:0.4560 | SPLoss:0.0000 | CLSLoss:0.0381 | top1:93.5733 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1827 | MainLoss:0.1827 | SPLoss:0.0000 | CLSLoss:0.0382 | top1:93.7949 | AUROC:0.9819\n",
      "Test | 123/16 | Loss:0.7194 | MainLoss:0.7194 | SPLoss:0.0000 | CLSLoss:0.0382 | top1:67.8506 | AUROC:0.8219\n",
      "\n",
      "Epoch: [424 | 1000] LR: 0.001018\n",
      "Train | 16/16 | Loss:0.2187 | MainLoss:0.1805 | Alpha:0.4582 | SPLoss:0.0000 | CLSLoss:0.0382 | top1:94.1333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1840 | MainLoss:0.1840 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:93.8077 | AUROC:0.9812\n",
      "Test | 123/16 | Loss:0.7155 | MainLoss:0.7155 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:68.3879 | AUROC:0.8182\n",
      "\n",
      "Epoch: [425 | 1000] LR: 0.001016\n",
      "Train | 16/16 | Loss:0.2257 | MainLoss:0.1874 | Alpha:0.4556 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:93.7600 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1871 | MainLoss:0.1871 | SPLoss:0.0000 | CLSLoss:0.0382 | top1:93.6923 | AUROC:0.9821\n",
      "Test | 123/16 | Loss:0.6729 | MainLoss:0.6729 | SPLoss:0.0000 | CLSLoss:0.0382 | top1:69.3021 | AUROC:0.8366\n",
      "\n",
      "Epoch: [426 | 1000] LR: 0.001014\n",
      "Train | 16/16 | Loss:0.2251 | MainLoss:0.1868 | Alpha:0.4568 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:93.8133 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1857 | MainLoss:0.1857 | SPLoss:0.0000 | CLSLoss:0.0382 | top1:93.7436 | AUROC:0.9820\n",
      "Test | 123/16 | Loss:0.6785 | MainLoss:0.6785 | SPLoss:0.0000 | CLSLoss:0.0382 | top1:69.0793 | AUROC:0.8353\n",
      "\n",
      "Epoch: [427 | 1000] LR: 0.001011\n",
      "Train | 16/16 | Loss:0.2136 | MainLoss:0.1753 | Alpha:0.4592 | SPLoss:0.0000 | CLSLoss:0.0382 | top1:94.1333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1835 | MainLoss:0.1835 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:93.8205 | AUROC:0.9821\n",
      "Test | 123/16 | Loss:0.7082 | MainLoss:0.7082 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:68.4404 | AUROC:0.8270\n",
      "\n",
      "Epoch: [428 | 1000] LR: 0.001009\n",
      "Train | 16/16 | Loss:0.2413 | MainLoss:0.2031 | Alpha:0.4523 | SPLoss:0.0000 | CLSLoss:0.0382 | top1:93.0667 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1845 | MainLoss:0.1845 | SPLoss:0.0000 | CLSLoss:0.0381 | top1:93.7821 | AUROC:0.9831\n",
      "Test | 123/16 | Loss:0.6551 | MainLoss:0.6551 | SPLoss:0.0000 | CLSLoss:0.0381 | top1:68.7942 | AUROC:0.8387\n",
      "\n",
      "Epoch: [429 | 1000] LR: 0.001006\n",
      "Train | 16/16 | Loss:0.2306 | MainLoss:0.1925 | Alpha:0.4550 | SPLoss:0.0000 | CLSLoss:0.0381 | top1:93.5200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1834 | MainLoss:0.1834 | SPLoss:0.0000 | CLSLoss:0.0381 | top1:93.8333 | AUROC:0.9827\n",
      "Test | 123/16 | Loss:0.6782 | MainLoss:0.6782 | SPLoss:0.0000 | CLSLoss:0.0381 | top1:68.5518 | AUROC:0.8343\n",
      "\n",
      "Epoch: [430 | 1000] LR: 0.001004\n",
      "Train | 16/16 | Loss:0.2246 | MainLoss:0.1864 | Alpha:0.4567 | SPLoss:0.0000 | CLSLoss:0.0382 | top1:93.6800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1852 | MainLoss:0.1852 | SPLoss:0.0000 | CLSLoss:0.0382 | top1:93.7564 | AUROC:0.9826\n",
      "Test | 123/16 | Loss:0.6612 | MainLoss:0.6612 | SPLoss:0.0000 | CLSLoss:0.0382 | top1:68.9122 | AUROC:0.8363\n",
      "\n",
      "Epoch: [431 | 1000] LR: 0.001001\n",
      "Train | 16/16 | Loss:0.2224 | MainLoss:0.1842 | Alpha:0.4573 | SPLoss:0.0000 | CLSLoss:0.0382 | top1:94.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1835 | MainLoss:0.1835 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:93.7949 | AUROC:0.9816\n",
      "Test | 123/16 | Loss:0.6993 | MainLoss:0.6993 | SPLoss:0.0000 | CLSLoss:0.0383 | top1:68.5583 | AUROC:0.8236\n",
      "\n",
      "Epoch: [432 | 1000] LR: 0.000999\n",
      "Train | 16/16 | Loss:0.2252 | MainLoss:0.1869 | Alpha:0.4573 | SPLoss:0.0000 | CLSLoss:0.0382 | top1:93.4933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1853 | MainLoss:0.1853 | SPLoss:0.0000 | CLSLoss:0.0382 | top1:93.7436 | AUROC:0.9818\n",
      "Test | 123/16 | Loss:0.6790 | MainLoss:0.6790 | SPLoss:0.0000 | CLSLoss:0.0382 | top1:69.0269 | AUROC:0.8280\n",
      "\n",
      "Epoch: [433 | 1000] LR: 0.000997\n",
      "Train | 16/16 | Loss:0.2306 | MainLoss:0.1924 | Alpha:0.4547 | SPLoss:0.0000 | CLSLoss:0.0382 | top1:93.4400 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1828 | MainLoss:0.1828 | SPLoss:0.0000 | CLSLoss:0.0382 | top1:93.8077 | AUROC:0.9821\n",
      "Test | 123/16 | Loss:0.6943 | MainLoss:0.6943 | SPLoss:0.0000 | CLSLoss:0.0382 | top1:68.5190 | AUROC:0.8269\n",
      "\n",
      "Epoch: [434 | 1000] LR: 0.000994\n",
      "Train | 16/16 | Loss:0.2255 | MainLoss:0.1874 | Alpha:0.4568 | SPLoss:0.0000 | CLSLoss:0.0382 | top1:93.7867 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1825 | MainLoss:0.1825 | SPLoss:0.0000 | CLSLoss:0.0381 | top1:93.7821 | AUROC:0.9828\n",
      "Test | 123/16 | Loss:0.6908 | MainLoss:0.6908 | SPLoss:0.0000 | CLSLoss:0.0381 | top1:68.2733 | AUROC:0.8340\n",
      "\n",
      "Epoch: [435 | 1000] LR: 0.000992\n",
      "Train | 16/16 | Loss:0.2239 | MainLoss:0.1857 | Alpha:0.4567 | SPLoss:0.0000 | CLSLoss:0.0381 | top1:93.9733 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1846 | MainLoss:0.1846 | SPLoss:0.0000 | CLSLoss:0.0381 | top1:93.7821 | AUROC:0.9827\n",
      "Test | 123/16 | Loss:0.6762 | MainLoss:0.6762 | SPLoss:0.0000 | CLSLoss:0.0381 | top1:68.8303 | AUROC:0.8332\n",
      "\n",
      "Epoch: [436 | 1000] LR: 0.000989\n",
      "Train | 16/16 | Loss:0.2304 | MainLoss:0.1923 | Alpha:0.4546 | SPLoss:0.0000 | CLSLoss:0.0381 | top1:93.2267 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1818 | MainLoss:0.1818 | SPLoss:0.0000 | CLSLoss:0.0381 | top1:93.8590 | AUROC:0.9827\n",
      "Test | 123/16 | Loss:0.6919 | MainLoss:0.6919 | SPLoss:0.0000 | CLSLoss:0.0381 | top1:68.1750 | AUROC:0.8338\n",
      "\n",
      "Epoch: [437 | 1000] LR: 0.000987\n",
      "Train | 16/16 | Loss:0.2420 | MainLoss:0.2039 | Alpha:0.4523 | SPLoss:0.0000 | CLSLoss:0.0381 | top1:93.0933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1836 | MainLoss:0.1836 | SPLoss:0.0000 | CLSLoss:0.0379 | top1:93.7821 | AUROC:0.9828\n",
      "Test | 123/16 | Loss:0.6689 | MainLoss:0.6689 | SPLoss:0.0000 | CLSLoss:0.0379 | top1:68.5944 | AUROC:0.8373\n",
      "\n",
      "Epoch: [438 | 1000] LR: 0.000984\n",
      "Train | 16/16 | Loss:0.2330 | MainLoss:0.1951 | Alpha:0.4542 | SPLoss:0.0000 | CLSLoss:0.0379 | top1:93.6000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1814 | MainLoss:0.1814 | SPLoss:0.0000 | CLSLoss:0.0379 | top1:93.8077 | AUROC:0.9827\n",
      "Test | 123/16 | Loss:0.6973 | MainLoss:0.6973 | SPLoss:0.0000 | CLSLoss:0.0379 | top1:67.9784 | AUROC:0.8315\n",
      "\n",
      "Epoch: [439 | 1000] LR: 0.000982\n",
      "Train | 16/16 | Loss:0.2316 | MainLoss:0.1938 | Alpha:0.4555 | SPLoss:0.0000 | CLSLoss:0.0378 | top1:93.1467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1821 | MainLoss:0.1821 | SPLoss:0.0000 | CLSLoss:0.0379 | top1:93.8462 | AUROC:0.9831\n",
      "Test | 123/16 | Loss:0.6821 | MainLoss:0.6821 | SPLoss:0.0000 | CLSLoss:0.0379 | top1:68.2896 | AUROC:0.8333\n",
      "\n",
      "Epoch: [440 | 1000] LR: 0.000979\n",
      "Train | 16/16 | Loss:0.2321 | MainLoss:0.1943 | Alpha:0.4543 | SPLoss:0.0000 | CLSLoss:0.0378 | top1:93.1733 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1829 | MainLoss:0.1829 | SPLoss:0.0000 | CLSLoss:0.0378 | top1:93.7949 | AUROC:0.9828\n",
      "Test | 123/16 | Loss:0.6822 | MainLoss:0.6822 | SPLoss:0.0000 | CLSLoss:0.0378 | top1:68.3879 | AUROC:0.8298\n",
      "\n",
      "Epoch: [441 | 1000] LR: 0.000977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 16/16 | Loss:0.2101 | MainLoss:0.1722 | Alpha:0.4598 | SPLoss:0.0000 | CLSLoss:0.0379 | top1:94.8800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1812 | MainLoss:0.1812 | SPLoss:0.0000 | CLSLoss:0.0380 | top1:93.8333 | AUROC:0.9816\n",
      "Test | 123/16 | Loss:0.7313 | MainLoss:0.7313 | SPLoss:0.0000 | CLSLoss:0.0380 | top1:67.5131 | AUROC:0.8131\n",
      "\n",
      "Epoch: [442 | 1000] LR: 0.000975\n",
      "Train | 16/16 | Loss:0.2237 | MainLoss:0.1857 | Alpha:0.4561 | SPLoss:0.0000 | CLSLoss:0.0380 | top1:93.5467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1808 | MainLoss:0.1808 | SPLoss:0.0000 | CLSLoss:0.0380 | top1:93.7949 | AUROC:0.9829\n",
      "Test | 123/16 | Loss:0.7061 | MainLoss:0.7061 | SPLoss:0.0000 | CLSLoss:0.0380 | top1:67.7163 | AUROC:0.8320\n",
      "\n",
      "Epoch: [443 | 1000] LR: 0.000972\n",
      "Train | 16/16 | Loss:0.2384 | MainLoss:0.2005 | Alpha:0.4532 | SPLoss:0.0000 | CLSLoss:0.0379 | top1:92.9067 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1826 | MainLoss:0.1826 | SPLoss:0.0000 | CLSLoss:0.0378 | top1:93.8333 | AUROC:0.9833\n",
      "Test | 123/16 | Loss:0.6753 | MainLoss:0.6753 | SPLoss:0.0000 | CLSLoss:0.0378 | top1:68.2569 | AUROC:0.8357\n",
      "\n",
      "Epoch: [444 | 1000] LR: 0.000970\n",
      "Train | 16/16 | Loss:0.2162 | MainLoss:0.1784 | Alpha:0.4586 | SPLoss:0.0000 | CLSLoss:0.0378 | top1:94.2133 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1816 | MainLoss:0.1816 | SPLoss:0.0000 | CLSLoss:0.0379 | top1:93.8462 | AUROC:0.9820\n",
      "Test | 123/16 | Loss:0.7094 | MainLoss:0.7094 | SPLoss:0.0000 | CLSLoss:0.0379 | top1:68.1029 | AUROC:0.8245\n",
      "\n",
      "Epoch: [445 | 1000] LR: 0.000967\n",
      "Train | 16/16 | Loss:0.2277 | MainLoss:0.1899 | Alpha:0.4554 | SPLoss:0.0000 | CLSLoss:0.0379 | top1:93.7333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1808 | MainLoss:0.1808 | SPLoss:0.0000 | CLSLoss:0.0378 | top1:93.8333 | AUROC:0.9828\n",
      "Test | 123/16 | Loss:0.7063 | MainLoss:0.7063 | SPLoss:0.0000 | CLSLoss:0.0378 | top1:67.7752 | AUROC:0.8309\n",
      "\n",
      "Epoch: [446 | 1000] LR: 0.000965\n",
      "Train | 16/16 | Loss:0.2284 | MainLoss:0.1906 | Alpha:0.4554 | SPLoss:0.0000 | CLSLoss:0.0378 | top1:93.3867 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1807 | MainLoss:0.1807 | SPLoss:0.0000 | CLSLoss:0.0378 | top1:93.7949 | AUROC:0.9831\n",
      "Test | 123/16 | Loss:0.7068 | MainLoss:0.7068 | SPLoss:0.0000 | CLSLoss:0.0378 | top1:67.7326 | AUROC:0.8271\n",
      "\n",
      "Epoch: [447 | 1000] LR: 0.000962\n",
      "Train | 16/16 | Loss:0.2101 | MainLoss:0.1722 | Alpha:0.4596 | SPLoss:0.0000 | CLSLoss:0.0379 | top1:94.5333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1834 | MainLoss:0.1834 | SPLoss:0.0000 | CLSLoss:0.0379 | top1:93.8590 | AUROC:0.9815\n",
      "Test | 123/16 | Loss:0.7134 | MainLoss:0.7134 | SPLoss:0.0000 | CLSLoss:0.0379 | top1:68.4174 | AUROC:0.8153\n",
      "\n",
      "Epoch: [448 | 1000] LR: 0.000960\n",
      "Train | 16/16 | Loss:0.2220 | MainLoss:0.1841 | Alpha:0.4569 | SPLoss:0.0000 | CLSLoss:0.0379 | top1:93.6800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1816 | MainLoss:0.1816 | SPLoss:0.0000 | CLSLoss:0.0379 | top1:93.8462 | AUROC:0.9821\n",
      "Test | 123/16 | Loss:0.7145 | MainLoss:0.7145 | SPLoss:0.0000 | CLSLoss:0.0379 | top1:68.0406 | AUROC:0.8218\n",
      "\n",
      "Epoch: [449 | 1000] LR: 0.000957\n",
      "Train | 16/16 | Loss:0.2343 | MainLoss:0.1964 | Alpha:0.4544 | SPLoss:0.0000 | CLSLoss:0.0379 | top1:93.3867 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1797 | MainLoss:0.1797 | SPLoss:0.0000 | CLSLoss:0.0377 | top1:93.8974 | AUROC:0.9834\n",
      "Test | 123/16 | Loss:0.7085 | MainLoss:0.7085 | SPLoss:0.0000 | CLSLoss:0.0377 | top1:67.2903 | AUROC:0.8331\n",
      "\n",
      "Epoch: [450 | 1000] LR: 0.000955\n",
      "Train | 16/16 | Loss:0.2114 | MainLoss:0.1735 | Alpha:0.4594 | SPLoss:0.0000 | CLSLoss:0.0379 | top1:94.3467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1845 | MainLoss:0.1845 | SPLoss:0.0000 | CLSLoss:0.0379 | top1:93.7692 | AUROC:0.9826\n",
      "Test | 123/16 | Loss:0.6800 | MainLoss:0.6800 | SPLoss:0.0000 | CLSLoss:0.0379 | top1:68.9187 | AUROC:0.8284\n",
      "\n",
      "Epoch: [451 | 1000] LR: 0.000952\n",
      "Train | 16/16 | Loss:0.2259 | MainLoss:0.1880 | Alpha:0.4553 | SPLoss:0.0000 | CLSLoss:0.0379 | top1:93.7600 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1818 | MainLoss:0.1818 | SPLoss:0.0000 | CLSLoss:0.0379 | top1:93.8462 | AUROC:0.9829\n",
      "Test | 123/16 | Loss:0.6932 | MainLoss:0.6932 | SPLoss:0.0000 | CLSLoss:0.0379 | top1:68.4305 | AUROC:0.8301\n",
      "\n",
      "Epoch: [452 | 1000] LR: 0.000950\n",
      "Train | 16/16 | Loss:0.2291 | MainLoss:0.1912 | Alpha:0.4557 | SPLoss:0.0000 | CLSLoss:0.0379 | top1:93.6533 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1832 | MainLoss:0.1832 | SPLoss:0.0000 | CLSLoss:0.0378 | top1:93.8974 | AUROC:0.9831\n",
      "Test | 123/16 | Loss:0.6652 | MainLoss:0.6652 | SPLoss:0.0000 | CLSLoss:0.0378 | top1:68.6632 | AUROC:0.8371\n",
      "\n",
      "Epoch: [453 | 1000] LR: 0.000947\n",
      "Train | 16/16 | Loss:0.2158 | MainLoss:0.1779 | Alpha:0.4580 | SPLoss:0.0000 | CLSLoss:0.0379 | top1:94.4533 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1803 | MainLoss:0.1803 | SPLoss:0.0000 | CLSLoss:0.0379 | top1:93.9103 | AUROC:0.9822\n",
      "Test | 123/16 | Loss:0.7299 | MainLoss:0.7299 | SPLoss:0.0000 | CLSLoss:0.0379 | top1:67.6769 | AUROC:0.8196\n",
      "\n",
      "Epoch: [454 | 1000] LR: 0.000945\n",
      "Train | 16/16 | Loss:0.2196 | MainLoss:0.1817 | Alpha:0.4576 | SPLoss:0.0000 | CLSLoss:0.0379 | top1:93.7867 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1846 | MainLoss:0.1846 | SPLoss:0.0000 | CLSLoss:0.0379 | top1:93.7949 | AUROC:0.9821\n",
      "Test | 123/16 | Loss:0.6884 | MainLoss:0.6884 | SPLoss:0.0000 | CLSLoss:0.0379 | top1:69.0302 | AUROC:0.8258\n",
      "\n",
      "Epoch: [455 | 1000] LR: 0.000942\n",
      "Train | 16/16 | Loss:0.2373 | MainLoss:0.1995 | Alpha:0.4537 | SPLoss:0.0000 | CLSLoss:0.0377 | top1:92.8800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1805 | MainLoss:0.1805 | SPLoss:0.0000 | CLSLoss:0.0377 | top1:93.8974 | AUROC:0.9831\n",
      "Test | 123/16 | Loss:0.7027 | MainLoss:0.7027 | SPLoss:0.0000 | CLSLoss:0.0377 | top1:68.0734 | AUROC:0.8301\n",
      "\n",
      "Epoch: [456 | 1000] LR: 0.000940\n",
      "Train | 16/16 | Loss:0.2130 | MainLoss:0.1752 | Alpha:0.4591 | SPLoss:0.0000 | CLSLoss:0.0378 | top1:94.2133 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1807 | MainLoss:0.1807 | SPLoss:0.0000 | CLSLoss:0.0378 | top1:93.8718 | AUROC:0.9824\n",
      "Test | 123/16 | Loss:0.7024 | MainLoss:0.7024 | SPLoss:0.0000 | CLSLoss:0.0378 | top1:68.3191 | AUROC:0.8263\n",
      "\n",
      "Epoch: [457 | 1000] LR: 0.000938\n",
      "Train | 16/16 | Loss:0.2246 | MainLoss:0.1868 | Alpha:0.4560 | SPLoss:0.0000 | CLSLoss:0.0378 | top1:93.6267 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1809 | MainLoss:0.1809 | SPLoss:0.0000 | CLSLoss:0.0378 | top1:93.8846 | AUROC:0.9826\n",
      "Test | 123/16 | Loss:0.6942 | MainLoss:0.6942 | SPLoss:0.0000 | CLSLoss:0.0378 | top1:68.3879 | AUROC:0.8297\n",
      "\n",
      "Epoch: [458 | 1000] LR: 0.000935\n",
      "Train | 16/16 | Loss:0.2232 | MainLoss:0.1853 | Alpha:0.4568 | SPLoss:0.0000 | CLSLoss:0.0378 | top1:94.0267 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1794 | MainLoss:0.1794 | SPLoss:0.0000 | CLSLoss:0.0378 | top1:93.8974 | AUROC:0.9832\n",
      "Test | 123/16 | Loss:0.7173 | MainLoss:0.7173 | SPLoss:0.0000 | CLSLoss:0.0378 | top1:67.6638 | AUROC:0.8257\n",
      "\n",
      "Epoch: [459 | 1000] LR: 0.000933\n",
      "Train | 16/16 | Loss:0.2166 | MainLoss:0.1788 | Alpha:0.4573 | SPLoss:0.0000 | CLSLoss:0.0378 | top1:94.1600 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1830 | MainLoss:0.1830 | SPLoss:0.0000 | CLSLoss:0.0379 | top1:93.9231 | AUROC:0.9828\n",
      "Test | 123/16 | Loss:0.6772 | MainLoss:0.6772 | SPLoss:0.0000 | CLSLoss:0.0379 | top1:68.8008 | AUROC:0.8338\n",
      "\n",
      "Epoch: [460 | 1000] LR: 0.000930\n",
      "Train | 16/16 | Loss:0.2273 | MainLoss:0.1894 | Alpha:0.4557 | SPLoss:0.0000 | CLSLoss:0.0379 | top1:93.3600 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1789 | MainLoss:0.1789 | SPLoss:0.0000 | CLSLoss:0.0379 | top1:93.9615 | AUROC:0.9826\n",
      "Test | 123/16 | Loss:0.7300 | MainLoss:0.7300 | SPLoss:0.0000 | CLSLoss:0.0379 | top1:67.3067 | AUROC:0.8224\n",
      "\n",
      "Epoch: [461 | 1000] LR: 0.000928\n",
      "Train | 16/16 | Loss:0.2189 | MainLoss:0.1810 | Alpha:0.4572 | SPLoss:0.0000 | CLSLoss:0.0379 | top1:94.2400 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1819 | MainLoss:0.1819 | SPLoss:0.0000 | CLSLoss:0.0379 | top1:93.9487 | AUROC:0.9815\n",
      "Test | 123/16 | Loss:0.7270 | MainLoss:0.7270 | SPLoss:0.0000 | CLSLoss:0.0379 | top1:68.2405 | AUROC:0.8137\n",
      "\n",
      "Epoch: [462 | 1000] LR: 0.000925\n",
      "Train | 16/16 | Loss:0.2144 | MainLoss:0.1765 | Alpha:0.4584 | SPLoss:0.0000 | CLSLoss:0.0379 | top1:94.2133 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1817 | MainLoss:0.1817 | SPLoss:0.0000 | CLSLoss:0.0380 | top1:93.9744 | AUROC:0.9820\n",
      "Test | 123/16 | Loss:0.7222 | MainLoss:0.7222 | SPLoss:0.0000 | CLSLoss:0.0380 | top1:68.3781 | AUROC:0.8174\n",
      "\n",
      "Epoch: [463 | 1000] LR: 0.000923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 16/16 | Loss:0.2222 | MainLoss:0.1842 | Alpha:0.4576 | SPLoss:0.0000 | CLSLoss:0.0379 | top1:93.6800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1794 | MainLoss:0.1794 | SPLoss:0.0000 | CLSLoss:0.0379 | top1:93.9872 | AUROC:0.9828\n",
      "Test | 123/16 | Loss:0.7134 | MainLoss:0.7134 | SPLoss:0.0000 | CLSLoss:0.0379 | top1:67.8473 | AUROC:0.8308\n",
      "\n",
      "Epoch: [464 | 1000] LR: 0.000920\n",
      "Train | 16/16 | Loss:0.2221 | MainLoss:0.1842 | Alpha:0.4577 | SPLoss:0.0000 | CLSLoss:0.0379 | top1:93.8933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1785 | MainLoss:0.1785 | SPLoss:0.0000 | CLSLoss:0.0378 | top1:94.0000 | AUROC:0.9832\n",
      "Test | 123/16 | Loss:0.7275 | MainLoss:0.7275 | SPLoss:0.0000 | CLSLoss:0.0378 | top1:67.3165 | AUROC:0.8305\n",
      "\n",
      "Epoch: [465 | 1000] LR: 0.000918\n",
      "Train | 16/16 | Loss:0.2174 | MainLoss:0.1796 | Alpha:0.4589 | SPLoss:0.0000 | CLSLoss:0.0378 | top1:93.7067 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1824 | MainLoss:0.1824 | SPLoss:0.0000 | CLSLoss:0.0378 | top1:93.9231 | AUROC:0.9829\n",
      "Test | 123/16 | Loss:0.6869 | MainLoss:0.6869 | SPLoss:0.0000 | CLSLoss:0.0378 | top1:68.6468 | AUROC:0.8310\n",
      "\n",
      "Epoch: [466 | 1000] LR: 0.000915\n",
      "Train | 16/16 | Loss:0.2218 | MainLoss:0.1840 | Alpha:0.4571 | SPLoss:0.0000 | CLSLoss:0.0378 | top1:93.6000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1808 | MainLoss:0.1808 | SPLoss:0.0000 | CLSLoss:0.0378 | top1:93.9359 | AUROC:0.9830\n",
      "Test | 123/16 | Loss:0.6954 | MainLoss:0.6954 | SPLoss:0.0000 | CLSLoss:0.0378 | top1:68.2765 | AUROC:0.8282\n",
      "\n",
      "Epoch: [467 | 1000] LR: 0.000913\n",
      "Train | 16/16 | Loss:0.2340 | MainLoss:0.1962 | Alpha:0.4541 | SPLoss:0.0000 | CLSLoss:0.0378 | top1:93.2000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1792 | MainLoss:0.1792 | SPLoss:0.0000 | CLSLoss:0.0377 | top1:93.8846 | AUROC:0.9834\n",
      "Test | 123/16 | Loss:0.6945 | MainLoss:0.6945 | SPLoss:0.0000 | CLSLoss:0.0377 | top1:67.7949 | AUROC:0.8327\n",
      "\n",
      "Epoch: [468 | 1000] LR: 0.000910\n",
      "Train | 16/16 | Loss:0.2292 | MainLoss:0.1915 | Alpha:0.4552 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:93.3867 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1828 | MainLoss:0.1828 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:93.8846 | AUROC:0.9831\n",
      "Test | 123/16 | Loss:0.6771 | MainLoss:0.6771 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:68.7353 | AUROC:0.8275\n",
      "\n",
      "Epoch: [469 | 1000] LR: 0.000908\n",
      "Train | 16/16 | Loss:0.2216 | MainLoss:0.1840 | Alpha:0.4570 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:93.7067 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1785 | MainLoss:0.1785 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:93.8974 | AUROC:0.9831\n",
      "Test | 123/16 | Loss:0.7139 | MainLoss:0.7139 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.4115 | AUROC:0.8246\n",
      "\n",
      "Epoch: [470 | 1000] LR: 0.000905\n",
      "Train | 16/16 | Loss:0.2256 | MainLoss:0.1880 | Alpha:0.4567 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:93.5467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1827 | MainLoss:0.1827 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:93.9615 | AUROC:0.9827\n",
      "Test | 123/16 | Loss:0.6836 | MainLoss:0.6836 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:68.4699 | AUROC:0.8271\n",
      "\n",
      "Epoch: [471 | 1000] LR: 0.000903\n",
      "Train | 16/16 | Loss:0.2207 | MainLoss:0.1831 | Alpha:0.4570 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:93.9467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1804 | MainLoss:0.1804 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:93.9103 | AUROC:0.9816\n",
      "Test | 123/16 | Loss:0.7261 | MainLoss:0.7261 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.9391 | AUROC:0.8089\n",
      "\n",
      "Epoch: [472 | 1000] LR: 0.000900\n",
      "Train | 16/16 | Loss:0.2186 | MainLoss:0.1809 | Alpha:0.4581 | SPLoss:0.0000 | CLSLoss:0.0377 | top1:93.9467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1783 | MainLoss:0.1783 | SPLoss:0.0000 | CLSLoss:0.0377 | top1:93.9359 | AUROC:0.9829\n",
      "Test | 123/16 | Loss:0.7322 | MainLoss:0.7322 | SPLoss:0.0000 | CLSLoss:0.0377 | top1:67.0708 | AUROC:0.8204\n",
      "\n",
      "Epoch: [473 | 1000] LR: 0.000898\n",
      "Train | 16/16 | Loss:0.2242 | MainLoss:0.1865 | Alpha:0.4560 | SPLoss:0.0000 | CLSLoss:0.0377 | top1:93.9200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1794 | MainLoss:0.1794 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:93.9359 | AUROC:0.9825\n",
      "Test | 123/16 | Loss:0.7311 | MainLoss:0.7311 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.7163 | AUROC:0.8120\n",
      "\n",
      "Epoch: [474 | 1000] LR: 0.000895\n",
      "Train | 16/16 | Loss:0.2159 | MainLoss:0.1782 | Alpha:0.4588 | SPLoss:0.0000 | CLSLoss:0.0377 | top1:93.8667 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1784 | MainLoss:0.1784 | SPLoss:0.0000 | CLSLoss:0.0377 | top1:93.9231 | AUROC:0.9827\n",
      "Test | 123/16 | Loss:0.7287 | MainLoss:0.7287 | SPLoss:0.0000 | CLSLoss:0.0377 | top1:67.4443 | AUROC:0.8189\n",
      "\n",
      "Epoch: [475 | 1000] LR: 0.000893\n",
      "Train | 16/16 | Loss:0.2190 | MainLoss:0.1813 | Alpha:0.4583 | SPLoss:0.0000 | CLSLoss:0.0377 | top1:93.8133 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1782 | MainLoss:0.1782 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:93.9615 | AUROC:0.9828\n",
      "Test | 123/16 | Loss:0.7400 | MainLoss:0.7400 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.1658 | AUROC:0.8184\n",
      "\n",
      "Epoch: [476 | 1000] LR: 0.000890\n",
      "Train | 16/16 | Loss:0.2134 | MainLoss:0.1757 | Alpha:0.4581 | SPLoss:0.0000 | CLSLoss:0.0377 | top1:94.3200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1782 | MainLoss:0.1782 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:93.9615 | AUROC:0.9816\n",
      "Test | 123/16 | Loss:0.7693 | MainLoss:0.7693 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:66.6940 | AUROC:0.8086\n",
      "\n",
      "Epoch: [477 | 1000] LR: 0.000888\n",
      "Train | 16/16 | Loss:0.2187 | MainLoss:0.1811 | Alpha:0.4577 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.0800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1781 | MainLoss:0.1781 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:93.9615 | AUROC:0.9824\n",
      "Test | 123/16 | Loss:0.7442 | MainLoss:0.7442 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.0806 | AUROC:0.8187\n",
      "\n",
      "Epoch: [478 | 1000] LR: 0.000885\n",
      "Train | 16/16 | Loss:0.2222 | MainLoss:0.1847 | Alpha:0.4570 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1786 | MainLoss:0.1786 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:93.9872 | AUROC:0.9831\n",
      "Test | 123/16 | Loss:0.7168 | MainLoss:0.7168 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.4410 | AUROC:0.8293\n",
      "\n",
      "Epoch: [479 | 1000] LR: 0.000883\n",
      "Train | 16/16 | Loss:0.2259 | MainLoss:0.1884 | Alpha:0.4557 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:93.3067 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1802 | MainLoss:0.1802 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:93.9744 | AUROC:0.9828\n",
      "Test | 123/16 | Loss:0.7039 | MainLoss:0.7039 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:68.1127 | AUROC:0.8254\n",
      "\n",
      "Epoch: [480 | 1000] LR: 0.000880\n",
      "Train | 16/16 | Loss:0.2228 | MainLoss:0.1852 | Alpha:0.4563 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:93.9467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1776 | MainLoss:0.1776 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.0000 | AUROC:0.9828\n",
      "Test | 123/16 | Loss:0.7263 | MainLoss:0.7263 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.3296 | AUROC:0.8251\n",
      "\n",
      "Epoch: [481 | 1000] LR: 0.000878\n",
      "Train | 16/16 | Loss:0.2158 | MainLoss:0.1782 | Alpha:0.4583 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1600 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1790 | MainLoss:0.1790 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.0000 | AUROC:0.9828\n",
      "Test | 123/16 | Loss:0.7120 | MainLoss:0.7120 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.9063 | AUROC:0.8255\n",
      "\n",
      "Epoch: [482 | 1000] LR: 0.000875\n",
      "Train | 16/16 | Loss:0.2258 | MainLoss:0.1883 | Alpha:0.4557 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:93.8400 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1799 | MainLoss:0.1799 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:93.9744 | AUROC:0.9833\n",
      "Test | 123/16 | Loss:0.6983 | MainLoss:0.6983 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:68.1815 | AUROC:0.8270\n",
      "\n",
      "Epoch: [483 | 1000] LR: 0.000873\n",
      "Train | 16/16 | Loss:0.2188 | MainLoss:0.1812 | Alpha:0.4584 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:93.9467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1785 | MainLoss:0.1785 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.0256 | AUROC:0.9828\n",
      "Test | 123/16 | Loss:0.7282 | MainLoss:0.7282 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.7818 | AUROC:0.8159\n",
      "\n",
      "Epoch: [484 | 1000] LR: 0.000870\n",
      "Train | 16/16 | Loss:0.2375 | MainLoss:0.2001 | Alpha:0.4536 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:93.3067 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1779 | MainLoss:0.1779 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:93.9231 | AUROC:0.9840\n",
      "Test | 123/16 | Loss:0.7032 | MainLoss:0.7032 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:67.5688 | AUROC:0.8313\n",
      "\n",
      "Epoch: [485 | 1000] LR: 0.000868\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 16/16 | Loss:0.2180 | MainLoss:0.1807 | Alpha:0.4583 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:93.8133 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1810 | MainLoss:0.1810 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:93.9744 | AUROC:0.9830\n",
      "Test | 123/16 | Loss:0.6946 | MainLoss:0.6946 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:68.4273 | AUROC:0.8243\n",
      "\n",
      "Epoch: [486 | 1000] LR: 0.000865\n",
      "Train | 16/16 | Loss:0.2107 | MainLoss:0.1732 | Alpha:0.4599 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.3200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1795 | MainLoss:0.1795 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:93.9615 | AUROC:0.9828\n",
      "Test | 123/16 | Loss:0.7143 | MainLoss:0.7143 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:68.0144 | AUROC:0.8175\n",
      "\n",
      "Epoch: [487 | 1000] LR: 0.000863\n",
      "Train | 16/16 | Loss:0.2168 | MainLoss:0.1793 | Alpha:0.4589 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:93.9467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1788 | MainLoss:0.1788 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.0128 | AUROC:0.9829\n",
      "Test | 123/16 | Loss:0.7216 | MainLoss:0.7216 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:68.0111 | AUROC:0.8152\n",
      "\n",
      "Epoch: [488 | 1000] LR: 0.000860\n",
      "Train | 16/16 | Loss:0.2132 | MainLoss:0.1756 | Alpha:0.4588 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1067 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1787 | MainLoss:0.1787 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:93.9872 | AUROC:0.9821\n",
      "Test | 123/16 | Loss:0.7389 | MainLoss:0.7389 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.7883 | AUROC:0.8086\n",
      "\n",
      "Epoch: [489 | 1000] LR: 0.000858\n",
      "Train | 16/16 | Loss:0.2208 | MainLoss:0.1832 | Alpha:0.4585 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:93.5733 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1794 | MainLoss:0.1794 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.0000 | AUROC:0.9829\n",
      "Test | 123/16 | Loss:0.6983 | MainLoss:0.6983 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:68.2634 | AUROC:0.8257\n",
      "\n",
      "Epoch: [490 | 1000] LR: 0.000855\n",
      "Train | 16/16 | Loss:0.2222 | MainLoss:0.1847 | Alpha:0.4571 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.0533 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1782 | MainLoss:0.1782 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.0385 | AUROC:0.9830\n",
      "Test | 123/16 | Loss:0.7141 | MainLoss:0.7141 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.8178 | AUROC:0.8254\n",
      "\n",
      "Epoch: [491 | 1000] LR: 0.000853\n",
      "Train | 16/16 | Loss:0.2165 | MainLoss:0.1790 | Alpha:0.4584 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:93.7600 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1792 | MainLoss:0.1792 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.0513 | AUROC:0.9836\n",
      "Test | 123/16 | Loss:0.6866 | MainLoss:0.6866 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:68.0963 | AUROC:0.8319\n",
      "\n",
      "Epoch: [492 | 1000] LR: 0.000850\n",
      "Train | 16/16 | Loss:0.2286 | MainLoss:0.1910 | Alpha:0.4563 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:93.3067 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1763 | MainLoss:0.1763 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.0256 | AUROC:0.9839\n",
      "Test | 123/16 | Loss:0.7138 | MainLoss:0.7138 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.0773 | AUROC:0.8292\n",
      "\n",
      "Epoch: [493 | 1000] LR: 0.000848\n",
      "Train | 16/16 | Loss:0.2263 | MainLoss:0.1888 | Alpha:0.4559 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:93.6800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1754 | MainLoss:0.1754 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:94.0897 | AUROC:0.9841\n",
      "Test | 123/16 | Loss:0.7227 | MainLoss:0.7227 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:66.6743 | AUROC:0.8299\n",
      "\n",
      "Epoch: [494 | 1000] LR: 0.000845\n",
      "Train | 16/16 | Loss:0.2313 | MainLoss:0.1939 | Alpha:0.4545 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:93.0133 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1799 | MainLoss:0.1799 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:93.9615 | AUROC:0.9834\n",
      "Test | 123/16 | Loss:0.6830 | MainLoss:0.6830 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:68.0406 | AUROC:0.8304\n",
      "\n",
      "Epoch: [495 | 1000] LR: 0.000843\n",
      "Train | 16/16 | Loss:0.2145 | MainLoss:0.1771 | Alpha:0.4581 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:94.0533 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1784 | MainLoss:0.1784 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.0000 | AUROC:0.9833\n",
      "Test | 123/16 | Loss:0.6981 | MainLoss:0.6981 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.8277 | AUROC:0.8275\n",
      "\n",
      "Epoch: [496 | 1000] LR: 0.000840\n",
      "Train | 16/16 | Loss:0.2175 | MainLoss:0.1800 | Alpha:0.4583 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:93.9733 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1785 | MainLoss:0.1785 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.0256 | AUROC:0.9830\n",
      "Test | 123/16 | Loss:0.7068 | MainLoss:0.7068 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.9260 | AUROC:0.8213\n",
      "\n",
      "Epoch: [497 | 1000] LR: 0.000838\n",
      "Train | 16/16 | Loss:0.2271 | MainLoss:0.1897 | Alpha:0.4559 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:93.7867 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1756 | MainLoss:0.1756 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:94.0769 | AUROC:0.9831\n",
      "Test | 123/16 | Loss:0.7312 | MainLoss:0.7312 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:66.9954 | AUROC:0.8211\n",
      "\n",
      "Epoch: [498 | 1000] LR: 0.000835\n",
      "Train | 16/16 | Loss:0.2146 | MainLoss:0.1772 | Alpha:0.4583 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:94.1333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1777 | MainLoss:0.1777 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:94.0385 | AUROC:0.9829\n",
      "Test | 123/16 | Loss:0.7087 | MainLoss:0.7087 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:67.9423 | AUROC:0.8228\n",
      "\n",
      "Epoch: [499 | 1000] LR: 0.000833\n",
      "Train | 16/16 | Loss:0.2066 | MainLoss:0.1690 | Alpha:0.4606 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.4800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1783 | MainLoss:0.1783 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.0256 | AUROC:0.9828\n",
      "Test | 123/16 | Loss:0.7193 | MainLoss:0.7193 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:68.0734 | AUROC:0.8198\n",
      "\n",
      "Epoch: [500 | 1000] LR: 0.000830\n",
      "Train | 16/16 | Loss:0.2220 | MainLoss:0.1845 | Alpha:0.4571 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:93.6533 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1796 | MainLoss:0.1796 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:93.9487 | AUROC:0.9836\n",
      "Test | 123/16 | Loss:0.6931 | MainLoss:0.6931 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:68.2864 | AUROC:0.8281\n",
      "\n",
      "Epoch: [501 | 1000] LR: 0.000828\n",
      "Train | 16/16 | Loss:0.2316 | MainLoss:0.1942 | Alpha:0.4546 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:93.2533 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1793 | MainLoss:0.1793 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:94.0000 | AUROC:0.9838\n",
      "Test | 123/16 | Loss:0.6807 | MainLoss:0.6807 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:68.2307 | AUROC:0.8292\n",
      "\n",
      "Epoch: [502 | 1000] LR: 0.000083\n",
      "Train | 16/16 | Loss:0.2224 | MainLoss:0.1851 | Alpha:0.4570 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:93.9200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1778 | MainLoss:0.1778 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:94.0385 | AUROC:0.9840\n",
      "Test | 123/16 | Loss:0.6926 | MainLoss:0.6926 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:67.9686 | AUROC:0.8284\n",
      "\n",
      "Epoch: [503 | 1000] LR: 0.000082\n",
      "Train | 16/16 | Loss:0.2254 | MainLoss:0.1880 | Alpha:0.4558 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:93.7333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1770 | MainLoss:0.1770 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:94.0641 | AUROC:0.9840\n",
      "Test | 123/16 | Loss:0.7018 | MainLoss:0.7018 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:67.8277 | AUROC:0.8264\n",
      "\n",
      "Epoch: [504 | 1000] LR: 0.000082\n",
      "Train | 16/16 | Loss:0.2201 | MainLoss:0.1828 | Alpha:0.4572 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:94.1067 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1774 | MainLoss:0.1774 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:94.0513 | AUROC:0.9839\n",
      "Test | 123/16 | Loss:0.6995 | MainLoss:0.6995 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:67.9260 | AUROC:0.8261\n",
      "\n",
      "Epoch: [505 | 1000] LR: 0.000082\n",
      "Train | 16/16 | Loss:0.2251 | MainLoss:0.1878 | Alpha:0.4566 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:93.8667 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1768 | MainLoss:0.1768 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:94.1026 | AUROC:0.9837\n",
      "Test | 123/16 | Loss:0.7051 | MainLoss:0.7051 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:67.7720 | AUROC:0.8261\n",
      "\n",
      "Epoch: [506 | 1000] LR: 0.000082\n",
      "Train | 16/16 | Loss:0.2070 | MainLoss:0.1696 | Alpha:0.4604 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:94.3467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1770 | MainLoss:0.1770 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:94.0769 | AUROC:0.9835\n",
      "Test | 123/16 | Loss:0.7072 | MainLoss:0.7072 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:67.8211 | AUROC:0.8245\n",
      "\n",
      "Epoch: [507 | 1000] LR: 0.000081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 16/16 | Loss:0.2139 | MainLoss:0.1765 | Alpha:0.4582 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:93.7333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1768 | MainLoss:0.1768 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:94.0769 | AUROC:0.9837\n",
      "Test | 123/16 | Loss:0.7121 | MainLoss:0.7121 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:67.7916 | AUROC:0.8223\n",
      "\n",
      "Epoch: [508 | 1000] LR: 0.000081\n",
      "Train | 16/16 | Loss:0.2221 | MainLoss:0.1847 | Alpha:0.4568 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:93.5733 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1767 | MainLoss:0.1767 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:94.0897 | AUROC:0.9840\n",
      "Test | 123/16 | Loss:0.7133 | MainLoss:0.7133 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:67.7261 | AUROC:0.8226\n",
      "\n",
      "Epoch: [509 | 1000] LR: 0.000081\n",
      "Train | 16/16 | Loss:0.2191 | MainLoss:0.1817 | Alpha:0.4564 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:93.4400 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1769 | MainLoss:0.1769 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:94.0769 | AUROC:0.9836\n",
      "Test | 123/16 | Loss:0.7100 | MainLoss:0.7100 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:67.8014 | AUROC:0.8236\n",
      "\n",
      "Epoch: [510 | 1000] LR: 0.000081\n",
      "Train | 16/16 | Loss:0.2247 | MainLoss:0.1873 | Alpha:0.4562 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:93.6267 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1766 | MainLoss:0.1766 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:94.0897 | AUROC:0.9836\n",
      "Test | 123/16 | Loss:0.7136 | MainLoss:0.7136 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:67.7228 | AUROC:0.8228\n",
      "\n",
      "Epoch: [511 | 1000] LR: 0.000080\n",
      "Train | 16/16 | Loss:0.2240 | MainLoss:0.1867 | Alpha:0.4564 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:93.4667 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1765 | MainLoss:0.1765 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:94.0897 | AUROC:0.9836\n",
      "Test | 123/16 | Loss:0.7166 | MainLoss:0.7166 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:67.6606 | AUROC:0.8218\n",
      "\n",
      "Epoch: [512 | 1000] LR: 0.000080\n",
      "Train | 16/16 | Loss:0.2066 | MainLoss:0.1692 | Alpha:0.4600 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:94.5867 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1765 | MainLoss:0.1765 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:94.0897 | AUROC:0.9831\n",
      "Test | 123/16 | Loss:0.7197 | MainLoss:0.7197 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:67.6573 | AUROC:0.8200\n",
      "\n",
      "Epoch: [513 | 1000] LR: 0.000080\n",
      "Train | 16/16 | Loss:0.2128 | MainLoss:0.1754 | Alpha:0.4587 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:94.2400 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1764 | MainLoss:0.1764 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:94.1026 | AUROC:0.9833\n",
      "Test | 123/16 | Loss:0.7222 | MainLoss:0.7222 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:67.6245 | AUROC:0.8191\n",
      "\n",
      "Epoch: [514 | 1000] LR: 0.000079\n",
      "Train | 16/16 | Loss:0.2242 | MainLoss:0.1868 | Alpha:0.4571 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:93.3333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1767 | MainLoss:0.1767 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:94.0769 | AUROC:0.9832\n",
      "Test | 123/16 | Loss:0.7171 | MainLoss:0.7171 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:67.7392 | AUROC:0.8210\n",
      "\n",
      "Epoch: [515 | 1000] LR: 0.000079\n",
      "Train | 16/16 | Loss:0.2215 | MainLoss:0.1841 | Alpha:0.4564 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:94.1067 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1769 | MainLoss:0.1769 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:94.0513 | AUROC:0.9834\n",
      "Test | 123/16 | Loss:0.7148 | MainLoss:0.7148 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:67.8342 | AUROC:0.8211\n",
      "\n",
      "Epoch: [516 | 1000] LR: 0.000079\n",
      "Train | 16/16 | Loss:0.1997 | MainLoss:0.1623 | Alpha:0.4620 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:94.7733 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1769 | MainLoss:0.1769 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:94.0513 | AUROC:0.9832\n",
      "Test | 123/16 | Loss:0.7178 | MainLoss:0.7178 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:67.8211 | AUROC:0.8195\n",
      "\n",
      "Epoch: [517 | 1000] LR: 0.000079\n",
      "Train | 16/16 | Loss:0.2085 | MainLoss:0.1710 | Alpha:0.4599 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:94.2667 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1767 | MainLoss:0.1767 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:94.0641 | AUROC:0.9831\n",
      "Test | 123/16 | Loss:0.7260 | MainLoss:0.7260 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:67.7326 | AUROC:0.8160\n",
      "\n",
      "Epoch: [518 | 1000] LR: 0.000078\n",
      "Train | 16/16 | Loss:0.2148 | MainLoss:0.1773 | Alpha:0.4593 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:94.2933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1772 | MainLoss:0.1772 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:94.0513 | AUROC:0.9831\n",
      "Test | 123/16 | Loss:0.7211 | MainLoss:0.7211 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:67.8735 | AUROC:0.8178\n",
      "\n",
      "Epoch: [519 | 1000] LR: 0.000078\n",
      "Train | 16/16 | Loss:0.2294 | MainLoss:0.1920 | Alpha:0.4565 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:93.5733 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1774 | MainLoss:0.1774 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:94.0128 | AUROC:0.9833\n",
      "Test | 123/16 | Loss:0.7128 | MainLoss:0.7128 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:67.9227 | AUROC:0.8209\n",
      "\n",
      "Epoch: [520 | 1000] LR: 0.000078\n",
      "Train | 16/16 | Loss:0.2295 | MainLoss:0.1920 | Alpha:0.4547 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:92.8800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1771 | MainLoss:0.1771 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:94.0641 | AUROC:0.9834\n",
      "Test | 123/16 | Loss:0.7109 | MainLoss:0.7109 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:67.9227 | AUROC:0.8231\n",
      "\n",
      "Epoch: [521 | 1000] LR: 0.000078\n",
      "Train | 16/16 | Loss:0.2280 | MainLoss:0.1906 | Alpha:0.4551 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:93.6800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1765 | MainLoss:0.1765 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:94.0897 | AUROC:0.9836\n",
      "Test | 123/16 | Loss:0.7152 | MainLoss:0.7152 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:67.7064 | AUROC:0.8227\n",
      "\n",
      "Epoch: [522 | 1000] LR: 0.000077\n",
      "Train | 16/16 | Loss:0.2189 | MainLoss:0.1815 | Alpha:0.4583 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:94.1067 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1765 | MainLoss:0.1765 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:94.0897 | AUROC:0.9833\n",
      "Test | 123/16 | Loss:0.7162 | MainLoss:0.7162 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:67.7326 | AUROC:0.8222\n",
      "\n",
      "Epoch: [523 | 1000] LR: 0.000077\n",
      "Train | 16/16 | Loss:0.2198 | MainLoss:0.1824 | Alpha:0.4574 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:93.6533 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1770 | MainLoss:0.1770 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:94.0641 | AUROC:0.9833\n",
      "Test | 123/16 | Loss:0.7126 | MainLoss:0.7126 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:67.8670 | AUROC:0.8221\n",
      "\n",
      "Epoch: [524 | 1000] LR: 0.000077\n",
      "Train | 16/16 | Loss:0.2177 | MainLoss:0.1803 | Alpha:0.4575 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:93.6267 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1774 | MainLoss:0.1774 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:94.0128 | AUROC:0.9834\n",
      "Test | 123/16 | Loss:0.7097 | MainLoss:0.7097 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:67.9292 | AUROC:0.8231\n",
      "\n",
      "Epoch: [525 | 1000] LR: 0.000077\n",
      "Train | 16/16 | Loss:0.2223 | MainLoss:0.1849 | Alpha:0.4570 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:93.6000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1774 | MainLoss:0.1774 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:94.0385 | AUROC:0.9836\n",
      "Test | 123/16 | Loss:0.7066 | MainLoss:0.7066 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:67.9456 | AUROC:0.8242\n",
      "\n",
      "Epoch: [526 | 1000] LR: 0.000076\n",
      "Train | 16/16 | Loss:0.2233 | MainLoss:0.1859 | Alpha:0.4569 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:93.6267 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1765 | MainLoss:0.1765 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:94.0897 | AUROC:0.9835\n",
      "Test | 123/16 | Loss:0.7133 | MainLoss:0.7133 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:67.7687 | AUROC:0.8242\n",
      "\n",
      "Epoch: [527 | 1000] LR: 0.000076\n",
      "Train | 16/16 | Loss:0.2196 | MainLoss:0.1822 | Alpha:0.4572 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:93.6267 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1764 | MainLoss:0.1764 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:94.0897 | AUROC:0.9834\n",
      "Test | 123/16 | Loss:0.7138 | MainLoss:0.7138 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:67.7195 | AUROC:0.8234\n",
      "\n",
      "Epoch: [528 | 1000] LR: 0.000076\n",
      "Train | 16/16 | Loss:0.2110 | MainLoss:0.1736 | Alpha:0.4596 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:93.8933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1763 | MainLoss:0.1763 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:94.1026 | AUROC:0.9833\n",
      "Test | 123/16 | Loss:0.7155 | MainLoss:0.7155 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:67.6802 | AUROC:0.8230\n",
      "\n",
      "Epoch: [529 | 1000] LR: 0.000076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 16/16 | Loss:0.2194 | MainLoss:0.1820 | Alpha:0.4578 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:94.1333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1758 | MainLoss:0.1758 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:94.1026 | AUROC:0.9837\n",
      "Test | 123/16 | Loss:0.7194 | MainLoss:0.7194 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:67.4771 | AUROC:0.8228\n",
      "\n",
      "Epoch: [530 | 1000] LR: 0.000075\n",
      "Train | 16/16 | Loss:0.2110 | MainLoss:0.1736 | Alpha:0.4600 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:93.8933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1763 | MainLoss:0.1763 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:94.1026 | AUROC:0.9832\n",
      "Test | 123/16 | Loss:0.7157 | MainLoss:0.7157 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:67.6835 | AUROC:0.8232\n",
      "\n",
      "Epoch: [531 | 1000] LR: 0.000075\n",
      "Train | 16/16 | Loss:0.2036 | MainLoss:0.1661 | Alpha:0.4612 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:94.8533 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1765 | MainLoss:0.1765 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:94.0769 | AUROC:0.9834\n",
      "Test | 123/16 | Loss:0.7183 | MainLoss:0.7183 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:67.7425 | AUROC:0.8211\n",
      "\n",
      "Epoch: [532 | 1000] LR: 0.000075\n",
      "Train | 16/16 | Loss:0.2175 | MainLoss:0.1800 | Alpha:0.4577 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:93.9467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1763 | MainLoss:0.1763 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:94.1026 | AUROC:0.9835\n",
      "Test | 123/16 | Loss:0.7211 | MainLoss:0.7211 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:67.6671 | AUROC:0.8205\n",
      "\n",
      "Epoch: [533 | 1000] LR: 0.000075\n",
      "Train | 16/16 | Loss:0.2186 | MainLoss:0.1811 | Alpha:0.4587 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:94.0533 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1764 | MainLoss:0.1764 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:94.0897 | AUROC:0.9831\n",
      "Test | 123/16 | Loss:0.7178 | MainLoss:0.7178 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:67.7425 | AUROC:0.8223\n",
      "\n",
      "Epoch: [534 | 1000] LR: 0.000074\n",
      "Train | 16/16 | Loss:0.2330 | MainLoss:0.1955 | Alpha:0.4540 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:93.0400 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1762 | MainLoss:0.1762 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:94.1026 | AUROC:0.9836\n",
      "Test | 123/16 | Loss:0.7200 | MainLoss:0.7200 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:67.6802 | AUROC:0.8214\n",
      "\n",
      "Epoch: [535 | 1000] LR: 0.000074\n",
      "Train | 16/16 | Loss:0.2056 | MainLoss:0.1681 | Alpha:0.4620 | SPLoss:0.0000 | CLSLoss:0.0374 | top1:94.6933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1764 | MainLoss:0.1764 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1026 | AUROC:0.9834\n",
      "Test | 123/16 | Loss:0.7203 | MainLoss:0.7203 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.7589 | AUROC:0.8201\n",
      "\n",
      "Epoch: [536 | 1000] LR: 0.000074\n",
      "Train | 16/16 | Loss:0.2063 | MainLoss:0.1688 | Alpha:0.4609 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.2133 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1762 | MainLoss:0.1762 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.0897 | AUROC:0.9835\n",
      "Test | 123/16 | Loss:0.7236 | MainLoss:0.7236 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.6868 | AUROC:0.8197\n",
      "\n",
      "Epoch: [537 | 1000] LR: 0.000074\n",
      "Train | 16/16 | Loss:0.2118 | MainLoss:0.1743 | Alpha:0.4588 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.2667 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1763 | MainLoss:0.1763 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.0897 | AUROC:0.9832\n",
      "Test | 123/16 | Loss:0.7232 | MainLoss:0.7232 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.7163 | AUROC:0.8195\n",
      "\n",
      "Epoch: [538 | 1000] LR: 0.000073\n",
      "Train | 16/16 | Loss:0.2129 | MainLoss:0.1755 | Alpha:0.4591 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.2933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1758 | MainLoss:0.1758 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1026 | AUROC:0.9831\n",
      "Test | 123/16 | Loss:0.7289 | MainLoss:0.7289 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.4935 | AUROC:0.8190\n",
      "\n",
      "Epoch: [539 | 1000] LR: 0.000073\n",
      "Train | 16/16 | Loss:0.2273 | MainLoss:0.1899 | Alpha:0.4562 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:93.3067 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1757 | MainLoss:0.1757 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.0897 | AUROC:0.9834\n",
      "Test | 123/16 | Loss:0.7279 | MainLoss:0.7279 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.4246 | AUROC:0.8206\n",
      "\n",
      "Epoch: [540 | 1000] LR: 0.000073\n",
      "Train | 16/16 | Loss:0.2177 | MainLoss:0.1802 | Alpha:0.4580 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:93.7600 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1758 | MainLoss:0.1758 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1026 | AUROC:0.9836\n",
      "Test | 123/16 | Loss:0.7251 | MainLoss:0.7251 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.4738 | AUROC:0.8219\n",
      "\n",
      "Epoch: [541 | 1000] LR: 0.000073\n",
      "Train | 16/16 | Loss:0.2208 | MainLoss:0.1833 | Alpha:0.4572 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1754 | MainLoss:0.1754 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.0641 | AUROC:0.9834\n",
      "Test | 123/16 | Loss:0.7310 | MainLoss:0.7310 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.3034 | AUROC:0.8210\n",
      "\n",
      "Epoch: [542 | 1000] LR: 0.000072\n",
      "Train | 16/16 | Loss:0.2192 | MainLoss:0.1817 | Alpha:0.4589 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:93.7333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1754 | MainLoss:0.1754 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.0769 | AUROC:0.9835\n",
      "Test | 123/16 | Loss:0.7313 | MainLoss:0.7313 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.3001 | AUROC:0.8209\n",
      "\n",
      "Epoch: [543 | 1000] LR: 0.000072\n",
      "Train | 16/16 | Loss:0.2111 | MainLoss:0.1737 | Alpha:0.4596 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.0267 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1760 | MainLoss:0.1760 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.0897 | AUROC:0.9836\n",
      "Test | 123/16 | Loss:0.7222 | MainLoss:0.7222 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.6147 | AUROC:0.8225\n",
      "\n",
      "Epoch: [544 | 1000] LR: 0.000072\n",
      "Train | 16/16 | Loss:0.2173 | MainLoss:0.1798 | Alpha:0.4581 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:93.7333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1765 | MainLoss:0.1765 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.0897 | AUROC:0.9836\n",
      "Test | 123/16 | Loss:0.7140 | MainLoss:0.7140 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.8244 | AUROC:0.8239\n",
      "\n",
      "Epoch: [545 | 1000] LR: 0.000072\n",
      "Train | 16/16 | Loss:0.2100 | MainLoss:0.1726 | Alpha:0.4595 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.4800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1765 | MainLoss:0.1765 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1026 | AUROC:0.9835\n",
      "Test | 123/16 | Loss:0.7136 | MainLoss:0.7136 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.8440 | AUROC:0.8236\n",
      "\n",
      "Epoch: [546 | 1000] LR: 0.000071\n",
      "Train | 16/16 | Loss:0.2190 | MainLoss:0.1815 | Alpha:0.4583 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:93.9200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1763 | MainLoss:0.1763 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1154 | AUROC:0.9836\n",
      "Test | 123/16 | Loss:0.7144 | MainLoss:0.7144 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.7654 | AUROC:0.8239\n",
      "\n",
      "Epoch: [547 | 1000] LR: 0.000071\n",
      "Train | 16/16 | Loss:0.2187 | MainLoss:0.1812 | Alpha:0.4583 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1867 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1766 | MainLoss:0.1766 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.0897 | AUROC:0.9834\n",
      "Test | 123/16 | Loss:0.7128 | MainLoss:0.7128 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.8735 | AUROC:0.8238\n",
      "\n",
      "Epoch: [548 | 1000] LR: 0.000071\n",
      "Train | 16/16 | Loss:0.2194 | MainLoss:0.1820 | Alpha:0.4576 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:93.2800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1768 | MainLoss:0.1768 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.0513 | AUROC:0.9835\n",
      "Test | 123/16 | Loss:0.7093 | MainLoss:0.7093 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.9391 | AUROC:0.8245\n",
      "\n",
      "Epoch: [549 | 1000] LR: 0.000071\n",
      "Train | 16/16 | Loss:0.2156 | MainLoss:0.1781 | Alpha:0.4598 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.0800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1766 | MainLoss:0.1766 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.0641 | AUROC:0.9833\n",
      "Test | 123/16 | Loss:0.7126 | MainLoss:0.7126 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.8735 | AUROC:0.8232\n",
      "\n",
      "Epoch: [550 | 1000] LR: 0.000070\n",
      "Train | 16/16 | Loss:0.2227 | MainLoss:0.1853 | Alpha:0.4571 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:93.4667 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1762 | MainLoss:0.1762 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1154 | AUROC:0.9835\n",
      "Test | 123/16 | Loss:0.7174 | MainLoss:0.7174 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.7490 | AUROC:0.8227\n",
      "\n",
      "Epoch: [551 | 1000] LR: 0.000070\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 16/16 | Loss:0.2201 | MainLoss:0.1826 | Alpha:0.4572 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:93.8933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1763 | MainLoss:0.1763 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1154 | AUROC:0.9832\n",
      "Test | 123/16 | Loss:0.7170 | MainLoss:0.7170 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.7589 | AUROC:0.8220\n",
      "\n",
      "Epoch: [552 | 1000] LR: 0.000070\n",
      "Train | 16/16 | Loss:0.2168 | MainLoss:0.1793 | Alpha:0.4585 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:93.9733 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1765 | MainLoss:0.1765 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.0897 | AUROC:0.9835\n",
      "Test | 123/16 | Loss:0.7125 | MainLoss:0.7125 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.8539 | AUROC:0.8232\n",
      "\n",
      "Epoch: [553 | 1000] LR: 0.000070\n",
      "Train | 16/16 | Loss:0.2188 | MainLoss:0.1814 | Alpha:0.4576 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.0800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1768 | MainLoss:0.1768 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.0513 | AUROC:0.9835\n",
      "Test | 123/16 | Loss:0.7104 | MainLoss:0.7104 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.9456 | AUROC:0.8239\n",
      "\n",
      "Epoch: [554 | 1000] LR: 0.000069\n",
      "Train | 16/16 | Loss:0.2152 | MainLoss:0.1777 | Alpha:0.4581 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:93.6533 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1764 | MainLoss:0.1764 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.0897 | AUROC:0.9832\n",
      "Test | 123/16 | Loss:0.7161 | MainLoss:0.7161 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.8440 | AUROC:0.8225\n",
      "\n",
      "Epoch: [555 | 1000] LR: 0.000069\n",
      "Train | 16/16 | Loss:0.2162 | MainLoss:0.1788 | Alpha:0.4581 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1067 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1763 | MainLoss:0.1763 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1154 | AUROC:0.9835\n",
      "Test | 123/16 | Loss:0.7176 | MainLoss:0.7176 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.7883 | AUROC:0.8221\n",
      "\n",
      "Epoch: [556 | 1000] LR: 0.000069\n",
      "Train | 16/16 | Loss:0.2213 | MainLoss:0.1838 | Alpha:0.4579 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.0267 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1763 | MainLoss:0.1763 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1282 | AUROC:0.9832\n",
      "Test | 123/16 | Loss:0.7156 | MainLoss:0.7156 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.8113 | AUROC:0.8232\n",
      "\n",
      "Epoch: [557 | 1000] LR: 0.000069\n",
      "Train | 16/16 | Loss:0.2226 | MainLoss:0.1851 | Alpha:0.4571 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.0267 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1764 | MainLoss:0.1764 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1026 | AUROC:0.9833\n",
      "Test | 123/16 | Loss:0.7157 | MainLoss:0.7157 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.8670 | AUROC:0.8225\n",
      "\n",
      "Epoch: [558 | 1000] LR: 0.000068\n",
      "Train | 16/16 | Loss:0.2099 | MainLoss:0.1724 | Alpha:0.4602 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.3200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1767 | MainLoss:0.1767 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.0769 | AUROC:0.9835\n",
      "Test | 123/16 | Loss:0.7137 | MainLoss:0.7137 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.9358 | AUROC:0.8228\n",
      "\n",
      "Epoch: [559 | 1000] LR: 0.000068\n",
      "Train | 16/16 | Loss:0.2316 | MainLoss:0.1941 | Alpha:0.4559 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:93.2267 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1766 | MainLoss:0.1766 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.0769 | AUROC:0.9834\n",
      "Test | 123/16 | Loss:0.7126 | MainLoss:0.7126 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.9391 | AUROC:0.8232\n",
      "\n",
      "Epoch: [560 | 1000] LR: 0.000068\n",
      "Train | 16/16 | Loss:0.2081 | MainLoss:0.1706 | Alpha:0.4597 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.2133 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1762 | MainLoss:0.1762 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1154 | AUROC:0.9832\n",
      "Test | 123/16 | Loss:0.7194 | MainLoss:0.7194 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.7949 | AUROC:0.8211\n",
      "\n",
      "Epoch: [561 | 1000] LR: 0.000068\n",
      "Train | 16/16 | Loss:0.2181 | MainLoss:0.1806 | Alpha:0.4580 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.2400 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1763 | MainLoss:0.1763 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1282 | AUROC:0.9832\n",
      "Test | 123/16 | Loss:0.7197 | MainLoss:0.7197 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.8113 | AUROC:0.8211\n",
      "\n",
      "Epoch: [562 | 1000] LR: 0.000067\n",
      "Train | 16/16 | Loss:0.2162 | MainLoss:0.1787 | Alpha:0.4579 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:93.8400 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1761 | MainLoss:0.1761 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1282 | AUROC:0.9834\n",
      "Test | 123/16 | Loss:0.7203 | MainLoss:0.7203 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.7556 | AUROC:0.8208\n",
      "\n",
      "Epoch: [563 | 1000] LR: 0.000067\n",
      "Train | 16/16 | Loss:0.2206 | MainLoss:0.1832 | Alpha:0.4567 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:93.9467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1763 | MainLoss:0.1763 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1282 | AUROC:0.9831\n",
      "Test | 123/16 | Loss:0.7193 | MainLoss:0.7193 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.8277 | AUROC:0.8212\n",
      "\n",
      "Epoch: [564 | 1000] LR: 0.000067\n",
      "Train | 16/16 | Loss:0.2082 | MainLoss:0.1708 | Alpha:0.4603 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.0800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1762 | MainLoss:0.1762 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1154 | AUROC:0.9830\n",
      "Test | 123/16 | Loss:0.7210 | MainLoss:0.7210 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.7883 | AUROC:0.8202\n",
      "\n",
      "Epoch: [565 | 1000] LR: 0.000067\n",
      "Train | 16/16 | Loss:0.2289 | MainLoss:0.1914 | Alpha:0.4551 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:93.3867 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1760 | MainLoss:0.1760 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1282 | AUROC:0.9834\n",
      "Test | 123/16 | Loss:0.7199 | MainLoss:0.7199 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.7490 | AUROC:0.8222\n",
      "\n",
      "Epoch: [566 | 1000] LR: 0.000066\n",
      "Train | 16/16 | Loss:0.2085 | MainLoss:0.1711 | Alpha:0.4593 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1067 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1758 | MainLoss:0.1758 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1026 | AUROC:0.9833\n",
      "Test | 123/16 | Loss:0.7240 | MainLoss:0.7240 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.6442 | AUROC:0.8203\n",
      "\n",
      "Epoch: [567 | 1000] LR: 0.000066\n",
      "Train | 16/16 | Loss:0.2200 | MainLoss:0.1825 | Alpha:0.4583 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:93.9200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1760 | MainLoss:0.1760 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1282 | AUROC:0.9835\n",
      "Test | 123/16 | Loss:0.7219 | MainLoss:0.7219 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.7261 | AUROC:0.8211\n",
      "\n",
      "Epoch: [568 | 1000] LR: 0.000066\n",
      "Train | 16/16 | Loss:0.2232 | MainLoss:0.1857 | Alpha:0.4566 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:93.8667 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1762 | MainLoss:0.1762 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1154 | AUROC:0.9834\n",
      "Test | 123/16 | Loss:0.7189 | MainLoss:0.7189 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.8277 | AUROC:0.8211\n",
      "\n",
      "Epoch: [569 | 1000] LR: 0.000066\n",
      "Train | 16/16 | Loss:0.2232 | MainLoss:0.1857 | Alpha:0.4573 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:93.7333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1767 | MainLoss:0.1767 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.0513 | AUROC:0.9834\n",
      "Test | 123/16 | Loss:0.7132 | MainLoss:0.7132 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.9587 | AUROC:0.8227\n",
      "\n",
      "Epoch: [570 | 1000] LR: 0.000066\n",
      "Train | 16/16 | Loss:0.2187 | MainLoss:0.1812 | Alpha:0.4571 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:93.4667 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1765 | MainLoss:0.1765 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.0641 | AUROC:0.9833\n",
      "Test | 123/16 | Loss:0.7139 | MainLoss:0.7139 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.9686 | AUROC:0.8219\n",
      "\n",
      "Epoch: [571 | 1000] LR: 0.000065\n",
      "Train | 16/16 | Loss:0.1999 | MainLoss:0.1624 | Alpha:0.4621 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.8800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1765 | MainLoss:0.1765 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.0641 | AUROC:0.9831\n",
      "Test | 123/16 | Loss:0.7201 | MainLoss:0.7201 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.9456 | AUROC:0.8193\n",
      "\n",
      "Epoch: [572 | 1000] LR: 0.000065\n",
      "Train | 16/16 | Loss:0.2104 | MainLoss:0.1729 | Alpha:0.4609 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.3200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1767 | MainLoss:0.1767 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.0513 | AUROC:0.9833\n",
      "Test | 123/16 | Loss:0.7196 | MainLoss:0.7196 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.9554 | AUROC:0.8186\n",
      "\n",
      "Epoch: [573 | 1000] LR: 0.000065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 16/16 | Loss:0.2025 | MainLoss:0.1649 | Alpha:0.4616 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.3200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1766 | MainLoss:0.1766 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.0513 | AUROC:0.9834\n",
      "Test | 123/16 | Loss:0.7221 | MainLoss:0.7221 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.9522 | AUROC:0.8173\n",
      "\n",
      "Epoch: [574 | 1000] LR: 0.000065\n",
      "Train | 16/16 | Loss:0.2232 | MainLoss:0.1857 | Alpha:0.4567 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:93.6800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1766 | MainLoss:0.1766 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.0513 | AUROC:0.9828\n",
      "Test | 123/16 | Loss:0.7213 | MainLoss:0.7213 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.9489 | AUROC:0.8185\n",
      "\n",
      "Epoch: [575 | 1000] LR: 0.000064\n",
      "Train | 16/16 | Loss:0.2041 | MainLoss:0.1666 | Alpha:0.4615 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.5333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1765 | MainLoss:0.1765 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.0769 | AUROC:0.9833\n",
      "Test | 123/16 | Loss:0.7229 | MainLoss:0.7229 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.9292 | AUROC:0.8177\n",
      "\n",
      "Epoch: [576 | 1000] LR: 0.000064\n",
      "Train | 16/16 | Loss:0.2284 | MainLoss:0.1909 | Alpha:0.4555 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:93.3333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1767 | MainLoss:0.1767 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.0513 | AUROC:0.9831\n",
      "Test | 123/16 | Loss:0.7183 | MainLoss:0.7183 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.9554 | AUROC:0.8198\n",
      "\n",
      "Epoch: [577 | 1000] LR: 0.000064\n",
      "Train | 16/16 | Loss:0.2179 | MainLoss:0.1804 | Alpha:0.4581 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.3200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1764 | MainLoss:0.1764 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1026 | AUROC:0.9832\n",
      "Test | 123/16 | Loss:0.7233 | MainLoss:0.7233 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.8834 | AUROC:0.8187\n",
      "\n",
      "Epoch: [578 | 1000] LR: 0.000064\n",
      "Train | 16/16 | Loss:0.2202 | MainLoss:0.1827 | Alpha:0.4578 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:93.6267 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1762 | MainLoss:0.1762 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1154 | AUROC:0.9832\n",
      "Test | 123/16 | Loss:0.7241 | MainLoss:0.7241 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.8047 | AUROC:0.8189\n",
      "\n",
      "Epoch: [579 | 1000] LR: 0.000063\n",
      "Train | 16/16 | Loss:0.2215 | MainLoss:0.1840 | Alpha:0.4576 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:93.7067 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1762 | MainLoss:0.1762 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1282 | AUROC:0.9832\n",
      "Test | 123/16 | Loss:0.7220 | MainLoss:0.7220 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.8473 | AUROC:0.8196\n",
      "\n",
      "Epoch: [580 | 1000] LR: 0.000063\n",
      "Train | 16/16 | Loss:0.2264 | MainLoss:0.1889 | Alpha:0.4560 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:93.3333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1762 | MainLoss:0.1762 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1026 | AUROC:0.9834\n",
      "Test | 123/16 | Loss:0.7212 | MainLoss:0.7212 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.8539 | AUROC:0.8206\n",
      "\n",
      "Epoch: [581 | 1000] LR: 0.000063\n",
      "Train | 16/16 | Loss:0.2187 | MainLoss:0.1812 | Alpha:0.4572 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1761 | MainLoss:0.1761 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1154 | AUROC:0.9832\n",
      "Test | 123/16 | Loss:0.7207 | MainLoss:0.7207 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.8113 | AUROC:0.8214\n",
      "\n",
      "Epoch: [582 | 1000] LR: 0.000063\n",
      "Train | 16/16 | Loss:0.2273 | MainLoss:0.1898 | Alpha:0.4560 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:93.8667 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1757 | MainLoss:0.1757 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1026 | AUROC:0.9833\n",
      "Test | 123/16 | Loss:0.7269 | MainLoss:0.7269 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.5917 | AUROC:0.8201\n",
      "\n",
      "Epoch: [583 | 1000] LR: 0.000062\n",
      "Train | 16/16 | Loss:0.2066 | MainLoss:0.1691 | Alpha:0.4605 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.5333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1755 | MainLoss:0.1755 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1154 | AUROC:0.9833\n",
      "Test | 123/16 | Loss:0.7298 | MainLoss:0.7298 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.4935 | AUROC:0.8199\n",
      "\n",
      "Epoch: [584 | 1000] LR: 0.000062\n",
      "Train | 16/16 | Loss:0.2145 | MainLoss:0.1770 | Alpha:0.4592 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:93.9467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1753 | MainLoss:0.1753 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.0897 | AUROC:0.9836\n",
      "Test | 123/16 | Loss:0.7311 | MainLoss:0.7311 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.4214 | AUROC:0.8198\n",
      "\n",
      "Epoch: [585 | 1000] LR: 0.000062\n",
      "Train | 16/16 | Loss:0.2124 | MainLoss:0.1749 | Alpha:0.4595 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1067 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1756 | MainLoss:0.1756 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1026 | AUROC:0.9834\n",
      "Test | 123/16 | Loss:0.7265 | MainLoss:0.7265 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.5360 | AUROC:0.8206\n",
      "\n",
      "Epoch: [586 | 1000] LR: 0.000062\n",
      "Train | 16/16 | Loss:0.2121 | MainLoss:0.1746 | Alpha:0.4585 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:93.9733 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1756 | MainLoss:0.1756 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.0897 | AUROC:0.9835\n",
      "Test | 123/16 | Loss:0.7278 | MainLoss:0.7278 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.5229 | AUROC:0.8204\n",
      "\n",
      "Epoch: [587 | 1000] LR: 0.000061\n",
      "Train | 16/16 | Loss:0.2197 | MainLoss:0.1822 | Alpha:0.4582 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.5333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1755 | MainLoss:0.1755 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1154 | AUROC:0.9834\n",
      "Test | 123/16 | Loss:0.7283 | MainLoss:0.7283 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.5066 | AUROC:0.8211\n",
      "\n",
      "Epoch: [588 | 1000] LR: 0.000061\n",
      "Train | 16/16 | Loss:0.2128 | MainLoss:0.1753 | Alpha:0.4588 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1867 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1755 | MainLoss:0.1755 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1154 | AUROC:0.9835\n",
      "Test | 123/16 | Loss:0.7287 | MainLoss:0.7287 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.4935 | AUROC:0.8203\n",
      "\n",
      "Epoch: [589 | 1000] LR: 0.000061\n",
      "Train | 16/16 | Loss:0.2113 | MainLoss:0.1737 | Alpha:0.4597 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1600 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1753 | MainLoss:0.1753 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.0897 | AUROC:0.9835\n",
      "Test | 123/16 | Loss:0.7322 | MainLoss:0.7322 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.3984 | AUROC:0.8197\n",
      "\n",
      "Epoch: [590 | 1000] LR: 0.000061\n",
      "Train | 16/16 | Loss:0.2096 | MainLoss:0.1720 | Alpha:0.4599 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.2133 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1757 | MainLoss:0.1757 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.0897 | AUROC:0.9832\n",
      "Test | 123/16 | Loss:0.7283 | MainLoss:0.7283 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.5623 | AUROC:0.8204\n",
      "\n",
      "Epoch: [591 | 1000] LR: 0.000060\n",
      "Train | 16/16 | Loss:0.2119 | MainLoss:0.1743 | Alpha:0.4591 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1067 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1755 | MainLoss:0.1755 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1026 | AUROC:0.9832\n",
      "Test | 123/16 | Loss:0.7314 | MainLoss:0.7314 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.5000 | AUROC:0.8188\n",
      "\n",
      "Epoch: [592 | 1000] LR: 0.000060\n",
      "Train | 16/16 | Loss:0.2019 | MainLoss:0.1644 | Alpha:0.4617 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.8533 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1760 | MainLoss:0.1760 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.0897 | AUROC:0.9834\n",
      "Test | 123/16 | Loss:0.7287 | MainLoss:0.7287 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.7425 | AUROC:0.8177\n",
      "\n",
      "Epoch: [593 | 1000] LR: 0.000060\n",
      "Train | 16/16 | Loss:0.2078 | MainLoss:0.1703 | Alpha:0.4600 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.3200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1763 | MainLoss:0.1763 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1154 | AUROC:0.9831\n",
      "Test | 123/16 | Loss:0.7254 | MainLoss:0.7254 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.8408 | AUROC:0.8190\n",
      "\n",
      "Epoch: [594 | 1000] LR: 0.000060\n",
      "Train | 16/16 | Loss:0.2133 | MainLoss:0.1757 | Alpha:0.4594 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1758 | MainLoss:0.1758 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1026 | AUROC:0.9833\n",
      "Test | 123/16 | Loss:0.7306 | MainLoss:0.7306 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.6606 | AUROC:0.8184\n",
      "\n",
      "Epoch: [595 | 1000] LR: 0.000059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 16/16 | Loss:0.2120 | MainLoss:0.1744 | Alpha:0.4593 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.0267 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1761 | MainLoss:0.1761 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1026 | AUROC:0.9834\n",
      "Test | 123/16 | Loss:0.7261 | MainLoss:0.7261 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.8014 | AUROC:0.8198\n",
      "\n",
      "Epoch: [596 | 1000] LR: 0.000059\n",
      "Train | 16/16 | Loss:0.2185 | MainLoss:0.1809 | Alpha:0.4589 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:93.7600 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1761 | MainLoss:0.1761 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1154 | AUROC:0.9833\n",
      "Test | 123/16 | Loss:0.7238 | MainLoss:0.7238 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.8703 | AUROC:0.8203\n",
      "\n",
      "Epoch: [597 | 1000] LR: 0.000059\n",
      "Train | 16/16 | Loss:0.2162 | MainLoss:0.1787 | Alpha:0.4577 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:93.9467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1762 | MainLoss:0.1762 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1154 | AUROC:0.9832\n",
      "Test | 123/16 | Loss:0.7224 | MainLoss:0.7224 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.9063 | AUROC:0.8207\n",
      "\n",
      "Epoch: [598 | 1000] LR: 0.000059\n",
      "Train | 16/16 | Loss:0.2126 | MainLoss:0.1751 | Alpha:0.4581 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:93.8133 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1761 | MainLoss:0.1761 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1154 | AUROC:0.9834\n",
      "Test | 123/16 | Loss:0.7214 | MainLoss:0.7214 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.8801 | AUROC:0.8212\n",
      "\n",
      "Epoch: [599 | 1000] LR: 0.000058\n",
      "Train | 16/16 | Loss:0.2287 | MainLoss:0.1911 | Alpha:0.4559 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:93.0667 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1763 | MainLoss:0.1763 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1154 | AUROC:0.9833\n",
      "Test | 123/16 | Loss:0.7171 | MainLoss:0.7171 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.9489 | AUROC:0.8227\n",
      "\n",
      "Epoch: [600 | 1000] LR: 0.000058\n",
      "Train | 16/16 | Loss:0.2128 | MainLoss:0.1753 | Alpha:0.4597 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:93.9200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1763 | MainLoss:0.1763 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1154 | AUROC:0.9831\n",
      "Test | 123/16 | Loss:0.7190 | MainLoss:0.7190 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.9358 | AUROC:0.8214\n",
      "\n",
      "Epoch: [601 | 1000] LR: 0.000058\n",
      "Train | 16/16 | Loss:0.2075 | MainLoss:0.1700 | Alpha:0.4600 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.2667 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1763 | MainLoss:0.1763 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1154 | AUROC:0.9830\n",
      "Test | 123/16 | Loss:0.7201 | MainLoss:0.7201 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.9194 | AUROC:0.8209\n",
      "\n",
      "Epoch: [602 | 1000] LR: 0.000058\n",
      "Train | 16/16 | Loss:0.2083 | MainLoss:0.1708 | Alpha:0.4595 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.9867 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1764 | MainLoss:0.1764 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.0641 | AUROC:0.9832\n",
      "Test | 123/16 | Loss:0.7202 | MainLoss:0.7202 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.9653 | AUROC:0.8206\n",
      "\n",
      "Epoch: [603 | 1000] LR: 0.000057\n",
      "Train | 16/16 | Loss:0.2187 | MainLoss:0.1811 | Alpha:0.4587 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:93.9733 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1762 | MainLoss:0.1762 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1282 | AUROC:0.9836\n",
      "Test | 123/16 | Loss:0.7201 | MainLoss:0.7201 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.9096 | AUROC:0.8213\n",
      "\n",
      "Epoch: [604 | 1000] LR: 0.000057\n",
      "Train | 16/16 | Loss:0.2291 | MainLoss:0.1915 | Alpha:0.4550 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:93.5200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1760 | MainLoss:0.1760 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1410 | AUROC:0.9832\n",
      "Test | 123/16 | Loss:0.7181 | MainLoss:0.7181 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.8735 | AUROC:0.8234\n",
      "\n",
      "Epoch: [605 | 1000] LR: 0.000057\n",
      "Train | 16/16 | Loss:0.2191 | MainLoss:0.1816 | Alpha:0.4581 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:93.8133 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1757 | MainLoss:0.1757 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1154 | AUROC:0.9833\n",
      "Test | 123/16 | Loss:0.7218 | MainLoss:0.7218 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.7163 | AUROC:0.8226\n",
      "\n",
      "Epoch: [606 | 1000] LR: 0.000057\n",
      "Train | 16/16 | Loss:0.2118 | MainLoss:0.1743 | Alpha:0.4589 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:93.7600 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1758 | MainLoss:0.1758 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1154 | AUROC:0.9833\n",
      "Test | 123/16 | Loss:0.7204 | MainLoss:0.7204 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.7687 | AUROC:0.8224\n",
      "\n",
      "Epoch: [607 | 1000] LR: 0.000056\n",
      "Train | 16/16 | Loss:0.2195 | MainLoss:0.1819 | Alpha:0.4570 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:93.6800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1755 | MainLoss:0.1755 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1026 | AUROC:0.9835\n",
      "Test | 123/16 | Loss:0.7232 | MainLoss:0.7232 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.6769 | AUROC:0.8222\n",
      "\n",
      "Epoch: [608 | 1000] LR: 0.000056\n",
      "Train | 16/16 | Loss:0.2119 | MainLoss:0.1743 | Alpha:0.4594 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1867 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1756 | MainLoss:0.1756 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1154 | AUROC:0.9834\n",
      "Test | 123/16 | Loss:0.7222 | MainLoss:0.7222 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.6966 | AUROC:0.8226\n",
      "\n",
      "Epoch: [609 | 1000] LR: 0.000056\n",
      "Train | 16/16 | Loss:0.2148 | MainLoss:0.1773 | Alpha:0.4582 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.3200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1757 | MainLoss:0.1757 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1154 | AUROC:0.9833\n",
      "Test | 123/16 | Loss:0.7225 | MainLoss:0.7225 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.7359 | AUROC:0.8221\n",
      "\n",
      "Epoch: [610 | 1000] LR: 0.000056\n",
      "Train | 16/16 | Loss:0.2213 | MainLoss:0.1837 | Alpha:0.4570 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.2133 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1755 | MainLoss:0.1755 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1026 | AUROC:0.9833\n",
      "Test | 123/16 | Loss:0.7252 | MainLoss:0.7252 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.6245 | AUROC:0.8224\n",
      "\n",
      "Epoch: [611 | 1000] LR: 0.000056\n",
      "Train | 16/16 | Loss:0.2141 | MainLoss:0.1765 | Alpha:0.4591 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:93.9733 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1753 | MainLoss:0.1753 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.0897 | AUROC:0.9837\n",
      "Test | 123/16 | Loss:0.7264 | MainLoss:0.7264 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.5328 | AUROC:0.8222\n",
      "\n",
      "Epoch: [612 | 1000] LR: 0.000055\n",
      "Train | 16/16 | Loss:0.2098 | MainLoss:0.1723 | Alpha:0.4600 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1067 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1754 | MainLoss:0.1754 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1154 | AUROC:0.9831\n",
      "Test | 123/16 | Loss:0.7266 | MainLoss:0.7266 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.5688 | AUROC:0.8222\n",
      "\n",
      "Epoch: [613 | 1000] LR: 0.000055\n",
      "Train | 16/16 | Loss:0.1980 | MainLoss:0.1604 | Alpha:0.4624 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.8000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1759 | MainLoss:0.1759 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1154 | AUROC:0.9832\n",
      "Test | 123/16 | Loss:0.7218 | MainLoss:0.7218 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.8211 | AUROC:0.8218\n",
      "\n",
      "Epoch: [614 | 1000] LR: 0.000055\n",
      "Train | 16/16 | Loss:0.2103 | MainLoss:0.1727 | Alpha:0.4593 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.2133 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1754 | MainLoss:0.1754 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1154 | AUROC:0.9830\n",
      "Test | 123/16 | Loss:0.7289 | MainLoss:0.7289 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.5852 | AUROC:0.8204\n",
      "\n",
      "Epoch: [615 | 1000] LR: 0.000055\n",
      "Train | 16/16 | Loss:0.2241 | MainLoss:0.1865 | Alpha:0.4552 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:93.8133 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1755 | MainLoss:0.1755 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.0897 | AUROC:0.9835\n",
      "Test | 123/16 | Loss:0.7270 | MainLoss:0.7270 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.6474 | AUROC:0.8213\n",
      "\n",
      "Epoch: [616 | 1000] LR: 0.000054\n",
      "Train | 16/16 | Loss:0.2221 | MainLoss:0.1845 | Alpha:0.4569 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:93.4400 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1752 | MainLoss:0.1752 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1026 | AUROC:0.9833\n",
      "Test | 123/16 | Loss:0.7294 | MainLoss:0.7294 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.5066 | AUROC:0.8206\n",
      "\n",
      "Epoch: [617 | 1000] LR: 0.000054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 16/16 | Loss:0.2147 | MainLoss:0.1771 | Alpha:0.4581 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:93.9467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1756 | MainLoss:0.1756 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1282 | AUROC:0.9836\n",
      "Test | 123/16 | Loss:0.7251 | MainLoss:0.7251 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.7261 | AUROC:0.8211\n",
      "\n",
      "Epoch: [618 | 1000] LR: 0.000054\n",
      "Train | 16/16 | Loss:0.2215 | MainLoss:0.1840 | Alpha:0.4569 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:93.7333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1762 | MainLoss:0.1762 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1282 | AUROC:0.9833\n",
      "Test | 123/16 | Loss:0.7192 | MainLoss:0.7192 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.9456 | AUROC:0.8225\n",
      "\n",
      "Epoch: [619 | 1000] LR: 0.000054\n",
      "Train | 16/16 | Loss:0.2275 | MainLoss:0.1900 | Alpha:0.4561 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:93.6000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1761 | MainLoss:0.1761 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1282 | AUROC:0.9831\n",
      "Test | 123/16 | Loss:0.7193 | MainLoss:0.7193 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.9391 | AUROC:0.8226\n",
      "\n",
      "Epoch: [620 | 1000] LR: 0.000053\n",
      "Train | 16/16 | Loss:0.2128 | MainLoss:0.1753 | Alpha:0.4592 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:93.7600 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1765 | MainLoss:0.1765 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.0513 | AUROC:0.9833\n",
      "Test | 123/16 | Loss:0.7157 | MainLoss:0.7157 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.9587 | AUROC:0.8230\n",
      "\n",
      "Epoch: [621 | 1000] LR: 0.000053\n",
      "Train | 16/16 | Loss:0.2087 | MainLoss:0.1711 | Alpha:0.4594 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.5067 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1765 | MainLoss:0.1765 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.0513 | AUROC:0.9834\n",
      "Test | 123/16 | Loss:0.7172 | MainLoss:0.7172 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.9620 | AUROC:0.8225\n",
      "\n",
      "Epoch: [622 | 1000] LR: 0.000053\n",
      "Train | 16/16 | Loss:0.2050 | MainLoss:0.1674 | Alpha:0.4610 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.4267 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1760 | MainLoss:0.1760 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1154 | AUROC:0.9833\n",
      "Test | 123/16 | Loss:0.7224 | MainLoss:0.7224 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.9063 | AUROC:0.8216\n",
      "\n",
      "Epoch: [623 | 1000] LR: 0.000053\n",
      "Train | 16/16 | Loss:0.2133 | MainLoss:0.1757 | Alpha:0.4588 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.2400 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1757 | MainLoss:0.1757 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1282 | AUROC:0.9833\n",
      "Test | 123/16 | Loss:0.7251 | MainLoss:0.7251 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.7523 | AUROC:0.8209\n",
      "\n",
      "Epoch: [624 | 1000] LR: 0.000052\n",
      "Train | 16/16 | Loss:0.2125 | MainLoss:0.1749 | Alpha:0.4588 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1067 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1759 | MainLoss:0.1759 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1154 | AUROC:0.9834\n",
      "Test | 123/16 | Loss:0.7245 | MainLoss:0.7245 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.8277 | AUROC:0.8202\n",
      "\n",
      "Epoch: [625 | 1000] LR: 0.000052\n",
      "Train | 16/16 | Loss:0.2058 | MainLoss:0.1683 | Alpha:0.4607 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.4800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1759 | MainLoss:0.1759 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1154 | AUROC:0.9835\n",
      "Test | 123/16 | Loss:0.7256 | MainLoss:0.7256 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.8375 | AUROC:0.8206\n",
      "\n",
      "Epoch: [626 | 1000] LR: 0.000052\n",
      "Train | 16/16 | Loss:0.2116 | MainLoss:0.1740 | Alpha:0.4583 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:93.9733 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1758 | MainLoss:0.1758 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1026 | AUROC:0.9827\n",
      "Test | 123/16 | Loss:0.7277 | MainLoss:0.7277 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.7687 | AUROC:0.8197\n",
      "\n",
      "Epoch: [627 | 1000] LR: 0.000052\n",
      "Train | 16/16 | Loss:0.2161 | MainLoss:0.1785 | Alpha:0.4577 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:93.7867 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1758 | MainLoss:0.1758 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1026 | AUROC:0.9832\n",
      "Test | 123/16 | Loss:0.7261 | MainLoss:0.7261 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.7883 | AUROC:0.8202\n",
      "\n",
      "Epoch: [628 | 1000] LR: 0.000051\n",
      "Train | 16/16 | Loss:0.2147 | MainLoss:0.1771 | Alpha:0.4588 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:93.7867 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1755 | MainLoss:0.1755 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.0897 | AUROC:0.9830\n",
      "Test | 123/16 | Loss:0.7300 | MainLoss:0.7300 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.6835 | AUROC:0.8194\n",
      "\n",
      "Epoch: [629 | 1000] LR: 0.000051\n",
      "Train | 16/16 | Loss:0.2074 | MainLoss:0.1698 | Alpha:0.4602 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.3467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1753 | MainLoss:0.1753 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1154 | AUROC:0.9833\n",
      "Test | 123/16 | Loss:0.7331 | MainLoss:0.7331 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.5688 | AUROC:0.8181\n",
      "\n",
      "Epoch: [630 | 1000] LR: 0.000051\n",
      "Train | 16/16 | Loss:0.2051 | MainLoss:0.1675 | Alpha:0.4610 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.5333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1757 | MainLoss:0.1757 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1410 | AUROC:0.9829\n",
      "Test | 123/16 | Loss:0.7307 | MainLoss:0.7307 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.7359 | AUROC:0.8180\n",
      "\n",
      "Epoch: [631 | 1000] LR: 0.000051\n",
      "Train | 16/16 | Loss:0.2073 | MainLoss:0.1697 | Alpha:0.4601 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.2667 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1758 | MainLoss:0.1758 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1026 | AUROC:0.9832\n",
      "Test | 123/16 | Loss:0.7310 | MainLoss:0.7310 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.7687 | AUROC:0.8169\n",
      "\n",
      "Epoch: [632 | 1000] LR: 0.000051\n",
      "Train | 16/16 | Loss:0.2211 | MainLoss:0.1835 | Alpha:0.4576 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:93.6533 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1757 | MainLoss:0.1757 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1282 | AUROC:0.9835\n",
      "Test | 123/16 | Loss:0.7322 | MainLoss:0.7322 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.7261 | AUROC:0.8171\n",
      "\n",
      "Epoch: [633 | 1000] LR: 0.000050\n",
      "Train | 16/16 | Loss:0.2001 | MainLoss:0.1625 | Alpha:0.4620 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:95.0667 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1760 | MainLoss:0.1760 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1154 | AUROC:0.9829\n",
      "Test | 123/16 | Loss:0.7311 | MainLoss:0.7311 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.8178 | AUROC:0.8168\n",
      "\n",
      "Epoch: [634 | 1000] LR: 0.000050\n",
      "Train | 16/16 | Loss:0.2227 | MainLoss:0.1851 | Alpha:0.4565 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:93.7067 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1764 | MainLoss:0.1764 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.0385 | AUROC:0.9833\n",
      "Test | 123/16 | Loss:0.7238 | MainLoss:0.7238 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.9489 | AUROC:0.8192\n",
      "\n",
      "Epoch: [635 | 1000] LR: 0.000050\n",
      "Train | 16/16 | Loss:0.2261 | MainLoss:0.1885 | Alpha:0.4555 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:93.5467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1767 | MainLoss:0.1767 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.0513 | AUROC:0.9833\n",
      "Test | 123/16 | Loss:0.7195 | MainLoss:0.7195 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:68.0111 | AUROC:0.8208\n",
      "\n",
      "Epoch: [636 | 1000] LR: 0.000050\n",
      "Train | 16/16 | Loss:0.2337 | MainLoss:0.1961 | Alpha:0.4544 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:93.0133 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1761 | MainLoss:0.1761 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1410 | AUROC:0.9831\n",
      "Test | 123/16 | Loss:0.7250 | MainLoss:0.7250 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.9292 | AUROC:0.8196\n",
      "\n",
      "Epoch: [637 | 1000] LR: 0.000049\n",
      "Train | 16/16 | Loss:0.2155 | MainLoss:0.1780 | Alpha:0.4585 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:93.9467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1758 | MainLoss:0.1758 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1154 | AUROC:0.9832\n",
      "Test | 123/16 | Loss:0.7270 | MainLoss:0.7270 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.7916 | AUROC:0.8200\n",
      "\n",
      "Epoch: [638 | 1000] LR: 0.000049\n",
      "Train | 16/16 | Loss:0.2225 | MainLoss:0.1850 | Alpha:0.4572 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:93.3067 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1758 | MainLoss:0.1758 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1154 | AUROC:0.9832\n",
      "Test | 123/16 | Loss:0.7250 | MainLoss:0.7250 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.7949 | AUROC:0.8212\n",
      "\n",
      "Epoch: [639 | 1000] LR: 0.000049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 16/16 | Loss:0.2049 | MainLoss:0.1673 | Alpha:0.4613 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.4533 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1756 | MainLoss:0.1756 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1282 | AUROC:0.9832\n",
      "Test | 123/16 | Loss:0.7294 | MainLoss:0.7294 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.7294 | AUROC:0.8200\n",
      "\n",
      "Epoch: [640 | 1000] LR: 0.000049\n",
      "Train | 16/16 | Loss:0.2133 | MainLoss:0.1757 | Alpha:0.4586 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.5600 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1755 | MainLoss:0.1755 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1282 | AUROC:0.9833\n",
      "Test | 123/16 | Loss:0.7291 | MainLoss:0.7291 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.6933 | AUROC:0.8203\n",
      "\n",
      "Epoch: [641 | 1000] LR: 0.000048\n",
      "Train | 16/16 | Loss:0.2108 | MainLoss:0.1732 | Alpha:0.4597 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.2933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1755 | MainLoss:0.1755 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1282 | AUROC:0.9833\n",
      "Test | 123/16 | Loss:0.7314 | MainLoss:0.7314 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.7031 | AUROC:0.8187\n",
      "\n",
      "Epoch: [642 | 1000] LR: 0.000048\n",
      "Train | 16/16 | Loss:0.2250 | MainLoss:0.1874 | Alpha:0.4563 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:93.6000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1758 | MainLoss:0.1758 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1282 | AUROC:0.9829\n",
      "Test | 123/16 | Loss:0.7279 | MainLoss:0.7279 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.7982 | AUROC:0.8201\n",
      "\n",
      "Epoch: [643 | 1000] LR: 0.000048\n",
      "Train | 16/16 | Loss:0.2146 | MainLoss:0.1771 | Alpha:0.4586 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1760 | MainLoss:0.1760 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1410 | AUROC:0.9836\n",
      "Test | 123/16 | Loss:0.7242 | MainLoss:0.7242 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.9096 | AUROC:0.8211\n",
      "\n",
      "Epoch: [644 | 1000] LR: 0.000048\n",
      "Train | 16/16 | Loss:0.2125 | MainLoss:0.1749 | Alpha:0.4596 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.0267 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1759 | MainLoss:0.1759 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1154 | AUROC:0.9830\n",
      "Test | 123/16 | Loss:0.7261 | MainLoss:0.7261 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.8408 | AUROC:0.8204\n",
      "\n",
      "Epoch: [645 | 1000] LR: 0.000048\n",
      "Train | 16/16 | Loss:0.2242 | MainLoss:0.1866 | Alpha:0.4564 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:93.2000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1761 | MainLoss:0.1761 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1154 | AUROC:0.9835\n",
      "Test | 123/16 | Loss:0.7213 | MainLoss:0.7213 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.9423 | AUROC:0.8220\n",
      "\n",
      "Epoch: [646 | 1000] LR: 0.000047\n",
      "Train | 16/16 | Loss:0.2215 | MainLoss:0.1839 | Alpha:0.4564 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:93.5467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1760 | MainLoss:0.1760 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1282 | AUROC:0.9834\n",
      "Test | 123/16 | Loss:0.7228 | MainLoss:0.7228 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.8997 | AUROC:0.8214\n",
      "\n",
      "Epoch: [647 | 1000] LR: 0.000047\n",
      "Train | 16/16 | Loss:0.2253 | MainLoss:0.1877 | Alpha:0.4566 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:93.4133 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1760 | MainLoss:0.1760 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1282 | AUROC:0.9834\n",
      "Test | 123/16 | Loss:0.7217 | MainLoss:0.7217 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.9194 | AUROC:0.8223\n",
      "\n",
      "Epoch: [648 | 1000] LR: 0.000047\n",
      "Train | 16/16 | Loss:0.2071 | MainLoss:0.1696 | Alpha:0.4603 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.7733 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1762 | MainLoss:0.1762 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1026 | AUROC:0.9832\n",
      "Test | 123/16 | Loss:0.7222 | MainLoss:0.7222 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.9554 | AUROC:0.8212\n",
      "\n",
      "Epoch: [649 | 1000] LR: 0.000047\n",
      "Train | 16/16 | Loss:0.2178 | MainLoss:0.1802 | Alpha:0.4579 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:93.8667 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1758 | MainLoss:0.1758 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1282 | AUROC:0.9832\n",
      "Test | 123/16 | Loss:0.7253 | MainLoss:0.7253 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.8408 | AUROC:0.8209\n",
      "\n",
      "Epoch: [650 | 1000] LR: 0.000046\n",
      "Train | 16/16 | Loss:0.2222 | MainLoss:0.1846 | Alpha:0.4577 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:93.7600 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1758 | MainLoss:0.1758 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1154 | AUROC:0.9832\n",
      "Test | 123/16 | Loss:0.7249 | MainLoss:0.7249 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.8146 | AUROC:0.8216\n",
      "\n",
      "Epoch: [651 | 1000] LR: 0.000046\n",
      "Train | 16/16 | Loss:0.2136 | MainLoss:0.1761 | Alpha:0.4587 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1758 | MainLoss:0.1758 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.0897 | AUROC:0.9833\n",
      "Test | 123/16 | Loss:0.7265 | MainLoss:0.7265 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.7818 | AUROC:0.8213\n",
      "\n",
      "Epoch: [652 | 1000] LR: 0.000046\n",
      "Train | 16/16 | Loss:0.2180 | MainLoss:0.1805 | Alpha:0.4586 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.0800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1756 | MainLoss:0.1756 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1026 | AUROC:0.9834\n",
      "Test | 123/16 | Loss:0.7264 | MainLoss:0.7264 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.7523 | AUROC:0.8216\n",
      "\n",
      "Epoch: [653 | 1000] LR: 0.000046\n",
      "Train | 16/16 | Loss:0.2196 | MainLoss:0.1821 | Alpha:0.4570 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:93.6800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1755 | MainLoss:0.1755 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1154 | AUROC:0.9832\n",
      "Test | 123/16 | Loss:0.7271 | MainLoss:0.7271 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.7195 | AUROC:0.8213\n",
      "\n",
      "Epoch: [654 | 1000] LR: 0.000045\n",
      "Train | 16/16 | Loss:0.2112 | MainLoss:0.1736 | Alpha:0.4593 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1600 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1757 | MainLoss:0.1757 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1154 | AUROC:0.9832\n",
      "Test | 123/16 | Loss:0.7261 | MainLoss:0.7261 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.7818 | AUROC:0.8215\n",
      "\n",
      "Epoch: [655 | 1000] LR: 0.000045\n",
      "Train | 16/16 | Loss:0.1996 | MainLoss:0.1620 | Alpha:0.4624 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.6400 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1758 | MainLoss:0.1758 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1154 | AUROC:0.9830\n",
      "Test | 123/16 | Loss:0.7278 | MainLoss:0.7278 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.7949 | AUROC:0.8202\n",
      "\n",
      "Epoch: [656 | 1000] LR: 0.000045\n",
      "Train | 16/16 | Loss:0.2237 | MainLoss:0.1862 | Alpha:0.4567 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:93.5733 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1760 | MainLoss:0.1760 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1154 | AUROC:0.9832\n",
      "Test | 123/16 | Loss:0.7223 | MainLoss:0.7223 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.9227 | AUROC:0.8223\n",
      "\n",
      "Epoch: [657 | 1000] LR: 0.000045\n",
      "Train | 16/16 | Loss:0.2163 | MainLoss:0.1787 | Alpha:0.4588 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1867 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1758 | MainLoss:0.1758 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1154 | AUROC:0.9831\n",
      "Test | 123/16 | Loss:0.7235 | MainLoss:0.7235 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.7949 | AUROC:0.8221\n",
      "\n",
      "Epoch: [658 | 1000] LR: 0.000045\n",
      "Train | 16/16 | Loss:0.2216 | MainLoss:0.1840 | Alpha:0.4562 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:93.6267 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1760 | MainLoss:0.1760 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1282 | AUROC:0.9831\n",
      "Test | 123/16 | Loss:0.7188 | MainLoss:0.7188 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.9325 | AUROC:0.8234\n",
      "\n",
      "Epoch: [659 | 1000] LR: 0.000044\n",
      "Train | 16/16 | Loss:0.2025 | MainLoss:0.1649 | Alpha:0.4606 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.5333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1760 | MainLoss:0.1760 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1282 | AUROC:0.9833\n",
      "Test | 123/16 | Loss:0.7194 | MainLoss:0.7194 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.9325 | AUROC:0.8234\n",
      "\n",
      "Epoch: [660 | 1000] LR: 0.000044\n",
      "Train | 16/16 | Loss:0.2101 | MainLoss:0.1725 | Alpha:0.4598 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1867 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1758 | MainLoss:0.1758 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1282 | AUROC:0.9833\n",
      "Test | 123/16 | Loss:0.7213 | MainLoss:0.7213 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.8539 | AUROC:0.8233\n",
      "\n",
      "Epoch: [661 | 1000] LR: 0.000044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 16/16 | Loss:0.2144 | MainLoss:0.1768 | Alpha:0.4592 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1867 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1761 | MainLoss:0.1761 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1154 | AUROC:0.9834\n",
      "Test | 123/16 | Loss:0.7187 | MainLoss:0.7187 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.9554 | AUROC:0.8236\n",
      "\n",
      "Epoch: [662 | 1000] LR: 0.000044\n",
      "Train | 16/16 | Loss:0.2170 | MainLoss:0.1794 | Alpha:0.4583 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:93.8667 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1757 | MainLoss:0.1757 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1026 | AUROC:0.9832\n",
      "Test | 123/16 | Loss:0.7233 | MainLoss:0.7233 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.7883 | AUROC:0.8228\n",
      "\n",
      "Epoch: [663 | 1000] LR: 0.000043\n",
      "Train | 16/16 | Loss:0.2154 | MainLoss:0.1778 | Alpha:0.4596 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.5333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1756 | MainLoss:0.1756 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1026 | AUROC:0.9834\n",
      "Test | 123/16 | Loss:0.7235 | MainLoss:0.7235 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.7851 | AUROC:0.8229\n",
      "\n",
      "Epoch: [664 | 1000] LR: 0.000043\n",
      "Train | 16/16 | Loss:0.2058 | MainLoss:0.1683 | Alpha:0.4614 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.8267 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1758 | MainLoss:0.1758 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1154 | AUROC:0.9833\n",
      "Test | 123/16 | Loss:0.7231 | MainLoss:0.7231 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.8244 | AUROC:0.8231\n",
      "\n",
      "Epoch: [665 | 1000] LR: 0.000043\n",
      "Train | 16/16 | Loss:0.2273 | MainLoss:0.1897 | Alpha:0.4555 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:93.5733 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1758 | MainLoss:0.1758 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1282 | AUROC:0.9834\n",
      "Test | 123/16 | Loss:0.7222 | MainLoss:0.7222 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.8080 | AUROC:0.8235\n",
      "\n",
      "Epoch: [666 | 1000] LR: 0.000043\n",
      "Train | 16/16 | Loss:0.2043 | MainLoss:0.1667 | Alpha:0.4609 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.4000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1755 | MainLoss:0.1755 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1026 | AUROC:0.9832\n",
      "Test | 123/16 | Loss:0.7255 | MainLoss:0.7255 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.7490 | AUROC:0.8223\n",
      "\n",
      "Epoch: [667 | 1000] LR: 0.000043\n",
      "Train | 16/16 | Loss:0.2095 | MainLoss:0.1719 | Alpha:0.4606 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.3200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1756 | MainLoss:0.1756 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1026 | AUROC:0.9833\n",
      "Test | 123/16 | Loss:0.7256 | MainLoss:0.7256 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.7687 | AUROC:0.8223\n",
      "\n",
      "Epoch: [668 | 1000] LR: 0.000042\n",
      "Train | 16/16 | Loss:0.2153 | MainLoss:0.1778 | Alpha:0.4597 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1756 | MainLoss:0.1756 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1026 | AUROC:0.9835\n",
      "Test | 123/16 | Loss:0.7264 | MainLoss:0.7264 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.7687 | AUROC:0.8217\n",
      "\n",
      "Epoch: [669 | 1000] LR: 0.000042\n",
      "Train | 16/16 | Loss:0.2111 | MainLoss:0.1735 | Alpha:0.4597 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.6667 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1759 | MainLoss:0.1759 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1154 | AUROC:0.9834\n",
      "Test | 123/16 | Loss:0.7252 | MainLoss:0.7252 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.8801 | AUROC:0.8211\n",
      "\n",
      "Epoch: [670 | 1000] LR: 0.000042\n",
      "Train | 16/16 | Loss:0.2185 | MainLoss:0.1809 | Alpha:0.4580 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:93.8667 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1757 | MainLoss:0.1757 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1026 | AUROC:0.9832\n",
      "Test | 123/16 | Loss:0.7283 | MainLoss:0.7283 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.7851 | AUROC:0.8203\n",
      "\n",
      "Epoch: [671 | 1000] LR: 0.000042\n",
      "Train | 16/16 | Loss:0.2172 | MainLoss:0.1796 | Alpha:0.4590 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:93.8400 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1757 | MainLoss:0.1757 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1154 | AUROC:0.9833\n",
      "Test | 123/16 | Loss:0.7263 | MainLoss:0.7263 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.8342 | AUROC:0.8211\n",
      "\n",
      "Epoch: [672 | 1000] LR: 0.000041\n",
      "Train | 16/16 | Loss:0.2191 | MainLoss:0.1815 | Alpha:0.4577 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.0267 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1760 | MainLoss:0.1760 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1154 | AUROC:0.9827\n",
      "Test | 123/16 | Loss:0.7226 | MainLoss:0.7226 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.9456 | AUROC:0.8219\n",
      "\n",
      "Epoch: [673 | 1000] LR: 0.000041\n",
      "Train | 16/16 | Loss:0.2055 | MainLoss:0.1679 | Alpha:0.4600 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.3467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1758 | MainLoss:0.1758 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1282 | AUROC:0.9833\n",
      "Test | 123/16 | Loss:0.7270 | MainLoss:0.7270 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.8637 | AUROC:0.8201\n",
      "\n",
      "Epoch: [674 | 1000] LR: 0.000041\n",
      "Train | 16/16 | Loss:0.2121 | MainLoss:0.1745 | Alpha:0.4599 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1067 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1758 | MainLoss:0.1758 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1026 | AUROC:0.9830\n",
      "Test | 123/16 | Loss:0.7296 | MainLoss:0.7296 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.8047 | AUROC:0.8189\n",
      "\n",
      "Epoch: [675 | 1000] LR: 0.000041\n",
      "Train | 16/16 | Loss:0.2163 | MainLoss:0.1787 | Alpha:0.4580 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.2400 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1758 | MainLoss:0.1758 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1154 | AUROC:0.9831\n",
      "Test | 123/16 | Loss:0.7299 | MainLoss:0.7299 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.8113 | AUROC:0.8191\n",
      "\n",
      "Epoch: [676 | 1000] LR: 0.000041\n",
      "Train | 16/16 | Loss:0.2199 | MainLoss:0.1823 | Alpha:0.4579 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:93.9200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1756 | MainLoss:0.1756 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1026 | AUROC:0.9833\n",
      "Test | 123/16 | Loss:0.7309 | MainLoss:0.7309 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.7523 | AUROC:0.8191\n",
      "\n",
      "Epoch: [677 | 1000] LR: 0.000040\n",
      "Train | 16/16 | Loss:0.2106 | MainLoss:0.1731 | Alpha:0.4600 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:93.8400 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1756 | MainLoss:0.1756 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1154 | AUROC:0.9832\n",
      "Test | 123/16 | Loss:0.7296 | MainLoss:0.7296 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.7621 | AUROC:0.8198\n",
      "\n",
      "Epoch: [678 | 1000] LR: 0.000040\n",
      "Train | 16/16 | Loss:0.2100 | MainLoss:0.1724 | Alpha:0.4605 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.4533 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1755 | MainLoss:0.1755 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1026 | AUROC:0.9832\n",
      "Test | 123/16 | Loss:0.7302 | MainLoss:0.7302 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.7228 | AUROC:0.8198\n",
      "\n",
      "Epoch: [679 | 1000] LR: 0.000040\n",
      "Train | 16/16 | Loss:0.2169 | MainLoss:0.1794 | Alpha:0.4581 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.2667 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1755 | MainLoss:0.1755 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.0897 | AUROC:0.9832\n",
      "Test | 123/16 | Loss:0.7289 | MainLoss:0.7289 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.7556 | AUROC:0.8208\n",
      "\n",
      "Epoch: [680 | 1000] LR: 0.000040\n",
      "Train | 16/16 | Loss:0.2188 | MainLoss:0.1812 | Alpha:0.4585 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.2133 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1754 | MainLoss:0.1754 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1154 | AUROC:0.9832\n",
      "Test | 123/16 | Loss:0.7315 | MainLoss:0.7315 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.6474 | AUROC:0.8202\n",
      "\n",
      "Epoch: [681 | 1000] LR: 0.000039\n",
      "Train | 16/16 | Loss:0.2200 | MainLoss:0.1824 | Alpha:0.4569 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:93.6267 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1752 | MainLoss:0.1752 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1282 | AUROC:0.9832\n",
      "Test | 123/16 | Loss:0.7321 | MainLoss:0.7321 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.5885 | AUROC:0.8206\n",
      "\n",
      "Epoch: [682 | 1000] LR: 0.000039\n",
      "Train | 16/16 | Loss:0.2043 | MainLoss:0.1667 | Alpha:0.4607 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.5333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1752 | MainLoss:0.1752 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1282 | AUROC:0.9835\n",
      "Test | 123/16 | Loss:0.7321 | MainLoss:0.7321 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.5983 | AUROC:0.8205\n",
      "\n",
      "Epoch: [683 | 1000] LR: 0.000039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 16/16 | Loss:0.2244 | MainLoss:0.1868 | Alpha:0.4569 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:93.7333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1753 | MainLoss:0.1753 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1154 | AUROC:0.9832\n",
      "Test | 123/16 | Loss:0.7287 | MainLoss:0.7287 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.6376 | AUROC:0.8216\n",
      "\n",
      "Epoch: [684 | 1000] LR: 0.000039\n",
      "Train | 16/16 | Loss:0.2085 | MainLoss:0.1709 | Alpha:0.4599 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1067 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1753 | MainLoss:0.1753 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1154 | AUROC:0.9833\n",
      "Test | 123/16 | Loss:0.7292 | MainLoss:0.7292 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.6769 | AUROC:0.8211\n",
      "\n",
      "Epoch: [685 | 1000] LR: 0.000039\n",
      "Train | 16/16 | Loss:0.2123 | MainLoss:0.1747 | Alpha:0.4593 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1755 | MainLoss:0.1755 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1282 | AUROC:0.9834\n",
      "Test | 123/16 | Loss:0.7267 | MainLoss:0.7267 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.7687 | AUROC:0.8221\n",
      "\n",
      "Epoch: [686 | 1000] LR: 0.000038\n",
      "Train | 16/16 | Loss:0.2141 | MainLoss:0.1765 | Alpha:0.4589 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.2933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1754 | MainLoss:0.1754 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.0897 | AUROC:0.9831\n",
      "Test | 123/16 | Loss:0.7274 | MainLoss:0.7274 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.7425 | AUROC:0.8213\n",
      "\n",
      "Epoch: [687 | 1000] LR: 0.000038\n",
      "Train | 16/16 | Loss:0.2136 | MainLoss:0.1760 | Alpha:0.4590 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1753 | MainLoss:0.1753 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1154 | AUROC:0.9836\n",
      "Test | 123/16 | Loss:0.7280 | MainLoss:0.7280 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.6638 | AUROC:0.8222\n",
      "\n",
      "Epoch: [688 | 1000] LR: 0.000038\n",
      "Train | 16/16 | Loss:0.2239 | MainLoss:0.1863 | Alpha:0.4572 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:93.5200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1752 | MainLoss:0.1752 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1282 | AUROC:0.9834\n",
      "Test | 123/16 | Loss:0.7281 | MainLoss:0.7281 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.6212 | AUROC:0.8224\n",
      "\n",
      "Epoch: [689 | 1000] LR: 0.000038\n",
      "Train | 16/16 | Loss:0.2254 | MainLoss:0.1879 | Alpha:0.4565 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:93.8400 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1754 | MainLoss:0.1754 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.0897 | AUROC:0.9835\n",
      "Test | 123/16 | Loss:0.7241 | MainLoss:0.7241 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.7621 | AUROC:0.8235\n",
      "\n",
      "Epoch: [690 | 1000] LR: 0.000038\n",
      "Train | 16/16 | Loss:0.2223 | MainLoss:0.1847 | Alpha:0.4571 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:93.9200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1753 | MainLoss:0.1753 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1154 | AUROC:0.9835\n",
      "Test | 123/16 | Loss:0.7253 | MainLoss:0.7253 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.7064 | AUROC:0.8231\n",
      "\n",
      "Epoch: [691 | 1000] LR: 0.000037\n",
      "Train | 16/16 | Loss:0.2124 | MainLoss:0.1749 | Alpha:0.4591 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.2400 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1755 | MainLoss:0.1755 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1154 | AUROC:0.9835\n",
      "Test | 123/16 | Loss:0.7236 | MainLoss:0.7236 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.7818 | AUROC:0.8240\n",
      "\n",
      "Epoch: [692 | 1000] LR: 0.000037\n",
      "Train | 16/16 | Loss:0.2117 | MainLoss:0.1741 | Alpha:0.4591 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.0533 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1754 | MainLoss:0.1754 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.0897 | AUROC:0.9835\n",
      "Test | 123/16 | Loss:0.7253 | MainLoss:0.7253 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.7294 | AUROC:0.8230\n",
      "\n",
      "Epoch: [693 | 1000] LR: 0.000037\n",
      "Train | 16/16 | Loss:0.2187 | MainLoss:0.1812 | Alpha:0.4585 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.0533 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1756 | MainLoss:0.1756 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1410 | AUROC:0.9835\n",
      "Test | 123/16 | Loss:0.7226 | MainLoss:0.7226 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.8047 | AUROC:0.8238\n",
      "\n",
      "Epoch: [694 | 1000] LR: 0.000037\n",
      "Train | 16/16 | Loss:0.2197 | MainLoss:0.1822 | Alpha:0.4579 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:93.9200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1754 | MainLoss:0.1754 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.0897 | AUROC:0.9833\n",
      "Test | 123/16 | Loss:0.7242 | MainLoss:0.7242 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.7425 | AUROC:0.8233\n",
      "\n",
      "Epoch: [695 | 1000] LR: 0.000036\n",
      "Train | 16/16 | Loss:0.2171 | MainLoss:0.1795 | Alpha:0.4587 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.3200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1754 | MainLoss:0.1754 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.0897 | AUROC:0.9835\n",
      "Test | 123/16 | Loss:0.7246 | MainLoss:0.7246 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.7392 | AUROC:0.8233\n",
      "\n",
      "Epoch: [696 | 1000] LR: 0.000036\n",
      "Train | 16/16 | Loss:0.2149 | MainLoss:0.1773 | Alpha:0.4585 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1867 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1755 | MainLoss:0.1755 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1026 | AUROC:0.9830\n",
      "Test | 123/16 | Loss:0.7253 | MainLoss:0.7253 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.7687 | AUROC:0.8226\n",
      "\n",
      "Epoch: [697 | 1000] LR: 0.000036\n",
      "Train | 16/16 | Loss:0.2224 | MainLoss:0.1848 | Alpha:0.4562 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:93.9733 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1754 | MainLoss:0.1754 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1026 | AUROC:0.9832\n",
      "Test | 123/16 | Loss:0.7260 | MainLoss:0.7260 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.7294 | AUROC:0.8225\n",
      "\n",
      "Epoch: [698 | 1000] LR: 0.000036\n",
      "Train | 16/16 | Loss:0.2114 | MainLoss:0.1738 | Alpha:0.4593 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.4000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1754 | MainLoss:0.1754 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.0897 | AUROC:0.9835\n",
      "Test | 123/16 | Loss:0.7275 | MainLoss:0.7275 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.7326 | AUROC:0.8215\n",
      "\n",
      "Epoch: [699 | 1000] LR: 0.000036\n",
      "Train | 16/16 | Loss:0.2243 | MainLoss:0.1867 | Alpha:0.4569 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:93.7333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1753 | MainLoss:0.1753 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1026 | AUROC:0.9832\n",
      "Test | 123/16 | Loss:0.7274 | MainLoss:0.7274 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.7130 | AUROC:0.8219\n",
      "\n",
      "Epoch: [700 | 1000] LR: 0.000035\n",
      "Train | 16/16 | Loss:0.2177 | MainLoss:0.1801 | Alpha:0.4576 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:93.8667 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1753 | MainLoss:0.1753 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1026 | AUROC:0.9832\n",
      "Test | 123/16 | Loss:0.7276 | MainLoss:0.7276 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.7097 | AUROC:0.8218\n",
      "\n",
      "Epoch: [701 | 1000] LR: 0.000035\n",
      "Train | 16/16 | Loss:0.2066 | MainLoss:0.1691 | Alpha:0.4597 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.5067 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1754 | MainLoss:0.1754 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.0897 | AUROC:0.9833\n",
      "Test | 123/16 | Loss:0.7258 | MainLoss:0.7258 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.7523 | AUROC:0.8222\n",
      "\n",
      "Epoch: [702 | 1000] LR: 0.000035\n",
      "Train | 16/16 | Loss:0.2020 | MainLoss:0.1644 | Alpha:0.4618 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.4800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1754 | MainLoss:0.1754 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1026 | AUROC:0.9831\n",
      "Test | 123/16 | Loss:0.7269 | MainLoss:0.7269 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.7654 | AUROC:0.8216\n",
      "\n",
      "Epoch: [703 | 1000] LR: 0.000035\n",
      "Train | 16/16 | Loss:0.2052 | MainLoss:0.1676 | Alpha:0.4609 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.7200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1751 | MainLoss:0.1751 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1410 | AUROC:0.9833\n",
      "Test | 123/16 | Loss:0.7318 | MainLoss:0.7318 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.6180 | AUROC:0.8202\n",
      "\n",
      "Epoch: [704 | 1000] LR: 0.000035\n",
      "Train | 16/16 | Loss:0.2177 | MainLoss:0.1802 | Alpha:0.4571 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1751 | MainLoss:0.1751 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1410 | AUROC:0.9829\n",
      "Test | 123/16 | Loss:0.7320 | MainLoss:0.7320 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.6147 | AUROC:0.8206\n",
      "\n",
      "Epoch: [705 | 1000] LR: 0.000034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 16/16 | Loss:0.2200 | MainLoss:0.1824 | Alpha:0.4573 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1867 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1751 | MainLoss:0.1751 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1410 | AUROC:0.9833\n",
      "Test | 123/16 | Loss:0.7323 | MainLoss:0.7323 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.5950 | AUROC:0.8201\n",
      "\n",
      "Epoch: [706 | 1000] LR: 0.000034\n",
      "Train | 16/16 | Loss:0.2164 | MainLoss:0.1788 | Alpha:0.4597 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1600 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1749 | MainLoss:0.1749 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1282 | AUROC:0.9832\n",
      "Test | 123/16 | Loss:0.7336 | MainLoss:0.7336 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.5066 | AUROC:0.8207\n",
      "\n",
      "Epoch: [707 | 1000] LR: 0.000034\n",
      "Train | 16/16 | Loss:0.2226 | MainLoss:0.1850 | Alpha:0.4570 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:93.6267 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1750 | MainLoss:0.1750 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1154 | AUROC:0.9836\n",
      "Test | 123/16 | Loss:0.7324 | MainLoss:0.7324 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.5557 | AUROC:0.8210\n",
      "\n",
      "Epoch: [708 | 1000] LR: 0.000034\n",
      "Train | 16/16 | Loss:0.2157 | MainLoss:0.1781 | Alpha:0.4592 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1748 | MainLoss:0.1748 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1026 | AUROC:0.9832\n",
      "Test | 123/16 | Loss:0.7355 | MainLoss:0.7355 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.4640 | AUROC:0.8196\n",
      "\n",
      "Epoch: [709 | 1000] LR: 0.000034\n",
      "Train | 16/16 | Loss:0.2125 | MainLoss:0.1750 | Alpha:0.4599 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.0800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1750 | MainLoss:0.1750 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1410 | AUROC:0.9832\n",
      "Test | 123/16 | Loss:0.7332 | MainLoss:0.7332 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.5688 | AUROC:0.8195\n",
      "\n",
      "Epoch: [710 | 1000] LR: 0.000033\n",
      "Train | 16/16 | Loss:0.2128 | MainLoss:0.1753 | Alpha:0.4601 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.6933 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1750 | MainLoss:0.1750 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1410 | AUROC:0.9837\n",
      "Test | 123/16 | Loss:0.7329 | MainLoss:0.7329 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.5917 | AUROC:0.8201\n",
      "\n",
      "Epoch: [711 | 1000] LR: 0.000033\n",
      "Train | 16/16 | Loss:0.2154 | MainLoss:0.1779 | Alpha:0.4584 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:93.9733 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1752 | MainLoss:0.1752 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1154 | AUROC:0.9831\n",
      "Test | 123/16 | Loss:0.7307 | MainLoss:0.7307 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.6442 | AUROC:0.8210\n",
      "\n",
      "Epoch: [712 | 1000] LR: 0.000033\n",
      "Train | 16/16 | Loss:0.2095 | MainLoss:0.1719 | Alpha:0.4590 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.0000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1753 | MainLoss:0.1753 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.0897 | AUROC:0.9832\n",
      "Test | 123/16 | Loss:0.7289 | MainLoss:0.7289 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.7490 | AUROC:0.8208\n",
      "\n",
      "Epoch: [713 | 1000] LR: 0.000033\n",
      "Train | 16/16 | Loss:0.2254 | MainLoss:0.1879 | Alpha:0.4561 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:93.7333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1753 | MainLoss:0.1753 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1026 | AUROC:0.9833\n",
      "Test | 123/16 | Loss:0.7294 | MainLoss:0.7294 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.7097 | AUROC:0.8205\n",
      "\n",
      "Epoch: [714 | 1000] LR: 0.000033\n",
      "Train | 16/16 | Loss:0.2139 | MainLoss:0.1764 | Alpha:0.4595 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.5333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1753 | MainLoss:0.1753 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1026 | AUROC:0.9830\n",
      "Test | 123/16 | Loss:0.7292 | MainLoss:0.7292 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.7097 | AUROC:0.8206\n",
      "\n",
      "Epoch: [715 | 1000] LR: 0.000032\n",
      "Train | 16/16 | Loss:0.2150 | MainLoss:0.1774 | Alpha:0.4588 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1600 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1753 | MainLoss:0.1753 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1026 | AUROC:0.9834\n",
      "Test | 123/16 | Loss:0.7295 | MainLoss:0.7295 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.7195 | AUROC:0.8207\n",
      "\n",
      "Epoch: [716 | 1000] LR: 0.000032\n",
      "Train | 16/16 | Loss:0.2130 | MainLoss:0.1755 | Alpha:0.4602 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1067 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1753 | MainLoss:0.1753 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1026 | AUROC:0.9833\n",
      "Test | 123/16 | Loss:0.7294 | MainLoss:0.7294 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.6933 | AUROC:0.8205\n",
      "\n",
      "Epoch: [717 | 1000] LR: 0.000032\n",
      "Train | 16/16 | Loss:0.2196 | MainLoss:0.1821 | Alpha:0.4584 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:93.8667 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1752 | MainLoss:0.1752 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1026 | AUROC:0.9835\n",
      "Test | 123/16 | Loss:0.7293 | MainLoss:0.7293 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.6966 | AUROC:0.8213\n",
      "\n",
      "Epoch: [718 | 1000] LR: 0.000032\n",
      "Train | 16/16 | Loss:0.2070 | MainLoss:0.1694 | Alpha:0.4597 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.2667 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1753 | MainLoss:0.1753 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1026 | AUROC:0.9831\n",
      "Test | 123/16 | Loss:0.7297 | MainLoss:0.7297 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.6999 | AUROC:0.8204\n",
      "\n",
      "Epoch: [719 | 1000] LR: 0.000032\n",
      "Train | 16/16 | Loss:0.2017 | MainLoss:0.1641 | Alpha:0.4616 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.5600 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1753 | MainLoss:0.1753 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1026 | AUROC:0.9832\n",
      "Test | 123/16 | Loss:0.7306 | MainLoss:0.7306 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.7031 | AUROC:0.8204\n",
      "\n",
      "Epoch: [720 | 1000] LR: 0.000031\n",
      "Train | 16/16 | Loss:0.2214 | MainLoss:0.1838 | Alpha:0.4573 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:93.8133 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1753 | MainLoss:0.1753 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1026 | AUROC:0.9832\n",
      "Test | 123/16 | Loss:0.7295 | MainLoss:0.7295 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.7425 | AUROC:0.8207\n",
      "\n",
      "Epoch: [721 | 1000] LR: 0.000031\n",
      "Train | 16/16 | Loss:0.2128 | MainLoss:0.1752 | Alpha:0.4595 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.3733 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1755 | MainLoss:0.1755 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1282 | AUROC:0.9833\n",
      "Test | 123/16 | Loss:0.7270 | MainLoss:0.7270 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.8146 | AUROC:0.8213\n",
      "\n",
      "Epoch: [722 | 1000] LR: 0.000031\n",
      "Train | 16/16 | Loss:0.2154 | MainLoss:0.1778 | Alpha:0.4598 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:93.8400 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1752 | MainLoss:0.1752 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1154 | AUROC:0.9834\n",
      "Test | 123/16 | Loss:0.7297 | MainLoss:0.7297 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.6638 | AUROC:0.8211\n",
      "\n",
      "Epoch: [723 | 1000] LR: 0.000031\n",
      "Train | 16/16 | Loss:0.2076 | MainLoss:0.1700 | Alpha:0.4607 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.4800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1753 | MainLoss:0.1753 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1026 | AUROC:0.9834\n",
      "Test | 123/16 | Loss:0.7287 | MainLoss:0.7287 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.7064 | AUROC:0.8210\n",
      "\n",
      "Epoch: [724 | 1000] LR: 0.000031\n",
      "Train | 16/16 | Loss:0.2116 | MainLoss:0.1740 | Alpha:0.4595 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.0267 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1753 | MainLoss:0.1753 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1154 | AUROC:0.9832\n",
      "Test | 123/16 | Loss:0.7266 | MainLoss:0.7266 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.7556 | AUROC:0.8222\n",
      "\n",
      "Epoch: [725 | 1000] LR: 0.000030\n",
      "Train | 16/16 | Loss:0.2097 | MainLoss:0.1722 | Alpha:0.4597 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.3467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1753 | MainLoss:0.1753 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1154 | AUROC:0.9832\n",
      "Test | 123/16 | Loss:0.7267 | MainLoss:0.7267 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.7589 | AUROC:0.8218\n",
      "\n",
      "Epoch: [726 | 1000] LR: 0.000030\n",
      "Train | 16/16 | Loss:0.2188 | MainLoss:0.1812 | Alpha:0.4571 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:93.3333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1752 | MainLoss:0.1752 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1026 | AUROC:0.9835\n",
      "Test | 123/16 | Loss:0.7270 | MainLoss:0.7270 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.6999 | AUROC:0.8221\n",
      "\n",
      "Epoch: [727 | 1000] LR: 0.000030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 16/16 | Loss:0.2212 | MainLoss:0.1837 | Alpha:0.4565 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:93.9733 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1753 | MainLoss:0.1753 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.0897 | AUROC:0.9833\n",
      "Test | 123/16 | Loss:0.7259 | MainLoss:0.7259 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.7261 | AUROC:0.8229\n",
      "\n",
      "Epoch: [728 | 1000] LR: 0.000030\n",
      "Train | 16/16 | Loss:0.2036 | MainLoss:0.1660 | Alpha:0.4610 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.2133 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1752 | MainLoss:0.1752 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1026 | AUROC:0.9833\n",
      "Test | 123/16 | Loss:0.7275 | MainLoss:0.7275 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.7064 | AUROC:0.8219\n",
      "\n",
      "Epoch: [729 | 1000] LR: 0.000030\n",
      "Train | 16/16 | Loss:0.2224 | MainLoss:0.1848 | Alpha:0.4570 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:93.7333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1753 | MainLoss:0.1753 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.0897 | AUROC:0.9833\n",
      "Test | 123/16 | Loss:0.7267 | MainLoss:0.7267 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.7392 | AUROC:0.8224\n",
      "\n",
      "Epoch: [730 | 1000] LR: 0.000029\n",
      "Train | 16/16 | Loss:0.2150 | MainLoss:0.1775 | Alpha:0.4586 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:93.8133 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1754 | MainLoss:0.1754 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1410 | AUROC:0.9835\n",
      "Test | 123/16 | Loss:0.7261 | MainLoss:0.7261 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.7785 | AUROC:0.8219\n",
      "\n",
      "Epoch: [731 | 1000] LR: 0.000029\n",
      "Train | 16/16 | Loss:0.2146 | MainLoss:0.1771 | Alpha:0.4595 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1067 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1753 | MainLoss:0.1753 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1154 | AUROC:0.9835\n",
      "Test | 123/16 | Loss:0.7273 | MainLoss:0.7273 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.7621 | AUROC:0.8216\n",
      "\n",
      "Epoch: [732 | 1000] LR: 0.000029\n",
      "Train | 16/16 | Loss:0.2101 | MainLoss:0.1726 | Alpha:0.4591 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.0267 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1752 | MainLoss:0.1752 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1026 | AUROC:0.9832\n",
      "Test | 123/16 | Loss:0.7287 | MainLoss:0.7287 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.7097 | AUROC:0.8212\n",
      "\n",
      "Epoch: [733 | 1000] LR: 0.000029\n",
      "Train | 16/16 | Loss:0.2060 | MainLoss:0.1685 | Alpha:0.4619 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.3733 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1753 | MainLoss:0.1753 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.0897 | AUROC:0.9831\n",
      "Test | 123/16 | Loss:0.7286 | MainLoss:0.7286 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.7326 | AUROC:0.8211\n",
      "\n",
      "Epoch: [734 | 1000] LR: 0.000029\n",
      "Train | 16/16 | Loss:0.1973 | MainLoss:0.1598 | Alpha:0.4633 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.8267 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1753 | MainLoss:0.1753 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1154 | AUROC:0.9835\n",
      "Test | 123/16 | Loss:0.7299 | MainLoss:0.7299 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.7392 | AUROC:0.8206\n",
      "\n",
      "Epoch: [735 | 1000] LR: 0.000028\n",
      "Train | 16/16 | Loss:0.2065 | MainLoss:0.1689 | Alpha:0.4606 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.4000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1755 | MainLoss:0.1755 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1282 | AUROC:0.9831\n",
      "Test | 123/16 | Loss:0.7289 | MainLoss:0.7289 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.8244 | AUROC:0.8196\n",
      "\n",
      "Epoch: [736 | 1000] LR: 0.000028\n",
      "Train | 16/16 | Loss:0.2090 | MainLoss:0.1714 | Alpha:0.4597 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1867 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1754 | MainLoss:0.1754 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1282 | AUROC:0.9832\n",
      "Test | 123/16 | Loss:0.7296 | MainLoss:0.7296 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.7818 | AUROC:0.8198\n",
      "\n",
      "Epoch: [737 | 1000] LR: 0.000028\n",
      "Train | 16/16 | Loss:0.2100 | MainLoss:0.1724 | Alpha:0.4591 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.3467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1755 | MainLoss:0.1755 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1282 | AUROC:0.9832\n",
      "Test | 123/16 | Loss:0.7289 | MainLoss:0.7289 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.8244 | AUROC:0.8205\n",
      "\n",
      "Epoch: [738 | 1000] LR: 0.000028\n",
      "Train | 16/16 | Loss:0.2182 | MainLoss:0.1806 | Alpha:0.4586 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:93.6000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1755 | MainLoss:0.1755 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1282 | AUROC:0.9836\n",
      "Test | 123/16 | Loss:0.7275 | MainLoss:0.7275 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.8211 | AUROC:0.8207\n",
      "\n",
      "Epoch: [739 | 1000] LR: 0.000028\n",
      "Train | 16/16 | Loss:0.2228 | MainLoss:0.1853 | Alpha:0.4569 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:93.7067 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1755 | MainLoss:0.1755 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1154 | AUROC:0.9832\n",
      "Test | 123/16 | Loss:0.7263 | MainLoss:0.7263 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.8309 | AUROC:0.8213\n",
      "\n",
      "Epoch: [740 | 1000] LR: 0.000027\n",
      "Train | 16/16 | Loss:0.2244 | MainLoss:0.1869 | Alpha:0.4568 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:93.5467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1754 | MainLoss:0.1754 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1282 | AUROC:0.9833\n",
      "Test | 123/16 | Loss:0.7272 | MainLoss:0.7272 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.7785 | AUROC:0.8218\n",
      "\n",
      "Epoch: [741 | 1000] LR: 0.000027\n",
      "Train | 16/16 | Loss:0.2280 | MainLoss:0.1905 | Alpha:0.4556 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:93.6533 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1753 | MainLoss:0.1753 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1282 | AUROC:0.9829\n",
      "Test | 123/16 | Loss:0.7260 | MainLoss:0.7260 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.7687 | AUROC:0.8220\n",
      "\n",
      "Epoch: [742 | 1000] LR: 0.000027\n",
      "Train | 16/16 | Loss:0.2213 | MainLoss:0.1837 | Alpha:0.4573 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:93.7333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1752 | MainLoss:0.1752 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1026 | AUROC:0.9834\n",
      "Test | 123/16 | Loss:0.7267 | MainLoss:0.7267 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.7064 | AUROC:0.8230\n",
      "\n",
      "Epoch: [743 | 1000] LR: 0.000027\n",
      "Train | 16/16 | Loss:0.2235 | MainLoss:0.1859 | Alpha:0.4567 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:93.5733 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1751 | MainLoss:0.1751 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1154 | AUROC:0.9837\n",
      "Test | 123/16 | Loss:0.7266 | MainLoss:0.7266 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.6999 | AUROC:0.8231\n",
      "\n",
      "Epoch: [744 | 1000] LR: 0.000027\n",
      "Train | 16/16 | Loss:0.2174 | MainLoss:0.1798 | Alpha:0.4591 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:93.6533 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1749 | MainLoss:0.1749 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1538 | AUROC:0.9834\n",
      "Test | 123/16 | Loss:0.7278 | MainLoss:0.7278 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.6180 | AUROC:0.8226\n",
      "\n",
      "Epoch: [745 | 1000] LR: 0.000027\n",
      "Train | 16/16 | Loss:0.2247 | MainLoss:0.1872 | Alpha:0.4569 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:93.3867 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1749 | MainLoss:0.1749 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1538 | AUROC:0.9836\n",
      "Test | 123/16 | Loss:0.7270 | MainLoss:0.7270 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.6212 | AUROC:0.8234\n",
      "\n",
      "Epoch: [746 | 1000] LR: 0.000026\n",
      "Train | 16/16 | Loss:0.2162 | MainLoss:0.1786 | Alpha:0.4585 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:93.5467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1750 | MainLoss:0.1750 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1282 | AUROC:0.9837\n",
      "Test | 123/16 | Loss:0.7250 | MainLoss:0.7250 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.6573 | AUROC:0.8238\n",
      "\n",
      "Epoch: [747 | 1000] LR: 0.000026\n",
      "Train | 16/16 | Loss:0.2160 | MainLoss:0.1785 | Alpha:0.4580 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:93.8400 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1749 | MainLoss:0.1749 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1538 | AUROC:0.9836\n",
      "Test | 123/16 | Loss:0.7261 | MainLoss:0.7261 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.6212 | AUROC:0.8236\n",
      "\n",
      "Epoch: [748 | 1000] LR: 0.000026\n",
      "Train | 16/16 | Loss:0.1990 | MainLoss:0.1615 | Alpha:0.4625 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:95.0133 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1750 | MainLoss:0.1750 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:94.1410 | AUROC:0.9836\n",
      "Test | 123/16 | Loss:0.7269 | MainLoss:0.7269 | SPLoss:0.0000 | CLSLoss:0.0376 | top1:67.6507 | AUROC:0.8226\n",
      "\n",
      "Epoch: [749 | 1000] LR: 0.000026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 16/16 | Loss:0.2241 | MainLoss:0.1865 | Alpha:0.4568 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:93.6267 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1751 | MainLoss:0.1751 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1154 | AUROC:0.9834\n",
      "Test | 123/16 | Loss:0.7248 | MainLoss:0.7248 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.7097 | AUROC:0.8235\n",
      "\n",
      "Epoch: [750 | 1000] LR: 0.000026\n",
      "Train | 16/16 | Loss:0.2261 | MainLoss:0.1886 | Alpha:0.4559 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:93.3600 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1752 | MainLoss:0.1752 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1282 | AUROC:0.9836\n",
      "Test | 123/16 | Loss:0.7223 | MainLoss:0.7223 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.7687 | AUROC:0.8240\n",
      "\n",
      "Epoch: [751 | 1000] LR: 0.000025\n",
      "Train | 16/16 | Loss:0.2166 | MainLoss:0.1791 | Alpha:0.4588 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:93.9467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1752 | MainLoss:0.1752 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.0897 | AUROC:0.9840\n",
      "Test | 123/16 | Loss:0.7225 | MainLoss:0.7225 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.7425 | AUROC:0.8240\n",
      "\n",
      "Epoch: [752 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.2259 | MainLoss:0.1883 | Alpha:0.4553 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:93.3867 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1752 | MainLoss:0.1752 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.0897 | AUROC:0.9835\n",
      "Test | 123/16 | Loss:0.7224 | MainLoss:0.7224 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.7425 | AUROC:0.8239\n",
      "\n",
      "Epoch: [753 | 1000] LR: 0.000003\n",
      "Train | 16/16 | Loss:0.2218 | MainLoss:0.1843 | Alpha:0.4564 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.0267 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1752 | MainLoss:0.1752 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.0897 | AUROC:0.9837\n",
      "Test | 123/16 | Loss:0.7224 | MainLoss:0.7224 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.7425 | AUROC:0.8242\n",
      "\n",
      "Epoch: [754 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.2168 | MainLoss:0.1793 | Alpha:0.4573 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1867 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1752 | MainLoss:0.1752 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1026 | AUROC:0.9835\n",
      "Test | 123/16 | Loss:0.7222 | MainLoss:0.7222 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.7589 | AUROC:0.8242\n",
      "\n",
      "Epoch: [755 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.2031 | MainLoss:0.1655 | Alpha:0.4620 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.6133 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1752 | MainLoss:0.1752 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.0897 | AUROC:0.9836\n",
      "Test | 123/16 | Loss:0.7224 | MainLoss:0.7224 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.7457 | AUROC:0.8244\n",
      "\n",
      "Epoch: [756 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.2200 | MainLoss:0.1824 | Alpha:0.4569 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:93.7600 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1751 | MainLoss:0.1751 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.0897 | AUROC:0.9836\n",
      "Test | 123/16 | Loss:0.7227 | MainLoss:0.7227 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.7294 | AUROC:0.8237\n",
      "\n",
      "Epoch: [757 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.2099 | MainLoss:0.1723 | Alpha:0.4598 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.3467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1751 | MainLoss:0.1751 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.0897 | AUROC:0.9836\n",
      "Test | 123/16 | Loss:0.7227 | MainLoss:0.7227 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.7359 | AUROC:0.8244\n",
      "\n",
      "Epoch: [758 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.2247 | MainLoss:0.1871 | Alpha:0.4568 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:93.4133 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1751 | MainLoss:0.1751 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.0897 | AUROC:0.9837\n",
      "Test | 123/16 | Loss:0.7227 | MainLoss:0.7227 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.7392 | AUROC:0.8242\n",
      "\n",
      "Epoch: [759 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.2289 | MainLoss:0.1913 | Alpha:0.4546 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:93.4400 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1752 | MainLoss:0.1752 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.0897 | AUROC:0.9836\n",
      "Test | 123/16 | Loss:0.7225 | MainLoss:0.7225 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.7392 | AUROC:0.8243\n",
      "\n",
      "Epoch: [760 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.2149 | MainLoss:0.1774 | Alpha:0.4595 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.4533 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1752 | MainLoss:0.1752 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.0897 | AUROC:0.9836\n",
      "Test | 123/16 | Loss:0.7222 | MainLoss:0.7222 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.7523 | AUROC:0.8241\n",
      "\n",
      "Epoch: [761 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.2183 | MainLoss:0.1807 | Alpha:0.4578 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:93.3333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1752 | MainLoss:0.1752 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.0897 | AUROC:0.9837\n",
      "Test | 123/16 | Loss:0.7223 | MainLoss:0.7223 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.7392 | AUROC:0.8244\n",
      "\n",
      "Epoch: [762 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.2045 | MainLoss:0.1670 | Alpha:0.4617 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.8000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1752 | MainLoss:0.1752 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.0897 | AUROC:0.9834\n",
      "Test | 123/16 | Loss:0.7223 | MainLoss:0.7223 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.7425 | AUROC:0.8241\n",
      "\n",
      "Epoch: [763 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.2147 | MainLoss:0.1772 | Alpha:0.4587 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.0533 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1752 | MainLoss:0.1752 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.0897 | AUROC:0.9833\n",
      "Test | 123/16 | Loss:0.7223 | MainLoss:0.7223 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.7457 | AUROC:0.8244\n",
      "\n",
      "Epoch: [764 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.2218 | MainLoss:0.1843 | Alpha:0.4573 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:93.7600 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1752 | MainLoss:0.1752 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.0897 | AUROC:0.9837\n",
      "Test | 123/16 | Loss:0.7223 | MainLoss:0.7223 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.7490 | AUROC:0.8243\n",
      "\n",
      "Epoch: [765 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.2259 | MainLoss:0.1884 | Alpha:0.4562 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:93.5200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1752 | MainLoss:0.1752 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.0897 | AUROC:0.9837\n",
      "Test | 123/16 | Loss:0.7222 | MainLoss:0.7222 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.7523 | AUROC:0.8245\n",
      "\n",
      "Epoch: [766 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.2111 | MainLoss:0.1735 | Alpha:0.4589 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1752 | MainLoss:0.1752 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1026 | AUROC:0.9834\n",
      "Test | 123/16 | Loss:0.7221 | MainLoss:0.7221 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.7589 | AUROC:0.8245\n",
      "\n",
      "Epoch: [767 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.2214 | MainLoss:0.1838 | Alpha:0.4574 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:93.6000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1752 | MainLoss:0.1752 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1026 | AUROC:0.9834\n",
      "Test | 123/16 | Loss:0.7220 | MainLoss:0.7220 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.7589 | AUROC:0.8244\n",
      "\n",
      "Epoch: [768 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.2112 | MainLoss:0.1737 | Alpha:0.4606 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1600 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1752 | MainLoss:0.1752 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.0897 | AUROC:0.9834\n",
      "Test | 123/16 | Loss:0.7224 | MainLoss:0.7224 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.7359 | AUROC:0.8246\n",
      "\n",
      "Epoch: [769 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.2214 | MainLoss:0.1838 | Alpha:0.4578 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:93.8400 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1751 | MainLoss:0.1751 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.0897 | AUROC:0.9838\n",
      "Test | 123/16 | Loss:0.7226 | MainLoss:0.7226 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.7326 | AUROC:0.8238\n",
      "\n",
      "Epoch: [770 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.2192 | MainLoss:0.1817 | Alpha:0.4571 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1600 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1752 | MainLoss:0.1752 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.0897 | AUROC:0.9835\n",
      "Test | 123/16 | Loss:0.7223 | MainLoss:0.7223 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.7490 | AUROC:0.8242\n",
      "\n",
      "Epoch: [771 | 1000] LR: 0.000002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 16/16 | Loss:0.2079 | MainLoss:0.1703 | Alpha:0.4596 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.0800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1752 | MainLoss:0.1752 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.0897 | AUROC:0.9836\n",
      "Test | 123/16 | Loss:0.7224 | MainLoss:0.7224 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.7523 | AUROC:0.8241\n",
      "\n",
      "Epoch: [772 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.2112 | MainLoss:0.1737 | Alpha:0.4592 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.3200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1752 | MainLoss:0.1752 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.0897 | AUROC:0.9837\n",
      "Test | 123/16 | Loss:0.7223 | MainLoss:0.7223 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.7523 | AUROC:0.8240\n",
      "\n",
      "Epoch: [773 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.2044 | MainLoss:0.1668 | Alpha:0.4617 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.5333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1752 | MainLoss:0.1752 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.0897 | AUROC:0.9832\n",
      "Test | 123/16 | Loss:0.7225 | MainLoss:0.7225 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.7490 | AUROC:0.8240\n",
      "\n",
      "Epoch: [774 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.2164 | MainLoss:0.1788 | Alpha:0.4584 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:93.7067 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1752 | MainLoss:0.1752 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.0897 | AUROC:0.9835\n",
      "Test | 123/16 | Loss:0.7225 | MainLoss:0.7225 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.7490 | AUROC:0.8239\n",
      "\n",
      "Epoch: [775 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.2124 | MainLoss:0.1749 | Alpha:0.4601 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.6133 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1752 | MainLoss:0.1752 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.0897 | AUROC:0.9837\n",
      "Test | 123/16 | Loss:0.7224 | MainLoss:0.7224 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.7490 | AUROC:0.8241\n",
      "\n",
      "Epoch: [776 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.2167 | MainLoss:0.1791 | Alpha:0.4584 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:93.9733 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1752 | MainLoss:0.1752 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1026 | AUROC:0.9835\n",
      "Test | 123/16 | Loss:0.7224 | MainLoss:0.7224 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.7556 | AUROC:0.8245\n",
      "\n",
      "Epoch: [777 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.2149 | MainLoss:0.1773 | Alpha:0.4583 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1600 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1752 | MainLoss:0.1752 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1026 | AUROC:0.9836\n",
      "Test | 123/16 | Loss:0.7222 | MainLoss:0.7222 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.7556 | AUROC:0.8244\n",
      "\n",
      "Epoch: [778 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.2178 | MainLoss:0.1803 | Alpha:0.4584 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:93.9200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1752 | MainLoss:0.1752 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1026 | AUROC:0.9839\n",
      "Test | 123/16 | Loss:0.7222 | MainLoss:0.7222 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.7621 | AUROC:0.8242\n",
      "\n",
      "Epoch: [779 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.2118 | MainLoss:0.1743 | Alpha:0.4584 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1752 | MainLoss:0.1752 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1026 | AUROC:0.9838\n",
      "Test | 123/16 | Loss:0.7222 | MainLoss:0.7222 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.7621 | AUROC:0.8242\n",
      "\n",
      "Epoch: [780 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.2200 | MainLoss:0.1825 | Alpha:0.4579 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:93.7333 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1752 | MainLoss:0.1752 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1026 | AUROC:0.9836\n",
      "Test | 123/16 | Loss:0.7221 | MainLoss:0.7221 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.7621 | AUROC:0.8240\n",
      "\n",
      "Epoch: [781 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.2179 | MainLoss:0.1804 | Alpha:0.4579 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.0800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1752 | MainLoss:0.1752 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1026 | AUROC:0.9837\n",
      "Test | 123/16 | Loss:0.7221 | MainLoss:0.7221 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.7589 | AUROC:0.8241\n",
      "\n",
      "Epoch: [782 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.2179 | MainLoss:0.1803 | Alpha:0.4583 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:93.5200 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1752 | MainLoss:0.1752 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1026 | AUROC:0.9836\n",
      "Test | 123/16 | Loss:0.7222 | MainLoss:0.7222 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.7589 | AUROC:0.8243\n",
      "\n",
      "Epoch: [783 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.2195 | MainLoss:0.1819 | Alpha:0.4572 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:93.6000 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1752 | MainLoss:0.1752 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1026 | AUROC:0.9836\n",
      "Test | 123/16 | Loss:0.7222 | MainLoss:0.7222 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.7556 | AUROC:0.8245\n",
      "\n",
      "Epoch: [784 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.2321 | MainLoss:0.1945 | Alpha:0.4549 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:93.5467 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1752 | MainLoss:0.1752 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1026 | AUROC:0.9837\n",
      "Test | 123/16 | Loss:0.7220 | MainLoss:0.7220 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.7621 | AUROC:0.8241\n",
      "\n",
      "Epoch: [785 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.2182 | MainLoss:0.1806 | Alpha:0.4582 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.4267 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1752 | MainLoss:0.1752 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1154 | AUROC:0.9837\n",
      "Test | 123/16 | Loss:0.7219 | MainLoss:0.7219 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.7687 | AUROC:0.8245\n",
      "\n",
      "Epoch: [786 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.2073 | MainLoss:0.1698 | Alpha:0.4603 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.2133 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1752 | MainLoss:0.1752 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1154 | AUROC:0.9832\n",
      "Test | 123/16 | Loss:0.7219 | MainLoss:0.7219 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.7654 | AUROC:0.8245\n",
      "\n",
      "Epoch: [787 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.2042 | MainLoss:0.1666 | Alpha:0.4610 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.5867 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1752 | MainLoss:0.1752 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1154 | AUROC:0.9836\n",
      "Test | 123/16 | Loss:0.7219 | MainLoss:0.7219 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.7654 | AUROC:0.8243\n",
      "\n",
      "Epoch: [788 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.2172 | MainLoss:0.1797 | Alpha:0.4578 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:93.6800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1752 | MainLoss:0.1752 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1154 | AUROC:0.9833\n",
      "Test | 123/16 | Loss:0.7218 | MainLoss:0.7218 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:67.7654 | AUROC:0.8242\n",
      "\n",
      "Epoch: [789 | 1000] LR: 0.000002\n",
      "Train | 16/16 | Loss:0.2101 | MainLoss:0.1725 | Alpha:0.4597 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.0800 | AUROC:0.0000\n",
      "Test | 32/16 | Loss:0.1752 | MainLoss:0.1752 | SPLoss:0.0000 | CLSLoss:0.0375 | top1:94.1154 | AUROC:0.9838\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(start_epoch, epochs):\n",
    "    state['lr'] = optimizer.state_dict()['param_groups'][0]['lr']\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "    print('\\nEpoch: [%d | %d] LR: %f' % (epoch + 1, epochs, state['lr']))\n",
    "    \n",
    "    train_loss, train_acc, train_auroc = train(train_loader, teacher_model, student_model, criterion, optimizer, epoch, use_cuda)\n",
    "    test_loss, test_acc, test_auroc = test(val_target_loader, student_model, criterion, epoch, use_cuda)\n",
    "    source_loss, source_acc, source_auroc = test(val_source_loader, student_model, criterion, epoch, use_cuda)\n",
    "\n",
    "\n",
    "    logger.append([state['lr'], train_loss, test_loss,  source_loss, train_acc, test_acc,source_acc, train_auroc, test_auroc, source_auroc])\n",
    "    is_best = test_auroc+source_auroc > best_acc\n",
    "    best_acc = max(test_auroc+source_auroc, best_acc)\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'state_dict' : student_model.state_dict(),\n",
    "        'acc': test_acc,\n",
    "        'best_acc': best_acc,\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    }, is_best, checkpoint=checkpoint)\n",
    "    scheduler_warmup.step()\n",
    "    \n",
    "    teacher_model.load_state_dict(student_model.state_dict())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
