{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from model_pytorch import EfficientNet\n",
    "from utils import Bar,Logger, AverageMeter, accuracy, mkdir_p, savefig\n",
    "from warmup_scheduler import GradualWarmupScheduler\n",
    "\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU device 0: True\n"
     ]
    }
   ],
   "source": [
    "# GPU Device\n",
    "gpu_id = 0\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(\"GPU device %d:\" %(gpu_id), use_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = '/media/data2/dataset/GAN_ImageData/StyleGAN_256/'\n",
    "target_dir = '/media/data2/dataset/GAN_ImageData/StarGAN_128/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained = './log/style1/128/b0/checkpoint.pth.tar'\n",
    "resume = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model_name = 'efficientnet-b0' # b0-b7 scale\n",
    "\n",
    "# Optimization\n",
    "num_classes = 2\n",
    "epochs = 5000\n",
    "start_epoch = 0\n",
    "train_batch = 32\n",
    "test_batch = 300\n",
    "lr = 0.04\n",
    "schedule = [1500, 3000]\n",
    "momentum = 0\n",
    "gamma = 0.1 # LR is multiplied by gamma on schedule\n",
    "\n",
    "# CheckPoint\n",
    "checkpoint = './log/style1/128/b0/to_star/l2sp_style1' # dir\n",
    "if not os.path.isdir(checkpoint):\n",
    "    os.makedirs(checkpoint)\n",
    "num_workers = 4\n",
    "\n",
    "# Seed\n",
    "manual_seed = 7\n",
    "random.seed(manual_seed)\n",
    "torch.cuda.manual_seed_all(manual_seed)\n",
    "\n",
    "# Image\n",
    "size = (128, 128)\n",
    "\n",
    "# sp\n",
    "alpha = 0.1\n",
    "beta = 0.1\n",
    "fc_name = 'fc.'\n",
    "\n",
    "best_acc = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {}\n",
    "state['num_classes'] = num_classes\n",
    "state['epochs'] = epochs\n",
    "state['start_epoch'] = start_epoch\n",
    "state['train_batch'] = train_batch\n",
    "state['test_batch'] = test_batch\n",
    "state['lr'] = lr\n",
    "state['schedule'] = schedule\n",
    "state['momentum'] = momentum\n",
    "state['gamma'] = gamma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join(target_dir, '100_shot_style1')\n",
    "val_target_dir = os.path.join(target_dir, 'validation')\n",
    "val_source_dir = os.path.join(source_dir, 'validation')\n",
    "\n",
    "train_aug = transforms.Compose([\n",
    "    transforms.RandomAffine(degrees=2, translate=(0.02, 0.02), scale=(0.98, 1.02), shear=2, fillcolor=(124,117,104)),\n",
    "    transforms.Resize(size),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomErasing(p=0.3, scale=(0.02, 0.10), ratio=(0.3, 3.3), value=0, inplace=True),\n",
    "])\n",
    "val_aug = transforms.Compose([\n",
    "    transforms.Resize(size),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# pin_memory : cuda pin memeory use\n",
    "train_loader = DataLoader(datasets.ImageFolder(train_dir, transform=train_aug),\n",
    "                          batch_size=train_batch, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "val_target_loader = DataLoader(datasets.ImageFolder(val_target_dir, val_aug),\n",
    "                       batch_size=test_batch, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "val_source_loader = DataLoader(datasets.ImageFolder(val_source_dir, val_aug),\n",
    "                       batch_size=test_batch, shuffle=True, num_workers=num_workers, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> using pre-trained model './log/style1/128/b0/checkpoint.pth.tar'\n"
     ]
    }
   ],
   "source": [
    "source_model = EfficientNet.from_name(model_name, num_classes=num_classes)\n",
    "model = EfficientNet.from_name(model_name, num_classes=num_classes, \n",
    "                               override_params={'dropout_rate':0.5})\n",
    "\n",
    "# Pre-trained\n",
    "if pretrained:\n",
    "    print(\"=> using pre-trained model '{}'\".format(pretrained))\n",
    "    source_model.load_state_dict(torch.load(pretrained)['state_dict'])\n",
    "    model.load_state_dict(torch.load(pretrained)['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Total params: 4.01M\n"
     ]
    }
   ],
   "source": [
    "source_model.to('cuda')\n",
    "model.to('cuda')\n",
    "cudnn.benchmark = True\n",
    "print('    Total params: %.2fM' % (sum(p.numel() for p in model.parameters())/1000000.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EfficientNet(\n",
       "  (_conv_stem): Conv2dStaticSamePadding(\n",
       "    3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
       "    (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "  )\n",
       "  (_bn0): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "  (_blocks): ModuleList(\n",
       "    (0): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        32, 32, kernel_size=(3, 3), stride=[1, 1], groups=32, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        32, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        8, 32, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): GroupNorm(4, 16, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (1): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): GroupNorm(24, 96, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        96, 96, kernel_size=(3, 3), stride=[2, 2], groups=96, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): GroupNorm(24, 96, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        96, 4, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        4, 96, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): GroupNorm(6, 24, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (2): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): GroupNorm(36, 144, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): GroupNorm(36, 144, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): GroupNorm(6, 24, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (3): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): GroupNorm(36, 144, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        144, 144, kernel_size=(5, 5), stride=[2, 2], groups=144, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): GroupNorm(36, 144, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): GroupNorm(10, 40, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (4): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): GroupNorm(60, 240, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        240, 240, kernel_size=(5, 5), stride=(1, 1), groups=240, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): GroupNorm(60, 240, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): GroupNorm(10, 40, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (5): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): GroupNorm(60, 240, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        240, 240, kernel_size=(3, 3), stride=[2, 2], groups=240, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): GroupNorm(60, 240, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): GroupNorm(20, 80, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (6): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): GroupNorm(120, 480, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): GroupNorm(120, 480, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): GroupNorm(20, 80, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (7): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): GroupNorm(120, 480, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): GroupNorm(120, 480, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): GroupNorm(20, 80, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (8): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): GroupNorm(120, 480, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        480, 480, kernel_size=(5, 5), stride=[1, 1], groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): GroupNorm(120, 480, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): GroupNorm(28, 112, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (9): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): GroupNorm(168, 672, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): GroupNorm(168, 672, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): GroupNorm(28, 112, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (10): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): GroupNorm(168, 672, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): GroupNorm(168, 672, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): GroupNorm(28, 112, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (11): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): GroupNorm(168, 672, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5), stride=[2, 2], groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): GroupNorm(168, 672, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): GroupNorm(48, 192, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (12): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): GroupNorm(288, 1152, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): GroupNorm(288, 1152, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): GroupNorm(48, 192, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (13): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): GroupNorm(288, 1152, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): GroupNorm(288, 1152, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): GroupNorm(48, 192, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (14): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): GroupNorm(288, 1152, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): GroupNorm(288, 1152, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): GroupNorm(48, 192, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (15): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): GroupNorm(288, 1152, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(3, 3), stride=[1, 1], groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): GroupNorm(288, 1152, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): GroupNorm(80, 320, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "  )\n",
       "  (_conv_head): Conv2dStaticSamePadding(\n",
       "    320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "    (static_padding): Identity()\n",
       "  )\n",
       "  (_bn1): GroupNorm(320, 1280, eps=1e-05, affine=True)\n",
       "  (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n",
       "  (_dropout): Dropout(p=0.2, inplace=False)\n",
       "  (_fc): Linear(in_features=1280, out_features=2, bias=True)\n",
       "  (_swish): MemoryEfficientSwish()\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for param in source_model.parameters():\n",
    "    param.requires_grad = False\n",
    "source_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_model_weights = {}\n",
    "for name, param in source_model.named_parameters():\n",
    "    source_model_weights[name] = param.detach()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_cls(model):\n",
    "    l2_cls = torch.tensor(0.).cuda()\n",
    "    for name, param in model.named_parameters():\n",
    "        if name.startswith(fc_name):\n",
    "            l2_cls += 0.5 * torch.norm(param) ** 2\n",
    "    return l2_cls\n",
    "\n",
    "def reg_l2sp(model):\n",
    "    sp_loss = torch.tensor(0.).cuda()\n",
    "    for name, param in model.named_parameters():\n",
    "        if not name.startswith(fc_name):\n",
    "            sp_loss += 0.5 * torch.norm(param - source_model_weights[name]) ** 2\n",
    "    return sp_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "         ZeroPad2d-1          [-1, 3, 129, 129]               0\n",
      "Conv2dStaticSamePadding-2           [-1, 32, 64, 64]             864\n",
      "         GroupNorm-3           [-1, 32, 64, 64]              64\n",
      "MemoryEfficientSwish-4           [-1, 32, 64, 64]               0\n",
      "         ZeroPad2d-5           [-1, 32, 66, 66]               0\n",
      "Conv2dStaticSamePadding-6           [-1, 32, 64, 64]             288\n",
      "         GroupNorm-7           [-1, 32, 64, 64]              64\n",
      "MemoryEfficientSwish-8           [-1, 32, 64, 64]               0\n",
      "          Identity-9             [-1, 32, 1, 1]               0\n",
      "Conv2dStaticSamePadding-10              [-1, 8, 1, 1]             264\n",
      "MemoryEfficientSwish-11              [-1, 8, 1, 1]               0\n",
      "         Identity-12              [-1, 8, 1, 1]               0\n",
      "Conv2dStaticSamePadding-13             [-1, 32, 1, 1]             288\n",
      "         Identity-14           [-1, 32, 64, 64]               0\n",
      "Conv2dStaticSamePadding-15           [-1, 16, 64, 64]             512\n",
      "        GroupNorm-16           [-1, 16, 64, 64]              32\n",
      "      MBConvBlock-17           [-1, 16, 64, 64]               0\n",
      "         Identity-18           [-1, 16, 64, 64]               0\n",
      "Conv2dStaticSamePadding-19           [-1, 96, 64, 64]           1,536\n",
      "        GroupNorm-20           [-1, 96, 64, 64]             192\n",
      "MemoryEfficientSwish-21           [-1, 96, 64, 64]               0\n",
      "        ZeroPad2d-22           [-1, 96, 65, 65]               0\n",
      "Conv2dStaticSamePadding-23           [-1, 96, 32, 32]             864\n",
      "        GroupNorm-24           [-1, 96, 32, 32]             192\n",
      "MemoryEfficientSwish-25           [-1, 96, 32, 32]               0\n",
      "         Identity-26             [-1, 96, 1, 1]               0\n",
      "Conv2dStaticSamePadding-27              [-1, 4, 1, 1]             388\n",
      "MemoryEfficientSwish-28              [-1, 4, 1, 1]               0\n",
      "         Identity-29              [-1, 4, 1, 1]               0\n",
      "Conv2dStaticSamePadding-30             [-1, 96, 1, 1]             480\n",
      "         Identity-31           [-1, 96, 32, 32]               0\n",
      "Conv2dStaticSamePadding-32           [-1, 24, 32, 32]           2,304\n",
      "        GroupNorm-33           [-1, 24, 32, 32]              48\n",
      "      MBConvBlock-34           [-1, 24, 32, 32]               0\n",
      "         Identity-35           [-1, 24, 32, 32]               0\n",
      "Conv2dStaticSamePadding-36          [-1, 144, 32, 32]           3,456\n",
      "        GroupNorm-37          [-1, 144, 32, 32]             288\n",
      "MemoryEfficientSwish-38          [-1, 144, 32, 32]               0\n",
      "        ZeroPad2d-39          [-1, 144, 34, 34]               0\n",
      "Conv2dStaticSamePadding-40          [-1, 144, 32, 32]           1,296\n",
      "        GroupNorm-41          [-1, 144, 32, 32]             288\n",
      "MemoryEfficientSwish-42          [-1, 144, 32, 32]               0\n",
      "         Identity-43            [-1, 144, 1, 1]               0\n",
      "Conv2dStaticSamePadding-44              [-1, 6, 1, 1]             870\n",
      "MemoryEfficientSwish-45              [-1, 6, 1, 1]               0\n",
      "         Identity-46              [-1, 6, 1, 1]               0\n",
      "Conv2dStaticSamePadding-47            [-1, 144, 1, 1]           1,008\n",
      "         Identity-48          [-1, 144, 32, 32]               0\n",
      "Conv2dStaticSamePadding-49           [-1, 24, 32, 32]           3,456\n",
      "        GroupNorm-50           [-1, 24, 32, 32]              48\n",
      "      MBConvBlock-51           [-1, 24, 32, 32]               0\n",
      "         Identity-52           [-1, 24, 32, 32]               0\n",
      "Conv2dStaticSamePadding-53          [-1, 144, 32, 32]           3,456\n",
      "        GroupNorm-54          [-1, 144, 32, 32]             288\n",
      "MemoryEfficientSwish-55          [-1, 144, 32, 32]               0\n",
      "        ZeroPad2d-56          [-1, 144, 35, 35]               0\n",
      "Conv2dStaticSamePadding-57          [-1, 144, 16, 16]           3,600\n",
      "        GroupNorm-58          [-1, 144, 16, 16]             288\n",
      "MemoryEfficientSwish-59          [-1, 144, 16, 16]               0\n",
      "         Identity-60            [-1, 144, 1, 1]               0\n",
      "Conv2dStaticSamePadding-61              [-1, 6, 1, 1]             870\n",
      "MemoryEfficientSwish-62              [-1, 6, 1, 1]               0\n",
      "         Identity-63              [-1, 6, 1, 1]               0\n",
      "Conv2dStaticSamePadding-64            [-1, 144, 1, 1]           1,008\n",
      "         Identity-65          [-1, 144, 16, 16]               0\n",
      "Conv2dStaticSamePadding-66           [-1, 40, 16, 16]           5,760\n",
      "        GroupNorm-67           [-1, 40, 16, 16]              80\n",
      "      MBConvBlock-68           [-1, 40, 16, 16]               0\n",
      "         Identity-69           [-1, 40, 16, 16]               0\n",
      "Conv2dStaticSamePadding-70          [-1, 240, 16, 16]           9,600\n",
      "        GroupNorm-71          [-1, 240, 16, 16]             480\n",
      "MemoryEfficientSwish-72          [-1, 240, 16, 16]               0\n",
      "        ZeroPad2d-73          [-1, 240, 20, 20]               0\n",
      "Conv2dStaticSamePadding-74          [-1, 240, 16, 16]           6,000\n",
      "        GroupNorm-75          [-1, 240, 16, 16]             480\n",
      "MemoryEfficientSwish-76          [-1, 240, 16, 16]               0\n",
      "         Identity-77            [-1, 240, 1, 1]               0\n",
      "Conv2dStaticSamePadding-78             [-1, 10, 1, 1]           2,410\n",
      "MemoryEfficientSwish-79             [-1, 10, 1, 1]               0\n",
      "         Identity-80             [-1, 10, 1, 1]               0\n",
      "Conv2dStaticSamePadding-81            [-1, 240, 1, 1]           2,640\n",
      "         Identity-82          [-1, 240, 16, 16]               0\n",
      "Conv2dStaticSamePadding-83           [-1, 40, 16, 16]           9,600\n",
      "        GroupNorm-84           [-1, 40, 16, 16]              80\n",
      "      MBConvBlock-85           [-1, 40, 16, 16]               0\n",
      "         Identity-86           [-1, 40, 16, 16]               0\n",
      "Conv2dStaticSamePadding-87          [-1, 240, 16, 16]           9,600\n",
      "        GroupNorm-88          [-1, 240, 16, 16]             480\n",
      "MemoryEfficientSwish-89          [-1, 240, 16, 16]               0\n",
      "        ZeroPad2d-90          [-1, 240, 17, 17]               0\n",
      "Conv2dStaticSamePadding-91            [-1, 240, 8, 8]           2,160\n",
      "        GroupNorm-92            [-1, 240, 8, 8]             480\n",
      "MemoryEfficientSwish-93            [-1, 240, 8, 8]               0\n",
      "         Identity-94            [-1, 240, 1, 1]               0\n",
      "Conv2dStaticSamePadding-95             [-1, 10, 1, 1]           2,410\n",
      "MemoryEfficientSwish-96             [-1, 10, 1, 1]               0\n",
      "         Identity-97             [-1, 10, 1, 1]               0\n",
      "Conv2dStaticSamePadding-98            [-1, 240, 1, 1]           2,640\n",
      "         Identity-99            [-1, 240, 8, 8]               0\n",
      "Conv2dStaticSamePadding-100             [-1, 80, 8, 8]          19,200\n",
      "       GroupNorm-101             [-1, 80, 8, 8]             160\n",
      "     MBConvBlock-102             [-1, 80, 8, 8]               0\n",
      "        Identity-103             [-1, 80, 8, 8]               0\n",
      "Conv2dStaticSamePadding-104            [-1, 480, 8, 8]          38,400\n",
      "       GroupNorm-105            [-1, 480, 8, 8]             960\n",
      "MemoryEfficientSwish-106            [-1, 480, 8, 8]               0\n",
      "       ZeroPad2d-107          [-1, 480, 10, 10]               0\n",
      "Conv2dStaticSamePadding-108            [-1, 480, 8, 8]           4,320\n",
      "       GroupNorm-109            [-1, 480, 8, 8]             960\n",
      "MemoryEfficientSwish-110            [-1, 480, 8, 8]               0\n",
      "        Identity-111            [-1, 480, 1, 1]               0\n",
      "Conv2dStaticSamePadding-112             [-1, 20, 1, 1]           9,620\n",
      "MemoryEfficientSwish-113             [-1, 20, 1, 1]               0\n",
      "        Identity-114             [-1, 20, 1, 1]               0\n",
      "Conv2dStaticSamePadding-115            [-1, 480, 1, 1]          10,080\n",
      "        Identity-116            [-1, 480, 8, 8]               0\n",
      "Conv2dStaticSamePadding-117             [-1, 80, 8, 8]          38,400\n",
      "       GroupNorm-118             [-1, 80, 8, 8]             160\n",
      "     MBConvBlock-119             [-1, 80, 8, 8]               0\n",
      "        Identity-120             [-1, 80, 8, 8]               0\n",
      "Conv2dStaticSamePadding-121            [-1, 480, 8, 8]          38,400\n",
      "       GroupNorm-122            [-1, 480, 8, 8]             960\n",
      "MemoryEfficientSwish-123            [-1, 480, 8, 8]               0\n",
      "       ZeroPad2d-124          [-1, 480, 10, 10]               0\n",
      "Conv2dStaticSamePadding-125            [-1, 480, 8, 8]           4,320\n",
      "       GroupNorm-126            [-1, 480, 8, 8]             960\n",
      "MemoryEfficientSwish-127            [-1, 480, 8, 8]               0\n",
      "        Identity-128            [-1, 480, 1, 1]               0\n",
      "Conv2dStaticSamePadding-129             [-1, 20, 1, 1]           9,620\n",
      "MemoryEfficientSwish-130             [-1, 20, 1, 1]               0\n",
      "        Identity-131             [-1, 20, 1, 1]               0\n",
      "Conv2dStaticSamePadding-132            [-1, 480, 1, 1]          10,080\n",
      "        Identity-133            [-1, 480, 8, 8]               0\n",
      "Conv2dStaticSamePadding-134             [-1, 80, 8, 8]          38,400\n",
      "       GroupNorm-135             [-1, 80, 8, 8]             160\n",
      "     MBConvBlock-136             [-1, 80, 8, 8]               0\n",
      "        Identity-137             [-1, 80, 8, 8]               0\n",
      "Conv2dStaticSamePadding-138            [-1, 480, 8, 8]          38,400\n",
      "       GroupNorm-139            [-1, 480, 8, 8]             960\n",
      "MemoryEfficientSwish-140            [-1, 480, 8, 8]               0\n",
      "       ZeroPad2d-141          [-1, 480, 12, 12]               0\n",
      "Conv2dStaticSamePadding-142            [-1, 480, 8, 8]          12,000\n",
      "       GroupNorm-143            [-1, 480, 8, 8]             960\n",
      "MemoryEfficientSwish-144            [-1, 480, 8, 8]               0\n",
      "        Identity-145            [-1, 480, 1, 1]               0\n",
      "Conv2dStaticSamePadding-146             [-1, 20, 1, 1]           9,620\n",
      "MemoryEfficientSwish-147             [-1, 20, 1, 1]               0\n",
      "        Identity-148             [-1, 20, 1, 1]               0\n",
      "Conv2dStaticSamePadding-149            [-1, 480, 1, 1]          10,080\n",
      "        Identity-150            [-1, 480, 8, 8]               0\n",
      "Conv2dStaticSamePadding-151            [-1, 112, 8, 8]          53,760\n",
      "       GroupNorm-152            [-1, 112, 8, 8]             224\n",
      "     MBConvBlock-153            [-1, 112, 8, 8]               0\n",
      "        Identity-154            [-1, 112, 8, 8]               0\n",
      "Conv2dStaticSamePadding-155            [-1, 672, 8, 8]          75,264\n",
      "       GroupNorm-156            [-1, 672, 8, 8]           1,344\n",
      "MemoryEfficientSwish-157            [-1, 672, 8, 8]               0\n",
      "       ZeroPad2d-158          [-1, 672, 12, 12]               0\n",
      "Conv2dStaticSamePadding-159            [-1, 672, 8, 8]          16,800\n",
      "       GroupNorm-160            [-1, 672, 8, 8]           1,344\n",
      "MemoryEfficientSwish-161            [-1, 672, 8, 8]               0\n",
      "        Identity-162            [-1, 672, 1, 1]               0\n",
      "Conv2dStaticSamePadding-163             [-1, 28, 1, 1]          18,844\n",
      "MemoryEfficientSwish-164             [-1, 28, 1, 1]               0\n",
      "        Identity-165             [-1, 28, 1, 1]               0\n",
      "Conv2dStaticSamePadding-166            [-1, 672, 1, 1]          19,488\n",
      "        Identity-167            [-1, 672, 8, 8]               0\n",
      "Conv2dStaticSamePadding-168            [-1, 112, 8, 8]          75,264\n",
      "       GroupNorm-169            [-1, 112, 8, 8]             224\n",
      "     MBConvBlock-170            [-1, 112, 8, 8]               0\n",
      "        Identity-171            [-1, 112, 8, 8]               0\n",
      "Conv2dStaticSamePadding-172            [-1, 672, 8, 8]          75,264\n",
      "       GroupNorm-173            [-1, 672, 8, 8]           1,344\n",
      "MemoryEfficientSwish-174            [-1, 672, 8, 8]               0\n",
      "       ZeroPad2d-175          [-1, 672, 12, 12]               0\n",
      "Conv2dStaticSamePadding-176            [-1, 672, 8, 8]          16,800\n",
      "       GroupNorm-177            [-1, 672, 8, 8]           1,344\n",
      "MemoryEfficientSwish-178            [-1, 672, 8, 8]               0\n",
      "        Identity-179            [-1, 672, 1, 1]               0\n",
      "Conv2dStaticSamePadding-180             [-1, 28, 1, 1]          18,844\n",
      "MemoryEfficientSwish-181             [-1, 28, 1, 1]               0\n",
      "        Identity-182             [-1, 28, 1, 1]               0\n",
      "Conv2dStaticSamePadding-183            [-1, 672, 1, 1]          19,488\n",
      "        Identity-184            [-1, 672, 8, 8]               0\n",
      "Conv2dStaticSamePadding-185            [-1, 112, 8, 8]          75,264\n",
      "       GroupNorm-186            [-1, 112, 8, 8]             224\n",
      "     MBConvBlock-187            [-1, 112, 8, 8]               0\n",
      "        Identity-188            [-1, 112, 8, 8]               0\n",
      "Conv2dStaticSamePadding-189            [-1, 672, 8, 8]          75,264\n",
      "       GroupNorm-190            [-1, 672, 8, 8]           1,344\n",
      "MemoryEfficientSwish-191            [-1, 672, 8, 8]               0\n",
      "       ZeroPad2d-192          [-1, 672, 11, 11]               0\n",
      "Conv2dStaticSamePadding-193            [-1, 672, 4, 4]          16,800\n",
      "       GroupNorm-194            [-1, 672, 4, 4]           1,344\n",
      "MemoryEfficientSwish-195            [-1, 672, 4, 4]               0\n",
      "        Identity-196            [-1, 672, 1, 1]               0\n",
      "Conv2dStaticSamePadding-197             [-1, 28, 1, 1]          18,844\n",
      "MemoryEfficientSwish-198             [-1, 28, 1, 1]               0\n",
      "        Identity-199             [-1, 28, 1, 1]               0\n",
      "Conv2dStaticSamePadding-200            [-1, 672, 1, 1]          19,488\n",
      "        Identity-201            [-1, 672, 4, 4]               0\n",
      "Conv2dStaticSamePadding-202            [-1, 192, 4, 4]         129,024\n",
      "       GroupNorm-203            [-1, 192, 4, 4]             384\n",
      "     MBConvBlock-204            [-1, 192, 4, 4]               0\n",
      "        Identity-205            [-1, 192, 4, 4]               0\n",
      "Conv2dStaticSamePadding-206           [-1, 1152, 4, 4]         221,184\n",
      "       GroupNorm-207           [-1, 1152, 4, 4]           2,304\n",
      "MemoryEfficientSwish-208           [-1, 1152, 4, 4]               0\n",
      "       ZeroPad2d-209           [-1, 1152, 8, 8]               0\n",
      "Conv2dStaticSamePadding-210           [-1, 1152, 4, 4]          28,800\n",
      "       GroupNorm-211           [-1, 1152, 4, 4]           2,304\n",
      "MemoryEfficientSwish-212           [-1, 1152, 4, 4]               0\n",
      "        Identity-213           [-1, 1152, 1, 1]               0\n",
      "Conv2dStaticSamePadding-214             [-1, 48, 1, 1]          55,344\n",
      "MemoryEfficientSwish-215             [-1, 48, 1, 1]               0\n",
      "        Identity-216             [-1, 48, 1, 1]               0\n",
      "Conv2dStaticSamePadding-217           [-1, 1152, 1, 1]          56,448\n",
      "        Identity-218           [-1, 1152, 4, 4]               0\n",
      "Conv2dStaticSamePadding-219            [-1, 192, 4, 4]         221,184\n",
      "       GroupNorm-220            [-1, 192, 4, 4]             384\n",
      "     MBConvBlock-221            [-1, 192, 4, 4]               0\n",
      "        Identity-222            [-1, 192, 4, 4]               0\n",
      "Conv2dStaticSamePadding-223           [-1, 1152, 4, 4]         221,184\n",
      "       GroupNorm-224           [-1, 1152, 4, 4]           2,304\n",
      "MemoryEfficientSwish-225           [-1, 1152, 4, 4]               0\n",
      "       ZeroPad2d-226           [-1, 1152, 8, 8]               0\n",
      "Conv2dStaticSamePadding-227           [-1, 1152, 4, 4]          28,800\n",
      "       GroupNorm-228           [-1, 1152, 4, 4]           2,304\n",
      "MemoryEfficientSwish-229           [-1, 1152, 4, 4]               0\n",
      "        Identity-230           [-1, 1152, 1, 1]               0\n",
      "Conv2dStaticSamePadding-231             [-1, 48, 1, 1]          55,344\n",
      "MemoryEfficientSwish-232             [-1, 48, 1, 1]               0\n",
      "        Identity-233             [-1, 48, 1, 1]               0\n",
      "Conv2dStaticSamePadding-234           [-1, 1152, 1, 1]          56,448\n",
      "        Identity-235           [-1, 1152, 4, 4]               0\n",
      "Conv2dStaticSamePadding-236            [-1, 192, 4, 4]         221,184\n",
      "       GroupNorm-237            [-1, 192, 4, 4]             384\n",
      "     MBConvBlock-238            [-1, 192, 4, 4]               0\n",
      "        Identity-239            [-1, 192, 4, 4]               0\n",
      "Conv2dStaticSamePadding-240           [-1, 1152, 4, 4]         221,184\n",
      "       GroupNorm-241           [-1, 1152, 4, 4]           2,304\n",
      "MemoryEfficientSwish-242           [-1, 1152, 4, 4]               0\n",
      "       ZeroPad2d-243           [-1, 1152, 8, 8]               0\n",
      "Conv2dStaticSamePadding-244           [-1, 1152, 4, 4]          28,800\n",
      "       GroupNorm-245           [-1, 1152, 4, 4]           2,304\n",
      "MemoryEfficientSwish-246           [-1, 1152, 4, 4]               0\n",
      "        Identity-247           [-1, 1152, 1, 1]               0\n",
      "Conv2dStaticSamePadding-248             [-1, 48, 1, 1]          55,344\n",
      "MemoryEfficientSwish-249             [-1, 48, 1, 1]               0\n",
      "        Identity-250             [-1, 48, 1, 1]               0\n",
      "Conv2dStaticSamePadding-251           [-1, 1152, 1, 1]          56,448\n",
      "        Identity-252           [-1, 1152, 4, 4]               0\n",
      "Conv2dStaticSamePadding-253            [-1, 192, 4, 4]         221,184\n",
      "       GroupNorm-254            [-1, 192, 4, 4]             384\n",
      "     MBConvBlock-255            [-1, 192, 4, 4]               0\n",
      "        Identity-256            [-1, 192, 4, 4]               0\n",
      "Conv2dStaticSamePadding-257           [-1, 1152, 4, 4]         221,184\n",
      "       GroupNorm-258           [-1, 1152, 4, 4]           2,304\n",
      "MemoryEfficientSwish-259           [-1, 1152, 4, 4]               0\n",
      "       ZeroPad2d-260           [-1, 1152, 6, 6]               0\n",
      "Conv2dStaticSamePadding-261           [-1, 1152, 4, 4]          10,368\n",
      "       GroupNorm-262           [-1, 1152, 4, 4]           2,304\n",
      "MemoryEfficientSwish-263           [-1, 1152, 4, 4]               0\n",
      "        Identity-264           [-1, 1152, 1, 1]               0\n",
      "Conv2dStaticSamePadding-265             [-1, 48, 1, 1]          55,344\n",
      "MemoryEfficientSwish-266             [-1, 48, 1, 1]               0\n",
      "        Identity-267             [-1, 48, 1, 1]               0\n",
      "Conv2dStaticSamePadding-268           [-1, 1152, 1, 1]          56,448\n",
      "        Identity-269           [-1, 1152, 4, 4]               0\n",
      "Conv2dStaticSamePadding-270            [-1, 320, 4, 4]         368,640\n",
      "       GroupNorm-271            [-1, 320, 4, 4]             640\n",
      "     MBConvBlock-272            [-1, 320, 4, 4]               0\n",
      "        Identity-273            [-1, 320, 4, 4]               0\n",
      "Conv2dStaticSamePadding-274           [-1, 1280, 4, 4]         409,600\n",
      "       GroupNorm-275           [-1, 1280, 4, 4]           2,560\n",
      "MemoryEfficientSwish-276           [-1, 1280, 4, 4]               0\n",
      "AdaptiveAvgPool2d-277           [-1, 1280, 1, 1]               0\n",
      "         Dropout-278                 [-1, 1280]               0\n",
      "          Linear-279                    [-1, 2]           2,562\n",
      "================================================================\n",
      "Total params: 4,010,110\n",
      "Trainable params: 4,010,110\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.19\n",
      "Forward/backward pass size (MB): 71.49\n",
      "Params size (MB): 15.30\n",
      "Estimated Total Size (MB): 86.97\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, input_size=(3,128,128),device='cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = optim.SGD(filter(lambda p: p.requires_grad, model.parameters()), lr=lr, momentum=momentum)\n",
    "# optimizer = optim.Adam(model.parameters(), weight_decay=0)\n",
    "scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)\n",
    "scheduler_warmup = GradualWarmupScheduler(optimizer, multiplier=8, total_epoch=10, after_scheduler=scheduler_cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resume\n",
    "if resume:\n",
    "    print('==> Resuming from checkpoint..')\n",
    "    checkpoint = os.path.dirname(resume)\n",
    "#     checkpoint = torch.load(resume)\n",
    "    resume = torch.load(resume)\n",
    "    best_acc = resume['best_acc']\n",
    "    start_epoch = resume['epoch']\n",
    "    model.load_state_dict(resume['state_dict'])\n",
    "    optimizer.load_state_dict(resume['optimizer'])\n",
    "    logger = Logger(os.path.join(checkpoint, 'log.txt'), resume=True)\n",
    "else:\n",
    "    logger = Logger(os.path.join(checkpoint, 'log.txt'))\n",
    "    logger.set_names(['Learning Rate', 'Train Loss', 'Valid Loss', 'Train Acc.', 'Valid Acc.', 'Source Loss', 'Source ACC.'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch, use_cuda):\n",
    "    model.train()\n",
    "    torch.set_grad_enabled(True)\n",
    "    \n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    end = time.time()\n",
    "    \n",
    "    bar = Bar('Processing', max=len(train_loader))\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        batch_size = inputs.size(0)\n",
    "        if batch_size < train_batch:\n",
    "            continue\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "        inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "\n",
    "        # compute output\n",
    "        outputs = model(inputs)\n",
    "        loss_main = criterion(outputs, targets)\n",
    "        loss_cls = 0\n",
    "        loss_sp = 0\n",
    "        loss_cls = reg_cls(model)\n",
    "        loss_sp = reg_l2sp(model)\n",
    "        loss = loss_main + alpha*loss_sp + beta*loss_cls\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1 = accuracy(outputs.data, targets.data)\n",
    "        losses.update(loss.data.tolist(), inputs.size(0))\n",
    "        top1.update(prec1[0], inputs.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        # plot progress\n",
    "        bar.suffix  = '({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | Total: {total:} | ETA: {eta:} | Loss: {loss:.4f} | top1: {top1: .4f} '.format(\n",
    "                    batch=batch_idx + 1,\n",
    "                    size=len(train_loader),\n",
    "                    data=data_time.val,\n",
    "                    bt=batch_time.val,\n",
    "                    total=bar.elapsed_td,\n",
    "                    eta=bar.eta_td,\n",
    "                    loss=losses.avg,\n",
    "                    top1=top1.avg,\n",
    "                    )\n",
    "        bar.next()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('{batch}/{size} | Total:{total:} | ETA:{eta:} | Loss:{loss:} | top1:{tp1:}'.format(\n",
    "                 batch=batch_idx+1, size=len(train_loader), total=bar.elapsed_td, eta=bar.eta_td, loss=losses.avg, tp1=top1.avg))\n",
    "    print('{batch}/{size} | Total:{total:} | ETA:{eta:} | Loss:{loss:} | top1:{tp1:}'.format(\n",
    "                 batch=batch_idx+1, size=len(train_loader), total=bar.elapsed_td, eta=bar.eta_td, loss=losses.avg, tp1=top1.avg))\n",
    "    bar.finish()\n",
    "    return (losses.avg, top1.avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(val_loader, model, criterion, epoch, use_cuda):\n",
    "    global best_acc\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "    torch.set_grad_enabled(False)\n",
    "\n",
    "    end = time.time()\n",
    "    bar = Bar('Processing', max=len(val_loader))\n",
    "    for batch_idx, (inputs, targets) in enumerate(val_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "        inputs, targets = torch.autograd.Variable(inputs, volatile=True), torch.autograd.Variable(targets)\n",
    "\n",
    "        # compute output\n",
    "        outputs = model(inputs)\n",
    "        loss_main = criterion(outputs, targets)\n",
    "        loss_cls = 0\n",
    "        loss_sp = 0\n",
    "        loss_cls = reg_cls(model)\n",
    "        loss_sp = reg_l2sp(model)\n",
    "        loss = loss_main + alpha*loss_sp + beta*loss_cls\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1 = accuracy(outputs.data, targets.data)\n",
    "        losses.update(loss.data.tolist(), inputs.size(0))\n",
    "        top1.update(prec1[0], inputs.size(0))\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        # plot progress\n",
    "        bar.suffix  = '({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | Total: {total:} | ETA: {eta:} | Loss: {loss:} | top1: {top1:}'.format(\n",
    "                    batch=batch_idx + 1,\n",
    "                    size=len(val_loader),\n",
    "                    data=data_time.avg,\n",
    "                    bt=batch_time.avg,\n",
    "                    total=bar.elapsed_td,\n",
    "                    eta=bar.eta_td,\n",
    "                    loss=losses.avg,\n",
    "                    top1=top1.avg,)\n",
    "        bar.next()\n",
    "    print('{batch}/{size} | Total:{total:} | ETA:{eta:} | Loss:{loss:} | top1:{tp1:}'.format(\n",
    "         batch=batch_idx+1, size=len(val_loader), total=bar.elapsed_td, eta=bar.eta_td, loss=losses.avg, tp1=top1.avg))\n",
    "    bar.finish()\n",
    "    return (losses.avg, top1.avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, checkpoint='checkpoint', filename='checkpoint.pth.tar'):\n",
    "    filepath = os.path.join(checkpoint, filename)\n",
    "    torch.save(state, filepath)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filepath, os.path.join(checkpoint, 'model_best.pth.tar'))\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    global state\n",
    "    lr_set = [1, 1e-1, 1e-2, 1e-3, 1e-4, 1e-5]\n",
    "    lr_list = schedule.copy()\n",
    "    lr_list.append(epoch)\n",
    "    lr_list.sort()\n",
    "    idx = lr_list.index(epoch)\n",
    "    state['lr'] *= lr_set[idx]\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = state['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [1 | 5000] LR: 0.040000\n",
      "1/13 | Total:0:00:03 | ETA:0:00:45 | Loss:2.524421453475952 | top1:68.75\n",
      "11/13 | Total:0:00:07 | ETA:0:00:02 | Loss:0.9840470091863112 | top1:68.46591186523438\n",
      "13/13 | Total:0:00:08 | ETA:0:00:01 | Loss:0.9389844685792923 | top1:69.27083587646484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cutz/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:21: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 | Total:0:00:45 | ETA:0:00:00 | Loss:0.7935269603488642 | top1:50.15727615356445\n",
      "26/26 | Total:0:00:18 | ETA:0:00:00 | Loss:0.1908557667182042 | top1:99.0\n",
      "\n",
      "Epoch: [2 | 5000] LR: 0.068000\n",
      "1/13 | Total:0:00:01 | ETA:0:00:16 | Loss:0.491579532623291 | top1:75.0\n",
      "11/13 | Total:0:00:04 | ETA:0:00:01 | Loss:0.5078635811805725 | top1:72.44318389892578\n",
      "13/13 | Total:0:00:05 | ETA:0:00:01 | Loss:0.5086046953996023 | top1:72.65625\n",
      "\n",
      "Epoch: [3 | 5000] LR: 0.096000\n",
      "1/13 | Total:0:00:01 | ETA:0:00:18 | Loss:0.5093801021575928 | top1:68.75\n",
      "11/13 | Total:0:00:04 | ETA:0:00:01 | Loss:0.5643341026522897 | top1:70.45454406738281\n",
      "13/13 | Total:0:00:05 | ETA:0:00:01 | Loss:0.5677584235866865 | top1:70.3125\n",
      "\n",
      "Epoch: [4 | 5000] LR: 0.124000\n",
      "1/13 | Total:0:00:01 | ETA:0:00:13 | Loss:0.6086311340332031 | top1:50.0\n",
      "11/13 | Total:0:00:04 | ETA:0:00:01 | Loss:0.5512994446537711 | top1:71.875\n",
      "13/13 | Total:0:00:05 | ETA:0:00:01 | Loss:0.5525914008418719 | top1:72.13542175292969\n",
      "\n",
      "Epoch: [5 | 5000] LR: 0.152000\n",
      "1/13 | Total:0:00:01 | ETA:0:00:17 | Loss:0.5912801623344421 | top1:71.875\n",
      "11/13 | Total:0:00:04 | ETA:0:00:01 | Loss:0.6102296628735282 | top1:71.0227279663086\n",
      "13/13 | Total:0:00:05 | ETA:0:00:01 | Loss:0.6173080429434776 | top1:69.79167175292969\n",
      "\n",
      "Epoch: [6 | 5000] LR: 0.180000\n",
      "1/13 | Total:0:00:01 | ETA:0:00:15 | Loss:0.5572685599327087 | top1:78.125\n",
      "11/13 | Total:0:00:04 | ETA:0:00:01 | Loss:0.5430784875696356 | top1:75.8522720336914\n",
      "13/13 | Total:0:00:05 | ETA:0:00:01 | Loss:0.5467791110277176 | top1:75.78125\n",
      "\n",
      "Epoch: [7 | 5000] LR: 0.208000\n",
      "1/13 | Total:0:00:01 | ETA:0:00:13 | Loss:0.4427820146083832 | top1:81.25\n",
      "11/13 | Total:0:00:04 | ETA:0:00:01 | Loss:9.468857551162893 | top1:70.73863983154297\n",
      "13/13 | Total:0:00:05 | ETA:0:00:01 | Loss:9.698032341897488 | top1:71.09375\n",
      "\n",
      "Epoch: [8 | 5000] LR: 0.236000\n",
      "1/13 | Total:0:00:01 | ETA:0:00:16 | Loss:11.744659423828125 | top1:71.875\n",
      "11/13 | Total:0:00:04 | ETA:0:00:01 | Loss:9.548367023468018 | top1:74.71591186523438\n",
      "13/13 | Total:0:00:05 | ETA:0:00:01 | Loss:9.370569785435995 | top1:73.17708587646484\n",
      "\n",
      "Epoch: [9 | 5000] LR: 0.264000\n",
      "1/13 | Total:0:00:01 | ETA:0:00:14 | Loss:6.946528911590576 | top1:84.375\n",
      "11/13 | Total:0:00:04 | ETA:0:00:01 | Loss:5.700531916184858 | top1:64.48863983154297\n",
      "13/13 | Total:0:00:04 | ETA:0:00:01 | Loss:5.565666238466899 | top1:65.88542175292969\n",
      "\n",
      "Epoch: [10 | 5000] LR: 0.292000\n",
      "1/13 | Total:0:00:01 | ETA:0:00:15 | Loss:3.941577672958374 | top1:71.875\n",
      "11/13 | Total:0:00:05 | ETA:0:00:01 | Loss:3.7319285652854224 | top1:53.69318389892578\n",
      "13/13 | Total:0:00:05 | ETA:0:00:01 | Loss:3.653275430202484 | top1:54.6875\n",
      "\n",
      "Epoch: [11 | 5000] LR: 0.320000\n",
      "1/13 | Total:0:00:01 | ETA:0:00:15 | Loss:2.762869358062744 | top1:40.625\n",
      "11/13 | Total:0:00:05 | ETA:0:00:01 | Loss:2.2947569001804697 | top1:54.82954788208008\n",
      "13/13 | Total:0:00:05 | ETA:0:00:01 | Loss:2.2503032883008323 | top1:53.38541793823242\n",
      "\n",
      "Epoch: [12 | 5000] LR: 0.320000\n",
      "1/13 | Total:0:00:01 | ETA:0:00:14 | Loss:1.609717607498169 | top1:71.875\n",
      "11/13 | Total:0:00:04 | ETA:0:00:01 | Loss:2.178443117575212 | top1:67.8977279663086\n",
      "13/13 | Total:0:00:05 | ETA:0:00:01 | Loss:2.2914027671019235 | top1:68.22917175292969\n",
      "\n",
      "Epoch: [13 | 5000] LR: 0.320000\n",
      "1/13 | Total:0:00:01 | ETA:0:00:13 | Loss:3.4059033393859863 | top1:75.0\n",
      "11/13 | Total:0:00:05 | ETA:0:00:01 | Loss:2.8277605013413862 | top1:63.6363639831543\n",
      "13/13 | Total:0:00:05 | ETA:0:00:01 | Loss:2.771530330181122 | top1:63.020835876464844\n",
      "\n",
      "Epoch: [14 | 5000] LR: 0.320000\n",
      "1/13 | Total:0:00:01 | ETA:0:00:13 | Loss:2.0752291679382324 | top1:68.75\n",
      "11/13 | Total:0:00:03 | ETA:0:00:01 | Loss:1.7035990411585027 | top1:65.625\n",
      "13/13 | Total:0:00:04 | ETA:0:00:01 | Loss:1.6742799480756123 | top1:65.88542175292969\n",
      "\n",
      "Epoch: [15 | 5000] LR: 0.320000\n",
      "1/13 | Total:0:00:00 | ETA:0:00:12 | Loss:1.3418314456939697 | top1:75.0\n",
      "11/13 | Total:0:00:03 | ETA:0:00:01 | Loss:1.4732478586110203 | top1:59.65909194946289\n",
      "13/13 | Total:0:00:04 | ETA:0:00:01 | Loss:1.4656772762537003 | top1:58.85416793823242\n",
      "\n",
      "Epoch: [16 | 5000] LR: 0.319999\n",
      "1/13 | Total:0:00:00 | ETA:0:00:12 | Loss:1.3006958961486816 | top1:53.125\n",
      "11/13 | Total:0:00:04 | ETA:0:00:01 | Loss:1.0771498571742664 | top1:66.19318389892578\n",
      "13/13 | Total:0:00:04 | ETA:0:00:01 | Loss:1.0661947180827458 | top1:66.40625\n",
      "\n",
      "Epoch: [17 | 5000] LR: 0.319999\n",
      "1/13 | Total:0:00:00 | ETA:0:00:10 | Loss:0.7581102848052979 | top1:78.125\n",
      "11/13 | Total:0:00:04 | ETA:0:00:01 | Loss:30.801823708144102 | top1:72.7272720336914\n",
      "13/13 | Total:0:00:04 | ETA:0:00:01 | Loss:32.80879561603069 | top1:72.39583587646484\n",
      "\n",
      "Epoch: [18 | 5000] LR: 0.319999\n",
      "1/13 | Total:0:00:01 | ETA:0:00:14 | Loss:51.4828987121582 | top1:90.625\n",
      "11/13 | Total:0:00:04 | ETA:0:00:01 | Loss:38.589430895718664 | top1:53.97727584838867\n",
      "13/13 | Total:0:00:04 | ETA:0:00:01 | Loss:37.52537520726522 | top1:54.6875\n",
      "\n",
      "Epoch: [19 | 5000] LR: 0.319998\n",
      "1/13 | Total:0:00:01 | ETA:0:00:14 | Loss:24.207996368408203 | top1:75.0\n",
      "11/13 | Total:0:00:04 | ETA:0:00:01 | Loss:18.027879975058816 | top1:70.45454406738281\n",
      "13/13 | Total:0:00:05 | ETA:0:00:01 | Loss:17.5565443833669 | top1:69.27083587646484\n",
      "\n",
      "Epoch: [20 | 5000] LR: 0.319998\n",
      "1/13 | Total:0:00:00 | ETA:0:00:12 | Loss:11.521097183227539 | top1:65.625\n",
      "11/13 | Total:0:00:04 | ETA:0:00:01 | Loss:8.729349093003707 | top1:63.06818389892578\n",
      "13/13 | Total:0:00:04 | ETA:0:00:01 | Loss:8.52319343884786 | top1:62.239585876464844\n",
      "\n",
      "Epoch: [21 | 5000] LR: 0.319997\n",
      "1/13 | Total:0:00:00 | ETA:0:00:12 | Loss:5.8625359535217285 | top1:68.75\n",
      "11/13 | Total:0:00:04 | ETA:0:00:01 | Loss:4.760827606374567 | top1:59.94318389892578\n",
      "13/13 | Total:0:00:04 | ETA:0:00:01 | Loss:4.672804137070973 | top1:60.15625\n",
      "\n",
      "Epoch: [22 | 5000] LR: 0.319997\n",
      "1/13 | Total:0:00:00 | ETA:0:00:12 | Loss:3.5105340480804443 | top1:50.0\n",
      "11/13 | Total:0:00:04 | ETA:0:00:01 | Loss:12.676053524017334 | top1:59.375\n",
      "13/13 | Total:0:00:04 | ETA:0:00:01 | Loss:12.636784593264261 | top1:57.03125\n",
      "\n",
      "Epoch: [23 | 5000] LR: 0.319996\n",
      "1/13 | Total:0:00:00 | ETA:0:00:09 | Loss:11.478808403015137 | top1:62.5\n",
      "11/13 | Total:0:00:05 | ETA:0:00:01 | Loss:8.561180634932084 | top1:67.04545593261719\n",
      "13/13 | Total:0:00:05 | ETA:0:00:01 | Loss:8.330214262008667 | top1:67.70833587646484\n",
      "\n",
      "Epoch: [24 | 5000] LR: 0.319995\n",
      "1/13 | Total:0:00:01 | ETA:0:00:18 | Loss:5.472487449645996 | top1:75.0\n",
      "11/13 | Total:0:00:04 | ETA:0:00:01 | Loss:4.4113688902421435 | top1:67.04545593261719\n",
      "13/13 | Total:0:00:05 | ETA:0:00:01 | Loss:4.352182428042094 | top1:65.625\n",
      "\n",
      "Epoch: [25 | 5000] LR: 0.319995\n",
      "1/13 | Total:0:00:01 | ETA:0:00:14 | Loss:3.9610297679901123 | top1:46.875\n",
      "11/13 | Total:0:00:04 | ETA:0:00:01 | Loss:3.1455307440324263 | top1:46.590911865234375\n",
      "13/13 | Total:0:00:05 | ETA:0:00:01 | Loss:3.078764339288076 | top1:46.875\n",
      "\n",
      "Epoch: [26 | 5000] LR: 0.319994\n",
      "1/13 | Total:0:00:00 | ETA:0:00:10 | Loss:2.2134695053100586 | top1:53.125\n",
      "11/13 | Total:0:00:04 | ETA:0:00:01 | Loss:1.9233196323568171 | top1:54.54545593261719\n",
      "13/13 | Total:0:00:04 | ETA:0:00:01 | Loss:1.8959451019763947 | top1:54.427085876464844\n",
      "\n",
      "Epoch: [27 | 5000] LR: 0.319993\n",
      "1/13 | Total:0:00:01 | ETA:0:00:16 | Loss:1.5303370952606201 | top1:50.0\n",
      "11/13 | Total:0:00:04 | ETA:0:00:01 | Loss:1.3132279894568704 | top1:52.556819915771484\n",
      "13/13 | Total:0:00:05 | ETA:0:00:01 | Loss:1.303459793329239 | top1:52.34375\n",
      "\n",
      "Epoch: [28 | 5000] LR: 0.319992\n",
      "1/13 | Total:0:00:00 | ETA:0:00:12 | Loss:1.328765869140625 | top1:43.75\n",
      "11/13 | Total:0:00:04 | ETA:0:00:01 | Loss:1.082339346408844 | top1:59.94318389892578\n",
      "13/13 | Total:0:00:04 | ETA:0:00:01 | Loss:1.06936913728714 | top1:60.677085876464844\n",
      "\n",
      "Epoch: [29 | 5000] LR: 0.319991\n",
      "1/13 | Total:0:00:01 | ETA:0:00:13 | Loss:0.8893260955810547 | top1:71.875\n",
      "11/13 | Total:0:00:04 | ETA:0:00:01 | Loss:0.833895206451416 | top1:68.75\n",
      "13/13 | Total:0:00:05 | ETA:0:00:01 | Loss:0.8362774948279063 | top1:68.22917175292969\n",
      "\n",
      "Epoch: [30 | 5000] LR: 0.319990\n",
      "1/13 | Total:0:00:01 | ETA:0:00:15 | Loss:0.8564627170562744 | top1:59.375\n",
      "11/13 | Total:0:00:04 | ETA:0:00:01 | Loss:0.8608101985671304 | top1:62.78409194946289\n",
      "13/13 | Total:0:00:04 | ETA:0:00:01 | Loss:0.8572299579779307 | top1:63.54166793823242\n",
      "\n",
      "Epoch: [31 | 5000] LR: 0.319989\n",
      "1/13 | Total:0:00:00 | ETA:0:00:12 | Loss:0.7181860208511353 | top1:68.75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/13 | Total:0:00:04 | ETA:0:00:01 | Loss:0.8876847624778748 | top1:65.625\n",
      "13/13 | Total:0:00:04 | ETA:0:00:01 | Loss:0.8911750862995783 | top1:64.84375\n",
      "\n",
      "Epoch: [32 | 5000] LR: 0.319987\n",
      "1/13 | Total:0:00:01 | ETA:0:00:14 | Loss:0.9925582408905029 | top1:46.875\n",
      "11/13 | Total:0:00:05 | ETA:0:00:01 | Loss:382.5903220826929 | top1:66.4772720336914\n",
      "13/13 | Total:0:00:05 | ETA:0:00:01 | Loss:452.2153432567914 | top1:67.1875\n",
      "\n",
      "Epoch: [33 | 5000] LR: 0.319986\n",
      "1/13 | Total:0:00:01 | ETA:0:00:13 | Loss:1141.495849609375 | top1:65.625\n",
      "11/13 | Total:0:00:04 | ETA:0:00:01 | Loss:842.5241865678267 | top1:65.625\n",
      "13/13 | Total:0:00:04 | ETA:0:00:01 | Loss:818.9148152669271 | top1:64.32292175292969\n",
      "\n",
      "Epoch: [34 | 5000] LR: 0.319985\n",
      "1/13 | Total:0:00:01 | ETA:0:00:17 | Loss:523.70751953125 | top1:46.875\n",
      "11/13 | Total:0:00:05 | ETA:0:00:01 | Loss:386.8147083629261 | top1:55.11363983154297\n",
      "13/13 | Total:0:00:06 | ETA:0:00:01 | Loss:375.98364003499347 | top1:54.94791793823242\n",
      "\n",
      "Epoch: [35 | 5000] LR: 0.319983\n",
      "1/13 | Total:0:00:01 | ETA:0:00:19 | Loss:240.71548461914062 | top1:53.125\n",
      "11/13 | Total:0:00:04 | ETA:0:00:01 | Loss:177.76678397438744 | top1:60.22727584838867\n",
      "13/13 | Total:0:00:05 | ETA:0:00:01 | Loss:172.79304186503092 | top1:60.15625\n",
      "\n",
      "Epoch: [36 | 5000] LR: 0.319982\n",
      "1/13 | Total:0:00:01 | ETA:0:00:14 | Loss:110.58924102783203 | top1:71.875\n",
      "11/13 | Total:0:00:04 | ETA:0:00:01 | Loss:81.82225972955877 | top1:65.05682373046875\n",
      "13/13 | Total:0:00:05 | ETA:0:00:01 | Loss:79.53432655334473 | top1:66.40625\n",
      "\n",
      "Epoch: [37 | 5000] LR: 0.319980\n",
      "1/13 | Total:0:00:01 | ETA:0:00:17 | Loss:51.047401428222656 | top1:71.875\n",
      "11/13 | Total:0:00:06 | ETA:0:00:02 | Loss:38.446278832175516 | top1:64.20454406738281\n",
      "13/13 | Total:0:00:06 | ETA:0:00:01 | Loss:37.40449984868368 | top1:63.020835876464844\n",
      "\n",
      "Epoch: [38 | 5000] LR: 0.319979\n",
      "1/13 | Total:0:00:01 | ETA:0:00:16 | Loss:24.26669692993164 | top1:71.875\n",
      "11/13 | Total:0:00:05 | ETA:0:00:02 | Loss:18.06665255806663 | top1:70.73863983154297\n",
      "13/13 | Total:0:00:05 | ETA:0:00:01 | Loss:17.6122940381368 | top1:70.05208587646484\n",
      "\n",
      "Epoch: [39 | 5000] LR: 0.319977\n",
      "1/13 | Total:0:00:01 | ETA:0:00:16 | Loss:11.793800354003906 | top1:65.625\n",
      "11/13 | Total:0:00:05 | ETA:0:00:02 | Loss:9.010253169319846 | top1:70.17045593261719\n",
      "13/13 | Total:0:00:06 | ETA:0:00:01 | Loss:8.809893369674683 | top1:68.22917175292969\n",
      "\n",
      "Epoch: [40 | 5000] LR: 0.319975\n",
      "1/13 | Total:0:00:01 | ETA:0:00:13 | Loss:6.094518661499023 | top1:59.375\n",
      "11/13 | Total:0:00:04 | ETA:0:00:01 | Loss:4.607555649497292 | top1:68.75\n",
      "13/13 | Total:0:00:05 | ETA:0:00:01 | Loss:4.507783770561218 | top1:68.22917175292969\n",
      "\n",
      "Epoch: [41 | 5000] LR: 0.319973\n",
      "1/13 | Total:0:00:01 | ETA:0:00:16 | Loss:3.3482162952423096 | top1:37.5\n",
      "11/13 | Total:0:00:04 | ETA:0:00:01 | Loss:2.5686293081803755 | top1:67.04545593261719\n",
      "13/13 | Total:0:00:04 | ETA:0:00:01 | Loss:2.5130157470703125 | top1:67.44792175292969\n",
      "\n",
      "Epoch: [42 | 5000] LR: 0.319972\n",
      "1/13 | Total:0:00:01 | ETA:0:00:16 | Loss:2.793233633041382 | top1:65.625\n",
      "11/13 | Total:0:00:04 | ETA:0:00:01 | Loss:2.306475140831687 | top1:70.45454406738281\n",
      "13/13 | Total:0:00:05 | ETA:0:00:01 | Loss:2.310677409172058 | top1:68.22917175292969\n",
      "\n",
      "Epoch: [43 | 5000] LR: 0.319970\n",
      "1/13 | Total:0:00:00 | ETA:0:00:10 | Loss:1.8795040845870972 | top1:59.375\n",
      "11/13 | Total:0:00:04 | ETA:0:00:01 | Loss:1.4962898601185193 | top1:67.8977279663086\n",
      "13/13 | Total:0:00:05 | ETA:0:00:01 | Loss:1.4721692502498627 | top1:67.70833587646484\n",
      "\n",
      "Epoch: [44 | 5000] LR: 0.319968\n",
      "1/13 | Total:0:00:01 | ETA:0:00:15 | Loss:1.0990328788757324 | top1:84.375\n",
      "11/13 | Total:0:00:05 | ETA:0:00:01 | Loss:1.1796117966825312 | top1:71.30682373046875\n",
      "13/13 | Total:0:00:05 | ETA:0:00:01 | Loss:1.1544229636589687 | top1:71.61458587646484\n",
      "\n",
      "Epoch: [45 | 5000] LR: 0.319966\n",
      "1/13 | Total:0:00:00 | ETA:0:00:12 | Loss:0.7331653833389282 | top1:87.5\n",
      "11/13 | Total:0:00:05 | ETA:0:00:02 | Loss:1.2908719236200505 | top1:59.94318389892578\n",
      "13/13 | Total:0:00:05 | ETA:0:00:01 | Loss:1.2742496530214946 | top1:59.375\n",
      "\n",
      "Epoch: [46 | 5000] LR: 0.319963\n",
      "1/13 | Total:0:00:00 | ETA:0:00:12 | Loss:0.9184763431549072 | top1:71.875\n",
      "11/13 | Total:0:00:04 | ETA:0:00:01 | Loss:0.8786348321221091 | top1:71.875\n",
      "13/13 | Total:0:00:05 | ETA:0:00:01 | Loss:0.8903850615024567 | top1:70.57292175292969\n",
      "\n",
      "Epoch: [47 | 5000] LR: 0.319961\n",
      "1/13 | Total:0:00:01 | ETA:0:00:16 | Loss:0.9625847339630127 | top1:59.375\n",
      "11/13 | Total:0:00:04 | ETA:0:00:01 | Loss:1.2542427778244019 | top1:60.79545593261719\n",
      "13/13 | Total:0:00:04 | ETA:0:00:01 | Loss:1.249979962905248 | top1:61.458335876464844\n",
      "\n",
      "Epoch: [48 | 5000] LR: 0.319959\n",
      "1/13 | Total:0:00:00 | ETA:0:00:10 | Loss:1.1391980648040771 | top1:71.875\n",
      "11/13 | Total:0:00:04 | ETA:0:00:01 | Loss:1.1547237092798406 | top1:64.20454406738281\n",
      "13/13 | Total:0:00:05 | ETA:0:00:01 | Loss:1.1513667901357014 | top1:61.97916793823242\n",
      "\n",
      "Epoch: [49 | 5000] LR: 0.319957\n",
      "1/13 | Total:0:00:01 | ETA:0:00:17 | Loss:1.413550853729248 | top1:78.125\n",
      "11/13 | Total:0:00:05 | ETA:0:00:02 | Loss:1.351966847072948 | top1:69.03409576416016\n",
      "13/13 | Total:0:00:06 | ETA:0:00:01 | Loss:1.3327573736508687 | top1:68.48958587646484\n",
      "\n",
      "Epoch: [50 | 5000] LR: 0.319954\n",
      "1/13 | Total:0:00:01 | ETA:0:00:14 | Loss:1.0493369102478027 | top1:75.0\n",
      "11/13 | Total:0:00:04 | ETA:0:00:01 | Loss:1.284456112168052 | top1:60.79545593261719\n",
      "13/13 | Total:0:00:04 | ETA:0:00:01 | Loss:1.2857583463191986 | top1:60.9375\n",
      "\n",
      "Epoch: [51 | 5000] LR: 0.319952\n",
      "1/13 | Total:0:00:00 | ETA:0:00:10 | Loss:1.3629465103149414 | top1:37.5\n",
      "11/13 | Total:0:00:04 | ETA:0:00:01 | Loss:1.1410770253701643 | top1:59.090911865234375\n",
      "13/13 | Total:0:00:05 | ETA:0:00:01 | Loss:1.1655859798192978 | top1:57.29166793823242\n",
      "102/102 | Total:0:00:34 | ETA:0:00:00 | Loss:1.1723630998581454 | top1:49.99017333984375\n",
      "26/26 | Total:0:00:16 | ETA:0:00:00 | Loss:1.048988475249364 | top1:87.76922607421875\n",
      "\n",
      "Epoch: [52 | 5000] LR: 0.319949\n",
      "1/13 | Total:0:00:00 | ETA:0:00:10 | Loss:1.1465140581130981 | top1:56.25\n",
      "11/13 | Total:0:00:04 | ETA:0:00:01 | Loss:1.0334687666459517 | top1:65.625\n",
      "13/13 | Total:0:00:05 | ETA:0:00:01 | Loss:1.0318515598773956 | top1:65.10417175292969\n",
      "\n",
      "Epoch: [53 | 5000] LR: 0.319947\n",
      "1/13 | Total:0:00:01 | ETA:0:00:13 | Loss:0.9888551235198975 | top1:78.125\n",
      "11/13 | Total:0:00:05 | ETA:0:00:01 | Loss:1.0386362184177746 | top1:67.04545593261719\n",
      "13/13 | Total:0:00:06 | ETA:0:00:01 | Loss:1.0166757454474766 | top1:68.22917175292969\n",
      "\n",
      "Epoch: [54 | 5000] LR: 0.319944\n",
      "1/13 | Total:0:00:01 | ETA:0:00:22 | Loss:1.0496784448623657 | top1:65.625\n",
      "11/13 | Total:0:00:07 | ETA:0:00:02 | Loss:1.6602801409634678 | top1:60.5113639831543\n",
      "13/13 | Total:0:00:08 | ETA:0:00:01 | Loss:1.7165504693984985 | top1:61.19791793823242\n",
      "\n",
      "Epoch: [55 | 5000] LR: 0.319942\n",
      "1/13 | Total:0:00:01 | ETA:0:00:20 | Loss:2.2639715671539307 | top1:56.25\n",
      "11/13 | Total:0:00:06 | ETA:0:00:02 | Loss:2.100947867740284 | top1:64.7727279663086\n",
      "13/13 | Total:0:00:07 | ETA:0:00:01 | Loss:2.0709619224071503 | top1:64.32292175292969\n",
      "\n",
      "Epoch: [56 | 5000] LR: 0.319939\n",
      "1/13 | Total:0:00:01 | ETA:0:00:19 | Loss:1.6117377281188965 | top1:65.625\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(start_epoch, epochs):\n",
    "    state['lr'] = optimizer.state_dict()['param_groups'][0]['lr']\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "    print('\\nEpoch: [%d | %d] LR: %f' % (epoch + 1, epochs, state['lr']))\n",
    "    \n",
    "    train_loss, train_acc = train(train_loader, model, criterion, optimizer, epoch, use_cuda)\n",
    "    \n",
    "    if epoch % 50 == 0:\n",
    "        test_loss, test_acc = test(val_target_loader, model, criterion, epoch, use_cuda)\n",
    "        source_loss, source_acc = test(val_source_loader, model, criterion, epoch, use_cuda)\n",
    "\n",
    "        logger.append([state['lr'], train_loss, test_loss, train_acc, test_acc, source_loss, source_acc])\n",
    "        \n",
    "\n",
    "        is_best = test_acc > best_acc\n",
    "        best_acc = max(test_acc, best_acc)\n",
    "        save_checkpoint({\n",
    "            'epoch': epoch + 1,\n",
    "            'state_dict' : model.state_dict(),\n",
    "            'acc': test_acc,\n",
    "            'best_acc': best_acc,\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "        }, is_best, checkpoint=checkpoint)\n",
    "    scheduler_warmup.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
