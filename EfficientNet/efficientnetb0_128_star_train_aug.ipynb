{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import collections\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "\n",
    "from model_pytorch import EfficientNet\n",
    "from utils import Bar,Logger, AverageMeter, accuracy, mkdir_p, savefig\n",
    "from warmup_scheduler import GradualWarmupScheduler\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "import cv2\n",
    "\n",
    "from PIL import ImageFile, ImageOps\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU device 0: True\n"
     ]
    }
   ],
   "source": [
    "# GPU Device\n",
    "gpu_id = 0\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(\"GPU device %d:\" %(gpu_id), use_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/media/data2/dataset/GAN_ImageData/StarGAN_128'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained = ''\n",
    "resume = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model_name = 'efficientnet-b0' # b0-b7 scale\n",
    "\n",
    "# Optimization\n",
    "num_classes = 2\n",
    "epochs = 400\n",
    "start_epoch = 0\n",
    "train_batch = 256\n",
    "test_batch = 256\n",
    "lr = 0.04\n",
    "schedule = [75, 175, 250]\n",
    "momentum = 0.9\n",
    "gamma = 0.1 # LR is multiplied by gamma on schedule\n",
    "\n",
    "# CheckPoint\n",
    "checkpoint = './log/star/128/b0/aug' # dir\n",
    "if not os.path.isdir(checkpoint):\n",
    "    os.mkdir(checkpoint)\n",
    "num_workers = 8\n",
    "\n",
    "# Seed\n",
    "manual_seed = 7\n",
    "random.seed(manual_seed)\n",
    "torch.cuda.manual_seed_all(manual_seed)\n",
    "\n",
    "# Image\n",
    "size = (128, 128)\n",
    "\n",
    "# cutmix\n",
    "cm_prob = 0.5\n",
    "cm_prob_init = 0.99\n",
    "cm_prob_low = 0.01\n",
    "cm_beta = 1.0\n",
    "\n",
    "# augmentation\n",
    "blur_prob = 0.2\n",
    "blog_sig = 0.5\n",
    "jpg_prob = 0.2\n",
    "\n",
    "best_acc = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {}\n",
    "state['num_classes'] = num_classes\n",
    "state['epochs'] = epochs\n",
    "state['start_epoch'] = start_epoch\n",
    "state['train_batch'] = train_batch\n",
    "state['test_batch'] = test_batch\n",
    "state['lr'] = lr\n",
    "state['schedule'] = schedule\n",
    "state['momentum'] = momentum\n",
    "state['gamma'] = gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_augment(img):\n",
    "    img = np.array(img)\n",
    "\n",
    "    if random.random() < blur_prob:\n",
    "        sig = np.random.uniform(0.0, 3.0)\n",
    "        gaussian_blur(img, sig)\n",
    "\n",
    "    if random.random() < jpg_prob:\n",
    "        qual = np.random.uniform(30.0, 100.0)\n",
    "        img = cv2_jpg(img, qual)\n",
    "\n",
    "    return Image.fromarray(img)\n",
    "\n",
    "\n",
    "def gaussian_blur(img, sigma):\n",
    "    gaussian_filter(img[:,:,0], output=img[:,:,0], sigma=sigma)\n",
    "    gaussian_filter(img[:,:,1], output=img[:,:,1], sigma=sigma)\n",
    "    gaussian_filter(img[:,:,2], output=img[:,:,2], sigma=sigma)\n",
    "\n",
    "\n",
    "def cv2_jpg(img, compress_val):\n",
    "    img_cv2 = img[:,:,::-1]\n",
    "    encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), compress_val]\n",
    "    result, encimg = cv2.imencode('.jpg', img_cv2, encode_param)\n",
    "    decimg = cv2.imdecode(encimg, 1)\n",
    "    return decimg[:,:,::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_bbox(size, lam):\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = np.int(W * cut_rat)\n",
    "    cut_h = np.int(H * cut_rat)\n",
    "\n",
    "    # uniform\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join(data_dir, 'train')\n",
    "val_dir = os.path.join(data_dir, 'validation')    \n",
    "\n",
    "train_aug = transforms.Compose([\n",
    "    transforms.Lambda(lambda img: data_augment(img)),\n",
    "    transforms.Resize(size),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "#     transforms.RandomErasing(p=0.3, scale=(0.02, 0.10), ratio=(0.3, 3.3), value=0, inplace=True),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "val_aug = transforms.Compose([\n",
    "    transforms.Resize(size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# pin_memory : cuda pin memeory use\n",
    "train_loader = DataLoader(datasets.ImageFolder(train_dir, transform=train_aug),\n",
    "                          batch_size=train_batch, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "val_loader = DataLoader(datasets.ImageFolder(val_dir, val_aug),\n",
    "                       batch_size=test_batch, shuffle=True, num_workers=num_workers, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EfficientNet.from_name(model_name, num_classes=num_classes,\n",
    "                              override_params={'dropout_rate':0.2, 'drop_connect_rate':0.2})\n",
    "\n",
    "# Pre-trained\n",
    "if pretrained:\n",
    "    print(\"=> using pre-trained model '{}'\".format(pretrained))\n",
    "    model.load_state_dict(torch.load(pretrained)['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Total params: 4.01M\n"
     ]
    }
   ],
   "source": [
    "model.to('cuda')\n",
    "cudnn.benchmark = True\n",
    "print('    Total params: %.2fM' % (sum(p.numel() for p in model.parameters())/1000000.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=1e-4)\n",
    "scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)\n",
    "scheduler_warmup = GradualWarmupScheduler(optimizer, multiplier=8, total_epoch=10, after_scheduler=scheduler_cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resume\n",
    "if resume:\n",
    "    print('==> Resuming from checkpoint..')\n",
    "    checkpoint = os.path.dirname(resume)\n",
    "#     checkpoint = torch.load(resume)\n",
    "    resume = torch.load(resume)\n",
    "    best_acc = resume['best_acc']\n",
    "    start_epoch = resume['epoch']\n",
    "    model.load_state_dict(resume['state_dict'])\n",
    "    optimizer.load_state_dict(resume['optimizer'])\n",
    "    logger = Logger(os.path.join(checkpoint, 'log.txt'), resume=True)\n",
    "else:\n",
    "    logger = Logger(os.path.join(checkpoint, 'log.txt'))\n",
    "    logger.set_names(['Learning Rate', 'Train Loss', 'Valid Loss', 'Train Acc.', 'Valid Acc.', 'Train AUROC.', 'Valid AUROC.'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch, use_cuda):\n",
    "    model.train()\n",
    "    \n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    arc = AverageMeter()\n",
    "    end = time.time()\n",
    "    \n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        batch_size = inputs.size(0)\n",
    "        if batch_size < train_batch:\n",
    "            continue\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            \n",
    "        r = np.random.rand(1)\n",
    "        if cm_beta > 0 and r < cm_prob:\n",
    "            \n",
    "            rand_index = torch.randperm(inputs.size()[0]).cuda()\n",
    "            tt= targets[rand_index]\n",
    "            boolean = targets==tt\n",
    "            rand_index = rand_index[boolean]\n",
    "            lam = np.random.beta(cm_beta, cm_beta)\n",
    "            bbx1, bby1, bbx2, bby2 = rand_bbox(inputs.size(), lam)\n",
    "            inputs[boolean, :, bbx1:bbx2, bby1:bby2] = inputs[rand_index, :, bbx1:bbx2, bby1:bby2]\n",
    "\n",
    "        # compute output\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1 = accuracy(outputs.data, targets.data)\n",
    "        auroc = roc_auc_score(targets.cpu().detach().numpy(), outputs.cpu().detach().numpy()[:,1])\n",
    "        losses.update(loss.data.tolist(), inputs.size(0))\n",
    "        top1.update(prec1[0], inputs.size(0))\n",
    "        arc.update(auroc, inputs.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print('{batch}/{size} | Loss:{loss:.4f} | top1:{tp1:.4f} | AUROC:{ac:.4f}'.format(\n",
    "                     batch=batch_idx+1, size=len(train_loader), loss=losses.avg, tp1=top1.avg, ac=arc.avg))\n",
    "    print('{batch}/{size} | Loss:{loss:.4f} | top1:{tp1:.4f} | AUROC:{ac:.4f}'.format(\n",
    "                     batch=batch_idx+1, size=len(train_loader), loss=losses.avg, tp1=top1.avg, ac=arc.avg))\n",
    "    return (losses.avg, top1.avg, arc.avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(val_loader, model, criterion, epoch, use_cuda):\n",
    "    global best_acc\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    arc = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(val_loader):\n",
    "            # measure data loading time\n",
    "            data_time.update(time.time() - end)\n",
    "\n",
    "            if use_cuda:\n",
    "                inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "            # compute output\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            prec1 = accuracy(outputs.data, targets.data)\n",
    "            auroc = roc_auc_score(targets.cpu().detach().numpy(), outputs.cpu().detach().numpy()[:,1])\n",
    "            losses.update(loss.data.tolist(), inputs.size(0))\n",
    "            top1.update(prec1[0], inputs.size(0))\n",
    "            arc.update(auroc, inputs.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "    print('{batch}/{size} | Loss:{loss:.4f} | top1:{tp1:.4f} | AUROC:{ac:.4f}'.format(\n",
    "         batch=batch_idx+1, size=len(val_loader), loss=losses.avg, tp1=top1.avg, ac=arc.avg))\n",
    "    return (losses.avg, top1.avg, arc.avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, checkpoint='checkpoint', filename='checkpoint.pth.tar'):\n",
    "    filepath = os.path.join(checkpoint, filename)\n",
    "    torch.save(state, filepath)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filepath, os.path.join(checkpoint, 'model_best.pth.tar'))\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    global state\n",
    "    lr_set = [1, 1e-1, 1e-2, 1e-3, 1e-4, 1e-5]\n",
    "    lr_list = schedule.copy()\n",
    "    lr_list.append(epoch)\n",
    "    lr_list.sort()\n",
    "    idx = lr_list.index(epoch)\n",
    "    state['lr'] *= lr_set[idx]\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = state['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [1 | 400] LR: 0.040000\n",
      "1/1073 | Loss:0.6945 | top1:50.0000 | AUROC:0.5456\n",
      "101/1073 | Loss:0.7263 | top1:50.3868 | AUROC:0.4950\n",
      "201/1073 | Loss:0.7160 | top1:50.3245 | AUROC:0.4997\n",
      "301/1073 | Loss:0.7102 | top1:50.1921 | AUROC:0.4999\n",
      "401/1073 | Loss:0.7068 | top1:50.1880 | AUROC:0.4998\n",
      "501/1073 | Loss:0.7044 | top1:50.2183 | AUROC:0.5002\n",
      "601/1073 | Loss:0.7028 | top1:50.2567 | AUROC:0.5010\n",
      "701/1073 | Loss:0.7018 | top1:50.2474 | AUROC:0.5012\n",
      "801/1073 | Loss:0.7009 | top1:50.2980 | AUROC:0.5018\n",
      "901/1073 | Loss:0.7002 | top1:50.2814 | AUROC:0.5022\n",
      "1001/1073 | Loss:0.6996 | top1:50.2400 | AUROC:0.5020\n",
      "1073/1073 | Loss:0.6992 | top1:50.2179 | AUROC:0.5025\n",
      "120/120 | Loss:0.6961 | top1:50.0000 | AUROC:0.5170\n",
      "\n",
      "Epoch: [2 | 400] LR: 0.068000\n",
      "1/1073 | Loss:0.7029 | top1:44.5312 | AUROC:0.5764\n",
      "101/1073 | Loss:0.6949 | top1:49.6945 | AUROC:0.5047\n",
      "201/1073 | Loss:0.6946 | top1:50.1846 | AUROC:0.5072\n",
      "301/1073 | Loss:0.6944 | top1:50.3154 | AUROC:0.5100\n",
      "401/1073 | Loss:0.6941 | top1:50.6147 | AUROC:0.5159\n",
      "501/1073 | Loss:0.6940 | top1:50.7485 | AUROC:0.5179\n",
      "601/1073 | Loss:0.6938 | top1:50.9788 | AUROC:0.5206\n",
      "701/1073 | Loss:0.6937 | top1:51.0554 | AUROC:0.5236\n",
      "801/1073 | Loss:0.6935 | top1:51.2948 | AUROC:0.5263\n",
      "901/1073 | Loss:0.6931 | top1:51.5417 | AUROC:0.5290\n",
      "1001/1073 | Loss:0.6926 | top1:51.7763 | AUROC:0.5325\n",
      "1073/1073 | Loss:0.6922 | top1:51.9611 | AUROC:0.5353\n",
      "120/120 | Loss:0.6818 | top1:56.2746 | AUROC:0.5894\n",
      "\n",
      "Epoch: [3 | 400] LR: 0.096000\n",
      "1/1073 | Loss:0.6912 | top1:54.6875 | AUROC:0.5355\n",
      "101/1073 | Loss:0.6856 | top1:54.7765 | AUROC:0.5774\n",
      "201/1073 | Loss:0.6830 | top1:55.5523 | AUROC:0.5894\n",
      "301/1073 | Loss:0.6808 | top1:56.0787 | AUROC:0.5992\n",
      "401/1073 | Loss:0.6769 | top1:56.9981 | AUROC:0.6116\n",
      "501/1073 | Loss:0.6676 | top1:58.4901 | AUROC:0.6314\n",
      "601/1073 | Loss:0.6531 | top1:60.2635 | AUROC:0.6541\n",
      "701/1073 | Loss:0.6365 | top1:62.0247 | AUROC:0.6769\n",
      "801/1073 | Loss:0.6214 | top1:63.5402 | AUROC:0.6969\n",
      "901/1073 | Loss:0.6044 | top1:65.1065 | AUROC:0.7157\n",
      "1001/1073 | Loss:0.5885 | top1:66.4968 | AUROC:0.7322\n",
      "1073/1073 | Loss:0.5779 | top1:67.3719 | AUROC:0.7426\n",
      "120/120 | Loss:0.3564 | top1:84.8034 | AUROC:0.9252\n",
      "\n",
      "Epoch: [4 | 400] LR: 0.124000\n",
      "1/1073 | Loss:0.4183 | top1:80.8594 | AUROC:0.8879\n",
      "101/1073 | Loss:0.4281 | top1:80.0433 | AUROC:0.8913\n",
      "201/1073 | Loss:0.4241 | top1:80.2589 | AUROC:0.8951\n",
      "301/1073 | Loss:0.4157 | top1:80.6582 | AUROC:0.8988\n",
      "401/1073 | Loss:0.4078 | top1:81.1039 | AUROC:0.9029\n",
      "501/1073 | Loss:0.4038 | top1:81.4075 | AUROC:0.9061\n",
      "601/1073 | Loss:0.3965 | top1:81.7563 | AUROC:0.9092\n",
      "701/1073 | Loss:0.3894 | top1:82.1477 | AUROC:0.9119\n",
      "801/1073 | Loss:0.3840 | top1:82.4453 | AUROC:0.9145\n",
      "901/1073 | Loss:0.3785 | top1:82.7613 | AUROC:0.9169\n",
      "1001/1073 | Loss:0.3735 | top1:83.0583 | AUROC:0.9190\n",
      "1073/1073 | Loss:0.3698 | top1:83.2545 | AUROC:0.9206\n",
      "120/120 | Loss:0.2362 | top1:90.3244 | AUROC:0.9673\n",
      "\n",
      "Epoch: [5 | 400] LR: 0.152000\n",
      "1/1073 | Loss:0.3096 | top1:86.3281 | AUROC:0.9411\n",
      "101/1073 | Loss:0.3168 | top1:86.2546 | AUROC:0.9426\n",
      "201/1073 | Loss:0.3179 | top1:86.2912 | AUROC:0.9438\n",
      "301/1073 | Loss:0.3156 | top1:86.3164 | AUROC:0.9445\n",
      "401/1073 | Loss:0.3108 | top1:86.5152 | AUROC:0.9457\n",
      "501/1073 | Loss:0.3115 | top1:86.4919 | AUROC:0.9463\n",
      "601/1073 | Loss:0.3090 | top1:86.5725 | AUROC:0.9471\n",
      "701/1073 | Loss:0.3066 | top1:86.7260 | AUROC:0.9482\n",
      "801/1073 | Loss:0.3032 | top1:86.8782 | AUROC:0.9492\n",
      "901/1073 | Loss:0.3001 | top1:87.0149 | AUROC:0.9502\n",
      "1001/1073 | Loss:0.2971 | top1:87.1578 | AUROC:0.9511\n",
      "1073/1073 | Loss:0.2958 | top1:87.2223 | AUROC:0.9516\n",
      "120/120 | Loss:0.1769 | top1:92.9915 | AUROC:0.9831\n",
      "\n",
      "Epoch: [6 | 400] LR: 0.180000\n",
      "1/1073 | Loss:0.2548 | top1:88.2812 | AUROC:0.9636\n",
      "101/1073 | Loss:0.2789 | top1:88.0376 | AUROC:0.9577\n",
      "201/1073 | Loss:0.2728 | top1:88.3026 | AUROC:0.9603\n",
      "301/1073 | Loss:0.2675 | top1:88.6797 | AUROC:0.9615\n",
      "401/1073 | Loss:0.2648 | top1:88.8073 | AUROC:0.9623\n",
      "501/1073 | Loss:0.2628 | top1:88.9183 | AUROC:0.9630\n",
      "601/1073 | Loss:0.2592 | top1:89.0833 | AUROC:0.9638\n",
      "701/1073 | Loss:0.2562 | top1:89.1823 | AUROC:0.9645\n",
      "801/1073 | Loss:0.2549 | top1:89.2366 | AUROC:0.9650\n",
      "901/1073 | Loss:0.2526 | top1:89.3239 | AUROC:0.9657\n",
      "1001/1073 | Loss:0.2503 | top1:89.4375 | AUROC:0.9661\n",
      "1073/1073 | Loss:0.2492 | top1:89.4863 | AUROC:0.9665\n",
      "120/120 | Loss:0.1724 | top1:93.5911 | AUROC:0.9874\n",
      "\n",
      "Epoch: [7 | 400] LR: 0.208000\n",
      "1/1073 | Loss:0.2655 | top1:89.0625 | AUROC:0.9657\n",
      "101/1073 | Loss:0.2380 | top1:90.0178 | AUROC:0.9720\n",
      "201/1073 | Loss:0.2367 | top1:90.0342 | AUROC:0.9712\n",
      "301/1073 | Loss:0.2348 | top1:90.1734 | AUROC:0.9712\n",
      "401/1073 | Loss:0.2340 | top1:90.2256 | AUROC:0.9713\n",
      "501/1073 | Loss:0.2299 | top1:90.4098 | AUROC:0.9721\n",
      "601/1073 | Loss:0.2286 | top1:90.4820 | AUROC:0.9723\n",
      "701/1073 | Loss:0.2278 | top1:90.5258 | AUROC:0.9727\n",
      "801/1073 | Loss:0.2257 | top1:90.6269 | AUROC:0.9731\n",
      "901/1073 | Loss:0.2302 | top1:90.4525 | AUROC:0.9721\n",
      "1001/1073 | Loss:0.2287 | top1:90.5220 | AUROC:0.9724\n",
      "1073/1073 | Loss:0.2286 | top1:90.5346 | AUROC:0.9725\n",
      "120/120 | Loss:0.1294 | top1:95.1409 | AUROC:0.9899\n",
      "\n",
      "Epoch: [8 | 400] LR: 0.236000\n",
      "1/1073 | Loss:0.1881 | top1:92.5781 | AUROC:0.9769\n",
      "101/1073 | Loss:0.2004 | top1:91.6499 | AUROC:0.9781\n",
      "201/1073 | Loss:0.2044 | top1:91.4276 | AUROC:0.9775\n",
      "301/1073 | Loss:0.2030 | top1:91.4932 | AUROC:0.9779\n",
      "401/1073 | Loss:0.2064 | top1:91.3517 | AUROC:0.9772\n",
      "501/1073 | Loss:0.2088 | top1:91.2745 | AUROC:0.9769\n",
      "601/1073 | Loss:0.2066 | top1:91.3926 | AUROC:0.9772\n",
      "701/1073 | Loss:0.2080 | top1:91.3355 | AUROC:0.9773\n",
      "801/1073 | Loss:0.2061 | top1:91.4350 | AUROC:0.9775\n",
      "901/1073 | Loss:0.2062 | top1:91.4418 | AUROC:0.9777\n",
      "1001/1073 | Loss:0.2053 | top1:91.4898 | AUROC:0.9779\n",
      "1073/1073 | Loss:0.2048 | top1:91.5156 | AUROC:0.9780\n",
      "120/120 | Loss:0.1398 | top1:94.4594 | AUROC:0.9906\n",
      "\n",
      "Epoch: [9 | 400] LR: 0.264000\n",
      "1/1073 | Loss:0.2181 | top1:91.4062 | AUROC:0.9711\n",
      "101/1073 | Loss:0.1926 | top1:92.1179 | AUROC:0.9807\n",
      "201/1073 | Loss:0.2076 | top1:91.4043 | AUROC:0.9790\n",
      "301/1073 | Loss:0.2073 | top1:91.4011 | AUROC:0.9791\n",
      "401/1073 | Loss:0.2074 | top1:91.3527 | AUROC:0.9791\n",
      "501/1073 | Loss:0.2060 | top1:91.4218 | AUROC:0.9790\n",
      "601/1073 | Loss:0.2054 | top1:91.4777 | AUROC:0.9789\n",
      "701/1073 | Loss:0.2042 | top1:91.5456 | AUROC:0.9791\n",
      "801/1073 | Loss:0.2035 | top1:91.5916 | AUROC:0.9791\n",
      "901/1073 | Loss:0.2016 | top1:91.6755 | AUROC:0.9794\n",
      "1001/1073 | Loss:0.2010 | top1:91.7044 | AUROC:0.9795\n",
      "1073/1073 | Loss:0.2015 | top1:91.7003 | AUROC:0.9795\n",
      "120/120 | Loss:0.2358 | top1:90.3834 | AUROC:0.9880\n",
      "\n",
      "Epoch: [10 | 400] LR: 0.292000\n",
      "1/1073 | Loss:0.2643 | top1:87.8906 | AUROC:0.9856\n",
      "101/1073 | Loss:0.2243 | top1:90.6908 | AUROC:0.9768\n",
      "201/1073 | Loss:0.2132 | top1:91.2858 | AUROC:0.9778\n",
      "301/1073 | Loss:0.2156 | top1:91.2310 | AUROC:0.9771\n",
      "401/1073 | Loss:0.2122 | top1:91.3634 | AUROC:0.9774\n",
      "501/1073 | Loss:0.2157 | top1:91.2129 | AUROC:0.9771\n",
      "601/1073 | Loss:0.2135 | top1:91.2899 | AUROC:0.9774\n",
      "701/1073 | Loss:0.2112 | top1:91.3829 | AUROC:0.9778\n",
      "801/1073 | Loss:0.2078 | top1:91.5316 | AUROC:0.9785\n",
      "901/1073 | Loss:0.2059 | top1:91.5870 | AUROC:0.9788\n",
      "1001/1073 | Loss:0.2034 | top1:91.6981 | AUROC:0.9793\n",
      "1073/1073 | Loss:0.2021 | top1:91.7404 | AUROC:0.9795\n",
      "120/120 | Loss:0.0971 | top1:96.4155 | AUROC:0.9939\n",
      "\n",
      "Epoch: [11 | 400] LR: 0.320000\n",
      "1/1073 | Loss:0.1549 | top1:92.1875 | AUROC:0.9843\n",
      "101/1073 | Loss:0.2035 | top1:91.7389 | AUROC:0.9804\n",
      "201/1073 | Loss:0.2038 | top1:91.7580 | AUROC:0.9800\n",
      "301/1073 | Loss:0.2140 | top1:91.3271 | AUROC:0.9787\n",
      "401/1073 | Loss:0.2112 | top1:91.4374 | AUROC:0.9788\n",
      "501/1073 | Loss:0.2053 | top1:91.6955 | AUROC:0.9794\n",
      "601/1073 | Loss:0.2025 | top1:91.7663 | AUROC:0.9800\n",
      "701/1073 | Loss:0.2014 | top1:91.7985 | AUROC:0.9803\n",
      "801/1073 | Loss:0.2022 | top1:91.7501 | AUROC:0.9800\n",
      "901/1073 | Loss:0.2003 | top1:91.8134 | AUROC:0.9803\n",
      "1001/1073 | Loss:0.1975 | top1:91.9167 | AUROC:0.9808\n",
      "1073/1073 | Loss:0.1964 | top1:91.9536 | AUROC:0.9809\n",
      "120/120 | Loss:0.1196 | top1:95.4456 | AUROC:0.9930\n",
      "\n",
      "Epoch: [12 | 400] LR: 0.320000\n",
      "1/1073 | Loss:0.1352 | top1:95.3125 | AUROC:0.9924\n",
      "101/1073 | Loss:0.1889 | top1:92.2648 | AUROC:0.9826\n",
      "201/1073 | Loss:0.1897 | top1:92.2400 | AUROC:0.9823\n",
      "301/1073 | Loss:0.1941 | top1:92.1278 | AUROC:0.9821\n",
      "401/1073 | Loss:0.1925 | top1:92.1651 | AUROC:0.9820\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "501/1073 | Loss:0.1951 | top1:92.0362 | AUROC:0.9815\n",
      "601/1073 | Loss:0.1953 | top1:92.0803 | AUROC:0.9814\n",
      "701/1073 | Loss:0.1935 | top1:92.1541 | AUROC:0.9816\n",
      "801/1073 | Loss:0.1924 | top1:92.1997 | AUROC:0.9817\n",
      "901/1073 | Loss:0.1909 | top1:92.2816 | AUROC:0.9820\n",
      "1001/1073 | Loss:0.1907 | top1:92.3014 | AUROC:0.9821\n",
      "1073/1073 | Loss:0.1897 | top1:92.3351 | AUROC:0.9822\n",
      "120/120 | Loss:0.0976 | top1:96.2975 | AUROC:0.9941\n",
      "\n",
      "Epoch: [13 | 400] LR: 0.319995\n",
      "1/1073 | Loss:0.1985 | top1:90.6250 | AUROC:0.9774\n",
      "101/1073 | Loss:0.1664 | top1:93.3130 | AUROC:0.9852\n",
      "201/1073 | Loss:0.1737 | top1:92.9765 | AUROC:0.9851\n",
      "301/1073 | Loss:0.1746 | top1:92.9428 | AUROC:0.9849\n",
      "401/1073 | Loss:0.1767 | top1:92.8558 | AUROC:0.9847\n",
      "501/1073 | Loss:0.1767 | top1:92.8884 | AUROC:0.9847\n",
      "601/1073 | Loss:0.1766 | top1:92.8986 | AUROC:0.9846\n",
      "701/1073 | Loss:0.1758 | top1:92.9231 | AUROC:0.9846\n",
      "801/1073 | Loss:0.1767 | top1:92.9083 | AUROC:0.9846\n",
      "901/1073 | Loss:0.1751 | top1:92.9518 | AUROC:0.9848\n",
      "1001/1073 | Loss:0.1761 | top1:92.9157 | AUROC:0.9848\n",
      "1073/1073 | Loss:0.1763 | top1:92.8908 | AUROC:0.9847\n",
      "120/120 | Loss:0.0977 | top1:96.3073 | AUROC:0.9946\n",
      "\n",
      "Epoch: [14 | 400] LR: 0.319980\n",
      "1/1073 | Loss:0.1264 | top1:95.3125 | AUROC:0.9922\n",
      "101/1073 | Loss:0.1711 | top1:93.1583 | AUROC:0.9844\n",
      "201/1073 | Loss:0.1796 | top1:92.7627 | AUROC:0.9840\n",
      "301/1073 | Loss:0.1797 | top1:92.7884 | AUROC:0.9838\n",
      "401/1073 | Loss:0.1805 | top1:92.6804 | AUROC:0.9837\n",
      "501/1073 | Loss:0.1780 | top1:92.8253 | AUROC:0.9840\n",
      "601/1073 | Loss:0.1766 | top1:92.8869 | AUROC:0.9843\n",
      "701/1073 | Loss:0.1746 | top1:92.9610 | AUROC:0.9844\n",
      "801/1073 | Loss:0.1740 | top1:92.9863 | AUROC:0.9846\n",
      "901/1073 | Loss:0.1739 | top1:92.9900 | AUROC:0.9847\n",
      "1001/1073 | Loss:0.1734 | top1:93.0171 | AUROC:0.9847\n",
      "1073/1073 | Loss:0.1738 | top1:92.9921 | AUROC:0.9848\n",
      "120/120 | Loss:0.0868 | top1:96.9135 | AUROC:0.9952\n",
      "\n",
      "Epoch: [15 | 400] LR: 0.319956\n",
      "1/1073 | Loss:0.2068 | top1:91.7969 | AUROC:0.9783\n",
      "101/1073 | Loss:0.1802 | top1:92.7831 | AUROC:0.9845\n",
      "201/1073 | Loss:0.1802 | top1:92.6908 | AUROC:0.9843\n",
      "301/1073 | Loss:0.1749 | top1:92.9220 | AUROC:0.9849\n",
      "401/1073 | Loss:0.1716 | top1:93.0282 | AUROC:0.9853\n",
      "501/1073 | Loss:0.1701 | top1:93.1208 | AUROC:0.9855\n",
      "601/1073 | Loss:0.1693 | top1:93.1845 | AUROC:0.9856\n",
      "701/1073 | Loss:0.1709 | top1:93.0891 | AUROC:0.9855\n",
      "801/1073 | Loss:0.1709 | top1:93.0858 | AUROC:0.9854\n",
      "901/1073 | Loss:0.1709 | top1:93.1110 | AUROC:0.9854\n",
      "1001/1073 | Loss:0.1708 | top1:93.1217 | AUROC:0.9855\n",
      "1073/1073 | Loss:0.1719 | top1:93.0777 | AUROC:0.9854\n",
      "120/120 | Loss:0.1301 | top1:94.9443 | AUROC:0.9940\n",
      "\n",
      "Epoch: [16 | 400] LR: 0.319921\n",
      "1/1073 | Loss:0.1270 | top1:94.9219 | AUROC:0.9969\n",
      "101/1073 | Loss:0.1818 | top1:92.4196 | AUROC:0.9853\n",
      "201/1073 | Loss:0.1773 | top1:92.7764 | AUROC:0.9854\n",
      "301/1073 | Loss:0.1786 | top1:92.7585 | AUROC:0.9850\n",
      "401/1073 | Loss:0.1762 | top1:92.8684 | AUROC:0.9853\n",
      "501/1073 | Loss:0.1784 | top1:92.7824 | AUROC:0.9851\n",
      "601/1073 | Loss:0.1775 | top1:92.8323 | AUROC:0.9852\n",
      "701/1073 | Loss:0.1768 | top1:92.8384 | AUROC:0.9852\n",
      "801/1073 | Loss:0.1772 | top1:92.8342 | AUROC:0.9851\n",
      "901/1073 | Loss:0.1747 | top1:92.9380 | AUROC:0.9854\n",
      "1001/1073 | Loss:0.1742 | top1:92.9566 | AUROC:0.9856\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(start_epoch, epochs):\n",
    "    state['lr'] = optimizer.state_dict()['param_groups'][0]['lr']\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "    print('\\nEpoch: [%d | %d] LR: %f' % (epoch + 1, epochs, state['lr']))\n",
    "    \n",
    "    train_loss, train_acc, train_auroc = train(train_loader, model, criterion, optimizer, epoch, use_cuda)\n",
    "    test_loss, test_acc, test_auroc = test(val_loader, model, criterion, epoch, use_cuda)\n",
    "    \n",
    "    logger.append([state['lr'], train_loss, test_loss, train_acc, test_acc, train_auroc, test_auroc])\n",
    "    scheduler_warmup.step()\n",
    "\n",
    "    is_best = test_acc > best_acc\n",
    "    best_acc = max(test_acc, best_acc)\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'state_dict' : model.state_dict(),\n",
    "        'acc': test_acc,\n",
    "        'best_acc': best_acc,\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    }, is_best, checkpoint=checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
