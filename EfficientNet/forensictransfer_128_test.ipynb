{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "import os, shutil\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "# torch.autograd.set_detect_anomaly(True)\n",
    "import numpy as np\n",
    "# declare batch size for act function\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from torch.autograd import Variable\n",
    "import torchvision.utils as vutils\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(0) \n",
    "\n",
    "batch_size = 1400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU device 2: True\n"
     ]
    }
   ],
   "source": [
    "# GPU Device\n",
    "gpu_id = 2\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(\"GPU device %d:\" %(gpu_id), use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_dir = '/home/kim1'\n",
    "data_dir = '/media/data2/dataset/GAN_ImageData/PGGAN_128/'\n",
    "d_dir = home_dir+data_dir\n",
    "\n",
    "resume = ''\n",
    "pretrained = './log/star/128/foresic/to_style2/2000shot/checkpoint.pth.tar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, checkpoint='checkpoint', filename='checkpoint.pth.tar'):\n",
    "    filepath = os.path.join(checkpoint, filename)\n",
    "    torch.save(state, filepath)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filepath, os.path.join(checkpoint, 'model_best.pth.tar'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = './log/pggan/128/foresic/aug' # dir\n",
    "if not os.path.isdir(checkpoint):\n",
    "    os.makedirs(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoencoder part\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        #should change channel 3\n",
    "        self.conv_1_1 = nn.Conv2d(in_channels=3,out_channels=8,kernel_size=3,padding=1)\n",
    "        self.relu_1_2 = nn.ReLU(True)\n",
    "            \n",
    "        self.conv_2_1 = nn.Conv2d(in_channels=8,out_channels=16,kernel_size=3,stride=2,padding=1)\n",
    "        self.bn_2_2 = nn.BatchNorm2d(16)\n",
    "        self.relu_2_3 = nn.ReLU(True)\n",
    "        \n",
    "        self.conv_3_1 = nn.Conv2d(in_channels=16,out_channels=32,kernel_size=3,stride=2,padding=1)\n",
    "        self.bn_3_2 = nn.BatchNorm2d(32)\n",
    "        self.relu_3_3 = nn.ReLU(True)\n",
    "        \n",
    "        self.conv_4_1=nn.Conv2d(in_channels=32,out_channels=64,kernel_size=3,stride=2,padding=1)\n",
    "        self.bn_4_2=nn.BatchNorm2d(64)\n",
    "        self.relu_4_3=nn.ReLU(True)\n",
    "        \n",
    "        self.conv_5_1 = nn.Conv2d(in_channels=64,out_channels=128,kernel_size=3,stride=2,padding=1)\n",
    "        self.bn_5_2 =nn.BatchNorm2d(128)\n",
    "        self.relu_5_3 = nn.ReLU(True)\n",
    "        \n",
    "        ## decoder\n",
    "        self.upsample_6_1 = nn.Upsample(scale_factor=2,mode='nearest')\n",
    "        self.convtranspose_6_2 = nn.Conv2d(in_channels=128,out_channels=64,kernel_size=3,padding=1)\n",
    "        self.bn_6_3 = nn.BatchNorm2d(64)\n",
    "        self.relu_6_4 = nn.ReLU(True)\n",
    "        \n",
    "        self.upsample_7_1 = nn.Upsample(scale_factor=2,mode='nearest')\n",
    "        self.convtranspose_7_2 = nn.Conv2d(in_channels=64,out_channels=32,kernel_size=3,padding=1)\n",
    "        self.bn_7_3 = nn.BatchNorm2d(32)\n",
    "        self.relu_7_4 = nn.ReLU(True)\n",
    "        \n",
    "        self.upsample_8_1 = nn.Upsample(scale_factor=2,mode='nearest')\n",
    "        self.convtranspose_8_2 = nn.Conv2d(in_channels=32,out_channels=16,kernel_size=3,padding=1)\n",
    "        self.bn_8_3 = nn.BatchNorm2d(16)\n",
    "        self.relu_8_4 = nn.ReLU(True)\n",
    "        \n",
    "        self.upsample_9_1 = nn.Upsample(scale_factor=2,mode='nearest')\n",
    "        self.convtranspose_9_2 = nn.Conv2d(in_channels=16,out_channels=8,kernel_size=3,padding=1)\n",
    "        self.bn_9_3 = nn.BatchNorm2d(8)\n",
    "        self.relu_9_4 = nn.ReLU(True)\n",
    "        #should change channel 6\n",
    "        # 혹시 안되면\n",
    "        # self.conv_10_1 = nn.ConvTranspose2d(in_channels=8,out_channels=3,kernel_size=3,padding=1)\n",
    "        #이걸로 마지막 conv 계층을 바꿔주세요 \n",
    "        self.conv_10_1 = nn.Conv2d(in_channels=8,out_channels=3,kernel_size=3,padding=1)\n",
    "        self.tanh_10_2=nn.Tanh()\n",
    "        \n",
    "        # no masking no *0 or assign value zero not done .        \n",
    "        \n",
    "    def forward(self, x,label):\n",
    "        x1 = self.conv_1_1(x)\n",
    "        x2 = self.relu_1_2(x1)\n",
    "\n",
    "        x3 = self.conv_2_1(x2)\n",
    "        x4 = self.bn_2_2(x3)\n",
    "        x5 = self.relu_2_3(x4)\n",
    "\n",
    "        \n",
    "        x6 = self.conv_3_1(x5)\n",
    "        x7 = self.bn_3_2(x6)\n",
    "        x8 = self.relu_3_3(x7)\n",
    "\n",
    "        \n",
    "        x9 = self.conv_4_1(x8)\n",
    "        x10 = self.bn_4_2(x9)\n",
    "        x11 = self.relu_4_3(x10)\n",
    "\n",
    "        \n",
    "        x12 = self.conv_5_1(x11)\n",
    "        x13 = self.bn_5_2(x12)\n",
    "        x14 = self.relu_5_3(x13)\n",
    "        \n",
    "        act = x14.clone()\n",
    "        dep = x14.clone()\n",
    "\n",
    "        # Selection block setting zero values based on label\n",
    "        # [:64] -> fake data latent space \n",
    "        # [64:] -> real data latent space\n",
    "        # 0->fake 1 ->real\n",
    "        # 15 15\n",
    "        A = torch.nn.Parameter(torch.zeros(64,8,8))\n",
    "        for i in range(len(label)):\n",
    "            #real \n",
    "            if label[i].item():\n",
    "                #setting fake latent space into zero\n",
    "                dep[i,:64] = A\n",
    "            else:\n",
    "                dep[i,64:]=A\n",
    "                \n",
    "        x15 = self.upsample_6_1(dep) \n",
    "        x16 = self.convtranspose_6_2(x15)\n",
    "        x17 = self.bn_6_3(x16)\n",
    "        x18 = self.relu_6_4(x17) \n",
    "        x19 = self.upsample_7_1(x18)\n",
    "        x20 = self.convtranspose_7_2(x19)\n",
    "        x21 = self.bn_7_3(x20)\n",
    "        x22 = self.relu_7_4(x21)\n",
    "        x23 = self.upsample_8_1(x22)\n",
    "        x24 = self.convtranspose_8_2(x23)\n",
    "        x25 = self.bn_8_3(x24)\n",
    "        x26 = self.relu_8_4(x25)\n",
    "        x27 = self.upsample_9_1(x26)\n",
    "        x28 = self.convtranspose_9_2(x27) \n",
    "        x29 = self.bn_9_3(x28)\n",
    "        x30 = self.relu_9_4(x29)\n",
    "        x31 = self.conv_10_1(x30)\n",
    "        x32 = self.tanh_10_2(x31)\n",
    "\n",
    "        return  x32 , act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Autoencoder(\n",
       "  (conv_1_1): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu_1_2): ReLU(inplace=True)\n",
       "  (conv_2_1): Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (bn_2_2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu_2_3): ReLU(inplace=True)\n",
       "  (conv_3_1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (bn_3_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu_3_3): ReLU(inplace=True)\n",
       "  (conv_4_1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (bn_4_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu_4_3): ReLU(inplace=True)\n",
       "  (conv_5_1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (bn_5_2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu_5_3): ReLU(inplace=True)\n",
       "  (upsample_6_1): Upsample(scale_factor=2.0, mode=nearest)\n",
       "  (convtranspose_6_2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn_6_3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu_6_4): ReLU(inplace=True)\n",
       "  (upsample_7_1): Upsample(scale_factor=2.0, mode=nearest)\n",
       "  (convtranspose_7_2): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn_7_3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu_7_4): ReLU(inplace=True)\n",
       "  (upsample_8_1): Upsample(scale_factor=2.0, mode=nearest)\n",
       "  (convtranspose_8_2): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn_8_3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu_8_4): ReLU(inplace=True)\n",
       "  (upsample_9_1): Upsample(scale_factor=2.0, mode=nearest)\n",
       "  (convtranspose_9_2): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn_9_3): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu_9_4): ReLU(inplace=True)\n",
       "  (conv_10_1): Conv2d(8, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (tanh_10_2): Tanh()\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Autoencoder()\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate,eps=1e-7)\n",
    "\n",
    "#configuration\n",
    "\n",
    "num_epochs = 100\n",
    "criterion1 = nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "train_dir = os.path.join(d_dir, 'train')\n",
    "val_dir = os.path.join(d_dir, 'validation')\n",
    "\n",
    "train_data =torchvision.datasets.ImageFolder(root=train_dir,\n",
    "                                                transform = transforms.Compose([transforms.Resize((128 ,128 )),transforms.ToTensor()]))\n",
    "validation_dataset =torchvision.datasets.ImageFolder(root=val_dir,\n",
    "                                                transform = transforms.Compose([transforms.Resize((128 ,128 )),transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(dataset=train_data,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=8)\n",
    "\n",
    "validation_dataloader = torch.utils.data.DataLoader(dataset=validation_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader.classes : ['0_real', '1_fake']\n",
      "validation_dataloader.classes : ['0_real', '1_fake']\n",
      "train_dataloader.classes : {'0_real': 0, '1_fake': 1}\n",
      "validation_dataloader.classes : {'0_real': 0, '1_fake': 1}\n"
     ]
    }
   ],
   "source": [
    "print(\"train_dataloader.classes : %s\" % train_data.classes)\n",
    "print(\"validation_dataloader.classes : %s\" % validation_dataset.classes)\n",
    "print(\"train_dataloader.classes : %s\" % train_data.class_to_idx)\n",
    "print(\"validation_dataloader.classes : %s\" % validation_dataset.class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resume\n",
    "if resume:\n",
    "    print('==> Resuming from checkpoint..')\n",
    "    checkpoint = os.path.dirname(resume)\n",
    "#     checkpoint = torch.load(resume)\n",
    "    resume = torch.load(resume)\n",
    "    best_acc = 0\n",
    "    start_epoch = resume['epoch']\n",
    "    model.load_state_dict(resume['state_dict'])\n",
    "    optimizer.load_state_dict(resume['optimizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def act_loss_func(outputs, labels):\n",
    "    batch_size = outputs.size()[0]\n",
    "    loss_list = torch.zeros([batch_size])\n",
    "    loss_list = loss_list.to(device)\n",
    "    for i in range(batch_size):\n",
    "        #fake\n",
    "        total_loss =torch.zeros([1],dtype=torch.float32)\n",
    "        total_loss = total_loss.to(device)\n",
    "        #real\n",
    "        total_loss_1 =torch.zeros([1],dtype=torch.float32)\n",
    "        total_loss_1 = total_loss.to(device)\n",
    "        # real\n",
    "        if labels[i].item():\n",
    "            #fake\n",
    "            for latent_index in range(64):\n",
    "                temp= torch.sum(torch.abs(outputs[i,latent_index,:,:]))/225\n",
    "                total_loss = torch.sum(total_loss+temp)\n",
    "            #real\n",
    "            for latent_index in range(64,128):\n",
    "                temp1= torch.abs(1 -torch.sum(torch.abs(outputs[i,latent_index,:,:]))/225)\n",
    "                total_loss_1 = torch.sum(total_loss_1+temp1)\n",
    "        #fake\n",
    "        else:\n",
    "            #fake\n",
    "            for latent_index in range(64):\n",
    "                temp= torch.abs(1- torch.sum(torch.abs(outputs[i,latent_index,:,:]))/225)\n",
    "                total_loss = torch.sum(total_loss+temp)\n",
    "            #real\n",
    "            for latent_index in range(64,128):\n",
    "                temp1= torch.sum(torch.abs(outputs[i,latent_index,:,:]))/225\n",
    "                total_loss_1 = torch.sum(total_loss_1+temp1)\n",
    "        \n",
    "        loss_list[i]=total_loss+total_loss_1\n",
    "\n",
    "        \n",
    "    return torch.sum(loss_list)\n",
    "\n",
    "#%%\n",
    "\n",
    "# test\n",
    "def act_loss_test(outputs):\n",
    "    batch_size = outputs.size()[0]\n",
    "    answer = torch.zeros([batch_size,2])\n",
    "    answer.cuda()\n",
    "    for i in range(batch_size):\n",
    "        fake = torch.zeros([1], dtype=torch.float32).to(device)\n",
    "        real = torch.zeros([1], dtype=torch.float32).to(device)\n",
    "        # fake latent space\n",
    "        for latent_index in range(64):\n",
    "            fake = fake + torch.sum(torch.abs(outputs[i, latent_index]))\n",
    "        # real latent space\n",
    "        for latent_index in range(64, 128):\n",
    "            real = real + torch.sum(torch.abs(outputs[i, latent_index]))\n",
    "\n",
    "\n",
    "        answer[i][0] = fake.item() / (fake.item() + real.item())\n",
    "        answer[i][1] = real.item() / (fake.item() + real.item())\n",
    "        \n",
    "            \n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/media/data2/dataset/GAN_ImageData/PGGAN_128/'\n",
    "test_dir = os.path.join(data_dir, 'test_50')\n",
    "target_dir1 = home_dir+test_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/media/data2/dataset/GAN_ImageData/StarGAN_128/'\n",
    "test_dir = os.path.join(data_dir, 'test')\n",
    "target_dir2 = home_dir+test_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/media/data2/dataset/GAN_ImageData/StyleGAN_256/'\n",
    "test_dir = os.path.join(data_dir, 'test')\n",
    "target_dir3 = home_dir+test_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/media/data2/dataset/GAN_ImageData/StyleGAN2_256/'\n",
    "test_dir = os.path.join(data_dir, 'test')\n",
    "target_dir4 = home_dir+test_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "target_names = ['fake','real']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StyleGAN2 loss is 6361463.000000\n",
      "Test Accuracy 0.499390 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.50      0.86      0.63     50000\n",
      "        real       0.50      0.14      0.22     50000\n",
      "\n",
      "    accuracy                           0.50    100000\n",
      "   macro avg       0.50      0.50      0.43    100000\n",
      "weighted avg       0.50      0.50      0.43    100000\n",
      "\n",
      "AUROC:  0.513276789\n",
      "loss is 3793293.750000\n",
      "Test Accuracy 0.520250 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.51      0.81      0.63     30000\n",
      "        real       0.55      0.24      0.33     30000\n",
      "\n",
      "    accuracy                           0.52     60000\n",
      "   macro avg       0.53      0.52      0.48     60000\n",
      "weighted avg       0.53      0.52      0.48     60000\n",
      "\n",
      "AUROC:  0.5314330822222222\n"
     ]
    }
   ],
   "source": [
    "\n",
    "MODEL= Autoencoder()\n",
    "MODEL.load_state_dict(torch.load(pretrained)['state_dict'])\n",
    "MODEL.cuda()\n",
    "MODEL.eval()\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "target_data_1 =torchvision.datasets.ImageFolder(root=target_dir1,\n",
    "                                                transform = transforms.Compose([transforms.Resize((128 ,128 )),transforms.ToTensor()]))\n",
    "target_data_2 =torchvision.datasets.ImageFolder(root=target_dir2,\n",
    "                                                transform = transforms.Compose([transforms.Resize((128 ,128 )),transforms.ToTensor()]))\n",
    "target_data_3 =torchvision.datasets.ImageFolder(root=target_dir3,\n",
    "                                                transform = transforms.Compose([transforms.Resize((128 ,128 )),transforms.ToTensor()]))\n",
    "target_data_4 =torchvision.datasets.ImageFolder(root=target_dir4,\n",
    "                                                transform = transforms.Compose([transforms.Resize((128 ,128 )),transforms.ToTensor()]))\n",
    "\n",
    "\n",
    "zeroshot_data_1 = torch.utils.data.DataLoader(dataset=target_data_1,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "\n",
    "zeroshot_data_2 = torch.utils.data.DataLoader(dataset=target_data_2,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "\n",
    "zeroshot_data_3 = torch.utils.data.DataLoader(dataset=target_data_3,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "\n",
    "zeroshot_data_4 = torch.utils.data.DataLoader(dataset=target_data_4,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     correct= 0\n",
    "#     loss = 0\n",
    "#     pred= []\n",
    "#     labels = []\n",
    "#     outputs_list = []\n",
    "#     for _, (x,label) in enumerate(zeroshot_data_1):\n",
    "#         init = x\n",
    "#         init= init.cuda()\n",
    "#         x = x.view(x.size(),-1)\n",
    "#         x = x.cuda()\n",
    "#         a= label.shape[0]\n",
    "#         temp = torch.rand([a])\n",
    "#         output,act_data = MODEL(x,temp)\n",
    "#         outputs  = act_loss_test(act_data)\n",
    "        \n",
    "#         rec_loss = criterion1(output, init)\n",
    "#         act_loss = act_loss_func(act_data, label)\n",
    "\n",
    "#         loss += act_loss+0.1*rec_loss  \n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         pred += predicted.tolist()\n",
    "#         labels += label.tolist()\n",
    "#         outputs_list += outputs.tolist()\n",
    "#         correct += (predicted == label).sum().item()\n",
    "#         optimizer.zero_grad()\n",
    "#     # print(\"PGGAN_128 loss is %f\" % loss)\n",
    "#     temp =correct/len(zeroshot_data_1)\n",
    "#     print('Test Accuracy %f %%' % temp)\n",
    "#     print(classification_report(labels, pred, target_names=target_names))\n",
    "#     print('AUROC: ', roc_auc_score(labels, np.asarray(outputs_list)[:,1]))\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct= 0\n",
    "    loss = 0\n",
    "    pred= []\n",
    "    labels = []\n",
    "    outputs_list = []\n",
    "    for _, (x,label) in enumerate(zeroshot_data_2):\n",
    "        init = x\n",
    "        init= init.cuda()\n",
    "        x = x.view(x.size(),-1)\n",
    "        x = x.cuda()\n",
    "        a= label.shape[0]\n",
    "        temp = torch.rand([a])\n",
    "        output,act_data = MODEL(x,temp)\n",
    "        outputs  = act_loss_test(act_data)\n",
    "        \n",
    "        rec_loss = criterion1(output, init)\n",
    "        act_loss = act_loss_func(act_data, label)\n",
    "\n",
    "        loss += act_loss+0.1*rec_loss  \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        pred += predicted.tolist()\n",
    "        outputs_list += outputs.tolist()\n",
    "        labels += label.tolist()\n",
    "        correct += (predicted == label).sum().item()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    print(\"StyleGAN2 loss is %f\" % loss)\n",
    "    temp =correct/len(target_data_2)\n",
    "    print('Test Accuracy %f %%' % temp)\n",
    "    print(classification_report(labels, pred, target_names=target_names))\n",
    "    print('AUROC: ', roc_auc_score(labels, np.asarray(outputs_list)[:,1]))\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     correct= 0\n",
    "#     loss = 0\n",
    "#     pred= []\n",
    "#     labels = []\n",
    "#     outputs_list = []\n",
    "#     for _, (x,label) in enumerate(zeroshot_data_3):\n",
    "#         init = x\n",
    "#         init= init.cuda()\n",
    "#         x = x.view(x.size(),-1)\n",
    "#         x = x.cuda()\n",
    "#         a= label.shape[0]\n",
    "#         temp = torch.rand([a])\n",
    "#         output,act_data = MODEL(x,temp)\n",
    "#         outputs  = act_loss_test(act_data)\n",
    "        \n",
    "#         rec_loss = criterion1(output, init)\n",
    "#         act_loss = act_loss_func(act_data, label)\n",
    "\n",
    "#         loss += act_loss+0.1*rec_loss  \n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         pred += predicted.tolist()\n",
    "#         outputs_list += outputs.tolist()\n",
    "#         labels += label.tolist()\n",
    "#         correct += (predicted == label).sum().item()\n",
    "        \n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "#     print(\"StyleGAN2 loss is %f\" % loss)\n",
    "#     temp =correct/len(target_data_3)\n",
    "#     print('Test Accuracy %f %%' % temp)\n",
    "#     print(classification_report(labels, pred, target_names=target_names))\n",
    "#     print('AUROC: ', roc_auc_score(labels, np.asarray(outputs_list)[:,1]))\n",
    "    \n",
    "with torch.no_grad():\n",
    "    correct= 0\n",
    "    loss = 0\n",
    "    pred= []\n",
    "    labels = []\n",
    "    outputs_list = []\n",
    "    for _, (x,label) in enumerate(zeroshot_data_4):\n",
    "        init = x\n",
    "        init= init.cuda()\n",
    "        x = x.view(x.size(),-1)\n",
    "        x = x.cuda()\n",
    "        a= label.shape[0]\n",
    "        temp = torch.rand([a])\n",
    "        output,act_data = MODEL(x,temp)\n",
    "        outputs  = act_loss_test(act_data)\n",
    "        \n",
    "        rec_loss = criterion1(output, init)\n",
    "        act_loss = act_loss_func(act_data, label)\n",
    "\n",
    "        loss += act_loss+0.1*rec_loss  \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        pred += predicted.tolist()\n",
    "        outputs_list += outputs.tolist()\n",
    "        labels += label.tolist()\n",
    "        correct += (predicted == label).sum().item()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    print(\"loss is %f\" % loss)\n",
    "    temp =correct/len(target_data_4)\n",
    "    print('Test Accuracy %f %%' % temp)\n",
    "    print(classification_report(labels, pred, target_names=target_names))\n",
    "    print('AUROC: ', roc_auc_score(labels, np.asarray(outputs_list)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
