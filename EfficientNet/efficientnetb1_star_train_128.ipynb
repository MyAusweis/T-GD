{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from model_pytorch import EfficientNet\n",
    "from utils import Bar,Logger, AverageMeter, accuracy, mkdir_p, savefig\n",
    "from warmup_scheduler import GradualWarmupScheduler\n",
    "\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU device 0: True\n"
     ]
    }
   ],
   "source": [
    "# GPU Device\n",
    "gpu_id = 0\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(\"GPU device %d:\" %(gpu_id), use_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/media/data2/dataset/GAN_ImageData/StarGAN_128/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained = ''\n",
    "resume = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model_name = 'efficientnet-b1' # b0-b7 scale\n",
    "\n",
    "# Optimization\n",
    "num_classes = 2\n",
    "epochs = 300\n",
    "start_epoch = 0\n",
    "train_batch = 200\n",
    "test_batch = 200\n",
    "lr = 0.04\n",
    "schedule = [75, 150, 225]\n",
    "momentum = 0.9\n",
    "gamma = 0.1 # LR is multiplied by gamma on schedule\n",
    "\n",
    "# CheckPoint\n",
    "checkpoint = './log/star/128/b1' # dir\n",
    "if not os.path.isdir(checkpoint):\n",
    "    os.makedirs(checkpoint)\n",
    "num_workers = 4\n",
    "\n",
    "# Seed\n",
    "manual_seed = 7\n",
    "random.seed(manual_seed)\n",
    "torch.cuda.manual_seed_all(manual_seed)\n",
    "\n",
    "# Image\n",
    "size = (128, 128)\n",
    "\n",
    "best_acc = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {}\n",
    "state['num_classes'] = num_classes\n",
    "state['epochs'] = epochs\n",
    "state['start_epoch'] = start_epoch\n",
    "state['train_batch'] = train_batch\n",
    "state['test_batch'] = test_batch\n",
    "state['lr'] = lr\n",
    "state['schedule'] = schedule\n",
    "state['momentum'] = momentum\n",
    "state['gamma'] = gamma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join(data_dir, 'train')\n",
    "val_dir = os.path.join(data_dir, 'validation')    \n",
    "train_aug = transforms.Compose([\n",
    "    transforms.RandomAffine(degrees=2, translate=(0.02, 0.02), scale=(0.98, 1.02), shear=2, fillcolor=(124,117,104)),\n",
    "    transforms.Resize(size),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomErasing(p=0.3, scale=(0.02, 0.10), ratio=(0.3, 3.3), value=0, inplace=True),\n",
    "])\n",
    "val_aug = transforms.Compose([\n",
    "    transforms.Resize(size),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# pin_memory : cuda pin memeory use\n",
    "train_loader = DataLoader(datasets.ImageFolder(train_dir, transform=train_aug),\n",
    "                          batch_size=train_batch, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "val_loader = DataLoader(datasets.ImageFolder(val_dir, val_aug),\n",
    "                       batch_size=test_batch, shuffle=True, num_workers=num_workers, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EfficientNet.from_name(model_name, num_classes=num_classes)\n",
    "\n",
    "# Pre-trained\n",
    "if pretrained:\n",
    "    print(\"=> using pre-trained model '{}'\".format(pretrained))\n",
    "    model.load_state_dict(torch.load(pretrained)['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Total params: 6.52M\n"
     ]
    }
   ],
   "source": [
    "model.to('cuda')\n",
    "cudnn.benchmark = True\n",
    "print('    Total params: %.2fM' % (sum(p.numel() for p in model.parameters())/1000000.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary(model, input_size=(3,64,64), device='cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=1e-4, nesterov=True)\n",
    "# optimizer = optim.Adam(model.parameters(), weight_decay=1e-4)\n",
    "scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)\n",
    "scheduler_warmup = GradualWarmupScheduler(optimizer, multiplier=8, total_epoch=10, after_scheduler=scheduler_cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resume\n",
    "if resume:\n",
    "    print('==> Resuming from checkpoint..')\n",
    "    checkpoint = os.path.dirname(resume)\n",
    "#     checkpoint = torch.load(resume)\n",
    "    resume = torch.load(resume)\n",
    "    best_acc = resume['best_acc']\n",
    "    start_epoch = resume['epoch']\n",
    "    model.load_state_dict(resume['state_dict'])\n",
    "    optimizer.load_state_dict(resume['optimizer'])\n",
    "    logger = Logger(os.path.join(checkpoint, 'log.txt'), resume=True)\n",
    "else:\n",
    "    logger = Logger(os.path.join(checkpoint, 'log.txt'))\n",
    "    logger.set_names(['Learning Rate', 'Train Loss', 'Valid Loss', 'Train Acc.', 'Valid Acc.'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch, use_cuda):\n",
    "    model.train()\n",
    "    torch.set_grad_enabled(True)\n",
    "    \n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    end = time.time()\n",
    "    \n",
    "    bar = Bar('Processing', max=len(train_loader))\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        batch_size = inputs.size(0)\n",
    "        if batch_size < train_batch:\n",
    "            continue\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "        inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "\n",
    "        # compute output\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1 = accuracy(outputs.data, targets.data)\n",
    "        losses.update(loss.data.tolist(), inputs.size(0))\n",
    "        top1.update(prec1[0], inputs.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        # plot progress\n",
    "        bar.suffix  = '({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | Total: {total:} | ETA: {eta:} | Loss: {loss:.4f} | top1: {top1: .4f} '.format(\n",
    "                    batch=batch_idx + 1,\n",
    "                    size=len(train_loader),\n",
    "                    data=data_time.val,\n",
    "                    bt=batch_time.val,\n",
    "                    total=bar.elapsed_td,\n",
    "                    eta=bar.eta_td,\n",
    "                    loss=losses.avg,\n",
    "                    top1=top1.avg,\n",
    "                    )\n",
    "        bar.next()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('{batch}/{size} Data:{data:.3f} | Batch:{bt:.3f} | Total:{total:} | ETA:{eta:} | Loss:{loss:} | top1:{tp1:}'.format(\n",
    "                 batch=batch_idx+1, size=len(train_loader), data=data_time.val, bt=batch_time.val, total=bar.elapsed_td, eta=bar.eta_td, loss=losses.avg, tp1=top1.avg))\n",
    "    bar.finish()\n",
    "    return (losses.avg, top1.avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(val_loader, model, criterion, epoch, use_cuda):\n",
    "    global best_acc\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "    torch.set_grad_enabled(False)\n",
    "\n",
    "    end = time.time()\n",
    "    bar = Bar('Processing', max=len(val_loader))\n",
    "    for batch_idx, (inputs, targets) in enumerate(val_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "        inputs, targets = torch.autograd.Variable(inputs, volatile=True), torch.autograd.Variable(targets)\n",
    "\n",
    "        # compute output\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1 = accuracy(outputs.data, targets.data)\n",
    "        losses.update(loss.data.tolist(), inputs.size(0))\n",
    "        top1.update(prec1[0], inputs.size(0))\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        # plot progress\n",
    "        bar.suffix  = '({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | Total: {total:} | ETA: {eta:} | Loss: {loss:} | top1: {top1:}'.format(\n",
    "                    batch=batch_idx + 1,\n",
    "                    size=len(val_loader),\n",
    "                    data=data_time.avg,\n",
    "                    bt=batch_time.avg,\n",
    "                    total=bar.elapsed_td,\n",
    "                    eta=bar.eta_td,\n",
    "                    loss=losses.avg,\n",
    "                    top1=top1.avg,)\n",
    "        bar.next()\n",
    "    print('{batch}/{size} Data:{data:.3f} | Batch:{bt:.3f} | Total:{total:} | ETA:{eta:} | Loss:{loss:} | top1:{tp1:}'.format(\n",
    "         batch=batch_idx+1, size=len(val_loader), data=data_time.val, bt=batch_time.val, total=bar.elapsed_td, eta=bar.eta_td, loss=losses.avg, tp1=top1.avg))\n",
    "    bar.finish()\n",
    "    return (losses.avg, top1.avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, checkpoint='checkpoint', filename='checkpoint.pth.tar'):\n",
    "    filepath = os.path.join(checkpoint, filename)\n",
    "    torch.save(state, filepath)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filepath, os.path.join(checkpoint, 'model_best.pth.tar'))\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    global state\n",
    "    lr_set = [1, 1e-1, 1e-2, 1e-3, 1e-4, 1e-5]\n",
    "    lr_list = schedule.copy()\n",
    "    lr_list.append(epoch)\n",
    "    lr_list.sort()\n",
    "    idx = lr_list.index(epoch)\n",
    "    state['lr'] *= lr_set[idx]\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = state['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [1 | 300] LR: 0.040000\n",
      "1/1374 Data:4.778 | Batch:8.775 | Total:0:00:08 | ETA:3:20:49 | Loss:0.6947049498558044 | top1:49.5\n",
      "11/1374 Data:0.010 | Batch:0.719 | Total:0:00:15 | ETA:0:32:34 | Loss:0.7476149689067494 | top1:50.09090805053711\n",
      "21/1374 Data:0.006 | Batch:0.640 | Total:0:00:22 | ETA:0:17:37 | Loss:0.7443042596181234 | top1:50.83333206176758\n",
      "31/1374 Data:0.001 | Batch:0.730 | Total:0:00:33 | ETA:0:24:25 | Loss:0.7497971057891846 | top1:50.51613235473633\n",
      "41/1374 Data:0.003 | Batch:0.704 | Total:0:00:44 | ETA:0:24:05 | Loss:0.7440140378184434 | top1:50.46341323852539\n",
      "51/1374 Data:0.003 | Batch:0.778 | Total:0:00:54 | ETA:0:21:37 | Loss:0.7421530157912011 | top1:50.33333206176758\n",
      "61/1374 Data:0.001 | Batch:0.550 | Total:0:01:03 | ETA:0:19:56 | Loss:0.7452344698984115 | top1:50.16393280029297\n",
      "71/1374 Data:0.007 | Batch:0.664 | Total:0:01:12 | ETA:0:19:57 | Loss:0.7419868522966412 | top1:50.04225540161133\n",
      "81/1374 Data:0.006 | Batch:0.609 | Total:0:01:19 | ETA:0:14:12 | Loss:0.7403922264958606 | top1:50.067901611328125\n",
      "91/1374 Data:0.015 | Batch:0.659 | Total:0:01:25 | ETA:0:14:03 | Loss:0.7369389894244435 | top1:49.989013671875\n",
      "101/1374 Data:0.001 | Batch:0.673 | Total:0:01:31 | ETA:0:12:19 | Loss:0.7350075941274662 | top1:50.0098991394043\n",
      "111/1374 Data:0.001 | Batch:0.556 | Total:0:01:37 | ETA:0:13:04 | Loss:0.7344537092758728 | top1:49.92792892456055\n",
      "121/1374 Data:0.001 | Batch:0.567 | Total:0:01:43 | ETA:0:11:36 | Loss:0.7322772603389646 | top1:50.0\n",
      "131/1374 Data:0.002 | Batch:0.432 | Total:0:01:49 | ETA:0:13:35 | Loss:0.7324555202294852 | top1:49.946563720703125\n",
      "141/1374 Data:0.004 | Batch:0.812 | Total:0:01:55 | ETA:0:11:09 | Loss:0.7297719987571663 | top1:50.08510971069336\n",
      "151/1374 Data:0.001 | Batch:0.443 | Total:0:02:01 | ETA:0:13:24 | Loss:0.728274651315828 | top1:50.052978515625\n",
      "161/1374 Data:0.009 | Batch:0.505 | Total:0:02:07 | ETA:0:11:01 | Loss:0.7269868065851816 | top1:50.04969024658203\n",
      "171/1374 Data:0.010 | Batch:0.530 | Total:0:02:13 | ETA:0:11:53 | Loss:0.7278073457946554 | top1:50.122806549072266\n",
      "181/1374 Data:0.010 | Batch:0.716 | Total:0:02:19 | ETA:0:12:18 | Loss:0.7262609986310505 | top1:50.15469741821289\n",
      "191/1374 Data:0.001 | Batch:0.715 | Total:0:02:25 | ETA:0:12:43 | Loss:0.7259072686365138 | top1:50.05497360229492\n",
      "201/1374 Data:0.001 | Batch:0.481 | Total:0:02:31 | ETA:0:12:18 | Loss:0.7245961495892919 | top1:50.16666793823242\n",
      "211/1374 Data:0.003 | Batch:0.593 | Total:0:02:37 | ETA:0:10:32 | Loss:0.7236689199203563 | top1:50.13507080078125\n",
      "221/1374 Data:0.004 | Batch:0.647 | Total:0:02:42 | ETA:0:10:41 | Loss:0.7228607929130485 | top1:50.07692337036133\n",
      "231/1374 Data:0.001 | Batch:0.616 | Total:0:02:48 | ETA:0:10:29 | Loss:0.7222397306780795 | top1:50.07142639160156\n",
      "241/1374 Data:0.004 | Batch:0.446 | Total:0:02:54 | ETA:0:13:14 | Loss:0.7214019471678991 | top1:50.089210510253906\n",
      "251/1374 Data:0.001 | Batch:0.462 | Total:0:03:01 | ETA:0:11:24 | Loss:0.7205093676350506 | top1:50.117530822753906\n",
      "261/1374 Data:0.001 | Batch:0.441 | Total:0:03:06 | ETA:0:10:17 | Loss:0.7196820501623482 | top1:50.08620834350586\n",
      "271/1374 Data:0.020 | Batch:0.573 | Total:0:03:12 | ETA:0:11:50 | Loss:0.7190741590908093 | top1:50.10332107543945\n",
      "281/1374 Data:0.017 | Batch:0.702 | Total:0:03:19 | ETA:0:10:57 | Loss:0.7187842762767208 | top1:50.081851959228516\n",
      "291/1374 Data:0.001 | Batch:0.747 | Total:0:03:25 | ETA:0:11:09 | Loss:0.7180512332424676 | top1:50.14776611328125\n",
      "301/1374 Data:0.003 | Batch:0.569 | Total:0:03:31 | ETA:0:12:03 | Loss:0.7175611081313453 | top1:50.12956619262695\n",
      "311/1374 Data:0.010 | Batch:0.662 | Total:0:03:37 | ETA:0:10:33 | Loss:0.716937442876135 | top1:50.14630126953125\n",
      "321/1374 Data:0.001 | Batch:0.522 | Total:0:03:43 | ETA:0:10:12 | Loss:0.7163663391383638 | top1:50.1370735168457\n",
      "331/1374 Data:0.001 | Batch:0.496 | Total:0:03:48 | ETA:0:09:06 | Loss:0.7158228310213348 | top1:50.1253776550293\n",
      "341/1374 Data:0.001 | Batch:0.675 | Total:0:03:55 | ETA:0:10:29 | Loss:0.71540345561819 | top1:50.14516067504883\n",
      "351/1374 Data:0.001 | Batch:0.581 | Total:0:04:01 | ETA:0:10:50 | Loss:0.714993443074729 | top1:50.13105392456055\n",
      "361/1374 Data:0.001 | Batch:0.751 | Total:0:04:07 | ETA:0:09:55 | Loss:0.7144169024813538 | top1:50.20637130737305\n",
      "371/1374 Data:0.001 | Batch:0.570 | Total:0:04:13 | ETA:0:09:52 | Loss:0.7139481845891701 | top1:50.194068908691406\n",
      "381/1374 Data:0.012 | Batch:0.511 | Total:0:04:18 | ETA:0:08:18 | Loss:0.7135299253338591 | top1:50.19291305541992\n",
      "391/1374 Data:0.001 | Batch:0.402 | Total:0:04:22 | ETA:0:06:40 | Loss:0.7135354908530974 | top1:50.18925857543945\n",
      "401/1374 Data:0.001 | Batch:0.466 | Total:0:04:26 | ETA:0:07:27 | Loss:0.7131864590537815 | top1:50.19700622558594\n",
      "411/1374 Data:0.000 | Batch:0.408 | Total:0:04:31 | ETA:0:07:06 | Loss:0.7128115292013126 | top1:50.1824836730957\n",
      "421/1374 Data:0.001 | Batch:0.493 | Total:0:04:36 | ETA:0:07:38 | Loss:0.712499721033273 | top1:50.1662712097168\n",
      "431/1374 Data:0.001 | Batch:0.474 | Total:0:04:40 | ETA:0:07:31 | Loss:0.7122098845008354 | top1:50.17401123046875\n",
      "441/1374 Data:0.006 | Batch:0.452 | Total:0:04:45 | ETA:0:07:26 | Loss:0.7119321427107398 | top1:50.166664123535156\n",
      "451/1374 Data:0.589 | Batch:1.069 | Total:0:04:51 | ETA:0:08:23 | Loss:0.7117041135310069 | top1:50.166297912597656\n",
      "461/1374 Data:0.000 | Batch:0.470 | Total:0:04:56 | ETA:0:08:30 | Loss:0.7115691855000312 | top1:50.14533615112305\n",
      "471/1374 Data:0.001 | Batch:0.441 | Total:0:05:01 | ETA:0:07:19 | Loss:0.711208348567825 | top1:50.154991149902344\n",
      "481/1374 Data:0.001 | Batch:0.436 | Total:0:05:05 | ETA:0:07:00 | Loss:0.7109442758461046 | top1:50.167362213134766\n",
      "491/1374 Data:0.000 | Batch:0.394 | Total:0:05:10 | ETA:0:06:32 | Loss:0.710772865294439 | top1:50.15071105957031\n",
      "501/1374 Data:0.009 | Batch:0.475 | Total:0:05:14 | ETA:0:06:37 | Loss:0.7105691311602107 | top1:50.12974166870117\n",
      "511/1374 Data:0.000 | Batch:0.382 | Total:0:05:19 | ETA:0:06:20 | Loss:0.710445677814185 | top1:50.09980392456055\n",
      "521/1374 Data:0.001 | Batch:0.491 | Total:0:05:23 | ETA:0:06:02 | Loss:0.7101571430629137 | top1:50.11900329589844\n",
      "531/1374 Data:0.000 | Batch:0.428 | Total:0:05:28 | ETA:0:06:19 | Loss:0.7099066635983139 | top1:50.13465118408203\n",
      "541/1374 Data:0.002 | Batch:0.715 | Total:0:05:32 | ETA:0:06:19 | Loss:0.7096728270463715 | top1:50.10166549682617\n",
      "551/1374 Data:0.002 | Batch:0.706 | Total:0:05:39 | ETA:0:08:33 | Loss:0.7094734636711771 | top1:50.09346389770508\n",
      "561/1374 Data:0.001 | Batch:0.371 | Total:0:05:45 | ETA:0:08:31 | Loss:0.7092904924496397 | top1:50.08556365966797\n",
      "571/1374 Data:0.000 | Batch:0.637 | Total:0:05:51 | ETA:0:08:03 | Loss:0.7091181861748838 | top1:50.086692810058594\n",
      "581/1374 Data:0.001 | Batch:0.624 | Total:0:05:57 | ETA:0:08:42 | Loss:0.7089410610945828 | top1:50.086055755615234\n",
      "591/1374 Data:0.002 | Batch:0.672 | Total:0:06:04 | ETA:0:08:24 | Loss:0.7087289816030189 | top1:50.09560012817383\n",
      "601/1374 Data:0.002 | Batch:0.655 | Total:0:06:10 | ETA:0:08:19 | Loss:0.7084725973213374 | top1:50.13726806640625\n",
      "611/1374 Data:0.001 | Batch:0.680 | Total:0:06:16 | ETA:0:08:00 | Loss:0.7084148234509408 | top1:50.10556411743164\n",
      "621/1374 Data:0.001 | Batch:0.666 | Total:0:06:23 | ETA:0:08:26 | Loss:0.708223925024607 | top1:50.14170837402344\n",
      "631/1374 Data:0.001 | Batch:0.683 | Total:0:06:30 | ETA:0:08:22 | Loss:0.7081039637657807 | top1:50.14976119995117\n",
      "641/1374 Data:0.006 | Batch:0.508 | Total:0:06:36 | ETA:0:08:01 | Loss:0.7079400922318516 | top1:50.13182830810547\n",
      "651/1374 Data:0.000 | Batch:0.449 | Total:0:06:41 | ETA:0:05:40 | Loss:0.7077773374529661 | top1:50.1344108581543\n",
      "661/1374 Data:0.001 | Batch:0.438 | Total:0:06:45 | ETA:0:05:23 | Loss:0.7076241922270332 | top1:50.12934875488281\n",
      "671/1374 Data:0.001 | Batch:0.523 | Total:0:06:50 | ETA:0:06:06 | Loss:0.7075111993911902 | top1:50.10879135131836\n",
      "681/1374 Data:0.001 | Batch:0.535 | Total:0:06:56 | ETA:0:05:57 | Loss:0.7074177910227782 | top1:50.07268524169922\n",
      "691/1374 Data:0.001 | Batch:0.444 | Total:0:07:00 | ETA:0:05:27 | Loss:0.7072414121821027 | top1:50.086830139160156\n",
      "701/1374 Data:0.001 | Batch:0.480 | Total:0:07:05 | ETA:0:05:15 | Loss:0.7069925343599197 | top1:50.135520935058594\n",
      "711/1374 Data:0.001 | Batch:0.386 | Total:0:07:09 | ETA:0:05:02 | Loss:0.70681206125415 | top1:50.163150787353516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "721/1374 Data:0.001 | Batch:0.490 | Total:0:07:14 | ETA:0:05:24 | Loss:0.7066438475858818 | top1:50.16435623168945\n",
      "731/1374 Data:0.003 | Batch:0.485 | Total:0:07:19 | ETA:0:04:42 | Loss:0.7065048694773672 | top1:50.167579650878906\n",
      "741/1374 Data:0.040 | Batch:0.484 | Total:0:07:24 | ETA:0:05:35 | Loss:0.7063694976762882 | top1:50.17409133911133\n",
      "751/1374 Data:0.001 | Batch:0.425 | Total:0:07:29 | ETA:0:05:04 | Loss:0.7062083797829446 | top1:50.20372772216797\n",
      "761/1374 Data:0.001 | Batch:0.516 | Total:0:07:33 | ETA:0:04:47 | Loss:0.7060715964996549 | top1:50.21156311035156\n",
      "771/1374 Data:0.001 | Batch:0.470 | Total:0:07:38 | ETA:0:04:39 | Loss:0.7059846882226403 | top1:50.209468841552734\n",
      "781/1374 Data:0.001 | Batch:0.510 | Total:0:07:43 | ETA:0:04:47 | Loss:0.7058205488549305 | top1:50.20870590209961\n",
      "791/1374 Data:0.001 | Batch:0.420 | Total:0:07:48 | ETA:0:04:39 | Loss:0.7056997121510704 | top1:50.208595275878906\n",
      "801/1374 Data:0.001 | Batch:0.482 | Total:0:07:52 | ETA:0:04:16 | Loss:0.7056108710173513 | top1:50.21036148071289\n",
      "811/1374 Data:0.001 | Batch:0.513 | Total:0:07:57 | ETA:0:04:40 | Loss:0.7055245302020401 | top1:50.23304748535156\n",
      "821/1374 Data:0.001 | Batch:0.572 | Total:0:08:03 | ETA:0:04:57 | Loss:0.7054325653632578 | top1:50.24299621582031\n",
      "831/1374 Data:0.000 | Batch:0.462 | Total:0:08:08 | ETA:0:04:29 | Loss:0.7052896860561072 | top1:50.258724212646484\n",
      "841/1374 Data:0.000 | Batch:0.437 | Total:0:08:12 | ETA:0:03:53 | Loss:0.705221970143698 | top1:50.2390022277832\n",
      "851/1374 Data:0.001 | Batch:0.535 | Total:0:08:16 | ETA:0:04:09 | Loss:0.7051020808141464 | top1:50.246768951416016\n",
      "861/1374 Data:0.001 | Batch:0.401 | Total:0:08:21 | ETA:0:03:56 | Loss:0.7050113135237035 | top1:50.24100112915039\n",
      "871/1374 Data:0.000 | Batch:0.476 | Total:0:08:26 | ETA:0:03:59 | Loss:0.7049296285473794 | top1:50.24454879760742\n",
      "881/1374 Data:0.001 | Batch:0.439 | Total:0:08:30 | ETA:0:03:59 | Loss:0.7048776948086656 | top1:50.19807052612305\n",
      "891/1374 Data:0.001 | Batch:0.492 | Total:0:08:36 | ETA:0:04:10 | Loss:0.7047582906906051 | top1:50.219417572021484\n",
      "901/1374 Data:0.001 | Batch:0.379 | Total:0:08:40 | ETA:0:03:47 | Loss:0.7046893962744735 | top1:50.22142028808594\n",
      "911/1374 Data:0.001 | Batch:0.451 | Total:0:08:45 | ETA:0:03:31 | Loss:0.7046094974492698 | top1:50.22118377685547\n",
      "921/1374 Data:0.001 | Batch:0.434 | Total:0:08:50 | ETA:0:03:36 | Loss:0.7044896232318153 | top1:50.23995590209961\n",
      "931/1374 Data:0.000 | Batch:0.482 | Total:0:08:54 | ETA:0:03:29 | Loss:0.7044127516920662 | top1:50.23576736450195\n",
      "941/1374 Data:0.001 | Batch:0.460 | Total:0:08:59 | ETA:0:03:38 | Loss:0.7043617078272366 | top1:50.23857498168945\n",
      "951/1374 Data:0.001 | Batch:0.555 | Total:0:09:05 | ETA:0:03:34 | Loss:0.7042929054434743 | top1:50.22397232055664\n",
      "961/1374 Data:0.001 | Batch:0.441 | Total:0:09:10 | ETA:0:03:28 | Loss:0.7041884046687544 | top1:50.236732482910156\n",
      "971/1374 Data:0.000 | Batch:0.369 | Total:0:09:14 | ETA:0:03:01 | Loss:0.704092779316691 | top1:50.239959716796875\n",
      "981/1374 Data:0.001 | Batch:0.442 | Total:0:09:19 | ETA:0:03:08 | Loss:0.7040141630124123 | top1:50.23088836669922\n",
      "991/1374 Data:0.001 | Batch:0.542 | Total:0:09:24 | ETA:0:03:05 | Loss:0.7039540443723545 | top1:50.21997833251953\n",
      "1001/1374 Data:0.001 | Batch:0.450 | Total:0:09:28 | ETA:0:02:56 | Loss:0.7038718018974814 | top1:50.220279693603516\n",
      "1011/1374 Data:0.001 | Batch:0.494 | Total:0:09:33 | ETA:0:02:52 | Loss:0.7038468618892892 | top1:50.20870590209961\n",
      "1021/1374 Data:0.001 | Batch:0.457 | Total:0:09:38 | ETA:0:02:48 | Loss:0.7037694312332893 | top1:50.19637680053711\n",
      "1031/1374 Data:0.001 | Batch:0.577 | Total:0:09:43 | ETA:0:03:05 | Loss:0.7037027342936926 | top1:50.18040466308594\n",
      "1041/1374 Data:0.001 | Batch:0.463 | Total:0:09:48 | ETA:0:02:38 | Loss:0.7036265673028175 | top1:50.16522216796875\n",
      "1051/1374 Data:0.001 | Batch:0.431 | Total:0:09:52 | ETA:0:02:34 | Loss:0.7035802282910478 | top1:50.14985656738281\n",
      "1061/1374 Data:0.001 | Batch:0.469 | Total:0:09:57 | ETA:0:02:23 | Loss:0.7034994096940245 | top1:50.153629302978516\n",
      "1071/1374 Data:0.001 | Batch:0.618 | Total:0:10:02 | ETA:0:02:32 | Loss:0.7034361650184645 | top1:50.14659118652344\n",
      "1081/1374 Data:0.001 | Batch:0.450 | Total:0:10:07 | ETA:0:02:23 | Loss:0.7033354701762062 | top1:50.154945373535156\n",
      "1091/1374 Data:0.000 | Batch:0.573 | Total:0:10:13 | ETA:0:02:58 | Loss:0.70326093584982 | top1:50.158573150634766\n",
      "1101/1374 Data:0.007 | Batch:0.703 | Total:0:10:20 | ETA:0:02:55 | Loss:0.7031947075508596 | top1:50.16939163208008\n",
      "1111/1374 Data:0.004 | Batch:0.670 | Total:0:10:25 | ETA:0:02:36 | Loss:0.7031460106641081 | top1:50.160213470458984\n",
      "1121/1374 Data:0.012 | Batch:0.670 | Total:0:10:32 | ETA:0:02:48 | Loss:0.7031223749497658 | top1:50.17618179321289\n",
      "1131/1374 Data:0.001 | Batch:0.660 | Total:0:10:39 | ETA:0:02:42 | Loss:0.7030446337030378 | top1:50.18788528442383\n",
      "1141/1374 Data:0.001 | Batch:0.658 | Total:0:10:45 | ETA:0:02:35 | Loss:0.7029750031091788 | top1:50.189308166503906\n",
      "1151/1374 Data:0.002 | Batch:0.654 | Total:0:10:52 | ETA:0:02:26 | Loss:0.7029115158407508 | top1:50.202430725097656\n",
      "1161/1374 Data:0.001 | Batch:0.623 | Total:0:10:59 | ETA:0:02:27 | Loss:0.7028431585387461 | top1:50.21317672729492\n",
      "1171/1374 Data:0.002 | Batch:0.693 | Total:0:11:05 | ETA:0:02:16 | Loss:0.7027795625791704 | top1:50.21092987060547\n",
      "1181/1374 Data:0.011 | Batch:0.408 | Total:0:11:11 | ETA:0:01:52 | Loss:0.702735833199119 | top1:50.21168518066406\n",
      "1191/1374 Data:0.001 | Batch:0.491 | Total:0:11:16 | ETA:0:01:24 | Loss:0.7026773627619098 | top1:50.2283821105957\n",
      "1201/1374 Data:0.012 | Batch:0.494 | Total:0:11:21 | ETA:0:01:24 | Loss:0.7026634792007078 | top1:50.22772979736328\n",
      "1211/1374 Data:0.001 | Batch:0.479 | Total:0:11:25 | ETA:0:01:13 | Loss:0.7026057629226949 | top1:50.2332763671875\n",
      "1221/1374 Data:0.000 | Batch:0.470 | Total:0:11:30 | ETA:0:01:18 | Loss:0.7025428027231903 | top1:50.22850036621094\n",
      "1231/1374 Data:0.001 | Batch:0.458 | Total:0:11:35 | ETA:0:01:06 | Loss:0.7024951054253876 | top1:50.225830078125\n",
      "1241/1374 Data:0.001 | Batch:0.520 | Total:0:11:40 | ETA:0:01:08 | Loss:0.7024489887581056 | top1:50.220787048339844\n",
      "1251/1374 Data:0.004 | Batch:0.439 | Total:0:11:45 | ETA:0:01:05 | Loss:0.7023879842792483 | top1:50.23381423950195\n",
      "1261/1374 Data:0.000 | Batch:0.478 | Total:0:11:50 | ETA:0:00:56 | Loss:0.7023244940223059 | top1:50.25376892089844\n",
      "1271/1374 Data:0.001 | Batch:0.392 | Total:0:11:55 | ETA:0:00:50 | Loss:0.7022566469891816 | top1:50.26593017578125\n",
      "1281/1374 Data:0.009 | Batch:0.535 | Total:0:12:00 | ETA:0:00:49 | Loss:0.7022103337363095 | top1:50.2689323425293\n",
      "1291/1374 Data:0.001 | Batch:0.423 | Total:0:12:05 | ETA:0:00:40 | Loss:0.7021433028207095 | top1:50.2714958190918\n",
      "1301/1374 Data:0.000 | Batch:0.441 | Total:0:12:09 | ETA:0:00:32 | Loss:0.7020950898768625 | top1:50.277095794677734\n",
      "1311/1374 Data:0.000 | Batch:0.545 | Total:0:12:14 | ETA:0:00:31 | Loss:0.7020509542171324 | top1:50.28070068359375\n",
      "1321/1374 Data:0.001 | Batch:0.462 | Total:0:12:18 | ETA:0:00:23 | Loss:0.7019954240746249 | top1:50.28652572631836\n",
      "1331/1374 Data:0.733 | Batch:1.214 | Total:0:12:23 | ETA:0:00:23 | Loss:0.7019428442421934 | top1:50.28887939453125\n",
      "1341/1374 Data:0.001 | Batch:0.383 | Total:0:12:29 | ETA:0:00:21 | Loss:0.7019103049431872 | top1:50.29157257080078\n",
      "1351/1374 Data:0.000 | Batch:0.487 | Total:0:12:33 | ETA:0:00:11 | Loss:0.7018887063999868 | top1:50.28497314453125\n",
      "1361/1374 Data:0.001 | Batch:0.431 | Total:0:12:38 | ETA:0:00:07 | Loss:0.7018302867379284 | top1:50.296104431152344\n",
      "1371/1374 Data:0.000 | Batch:0.469 | Total:0:12:42 | ETA:0:00:02 | Loss:0.7017968288744392 | top1:50.286651611328125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cutz/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:21: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153/153 Data:0.000 | Batch:0.786 | Total:0:01:02 | ETA:0:00:00 | Loss:0.6940237873503609 | top1:50.429229736328125\n",
      "\n",
      "Epoch: [2 | 300] LR: 0.068000\n",
      "1/1374 Data:1.162 | Batch:1.852 | Total:0:00:01 | ETA:0:42:24 | Loss:0.6997387409210205 | top1:47.5\n",
      "11/1374 Data:0.000 | Batch:0.394 | Total:0:00:06 | ETA:0:13:49 | Loss:0.6987679275599393 | top1:50.681819915771484\n",
      "21/1374 Data:0.001 | Batch:0.482 | Total:0:00:10 | ETA:0:09:54 | Loss:0.6989927973066058 | top1:51.35714340209961\n",
      "31/1374 Data:0.001 | Batch:0.371 | Total:0:00:15 | ETA:0:10:04 | Loss:0.6977941778398329 | top1:51.000003814697266\n",
      "41/1374 Data:0.001 | Batch:0.459 | Total:0:00:19 | ETA:0:09:44 | Loss:0.6977050537016334 | top1:50.70731735229492\n",
      "51/1374 Data:0.001 | Batch:0.476 | Total:0:00:24 | ETA:0:10:10 | Loss:0.6974992857259863 | top1:50.97058868408203\n",
      "61/1374 Data:0.001 | Batch:0.565 | Total:0:00:28 | ETA:0:09:32 | Loss:0.6974737888476887 | top1:51.02458953857422\n",
      "71/1374 Data:0.001 | Batch:0.462 | Total:0:00:33 | ETA:0:10:44 | Loss:0.6968637411023529 | top1:51.00704574584961\n",
      "81/1374 Data:0.005 | Batch:0.480 | Total:0:00:38 | ETA:0:09:27 | Loss:0.6968982168185858 | top1:51.22222137451172\n",
      "91/1374 Data:0.000 | Batch:0.464 | Total:0:00:43 | ETA:0:10:38 | Loss:0.6969803001854445 | top1:51.20879364013672\n",
      "101/1374 Data:0.000 | Batch:0.452 | Total:0:00:47 | ETA:0:10:15 | Loss:0.6968576135021625 | top1:51.153465270996094\n",
      "111/1374 Data:0.000 | Batch:0.496 | Total:0:00:52 | ETA:0:10:00 | Loss:0.696405579377939 | top1:51.25675964355469\n",
      "121/1374 Data:0.001 | Batch:0.413 | Total:0:00:57 | ETA:0:09:42 | Loss:0.6968622429311768 | top1:51.30165100097656\n",
      "131/1374 Data:0.001 | Batch:0.574 | Total:0:01:03 | ETA:0:11:40 | Loss:0.6966253596407767 | top1:51.3015251159668\n",
      "141/1374 Data:0.001 | Batch:0.380 | Total:0:01:08 | ETA:0:11:47 | Loss:0.6965559133401154 | top1:51.2907829284668\n",
      "151/1374 Data:0.001 | Batch:0.659 | Total:0:01:14 | ETA:0:11:06 | Loss:0.6964429198511389 | top1:51.29138946533203\n",
      "161/1374 Data:0.001 | Batch:0.555 | Total:0:01:20 | ETA:0:12:43 | Loss:0.6964695760922403 | top1:51.260868072509766\n",
      "171/1374 Data:0.001 | Batch:0.592 | Total:0:01:27 | ETA:0:13:06 | Loss:0.6965740072099786 | top1:51.122806549072266\n",
      "181/1374 Data:0.001 | Batch:0.679 | Total:0:01:33 | ETA:0:13:19 | Loss:0.6966047741431558 | top1:51.143646240234375\n",
      "191/1374 Data:0.002 | Batch:0.731 | Total:0:01:40 | ETA:0:12:57 | Loss:0.6967146168828635 | top1:51.143978118896484\n",
      "201/1374 Data:0.002 | Batch:0.660 | Total:0:01:47 | ETA:0:13:03 | Loss:0.6966087079759854 | top1:51.14179229736328\n",
      "211/1374 Data:0.011 | Batch:0.621 | Total:0:01:53 | ETA:0:12:50 | Loss:0.6965665286186182 | top1:51.1895751953125\n",
      "221/1374 Data:0.001 | Batch:0.725 | Total:0:02:00 | ETA:0:12:31 | Loss:0.6964394239818349 | top1:51.2669677734375\n",
      "231/1374 Data:0.000 | Batch:0.425 | Total:0:02:05 | ETA:0:09:54 | Loss:0.696437258999069 | top1:51.21861267089844\n",
      "241/1374 Data:0.001 | Batch:0.459 | Total:0:02:10 | ETA:0:09:01 | Loss:0.6964793690012698 | top1:51.17219924926758\n",
      "251/1374 Data:0.001 | Batch:0.393 | Total:0:02:14 | ETA:0:09:04 | Loss:0.696564061233247 | top1:51.11952209472656\n",
      "261/1374 Data:0.001 | Batch:0.475 | Total:0:02:19 | ETA:0:08:33 | Loss:0.696515975098957 | top1:51.11302947998047\n",
      "271/1374 Data:0.001 | Batch:0.402 | Total:0:02:24 | ETA:0:08:59 | Loss:0.696500038308851 | top1:51.13837432861328\n",
      "281/1374 Data:0.000 | Batch:0.469 | Total:0:02:28 | ETA:0:08:09 | Loss:0.6963527722290827 | top1:51.1298942565918\n",
      "291/1374 Data:0.001 | Batch:0.506 | Total:0:02:33 | ETA:0:08:44 | Loss:0.6964334456371688 | top1:51.08762741088867\n",
      "301/1374 Data:0.001 | Batch:0.516 | Total:0:02:38 | ETA:0:08:18 | Loss:0.6964434151633634 | top1:51.02159118652344\n",
      "311/1374 Data:0.000 | Batch:0.474 | Total:0:02:43 | ETA:0:08:38 | Loss:0.6966519503348126 | top1:50.93729782104492\n",
      "321/1374 Data:0.000 | Batch:0.461 | Total:0:02:47 | ETA:0:07:51 | Loss:0.6967516844146349 | top1:50.86293029785156\n",
      "331/1374 Data:0.000 | Batch:0.480 | Total:0:02:52 | ETA:0:08:14 | Loss:0.6967219602305363 | top1:50.85649490356445\n",
      "341/1374 Data:0.001 | Batch:0.454 | Total:0:02:56 | ETA:0:07:50 | Loss:0.6966762025335318 | top1:50.88269805908203\n",
      "351/1374 Data:0.001 | Batch:0.510 | Total:0:03:01 | ETA:0:08:05 | Loss:0.6967072133664731 | top1:50.8831901550293\n",
      "361/1374 Data:0.010 | Batch:0.594 | Total:0:03:06 | ETA:0:08:15 | Loss:0.6965618612363398 | top1:50.950138092041016\n",
      "371/1374 Data:0.001 | Batch:0.473 | Total:0:03:11 | ETA:0:07:53 | Loss:0.6966158243202456 | top1:50.90565872192383\n",
      "381/1374 Data:0.001 | Batch:0.447 | Total:0:03:15 | ETA:0:07:29 | Loss:0.6966075141598859 | top1:50.83595657348633\n",
      "391/1374 Data:0.001 | Batch:0.451 | Total:0:03:19 | ETA:0:06:58 | Loss:0.6965212494211124 | top1:50.87467956542969\n",
      "401/1374 Data:0.000 | Batch:0.479 | Total:0:03:24 | ETA:0:07:27 | Loss:0.6963706810278191 | top1:50.94638442993164\n",
      "411/1374 Data:0.001 | Batch:0.381 | Total:0:03:28 | ETA:0:07:02 | Loss:0.6962561581256616 | top1:51.01581573486328\n",
      "421/1374 Data:0.001 | Batch:0.513 | Total:0:03:33 | ETA:0:07:46 | Loss:0.6962504361417684 | top1:51.040382385253906\n",
      "431/1374 Data:0.001 | Batch:0.389 | Total:0:03:38 | ETA:0:07:25 | Loss:0.6961993550203239 | top1:51.03132247924805\n",
      "441/1374 Data:0.001 | Batch:0.462 | Total:0:03:42 | ETA:0:06:48 | Loss:0.6961849364293676 | top1:51.01133728027344\n",
      "451/1374 Data:0.001 | Batch:0.523 | Total:0:03:47 | ETA:0:07:21 | Loss:0.6963119275554056 | top1:50.96895980834961\n",
      "461/1374 Data:0.001 | Batch:0.568 | Total:0:03:52 | ETA:0:07:19 | Loss:0.6963029551661195 | top1:50.9425163269043\n",
      "471/1374 Data:0.001 | Batch:0.557 | Total:0:03:57 | ETA:0:07:19 | Loss:0.6962754537851694 | top1:50.96603012084961\n",
      "481/1374 Data:0.001 | Batch:0.512 | Total:0:04:01 | ETA:0:06:45 | Loss:0.6962559184760413 | top1:50.95738220214844\n",
      "491/1374 Data:0.001 | Batch:0.514 | Total:0:04:06 | ETA:0:07:25 | Loss:0.696248530491792 | top1:50.9521369934082\n",
      "501/1374 Data:0.001 | Batch:0.515 | Total:0:04:11 | ETA:0:06:38 | Loss:0.6962933905586273 | top1:50.95109939575195\n",
      "511/1374 Data:0.016 | Batch:0.506 | Total:0:04:16 | ETA:0:06:57 | Loss:0.6962897946689927 | top1:50.966732025146484\n",
      "521/1374 Data:0.001 | Batch:0.444 | Total:0:04:20 | ETA:0:06:39 | Loss:0.6962695076003413 | top1:50.9577751159668\n",
      "531/1374 Data:0.001 | Batch:0.462 | Total:0:04:25 | ETA:0:06:35 | Loss:0.6961973312884401 | top1:50.980228424072266\n",
      "541/1374 Data:0.000 | Batch:0.433 | Total:0:04:30 | ETA:0:06:23 | Loss:0.6961077604849105 | top1:51.02218246459961\n",
      "551/1374 Data:0.001 | Batch:0.452 | Total:0:04:34 | ETA:0:06:25 | Loss:0.6961259090099923 | top1:50.99455261230469\n",
      "561/1374 Data:0.000 | Batch:0.494 | Total:0:04:39 | ETA:0:06:20 | Loss:0.6961842202672771 | top1:50.95900344848633\n",
      "571/1374 Data:0.001 | Batch:0.446 | Total:0:04:43 | ETA:0:05:50 | Loss:0.69617577453002 | top1:50.9544677734375\n",
      "581/1374 Data:0.001 | Batch:0.465 | Total:0:04:48 | ETA:0:06:33 | Loss:0.6961001191615238 | top1:50.98192596435547\n",
      "591/1374 Data:0.009 | Batch:0.423 | Total:0:04:53 | ETA:0:05:33 | Loss:0.6960584998332506 | top1:50.98646545410156\n",
      "601/1374 Data:0.002 | Batch:0.549 | Total:0:04:57 | ETA:0:05:56 | Loss:0.6960291242639157 | top1:51.009151458740234\n",
      "611/1374 Data:0.001 | Batch:0.450 | Total:0:05:02 | ETA:0:05:53 | Loss:0.6960074687940594 | top1:51.01145553588867\n",
      "621/1374 Data:0.000 | Batch:0.434 | Total:0:05:06 | ETA:0:05:25 | Loss:0.6959573909664307 | top1:51.03865051269531\n",
      "631/1374 Data:0.001 | Batch:0.486 | Total:0:05:11 | ETA:0:05:56 | Loss:0.6958840695311641 | top1:51.05467224121094\n",
      "641/1374 Data:0.000 | Batch:0.454 | Total:0:05:16 | ETA:0:05:26 | Loss:0.6958378470632104 | top1:51.06552505493164\n",
      "651/1374 Data:0.000 | Batch:0.483 | Total:0:05:20 | ETA:0:05:50 | Loss:0.6958349662991713 | top1:51.07219696044922\n",
      "661/1374 Data:0.012 | Batch:0.445 | Total:0:05:25 | ETA:0:05:17 | Loss:0.6957964175768231 | top1:51.099090576171875\n",
      "671/1374 Data:0.001 | Batch:0.445 | Total:0:05:30 | ETA:0:05:30 | Loss:0.6957557659746104 | top1:51.11400604248047\n",
      "681/1374 Data:0.001 | Batch:0.410 | Total:0:05:34 | ETA:0:05:10 | Loss:0.6957307207601886 | top1:51.12922286987305\n",
      "691/1374 Data:0.002 | Batch:0.495 | Total:0:05:39 | ETA:0:06:09 | Loss:0.6957059283504955 | top1:51.122283935546875\n",
      "701/1374 Data:0.001 | Batch:0.670 | Total:0:05:46 | ETA:0:06:56 | Loss:0.6956661700692225 | top1:51.14122772216797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "711/1374 Data:0.001 | Batch:0.607 | Total:0:05:52 | ETA:0:06:33 | Loss:0.6956410822989065 | top1:51.14134979248047\n",
      "721/1374 Data:0.002 | Batch:0.636 | Total:0:05:58 | ETA:0:07:12 | Loss:0.695562124004311 | top1:51.17753219604492\n",
      "731/1374 Data:0.003 | Batch:0.637 | Total:0:06:05 | ETA:0:07:12 | Loss:0.6955384610452665 | top1:51.193572998046875\n",
      "741/1374 Data:0.001 | Batch:0.640 | Total:0:06:12 | ETA:0:06:58 | Loss:0.6955070173048619 | top1:51.194332122802734\n",
      "751/1374 Data:0.001 | Batch:0.650 | Total:0:06:18 | ETA:0:06:47 | Loss:0.6954355785913379 | top1:51.228363037109375\n",
      "761/1374 Data:0.003 | Batch:0.700 | Total:0:06:25 | ETA:0:06:54 | Loss:0.6953845577077076 | top1:51.25295639038086\n",
      "771/1374 Data:0.002 | Batch:0.671 | Total:0:06:31 | ETA:0:06:34 | Loss:0.6953488003109835 | top1:51.27756118774414\n",
      "781/1374 Data:0.002 | Batch:0.516 | Total:0:06:38 | ETA:0:06:41 | Loss:0.6952881658886215 | top1:51.30665969848633\n",
      "791/1374 Data:0.001 | Batch:0.562 | Total:0:06:43 | ETA:0:04:40 | Loss:0.6952991638563376 | top1:51.31605529785156\n",
      "801/1374 Data:0.001 | Batch:0.460 | Total:0:06:48 | ETA:0:04:50 | Loss:0.6952890910012892 | top1:51.30961227416992\n",
      "811/1374 Data:0.000 | Batch:0.485 | Total:0:06:52 | ETA:0:04:10 | Loss:0.6953044202265992 | top1:51.31011199951172\n",
      "821/1374 Data:0.000 | Batch:0.482 | Total:0:06:57 | ETA:0:04:18 | Loss:0.6952507219999919 | top1:51.33921813964844\n",
      "831/1374 Data:0.000 | Batch:0.371 | Total:0:07:01 | ETA:0:04:05 | Loss:0.695184549915231 | top1:51.37966537475586\n",
      "841/1374 Data:0.001 | Batch:0.440 | Total:0:07:06 | ETA:0:04:04 | Loss:0.695162121875391 | top1:51.39179611206055\n",
      "851/1374 Data:0.001 | Batch:0.455 | Total:0:07:10 | ETA:0:03:57 | Loss:0.6951867638267445 | top1:51.37720489501953\n",
      "861/1374 Data:0.000 | Batch:0.426 | Total:0:07:15 | ETA:0:03:47 | Loss:0.6951309047924932 | top1:51.403018951416016\n",
      "871/1374 Data:0.000 | Batch:0.469 | Total:0:07:20 | ETA:0:04:03 | Loss:0.6951290117886803 | top1:51.396671295166016\n",
      "881/1374 Data:0.000 | Batch:0.504 | Total:0:07:24 | ETA:0:03:42 | Loss:0.695121372530869 | top1:51.39897918701172\n",
      "891/1374 Data:0.001 | Batch:0.461 | Total:0:07:29 | ETA:0:03:46 | Loss:0.6951051864827388 | top1:51.416385650634766\n",
      "901/1374 Data:0.000 | Batch:0.371 | Total:0:07:33 | ETA:0:03:27 | Loss:0.6950652377719223 | top1:51.42619323730469\n",
      "911/1374 Data:0.001 | Batch:0.419 | Total:0:07:37 | ETA:0:03:25 | Loss:0.6950228502145844 | top1:51.45060348510742\n",
      "921/1374 Data:0.001 | Batch:0.564 | Total:0:07:42 | ETA:0:03:29 | Loss:0.6949851701236315 | top1:51.45656967163086\n",
      "931/1374 Data:0.001 | Batch:0.452 | Total:0:07:47 | ETA:0:03:23 | Loss:0.6950337696664444 | top1:51.44199752807617\n",
      "941/1374 Data:0.001 | Batch:0.518 | Total:0:07:52 | ETA:0:03:34 | Loss:0.6950144271161427 | top1:51.453773498535156\n",
      "951/1374 Data:0.000 | Batch:0.469 | Total:0:07:56 | ETA:0:03:11 | Loss:0.6950177107198255 | top1:51.46214294433594\n",
      "961/1374 Data:0.005 | Batch:0.527 | Total:0:08:01 | ETA:0:03:17 | Loss:0.6950197379869427 | top1:51.457855224609375\n",
      "971/1374 Data:0.001 | Batch:0.426 | Total:0:08:05 | ETA:0:03:08 | Loss:0.6949990122251972 | top1:51.45211410522461\n",
      "981/1374 Data:0.003 | Batch:0.503 | Total:0:08:10 | ETA:0:02:55 | Loss:0.6949854682101873 | top1:51.464324951171875\n",
      "991/1374 Data:0.001 | Batch:0.450 | Total:0:08:15 | ETA:0:03:03 | Loss:0.6949563921400084 | top1:51.47376251220703\n",
      "1001/1374 Data:0.001 | Batch:0.493 | Total:0:08:19 | ETA:0:02:37 | Loss:0.6948939998309452 | top1:51.4995002746582\n",
      "1011/1374 Data:0.001 | Batch:0.487 | Total:0:08:24 | ETA:0:02:59 | Loss:0.6948293505861073 | top1:51.50197982788086\n",
      "1021/1374 Data:0.001 | Batch:0.438 | Total:0:08:28 | ETA:0:02:42 | Loss:0.6948368566276745 | top1:51.51371383666992\n",
      "1031/1374 Data:0.001 | Batch:0.430 | Total:0:08:33 | ETA:0:02:46 | Loss:0.6947978030236223 | top1:51.526187896728516\n",
      "1041/1374 Data:0.012 | Batch:0.435 | Total:0:08:38 | ETA:0:02:32 | Loss:0.6947671424644023 | top1:51.53217697143555\n",
      "1051/1374 Data:0.000 | Batch:0.491 | Total:0:08:42 | ETA:0:02:34 | Loss:0.694732428164169 | top1:51.53758239746094\n",
      "1061/1374 Data:0.000 | Batch:0.415 | Total:0:08:47 | ETA:0:02:30 | Loss:0.6947145400802331 | top1:51.53864288330078\n",
      "1071/1374 Data:0.001 | Batch:0.451 | Total:0:08:51 | ETA:0:02:14 | Loss:0.694684480196065 | top1:51.5345458984375\n",
      "1081/1374 Data:0.001 | Batch:0.464 | Total:0:08:56 | ETA:0:02:18 | Loss:0.6946636409146382 | top1:51.547637939453125\n",
      "1091/1374 Data:0.001 | Batch:0.391 | Total:0:09:00 | ETA:0:02:03 | Loss:0.6946331451072483 | top1:51.56874465942383\n",
      "1101/1374 Data:0.000 | Batch:0.448 | Total:0:09:05 | ETA:0:02:14 | Loss:0.6945955229823314 | top1:51.59491729736328\n",
      "1111/1374 Data:0.005 | Batch:0.510 | Total:0:09:10 | ETA:0:02:07 | Loss:0.6945613074903548 | top1:51.613861083984375\n",
      "1121/1374 Data:0.001 | Batch:0.462 | Total:0:09:14 | ETA:0:01:52 | Loss:0.6945322515388135 | top1:51.627567291259766\n",
      "1131/1374 Data:0.001 | Batch:0.490 | Total:0:09:19 | ETA:0:01:53 | Loss:0.6945176217326224 | top1:51.6379280090332\n",
      "1141/1374 Data:0.001 | Batch:0.467 | Total:0:09:24 | ETA:0:01:45 | Loss:0.6945106801915649 | top1:51.63716125488281\n",
      "1151/1374 Data:0.001 | Batch:0.459 | Total:0:09:28 | ETA:0:01:49 | Loss:0.6944789591299566 | top1:51.649436950683594\n",
      "1161/1374 Data:0.009 | Batch:0.482 | Total:0:09:33 | ETA:0:01:38 | Loss:0.6944453850786405 | top1:51.66278839111328\n",
      "1171/1374 Data:0.001 | Batch:0.490 | Total:0:09:38 | ETA:0:01:34 | Loss:0.6944435808416313 | top1:51.66566848754883\n",
      "1181/1374 Data:0.001 | Batch:0.446 | Total:0:09:42 | ETA:0:01:25 | Loss:0.6943882940988436 | top1:51.67019271850586\n",
      "1191/1374 Data:0.001 | Batch:0.465 | Total:0:09:47 | ETA:0:01:30 | Loss:0.6943435261071379 | top1:51.69227600097656\n",
      "1201/1374 Data:0.000 | Batch:0.369 | Total:0:09:52 | ETA:0:01:26 | Loss:0.6943240115584978 | top1:51.69608688354492\n",
      "1211/1374 Data:0.000 | Batch:0.424 | Total:0:09:56 | ETA:0:01:19 | Loss:0.6943331540959813 | top1:51.69446563720703\n",
      "1221/1374 Data:0.000 | Batch:0.485 | Total:0:10:01 | ETA:0:01:15 | Loss:0.6943050889964967 | top1:51.702701568603516\n",
      "1231/1374 Data:0.001 | Batch:0.486 | Total:0:10:06 | ETA:0:01:07 | Loss:0.694280480534734 | top1:51.70755386352539\n",
      "1241/1374 Data:0.001 | Batch:0.448 | Total:0:10:11 | ETA:0:01:07 | Loss:0.6942619841296667 | top1:51.7199821472168\n",
      "1251/1374 Data:0.001 | Batch:0.467 | Total:0:10:16 | ETA:0:00:58 | Loss:0.6942363942174508 | top1:51.727420806884766\n",
      "1261/1374 Data:0.002 | Batch:1.067 | Total:0:10:25 | ETA:0:01:41 | Loss:0.6941662322047397 | top1:51.75852584838867\n",
      "1271/1374 Data:0.002 | Batch:0.716 | Total:0:10:35 | ETA:0:01:45 | Loss:0.6941357163535057 | top1:51.790714263916016\n",
      "1281/1374 Data:0.009 | Batch:1.101 | Total:0:10:45 | ETA:0:01:39 | Loss:0.6941269708275329 | top1:51.790008544921875\n",
      "1291/1374 Data:0.002 | Batch:1.040 | Total:0:10:56 | ETA:0:01:28 | Loss:0.6941094099782771 | top1:51.78892517089844\n",
      "1301/1374 Data:0.001 | Batch:0.628 | Total:0:11:04 | ETA:0:01:06 | Loss:0.6940666171425036 | top1:51.80553436279297\n",
      "1311/1374 Data:0.003 | Batch:0.736 | Total:0:11:13 | ETA:0:00:55 | Loss:0.6940136385000362 | top1:51.82837677001953\n",
      "1321/1374 Data:0.002 | Batch:0.955 | Total:0:11:21 | ETA:0:00:44 | Loss:0.694008101124731 | top1:51.831947326660156\n",
      "1331/1374 Data:0.018 | Batch:0.905 | Total:0:11:30 | ETA:0:00:38 | Loss:0.6939445981219869 | top1:51.85649871826172\n",
      "1341/1374 Data:0.014 | Batch:0.432 | Total:0:11:38 | ETA:0:00:29 | Loss:0.6939283099572753 | top1:51.858314514160156\n",
      "1351/1374 Data:0.001 | Batch:0.888 | Total:0:11:44 | ETA:0:00:13 | Loss:0.6938874200923985 | top1:51.874168395996094\n",
      "1361/1374 Data:0.009 | Batch:0.425 | Total:0:11:50 | ETA:0:00:08 | Loss:0.6938533230269331 | top1:51.88941955566406\n",
      "1371/1374 Data:0.002 | Batch:0.841 | Total:0:11:56 | ETA:0:00:02 | Loss:0.6938254403250658 | top1:51.902626037597656\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(start_epoch, epochs):\n",
    "    state['lr'] = optimizer.state_dict()['param_groups'][0]['lr']\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "    print('\\nEpoch: [%d | %d] LR: %f' % (epoch + 1, epochs, state['lr']))\n",
    "    train_loss, train_acc = train(train_loader, model, criterion, optimizer, epoch, use_cuda)\n",
    "    test_loss, test_acc = test(val_loader, model, criterion, epoch, use_cuda)\n",
    "    \n",
    "    logger.append([state['lr'], train_loss, test_loss, train_acc, test_acc])\n",
    "    scheduler_warmup.step()\n",
    "\n",
    "    is_best = test_acc > best_acc\n",
    "    best_acc = max(test_acc, best_acc)\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'state_dict' : model.state_dict(),\n",
    "        'acc': test_acc,\n",
    "        'best_acc': best_acc,\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    }, is_best, checkpoint=checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
