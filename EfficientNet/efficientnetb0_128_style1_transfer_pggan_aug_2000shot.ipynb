{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import collections\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "\n",
    "from model_pytorch import EfficientNet\n",
    "from utils import Bar,Logger, AverageMeter, accuracy, mkdir_p, savefig\n",
    "from warmup_scheduler import GradualWarmupScheduler\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "import cv2\n",
    "\n",
    "from PIL import ImageFile, ImageOps\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU device 0: True\n"
     ]
    }
   ],
   "source": [
    "# GPU Device\n",
    "gpu_id = 0\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(\"GPU device %d:\" %(gpu_id), use_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = '/media/data2/dataset/GAN_ImageData/StyleGAN_256/'\n",
    "target_dir = '/media/data2/dataset/GAN_ImageData/PGGAN_128/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained = './log/style1/128/b0/aug/checkpoint.pth.tar'\n",
    "resume = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model_name = 'efficientnet-b0' # b0-b7 scale\n",
    "\n",
    "# Optimization\n",
    "num_classes = 2\n",
    "epochs = 1000\n",
    "start_epoch = 0\n",
    "train_batch = 200\n",
    "test_batch = 200\n",
    "lr = 0.1\n",
    "schedule = [50, 250, 500, 750]\n",
    "momentum = 0.1\n",
    "gamma = 0.1 # LR is multiplied by gamma on schedule\n",
    "\n",
    "# CheckPoint\n",
    "checkpoint = './log/style1/128/b0/to_pggan/1000shot' # dir\n",
    "if not os.path.isdir(checkpoint):\n",
    "    os.makedirs(checkpoint)\n",
    "num_workers = 8\n",
    "\n",
    "# Seed\n",
    "manual_seed = 7\n",
    "random.seed(manual_seed)\n",
    "torch.cuda.manual_seed_all(manual_seed)\n",
    "\n",
    "# Image\n",
    "size = (128, 128)\n",
    "\n",
    "# cutmix\n",
    "cm_prob = 0.5\n",
    "cm_prob_init = 0.99\n",
    "cm_prob_low = 0.01\n",
    "cm_beta = 1.0\n",
    "\n",
    "# augmentation\n",
    "blur_prob = 0.2\n",
    "blog_sig = 0.5\n",
    "jpg_prob = 0.2\n",
    "\n",
    "best_acc = 0\n",
    "\n",
    "# sp\n",
    "sp_alpha = 0.01\n",
    "sp_beta = 0.01\n",
    "fc_name = '_fc.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {}\n",
    "state['num_classes'] = num_classes\n",
    "state['epochs'] = epochs\n",
    "state['start_epoch'] = start_epoch\n",
    "state['train_batch'] = train_batch\n",
    "state['test_batch'] = test_batch\n",
    "state['lr'] = lr\n",
    "state['schedule'] = schedule\n",
    "state['momentum'] = momentum\n",
    "state['gamma'] = gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_augment(img):\n",
    "    img = np.array(img)\n",
    "\n",
    "    if random.random() < blur_prob:\n",
    "        sig = np.random.uniform(0.0, 3.0)\n",
    "        gaussian_blur(img, sig)\n",
    "\n",
    "    if random.random() < jpg_prob:\n",
    "        qual = np.random.uniform(30.0, 100.0)\n",
    "        img = cv2_jpg(img, qual)\n",
    "\n",
    "    return Image.fromarray(img)\n",
    "\n",
    "\n",
    "def gaussian_blur(img, sigma):\n",
    "    gaussian_filter(img[:,:,0], output=img[:,:,0], sigma=sigma)\n",
    "    gaussian_filter(img[:,:,1], output=img[:,:,1], sigma=sigma)\n",
    "    gaussian_filter(img[:,:,2], output=img[:,:,2], sigma=sigma)\n",
    "\n",
    "\n",
    "def cv2_jpg(img, compress_val):\n",
    "    img_cv2 = img[:,:,::-1]\n",
    "    encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), compress_val]\n",
    "    result, encimg = cv2.imencode('.jpg', img_cv2, encode_param)\n",
    "    decimg = cv2.imdecode(encimg, 1)\n",
    "    return decimg[:,:,::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_bbox(size, lam):\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = np.int(W * cut_rat)\n",
    "    cut_h = np.int(H * cut_rat)\n",
    "\n",
    "    # uniform\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join(source_dir, 'pggan/1000_shot_only')\n",
    "val_target_dir = os.path.join(target_dir, 'validation')\n",
    "val_source_dir = os.path.join(source_dir, 'validation')\n",
    "\n",
    "train_aug = transforms.Compose([\n",
    "    transforms.Lambda(lambda img: data_augment(img)),\n",
    "    transforms.Resize(size),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "#     transforms.RandomErasing(p=0.3, scale=(0.02, 0.10), ratio=(0.3, 3.3), value=0, inplace=True),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "val_aug = transforms.Compose([\n",
    "    transforms.Resize(size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# pin_memory : cuda pin memeory use\n",
    "train_loader = DataLoader(datasets.ImageFolder(train_dir, transform=train_aug),\n",
    "                          batch_size=train_batch, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "val_target_loader = DataLoader(datasets.ImageFolder(val_target_dir, val_aug),\n",
    "                       batch_size=test_batch, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "val_source_loader = DataLoader(datasets.ImageFolder(val_source_dir, val_aug),\n",
    "                       batch_size=test_batch, shuffle=True, num_workers=num_workers, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> using pre-trained model './log/style1/128/b0/aug/checkpoint.pth.tar'\n"
     ]
    }
   ],
   "source": [
    "teacher_model = EfficientNet.from_name(model_name, num_classes=num_classes,\n",
    "                              override_params={'dropout_rate':0.2, 'drop_connect_rate':0.2})\n",
    "student_model = EfficientNet.from_name(model_name, num_classes=num_classes,\n",
    "                              override_params={'dropout_rate':0.2, 'drop_connect_rate':0.2})\n",
    "\n",
    "# Pre-trained\n",
    "if pretrained:\n",
    "    print(\"=> using pre-trained model '{}'\".format(pretrained))\n",
    "    teacher_model.load_state_dict(torch.load(pretrained)['state_dict'])\n",
    "    student_model.load_state_dict(torch.load(pretrained)['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Total params: 4.01M\n"
     ]
    }
   ],
   "source": [
    "teacher_model.to('cuda')\n",
    "student_model.to('cuda')\n",
    "cudnn.benchmark = True\n",
    "print('    Total params: %.2fM' % (sum(p.numel() for p in teacher_model.parameters())/1000000.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = optim.SGD(student_model.parameters(), lr=lr, momentum=momentum)\n",
    "# optimizer = optim.Adam(student_model.parameters())\n",
    "scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)\n",
    "scheduler_warmup = GradualWarmupScheduler(optimizer, multiplier=4, total_epoch=10, after_scheduler=scheduler_cosine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resume\n",
    "if resume:\n",
    "    print('==> Resuming from checkpoint..')\n",
    "    checkpoint = os.path.dirname(resume)\n",
    "#     checkpoint = torch.load(resume)\n",
    "    resume = torch.load(resume)\n",
    "    best_acc = resume['best_acc']\n",
    "    start_epoch = resume['epoch']\n",
    "    student_model.load_state_dict(resume['state_dict'])\n",
    "    optimizer.load_state_dict(resume['optimizer'])\n",
    "    logger = Logger(os.path.join(checkpoint, 'log.txt'), resume=True)\n",
    "else:\n",
    "    logger = Logger(os.path.join(checkpoint, 'log.txt'))\n",
    "    logger.set_names(['Learning Rate', 'Train Loss', 'Valid Loss', 'Source Loss', 'Train Acc.', 'Valid Acc.', 'Source ACC.', 'Train AUROC', 'Valid AUROC', 'Source AUROC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EfficientNet(\n",
       "  (_conv_stem): Conv2dStaticSamePadding(\n",
       "    3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
       "    (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "  )\n",
       "  (_gn0): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "  (_blocks): ModuleList(\n",
       "    (0): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        32, 32, kernel_size=(3, 3), stride=[1, 1], groups=32, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        32, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        8, 32, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 16, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (1): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 96, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        96, 96, kernel_size=(3, 3), stride=[2, 2], groups=96, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 96, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        96, 4, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        4, 96, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 24, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (2): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 144, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 144, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 24, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (3): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 144, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        144, 144, kernel_size=(5, 5), stride=[2, 2], groups=144, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 144, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 40, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (4): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 240, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        240, 240, kernel_size=(5, 5), stride=(1, 1), groups=240, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 240, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 40, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (5): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 240, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        240, 240, kernel_size=(3, 3), stride=[2, 2], groups=240, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 240, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 80, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (6): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 480, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 480, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 80, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (7): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 480, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 480, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 80, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (8): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 480, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        480, 480, kernel_size=(5, 5), stride=[1, 1], groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 480, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 112, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (9): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 672, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 672, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 112, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (10): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 672, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 672, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 112, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (11): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 672, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5), stride=[2, 2], groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 672, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 192, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (12): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 1152, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 1152, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 192, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (13): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 1152, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 1152, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 192, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (14): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 1152, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 1152, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 192, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (15): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn0): GroupNorm(8, 1152, eps=1e-05, affine=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(3, 3), stride=[1, 1], groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_gn1): GroupNorm(8, 1152, eps=1e-05, affine=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_gn2): GroupNorm(8, 320, eps=1e-05, affine=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "  )\n",
       "  (_conv_head): Conv2dStaticSamePadding(\n",
       "    320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "    (static_padding): Identity()\n",
       "  )\n",
       "  (_gn1): GroupNorm(8, 1280, eps=1e-05, affine=True)\n",
       "  (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n",
       "  (_dropout): Dropout(p=0.2, inplace=False)\n",
       "  (_fc): Linear(in_features=1280, out_features=2, bias=True)\n",
       "  (_swish): MemoryEfficientSwish()\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for param in teacher_model.parameters():\n",
    "    param.requires_grad = False\n",
    "teacher_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_model_weights = {}\n",
    "for name, param in teacher_model.named_parameters():\n",
    "    teacher_model_weights[name] = param.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_cls(model):\n",
    "    l2_cls = torch.tensor(0.).cuda()\n",
    "    for name, param in model.named_parameters():\n",
    "        if name.startswith(fc_name):\n",
    "            l2_cls += 0.5 * torch.norm(param) ** 2\n",
    "    return l2_cls\n",
    "\n",
    "def reg_l2sp(model):\n",
    "    sp_loss = torch.tensor(0.).cuda()\n",
    "    for name, param in model.named_parameters():\n",
    "        if not name.startswith(fc_name):\n",
    "            sp_loss += 0.5 * torch.norm(param - teacher_model_weights[name]) ** 2\n",
    "    return sp_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch, use_cuda):\n",
    "    model.train()\n",
    "    \n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    arc = AverageMeter()\n",
    "    end = time.time()\n",
    "    cls_losses = AverageMeter()\n",
    "    sp_losses = AverageMeter()\n",
    "    main_losses = AverageMeter()\n",
    "    \n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        batch_size = inputs.size(0)\n",
    "        if batch_size < train_batch:\n",
    "            continue\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            \n",
    "        r = np.random.rand(1)\n",
    "        if cm_beta > 0 and r < cm_prob:\n",
    "            \n",
    "            rand_index = torch.randperm(inputs.size()[0]).cuda()\n",
    "            tt= targets[rand_index]\n",
    "            boolean = targets==tt\n",
    "            rand_index = rand_index[boolean]\n",
    "            lam = np.random.beta(cm_beta, cm_beta)\n",
    "            bbx1, bby1, bbx2, bby2 = rand_bbox(inputs.size(), lam)\n",
    "            inputs[boolean, :, bbx1:bbx2, bby1:bby2] = inputs[rand_index, :, bbx1:bbx2, bby1:bby2]\n",
    "\n",
    "        # compute output\n",
    "        outputs = model(inputs)\n",
    "        loss_main = criterion(outputs, targets)\n",
    "        loss_cls = 0\n",
    "        loss_sp = 0\n",
    "        loss_cls = reg_cls(model)\n",
    "        loss_sp = reg_l2sp(model)\n",
    "        loss =  loss_main + sp_alpha*loss_sp + sp_beta*loss_cls\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1 = accuracy(outputs.data, targets.data)\n",
    "#         auroc = roc_auc_score(targets.cpu().detach().numpy(), outputs.cpu().detach().numpy()[:,1])\n",
    "        losses.update(loss.data.tolist(), inputs.size(0))\n",
    "        top1.update(prec1[0], inputs.size(0))\n",
    "#         arc.update(auroc, inputs.size(0))\n",
    "        cls_losses.update(loss_cls, inputs.size(0))\n",
    "        sp_losses.update(loss_sp, inputs.size(0))\n",
    "        main_losses.update(loss_main.tolist(), inputs.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        \n",
    "#         if batch_idx % 100 == 0:\n",
    "#             print('{batch}/{size} | Loss:{loss:.4f} | MainLoss:{main:.4f} | SPLoss:{sp:.4f} | CLSLoss:{cls:.4f} | top1:{tp1:.4f} | AUROC:{ac:.4f}'.format(\n",
    "#                      batch=batch_idx+1, size=len(train_loader), loss=losses.avg, main=main_losses.avg, sp=sp_losses.avg, cls=cls_losses.avg, tp1=top1.avg, ac=arc.avg))\n",
    "    print('Train | {batch}/{size} | Loss:{loss:.4f} | MainLoss:{main:.4f} | SPLoss:{sp:.4f} | CLSLoss:{cls:.4f} | top1:{tp1:.4f} | AUROC:{ac:.4f}'.format(\n",
    "                     batch=batch_idx+1, size=len(train_loader), loss=losses.avg, main=main_losses.avg, sp=sp_losses.avg, cls=cls_losses.avg, tp1=top1.avg, ac=arc.avg))\n",
    "    return (losses.avg, top1.avg, arc.avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(val_loader, model, criterion, epoch, use_cuda):\n",
    "    global best_acc\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    arc = AverageMeter()\n",
    "    cls_losses = AverageMeter()\n",
    "    sp_losses = AverageMeter()\n",
    "    main_losses = AverageMeter()\n",
    "\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(val_loader):\n",
    "            # measure data loading time\n",
    "            data_time.update(time.time() - end)\n",
    "\n",
    "            if use_cuda:\n",
    "                inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "            # compute output\n",
    "            outputs = model(inputs)\n",
    "            loss_main = criterion(outputs, targets)\n",
    "            loss_cls = 0\n",
    "            loss_sp = 0\n",
    "            loss_cls = reg_cls(model)\n",
    "            loss_sp = reg_l2sp(model)\n",
    "            loss = loss_main + sp_alpha*loss_sp + sp_beta*loss_cls\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            prec1 = accuracy(outputs.data, targets.data)\n",
    "            auroc = roc_auc_score(targets.cpu().detach().numpy(), outputs.cpu().detach().numpy()[:,1])\n",
    "            losses.update(loss.data.tolist(), inputs.size(0))\n",
    "            top1.update(prec1[0], inputs.size(0))\n",
    "            arc.update(auroc, inputs.size(0))\n",
    "            cls_losses.update(loss_cls, inputs.size(0))\n",
    "            sp_losses.update(loss_sp, inputs.size(0))\n",
    "            main_losses.update(loss_main.tolist(), inputs.size(0))\n",
    "\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "    print('Test | {batch}/{size} | Loss:{loss:.4f} | MainLoss:{main:.4f} | SPLoss:{sp:.4f} | CLSLoss:{cls:.4f} | top1:{tp1:.4f} | AUROC:{ac:.4f}'.format(\n",
    "                     batch=batch_idx+1, size=len(train_loader), loss=losses.avg, main=main_losses.avg, sp=sp_losses.avg, cls=cls_losses.avg, tp1=top1.avg, ac=arc.avg))\n",
    "    return (losses.avg, top1.avg, arc.avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, checkpoint='checkpoint', filename='checkpoint.pth.tar'):\n",
    "    filepath = os.path.join(checkpoint, filename)\n",
    "    torch.save(state, filepath)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filepath, os.path.join(checkpoint, 'model_best.pth.tar'))\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    global state\n",
    "    lr_set = [1, 1e-1, 1e-2, 1e-3, 1e-4, 1e-5]\n",
    "    lr_list = schedule.copy()\n",
    "    lr_list.append(epoch)\n",
    "    lr_list.sort()\n",
    "    idx = lr_list.index(epoch)\n",
    "    state['lr'] *= lr_set[idx]\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = state['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [1 | 1000] LR: 0.100000\n",
      "Train | 10/10 | Loss:1.5755 | MainLoss:1.5271 | SPLoss:0.5112 | CLSLoss:4.3294 | top1:49.6500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.8168 | MainLoss:0.7687 | SPLoss:0.9394 | CLSLoss:3.8758 | top1:51.3676 | AUROC:0.5204\n",
      "Test | 39/10 | Loss:0.3638 | MainLoss:0.3156 | SPLoss:0.9394 | CLSLoss:3.8758 | top1:87.2821 | AUROC:0.9997\n",
      "\n",
      "Epoch: [2 | 1000] LR: 0.130000\n",
      "Train | 10/10 | Loss:0.8132 | MainLoss:0.7657 | SPLoss:1.0242 | CLSLoss:3.7228 | top1:51.2000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.7632 | MainLoss:0.7169 | SPLoss:1.0611 | CLSLoss:3.5767 | top1:52.2243 | AUROC:0.5324\n",
      "Test | 39/10 | Loss:0.3721 | MainLoss:0.3257 | SPLoss:1.0611 | CLSLoss:3.5767 | top1:86.8846 | AUROC:0.9997\n",
      "\n",
      "Epoch: [3 | 1000] LR: 0.160000\n",
      "Train | 10/10 | Loss:0.7652 | MainLoss:0.7195 | SPLoss:1.1082 | CLSLoss:3.4631 | top1:52.4000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.7440 | MainLoss:0.6987 | SPLoss:1.1934 | CLSLoss:3.3408 | top1:53.0187 | AUROC:0.5411\n",
      "Test | 39/10 | Loss:0.4144 | MainLoss:0.3691 | SPLoss:1.1934 | CLSLoss:3.3408 | top1:79.3718 | AUROC:0.9997\n",
      "\n",
      "Epoch: [4 | 1000] LR: 0.190000\n",
      "Train | 10/10 | Loss:0.7519 | MainLoss:0.7075 | SPLoss:1.1999 | CLSLoss:3.2418 | top1:51.8000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.7364 | MainLoss:0.6929 | SPLoss:1.2232 | CLSLoss:3.1290 | top1:53.4019 | AUROC:0.5498\n",
      "Test | 39/10 | Loss:0.3819 | MainLoss:0.3384 | SPLoss:1.2232 | CLSLoss:3.1290 | top1:85.8077 | AUROC:0.9996\n",
      "\n",
      "Epoch: [5 | 1000] LR: 0.220000\n",
      "Train | 10/10 | Loss:0.7430 | MainLoss:0.7002 | SPLoss:1.2465 | CLSLoss:3.0359 | top1:51.4000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.7303 | MainLoss:0.6882 | SPLoss:1.2926 | CLSLoss:2.9250 | top1:54.1433 | AUROC:0.5601\n",
      "Test | 39/10 | Loss:0.3974 | MainLoss:0.3552 | SPLoss:1.2926 | CLSLoss:2.9250 | top1:81.2821 | AUROC:0.9997\n",
      "\n",
      "Epoch: [6 | 1000] LR: 0.250000\n",
      "Train | 10/10 | Loss:0.7325 | MainLoss:0.6912 | SPLoss:1.2879 | CLSLoss:2.8422 | top1:55.0000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.7259 | MainLoss:0.6853 | SPLoss:1.3155 | CLSLoss:2.7419 | top1:55.0810 | AUROC:0.5732\n",
      "Test | 39/10 | Loss:0.4001 | MainLoss:0.3595 | SPLoss:1.3155 | CLSLoss:2.7419 | top1:79.7436 | AUROC:0.9997\n",
      "\n",
      "Epoch: [7 | 1000] LR: 0.280000\n",
      "Train | 10/10 | Loss:0.7339 | MainLoss:0.6943 | SPLoss:1.3101 | CLSLoss:2.6525 | top1:53.1000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.7220 | MainLoss:0.6833 | SPLoss:1.3356 | CLSLoss:2.5364 | top1:55.5296 | AUROC:0.5845\n",
      "Test | 39/10 | Loss:0.3833 | MainLoss:0.3446 | SPLoss:1.3356 | CLSLoss:2.5364 | top1:84.5513 | AUROC:0.9997\n",
      "\n",
      "Epoch: [8 | 1000] LR: 0.310000\n",
      "Train | 10/10 | Loss:0.7308 | MainLoss:0.6928 | SPLoss:1.3532 | CLSLoss:2.4445 | top1:55.3500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.7208 | MainLoss:0.6841 | SPLoss:1.3335 | CLSLoss:2.3297 | top1:54.7726 | AUROC:0.5965\n",
      "Test | 39/10 | Loss:0.3566 | MainLoss:0.3199 | SPLoss:1.3335 | CLSLoss:2.3297 | top1:90.9103 | AUROC:0.9996\n",
      "\n",
      "Epoch: [9 | 1000] LR: 0.340000\n",
      "Train | 10/10 | Loss:0.7239 | MainLoss:0.6879 | SPLoss:1.3612 | CLSLoss:2.2476 | top1:54.4000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.7135 | MainLoss:0.6779 | SPLoss:1.4148 | CLSLoss:2.1427 | top1:58.0685 | AUROC:0.6129\n",
      "Test | 39/10 | Loss:0.4091 | MainLoss:0.3736 | SPLoss:1.4148 | CLSLoss:2.1427 | top1:73.7436 | AUROC:0.9997\n",
      "\n",
      "Epoch: [10 | 1000] LR: 0.370000\n",
      "Train | 10/10 | Loss:0.7235 | MainLoss:0.6890 | SPLoss:1.3943 | CLSLoss:2.0573 | top1:54.3500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.7080 | MainLoss:0.6744 | SPLoss:1.4124 | CLSLoss:1.9547 | top1:58.4891 | AUROC:0.6291\n",
      "Test | 39/10 | Loss:0.3857 | MainLoss:0.3520 | SPLoss:1.4124 | CLSLoss:1.9547 | top1:82.7051 | AUROC:0.9997\n",
      "\n",
      "Epoch: [11 | 1000] LR: 0.400000\n",
      "Train | 10/10 | Loss:0.7173 | MainLoss:0.6844 | SPLoss:1.4177 | CLSLoss:1.8767 | top1:55.8500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.7045 | MainLoss:0.6716 | SPLoss:1.5074 | CLSLoss:1.7830 | top1:59.6355 | AUROC:0.6520\n",
      "Test | 39/10 | Loss:0.4335 | MainLoss:0.4006 | SPLoss:1.5074 | CLSLoss:1.7830 | top1:64.0641 | AUROC:0.9997\n",
      "\n",
      "Epoch: [12 | 1000] LR: 0.400000\n",
      "Train | 10/10 | Loss:0.7110 | MainLoss:0.6793 | SPLoss:1.4594 | CLSLoss:1.7129 | top1:57.2000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.6917 | MainLoss:0.6605 | SPLoss:1.4895 | CLSLoss:1.6313 | top1:62.0872 | AUROC:0.6748\n",
      "Test | 39/10 | Loss:0.3933 | MainLoss:0.3621 | SPLoss:1.4895 | CLSLoss:1.6313 | top1:79.5128 | AUROC:0.9996\n",
      "\n",
      "Epoch: [13 | 1000] LR: 0.399999\n",
      "Train | 10/10 | Loss:0.7073 | MainLoss:0.6766 | SPLoss:1.4952 | CLSLoss:1.5701 | top1:57.1000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.6834 | MainLoss:0.6523 | SPLoss:1.6028 | CLSLoss:1.5006 | top1:64.0561 | AUROC:0.7003\n",
      "Test | 39/10 | Loss:0.4362 | MainLoss:0.4051 | SPLoss:1.6028 | CLSLoss:1.5006 | top1:67.3590 | AUROC:0.9997\n",
      "\n",
      "Epoch: [14 | 1000] LR: 0.399996\n",
      "Train | 10/10 | Loss:0.6992 | MainLoss:0.6689 | SPLoss:1.5804 | CLSLoss:1.4469 | top1:59.4000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.6651 | MainLoss:0.6348 | SPLoss:1.6400 | CLSLoss:1.3934 | top1:65.9315 | AUROC:0.7290\n",
      "Test | 39/10 | Loss:0.3925 | MainLoss:0.3621 | SPLoss:1.6400 | CLSLoss:1.3934 | top1:78.9359 | AUROC:0.9996\n",
      "\n",
      "Epoch: [15 | 1000] LR: 0.399991\n",
      "Train | 10/10 | Loss:0.6957 | MainLoss:0.6651 | SPLoss:1.7092 | CLSLoss:1.3510 | top1:59.7500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.6497 | MainLoss:0.6190 | SPLoss:1.7705 | CLSLoss:1.2967 | top1:66.7446 | AUROC:0.7617\n",
      "Test | 39/10 | Loss:0.3672 | MainLoss:0.3365 | SPLoss:1.7705 | CLSLoss:1.2967 | top1:83.8333 | AUROC:0.9995\n",
      "\n",
      "Epoch: [16 | 1000] LR: 0.399984\n",
      "Train | 10/10 | Loss:0.6856 | MainLoss:0.6539 | SPLoss:1.8970 | CLSLoss:1.2698 | top1:61.3000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.6196 | MainLoss:0.5865 | SPLoss:2.0952 | CLSLoss:1.2168 | top1:72.4642 | AUROC:0.8020\n",
      "Test | 39/10 | Loss:0.4182 | MainLoss:0.3851 | SPLoss:2.0952 | CLSLoss:1.2168 | top1:74.4872 | AUROC:0.9994\n",
      "\n",
      "Epoch: [17 | 1000] LR: 0.399975\n",
      "Train | 10/10 | Loss:0.7569 | MainLoss:0.6180 | SPLoss:12.6609 | CLSLoss:1.2301 | top1:66.3500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.7575 | MainLoss:0.5467 | SPLoss:19.8666 | CLSLoss:1.2064 | top1:74.0810 | AUROC:0.8418\n",
      "Test | 39/10 | Loss:0.5618 | MainLoss:0.3511 | SPLoss:19.8666 | CLSLoss:1.2064 | top1:80.1923 | AUROC:0.9992\n",
      "\n",
      "Epoch: [18 | 1000] LR: 0.399964\n",
      "Train | 10/10 | Loss:0.8143 | MainLoss:0.6086 | SPLoss:19.3938 | CLSLoss:1.1743 | top1:66.8000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.7009 | MainLoss:0.5016 | SPLoss:18.7657 | CLSLoss:1.1601 | top1:76.9065 | AUROC:0.8828\n",
      "Test | 39/10 | Loss:0.5336 | MainLoss:0.3343 | SPLoss:18.7657 | CLSLoss:1.1601 | top1:80.9103 | AUROC:0.9990\n",
      "\n",
      "Epoch: [19 | 1000] LR: 0.399952\n",
      "Train | 10/10 | Loss:0.7905 | MainLoss:0.5951 | SPLoss:18.4459 | CLSLoss:1.1002 | top1:68.9000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.6473 | MainLoss:0.4575 | SPLoss:17.9330 | CLSLoss:1.0492 | top1:80.1963 | AUROC:0.9227\n",
      "Test | 39/10 | Loss:0.5280 | MainLoss:0.3382 | SPLoss:17.9330 | CLSLoss:1.0492 | top1:80.4103 | AUROC:0.9983\n",
      "\n",
      "Epoch: [20 | 1000] LR: 0.399937\n",
      "Train | 10/10 | Loss:0.7475 | MainLoss:0.5602 | SPLoss:17.6983 | CLSLoss:1.0306 | top1:71.5500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.5808 | MainLoss:0.3989 | SPLoss:17.2138 | CLSLoss:0.9841 | top1:84.7913 | AUROC:0.9537\n",
      "Test | 39/10 | Loss:0.5497 | MainLoss:0.3678 | SPLoss:17.2138 | CLSLoss:0.9841 | top1:77.1667 | AUROC:0.9971\n",
      "\n",
      "Epoch: [21 | 1000] LR: 0.399920\n",
      "Train | 10/10 | Loss:0.7056 | MainLoss:0.5261 | SPLoss:16.9894 | CLSLoss:0.9560 | top1:73.3000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.4930 | MainLoss:0.3171 | SPLoss:16.6782 | CLSLoss:0.9106 | top1:91.4174 | AUROC:0.9719\n",
      "Test | 39/10 | Loss:0.7042 | MainLoss:0.5284 | SPLoss:16.6782 | CLSLoss:0.9106 | top1:62.0256 | AUROC:0.9959\n",
      "\n",
      "Epoch: [22 | 1000] LR: 0.399901\n",
      "Train | 10/10 | Loss:0.6784 | MainLoss:0.5062 | SPLoss:16.3326 | CLSLoss:0.8886 | top1:74.1000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.4309 | MainLoss:0.2613 | SPLoss:16.0865 | CLSLoss:0.8791 | top1:93.5732 | AUROC:0.9834\n",
      "Test | 39/10 | Loss:0.7132 | MainLoss:0.5436 | SPLoss:16.0865 | CLSLoss:0.8791 | top1:62.1154 | AUROC:0.9938\n",
      "\n",
      "Epoch: [23 | 1000] LR: 0.399881\n",
      "Train | 10/10 | Loss:0.6561 | MainLoss:0.4896 | SPLoss:15.8016 | CLSLoss:0.8494 | top1:76.0500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.4289 | MainLoss:0.2657 | SPLoss:15.5326 | CLSLoss:0.7875 | top1:94.2087 | AUROC:0.9882\n",
      "Test | 39/10 | Loss:0.6745 | MainLoss:0.5113 | SPLoss:15.5326 | CLSLoss:0.7875 | top1:63.3590 | AUROC:0.9923\n",
      "\n",
      "Epoch: [24 | 1000] LR: 0.399858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 10/10 | Loss:0.6278 | MainLoss:0.4673 | SPLoss:15.2810 | CLSLoss:0.7720 | top1:77.6500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.3877 | MainLoss:0.2301 | SPLoss:14.9930 | CLSLoss:0.7707 | top1:95.6137 | AUROC:0.9909\n",
      "Test | 39/10 | Loss:0.7670 | MainLoss:0.6094 | SPLoss:14.9930 | CLSLoss:0.7707 | top1:56.7436 | AUROC:0.9903\n",
      "\n",
      "Epoch: [25 | 1000] LR: 0.399833\n",
      "Train | 10/10 | Loss:0.6056 | MainLoss:0.4521 | SPLoss:14.5880 | CLSLoss:0.7649 | top1:78.3000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.3722 | MainLoss:0.2213 | SPLoss:14.3280 | CLSLoss:0.7540 | top1:95.7446 | AUROC:0.9919\n",
      "Test | 39/10 | Loss:0.7921 | MainLoss:0.6413 | SPLoss:14.3279 | CLSLoss:0.7540 | top1:55.3974 | AUROC:0.9895\n",
      "\n",
      "Epoch: [26 | 1000] LR: 0.399807\n",
      "Train | 10/10 | Loss:0.6100 | MainLoss:0.4632 | SPLoss:13.9443 | CLSLoss:0.7404 | top1:77.0500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.3862 | MainLoss:0.2431 | SPLoss:13.5777 | CLSLoss:0.7254 | top1:95.4455 | AUROC:0.9926\n",
      "Test | 39/10 | Loss:0.6760 | MainLoss:0.5330 | SPLoss:13.5777 | CLSLoss:0.7254 | top1:60.9103 | AUROC:0.9903\n",
      "\n",
      "Epoch: [27 | 1000] LR: 0.399778\n",
      "Train | 10/10 | Loss:0.6063 | MainLoss:0.4657 | SPLoss:13.3431 | CLSLoss:0.7223 | top1:77.6000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.3652 | MainLoss:0.2283 | SPLoss:13.0362 | CLSLoss:0.6549 | top1:96.2461 | AUROC:0.9930\n",
      "Test | 39/10 | Loss:0.7456 | MainLoss:0.6087 | SPLoss:13.0362 | CLSLoss:0.6549 | top1:56.3974 | AUROC:0.9900\n",
      "\n",
      "Epoch: [28 | 1000] LR: 0.399747\n",
      "Train | 10/10 | Loss:0.5839 | MainLoss:0.4503 | SPLoss:12.6978 | CLSLoss:0.6683 | top1:78.6500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.3578 | MainLoss:0.2274 | SPLoss:12.3770 | CLSLoss:0.6623 | top1:95.6698 | AUROC:0.9930\n",
      "Test | 39/10 | Loss:0.6985 | MainLoss:0.5681 | SPLoss:12.3770 | CLSLoss:0.6623 | top1:59.4744 | AUROC:0.9895\n",
      "\n",
      "Epoch: [29 | 1000] LR: 0.399715\n",
      "Train | 10/10 | Loss:0.5850 | MainLoss:0.4564 | SPLoss:12.2228 | CLSLoss:0.6450 | top1:78.7500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.3514 | MainLoss:0.2252 | SPLoss:12.0337 | CLSLoss:0.5897 | top1:96.5140 | AUROC:0.9944\n",
      "Test | 39/10 | Loss:0.7151 | MainLoss:0.5889 | SPLoss:12.0337 | CLSLoss:0.5897 | top1:57.8462 | AUROC:0.9882\n",
      "\n",
      "Epoch: [30 | 1000] LR: 0.399680\n",
      "Train | 10/10 | Loss:0.5726 | MainLoss:0.4488 | SPLoss:11.7762 | CLSLoss:0.6028 | top1:78.6000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.3534 | MainLoss:0.2328 | SPLoss:11.4594 | CLSLoss:0.6065 | top1:95.7788 | AUROC:0.9939\n",
      "Test | 39/10 | Loss:0.6722 | MainLoss:0.5516 | SPLoss:11.4594 | CLSLoss:0.6065 | top1:60.5641 | AUROC:0.9886\n",
      "\n",
      "Epoch: [31 | 1000] LR: 0.399644\n",
      "Train | 10/10 | Loss:0.5694 | MainLoss:0.4508 | SPLoss:11.2713 | CLSLoss:0.5883 | top1:78.3000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.3397 | MainLoss:0.2239 | SPLoss:11.0005 | CLSLoss:0.5882 | top1:96.2586 | AUROC:0.9944\n",
      "Test | 39/10 | Loss:0.6869 | MainLoss:0.5710 | SPLoss:11.0005 | CLSLoss:0.5882 | top1:59.2436 | AUROC:0.9896\n",
      "\n",
      "Epoch: [32 | 1000] LR: 0.399605\n",
      "Train | 10/10 | Loss:0.5445 | MainLoss:0.4303 | SPLoss:10.8136 | CLSLoss:0.6026 | top1:79.5000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.3043 | MainLoss:0.1914 | SPLoss:10.6758 | CLSLoss:0.6177 | top1:96.9875 | AUROC:0.9948\n",
      "Test | 39/10 | Loss:0.7598 | MainLoss:0.6469 | SPLoss:10.6758 | CLSLoss:0.6177 | top1:56.2308 | AUROC:0.9885\n",
      "\n",
      "Epoch: [33 | 1000] LR: 0.399565\n",
      "Train | 10/10 | Loss:0.5528 | MainLoss:0.4422 | SPLoss:10.4546 | CLSLoss:0.6060 | top1:78.7500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.3220 | MainLoss:0.2134 | SPLoss:10.2701 | CLSLoss:0.5874 | top1:96.7196 | AUROC:0.9946\n",
      "Test | 39/10 | Loss:0.7199 | MainLoss:0.6113 | SPLoss:10.2701 | CLSLoss:0.5874 | top1:56.8590 | AUROC:0.9892\n",
      "\n",
      "Epoch: [34 | 1000] LR: 0.399523\n",
      "Train | 10/10 | Loss:0.5445 | MainLoss:0.4376 | SPLoss:10.1119 | CLSLoss:0.5861 | top1:80.0000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.3295 | MainLoss:0.2252 | SPLoss:9.8604 | CLSLoss:0.5625 | top1:96.1713 | AUROC:0.9948\n",
      "Test | 39/10 | Loss:0.6656 | MainLoss:0.5613 | SPLoss:9.8604 | CLSLoss:0.5625 | top1:60.0641 | AUROC:0.9893\n",
      "\n",
      "Epoch: [35 | 1000] LR: 0.399478\n",
      "Train | 10/10 | Loss:0.5348 | MainLoss:0.4313 | SPLoss:9.7868 | CLSLoss:0.5629 | top1:80.0000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.3086 | MainLoss:0.2066 | SPLoss:9.6328 | CLSLoss:0.5648 | top1:96.6978 | AUROC:0.9948\n",
      "Test | 39/10 | Loss:0.7092 | MainLoss:0.6072 | SPLoss:9.6328 | CLSLoss:0.5648 | top1:57.8590 | AUROC:0.9888\n",
      "\n",
      "Epoch: [36 | 1000] LR: 0.399432\n",
      "Train | 10/10 | Loss:0.5336 | MainLoss:0.4332 | SPLoss:9.4902 | CLSLoss:0.5549 | top1:79.4000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2867 | MainLoss:0.1871 | SPLoss:9.3907 | CLSLoss:0.5666 | top1:96.9751 | AUROC:0.9947\n",
      "Test | 39/10 | Loss:0.7640 | MainLoss:0.6644 | SPLoss:9.3907 | CLSLoss:0.5666 | top1:56.1795 | AUROC:0.9878\n",
      "\n",
      "Epoch: [37 | 1000] LR: 0.399383\n",
      "Train | 10/10 | Loss:0.5388 | MainLoss:0.4411 | SPLoss:9.2260 | CLSLoss:0.5420 | top1:79.0000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.3328 | MainLoss:0.2376 | SPLoss:8.9966 | CLSLoss:0.5208 | top1:96.2492 | AUROC:0.9946\n",
      "Test | 39/10 | Loss:0.6511 | MainLoss:0.5559 | SPLoss:8.9966 | CLSLoss:0.5208 | top1:59.4744 | AUROC:0.9885\n",
      "\n",
      "Epoch: [38 | 1000] LR: 0.399333\n",
      "Train | 10/10 | Loss:0.5292 | MainLoss:0.4349 | SPLoss:8.9082 | CLSLoss:0.5244 | top1:79.5000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2854 | MainLoss:0.1915 | SPLoss:8.8491 | CLSLoss:0.5413 | top1:97.0343 | AUROC:0.9948\n",
      "Test | 39/10 | Loss:0.7528 | MainLoss:0.6589 | SPLoss:8.8491 | CLSLoss:0.5413 | top1:55.3718 | AUROC:0.9878\n",
      "\n",
      "Epoch: [39 | 1000] LR: 0.399281\n",
      "Train | 10/10 | Loss:0.5131 | MainLoss:0.4216 | SPLoss:8.6170 | CLSLoss:0.5392 | top1:79.9500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.3086 | MainLoss:0.2189 | SPLoss:8.4182 | CLSLoss:0.5575 | top1:95.9408 | AUROC:0.9940\n",
      "Test | 39/10 | Loss:0.6720 | MainLoss:0.5822 | SPLoss:8.4182 | CLSLoss:0.5575 | top1:59.7436 | AUROC:0.9881\n",
      "\n",
      "Epoch: [40 | 1000] LR: 0.399227\n",
      "Train | 10/10 | Loss:0.5304 | MainLoss:0.4414 | SPLoss:8.3887 | CLSLoss:0.5111 | top1:79.1500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.3230 | MainLoss:0.2359 | SPLoss:8.1770 | CLSLoss:0.5382 | top1:95.1340 | AUROC:0.9938\n",
      "Test | 39/10 | Loss:0.6428 | MainLoss:0.5557 | SPLoss:8.1770 | CLSLoss:0.5382 | top1:62.0128 | AUROC:0.9875\n",
      "\n",
      "Epoch: [41 | 1000] LR: 0.399171\n",
      "Train | 10/10 | Loss:0.5230 | MainLoss:0.4365 | SPLoss:8.1482 | CLSLoss:0.5049 | top1:79.3000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2971 | MainLoss:0.2118 | SPLoss:8.0619 | CLSLoss:0.4753 | top1:96.7788 | AUROC:0.9940\n",
      "Test | 39/10 | Loss:0.7170 | MainLoss:0.6316 | SPLoss:8.0619 | CLSLoss:0.4753 | top1:56.1026 | AUROC:0.9878\n",
      "\n",
      "Epoch: [42 | 1000] LR: 0.399112\n",
      "Train | 10/10 | Loss:0.5209 | MainLoss:0.4376 | SPLoss:7.8455 | CLSLoss:0.4826 | top1:79.0500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2870 | MainLoss:0.2037 | SPLoss:7.8147 | CLSLoss:0.5068 | top1:96.7103 | AUROC:0.9943\n",
      "Test | 39/10 | Loss:0.7093 | MainLoss:0.6261 | SPLoss:7.8147 | CLSLoss:0.5068 | top1:57.0641 | AUROC:0.9897\n",
      "\n",
      "Epoch: [43 | 1000] LR: 0.399052\n",
      "Train | 10/10 | Loss:0.5151 | MainLoss:0.4322 | SPLoss:7.7928 | CLSLoss:0.4974 | top1:80.3500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2737 | MainLoss:0.1902 | SPLoss:7.8621 | CLSLoss:0.4868 | top1:97.0935 | AUROC:0.9943\n",
      "Test | 39/10 | Loss:0.7590 | MainLoss:0.6755 | SPLoss:7.8621 | CLSLoss:0.4868 | top1:55.5641 | AUROC:0.9867\n",
      "\n",
      "Epoch: [44 | 1000] LR: 0.398990\n",
      "Train | 10/10 | Loss:0.5148 | MainLoss:0.4324 | SPLoss:7.7680 | CLSLoss:0.4767 | top1:79.4500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2919 | MainLoss:0.2096 | SPLoss:7.7519 | CLSLoss:0.4753 | top1:96.9502 | AUROC:0.9939\n",
      "Test | 39/10 | Loss:0.7250 | MainLoss:0.6427 | SPLoss:7.7519 | CLSLoss:0.4753 | top1:55.5256 | AUROC:0.9874\n",
      "\n",
      "Epoch: [45 | 1000] LR: 0.398926\n",
      "Train | 10/10 | Loss:0.5232 | MainLoss:0.4414 | SPLoss:7.7082 | CLSLoss:0.4714 | top1:78.8000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.3151 | MainLoss:0.2349 | SPLoss:7.5470 | CLSLoss:0.4710 | top1:96.0810 | AUROC:0.9938\n",
      "Test | 39/10 | Loss:0.6540 | MainLoss:0.5739 | SPLoss:7.5470 | CLSLoss:0.4710 | top1:59.0256 | AUROC:0.9889\n",
      "\n",
      "Epoch: [46 | 1000] LR: 0.398860\n",
      "Train | 10/10 | Loss:0.5254 | MainLoss:0.4464 | SPLoss:7.4324 | CLSLoss:0.4712 | top1:79.2500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2918 | MainLoss:0.2135 | SPLoss:7.3784 | CLSLoss:0.4466 | top1:96.7009 | AUROC:0.9938\n",
      "Test | 39/10 | Loss:0.7136 | MainLoss:0.6354 | SPLoss:7.3784 | CLSLoss:0.4466 | top1:56.2308 | AUROC:0.9898\n",
      "\n",
      "Epoch: [47 | 1000] LR: 0.398792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 10/10 | Loss:0.5044 | MainLoss:0.4268 | SPLoss:7.2945 | CLSLoss:0.4662 | top1:80.3000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2745 | MainLoss:0.1976 | SPLoss:7.2009 | CLSLoss:0.4874 | top1:96.5857 | AUROC:0.9941\n",
      "Test | 39/10 | Loss:0.7234 | MainLoss:0.6466 | SPLoss:7.2008 | CLSLoss:0.4874 | top1:57.2308 | AUROC:0.9893\n",
      "\n",
      "Epoch: [48 | 1000] LR: 0.398722\n",
      "Train | 10/10 | Loss:0.5110 | MainLoss:0.4352 | SPLoss:7.1070 | CLSLoss:0.4724 | top1:79.9000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2953 | MainLoss:0.2197 | SPLoss:7.1085 | CLSLoss:0.4487 | top1:96.3146 | AUROC:0.9937\n",
      "Test | 39/10 | Loss:0.6785 | MainLoss:0.6029 | SPLoss:7.1085 | CLSLoss:0.4487 | top1:57.8974 | AUROC:0.9904\n",
      "\n",
      "Epoch: [49 | 1000] LR: 0.398650\n",
      "Train | 10/10 | Loss:0.4961 | MainLoss:0.4207 | SPLoss:7.0589 | CLSLoss:0.4745 | top1:80.0500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.3074 | MainLoss:0.2329 | SPLoss:6.9778 | CLSLoss:0.4642 | top1:95.9097 | AUROC:0.9935\n",
      "Test | 39/10 | Loss:0.6489 | MainLoss:0.5744 | SPLoss:6.9778 | CLSLoss:0.4642 | top1:59.1154 | AUROC:0.9907\n",
      "\n",
      "Epoch: [50 | 1000] LR: 0.398577\n",
      "Train | 10/10 | Loss:0.5059 | MainLoss:0.4313 | SPLoss:6.9882 | CLSLoss:0.4713 | top1:80.0500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.3043 | MainLoss:0.2309 | SPLoss:6.9229 | CLSLoss:0.4151 | top1:96.5078 | AUROC:0.9926\n",
      "Test | 39/10 | Loss:0.7052 | MainLoss:0.6318 | SPLoss:6.9229 | CLSLoss:0.4151 | top1:54.6795 | AUROC:0.9904\n",
      "\n",
      "Epoch: [51 | 1000] LR: 0.398501\n",
      "Train | 10/10 | Loss:0.4997 | MainLoss:0.4267 | SPLoss:6.8534 | CLSLoss:0.4535 | top1:80.1000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2792 | MainLoss:0.2050 | SPLoss:6.9330 | CLSLoss:0.4830 | top1:96.5421 | AUROC:0.9945\n",
      "Test | 39/10 | Loss:0.6930 | MainLoss:0.6189 | SPLoss:6.9330 | CLSLoss:0.4830 | top1:58.3462 | AUROC:0.9876\n",
      "\n",
      "Epoch: [52 | 1000] LR: 0.039842\n",
      "Train | 10/10 | Loss:0.4793 | MainLoss:0.4052 | SPLoss:6.9292 | CLSLoss:0.4845 | top1:81.3500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2848 | MainLoss:0.2109 | SPLoss:6.9124 | CLSLoss:0.4836 | top1:96.3240 | AUROC:0.9943\n",
      "Test | 39/10 | Loss:0.6813 | MainLoss:0.6073 | SPLoss:6.9124 | CLSLoss:0.4836 | top1:58.8590 | AUROC:0.9878\n",
      "\n",
      "Epoch: [53 | 1000] LR: 0.039834\n",
      "Train | 10/10 | Loss:0.4966 | MainLoss:0.4227 | SPLoss:6.9067 | CLSLoss:0.4825 | top1:80.0500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2890 | MainLoss:0.2153 | SPLoss:6.8898 | CLSLoss:0.4803 | top1:96.1682 | AUROC:0.9943\n",
      "Test | 39/10 | Loss:0.6715 | MainLoss:0.5978 | SPLoss:6.8898 | CLSLoss:0.4803 | top1:59.1667 | AUROC:0.9876\n",
      "\n",
      "Epoch: [54 | 1000] LR: 0.039826\n",
      "Train | 10/10 | Loss:0.4978 | MainLoss:0.4241 | SPLoss:6.8889 | CLSLoss:0.4785 | top1:80.4000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2860 | MainLoss:0.2124 | SPLoss:6.8829 | CLSLoss:0.4741 | top1:96.3115 | AUROC:0.9944\n",
      "Test | 39/10 | Loss:0.6783 | MainLoss:0.6047 | SPLoss:6.8829 | CLSLoss:0.4741 | top1:58.7179 | AUROC:0.9877\n",
      "\n",
      "Epoch: [55 | 1000] LR: 0.039818\n",
      "Train | 10/10 | Loss:0.4920 | MainLoss:0.4185 | SPLoss:6.8713 | CLSLoss:0.4751 | top1:80.7000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2861 | MainLoss:0.2128 | SPLoss:6.8559 | CLSLoss:0.4724 | top1:96.3146 | AUROC:0.9941\n",
      "Test | 39/10 | Loss:0.6783 | MainLoss:0.6050 | SPLoss:6.8559 | CLSLoss:0.4724 | top1:58.6154 | AUROC:0.9878\n",
      "\n",
      "Epoch: [56 | 1000] LR: 0.039809\n",
      "Train | 10/10 | Loss:0.4824 | MainLoss:0.4092 | SPLoss:6.8454 | CLSLoss:0.4734 | top1:80.3500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2849 | MainLoss:0.2118 | SPLoss:6.8338 | CLSLoss:0.4755 | top1:96.3240 | AUROC:0.9941\n",
      "Test | 39/10 | Loss:0.6800 | MainLoss:0.6069 | SPLoss:6.8338 | CLSLoss:0.4755 | top1:58.5128 | AUROC:0.9881\n",
      "\n",
      "Epoch: [57 | 1000] LR: 0.039800\n",
      "Train | 10/10 | Loss:0.4966 | MainLoss:0.4235 | SPLoss:6.8311 | CLSLoss:0.4742 | top1:80.4500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2857 | MainLoss:0.2127 | SPLoss:6.8308 | CLSLoss:0.4726 | top1:96.2928 | AUROC:0.9941\n",
      "Test | 39/10 | Loss:0.6782 | MainLoss:0.6052 | SPLoss:6.8308 | CLSLoss:0.4726 | top1:58.6538 | AUROC:0.9880\n",
      "\n",
      "Epoch: [58 | 1000] LR: 0.039792\n",
      "Train | 10/10 | Loss:0.4903 | MainLoss:0.4172 | SPLoss:6.8313 | CLSLoss:0.4713 | top1:80.0000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2855 | MainLoss:0.2125 | SPLoss:6.8289 | CLSLoss:0.4741 | top1:96.3364 | AUROC:0.9940\n",
      "Test | 39/10 | Loss:0.6789 | MainLoss:0.6059 | SPLoss:6.8289 | CLSLoss:0.4741 | top1:58.4744 | AUROC:0.9876\n",
      "\n",
      "Epoch: [59 | 1000] LR: 0.039782\n",
      "Train | 10/10 | Loss:0.4972 | MainLoss:0.4242 | SPLoss:6.8273 | CLSLoss:0.4746 | top1:79.7500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2832 | MainLoss:0.2101 | SPLoss:6.8306 | CLSLoss:0.4732 | top1:96.4548 | AUROC:0.9940\n",
      "Test | 39/10 | Loss:0.6844 | MainLoss:0.6114 | SPLoss:6.8306 | CLSLoss:0.4732 | top1:58.1410 | AUROC:0.9880\n",
      "\n",
      "Epoch: [60 | 1000] LR: 0.039773\n",
      "Train | 10/10 | Loss:0.4975 | MainLoss:0.4245 | SPLoss:6.8218 | CLSLoss:0.4704 | top1:80.3500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2845 | MainLoss:0.2117 | SPLoss:6.8128 | CLSLoss:0.4701 | top1:96.3770 | AUROC:0.9941\n",
      "Test | 39/10 | Loss:0.6801 | MainLoss:0.6072 | SPLoss:6.8128 | CLSLoss:0.4701 | top1:58.2949 | AUROC:0.9881\n",
      "\n",
      "Epoch: [61 | 1000] LR: 0.039763\n",
      "Train | 10/10 | Loss:0.4784 | MainLoss:0.4057 | SPLoss:6.8019 | CLSLoss:0.4703 | top1:81.2500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2840 | MainLoss:0.2113 | SPLoss:6.7982 | CLSLoss:0.4754 | top1:96.3364 | AUROC:0.9941\n",
      "Test | 39/10 | Loss:0.6803 | MainLoss:0.6076 | SPLoss:6.7982 | CLSLoss:0.4754 | top1:58.4872 | AUROC:0.9882\n",
      "\n",
      "Epoch: [62 | 1000] LR: 0.039754\n",
      "Train | 10/10 | Loss:0.5140 | MainLoss:0.4414 | SPLoss:6.7930 | CLSLoss:0.4695 | top1:79.5000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2814 | MainLoss:0.2089 | SPLoss:6.7890 | CLSLoss:0.4650 | top1:96.5389 | AUROC:0.9941\n",
      "Test | 39/10 | Loss:0.6870 | MainLoss:0.6145 | SPLoss:6.7890 | CLSLoss:0.4650 | top1:57.7949 | AUROC:0.9882\n",
      "\n",
      "Epoch: [63 | 1000] LR: 0.039744\n",
      "Train | 10/10 | Loss:0.5105 | MainLoss:0.4380 | SPLoss:6.7834 | CLSLoss:0.4654 | top1:80.4500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2840 | MainLoss:0.2116 | SPLoss:6.7774 | CLSLoss:0.4584 | top1:96.4984 | AUROC:0.9941\n",
      "Test | 39/10 | Loss:0.6833 | MainLoss:0.6109 | SPLoss:6.7774 | CLSLoss:0.4584 | top1:58.0000 | AUROC:0.9884\n",
      "\n",
      "Epoch: [64 | 1000] LR: 0.039734\n",
      "Train | 10/10 | Loss:0.5163 | MainLoss:0.4441 | SPLoss:6.7704 | CLSLoss:0.4524 | top1:78.9500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2832 | MainLoss:0.2111 | SPLoss:6.7620 | CLSLoss:0.4505 | top1:96.6137 | AUROC:0.9941\n",
      "Test | 39/10 | Loss:0.6872 | MainLoss:0.6151 | SPLoss:6.7620 | CLSLoss:0.4505 | top1:57.4872 | AUROC:0.9885\n",
      "\n",
      "Epoch: [65 | 1000] LR: 0.039723\n",
      "Train | 10/10 | Loss:0.4951 | MainLoss:0.4230 | SPLoss:6.7566 | CLSLoss:0.4537 | top1:80.0000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2908 | MainLoss:0.2188 | SPLoss:6.7382 | CLSLoss:0.4545 | top1:96.2835 | AUROC:0.9940\n",
      "Test | 39/10 | Loss:0.6676 | MainLoss:0.5957 | SPLoss:6.7382 | CLSLoss:0.4545 | top1:58.5641 | AUROC:0.9888\n",
      "\n",
      "Epoch: [66 | 1000] LR: 0.039713\n",
      "Train | 10/10 | Loss:0.4920 | MainLoss:0.4202 | SPLoss:6.7250 | CLSLoss:0.4572 | top1:80.5000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2862 | MainLoss:0.2143 | SPLoss:6.7337 | CLSLoss:0.4588 | top1:96.3956 | AUROC:0.9939\n",
      "Test | 39/10 | Loss:0.6763 | MainLoss:0.6043 | SPLoss:6.7337 | CLSLoss:0.4588 | top1:58.2820 | AUROC:0.9887\n",
      "\n",
      "Epoch: [67 | 1000] LR: 0.039702\n",
      "Train | 10/10 | Loss:0.5090 | MainLoss:0.4371 | SPLoss:6.7349 | CLSLoss:0.4599 | top1:79.7000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2881 | MainLoss:0.2163 | SPLoss:6.7253 | CLSLoss:0.4567 | top1:96.3396 | AUROC:0.9941\n",
      "Test | 39/10 | Loss:0.6717 | MainLoss:0.5999 | SPLoss:6.7253 | CLSLoss:0.4567 | top1:58.4231 | AUROC:0.9884\n",
      "\n",
      "Epoch: [68 | 1000] LR: 0.039691\n",
      "Train | 10/10 | Loss:0.4959 | MainLoss:0.4240 | SPLoss:6.7250 | CLSLoss:0.4574 | top1:79.8000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2866 | MainLoss:0.2148 | SPLoss:6.7293 | CLSLoss:0.4587 | top1:96.3427 | AUROC:0.9942\n",
      "Test | 39/10 | Loss:0.6741 | MainLoss:0.6022 | SPLoss:6.7293 | CLSLoss:0.4587 | top1:58.3974 | AUROC:0.9887\n",
      "\n",
      "Epoch: [69 | 1000] LR: 0.039680\n",
      "Train | 10/10 | Loss:0.4928 | MainLoss:0.4208 | SPLoss:6.7361 | CLSLoss:0.4628 | top1:80.3500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2897 | MainLoss:0.2179 | SPLoss:6.7152 | CLSLoss:0.4600 | top1:96.2679 | AUROC:0.9941\n",
      "Test | 39/10 | Loss:0.6681 | MainLoss:0.5964 | SPLoss:6.7152 | CLSLoss:0.4600 | top1:58.6795 | AUROC:0.9882\n",
      "\n",
      "Epoch: [70 | 1000] LR: 0.039669\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 10/10 | Loss:0.4955 | MainLoss:0.4237 | SPLoss:6.7148 | CLSLoss:0.4613 | top1:80.5000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2854 | MainLoss:0.2137 | SPLoss:6.7146 | CLSLoss:0.4590 | top1:96.4393 | AUROC:0.9940\n",
      "Test | 39/10 | Loss:0.6783 | MainLoss:0.6065 | SPLoss:6.7146 | CLSLoss:0.4590 | top1:58.2436 | AUROC:0.9881\n",
      "\n",
      "Epoch: [71 | 1000] LR: 0.039657\n",
      "Train | 10/10 | Loss:0.4975 | MainLoss:0.4258 | SPLoss:6.7146 | CLSLoss:0.4573 | top1:80.3500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2799 | MainLoss:0.2080 | SPLoss:6.7247 | CLSLoss:0.4586 | top1:96.6449 | AUROC:0.9941\n",
      "Test | 39/10 | Loss:0.6908 | MainLoss:0.6189 | SPLoss:6.7247 | CLSLoss:0.4586 | top1:57.5000 | AUROC:0.9884\n",
      "\n",
      "Epoch: [72 | 1000] LR: 0.039646\n",
      "Train | 10/10 | Loss:0.4791 | MainLoss:0.4074 | SPLoss:6.7187 | CLSLoss:0.4595 | top1:81.3000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2819 | MainLoss:0.2102 | SPLoss:6.7074 | CLSLoss:0.4637 | top1:96.5203 | AUROC:0.9940\n",
      "Test | 39/10 | Loss:0.6851 | MainLoss:0.6134 | SPLoss:6.7074 | CLSLoss:0.4637 | top1:57.8590 | AUROC:0.9886\n",
      "\n",
      "Epoch: [73 | 1000] LR: 0.039634\n",
      "Train | 10/10 | Loss:0.4835 | MainLoss:0.4118 | SPLoss:6.7092 | CLSLoss:0.4638 | top1:80.7500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2816 | MainLoss:0.2098 | SPLoss:6.7079 | CLSLoss:0.4656 | top1:96.5389 | AUROC:0.9941\n",
      "Test | 39/10 | Loss:0.6865 | MainLoss:0.6148 | SPLoss:6.7079 | CLSLoss:0.4656 | top1:57.9359 | AUROC:0.9882\n",
      "\n",
      "Epoch: [74 | 1000] LR: 0.039622\n",
      "Train | 10/10 | Loss:0.5077 | MainLoss:0.4361 | SPLoss:6.6992 | CLSLoss:0.4611 | top1:79.1000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2827 | MainLoss:0.2112 | SPLoss:6.6888 | CLSLoss:0.4598 | top1:96.5670 | AUROC:0.9939\n",
      "Test | 39/10 | Loss:0.6840 | MainLoss:0.6125 | SPLoss:6.6888 | CLSLoss:0.4598 | top1:57.7051 | AUROC:0.9884\n",
      "\n",
      "Epoch: [75 | 1000] LR: 0.039610\n",
      "Train | 10/10 | Loss:0.4862 | MainLoss:0.4148 | SPLoss:6.6820 | CLSLoss:0.4610 | top1:80.4000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2820 | MainLoss:0.2106 | SPLoss:6.6723 | CLSLoss:0.4631 | top1:96.5701 | AUROC:0.9940\n",
      "Test | 39/10 | Loss:0.6846 | MainLoss:0.6132 | SPLoss:6.6723 | CLSLoss:0.4631 | top1:57.7308 | AUROC:0.9888\n",
      "\n",
      "Epoch: [76 | 1000] LR: 0.039597\n",
      "Train | 10/10 | Loss:0.4879 | MainLoss:0.4166 | SPLoss:6.6624 | CLSLoss:0.4645 | top1:80.6500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2834 | MainLoss:0.2122 | SPLoss:6.6543 | CLSLoss:0.4664 | top1:96.4455 | AUROC:0.9940\n",
      "Test | 39/10 | Loss:0.6812 | MainLoss:0.6100 | SPLoss:6.6543 | CLSLoss:0.4664 | top1:58.1282 | AUROC:0.9888\n",
      "\n",
      "Epoch: [77 | 1000] LR: 0.039584\n",
      "Train | 10/10 | Loss:0.4945 | MainLoss:0.4233 | SPLoss:6.6503 | CLSLoss:0.4644 | top1:80.2000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2824 | MainLoss:0.2112 | SPLoss:6.6577 | CLSLoss:0.4639 | top1:96.5265 | AUROC:0.9939\n",
      "Test | 39/10 | Loss:0.6843 | MainLoss:0.6131 | SPLoss:6.6577 | CLSLoss:0.4639 | top1:57.8333 | AUROC:0.9891\n",
      "\n",
      "Epoch: [78 | 1000] LR: 0.039572\n",
      "Train | 10/10 | Loss:0.4836 | MainLoss:0.4125 | SPLoss:6.6436 | CLSLoss:0.4656 | top1:81.0500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2840 | MainLoss:0.2130 | SPLoss:6.6406 | CLSLoss:0.4658 | top1:96.3801 | AUROC:0.9938\n",
      "Test | 39/10 | Loss:0.6797 | MainLoss:0.6086 | SPLoss:6.6406 | CLSLoss:0.4658 | top1:58.3205 | AUROC:0.9886\n",
      "\n",
      "Epoch: [79 | 1000] LR: 0.039559\n",
      "Train | 10/10 | Loss:0.4935 | MainLoss:0.4224 | SPLoss:6.6431 | CLSLoss:0.4668 | top1:80.2000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2862 | MainLoss:0.2153 | SPLoss:6.6267 | CLSLoss:0.4652 | top1:96.2960 | AUROC:0.9939\n",
      "Test | 39/10 | Loss:0.6735 | MainLoss:0.6026 | SPLoss:6.6267 | CLSLoss:0.4652 | top1:58.5256 | AUROC:0.9889\n",
      "\n",
      "Epoch: [80 | 1000] LR: 0.039545\n",
      "Train | 10/10 | Loss:0.4999 | MainLoss:0.4290 | SPLoss:6.6265 | CLSLoss:0.4626 | top1:80.2000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2823 | MainLoss:0.2113 | SPLoss:6.6328 | CLSLoss:0.4625 | top1:96.4424 | AUROC:0.9937\n",
      "Test | 39/10 | Loss:0.6827 | MainLoss:0.6117 | SPLoss:6.6328 | CLSLoss:0.4625 | top1:58.0641 | AUROC:0.9888\n",
      "\n",
      "Epoch: [81 | 1000] LR: 0.039532\n",
      "Train | 10/10 | Loss:0.4816 | MainLoss:0.4107 | SPLoss:6.6197 | CLSLoss:0.4621 | top1:80.8000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2816 | MainLoss:0.2107 | SPLoss:6.6183 | CLSLoss:0.4653 | top1:96.4361 | AUROC:0.9939\n",
      "Test | 39/10 | Loss:0.6836 | MainLoss:0.6127 | SPLoss:6.6183 | CLSLoss:0.4653 | top1:58.0641 | AUROC:0.9889\n",
      "\n",
      "Epoch: [82 | 1000] LR: 0.039518\n",
      "Train | 10/10 | Loss:0.4954 | MainLoss:0.4245 | SPLoss:6.6239 | CLSLoss:0.4651 | top1:80.4500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2796 | MainLoss:0.2087 | SPLoss:6.6237 | CLSLoss:0.4620 | top1:96.5670 | AUROC:0.9938\n",
      "Test | 39/10 | Loss:0.6898 | MainLoss:0.6189 | SPLoss:6.6237 | CLSLoss:0.4620 | top1:57.6923 | AUROC:0.9886\n",
      "\n",
      "Epoch: [83 | 1000] LR: 0.039505\n",
      "Train | 10/10 | Loss:0.5028 | MainLoss:0.4320 | SPLoss:6.6171 | CLSLoss:0.4628 | top1:79.7500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2850 | MainLoss:0.2144 | SPLoss:6.6011 | CLSLoss:0.4579 | top1:96.3801 | AUROC:0.9936\n",
      "Test | 39/10 | Loss:0.6771 | MainLoss:0.6065 | SPLoss:6.6011 | CLSLoss:0.4579 | top1:58.2179 | AUROC:0.9888\n",
      "\n",
      "Epoch: [84 | 1000] LR: 0.039491\n",
      "Train | 10/10 | Loss:0.4770 | MainLoss:0.4064 | SPLoss:6.6018 | CLSLoss:0.4604 | top1:81.6000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2826 | MainLoss:0.2120 | SPLoss:6.5933 | CLSLoss:0.4621 | top1:96.3863 | AUROC:0.9937\n",
      "Test | 39/10 | Loss:0.6823 | MainLoss:0.6118 | SPLoss:6.5932 | CLSLoss:0.4621 | top1:58.1410 | AUROC:0.9886\n",
      "\n",
      "Epoch: [85 | 1000] LR: 0.039476\n",
      "Train | 10/10 | Loss:0.4859 | MainLoss:0.4153 | SPLoss:6.5929 | CLSLoss:0.4629 | top1:80.6000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2789 | MainLoss:0.2082 | SPLoss:6.5985 | CLSLoss:0.4639 | top1:96.5078 | AUROC:0.9939\n",
      "Test | 39/10 | Loss:0.6902 | MainLoss:0.6196 | SPLoss:6.5985 | CLSLoss:0.4639 | top1:57.8205 | AUROC:0.9883\n",
      "\n",
      "Epoch: [86 | 1000] LR: 0.039462\n",
      "Train | 10/10 | Loss:0.4944 | MainLoss:0.4238 | SPLoss:6.5929 | CLSLoss:0.4619 | top1:80.5000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2802 | MainLoss:0.2097 | SPLoss:6.5883 | CLSLoss:0.4606 | top1:96.5389 | AUROC:0.9938\n",
      "Test | 39/10 | Loss:0.6865 | MainLoss:0.6160 | SPLoss:6.5883 | CLSLoss:0.4606 | top1:57.8205 | AUROC:0.9887\n",
      "\n",
      "Epoch: [87 | 1000] LR: 0.039447\n",
      "Train | 10/10 | Loss:0.4828 | MainLoss:0.4124 | SPLoss:6.5775 | CLSLoss:0.4631 | top1:80.9500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2851 | MainLoss:0.2148 | SPLoss:6.5688 | CLSLoss:0.4636 | top1:96.1682 | AUROC:0.9938\n",
      "Test | 39/10 | Loss:0.6737 | MainLoss:0.6034 | SPLoss:6.5688 | CLSLoss:0.4636 | top1:58.7179 | AUROC:0.9885\n",
      "\n",
      "Epoch: [88 | 1000] LR: 0.039433\n",
      "Train | 10/10 | Loss:0.4874 | MainLoss:0.4172 | SPLoss:6.5623 | CLSLoss:0.4621 | top1:80.6000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2805 | MainLoss:0.2101 | SPLoss:6.5717 | CLSLoss:0.4640 | top1:96.2866 | AUROC:0.9938\n",
      "Test | 39/10 | Loss:0.6833 | MainLoss:0.6129 | SPLoss:6.5717 | CLSLoss:0.4640 | top1:58.3974 | AUROC:0.9884\n",
      "\n",
      "Epoch: [89 | 1000] LR: 0.039418\n",
      "Train | 10/10 | Loss:0.4927 | MainLoss:0.4223 | SPLoss:6.5760 | CLSLoss:0.4639 | top1:80.2000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2797 | MainLoss:0.2092 | SPLoss:6.5897 | CLSLoss:0.4606 | top1:96.4361 | AUROC:0.9939\n",
      "Test | 39/10 | Loss:0.6876 | MainLoss:0.6171 | SPLoss:6.5897 | CLSLoss:0.4606 | top1:58.1410 | AUROC:0.9881\n",
      "\n",
      "Epoch: [90 | 1000] LR: 0.039403\n",
      "Train | 10/10 | Loss:0.4862 | MainLoss:0.4158 | SPLoss:6.5833 | CLSLoss:0.4590 | top1:80.3500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2823 | MainLoss:0.2120 | SPLoss:6.5758 | CLSLoss:0.4597 | top1:96.3364 | AUROC:0.9937\n",
      "Test | 39/10 | Loss:0.6822 | MainLoss:0.6118 | SPLoss:6.5758 | CLSLoss:0.4597 | top1:58.3462 | AUROC:0.9882\n",
      "\n",
      "Epoch: [91 | 1000] LR: 0.039387\n",
      "Train | 10/10 | Loss:0.4876 | MainLoss:0.4173 | SPLoss:6.5726 | CLSLoss:0.4590 | top1:80.7500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2814 | MainLoss:0.2111 | SPLoss:6.5694 | CLSLoss:0.4603 | top1:96.3863 | AUROC:0.9937\n",
      "Test | 39/10 | Loss:0.6851 | MainLoss:0.6148 | SPLoss:6.5694 | CLSLoss:0.4603 | top1:58.1154 | AUROC:0.9882\n",
      "\n",
      "Epoch: [92 | 1000] LR: 0.039372\n",
      "Train | 10/10 | Loss:0.4764 | MainLoss:0.4061 | SPLoss:6.5706 | CLSLoss:0.4624 | top1:81.2500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2867 | MainLoss:0.2166 | SPLoss:6.5481 | CLSLoss:0.4629 | top1:96.1122 | AUROC:0.9935\n",
      "Test | 39/10 | Loss:0.6739 | MainLoss:0.6038 | SPLoss:6.5481 | CLSLoss:0.4629 | top1:58.8205 | AUROC:0.9883\n",
      "\n",
      "Epoch: [93 | 1000] LR: 0.039356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 10/10 | Loss:0.4952 | MainLoss:0.4252 | SPLoss:6.5377 | CLSLoss:0.4604 | top1:79.9000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2823 | MainLoss:0.2123 | SPLoss:6.5461 | CLSLoss:0.4601 | top1:96.2710 | AUROC:0.9936\n",
      "Test | 39/10 | Loss:0.6825 | MainLoss:0.6125 | SPLoss:6.5461 | CLSLoss:0.4601 | top1:58.3462 | AUROC:0.9882\n",
      "\n",
      "Epoch: [94 | 1000] LR: 0.039340\n",
      "Train | 10/10 | Loss:0.4906 | MainLoss:0.4206 | SPLoss:6.5450 | CLSLoss:0.4607 | top1:80.0000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2854 | MainLoss:0.2155 | SPLoss:6.5329 | CLSLoss:0.4571 | top1:96.1994 | AUROC:0.9935\n",
      "Test | 39/10 | Loss:0.6755 | MainLoss:0.6056 | SPLoss:6.5329 | CLSLoss:0.4571 | top1:58.5385 | AUROC:0.9889\n",
      "\n",
      "Epoch: [95 | 1000] LR: 0.039324\n",
      "Train | 10/10 | Loss:0.4952 | MainLoss:0.4252 | SPLoss:6.5377 | CLSLoss:0.4577 | top1:80.3000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2856 | MainLoss:0.2158 | SPLoss:6.5246 | CLSLoss:0.4540 | top1:96.2243 | AUROC:0.9934\n",
      "Test | 39/10 | Loss:0.6755 | MainLoss:0.6057 | SPLoss:6.5246 | CLSLoss:0.4540 | top1:58.5000 | AUROC:0.9887\n",
      "\n",
      "Epoch: [96 | 1000] LR: 0.039308\n",
      "Train | 10/10 | Loss:0.4877 | MainLoss:0.4179 | SPLoss:6.5256 | CLSLoss:0.4525 | top1:80.4500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2839 | MainLoss:0.2142 | SPLoss:6.5199 | CLSLoss:0.4533 | top1:96.2399 | AUROC:0.9934\n",
      "Test | 39/10 | Loss:0.6795 | MainLoss:0.6098 | SPLoss:6.5199 | CLSLoss:0.4533 | top1:58.4231 | AUROC:0.9886\n",
      "\n",
      "Epoch: [97 | 1000] LR: 0.039291\n",
      "Train | 10/10 | Loss:0.4856 | MainLoss:0.4159 | SPLoss:6.5153 | CLSLoss:0.4553 | top1:81.1500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2863 | MainLoss:0.2168 | SPLoss:6.4989 | CLSLoss:0.4528 | top1:96.1090 | AUROC:0.9933\n",
      "Test | 39/10 | Loss:0.6731 | MainLoss:0.6035 | SPLoss:6.4989 | CLSLoss:0.4528 | top1:58.8333 | AUROC:0.9888\n",
      "\n",
      "Epoch: [98 | 1000] LR: 0.039274\n",
      "Train | 10/10 | Loss:0.4830 | MainLoss:0.4136 | SPLoss:6.4915 | CLSLoss:0.4544 | top1:80.6000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2855 | MainLoss:0.2160 | SPLoss:6.4945 | CLSLoss:0.4548 | top1:96.1028 | AUROC:0.9933\n",
      "Test | 39/10 | Loss:0.6752 | MainLoss:0.6057 | SPLoss:6.4945 | CLSLoss:0.4548 | top1:58.7436 | AUROC:0.9886\n",
      "\n",
      "Epoch: [99 | 1000] LR: 0.039258\n",
      "Train | 10/10 | Loss:0.4876 | MainLoss:0.4183 | SPLoss:6.4789 | CLSLoss:0.4539 | top1:80.8000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2873 | MainLoss:0.2181 | SPLoss:6.4630 | CLSLoss:0.4546 | top1:95.9969 | AUROC:0.9931\n",
      "Test | 39/10 | Loss:0.6714 | MainLoss:0.6022 | SPLoss:6.4630 | CLSLoss:0.4546 | top1:58.8974 | AUROC:0.9892\n",
      "\n",
      "Epoch: [100 | 1000] LR: 0.039241\n",
      "Train | 10/10 | Loss:0.4785 | MainLoss:0.4091 | SPLoss:6.4798 | CLSLoss:0.4552 | top1:81.1500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2835 | MainLoss:0.2141 | SPLoss:6.4847 | CLSLoss:0.4568 | top1:96.1464 | AUROC:0.9931\n",
      "Test | 39/10 | Loss:0.6798 | MainLoss:0.6104 | SPLoss:6.4847 | CLSLoss:0.4568 | top1:58.4487 | AUROC:0.9890\n",
      "\n",
      "Epoch: [101 | 1000] LR: 0.039223\n",
      "Train | 10/10 | Loss:0.4801 | MainLoss:0.4106 | SPLoss:6.4856 | CLSLoss:0.4586 | top1:81.4000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2835 | MainLoss:0.2141 | SPLoss:6.4846 | CLSLoss:0.4579 | top1:96.1464 | AUROC:0.9929\n",
      "Test | 39/10 | Loss:0.6806 | MainLoss:0.6111 | SPLoss:6.4846 | CLSLoss:0.4579 | top1:58.5513 | AUROC:0.9886\n",
      "\n",
      "Epoch: [102 | 1000] LR: 0.039206\n",
      "Train | 10/10 | Loss:0.4861 | MainLoss:0.4166 | SPLoss:6.4853 | CLSLoss:0.4597 | top1:80.3500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2865 | MainLoss:0.2171 | SPLoss:6.4855 | CLSLoss:0.4591 | top1:96.0031 | AUROC:0.9931\n",
      "Test | 39/10 | Loss:0.6730 | MainLoss:0.6035 | SPLoss:6.4855 | CLSLoss:0.4591 | top1:58.9615 | AUROC:0.9889\n",
      "\n",
      "Epoch: [103 | 1000] LR: 0.039188\n",
      "Train | 10/10 | Loss:0.4819 | MainLoss:0.4124 | SPLoss:6.4889 | CLSLoss:0.4606 | top1:80.3000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2867 | MainLoss:0.2173 | SPLoss:6.4878 | CLSLoss:0.4588 | top1:96.0561 | AUROC:0.9932\n",
      "Test | 39/10 | Loss:0.6738 | MainLoss:0.6044 | SPLoss:6.4878 | CLSLoss:0.4588 | top1:58.9744 | AUROC:0.9887\n",
      "\n",
      "Epoch: [104 | 1000] LR: 0.039170\n",
      "Train | 10/10 | Loss:0.4780 | MainLoss:0.4086 | SPLoss:6.4790 | CLSLoss:0.4616 | top1:81.5000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2878 | MainLoss:0.2185 | SPLoss:6.4773 | CLSLoss:0.4598 | top1:95.9065 | AUROC:0.9933\n",
      "Test | 39/10 | Loss:0.6701 | MainLoss:0.6008 | SPLoss:6.4773 | CLSLoss:0.4598 | top1:59.2436 | AUROC:0.9884\n",
      "\n",
      "Epoch: [105 | 1000] LR: 0.039152\n",
      "Train | 10/10 | Loss:0.4904 | MainLoss:0.4210 | SPLoss:6.4771 | CLSLoss:0.4580 | top1:80.7500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2882 | MainLoss:0.2189 | SPLoss:6.4717 | CLSLoss:0.4575 | top1:95.9377 | AUROC:0.9932\n",
      "Test | 39/10 | Loss:0.6700 | MainLoss:0.6007 | SPLoss:6.4717 | CLSLoss:0.4575 | top1:59.2051 | AUROC:0.9888\n",
      "\n",
      "Epoch: [106 | 1000] LR: 0.039134\n",
      "Train | 10/10 | Loss:0.4963 | MainLoss:0.4272 | SPLoss:6.4572 | CLSLoss:0.4535 | top1:80.5000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2856 | MainLoss:0.2165 | SPLoss:6.4575 | CLSLoss:0.4526 | top1:96.0654 | AUROC:0.9933\n",
      "Test | 39/10 | Loss:0.6747 | MainLoss:0.6056 | SPLoss:6.4575 | CLSLoss:0.4526 | top1:58.9615 | AUROC:0.9884\n",
      "\n",
      "Epoch: [107 | 1000] LR: 0.039116\n",
      "Train | 10/10 | Loss:0.5011 | MainLoss:0.4320 | SPLoss:6.4637 | CLSLoss:0.4496 | top1:80.4000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2822 | MainLoss:0.2131 | SPLoss:6.4660 | CLSLoss:0.4458 | top1:96.2617 | AUROC:0.9933\n",
      "Test | 39/10 | Loss:0.6818 | MainLoss:0.6126 | SPLoss:6.4661 | CLSLoss:0.4458 | top1:58.4487 | AUROC:0.9886\n",
      "\n",
      "Epoch: [108 | 1000] LR: 0.039097\n",
      "Train | 10/10 | Loss:0.4758 | MainLoss:0.4067 | SPLoss:6.4617 | CLSLoss:0.4500 | top1:80.9500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2823 | MainLoss:0.2132 | SPLoss:6.4601 | CLSLoss:0.4494 | top1:96.2150 | AUROC:0.9932\n",
      "Test | 39/10 | Loss:0.6825 | MainLoss:0.6134 | SPLoss:6.4601 | CLSLoss:0.4494 | top1:58.4359 | AUROC:0.9887\n",
      "\n",
      "Epoch: [109 | 1000] LR: 0.039079\n",
      "Train | 10/10 | Loss:0.4747 | MainLoss:0.4057 | SPLoss:6.4507 | CLSLoss:0.4517 | top1:81.5000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2856 | MainLoss:0.2168 | SPLoss:6.4292 | CLSLoss:0.4528 | top1:95.9626 | AUROC:0.9931\n",
      "Test | 39/10 | Loss:0.6752 | MainLoss:0.6064 | SPLoss:6.4292 | CLSLoss:0.4528 | top1:59.0256 | AUROC:0.9885\n",
      "\n",
      "Epoch: [110 | 1000] LR: 0.039060\n",
      "Train | 10/10 | Loss:0.4843 | MainLoss:0.4154 | SPLoss:6.4379 | CLSLoss:0.4521 | top1:80.3000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2816 | MainLoss:0.2126 | SPLoss:6.4402 | CLSLoss:0.4531 | top1:96.1682 | AUROC:0.9930\n",
      "Test | 39/10 | Loss:0.6847 | MainLoss:0.6157 | SPLoss:6.4402 | CLSLoss:0.4531 | top1:58.5128 | AUROC:0.9885\n",
      "\n",
      "Epoch: [111 | 1000] LR: 0.039040\n",
      "Train | 10/10 | Loss:0.4780 | MainLoss:0.4091 | SPLoss:6.4400 | CLSLoss:0.4531 | top1:81.0500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2832 | MainLoss:0.2144 | SPLoss:6.4313 | CLSLoss:0.4535 | top1:96.0436 | AUROC:0.9929\n",
      "Test | 39/10 | Loss:0.6804 | MainLoss:0.6115 | SPLoss:6.4313 | CLSLoss:0.4535 | top1:58.7949 | AUROC:0.9883\n",
      "\n",
      "Epoch: [112 | 1000] LR: 0.039021\n",
      "Train | 10/10 | Loss:0.4830 | MainLoss:0.4143 | SPLoss:6.4222 | CLSLoss:0.4529 | top1:80.5500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2825 | MainLoss:0.2138 | SPLoss:6.4224 | CLSLoss:0.4526 | top1:96.0685 | AUROC:0.9929\n",
      "Test | 39/10 | Loss:0.6812 | MainLoss:0.6124 | SPLoss:6.4224 | CLSLoss:0.4526 | top1:58.7564 | AUROC:0.9891\n",
      "\n",
      "Epoch: [113 | 1000] LR: 0.039002\n",
      "Train | 10/10 | Loss:0.4829 | MainLoss:0.4141 | SPLoss:6.4288 | CLSLoss:0.4553 | top1:80.3500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2836 | MainLoss:0.2148 | SPLoss:6.4261 | CLSLoss:0.4543 | top1:95.9938 | AUROC:0.9930\n",
      "Test | 39/10 | Loss:0.6790 | MainLoss:0.6102 | SPLoss:6.4261 | CLSLoss:0.4543 | top1:58.9615 | AUROC:0.9885\n",
      "\n",
      "Epoch: [114 | 1000] LR: 0.038982\n",
      "Train | 10/10 | Loss:0.4943 | MainLoss:0.4255 | SPLoss:6.4241 | CLSLoss:0.4535 | top1:80.1000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2883 | MainLoss:0.2197 | SPLoss:6.4146 | CLSLoss:0.4495 | top1:95.8941 | AUROC:0.9931\n",
      "Test | 39/10 | Loss:0.6676 | MainLoss:0.5990 | SPLoss:6.4146 | CLSLoss:0.4495 | top1:59.2820 | AUROC:0.9888\n",
      "\n",
      "Epoch: [115 | 1000] LR: 0.038962\n",
      "Train | 10/10 | Loss:0.4758 | MainLoss:0.4070 | SPLoss:6.4232 | CLSLoss:0.4490 | top1:80.7500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2813 | MainLoss:0.2126 | SPLoss:6.4231 | CLSLoss:0.4513 | top1:96.1838 | AUROC:0.9930\n",
      "Test | 39/10 | Loss:0.6833 | MainLoss:0.6145 | SPLoss:6.4231 | CLSLoss:0.4513 | top1:58.4231 | AUROC:0.9890\n",
      "\n",
      "Epoch: [116 | 1000] LR: 0.038942\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 10/10 | Loss:0.4907 | MainLoss:0.4219 | SPLoss:6.4323 | CLSLoss:0.4500 | top1:80.2000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2815 | MainLoss:0.2127 | SPLoss:6.4312 | CLSLoss:0.4492 | top1:96.2679 | AUROC:0.9929\n",
      "Test | 39/10 | Loss:0.6844 | MainLoss:0.6156 | SPLoss:6.4312 | CLSLoss:0.4492 | top1:58.1154 | AUROC:0.9888\n",
      "\n",
      "Epoch: [117 | 1000] LR: 0.038922\n",
      "Train | 10/10 | Loss:0.4803 | MainLoss:0.4116 | SPLoss:6.4215 | CLSLoss:0.4493 | top1:80.5500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2807 | MainLoss:0.2119 | SPLoss:6.4262 | CLSLoss:0.4505 | top1:96.2897 | AUROC:0.9930\n",
      "Test | 39/10 | Loss:0.6859 | MainLoss:0.6172 | SPLoss:6.4262 | CLSLoss:0.4505 | top1:58.0897 | AUROC:0.9887\n",
      "\n",
      "Epoch: [118 | 1000] LR: 0.038901\n",
      "Train | 10/10 | Loss:0.4755 | MainLoss:0.4069 | SPLoss:6.4170 | CLSLoss:0.4498 | top1:81.1000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2849 | MainLoss:0.2163 | SPLoss:6.4102 | CLSLoss:0.4530 | top1:96.1215 | AUROC:0.9929\n",
      "Test | 39/10 | Loss:0.6763 | MainLoss:0.6077 | SPLoss:6.4101 | CLSLoss:0.4530 | top1:58.6282 | AUROC:0.9891\n",
      "\n",
      "Epoch: [119 | 1000] LR: 0.038881\n",
      "Train | 10/10 | Loss:0.4788 | MainLoss:0.4103 | SPLoss:6.3995 | CLSLoss:0.4551 | top1:81.1000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2857 | MainLoss:0.2171 | SPLoss:6.4063 | CLSLoss:0.4570 | top1:96.0374 | AUROC:0.9929\n",
      "Test | 39/10 | Loss:0.6754 | MainLoss:0.6068 | SPLoss:6.4062 | CLSLoss:0.4570 | top1:58.9359 | AUROC:0.9890\n",
      "\n",
      "Epoch: [120 | 1000] LR: 0.038860\n",
      "Train | 10/10 | Loss:0.4767 | MainLoss:0.4082 | SPLoss:6.4017 | CLSLoss:0.4556 | top1:81.2000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2788 | MainLoss:0.2102 | SPLoss:6.4078 | CLSLoss:0.4581 | top1:96.2617 | AUROC:0.9928\n",
      "Test | 39/10 | Loss:0.6919 | MainLoss:0.6232 | SPLoss:6.4078 | CLSLoss:0.4581 | top1:58.0641 | AUROC:0.9887\n",
      "\n",
      "Epoch: [121 | 1000] LR: 0.038839\n",
      "Train | 10/10 | Loss:0.4656 | MainLoss:0.3972 | SPLoss:6.3873 | CLSLoss:0.4582 | top1:82.1000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2817 | MainLoss:0.2131 | SPLoss:6.3957 | CLSLoss:0.4621 | top1:96.1246 | AUROC:0.9926\n",
      "Test | 39/10 | Loss:0.6858 | MainLoss:0.6172 | SPLoss:6.3957 | CLSLoss:0.4621 | top1:58.4872 | AUROC:0.9889\n",
      "\n",
      "Epoch: [122 | 1000] LR: 0.038818\n",
      "Train | 10/10 | Loss:0.5041 | MainLoss:0.4355 | SPLoss:6.4018 | CLSLoss:0.4586 | top1:79.8000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2821 | MainLoss:0.2136 | SPLoss:6.3952 | CLSLoss:0.4521 | top1:96.1994 | AUROC:0.9930\n",
      "Test | 39/10 | Loss:0.6837 | MainLoss:0.6152 | SPLoss:6.3952 | CLSLoss:0.4521 | top1:58.2308 | AUROC:0.9888\n",
      "\n",
      "Epoch: [123 | 1000] LR: 0.038796\n",
      "Train | 10/10 | Loss:0.4820 | MainLoss:0.4135 | SPLoss:6.3957 | CLSLoss:0.4545 | top1:81.5000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2816 | MainLoss:0.2130 | SPLoss:6.4058 | CLSLoss:0.4521 | top1:96.2150 | AUROC:0.9928\n",
      "Test | 39/10 | Loss:0.6857 | MainLoss:0.6171 | SPLoss:6.4058 | CLSLoss:0.4521 | top1:58.2308 | AUROC:0.9884\n",
      "\n",
      "Epoch: [124 | 1000] LR: 0.038775\n",
      "Train | 10/10 | Loss:0.4758 | MainLoss:0.4073 | SPLoss:6.4019 | CLSLoss:0.4539 | top1:81.5000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2870 | MainLoss:0.2187 | SPLoss:6.3792 | CLSLoss:0.4541 | top1:95.9439 | AUROC:0.9927\n",
      "Test | 39/10 | Loss:0.6736 | MainLoss:0.6053 | SPLoss:6.3792 | CLSLoss:0.4541 | top1:59.1667 | AUROC:0.9886\n",
      "\n",
      "Epoch: [125 | 1000] LR: 0.038753\n",
      "Train | 10/10 | Loss:0.5021 | MainLoss:0.4338 | SPLoss:6.3823 | CLSLoss:0.4495 | top1:79.7000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2840 | MainLoss:0.2159 | SPLoss:6.3695 | CLSLoss:0.4449 | top1:96.1184 | AUROC:0.9929\n",
      "Test | 39/10 | Loss:0.6785 | MainLoss:0.6104 | SPLoss:6.3695 | CLSLoss:0.4449 | top1:58.6026 | AUROC:0.9889\n",
      "\n",
      "Epoch: [126 | 1000] LR: 0.038731\n",
      "Train | 10/10 | Loss:0.4949 | MainLoss:0.4267 | SPLoss:6.3704 | CLSLoss:0.4432 | top1:79.6000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2811 | MainLoss:0.2129 | SPLoss:6.3732 | CLSLoss:0.4423 | top1:96.3084 | AUROC:0.9930\n",
      "Test | 39/10 | Loss:0.6850 | MainLoss:0.6169 | SPLoss:6.3732 | CLSLoss:0.4423 | top1:57.9744 | AUROC:0.9887\n",
      "\n",
      "Epoch: [127 | 1000] LR: 0.038709\n",
      "Train | 10/10 | Loss:0.4763 | MainLoss:0.4082 | SPLoss:6.3631 | CLSLoss:0.4452 | top1:81.4000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2826 | MainLoss:0.2146 | SPLoss:6.3533 | CLSLoss:0.4459 | top1:96.1963 | AUROC:0.9931\n",
      "Test | 39/10 | Loss:0.6793 | MainLoss:0.6113 | SPLoss:6.3533 | CLSLoss:0.4459 | top1:58.4744 | AUROC:0.9893\n",
      "\n",
      "Epoch: [128 | 1000] LR: 0.038687\n",
      "Train | 10/10 | Loss:0.4870 | MainLoss:0.4188 | SPLoss:6.3652 | CLSLoss:0.4472 | top1:80.9000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2823 | MainLoss:0.2144 | SPLoss:6.3528 | CLSLoss:0.4438 | top1:96.2274 | AUROC:0.9929\n",
      "Test | 39/10 | Loss:0.6804 | MainLoss:0.6124 | SPLoss:6.3528 | CLSLoss:0.4438 | top1:58.3333 | AUROC:0.9890\n",
      "\n",
      "Epoch: [129 | 1000] LR: 0.038664\n",
      "Train | 10/10 | Loss:0.4915 | MainLoss:0.4235 | SPLoss:6.3580 | CLSLoss:0.4435 | top1:80.1000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2816 | MainLoss:0.2135 | SPLoss:6.3634 | CLSLoss:0.4414 | top1:96.2648 | AUROC:0.9929\n",
      "Test | 39/10 | Loss:0.6829 | MainLoss:0.6149 | SPLoss:6.3634 | CLSLoss:0.4414 | top1:58.1282 | AUROC:0.9889\n",
      "\n",
      "Epoch: [130 | 1000] LR: 0.038641\n",
      "Train | 10/10 | Loss:0.4800 | MainLoss:0.4121 | SPLoss:6.3484 | CLSLoss:0.4432 | top1:80.7500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2836 | MainLoss:0.2157 | SPLoss:6.3498 | CLSLoss:0.4442 | top1:96.1807 | AUROC:0.9931\n",
      "Test | 39/10 | Loss:0.6777 | MainLoss:0.6098 | SPLoss:6.3498 | CLSLoss:0.4442 | top1:58.5897 | AUROC:0.9890\n",
      "\n",
      "Epoch: [131 | 1000] LR: 0.038619\n",
      "Train | 10/10 | Loss:0.4827 | MainLoss:0.4147 | SPLoss:6.3532 | CLSLoss:0.4432 | top1:81.3500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2814 | MainLoss:0.2134 | SPLoss:6.3522 | CLSLoss:0.4434 | top1:96.2648 | AUROC:0.9931\n",
      "Test | 39/10 | Loss:0.6823 | MainLoss:0.6144 | SPLoss:6.3522 | CLSLoss:0.4434 | top1:58.2436 | AUROC:0.9888\n",
      "\n",
      "Epoch: [132 | 1000] LR: 0.038596\n",
      "Train | 10/10 | Loss:0.4986 | MainLoss:0.4307 | SPLoss:6.3473 | CLSLoss:0.4375 | top1:79.9500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2819 | MainLoss:0.2142 | SPLoss:6.3387 | CLSLoss:0.4377 | top1:96.2741 | AUROC:0.9930\n",
      "Test | 39/10 | Loss:0.6800 | MainLoss:0.6122 | SPLoss:6.3387 | CLSLoss:0.4377 | top1:58.2051 | AUROC:0.9892\n",
      "\n",
      "Epoch: [133 | 1000] LR: 0.038572\n",
      "Train | 10/10 | Loss:0.4985 | MainLoss:0.4306 | SPLoss:6.3523 | CLSLoss:0.4365 | top1:79.9500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2809 | MainLoss:0.2131 | SPLoss:6.3454 | CLSLoss:0.4348 | top1:96.3551 | AUROC:0.9931\n",
      "Test | 39/10 | Loss:0.6826 | MainLoss:0.6148 | SPLoss:6.3454 | CLSLoss:0.4348 | top1:57.9231 | AUROC:0.9892\n",
      "\n",
      "Epoch: [134 | 1000] LR: 0.038549\n",
      "Train | 10/10 | Loss:0.4755 | MainLoss:0.4078 | SPLoss:6.3371 | CLSLoss:0.4349 | top1:81.1000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2798 | MainLoss:0.2120 | SPLoss:6.3407 | CLSLoss:0.4394 | top1:96.2866 | AUROC:0.9930\n",
      "Test | 39/10 | Loss:0.6850 | MainLoss:0.6172 | SPLoss:6.3407 | CLSLoss:0.4394 | top1:58.0769 | AUROC:0.9893\n",
      "\n",
      "Epoch: [135 | 1000] LR: 0.038525\n",
      "Train | 10/10 | Loss:0.4746 | MainLoss:0.4068 | SPLoss:6.3427 | CLSLoss:0.4405 | top1:81.0500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2808 | MainLoss:0.2131 | SPLoss:6.3330 | CLSLoss:0.4425 | top1:96.1963 | AUROC:0.9930\n",
      "Test | 39/10 | Loss:0.6827 | MainLoss:0.6149 | SPLoss:6.3330 | CLSLoss:0.4425 | top1:58.4103 | AUROC:0.9891\n",
      "\n",
      "Epoch: [136 | 1000] LR: 0.038502\n",
      "Train | 10/10 | Loss:0.4838 | MainLoss:0.4161 | SPLoss:6.3308 | CLSLoss:0.4423 | top1:81.0000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2773 | MainLoss:0.2095 | SPLoss:6.3404 | CLSLoss:0.4397 | top1:96.3583 | AUROC:0.9930\n",
      "Test | 39/10 | Loss:0.6918 | MainLoss:0.6240 | SPLoss:6.3404 | CLSLoss:0.4397 | top1:57.7436 | AUROC:0.9891\n",
      "\n",
      "Epoch: [137 | 1000] LR: 0.038478\n",
      "Train | 10/10 | Loss:0.4820 | MainLoss:0.4142 | SPLoss:6.3340 | CLSLoss:0.4421 | top1:80.4000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2805 | MainLoss:0.2127 | SPLoss:6.3381 | CLSLoss:0.4395 | top1:96.2305 | AUROC:0.9928\n",
      "Test | 39/10 | Loss:0.6847 | MainLoss:0.6169 | SPLoss:6.3381 | CLSLoss:0.4395 | top1:58.1154 | AUROC:0.9889\n",
      "\n",
      "Epoch: [138 | 1000] LR: 0.038453\n",
      "Train | 10/10 | Loss:0.4836 | MainLoss:0.4158 | SPLoss:6.3344 | CLSLoss:0.4401 | top1:81.1000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2826 | MainLoss:0.2147 | SPLoss:6.3484 | CLSLoss:0.4411 | top1:96.0997 | AUROC:0.9927\n",
      "Test | 39/10 | Loss:0.6816 | MainLoss:0.6137 | SPLoss:6.3484 | CLSLoss:0.4411 | top1:58.4231 | AUROC:0.9888\n",
      "\n",
      "Epoch: [139 | 1000] LR: 0.038429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 10/10 | Loss:0.4780 | MainLoss:0.4100 | SPLoss:6.3546 | CLSLoss:0.4407 | top1:81.2000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2813 | MainLoss:0.2132 | SPLoss:6.3669 | CLSLoss:0.4445 | top1:96.1308 | AUROC:0.9929\n",
      "Test | 39/10 | Loss:0.6828 | MainLoss:0.6147 | SPLoss:6.3669 | CLSLoss:0.4445 | top1:58.5000 | AUROC:0.9887\n",
      "\n",
      "Epoch: [140 | 1000] LR: 0.038405\n",
      "Train | 10/10 | Loss:0.4904 | MainLoss:0.4222 | SPLoss:6.3770 | CLSLoss:0.4439 | top1:80.2000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2795 | MainLoss:0.2113 | SPLoss:6.3793 | CLSLoss:0.4399 | top1:96.3520 | AUROC:0.9929\n",
      "Test | 39/10 | Loss:0.6880 | MainLoss:0.6198 | SPLoss:6.3793 | CLSLoss:0.4399 | top1:58.0641 | AUROC:0.9888\n",
      "\n",
      "Epoch: [141 | 1000] LR: 0.038380\n",
      "Train | 10/10 | Loss:0.4943 | MainLoss:0.4261 | SPLoss:6.3787 | CLSLoss:0.4373 | top1:80.5500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2804 | MainLoss:0.2122 | SPLoss:6.3791 | CLSLoss:0.4338 | top1:96.3863 | AUROC:0.9927\n",
      "Test | 39/10 | Loss:0.6888 | MainLoss:0.6207 | SPLoss:6.3791 | CLSLoss:0.4338 | top1:57.7692 | AUROC:0.9887\n",
      "\n",
      "Epoch: [142 | 1000] LR: 0.038355\n",
      "Train | 10/10 | Loss:0.4836 | MainLoss:0.4155 | SPLoss:6.3822 | CLSLoss:0.4307 | top1:81.1000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2805 | MainLoss:0.2124 | SPLoss:6.3823 | CLSLoss:0.4333 | top1:96.3614 | AUROC:0.9926\n",
      "Test | 39/10 | Loss:0.6894 | MainLoss:0.6212 | SPLoss:6.3823 | CLSLoss:0.4333 | top1:57.8462 | AUROC:0.9885\n",
      "\n",
      "Epoch: [143 | 1000] LR: 0.038330\n",
      "Train | 10/10 | Loss:0.4834 | MainLoss:0.4154 | SPLoss:6.3728 | CLSLoss:0.4342 | top1:81.4500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2820 | MainLoss:0.2140 | SPLoss:6.3641 | CLSLoss:0.4352 | top1:96.2056 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6865 | MainLoss:0.6185 | SPLoss:6.3641 | CLSLoss:0.4352 | top1:58.1410 | AUROC:0.9884\n",
      "\n",
      "Epoch: [144 | 1000] LR: 0.038305\n",
      "Train | 10/10 | Loss:0.4883 | MainLoss:0.4204 | SPLoss:6.3602 | CLSLoss:0.4338 | top1:80.1000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2811 | MainLoss:0.2132 | SPLoss:6.3536 | CLSLoss:0.4343 | top1:96.2523 | AUROC:0.9927\n",
      "Test | 39/10 | Loss:0.6868 | MainLoss:0.6189 | SPLoss:6.3536 | CLSLoss:0.4343 | top1:57.9615 | AUROC:0.9890\n",
      "\n",
      "Epoch: [145 | 1000] LR: 0.038279\n",
      "Train | 10/10 | Loss:0.4873 | MainLoss:0.4194 | SPLoss:6.3504 | CLSLoss:0.4348 | top1:80.9000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2880 | MainLoss:0.2202 | SPLoss:6.3401 | CLSLoss:0.4381 | top1:95.9688 | AUROC:0.9925\n",
      "Test | 39/10 | Loss:0.6717 | MainLoss:0.6039 | SPLoss:6.3401 | CLSLoss:0.4381 | top1:58.9872 | AUROC:0.9890\n",
      "\n",
      "Epoch: [146 | 1000] LR: 0.038254\n",
      "Train | 10/10 | Loss:0.4931 | MainLoss:0.4254 | SPLoss:6.3381 | CLSLoss:0.4373 | top1:79.8500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2809 | MainLoss:0.2131 | SPLoss:6.3450 | CLSLoss:0.4349 | top1:96.2368 | AUROC:0.9925\n",
      "Test | 39/10 | Loss:0.6870 | MainLoss:0.6192 | SPLoss:6.3450 | CLSLoss:0.4349 | top1:57.8462 | AUROC:0.9890\n",
      "\n",
      "Epoch: [147 | 1000] LR: 0.038228\n",
      "Train | 10/10 | Loss:0.4757 | MainLoss:0.4079 | SPLoss:6.3434 | CLSLoss:0.4379 | top1:81.3500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2801 | MainLoss:0.2122 | SPLoss:6.3475 | CLSLoss:0.4406 | top1:96.2274 | AUROC:0.9927\n",
      "Test | 39/10 | Loss:0.6868 | MainLoss:0.6189 | SPLoss:6.3475 | CLSLoss:0.4406 | top1:58.0769 | AUROC:0.9889\n",
      "\n",
      "Epoch: [148 | 1000] LR: 0.038202\n",
      "Train | 10/10 | Loss:0.4825 | MainLoss:0.4145 | SPLoss:6.3517 | CLSLoss:0.4409 | top1:80.3500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2827 | MainLoss:0.2148 | SPLoss:6.3546 | CLSLoss:0.4417 | top1:96.1371 | AUROC:0.9925\n",
      "Test | 39/10 | Loss:0.6820 | MainLoss:0.6140 | SPLoss:6.3546 | CLSLoss:0.4417 | top1:58.3718 | AUROC:0.9886\n",
      "\n",
      "Epoch: [149 | 1000] LR: 0.038176\n",
      "Train | 10/10 | Loss:0.4847 | MainLoss:0.4167 | SPLoss:6.3605 | CLSLoss:0.4411 | top1:80.4500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2817 | MainLoss:0.2138 | SPLoss:6.3541 | CLSLoss:0.4401 | top1:96.2181 | AUROC:0.9925\n",
      "Test | 39/10 | Loss:0.6847 | MainLoss:0.6168 | SPLoss:6.3541 | CLSLoss:0.4401 | top1:58.0128 | AUROC:0.9884\n",
      "\n",
      "Epoch: [150 | 1000] LR: 0.038150\n",
      "Train | 10/10 | Loss:0.4846 | MainLoss:0.4167 | SPLoss:6.3502 | CLSLoss:0.4411 | top1:80.9500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2850 | MainLoss:0.2170 | SPLoss:6.3517 | CLSLoss:0.4408 | top1:96.0187 | AUROC:0.9927\n",
      "Test | 39/10 | Loss:0.6766 | MainLoss:0.6087 | SPLoss:6.3517 | CLSLoss:0.4408 | top1:58.7436 | AUROC:0.9881\n",
      "\n",
      "Epoch: [151 | 1000] LR: 0.038123\n",
      "Train | 10/10 | Loss:0.4724 | MainLoss:0.4045 | SPLoss:6.3449 | CLSLoss:0.4457 | top1:81.1500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2863 | MainLoss:0.2184 | SPLoss:6.3437 | CLSLoss:0.4467 | top1:95.8224 | AUROC:0.9928\n",
      "Test | 39/10 | Loss:0.6724 | MainLoss:0.6045 | SPLoss:6.3437 | CLSLoss:0.4467 | top1:59.3462 | AUROC:0.9883\n",
      "\n",
      "Epoch: [152 | 1000] LR: 0.038097\n",
      "Train | 10/10 | Loss:0.4787 | MainLoss:0.4108 | SPLoss:6.3509 | CLSLoss:0.4456 | top1:81.0000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2778 | MainLoss:0.2098 | SPLoss:6.3613 | CLSLoss:0.4447 | top1:96.1963 | AUROC:0.9929\n",
      "Test | 39/10 | Loss:0.6904 | MainLoss:0.6223 | SPLoss:6.3613 | CLSLoss:0.4447 | top1:58.2436 | AUROC:0.9878\n",
      "\n",
      "Epoch: [153 | 1000] LR: 0.038070\n",
      "Train | 10/10 | Loss:0.4775 | MainLoss:0.4095 | SPLoss:6.3581 | CLSLoss:0.4429 | top1:80.8500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2811 | MainLoss:0.2130 | SPLoss:6.3591 | CLSLoss:0.4456 | top1:96.0779 | AUROC:0.9930\n",
      "Test | 39/10 | Loss:0.6822 | MainLoss:0.6141 | SPLoss:6.3591 | CLSLoss:0.4456 | top1:58.6923 | AUROC:0.9876\n",
      "\n",
      "Epoch: [154 | 1000] LR: 0.038043\n",
      "Train | 10/10 | Loss:0.4961 | MainLoss:0.4282 | SPLoss:6.3486 | CLSLoss:0.4419 | top1:80.6500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2864 | MainLoss:0.2188 | SPLoss:6.3212 | CLSLoss:0.4393 | top1:95.8349 | AUROC:0.9928\n",
      "Test | 39/10 | Loss:0.6695 | MainLoss:0.6019 | SPLoss:6.3212 | CLSLoss:0.4393 | top1:59.2692 | AUROC:0.9881\n",
      "\n",
      "Epoch: [155 | 1000] LR: 0.038015\n",
      "Train | 10/10 | Loss:0.4994 | MainLoss:0.4316 | SPLoss:6.3344 | CLSLoss:0.4376 | top1:79.5000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2849 | MainLoss:0.2171 | SPLoss:6.3464 | CLSLoss:0.4383 | top1:95.9907 | AUROC:0.9928\n",
      "Test | 39/10 | Loss:0.6736 | MainLoss:0.6057 | SPLoss:6.3464 | CLSLoss:0.4383 | top1:58.9231 | AUROC:0.9880\n",
      "\n",
      "Epoch: [156 | 1000] LR: 0.037988\n",
      "Train | 10/10 | Loss:0.4823 | MainLoss:0.4145 | SPLoss:6.3438 | CLSLoss:0.4373 | top1:81.1500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2837 | MainLoss:0.2159 | SPLoss:6.3439 | CLSLoss:0.4391 | top1:96.0062 | AUROC:0.9929\n",
      "Test | 39/10 | Loss:0.6773 | MainLoss:0.6095 | SPLoss:6.3439 | CLSLoss:0.4391 | top1:58.8462 | AUROC:0.9879\n",
      "\n",
      "Epoch: [157 | 1000] LR: 0.037961\n",
      "Train | 10/10 | Loss:0.4749 | MainLoss:0.4071 | SPLoss:6.3442 | CLSLoss:0.4416 | top1:81.5000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2855 | MainLoss:0.2177 | SPLoss:6.3376 | CLSLoss:0.4411 | top1:95.8692 | AUROC:0.9930\n",
      "Test | 39/10 | Loss:0.6728 | MainLoss:0.6050 | SPLoss:6.3376 | CLSLoss:0.4411 | top1:59.2820 | AUROC:0.9881\n",
      "\n",
      "Epoch: [158 | 1000] LR: 0.037933\n",
      "Train | 10/10 | Loss:0.4827 | MainLoss:0.4150 | SPLoss:6.3258 | CLSLoss:0.4398 | top1:80.9500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2858 | MainLoss:0.2182 | SPLoss:6.3158 | CLSLoss:0.4431 | top1:95.7757 | AUROC:0.9931\n",
      "Test | 39/10 | Loss:0.6681 | MainLoss:0.6005 | SPLoss:6.3158 | CLSLoss:0.4431 | top1:59.6667 | AUROC:0.9884\n",
      "\n",
      "Epoch: [159 | 1000] LR: 0.037905\n",
      "Train | 10/10 | Loss:0.4807 | MainLoss:0.4132 | SPLoss:6.3083 | CLSLoss:0.4429 | top1:80.7000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2812 | MainLoss:0.2136 | SPLoss:6.3181 | CLSLoss:0.4437 | top1:95.9128 | AUROC:0.9930\n",
      "Test | 39/10 | Loss:0.6776 | MainLoss:0.6100 | SPLoss:6.3181 | CLSLoss:0.4437 | top1:59.2051 | AUROC:0.9882\n",
      "\n",
      "Epoch: [160 | 1000] LR: 0.037877\n",
      "Train | 10/10 | Loss:0.4753 | MainLoss:0.4076 | SPLoss:6.3266 | CLSLoss:0.4437 | top1:81.3000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2782 | MainLoss:0.2104 | SPLoss:6.3285 | CLSLoss:0.4448 | top1:96.0343 | AUROC:0.9930\n",
      "Test | 39/10 | Loss:0.6840 | MainLoss:0.6163 | SPLoss:6.3285 | CLSLoss:0.4448 | top1:58.8462 | AUROC:0.9882\n",
      "\n",
      "Epoch: [161 | 1000] LR: 0.037849\n",
      "Train | 10/10 | Loss:0.4685 | MainLoss:0.4009 | SPLoss:6.3208 | CLSLoss:0.4460 | top1:81.3500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2826 | MainLoss:0.2149 | SPLoss:6.3214 | CLSLoss:0.4483 | top1:95.8505 | AUROC:0.9932\n",
      "Test | 39/10 | Loss:0.6734 | MainLoss:0.6057 | SPLoss:6.3214 | CLSLoss:0.4483 | top1:59.4359 | AUROC:0.9882\n",
      "\n",
      "Epoch: [162 | 1000] LR: 0.037820\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 10/10 | Loss:0.4796 | MainLoss:0.4118 | SPLoss:6.3331 | CLSLoss:0.4482 | top1:80.9500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2820 | MainLoss:0.2142 | SPLoss:6.3263 | CLSLoss:0.4472 | top1:95.9626 | AUROC:0.9931\n",
      "Test | 39/10 | Loss:0.6753 | MainLoss:0.6076 | SPLoss:6.3263 | CLSLoss:0.4472 | top1:59.1410 | AUROC:0.9883\n",
      "\n",
      "Epoch: [163 | 1000] LR: 0.037792\n",
      "Train | 10/10 | Loss:0.4870 | MainLoss:0.4191 | SPLoss:6.3436 | CLSLoss:0.4445 | top1:80.4000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2743 | MainLoss:0.2062 | SPLoss:6.3594 | CLSLoss:0.4438 | top1:96.3209 | AUROC:0.9932\n",
      "Test | 39/10 | Loss:0.6948 | MainLoss:0.6267 | SPLoss:6.3593 | CLSLoss:0.4438 | top1:57.9103 | AUROC:0.9874\n",
      "\n",
      "Epoch: [164 | 1000] LR: 0.037763\n",
      "Train | 10/10 | Loss:0.4767 | MainLoss:0.4087 | SPLoss:6.3533 | CLSLoss:0.4449 | top1:81.0500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2757 | MainLoss:0.2077 | SPLoss:6.3555 | CLSLoss:0.4454 | top1:96.2523 | AUROC:0.9931\n",
      "Test | 39/10 | Loss:0.6914 | MainLoss:0.6234 | SPLoss:6.3555 | CLSLoss:0.4454 | top1:58.1795 | AUROC:0.9874\n",
      "\n",
      "Epoch: [165 | 1000] LR: 0.037734\n",
      "Train | 10/10 | Loss:0.4693 | MainLoss:0.4014 | SPLoss:6.3394 | CLSLoss:0.4477 | top1:81.6000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2809 | MainLoss:0.2130 | SPLoss:6.3356 | CLSLoss:0.4488 | top1:96.0623 | AUROC:0.9933\n",
      "Test | 39/10 | Loss:0.6791 | MainLoss:0.6113 | SPLoss:6.3356 | CLSLoss:0.4488 | top1:58.9744 | AUROC:0.9871\n",
      "\n",
      "Epoch: [166 | 1000] LR: 0.037705\n",
      "Train | 10/10 | Loss:0.4728 | MainLoss:0.4048 | SPLoss:6.3471 | CLSLoss:0.4496 | top1:81.4500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2728 | MainLoss:0.2046 | SPLoss:6.3652 | CLSLoss:0.4478 | top1:96.2960 | AUROC:0.9930\n",
      "Test | 39/10 | Loss:0.6998 | MainLoss:0.6316 | SPLoss:6.3652 | CLSLoss:0.4478 | top1:57.9103 | AUROC:0.9867\n",
      "\n",
      "Epoch: [167 | 1000] LR: 0.037675\n",
      "Train | 10/10 | Loss:0.4841 | MainLoss:0.4161 | SPLoss:6.3574 | CLSLoss:0.4476 | top1:81.5000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2831 | MainLoss:0.2152 | SPLoss:6.3409 | CLSLoss:0.4464 | top1:95.9720 | AUROC:0.9932\n",
      "Test | 39/10 | Loss:0.6760 | MainLoss:0.6081 | SPLoss:6.3409 | CLSLoss:0.4464 | top1:59.1282 | AUROC:0.9875\n",
      "\n",
      "Epoch: [168 | 1000] LR: 0.037646\n",
      "Train | 10/10 | Loss:0.4746 | MainLoss:0.4067 | SPLoss:6.3473 | CLSLoss:0.4471 | top1:81.2500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2824 | MainLoss:0.2145 | SPLoss:6.3438 | CLSLoss:0.4480 | top1:95.9626 | AUROC:0.9931\n",
      "Test | 39/10 | Loss:0.6777 | MainLoss:0.6098 | SPLoss:6.3438 | CLSLoss:0.4480 | top1:59.1282 | AUROC:0.9869\n",
      "\n",
      "Epoch: [169 | 1000] LR: 0.037616\n",
      "Train | 10/10 | Loss:0.4798 | MainLoss:0.4118 | SPLoss:6.3461 | CLSLoss:0.4475 | top1:80.8000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2850 | MainLoss:0.2172 | SPLoss:6.3338 | CLSLoss:0.4457 | top1:95.8910 | AUROC:0.9930\n",
      "Test | 39/10 | Loss:0.6720 | MainLoss:0.6042 | SPLoss:6.3338 | CLSLoss:0.4457 | top1:59.3462 | AUROC:0.9874\n",
      "\n",
      "Epoch: [170 | 1000] LR: 0.037586\n",
      "Train | 10/10 | Loss:0.4763 | MainLoss:0.4085 | SPLoss:6.3341 | CLSLoss:0.4445 | top1:80.9500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2838 | MainLoss:0.2160 | SPLoss:6.3301 | CLSLoss:0.4451 | top1:95.9097 | AUROC:0.9927\n",
      "Test | 39/10 | Loss:0.6760 | MainLoss:0.6082 | SPLoss:6.3301 | CLSLoss:0.4451 | top1:59.0513 | AUROC:0.9880\n",
      "\n",
      "Epoch: [171 | 1000] LR: 0.037556\n",
      "Train | 10/10 | Loss:0.4774 | MainLoss:0.4096 | SPLoss:6.3289 | CLSLoss:0.4463 | top1:80.1000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2750 | MainLoss:0.2071 | SPLoss:6.3467 | CLSLoss:0.4456 | top1:96.2991 | AUROC:0.9930\n",
      "Test | 39/10 | Loss:0.6954 | MainLoss:0.6274 | SPLoss:6.3467 | CLSLoss:0.4456 | top1:58.0128 | AUROC:0.9877\n",
      "\n",
      "Epoch: [172 | 1000] LR: 0.037526\n",
      "Train | 10/10 | Loss:0.4820 | MainLoss:0.4141 | SPLoss:6.3470 | CLSLoss:0.4442 | top1:80.5500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2812 | MainLoss:0.2133 | SPLoss:6.3389 | CLSLoss:0.4442 | top1:96.0810 | AUROC:0.9931\n",
      "Test | 39/10 | Loss:0.6805 | MainLoss:0.6126 | SPLoss:6.3389 | CLSLoss:0.4442 | top1:58.6923 | AUROC:0.9878\n",
      "\n",
      "Epoch: [173 | 1000] LR: 0.037496\n",
      "Train | 10/10 | Loss:0.4697 | MainLoss:0.4019 | SPLoss:6.3302 | CLSLoss:0.4456 | top1:81.7500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2831 | MainLoss:0.2152 | SPLoss:6.3403 | CLSLoss:0.4490 | top1:95.9720 | AUROC:0.9931\n",
      "Test | 39/10 | Loss:0.6772 | MainLoss:0.6093 | SPLoss:6.3403 | CLSLoss:0.4490 | top1:59.1410 | AUROC:0.9877\n",
      "\n",
      "Epoch: [174 | 1000] LR: 0.037465\n",
      "Train | 10/10 | Loss:0.4835 | MainLoss:0.4156 | SPLoss:6.3406 | CLSLoss:0.4496 | top1:80.2500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2767 | MainLoss:0.2089 | SPLoss:6.3386 | CLSLoss:0.4466 | top1:96.1682 | AUROC:0.9931\n",
      "Test | 39/10 | Loss:0.6886 | MainLoss:0.6208 | SPLoss:6.3386 | CLSLoss:0.4466 | top1:58.4744 | AUROC:0.9875\n",
      "\n",
      "Epoch: [175 | 1000] LR: 0.037435\n",
      "Train | 10/10 | Loss:0.4744 | MainLoss:0.4065 | SPLoss:6.3389 | CLSLoss:0.4471 | top1:81.0500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2817 | MainLoss:0.2138 | SPLoss:6.3397 | CLSLoss:0.4472 | top1:96.0374 | AUROC:0.9932\n",
      "Test | 39/10 | Loss:0.6798 | MainLoss:0.6119 | SPLoss:6.3396 | CLSLoss:0.4472 | top1:58.8974 | AUROC:0.9872\n",
      "\n",
      "Epoch: [176 | 1000] LR: 0.037404\n",
      "Train | 10/10 | Loss:0.4783 | MainLoss:0.4105 | SPLoss:6.3338 | CLSLoss:0.4502 | top1:80.5000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2883 | MainLoss:0.2204 | SPLoss:6.3367 | CLSLoss:0.4475 | top1:95.7601 | AUROC:0.9931\n",
      "Test | 39/10 | Loss:0.6667 | MainLoss:0.5989 | SPLoss:6.3367 | CLSLoss:0.4475 | top1:59.7820 | AUROC:0.9874\n",
      "\n",
      "Epoch: [177 | 1000] LR: 0.037373\n",
      "Train | 10/10 | Loss:0.4786 | MainLoss:0.4107 | SPLoss:6.3458 | CLSLoss:0.4487 | top1:81.2000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2825 | MainLoss:0.2145 | SPLoss:6.3500 | CLSLoss:0.4449 | top1:96.0561 | AUROC:0.9932\n",
      "Test | 39/10 | Loss:0.6789 | MainLoss:0.6109 | SPLoss:6.3500 | CLSLoss:0.4449 | top1:58.9359 | AUROC:0.9876\n",
      "\n",
      "Epoch: [178 | 1000] LR: 0.037341\n",
      "Train | 10/10 | Loss:0.4600 | MainLoss:0.3921 | SPLoss:6.3472 | CLSLoss:0.4462 | top1:81.8500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2835 | MainLoss:0.2156 | SPLoss:6.3402 | CLSLoss:0.4489 | top1:95.9065 | AUROC:0.9930\n",
      "Test | 39/10 | Loss:0.6772 | MainLoss:0.6093 | SPLoss:6.3402 | CLSLoss:0.4489 | top1:59.2179 | AUROC:0.9874\n",
      "\n",
      "Epoch: [179 | 1000] LR: 0.037310\n",
      "Train | 10/10 | Loss:0.4748 | MainLoss:0.4069 | SPLoss:6.3380 | CLSLoss:0.4478 | top1:81.0000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2809 | MainLoss:0.2130 | SPLoss:6.3416 | CLSLoss:0.4476 | top1:96.0592 | AUROC:0.9928\n",
      "Test | 39/10 | Loss:0.6843 | MainLoss:0.6164 | SPLoss:6.3416 | CLSLoss:0.4476 | top1:58.7308 | AUROC:0.9878\n",
      "\n",
      "Epoch: [180 | 1000] LR: 0.037278\n",
      "Train | 10/10 | Loss:0.4751 | MainLoss:0.4072 | SPLoss:6.3388 | CLSLoss:0.4474 | top1:81.0500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2813 | MainLoss:0.2135 | SPLoss:6.3324 | CLSLoss:0.4479 | top1:96.0530 | AUROC:0.9927\n",
      "Test | 39/10 | Loss:0.6848 | MainLoss:0.6170 | SPLoss:6.3324 | CLSLoss:0.4479 | top1:58.7308 | AUROC:0.9877\n",
      "\n",
      "Epoch: [181 | 1000] LR: 0.037247\n",
      "Train | 10/10 | Loss:0.4738 | MainLoss:0.4061 | SPLoss:6.3192 | CLSLoss:0.4472 | top1:81.6500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2890 | MainLoss:0.2213 | SPLoss:6.3164 | CLSLoss:0.4493 | top1:95.6667 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6696 | MainLoss:0.6019 | SPLoss:6.3164 | CLSLoss:0.4493 | top1:59.8077 | AUROC:0.9882\n",
      "\n",
      "Epoch: [182 | 1000] LR: 0.037215\n",
      "Train | 10/10 | Loss:0.4769 | MainLoss:0.4090 | SPLoss:6.3400 | CLSLoss:0.4477 | top1:81.2000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2775 | MainLoss:0.2094 | SPLoss:6.3607 | CLSLoss:0.4467 | top1:96.0685 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6965 | MainLoss:0.6285 | SPLoss:6.3607 | CLSLoss:0.4467 | top1:58.2820 | AUROC:0.9872\n",
      "\n",
      "Epoch: [183 | 1000] LR: 0.037183\n",
      "Train | 10/10 | Loss:0.4699 | MainLoss:0.4019 | SPLoss:6.3529 | CLSLoss:0.4473 | top1:81.2000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2819 | MainLoss:0.2139 | SPLoss:6.3520 | CLSLoss:0.4495 | top1:95.9252 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6854 | MainLoss:0.6174 | SPLoss:6.3521 | CLSLoss:0.4495 | top1:58.9487 | AUROC:0.9875\n",
      "\n",
      "Epoch: [184 | 1000] LR: 0.037151\n",
      "Train | 10/10 | Loss:0.4817 | MainLoss:0.4138 | SPLoss:6.3483 | CLSLoss:0.4473 | top1:80.8000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2873 | MainLoss:0.2194 | SPLoss:6.3403 | CLSLoss:0.4475 | top1:95.7632 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6735 | MainLoss:0.6056 | SPLoss:6.3403 | CLSLoss:0.4475 | top1:59.5769 | AUROC:0.9876\n",
      "\n",
      "Epoch: [185 | 1000] LR: 0.037118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 10/10 | Loss:0.4818 | MainLoss:0.4138 | SPLoss:6.3533 | CLSLoss:0.4475 | top1:80.9000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2767 | MainLoss:0.2086 | SPLoss:6.3666 | CLSLoss:0.4450 | top1:96.1277 | AUROC:0.9927\n",
      "Test | 39/10 | Loss:0.6942 | MainLoss:0.6261 | SPLoss:6.3666 | CLSLoss:0.4450 | top1:58.5256 | AUROC:0.9876\n",
      "\n",
      "Epoch: [186 | 1000] LR: 0.037086\n",
      "Train | 10/10 | Loss:0.4884 | MainLoss:0.4204 | SPLoss:6.3558 | CLSLoss:0.4425 | top1:81.0000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2777 | MainLoss:0.2098 | SPLoss:6.3554 | CLSLoss:0.4369 | top1:96.0561 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6920 | MainLoss:0.6241 | SPLoss:6.3554 | CLSLoss:0.4369 | top1:58.5641 | AUROC:0.9878\n",
      "\n",
      "Epoch: [187 | 1000] LR: 0.037053\n",
      "Train | 10/10 | Loss:0.4800 | MainLoss:0.4122 | SPLoss:6.3477 | CLSLoss:0.4357 | top1:80.7500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2855 | MainLoss:0.2176 | SPLoss:6.3488 | CLSLoss:0.4360 | top1:95.8193 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6748 | MainLoss:0.6070 | SPLoss:6.3488 | CLSLoss:0.4360 | top1:59.3718 | AUROC:0.9880\n",
      "\n",
      "Epoch: [188 | 1000] LR: 0.037020\n",
      "Train | 10/10 | Loss:0.4797 | MainLoss:0.4116 | SPLoss:6.3715 | CLSLoss:0.4351 | top1:81.4500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2799 | MainLoss:0.2117 | SPLoss:6.3846 | CLSLoss:0.4349 | top1:96.0530 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6895 | MainLoss:0.6213 | SPLoss:6.3846 | CLSLoss:0.4349 | top1:58.6026 | AUROC:0.9874\n",
      "\n",
      "Epoch: [189 | 1000] LR: 0.036987\n",
      "Train | 10/10 | Loss:0.4801 | MainLoss:0.4120 | SPLoss:6.3738 | CLSLoss:0.4359 | top1:81.0000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2771 | MainLoss:0.2090 | SPLoss:6.3759 | CLSLoss:0.4331 | top1:96.1558 | AUROC:0.9927\n",
      "Test | 39/10 | Loss:0.6933 | MainLoss:0.6252 | SPLoss:6.3759 | CLSLoss:0.4331 | top1:58.3718 | AUROC:0.9875\n",
      "\n",
      "Epoch: [190 | 1000] LR: 0.036954\n",
      "Train | 10/10 | Loss:0.4994 | MainLoss:0.4313 | SPLoss:6.3758 | CLSLoss:0.4306 | top1:79.9000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2803 | MainLoss:0.2123 | SPLoss:6.3709 | CLSLoss:0.4283 | top1:96.1464 | AUROC:0.9927\n",
      "Test | 39/10 | Loss:0.6854 | MainLoss:0.6174 | SPLoss:6.3710 | CLSLoss:0.4283 | top1:58.5256 | AUROC:0.9881\n",
      "\n",
      "Epoch: [191 | 1000] LR: 0.036920\n",
      "Train | 10/10 | Loss:0.4786 | MainLoss:0.4106 | SPLoss:6.3643 | CLSLoss:0.4278 | top1:81.1500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2825 | MainLoss:0.2145 | SPLoss:6.3660 | CLSLoss:0.4306 | top1:96.0530 | AUROC:0.9926\n",
      "Test | 39/10 | Loss:0.6816 | MainLoss:0.6136 | SPLoss:6.3661 | CLSLoss:0.4306 | top1:58.6795 | AUROC:0.9878\n",
      "\n",
      "Epoch: [192 | 1000] LR: 0.036887\n",
      "Train | 10/10 | Loss:0.4757 | MainLoss:0.4078 | SPLoss:6.3536 | CLSLoss:0.4331 | top1:81.3000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2854 | MainLoss:0.2176 | SPLoss:6.3479 | CLSLoss:0.4358 | top1:95.8287 | AUROC:0.9929\n",
      "Test | 39/10 | Loss:0.6720 | MainLoss:0.6042 | SPLoss:6.3479 | CLSLoss:0.4358 | top1:59.5256 | AUROC:0.9882\n",
      "\n",
      "Epoch: [193 | 1000] LR: 0.036853\n",
      "Train | 10/10 | Loss:0.4696 | MainLoss:0.4017 | SPLoss:6.3561 | CLSLoss:0.4374 | top1:80.9000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2844 | MainLoss:0.2166 | SPLoss:6.3492 | CLSLoss:0.4380 | top1:95.9221 | AUROC:0.9928\n",
      "Test | 39/10 | Loss:0.6748 | MainLoss:0.6069 | SPLoss:6.3492 | CLSLoss:0.4380 | top1:59.2436 | AUROC:0.9881\n",
      "\n",
      "Epoch: [194 | 1000] LR: 0.036819\n",
      "Train | 10/10 | Loss:0.4739 | MainLoss:0.4060 | SPLoss:6.3437 | CLSLoss:0.4393 | top1:80.9000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2882 | MainLoss:0.2204 | SPLoss:6.3435 | CLSLoss:0.4394 | top1:95.7539 | AUROC:0.9928\n",
      "Test | 39/10 | Loss:0.6676 | MainLoss:0.5997 | SPLoss:6.3435 | CLSLoss:0.4394 | top1:59.6154 | AUROC:0.9882\n",
      "\n",
      "Epoch: [195 | 1000] LR: 0.036785\n",
      "Train | 10/10 | Loss:0.4755 | MainLoss:0.4075 | SPLoss:6.3550 | CLSLoss:0.4408 | top1:80.8500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2841 | MainLoss:0.2162 | SPLoss:6.3430 | CLSLoss:0.4410 | top1:95.8785 | AUROC:0.9928\n",
      "Test | 39/10 | Loss:0.6752 | MainLoss:0.6074 | SPLoss:6.3429 | CLSLoss:0.4409 | top1:59.2820 | AUROC:0.9879\n",
      "\n",
      "Epoch: [196 | 1000] LR: 0.036751\n",
      "Train | 10/10 | Loss:0.4662 | MainLoss:0.3983 | SPLoss:6.3487 | CLSLoss:0.4414 | top1:81.9500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2827 | MainLoss:0.2146 | SPLoss:6.3635 | CLSLoss:0.4441 | top1:95.8661 | AUROC:0.9930\n",
      "Test | 39/10 | Loss:0.6793 | MainLoss:0.6112 | SPLoss:6.3635 | CLSLoss:0.4441 | top1:59.2820 | AUROC:0.9876\n",
      "\n",
      "Epoch: [197 | 1000] LR: 0.036716\n",
      "Train | 10/10 | Loss:0.4765 | MainLoss:0.4085 | SPLoss:6.3520 | CLSLoss:0.4429 | top1:81.2000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2789 | MainLoss:0.2108 | SPLoss:6.3671 | CLSLoss:0.4458 | top1:95.9938 | AUROC:0.9929\n",
      "Test | 39/10 | Loss:0.6862 | MainLoss:0.6180 | SPLoss:6.3671 | CLSLoss:0.4458 | top1:59.0128 | AUROC:0.9875\n",
      "\n",
      "Epoch: [198 | 1000] LR: 0.036682\n",
      "Train | 10/10 | Loss:0.4869 | MainLoss:0.4189 | SPLoss:6.3567 | CLSLoss:0.4431 | top1:79.8500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2804 | MainLoss:0.2124 | SPLoss:6.3574 | CLSLoss:0.4399 | top1:96.0685 | AUROC:0.9928\n",
      "Test | 39/10 | Loss:0.6826 | MainLoss:0.6147 | SPLoss:6.3574 | CLSLoss:0.4399 | top1:58.6538 | AUROC:0.9884\n",
      "\n",
      "Epoch: [199 | 1000] LR: 0.036647\n",
      "Train | 10/10 | Loss:0.4936 | MainLoss:0.4257 | SPLoss:6.3538 | CLSLoss:0.4372 | top1:80.2500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2819 | MainLoss:0.2140 | SPLoss:6.3554 | CLSLoss:0.4345 | top1:96.1028 | AUROC:0.9928\n",
      "Test | 39/10 | Loss:0.6782 | MainLoss:0.6103 | SPLoss:6.3554 | CLSLoss:0.4345 | top1:58.6410 | AUROC:0.9884\n",
      "\n",
      "Epoch: [200 | 1000] LR: 0.036612\n",
      "Train | 10/10 | Loss:0.4741 | MainLoss:0.4061 | SPLoss:6.3652 | CLSLoss:0.4344 | top1:81.3500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2800 | MainLoss:0.2119 | SPLoss:6.3691 | CLSLoss:0.4367 | top1:96.1340 | AUROC:0.9928\n",
      "Test | 39/10 | Loss:0.6826 | MainLoss:0.6146 | SPLoss:6.3691 | CLSLoss:0.4367 | top1:58.5641 | AUROC:0.9885\n",
      "\n",
      "Epoch: [201 | 1000] LR: 0.036577\n",
      "Train | 10/10 | Loss:0.4786 | MainLoss:0.4105 | SPLoss:6.3716 | CLSLoss:0.4389 | top1:81.6000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2890 | MainLoss:0.2210 | SPLoss:6.3626 | CLSLoss:0.4377 | top1:95.7726 | AUROC:0.9930\n",
      "Test | 39/10 | Loss:0.6634 | MainLoss:0.5954 | SPLoss:6.3626 | CLSLoss:0.4377 | top1:59.7564 | AUROC:0.9888\n",
      "\n",
      "Epoch: [202 | 1000] LR: 0.036542\n",
      "Train | 10/10 | Loss:0.4729 | MainLoss:0.4048 | SPLoss:6.3718 | CLSLoss:0.4404 | top1:81.7500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2841 | MainLoss:0.2159 | SPLoss:6.3753 | CLSLoss:0.4393 | top1:95.9128 | AUROC:0.9928\n",
      "Test | 39/10 | Loss:0.6749 | MainLoss:0.6067 | SPLoss:6.3753 | CLSLoss:0.4393 | top1:59.2308 | AUROC:0.9880\n",
      "\n",
      "Epoch: [203 | 1000] LR: 0.036506\n",
      "Train | 10/10 | Loss:0.4691 | MainLoss:0.4010 | SPLoss:6.3674 | CLSLoss:0.4423 | top1:81.7500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2828 | MainLoss:0.2146 | SPLoss:6.3734 | CLSLoss:0.4453 | top1:95.8629 | AUROC:0.9930\n",
      "Test | 39/10 | Loss:0.6777 | MainLoss:0.6096 | SPLoss:6.3733 | CLSLoss:0.4453 | top1:59.4744 | AUROC:0.9879\n",
      "\n",
      "Epoch: [204 | 1000] LR: 0.036471\n",
      "Train | 10/10 | Loss:0.4761 | MainLoss:0.4080 | SPLoss:6.3671 | CLSLoss:0.4437 | top1:81.3500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2884 | MainLoss:0.2203 | SPLoss:6.3641 | CLSLoss:0.4438 | top1:95.6573 | AUROC:0.9929\n",
      "Test | 39/10 | Loss:0.6677 | MainLoss:0.5996 | SPLoss:6.3640 | CLSLoss:0.4438 | top1:59.9487 | AUROC:0.9885\n",
      "\n",
      "Epoch: [205 | 1000] LR: 0.036435\n",
      "Train | 10/10 | Loss:0.4562 | MainLoss:0.3879 | SPLoss:6.3781 | CLSLoss:0.4487 | top1:82.6000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2869 | MainLoss:0.2185 | SPLoss:6.3843 | CLSLoss:0.4499 | top1:95.6449 | AUROC:0.9928\n",
      "Test | 39/10 | Loss:0.6747 | MainLoss:0.6063 | SPLoss:6.3843 | CLSLoss:0.4499 | top1:59.9359 | AUROC:0.9876\n",
      "\n",
      "Epoch: [206 | 1000] LR: 0.036399\n",
      "Train | 10/10 | Loss:0.4646 | MainLoss:0.3962 | SPLoss:6.3874 | CLSLoss:0.4519 | top1:81.9000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2882 | MainLoss:0.2198 | SPLoss:6.3826 | CLSLoss:0.4517 | top1:95.5981 | AUROC:0.9928\n",
      "Test | 39/10 | Loss:0.6732 | MainLoss:0.6049 | SPLoss:6.3826 | CLSLoss:0.4517 | top1:60.0641 | AUROC:0.9876\n",
      "\n",
      "Epoch: [207 | 1000] LR: 0.036363\n",
      "Train | 10/10 | Loss:0.4701 | MainLoss:0.4018 | SPLoss:6.3773 | CLSLoss:0.4511 | top1:81.7000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2909 | MainLoss:0.2227 | SPLoss:6.3708 | CLSLoss:0.4521 | top1:95.5109 | AUROC:0.9926\n",
      "Test | 39/10 | Loss:0.6700 | MainLoss:0.6018 | SPLoss:6.3708 | CLSLoss:0.4521 | top1:60.2692 | AUROC:0.9877\n",
      "\n",
      "Epoch: [208 | 1000] LR: 0.036327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 10/10 | Loss:0.4813 | MainLoss:0.4130 | SPLoss:6.3823 | CLSLoss:0.4513 | top1:80.8000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2791 | MainLoss:0.2107 | SPLoss:6.3861 | CLSLoss:0.4468 | top1:95.9782 | AUROC:0.9925\n",
      "Test | 39/10 | Loss:0.6926 | MainLoss:0.6242 | SPLoss:6.3861 | CLSLoss:0.4468 | top1:58.8333 | AUROC:0.9872\n",
      "\n",
      "Epoch: [209 | 1000] LR: 0.036290\n",
      "Train | 10/10 | Loss:0.4629 | MainLoss:0.3946 | SPLoss:6.3795 | CLSLoss:0.4488 | top1:81.5500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2834 | MainLoss:0.2150 | SPLoss:6.3826 | CLSLoss:0.4510 | top1:95.7632 | AUROC:0.9927\n",
      "Test | 39/10 | Loss:0.6821 | MainLoss:0.6138 | SPLoss:6.3826 | CLSLoss:0.4510 | top1:59.6923 | AUROC:0.9876\n",
      "\n",
      "Epoch: [210 | 1000] LR: 0.036254\n",
      "Train | 10/10 | Loss:0.4705 | MainLoss:0.4022 | SPLoss:6.3828 | CLSLoss:0.4495 | top1:81.9000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2805 | MainLoss:0.2121 | SPLoss:6.3826 | CLSLoss:0.4502 | top1:95.9159 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6897 | MainLoss:0.6214 | SPLoss:6.3826 | CLSLoss:0.4502 | top1:59.0641 | AUROC:0.9881\n",
      "\n",
      "Epoch: [211 | 1000] LR: 0.036217\n",
      "Train | 10/10 | Loss:0.4836 | MainLoss:0.4153 | SPLoss:6.3867 | CLSLoss:0.4467 | top1:80.8000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2835 | MainLoss:0.2153 | SPLoss:6.3766 | CLSLoss:0.4446 | top1:95.8879 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6805 | MainLoss:0.6123 | SPLoss:6.3766 | CLSLoss:0.4446 | top1:59.1667 | AUROC:0.9884\n",
      "\n",
      "Epoch: [212 | 1000] LR: 0.036180\n",
      "Train | 10/10 | Loss:0.4856 | MainLoss:0.4173 | SPLoss:6.3827 | CLSLoss:0.4431 | top1:80.2000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2809 | MainLoss:0.2124 | SPLoss:6.4078 | CLSLoss:0.4424 | top1:95.9751 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6880 | MainLoss:0.6195 | SPLoss:6.4078 | CLSLoss:0.4424 | top1:58.6026 | AUROC:0.9877\n",
      "\n",
      "Epoch: [213 | 1000] LR: 0.036143\n",
      "Train | 10/10 | Loss:0.4850 | MainLoss:0.4164 | SPLoss:6.4193 | CLSLoss:0.4404 | top1:80.4000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2812 | MainLoss:0.2126 | SPLoss:6.4198 | CLSLoss:0.4400 | top1:96.0436 | AUROC:0.9925\n",
      "Test | 39/10 | Loss:0.6862 | MainLoss:0.6176 | SPLoss:6.4198 | CLSLoss:0.4400 | top1:58.6154 | AUROC:0.9879\n",
      "\n",
      "Epoch: [214 | 1000] LR: 0.036106\n",
      "Train | 10/10 | Loss:0.4804 | MainLoss:0.4119 | SPLoss:6.4158 | CLSLoss:0.4402 | top1:80.8500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2793 | MainLoss:0.2108 | SPLoss:6.4156 | CLSLoss:0.4384 | top1:96.0623 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6899 | MainLoss:0.6213 | SPLoss:6.4156 | CLSLoss:0.4384 | top1:58.4103 | AUROC:0.9879\n",
      "\n",
      "Epoch: [215 | 1000] LR: 0.036069\n",
      "Train | 10/10 | Loss:0.4706 | MainLoss:0.4020 | SPLoss:6.4165 | CLSLoss:0.4398 | top1:82.0500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2834 | MainLoss:0.2149 | SPLoss:6.4126 | CLSLoss:0.4411 | top1:95.9003 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6819 | MainLoss:0.6134 | SPLoss:6.4125 | CLSLoss:0.4411 | top1:59.0385 | AUROC:0.9876\n",
      "\n",
      "Epoch: [216 | 1000] LR: 0.036031\n",
      "Train | 10/10 | Loss:0.4913 | MainLoss:0.4230 | SPLoss:6.3986 | CLSLoss:0.4382 | top1:80.4000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2832 | MainLoss:0.2150 | SPLoss:6.3916 | CLSLoss:0.4338 | top1:95.9377 | AUROC:0.9926\n",
      "Test | 39/10 | Loss:0.6811 | MainLoss:0.6129 | SPLoss:6.3916 | CLSLoss:0.4338 | top1:58.8462 | AUROC:0.9881\n",
      "\n",
      "Epoch: [217 | 1000] LR: 0.035994\n",
      "Train | 10/10 | Loss:0.4876 | MainLoss:0.4194 | SPLoss:6.3910 | CLSLoss:0.4346 | top1:80.6500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2849 | MainLoss:0.2167 | SPLoss:6.3902 | CLSLoss:0.4312 | top1:95.9034 | AUROC:0.9925\n",
      "Test | 39/10 | Loss:0.6768 | MainLoss:0.6086 | SPLoss:6.3902 | CLSLoss:0.4312 | top1:59.0897 | AUROC:0.9880\n",
      "\n",
      "Epoch: [218 | 1000] LR: 0.035956\n",
      "Train | 10/10 | Loss:0.4661 | MainLoss:0.3979 | SPLoss:6.3889 | CLSLoss:0.4349 | top1:81.8000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2870 | MainLoss:0.2188 | SPLoss:6.3850 | CLSLoss:0.4366 | top1:95.7103 | AUROC:0.9926\n",
      "Test | 39/10 | Loss:0.6714 | MainLoss:0.6032 | SPLoss:6.3850 | CLSLoss:0.4366 | top1:59.6410 | AUROC:0.9882\n",
      "\n",
      "Epoch: [219 | 1000] LR: 0.035918\n",
      "Train | 10/10 | Loss:0.4660 | MainLoss:0.3979 | SPLoss:6.3772 | CLSLoss:0.4384 | top1:81.8500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2889 | MainLoss:0.2207 | SPLoss:6.3792 | CLSLoss:0.4409 | top1:95.5545 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6694 | MainLoss:0.6012 | SPLoss:6.3792 | CLSLoss:0.4409 | top1:59.9103 | AUROC:0.9881\n",
      "\n",
      "Epoch: [220 | 1000] LR: 0.035880\n",
      "Train | 10/10 | Loss:0.4904 | MainLoss:0.4222 | SPLoss:6.3774 | CLSLoss:0.4401 | top1:80.8500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2852 | MainLoss:0.2171 | SPLoss:6.3794 | CLSLoss:0.4370 | top1:95.7072 | AUROC:0.9925\n",
      "Test | 39/10 | Loss:0.6761 | MainLoss:0.6080 | SPLoss:6.3794 | CLSLoss:0.4370 | top1:59.5769 | AUROC:0.9878\n",
      "\n",
      "Epoch: [221 | 1000] LR: 0.035842\n",
      "Train | 10/10 | Loss:0.4882 | MainLoss:0.4200 | SPLoss:6.3890 | CLSLoss:0.4354 | top1:80.6000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2815 | MainLoss:0.2132 | SPLoss:6.3946 | CLSLoss:0.4320 | top1:95.9377 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6855 | MainLoss:0.6172 | SPLoss:6.3946 | CLSLoss:0.4320 | top1:58.8462 | AUROC:0.9878\n",
      "\n",
      "Epoch: [222 | 1000] LR: 0.035803\n",
      "Train | 10/10 | Loss:0.4711 | MainLoss:0.4028 | SPLoss:6.3947 | CLSLoss:0.4302 | top1:81.9000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2842 | MainLoss:0.2159 | SPLoss:6.3948 | CLSLoss:0.4346 | top1:95.7259 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6805 | MainLoss:0.6122 | SPLoss:6.3948 | CLSLoss:0.4346 | top1:59.3974 | AUROC:0.9873\n",
      "\n",
      "Epoch: [223 | 1000] LR: 0.035765\n",
      "Train | 10/10 | Loss:0.4849 | MainLoss:0.4165 | SPLoss:6.4038 | CLSLoss:0.4322 | top1:80.4500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2843 | MainLoss:0.2159 | SPLoss:6.4051 | CLSLoss:0.4325 | top1:95.7882 | AUROC:0.9926\n",
      "Test | 39/10 | Loss:0.6793 | MainLoss:0.6109 | SPLoss:6.4051 | CLSLoss:0.4325 | top1:59.3205 | AUROC:0.9878\n",
      "\n",
      "Epoch: [224 | 1000] LR: 0.035726\n",
      "Train | 10/10 | Loss:0.4866 | MainLoss:0.4183 | SPLoss:6.4036 | CLSLoss:0.4313 | top1:80.4500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2846 | MainLoss:0.2163 | SPLoss:6.4034 | CLSLoss:0.4293 | top1:95.8910 | AUROC:0.9927\n",
      "Test | 39/10 | Loss:0.6791 | MainLoss:0.6108 | SPLoss:6.4034 | CLSLoss:0.4293 | top1:59.0513 | AUROC:0.9872\n",
      "\n",
      "Epoch: [225 | 1000] LR: 0.035687\n",
      "Train | 10/10 | Loss:0.4826 | MainLoss:0.4144 | SPLoss:6.3925 | CLSLoss:0.4284 | top1:80.8000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2829 | MainLoss:0.2146 | SPLoss:6.3984 | CLSLoss:0.4293 | top1:95.9688 | AUROC:0.9926\n",
      "Test | 39/10 | Loss:0.6825 | MainLoss:0.6143 | SPLoss:6.3984 | CLSLoss:0.4293 | top1:58.8718 | AUROC:0.9870\n",
      "\n",
      "Epoch: [226 | 1000] LR: 0.035648\n",
      "Train | 10/10 | Loss:0.4932 | MainLoss:0.4249 | SPLoss:6.4073 | CLSLoss:0.4275 | top1:80.0500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2794 | MainLoss:0.2110 | SPLoss:6.4124 | CLSLoss:0.4258 | top1:96.1558 | AUROC:0.9929\n",
      "Test | 39/10 | Loss:0.6902 | MainLoss:0.6218 | SPLoss:6.4124 | CLSLoss:0.4259 | top1:58.1923 | AUROC:0.9872\n",
      "\n",
      "Epoch: [227 | 1000] LR: 0.035609\n",
      "Train | 10/10 | Loss:0.4839 | MainLoss:0.4156 | SPLoss:6.4081 | CLSLoss:0.4253 | top1:80.7000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2854 | MainLoss:0.2173 | SPLoss:6.3891 | CLSLoss:0.4260 | top1:95.8941 | AUROC:0.9929\n",
      "Test | 39/10 | Loss:0.6753 | MainLoss:0.6071 | SPLoss:6.3891 | CLSLoss:0.4260 | top1:59.1026 | AUROC:0.9874\n",
      "\n",
      "Epoch: [228 | 1000] LR: 0.035569\n",
      "Train | 10/10 | Loss:0.4695 | MainLoss:0.4013 | SPLoss:6.3944 | CLSLoss:0.4296 | top1:81.3000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2832 | MainLoss:0.2149 | SPLoss:6.4066 | CLSLoss:0.4303 | top1:95.9003 | AUROC:0.9927\n",
      "Test | 39/10 | Loss:0.6828 | MainLoss:0.6145 | SPLoss:6.4066 | CLSLoss:0.4303 | top1:59.0256 | AUROC:0.9868\n",
      "\n",
      "Epoch: [229 | 1000] LR: 0.035530\n",
      "Train | 10/10 | Loss:0.4856 | MainLoss:0.4172 | SPLoss:6.4072 | CLSLoss:0.4293 | top1:80.8500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2829 | MainLoss:0.2145 | SPLoss:6.4056 | CLSLoss:0.4278 | top1:95.9688 | AUROC:0.9925\n",
      "Test | 39/10 | Loss:0.6845 | MainLoss:0.6161 | SPLoss:6.4056 | CLSLoss:0.4278 | top1:58.7436 | AUROC:0.9868\n",
      "\n",
      "Epoch: [230 | 1000] LR: 0.035490\n",
      "Train | 10/10 | Loss:0.4730 | MainLoss:0.4048 | SPLoss:6.3967 | CLSLoss:0.4290 | top1:81.3500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2852 | MainLoss:0.2170 | SPLoss:6.3913 | CLSLoss:0.4282 | top1:95.9377 | AUROC:0.9925\n",
      "Test | 39/10 | Loss:0.6784 | MainLoss:0.6102 | SPLoss:6.3913 | CLSLoss:0.4282 | top1:58.9103 | AUROC:0.9877\n",
      "\n",
      "Epoch: [231 | 1000] LR: 0.035450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 10/10 | Loss:0.4786 | MainLoss:0.4105 | SPLoss:6.3802 | CLSLoss:0.4296 | top1:80.8000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2882 | MainLoss:0.2201 | SPLoss:6.3737 | CLSLoss:0.4294 | top1:95.8069 | AUROC:0.9927\n",
      "Test | 39/10 | Loss:0.6700 | MainLoss:0.6019 | SPLoss:6.3737 | CLSLoss:0.4294 | top1:59.3333 | AUROC:0.9883\n",
      "\n",
      "Epoch: [232 | 1000] LR: 0.035410\n",
      "Train | 10/10 | Loss:0.4724 | MainLoss:0.4043 | SPLoss:6.3792 | CLSLoss:0.4310 | top1:81.5500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2832 | MainLoss:0.2150 | SPLoss:6.3856 | CLSLoss:0.4326 | top1:95.9688 | AUROC:0.9929\n",
      "Test | 39/10 | Loss:0.6790 | MainLoss:0.6109 | SPLoss:6.3856 | CLSLoss:0.4326 | top1:59.0641 | AUROC:0.9879\n",
      "\n",
      "Epoch: [233 | 1000] LR: 0.035370\n",
      "Train | 10/10 | Loss:0.4706 | MainLoss:0.4024 | SPLoss:6.3918 | CLSLoss:0.4340 | top1:81.6000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2851 | MainLoss:0.2168 | SPLoss:6.3973 | CLSLoss:0.4361 | top1:95.8380 | AUROC:0.9927\n",
      "Test | 39/10 | Loss:0.6763 | MainLoss:0.6080 | SPLoss:6.3973 | CLSLoss:0.4361 | top1:59.4744 | AUROC:0.9871\n",
      "\n",
      "Epoch: [234 | 1000] LR: 0.035330\n",
      "Train | 10/10 | Loss:0.4798 | MainLoss:0.4114 | SPLoss:6.4046 | CLSLoss:0.4363 | top1:80.7500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2784 | MainLoss:0.2097 | SPLoss:6.4294 | CLSLoss:0.4360 | top1:96.0810 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6963 | MainLoss:0.6276 | SPLoss:6.4294 | CLSLoss:0.4360 | top1:58.2436 | AUROC:0.9866\n",
      "\n",
      "Epoch: [235 | 1000] LR: 0.035289\n",
      "Train | 10/10 | Loss:0.4710 | MainLoss:0.4023 | SPLoss:6.4339 | CLSLoss:0.4345 | top1:81.4000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2792 | MainLoss:0.2105 | SPLoss:6.4327 | CLSLoss:0.4371 | top1:96.0374 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6944 | MainLoss:0.6257 | SPLoss:6.4327 | CLSLoss:0.4371 | top1:58.3718 | AUROC:0.9869\n",
      "\n",
      "Epoch: [236 | 1000] LR: 0.035249\n",
      "Train | 10/10 | Loss:0.4732 | MainLoss:0.4045 | SPLoss:6.4316 | CLSLoss:0.4379 | top1:81.3000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2789 | MainLoss:0.2102 | SPLoss:6.4333 | CLSLoss:0.4383 | top1:96.0218 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6941 | MainLoss:0.6253 | SPLoss:6.4333 | CLSLoss:0.4383 | top1:58.4872 | AUROC:0.9867\n",
      "\n",
      "Epoch: [237 | 1000] LR: 0.035208\n",
      "Train | 10/10 | Loss:0.4620 | MainLoss:0.3932 | SPLoss:6.4318 | CLSLoss:0.4392 | top1:81.9500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2823 | MainLoss:0.2136 | SPLoss:6.4244 | CLSLoss:0.4416 | top1:95.8692 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6875 | MainLoss:0.6188 | SPLoss:6.4244 | CLSLoss:0.4416 | top1:58.9744 | AUROC:0.9861\n",
      "\n",
      "Epoch: [238 | 1000] LR: 0.035167\n",
      "Train | 10/10 | Loss:0.4808 | MainLoss:0.4122 | SPLoss:6.4176 | CLSLoss:0.4415 | top1:81.0000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2867 | MainLoss:0.2181 | SPLoss:6.4115 | CLSLoss:0.4395 | top1:95.7788 | AUROC:0.9925\n",
      "Test | 39/10 | Loss:0.6766 | MainLoss:0.6081 | SPLoss:6.4115 | CLSLoss:0.4395 | top1:59.3205 | AUROC:0.9867\n",
      "\n",
      "Epoch: [239 | 1000] LR: 0.035126\n",
      "Train | 10/10 | Loss:0.4824 | MainLoss:0.4139 | SPLoss:6.4107 | CLSLoss:0.4399 | top1:80.2500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2854 | MainLoss:0.2168 | SPLoss:6.4220 | CLSLoss:0.4396 | top1:95.8131 | AUROC:0.9925\n",
      "Test | 39/10 | Loss:0.6798 | MainLoss:0.6112 | SPLoss:6.4220 | CLSLoss:0.4396 | top1:59.1795 | AUROC:0.9866\n",
      "\n",
      "Epoch: [240 | 1000] LR: 0.035085\n",
      "Train | 10/10 | Loss:0.4717 | MainLoss:0.4031 | SPLoss:6.4238 | CLSLoss:0.4379 | top1:81.1500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2787 | MainLoss:0.2099 | SPLoss:6.4410 | CLSLoss:0.4409 | top1:96.0966 | AUROC:0.9925\n",
      "Test | 39/10 | Loss:0.6949 | MainLoss:0.6261 | SPLoss:6.4410 | CLSLoss:0.4409 | top1:58.4744 | AUROC:0.9862\n",
      "\n",
      "Epoch: [241 | 1000] LR: 0.035044\n",
      "Train | 10/10 | Loss:0.4671 | MainLoss:0.3984 | SPLoss:6.4329 | CLSLoss:0.4424 | top1:81.8000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2833 | MainLoss:0.2147 | SPLoss:6.4191 | CLSLoss:0.4422 | top1:95.8816 | AUROC:0.9925\n",
      "Test | 39/10 | Loss:0.6846 | MainLoss:0.6160 | SPLoss:6.4191 | CLSLoss:0.4422 | top1:59.0769 | AUROC:0.9865\n",
      "\n",
      "Epoch: [242 | 1000] LR: 0.035002\n",
      "Train | 10/10 | Loss:0.4763 | MainLoss:0.4076 | SPLoss:6.4273 | CLSLoss:0.4428 | top1:80.7000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2812 | MainLoss:0.2125 | SPLoss:6.4301 | CLSLoss:0.4410 | top1:95.9720 | AUROC:0.9925\n",
      "Test | 39/10 | Loss:0.6879 | MainLoss:0.6192 | SPLoss:6.4301 | CLSLoss:0.4410 | top1:58.9231 | AUROC:0.9861\n",
      "\n",
      "Epoch: [243 | 1000] LR: 0.034961\n",
      "Train | 10/10 | Loss:0.4785 | MainLoss:0.4097 | SPLoss:6.4453 | CLSLoss:0.4393 | top1:80.9000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2815 | MainLoss:0.2127 | SPLoss:6.4443 | CLSLoss:0.4384 | top1:95.9408 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6876 | MainLoss:0.6188 | SPLoss:6.4443 | CLSLoss:0.4384 | top1:58.9359 | AUROC:0.9860\n",
      "\n",
      "Epoch: [244 | 1000] LR: 0.034919\n",
      "Train | 10/10 | Loss:0.4692 | MainLoss:0.4003 | SPLoss:6.4405 | CLSLoss:0.4405 | top1:81.4000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2863 | MainLoss:0.2175 | SPLoss:6.4401 | CLSLoss:0.4414 | top1:95.7196 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6798 | MainLoss:0.6110 | SPLoss:6.4401 | CLSLoss:0.4414 | top1:59.3974 | AUROC:0.9865\n",
      "\n",
      "Epoch: [245 | 1000] LR: 0.034877\n",
      "Train | 10/10 | Loss:0.4795 | MainLoss:0.4107 | SPLoss:6.4356 | CLSLoss:0.4410 | top1:81.1500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2863 | MainLoss:0.2176 | SPLoss:6.4371 | CLSLoss:0.4401 | top1:95.6604 | AUROC:0.9920\n",
      "Test | 39/10 | Loss:0.6821 | MainLoss:0.6134 | SPLoss:6.4371 | CLSLoss:0.4401 | top1:59.3462 | AUROC:0.9864\n",
      "\n",
      "Epoch: [246 | 1000] LR: 0.034835\n",
      "Train | 10/10 | Loss:0.4727 | MainLoss:0.4040 | SPLoss:6.4306 | CLSLoss:0.4390 | top1:81.6500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2818 | MainLoss:0.2130 | SPLoss:6.4411 | CLSLoss:0.4406 | top1:95.8847 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6905 | MainLoss:0.6216 | SPLoss:6.4411 | CLSLoss:0.4406 | top1:58.7436 | AUROC:0.9862\n",
      "\n",
      "Epoch: [247 | 1000] LR: 0.034793\n",
      "Train | 10/10 | Loss:0.4861 | MainLoss:0.4174 | SPLoss:6.4335 | CLSLoss:0.4395 | top1:80.4500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2862 | MainLoss:0.2175 | SPLoss:6.4340 | CLSLoss:0.4395 | top1:95.7601 | AUROC:0.9921\n",
      "Test | 39/10 | Loss:0.6810 | MainLoss:0.6123 | SPLoss:6.4340 | CLSLoss:0.4395 | top1:59.1667 | AUROC:0.9863\n",
      "\n",
      "Epoch: [248 | 1000] LR: 0.034750\n",
      "Train | 10/10 | Loss:0.4795 | MainLoss:0.4108 | SPLoss:6.4256 | CLSLoss:0.4378 | top1:81.1500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2831 | MainLoss:0.2144 | SPLoss:6.4298 | CLSLoss:0.4395 | top1:95.8069 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6868 | MainLoss:0.6181 | SPLoss:6.4298 | CLSLoss:0.4395 | top1:58.8974 | AUROC:0.9864\n",
      "\n",
      "Epoch: [249 | 1000] LR: 0.034708\n",
      "Train | 10/10 | Loss:0.4674 | MainLoss:0.3987 | SPLoss:6.4286 | CLSLoss:0.4408 | top1:81.7500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2909 | MainLoss:0.2223 | SPLoss:6.4208 | CLSLoss:0.4411 | top1:95.4860 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6711 | MainLoss:0.6025 | SPLoss:6.4208 | CLSLoss:0.4411 | top1:59.8462 | AUROC:0.9864\n",
      "\n",
      "Epoch: [250 | 1000] LR: 0.034665\n",
      "Train | 10/10 | Loss:0.4670 | MainLoss:0.3984 | SPLoss:6.4112 | CLSLoss:0.4424 | top1:81.8500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2878 | MainLoss:0.2192 | SPLoss:6.4114 | CLSLoss:0.4436 | top1:95.6293 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6772 | MainLoss:0.6086 | SPLoss:6.4114 | CLSLoss:0.4436 | top1:59.4744 | AUROC:0.9870\n",
      "\n",
      "Epoch: [251 | 1000] LR: 0.034622\n",
      "Train | 10/10 | Loss:0.4721 | MainLoss:0.4035 | SPLoss:6.4199 | CLSLoss:0.4434 | top1:81.4000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2808 | MainLoss:0.2121 | SPLoss:6.4321 | CLSLoss:0.4425 | top1:95.9875 | AUROC:0.9926\n",
      "Test | 39/10 | Loss:0.6912 | MainLoss:0.6225 | SPLoss:6.4321 | CLSLoss:0.4425 | top1:58.7308 | AUROC:0.9867\n",
      "\n",
      "Epoch: [252 | 1000] LR: 0.003458\n",
      "Train | 10/10 | Loss:0.4680 | MainLoss:0.3992 | SPLoss:6.4320 | CLSLoss:0.4427 | top1:81.7500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2805 | MainLoss:0.2117 | SPLoss:6.4326 | CLSLoss:0.4426 | top1:95.9844 | AUROC:0.9925\n",
      "Test | 39/10 | Loss:0.6920 | MainLoss:0.6232 | SPLoss:6.4326 | CLSLoss:0.4426 | top1:58.7308 | AUROC:0.9865\n",
      "\n",
      "Epoch: [253 | 1000] LR: 0.003454\n",
      "Train | 10/10 | Loss:0.4761 | MainLoss:0.4073 | SPLoss:6.4313 | CLSLoss:0.4425 | top1:80.8000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2819 | MainLoss:0.2132 | SPLoss:6.4289 | CLSLoss:0.4425 | top1:95.9284 | AUROC:0.9925\n",
      "Test | 39/10 | Loss:0.6888 | MainLoss:0.6201 | SPLoss:6.4289 | CLSLoss:0.4425 | top1:58.8077 | AUROC:0.9865\n",
      "\n",
      "Epoch: [254 | 1000] LR: 0.003449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 10/10 | Loss:0.4567 | MainLoss:0.3880 | SPLoss:6.4288 | CLSLoss:0.4427 | top1:81.9500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2818 | MainLoss:0.2131 | SPLoss:6.4276 | CLSLoss:0.4429 | top1:95.9159 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6889 | MainLoss:0.6202 | SPLoss:6.4276 | CLSLoss:0.4429 | top1:58.8462 | AUROC:0.9866\n",
      "\n",
      "Epoch: [255 | 1000] LR: 0.003445\n",
      "Train | 10/10 | Loss:0.4791 | MainLoss:0.4104 | SPLoss:6.4280 | CLSLoss:0.4426 | top1:81.2500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2816 | MainLoss:0.2129 | SPLoss:6.4288 | CLSLoss:0.4426 | top1:95.9190 | AUROC:0.9925\n",
      "Test | 39/10 | Loss:0.6894 | MainLoss:0.6207 | SPLoss:6.4288 | CLSLoss:0.4426 | top1:58.8077 | AUROC:0.9866\n",
      "\n",
      "Epoch: [256 | 1000] LR: 0.003441\n",
      "Train | 10/10 | Loss:0.4638 | MainLoss:0.3951 | SPLoss:6.4297 | CLSLoss:0.4428 | top1:82.0500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2816 | MainLoss:0.2129 | SPLoss:6.4293 | CLSLoss:0.4428 | top1:95.9097 | AUROC:0.9925\n",
      "Test | 39/10 | Loss:0.6896 | MainLoss:0.6208 | SPLoss:6.4293 | CLSLoss:0.4428 | top1:58.8077 | AUROC:0.9864\n",
      "\n",
      "Epoch: [257 | 1000] LR: 0.003436\n",
      "Train | 10/10 | Loss:0.4791 | MainLoss:0.4104 | SPLoss:6.4279 | CLSLoss:0.4427 | top1:81.0000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2831 | MainLoss:0.2144 | SPLoss:6.4264 | CLSLoss:0.4427 | top1:95.8785 | AUROC:0.9925\n",
      "Test | 39/10 | Loss:0.6863 | MainLoss:0.6176 | SPLoss:6.4264 | CLSLoss:0.4427 | top1:58.9872 | AUROC:0.9868\n",
      "\n",
      "Epoch: [258 | 1000] LR: 0.003432\n",
      "Train | 10/10 | Loss:0.4833 | MainLoss:0.4146 | SPLoss:6.4271 | CLSLoss:0.4424 | top1:80.3500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2827 | MainLoss:0.2140 | SPLoss:6.4274 | CLSLoss:0.4422 | top1:95.8941 | AUROC:0.9925\n",
      "Test | 39/10 | Loss:0.6870 | MainLoss:0.6183 | SPLoss:6.4274 | CLSLoss:0.4422 | top1:58.9103 | AUROC:0.9865\n",
      "\n",
      "Epoch: [259 | 1000] LR: 0.003427\n",
      "Train | 10/10 | Loss:0.4871 | MainLoss:0.4185 | SPLoss:6.4259 | CLSLoss:0.4421 | top1:80.0500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2827 | MainLoss:0.2140 | SPLoss:6.4253 | CLSLoss:0.4417 | top1:95.8941 | AUROC:0.9925\n",
      "Test | 39/10 | Loss:0.6870 | MainLoss:0.6183 | SPLoss:6.4253 | CLSLoss:0.4417 | top1:58.8974 | AUROC:0.9866\n",
      "\n",
      "Epoch: [260 | 1000] LR: 0.003423\n",
      "Train | 10/10 | Loss:0.4742 | MainLoss:0.4055 | SPLoss:6.4257 | CLSLoss:0.4416 | top1:81.4500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2827 | MainLoss:0.2140 | SPLoss:6.4262 | CLSLoss:0.4415 | top1:95.8972 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6870 | MainLoss:0.6183 | SPLoss:6.4261 | CLSLoss:0.4415 | top1:58.8846 | AUROC:0.9867\n",
      "\n",
      "Epoch: [261 | 1000] LR: 0.003419\n",
      "Train | 10/10 | Loss:0.4826 | MainLoss:0.4139 | SPLoss:6.4262 | CLSLoss:0.4413 | top1:81.0500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2827 | MainLoss:0.2140 | SPLoss:6.4254 | CLSLoss:0.4410 | top1:95.9003 | AUROC:0.9925\n",
      "Test | 39/10 | Loss:0.6870 | MainLoss:0.6183 | SPLoss:6.4254 | CLSLoss:0.4410 | top1:58.9103 | AUROC:0.9865\n",
      "\n",
      "Epoch: [262 | 1000] LR: 0.003414\n",
      "Train | 10/10 | Loss:0.4641 | MainLoss:0.3954 | SPLoss:6.4250 | CLSLoss:0.4412 | top1:82.0500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2824 | MainLoss:0.2137 | SPLoss:6.4252 | CLSLoss:0.4411 | top1:95.9034 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6876 | MainLoss:0.6189 | SPLoss:6.4252 | CLSLoss:0.4411 | top1:58.8974 | AUROC:0.9867\n",
      "\n",
      "Epoch: [263 | 1000] LR: 0.003410\n",
      "Train | 10/10 | Loss:0.4802 | MainLoss:0.4115 | SPLoss:6.4260 | CLSLoss:0.4408 | top1:81.2500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2817 | MainLoss:0.2130 | SPLoss:6.4263 | CLSLoss:0.4405 | top1:95.9065 | AUROC:0.9925\n",
      "Test | 39/10 | Loss:0.6892 | MainLoss:0.6205 | SPLoss:6.4263 | CLSLoss:0.4405 | top1:58.7692 | AUROC:0.9868\n",
      "\n",
      "Epoch: [264 | 1000] LR: 0.003405\n",
      "Train | 10/10 | Loss:0.4776 | MainLoss:0.4089 | SPLoss:6.4252 | CLSLoss:0.4402 | top1:80.4500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2822 | MainLoss:0.2135 | SPLoss:6.4246 | CLSLoss:0.4403 | top1:95.8941 | AUROC:0.9926\n",
      "Test | 39/10 | Loss:0.6879 | MainLoss:0.6193 | SPLoss:6.4246 | CLSLoss:0.4403 | top1:58.8462 | AUROC:0.9867\n",
      "\n",
      "Epoch: [265 | 1000] LR: 0.003401\n",
      "Train | 10/10 | Loss:0.4755 | MainLoss:0.4069 | SPLoss:6.4244 | CLSLoss:0.4401 | top1:80.8500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2819 | MainLoss:0.2133 | SPLoss:6.4248 | CLSLoss:0.4401 | top1:95.8972 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6887 | MainLoss:0.6200 | SPLoss:6.4248 | CLSLoss:0.4401 | top1:58.7692 | AUROC:0.9868\n",
      "\n",
      "Epoch: [266 | 1000] LR: 0.003396\n",
      "Train | 10/10 | Loss:0.4803 | MainLoss:0.4116 | SPLoss:6.4242 | CLSLoss:0.4401 | top1:80.6500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2818 | MainLoss:0.2131 | SPLoss:6.4244 | CLSLoss:0.4400 | top1:95.9221 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6890 | MainLoss:0.6204 | SPLoss:6.4244 | CLSLoss:0.4400 | top1:58.7949 | AUROC:0.9865\n",
      "\n",
      "Epoch: [267 | 1000] LR: 0.003392\n",
      "Train | 10/10 | Loss:0.4647 | MainLoss:0.3961 | SPLoss:6.4236 | CLSLoss:0.4400 | top1:81.6500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2825 | MainLoss:0.2139 | SPLoss:6.4226 | CLSLoss:0.4402 | top1:95.9003 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6874 | MainLoss:0.6187 | SPLoss:6.4226 | CLSLoss:0.4402 | top1:58.8462 | AUROC:0.9866\n",
      "\n",
      "Epoch: [268 | 1000] LR: 0.003387\n",
      "Train | 10/10 | Loss:0.4712 | MainLoss:0.4026 | SPLoss:6.4225 | CLSLoss:0.4403 | top1:81.5000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2827 | MainLoss:0.2141 | SPLoss:6.4209 | CLSLoss:0.4402 | top1:95.8972 | AUROC:0.9925\n",
      "Test | 39/10 | Loss:0.6869 | MainLoss:0.6183 | SPLoss:6.4209 | CLSLoss:0.4402 | top1:58.8974 | AUROC:0.9868\n",
      "\n",
      "Epoch: [269 | 1000] LR: 0.003383\n",
      "Train | 10/10 | Loss:0.4810 | MainLoss:0.4123 | SPLoss:6.4223 | CLSLoss:0.4402 | top1:80.6000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2823 | MainLoss:0.2137 | SPLoss:6.4231 | CLSLoss:0.4400 | top1:95.8972 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6878 | MainLoss:0.6192 | SPLoss:6.4232 | CLSLoss:0.4400 | top1:58.8077 | AUROC:0.9865\n",
      "\n",
      "Epoch: [270 | 1000] LR: 0.003378\n",
      "Train | 10/10 | Loss:0.4732 | MainLoss:0.4046 | SPLoss:6.4225 | CLSLoss:0.4400 | top1:80.8000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2823 | MainLoss:0.2137 | SPLoss:6.4224 | CLSLoss:0.4399 | top1:95.9159 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6877 | MainLoss:0.6191 | SPLoss:6.4224 | CLSLoss:0.4399 | top1:58.8205 | AUROC:0.9865\n",
      "\n",
      "Epoch: [271 | 1000] LR: 0.003374\n",
      "Train | 10/10 | Loss:0.4635 | MainLoss:0.3949 | SPLoss:6.4217 | CLSLoss:0.4400 | top1:82.0500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2828 | MainLoss:0.2142 | SPLoss:6.4212 | CLSLoss:0.4403 | top1:95.8941 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6868 | MainLoss:0.6181 | SPLoss:6.4212 | CLSLoss:0.4403 | top1:58.9103 | AUROC:0.9866\n",
      "\n",
      "Epoch: [272 | 1000] LR: 0.003369\n",
      "Train | 10/10 | Loss:0.4738 | MainLoss:0.4052 | SPLoss:6.4200 | CLSLoss:0.4401 | top1:81.4000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2827 | MainLoss:0.2141 | SPLoss:6.4196 | CLSLoss:0.4401 | top1:95.9003 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6870 | MainLoss:0.6184 | SPLoss:6.4196 | CLSLoss:0.4401 | top1:58.8718 | AUROC:0.9865\n",
      "\n",
      "Epoch: [273 | 1000] LR: 0.003365\n",
      "Train | 10/10 | Loss:0.4757 | MainLoss:0.4071 | SPLoss:6.4191 | CLSLoss:0.4399 | top1:81.4500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2828 | MainLoss:0.2142 | SPLoss:6.4183 | CLSLoss:0.4400 | top1:95.9003 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6866 | MainLoss:0.6180 | SPLoss:6.4183 | CLSLoss:0.4400 | top1:58.8974 | AUROC:0.9867\n",
      "\n",
      "Epoch: [274 | 1000] LR: 0.003360\n",
      "Train | 10/10 | Loss:0.4735 | MainLoss:0.4049 | SPLoss:6.4188 | CLSLoss:0.4400 | top1:80.9500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2828 | MainLoss:0.2142 | SPLoss:6.4183 | CLSLoss:0.4400 | top1:95.8941 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6864 | MainLoss:0.6179 | SPLoss:6.4183 | CLSLoss:0.4400 | top1:58.9231 | AUROC:0.9869\n",
      "\n",
      "Epoch: [275 | 1000] LR: 0.003355\n",
      "Train | 10/10 | Loss:0.4751 | MainLoss:0.4065 | SPLoss:6.4191 | CLSLoss:0.4401 | top1:81.0000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2825 | MainLoss:0.2139 | SPLoss:6.4205 | CLSLoss:0.4400 | top1:95.8972 | AUROC:0.9925\n",
      "Test | 39/10 | Loss:0.6872 | MainLoss:0.6186 | SPLoss:6.4204 | CLSLoss:0.4400 | top1:58.8718 | AUROC:0.9867\n",
      "\n",
      "Epoch: [276 | 1000] LR: 0.003351\n",
      "Train | 10/10 | Loss:0.4848 | MainLoss:0.4162 | SPLoss:6.4217 | CLSLoss:0.4397 | top1:81.2500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2830 | MainLoss:0.2144 | SPLoss:6.4211 | CLSLoss:0.4396 | top1:95.8785 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6864 | MainLoss:0.6178 | SPLoss:6.4211 | CLSLoss:0.4396 | top1:58.8846 | AUROC:0.9868\n",
      "\n",
      "Epoch: [277 | 1000] LR: 0.003346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 10/10 | Loss:0.4784 | MainLoss:0.4098 | SPLoss:6.4212 | CLSLoss:0.4395 | top1:80.8500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2831 | MainLoss:0.2144 | SPLoss:6.4216 | CLSLoss:0.4394 | top1:95.8785 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6863 | MainLoss:0.6177 | SPLoss:6.4216 | CLSLoss:0.4394 | top1:58.8718 | AUROC:0.9868\n",
      "\n",
      "Epoch: [278 | 1000] LR: 0.003341\n",
      "Train | 10/10 | Loss:0.4787 | MainLoss:0.4100 | SPLoss:6.4213 | CLSLoss:0.4396 | top1:81.1500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2828 | MainLoss:0.2142 | SPLoss:6.4206 | CLSLoss:0.4392 | top1:95.8847 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6866 | MainLoss:0.6180 | SPLoss:6.4207 | CLSLoss:0.4392 | top1:58.8462 | AUROC:0.9869\n",
      "\n",
      "Epoch: [279 | 1000] LR: 0.003337\n",
      "Train | 10/10 | Loss:0.4656 | MainLoss:0.3970 | SPLoss:6.4201 | CLSLoss:0.4391 | top1:81.6000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2833 | MainLoss:0.2147 | SPLoss:6.4199 | CLSLoss:0.4394 | top1:95.8910 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6855 | MainLoss:0.6169 | SPLoss:6.4199 | CLSLoss:0.4394 | top1:58.9487 | AUROC:0.9868\n",
      "\n",
      "Epoch: [280 | 1000] LR: 0.003332\n",
      "Train | 10/10 | Loss:0.4661 | MainLoss:0.3975 | SPLoss:6.4209 | CLSLoss:0.4395 | top1:81.8500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2824 | MainLoss:0.2138 | SPLoss:6.4218 | CLSLoss:0.4395 | top1:95.9097 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6874 | MainLoss:0.6188 | SPLoss:6.4218 | CLSLoss:0.4395 | top1:58.8077 | AUROC:0.9867\n",
      "\n",
      "Epoch: [281 | 1000] LR: 0.003327\n",
      "Train | 10/10 | Loss:0.4699 | MainLoss:0.4014 | SPLoss:6.4198 | CLSLoss:0.4395 | top1:81.3000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2834 | MainLoss:0.2149 | SPLoss:6.4196 | CLSLoss:0.4398 | top1:95.8879 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6850 | MainLoss:0.6165 | SPLoss:6.4196 | CLSLoss:0.4398 | top1:58.9615 | AUROC:0.9870\n",
      "\n",
      "Epoch: [282 | 1000] LR: 0.003323\n",
      "Train | 10/10 | Loss:0.4738 | MainLoss:0.4052 | SPLoss:6.4190 | CLSLoss:0.4398 | top1:80.7000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2835 | MainLoss:0.2149 | SPLoss:6.4195 | CLSLoss:0.4397 | top1:95.8910 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6850 | MainLoss:0.6164 | SPLoss:6.4195 | CLSLoss:0.4397 | top1:58.9615 | AUROC:0.9868\n",
      "\n",
      "Epoch: [283 | 1000] LR: 0.003318\n",
      "Train | 10/10 | Loss:0.4790 | MainLoss:0.4104 | SPLoss:6.4195 | CLSLoss:0.4397 | top1:81.0000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2835 | MainLoss:0.2149 | SPLoss:6.4188 | CLSLoss:0.4397 | top1:95.8816 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6848 | MainLoss:0.6162 | SPLoss:6.4188 | CLSLoss:0.4397 | top1:58.9872 | AUROC:0.9870\n",
      "\n",
      "Epoch: [284 | 1000] LR: 0.003313\n",
      "Train | 10/10 | Loss:0.4848 | MainLoss:0.4162 | SPLoss:6.4199 | CLSLoss:0.4397 | top1:80.6000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2829 | MainLoss:0.2143 | SPLoss:6.4185 | CLSLoss:0.4393 | top1:95.9003 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6859 | MainLoss:0.6173 | SPLoss:6.4185 | CLSLoss:0.4393 | top1:58.8846 | AUROC:0.9871\n",
      "\n",
      "Epoch: [285 | 1000] LR: 0.003308\n",
      "Train | 10/10 | Loss:0.4731 | MainLoss:0.4045 | SPLoss:6.4191 | CLSLoss:0.4393 | top1:81.3000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2827 | MainLoss:0.2141 | SPLoss:6.4180 | CLSLoss:0.4393 | top1:95.9003 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6862 | MainLoss:0.6177 | SPLoss:6.4180 | CLSLoss:0.4393 | top1:58.8333 | AUROC:0.9868\n",
      "\n",
      "Epoch: [286 | 1000] LR: 0.003304\n",
      "Train | 10/10 | Loss:0.4711 | MainLoss:0.4025 | SPLoss:6.4177 | CLSLoss:0.4390 | top1:81.5000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2823 | MainLoss:0.2137 | SPLoss:6.4183 | CLSLoss:0.4392 | top1:95.9159 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6871 | MainLoss:0.6186 | SPLoss:6.4183 | CLSLoss:0.4392 | top1:58.7949 | AUROC:0.9867\n",
      "\n",
      "Epoch: [287 | 1000] LR: 0.003299\n",
      "Train | 10/10 | Loss:0.4785 | MainLoss:0.4100 | SPLoss:6.4178 | CLSLoss:0.4393 | top1:80.9500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2826 | MainLoss:0.2140 | SPLoss:6.4184 | CLSLoss:0.4392 | top1:95.9003 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6865 | MainLoss:0.6179 | SPLoss:6.4184 | CLSLoss:0.4392 | top1:58.8462 | AUROC:0.9870\n",
      "\n",
      "Epoch: [288 | 1000] LR: 0.003294\n",
      "Train | 10/10 | Loss:0.4701 | MainLoss:0.4015 | SPLoss:6.4177 | CLSLoss:0.4392 | top1:81.6000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2829 | MainLoss:0.2143 | SPLoss:6.4175 | CLSLoss:0.4393 | top1:95.8972 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6858 | MainLoss:0.6173 | SPLoss:6.4175 | CLSLoss:0.4393 | top1:58.8718 | AUROC:0.9870\n",
      "\n",
      "Epoch: [289 | 1000] LR: 0.003289\n",
      "Train | 10/10 | Loss:0.4802 | MainLoss:0.4117 | SPLoss:6.4174 | CLSLoss:0.4392 | top1:81.1000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2834 | MainLoss:0.2148 | SPLoss:6.4175 | CLSLoss:0.4390 | top1:95.8910 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6849 | MainLoss:0.6163 | SPLoss:6.4175 | CLSLoss:0.4390 | top1:58.9359 | AUROC:0.9867\n",
      "\n",
      "Epoch: [290 | 1000] LR: 0.003285\n",
      "Train | 10/10 | Loss:0.4713 | MainLoss:0.4027 | SPLoss:6.4173 | CLSLoss:0.4390 | top1:82.3500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2835 | MainLoss:0.2150 | SPLoss:6.4157 | CLSLoss:0.4389 | top1:95.8785 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6844 | MainLoss:0.6158 | SPLoss:6.4157 | CLSLoss:0.4389 | top1:58.9615 | AUROC:0.9869\n",
      "\n",
      "Epoch: [291 | 1000] LR: 0.003280\n",
      "Train | 10/10 | Loss:0.4695 | MainLoss:0.4009 | SPLoss:6.4147 | CLSLoss:0.4390 | top1:81.9500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2844 | MainLoss:0.2159 | SPLoss:6.4138 | CLSLoss:0.4390 | top1:95.8474 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6825 | MainLoss:0.6140 | SPLoss:6.4138 | CLSLoss:0.4390 | top1:59.1154 | AUROC:0.9869\n",
      "\n",
      "Epoch: [292 | 1000] LR: 0.003275\n",
      "Train | 10/10 | Loss:0.4689 | MainLoss:0.4003 | SPLoss:6.4129 | CLSLoss:0.4391 | top1:81.1500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2846 | MainLoss:0.2161 | SPLoss:6.4130 | CLSLoss:0.4391 | top1:95.8318 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6822 | MainLoss:0.6137 | SPLoss:6.4130 | CLSLoss:0.4391 | top1:59.1154 | AUROC:0.9871\n",
      "\n",
      "Epoch: [293 | 1000] LR: 0.003270\n",
      "Train | 10/10 | Loss:0.4702 | MainLoss:0.4016 | SPLoss:6.4123 | CLSLoss:0.4391 | top1:81.8000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2846 | MainLoss:0.2160 | SPLoss:6.4121 | CLSLoss:0.4391 | top1:95.8349 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6823 | MainLoss:0.6138 | SPLoss:6.4121 | CLSLoss:0.4391 | top1:59.1154 | AUROC:0.9870\n",
      "\n",
      "Epoch: [294 | 1000] LR: 0.003265\n",
      "Train | 10/10 | Loss:0.4805 | MainLoss:0.4120 | SPLoss:6.4122 | CLSLoss:0.4392 | top1:80.4000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2840 | MainLoss:0.2154 | SPLoss:6.4130 | CLSLoss:0.4393 | top1:95.8598 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6832 | MainLoss:0.6147 | SPLoss:6.4130 | CLSLoss:0.4393 | top1:59.0897 | AUROC:0.9869\n",
      "\n",
      "Epoch: [295 | 1000] LR: 0.003260\n",
      "Train | 10/10 | Loss:0.4749 | MainLoss:0.4064 | SPLoss:6.4141 | CLSLoss:0.4393 | top1:81.0000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2838 | MainLoss:0.2153 | SPLoss:6.4138 | CLSLoss:0.4393 | top1:95.8785 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6835 | MainLoss:0.6150 | SPLoss:6.4138 | CLSLoss:0.4393 | top1:59.0641 | AUROC:0.9869\n",
      "\n",
      "Epoch: [296 | 1000] LR: 0.003255\n",
      "Train | 10/10 | Loss:0.4769 | MainLoss:0.4083 | SPLoss:6.4138 | CLSLoss:0.4394 | top1:81.1000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2837 | MainLoss:0.2152 | SPLoss:6.4132 | CLSLoss:0.4390 | top1:95.8754 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6837 | MainLoss:0.6152 | SPLoss:6.4132 | CLSLoss:0.4390 | top1:59.0128 | AUROC:0.9869\n",
      "\n",
      "Epoch: [297 | 1000] LR: 0.003250\n",
      "Train | 10/10 | Loss:0.4742 | MainLoss:0.4057 | SPLoss:6.4127 | CLSLoss:0.4390 | top1:81.4000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2839 | MainLoss:0.2154 | SPLoss:6.4136 | CLSLoss:0.4390 | top1:95.8474 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6834 | MainLoss:0.6148 | SPLoss:6.4136 | CLSLoss:0.4390 | top1:59.0256 | AUROC:0.9871\n",
      "\n",
      "Epoch: [298 | 1000] LR: 0.003246\n",
      "Train | 10/10 | Loss:0.4568 | MainLoss:0.3883 | SPLoss:6.4131 | CLSLoss:0.4394 | top1:82.2500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2841 | MainLoss:0.2156 | SPLoss:6.4138 | CLSLoss:0.4396 | top1:95.8380 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6829 | MainLoss:0.6144 | SPLoss:6.4138 | CLSLoss:0.4396 | top1:59.1154 | AUROC:0.9868\n",
      "\n",
      "Epoch: [299 | 1000] LR: 0.003241\n",
      "Train | 10/10 | Loss:0.4827 | MainLoss:0.4141 | SPLoss:6.4132 | CLSLoss:0.4395 | top1:80.7000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2842 | MainLoss:0.2157 | SPLoss:6.4129 | CLSLoss:0.4394 | top1:95.8318 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6824 | MainLoss:0.6139 | SPLoss:6.4129 | CLSLoss:0.4394 | top1:59.1282 | AUROC:0.9870\n",
      "\n",
      "Epoch: [300 | 1000] LR: 0.003236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 10/10 | Loss:0.4724 | MainLoss:0.4038 | SPLoss:6.4134 | CLSLoss:0.4395 | top1:81.8500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2836 | MainLoss:0.2151 | SPLoss:6.4147 | CLSLoss:0.4395 | top1:95.8692 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6838 | MainLoss:0.6153 | SPLoss:6.4147 | CLSLoss:0.4395 | top1:59.0385 | AUROC:0.9868\n",
      "\n",
      "Epoch: [301 | 1000] LR: 0.003231\n",
      "Train | 10/10 | Loss:0.4787 | MainLoss:0.4102 | SPLoss:6.4144 | CLSLoss:0.4395 | top1:81.1500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2833 | MainLoss:0.2147 | SPLoss:6.4145 | CLSLoss:0.4392 | top1:95.8941 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6845 | MainLoss:0.6160 | SPLoss:6.4145 | CLSLoss:0.4392 | top1:59.0128 | AUROC:0.9869\n",
      "\n",
      "Epoch: [302 | 1000] LR: 0.003226\n",
      "Train | 10/10 | Loss:0.4530 | MainLoss:0.3844 | SPLoss:6.4148 | CLSLoss:0.4396 | top1:83.3000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2838 | MainLoss:0.2152 | SPLoss:6.4135 | CLSLoss:0.4398 | top1:95.8536 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6836 | MainLoss:0.6150 | SPLoss:6.4135 | CLSLoss:0.4398 | top1:59.1154 | AUROC:0.9870\n",
      "\n",
      "Epoch: [303 | 1000] LR: 0.003221\n",
      "Train | 10/10 | Loss:0.4741 | MainLoss:0.4056 | SPLoss:6.4120 | CLSLoss:0.4399 | top1:81.2000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2846 | MainLoss:0.2161 | SPLoss:6.4110 | CLSLoss:0.4398 | top1:95.7975 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6815 | MainLoss:0.6130 | SPLoss:6.4110 | CLSLoss:0.4398 | top1:59.2564 | AUROC:0.9867\n",
      "\n",
      "Epoch: [304 | 1000] LR: 0.003216\n",
      "Train | 10/10 | Loss:0.4798 | MainLoss:0.4113 | SPLoss:6.4101 | CLSLoss:0.4398 | top1:80.5000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2847 | MainLoss:0.2162 | SPLoss:6.4098 | CLSLoss:0.4397 | top1:95.8006 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6812 | MainLoss:0.6127 | SPLoss:6.4098 | CLSLoss:0.4397 | top1:59.2564 | AUROC:0.9867\n",
      "\n",
      "Epoch: [305 | 1000] LR: 0.003211\n",
      "Train | 10/10 | Loss:0.4781 | MainLoss:0.4096 | SPLoss:6.4102 | CLSLoss:0.4396 | top1:81.3500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2850 | MainLoss:0.2165 | SPLoss:6.4110 | CLSLoss:0.4397 | top1:95.7819 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6805 | MainLoss:0.6120 | SPLoss:6.4110 | CLSLoss:0.4397 | top1:59.2692 | AUROC:0.9871\n",
      "\n",
      "Epoch: [306 | 1000] LR: 0.003206\n",
      "Train | 10/10 | Loss:0.4745 | MainLoss:0.4060 | SPLoss:6.4110 | CLSLoss:0.4398 | top1:80.9500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2855 | MainLoss:0.2170 | SPLoss:6.4097 | CLSLoss:0.4398 | top1:95.7570 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6794 | MainLoss:0.6109 | SPLoss:6.4097 | CLSLoss:0.4398 | top1:59.3077 | AUROC:0.9871\n",
      "\n",
      "Epoch: [307 | 1000] LR: 0.003201\n",
      "Train | 10/10 | Loss:0.4775 | MainLoss:0.4090 | SPLoss:6.4100 | CLSLoss:0.4398 | top1:80.7500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2848 | MainLoss:0.2163 | SPLoss:6.4097 | CLSLoss:0.4395 | top1:95.7882 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6807 | MainLoss:0.6123 | SPLoss:6.4097 | CLSLoss:0.4395 | top1:59.3077 | AUROC:0.9873\n",
      "\n",
      "Epoch: [308 | 1000] LR: 0.003196\n",
      "Train | 10/10 | Loss:0.4766 | MainLoss:0.4081 | SPLoss:6.4102 | CLSLoss:0.4396 | top1:81.5500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2847 | MainLoss:0.2162 | SPLoss:6.4094 | CLSLoss:0.4394 | top1:95.7944 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6808 | MainLoss:0.6124 | SPLoss:6.4093 | CLSLoss:0.4394 | top1:59.2820 | AUROC:0.9870\n",
      "\n",
      "Epoch: [309 | 1000] LR: 0.003191\n",
      "Train | 10/10 | Loss:0.4752 | MainLoss:0.4067 | SPLoss:6.4104 | CLSLoss:0.4393 | top1:81.2500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2841 | MainLoss:0.2156 | SPLoss:6.4103 | CLSLoss:0.4392 | top1:95.8380 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6821 | MainLoss:0.6136 | SPLoss:6.4103 | CLSLoss:0.4392 | top1:59.1410 | AUROC:0.9870\n",
      "\n",
      "Epoch: [310 | 1000] LR: 0.003186\n",
      "Train | 10/10 | Loss:0.4625 | MainLoss:0.3940 | SPLoss:6.4098 | CLSLoss:0.4394 | top1:82.1000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2846 | MainLoss:0.2162 | SPLoss:6.4090 | CLSLoss:0.4396 | top1:95.7975 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6810 | MainLoss:0.6125 | SPLoss:6.4090 | CLSLoss:0.4396 | top1:59.2308 | AUROC:0.9870\n",
      "\n",
      "Epoch: [311 | 1000] LR: 0.003181\n",
      "Train | 10/10 | Loss:0.4677 | MainLoss:0.3993 | SPLoss:6.4085 | CLSLoss:0.4395 | top1:81.3500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2847 | MainLoss:0.2162 | SPLoss:6.4074 | CLSLoss:0.4397 | top1:95.7975 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6808 | MainLoss:0.6123 | SPLoss:6.4074 | CLSLoss:0.4397 | top1:59.2436 | AUROC:0.9870\n",
      "\n",
      "Epoch: [312 | 1000] LR: 0.003176\n",
      "Train | 10/10 | Loss:0.4683 | MainLoss:0.3998 | SPLoss:6.4081 | CLSLoss:0.4399 | top1:81.5000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2848 | MainLoss:0.2164 | SPLoss:6.4085 | CLSLoss:0.4398 | top1:95.7850 | AUROC:0.9925\n",
      "Test | 39/10 | Loss:0.6806 | MainLoss:0.6121 | SPLoss:6.4085 | CLSLoss:0.4398 | top1:59.2564 | AUROC:0.9872\n",
      "\n",
      "Epoch: [313 | 1000] LR: 0.003170\n",
      "Train | 10/10 | Loss:0.4675 | MainLoss:0.3990 | SPLoss:6.4086 | CLSLoss:0.4398 | top1:82.0000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2844 | MainLoss:0.2159 | SPLoss:6.4094 | CLSLoss:0.4399 | top1:95.8069 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6815 | MainLoss:0.6130 | SPLoss:6.4094 | CLSLoss:0.4399 | top1:59.1923 | AUROC:0.9869\n",
      "\n",
      "Epoch: [314 | 1000] LR: 0.003165\n",
      "Train | 10/10 | Loss:0.4661 | MainLoss:0.3976 | SPLoss:6.4097 | CLSLoss:0.4402 | top1:81.8500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2844 | MainLoss:0.2159 | SPLoss:6.4099 | CLSLoss:0.4402 | top1:95.8100 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6816 | MainLoss:0.6131 | SPLoss:6.4099 | CLSLoss:0.4402 | top1:59.1923 | AUROC:0.9870\n",
      "\n",
      "Epoch: [315 | 1000] LR: 0.003160\n",
      "Train | 10/10 | Loss:0.4797 | MainLoss:0.4111 | SPLoss:6.4107 | CLSLoss:0.4401 | top1:80.7000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2837 | MainLoss:0.2152 | SPLoss:6.4117 | CLSLoss:0.4400 | top1:95.8692 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6832 | MainLoss:0.6147 | SPLoss:6.4117 | CLSLoss:0.4400 | top1:59.1282 | AUROC:0.9868\n",
      "\n",
      "Epoch: [316 | 1000] LR: 0.003155\n",
      "Train | 10/10 | Loss:0.4766 | MainLoss:0.4081 | SPLoss:6.4110 | CLSLoss:0.4398 | top1:81.1500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2837 | MainLoss:0.2152 | SPLoss:6.4106 | CLSLoss:0.4400 | top1:95.8723 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6831 | MainLoss:0.6146 | SPLoss:6.4106 | CLSLoss:0.4400 | top1:59.1410 | AUROC:0.9869\n",
      "\n",
      "Epoch: [317 | 1000] LR: 0.003150\n",
      "Train | 10/10 | Loss:0.4749 | MainLoss:0.4064 | SPLoss:6.4107 | CLSLoss:0.4399 | top1:80.9500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2832 | MainLoss:0.2147 | SPLoss:6.4119 | CLSLoss:0.4397 | top1:95.8910 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6843 | MainLoss:0.6157 | SPLoss:6.4119 | CLSLoss:0.4397 | top1:59.0256 | AUROC:0.9870\n",
      "\n",
      "Epoch: [318 | 1000] LR: 0.003145\n",
      "Train | 10/10 | Loss:0.4779 | MainLoss:0.4094 | SPLoss:6.4102 | CLSLoss:0.4395 | top1:81.0000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2838 | MainLoss:0.2153 | SPLoss:6.4089 | CLSLoss:0.4396 | top1:95.8598 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6830 | MainLoss:0.6145 | SPLoss:6.4089 | CLSLoss:0.4396 | top1:59.1410 | AUROC:0.9870\n",
      "\n",
      "Epoch: [319 | 1000] LR: 0.003140\n",
      "Train | 10/10 | Loss:0.4859 | MainLoss:0.4174 | SPLoss:6.4085 | CLSLoss:0.4395 | top1:79.8500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2841 | MainLoss:0.2156 | SPLoss:6.4078 | CLSLoss:0.4394 | top1:95.8474 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6823 | MainLoss:0.6139 | SPLoss:6.4078 | CLSLoss:0.4394 | top1:59.1795 | AUROC:0.9871\n",
      "\n",
      "Epoch: [320 | 1000] LR: 0.003135\n",
      "Train | 10/10 | Loss:0.4710 | MainLoss:0.4025 | SPLoss:6.4082 | CLSLoss:0.4394 | top1:81.2500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2839 | MainLoss:0.2154 | SPLoss:6.4081 | CLSLoss:0.4396 | top1:95.8474 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6828 | MainLoss:0.6143 | SPLoss:6.4081 | CLSLoss:0.4396 | top1:59.1538 | AUROC:0.9868\n",
      "\n",
      "Epoch: [321 | 1000] LR: 0.003129\n",
      "Train | 10/10 | Loss:0.4688 | MainLoss:0.4003 | SPLoss:6.4073 | CLSLoss:0.4396 | top1:82.2000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2841 | MainLoss:0.2156 | SPLoss:6.4074 | CLSLoss:0.4398 | top1:95.8287 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6823 | MainLoss:0.6138 | SPLoss:6.4074 | CLSLoss:0.4398 | top1:59.1923 | AUROC:0.9872\n",
      "\n",
      "Epoch: [322 | 1000] LR: 0.003124\n",
      "Train | 10/10 | Loss:0.4646 | MainLoss:0.3962 | SPLoss:6.4076 | CLSLoss:0.4400 | top1:81.7000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2837 | MainLoss:0.2152 | SPLoss:6.4081 | CLSLoss:0.4401 | top1:95.8692 | AUROC:0.9925\n",
      "Test | 39/10 | Loss:0.6831 | MainLoss:0.6146 | SPLoss:6.4081 | CLSLoss:0.4401 | top1:59.1282 | AUROC:0.9871\n",
      "\n",
      "Epoch: [323 | 1000] LR: 0.003119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 10/10 | Loss:0.4783 | MainLoss:0.4098 | SPLoss:6.4079 | CLSLoss:0.4398 | top1:80.7500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2842 | MainLoss:0.2157 | SPLoss:6.4076 | CLSLoss:0.4400 | top1:95.8224 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6819 | MainLoss:0.6134 | SPLoss:6.4076 | CLSLoss:0.4400 | top1:59.2179 | AUROC:0.9870\n",
      "\n",
      "Epoch: [324 | 1000] LR: 0.003114\n",
      "Train | 10/10 | Loss:0.4652 | MainLoss:0.3967 | SPLoss:6.4075 | CLSLoss:0.4401 | top1:81.7500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2840 | MainLoss:0.2156 | SPLoss:6.4078 | CLSLoss:0.4402 | top1:95.8318 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6822 | MainLoss:0.6137 | SPLoss:6.4078 | CLSLoss:0.4402 | top1:59.1667 | AUROC:0.9871\n",
      "\n",
      "Epoch: [325 | 1000] LR: 0.003109\n",
      "Train | 10/10 | Loss:0.4805 | MainLoss:0.4120 | SPLoss:6.4086 | CLSLoss:0.4402 | top1:80.6500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2841 | MainLoss:0.2156 | SPLoss:6.4078 | CLSLoss:0.4402 | top1:95.8380 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6819 | MainLoss:0.6134 | SPLoss:6.4078 | CLSLoss:0.4402 | top1:59.1795 | AUROC:0.9870\n",
      "\n",
      "Epoch: [326 | 1000] LR: 0.003103\n",
      "Train | 10/10 | Loss:0.4749 | MainLoss:0.4064 | SPLoss:6.4067 | CLSLoss:0.4400 | top1:81.5000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2844 | MainLoss:0.2160 | SPLoss:6.4066 | CLSLoss:0.4401 | top1:95.8100 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6813 | MainLoss:0.6128 | SPLoss:6.4066 | CLSLoss:0.4401 | top1:59.2051 | AUROC:0.9873\n",
      "\n",
      "Epoch: [327 | 1000] LR: 0.003098\n",
      "Train | 10/10 | Loss:0.4686 | MainLoss:0.4001 | SPLoss:6.4061 | CLSLoss:0.4403 | top1:81.7000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2848 | MainLoss:0.2163 | SPLoss:6.4059 | CLSLoss:0.4402 | top1:95.8006 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6805 | MainLoss:0.6120 | SPLoss:6.4059 | CLSLoss:0.4402 | top1:59.2308 | AUROC:0.9869\n",
      "\n",
      "Epoch: [328 | 1000] LR: 0.003093\n",
      "Train | 10/10 | Loss:0.4729 | MainLoss:0.4044 | SPLoss:6.4047 | CLSLoss:0.4402 | top1:81.3000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2851 | MainLoss:0.2166 | SPLoss:6.4046 | CLSLoss:0.4402 | top1:95.7913 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6799 | MainLoss:0.6114 | SPLoss:6.4046 | CLSLoss:0.4402 | top1:59.3205 | AUROC:0.9872\n",
      "\n",
      "Epoch: [329 | 1000] LR: 0.003088\n",
      "Train | 10/10 | Loss:0.4773 | MainLoss:0.4088 | SPLoss:6.4050 | CLSLoss:0.4404 | top1:80.8000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2848 | MainLoss:0.2164 | SPLoss:6.4060 | CLSLoss:0.4402 | top1:95.8006 | AUROC:0.9925\n",
      "Test | 39/10 | Loss:0.6806 | MainLoss:0.6122 | SPLoss:6.4060 | CLSLoss:0.4402 | top1:59.2692 | AUROC:0.9870\n",
      "\n",
      "Epoch: [330 | 1000] LR: 0.003082\n",
      "Train | 10/10 | Loss:0.4656 | MainLoss:0.3972 | SPLoss:6.4072 | CLSLoss:0.4405 | top1:81.7000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2846 | MainLoss:0.2161 | SPLoss:6.4071 | CLSLoss:0.4404 | top1:95.8131 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6811 | MainLoss:0.6127 | SPLoss:6.4071 | CLSLoss:0.4404 | top1:59.2436 | AUROC:0.9874\n",
      "\n",
      "Epoch: [331 | 1000] LR: 0.003077\n",
      "Train | 10/10 | Loss:0.4787 | MainLoss:0.4102 | SPLoss:6.4073 | CLSLoss:0.4403 | top1:80.8000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2845 | MainLoss:0.2160 | SPLoss:6.4083 | CLSLoss:0.4404 | top1:95.8224 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6814 | MainLoss:0.6129 | SPLoss:6.4083 | CLSLoss:0.4404 | top1:59.2308 | AUROC:0.9871\n",
      "\n",
      "Epoch: [332 | 1000] LR: 0.003072\n",
      "Train | 10/10 | Loss:0.4629 | MainLoss:0.3944 | SPLoss:6.4078 | CLSLoss:0.4407 | top1:81.4500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2846 | MainLoss:0.2162 | SPLoss:6.4079 | CLSLoss:0.4408 | top1:95.8131 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6813 | MainLoss:0.6128 | SPLoss:6.4079 | CLSLoss:0.4408 | top1:59.2436 | AUROC:0.9868\n",
      "\n",
      "Epoch: [333 | 1000] LR: 0.003066\n",
      "Train | 10/10 | Loss:0.4636 | MainLoss:0.3951 | SPLoss:6.4077 | CLSLoss:0.4409 | top1:82.1000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2852 | MainLoss:0.2167 | SPLoss:6.4076 | CLSLoss:0.4412 | top1:95.7695 | AUROC:0.9925\n",
      "Test | 39/10 | Loss:0.6803 | MainLoss:0.6118 | SPLoss:6.4076 | CLSLoss:0.4412 | top1:59.3462 | AUROC:0.9870\n",
      "\n",
      "Epoch: [334 | 1000] LR: 0.003061\n",
      "Train | 10/10 | Loss:0.4778 | MainLoss:0.4093 | SPLoss:6.4087 | CLSLoss:0.4412 | top1:81.0000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2849 | MainLoss:0.2164 | SPLoss:6.4088 | CLSLoss:0.4413 | top1:95.7819 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6810 | MainLoss:0.6125 | SPLoss:6.4088 | CLSLoss:0.4413 | top1:59.3077 | AUROC:0.9869\n",
      "\n",
      "Epoch: [335 | 1000] LR: 0.003056\n",
      "Train | 10/10 | Loss:0.4640 | MainLoss:0.3955 | SPLoss:6.4088 | CLSLoss:0.4414 | top1:82.3000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2852 | MainLoss:0.2167 | SPLoss:6.4094 | CLSLoss:0.4416 | top1:95.7601 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6805 | MainLoss:0.6120 | SPLoss:6.4094 | CLSLoss:0.4416 | top1:59.3333 | AUROC:0.9869\n",
      "\n",
      "Epoch: [336 | 1000] LR: 0.003050\n",
      "Train | 10/10 | Loss:0.4808 | MainLoss:0.4123 | SPLoss:6.4095 | CLSLoss:0.4414 | top1:80.8000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2857 | MainLoss:0.2172 | SPLoss:6.4079 | CLSLoss:0.4415 | top1:95.7477 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6793 | MainLoss:0.6108 | SPLoss:6.4079 | CLSLoss:0.4415 | top1:59.3718 | AUROC:0.9867\n",
      "\n",
      "Epoch: [337 | 1000] LR: 0.003045\n",
      "Train | 10/10 | Loss:0.4654 | MainLoss:0.3969 | SPLoss:6.4083 | CLSLoss:0.4416 | top1:82.4000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2855 | MainLoss:0.2170 | SPLoss:6.4079 | CLSLoss:0.4417 | top1:95.7508 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6797 | MainLoss:0.6112 | SPLoss:6.4079 | CLSLoss:0.4417 | top1:59.3846 | AUROC:0.9870\n",
      "\n",
      "Epoch: [338 | 1000] LR: 0.003040\n",
      "Train | 10/10 | Loss:0.4774 | MainLoss:0.4089 | SPLoss:6.4074 | CLSLoss:0.4413 | top1:81.6000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2852 | MainLoss:0.2167 | SPLoss:6.4081 | CLSLoss:0.4414 | top1:95.7695 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6803 | MainLoss:0.6119 | SPLoss:6.4081 | CLSLoss:0.4414 | top1:59.3462 | AUROC:0.9869\n",
      "\n",
      "Epoch: [339 | 1000] LR: 0.003034\n",
      "Train | 10/10 | Loss:0.4778 | MainLoss:0.4093 | SPLoss:6.4070 | CLSLoss:0.4410 | top1:81.2500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2860 | MainLoss:0.2175 | SPLoss:6.4060 | CLSLoss:0.4411 | top1:95.7383 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6788 | MainLoss:0.6103 | SPLoss:6.4060 | CLSLoss:0.4411 | top1:59.4103 | AUROC:0.9870\n",
      "\n",
      "Epoch: [340 | 1000] LR: 0.003029\n",
      "Train | 10/10 | Loss:0.4645 | MainLoss:0.3960 | SPLoss:6.4061 | CLSLoss:0.4413 | top1:81.5000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2858 | MainLoss:0.2174 | SPLoss:6.4063 | CLSLoss:0.4414 | top1:95.7321 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6790 | MainLoss:0.6105 | SPLoss:6.4063 | CLSLoss:0.4414 | top1:59.4487 | AUROC:0.9872\n",
      "\n",
      "Epoch: [341 | 1000] LR: 0.003023\n",
      "Train | 10/10 | Loss:0.4578 | MainLoss:0.3893 | SPLoss:6.4066 | CLSLoss:0.4415 | top1:82.1500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2859 | MainLoss:0.2174 | SPLoss:6.4073 | CLSLoss:0.4418 | top1:95.7227 | AUROC:0.9925\n",
      "Test | 39/10 | Loss:0.6792 | MainLoss:0.6107 | SPLoss:6.4073 | CLSLoss:0.4418 | top1:59.4615 | AUROC:0.9869\n",
      "\n",
      "Epoch: [342 | 1000] LR: 0.003018\n",
      "Train | 10/10 | Loss:0.4831 | MainLoss:0.4146 | SPLoss:6.4071 | CLSLoss:0.4417 | top1:80.0000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2861 | MainLoss:0.2176 | SPLoss:6.4075 | CLSLoss:0.4417 | top1:95.7072 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6788 | MainLoss:0.6103 | SPLoss:6.4075 | CLSLoss:0.4417 | top1:59.4872 | AUROC:0.9871\n",
      "\n",
      "Epoch: [343 | 1000] LR: 0.003013\n",
      "Train | 10/10 | Loss:0.4677 | MainLoss:0.3992 | SPLoss:6.4072 | CLSLoss:0.4418 | top1:81.9500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2867 | MainLoss:0.2182 | SPLoss:6.4072 | CLSLoss:0.4419 | top1:95.6698 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6779 | MainLoss:0.6094 | SPLoss:6.4072 | CLSLoss:0.4419 | top1:59.5385 | AUROC:0.9869\n",
      "\n",
      "Epoch: [344 | 1000] LR: 0.003007\n",
      "Train | 10/10 | Loss:0.4715 | MainLoss:0.4030 | SPLoss:6.4075 | CLSLoss:0.4419 | top1:81.3000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2860 | MainLoss:0.2175 | SPLoss:6.4079 | CLSLoss:0.4418 | top1:95.7009 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6791 | MainLoss:0.6106 | SPLoss:6.4079 | CLSLoss:0.4418 | top1:59.5000 | AUROC:0.9869\n",
      "\n",
      "Epoch: [345 | 1000] LR: 0.003002\n",
      "Train | 10/10 | Loss:0.4973 | MainLoss:0.4288 | SPLoss:6.4089 | CLSLoss:0.4414 | top1:81.2000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2852 | MainLoss:0.2167 | SPLoss:6.4085 | CLSLoss:0.4408 | top1:95.7352 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6805 | MainLoss:0.6120 | SPLoss:6.4085 | CLSLoss:0.4408 | top1:59.4359 | AUROC:0.9866\n",
      "\n",
      "Epoch: [346 | 1000] LR: 0.002996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 10/10 | Loss:0.4701 | MainLoss:0.4016 | SPLoss:6.4093 | CLSLoss:0.4407 | top1:81.4500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2845 | MainLoss:0.2160 | SPLoss:6.4104 | CLSLoss:0.4408 | top1:95.7632 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6821 | MainLoss:0.6136 | SPLoss:6.4104 | CLSLoss:0.4408 | top1:59.3462 | AUROC:0.9868\n",
      "\n",
      "Epoch: [347 | 1000] LR: 0.002991\n",
      "Train | 10/10 | Loss:0.4705 | MainLoss:0.4020 | SPLoss:6.4102 | CLSLoss:0.4409 | top1:80.8500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2847 | MainLoss:0.2162 | SPLoss:6.4102 | CLSLoss:0.4410 | top1:95.7570 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6815 | MainLoss:0.6130 | SPLoss:6.4102 | CLSLoss:0.4410 | top1:59.3846 | AUROC:0.9867\n",
      "\n",
      "Epoch: [348 | 1000] LR: 0.002985\n",
      "Train | 10/10 | Loss:0.4713 | MainLoss:0.4028 | SPLoss:6.4094 | CLSLoss:0.4411 | top1:80.5000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2857 | MainLoss:0.2172 | SPLoss:6.4089 | CLSLoss:0.4411 | top1:95.7227 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6794 | MainLoss:0.6109 | SPLoss:6.4089 | CLSLoss:0.4411 | top1:59.4487 | AUROC:0.9868\n",
      "\n",
      "Epoch: [349 | 1000] LR: 0.002980\n",
      "Train | 10/10 | Loss:0.4655 | MainLoss:0.3970 | SPLoss:6.4089 | CLSLoss:0.4411 | top1:82.0000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2854 | MainLoss:0.2169 | SPLoss:6.4086 | CLSLoss:0.4412 | top1:95.7352 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6801 | MainLoss:0.6116 | SPLoss:6.4086 | CLSLoss:0.4412 | top1:59.4359 | AUROC:0.9870\n",
      "\n",
      "Epoch: [350 | 1000] LR: 0.002975\n",
      "Train | 10/10 | Loss:0.4952 | MainLoss:0.4268 | SPLoss:6.4079 | CLSLoss:0.4407 | top1:80.0000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2854 | MainLoss:0.2169 | SPLoss:6.4087 | CLSLoss:0.4404 | top1:95.7570 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6799 | MainLoss:0.6114 | SPLoss:6.4087 | CLSLoss:0.4404 | top1:59.4103 | AUROC:0.9866\n",
      "\n",
      "Epoch: [351 | 1000] LR: 0.002969\n",
      "Train | 10/10 | Loss:0.4784 | MainLoss:0.4099 | SPLoss:6.4101 | CLSLoss:0.4404 | top1:81.1000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2848 | MainLoss:0.2163 | SPLoss:6.4098 | CLSLoss:0.4402 | top1:95.7726 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6811 | MainLoss:0.6126 | SPLoss:6.4098 | CLSLoss:0.4402 | top1:59.3077 | AUROC:0.9870\n",
      "\n",
      "Epoch: [352 | 1000] LR: 0.002964\n",
      "Train | 10/10 | Loss:0.4611 | MainLoss:0.3926 | SPLoss:6.4088 | CLSLoss:0.4403 | top1:82.0000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2851 | MainLoss:0.2166 | SPLoss:6.4089 | CLSLoss:0.4404 | top1:95.7601 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6805 | MainLoss:0.6120 | SPLoss:6.4089 | CLSLoss:0.4404 | top1:59.3846 | AUROC:0.9868\n",
      "\n",
      "Epoch: [353 | 1000] LR: 0.002958\n",
      "Train | 10/10 | Loss:0.4627 | MainLoss:0.3943 | SPLoss:6.4089 | CLSLoss:0.4406 | top1:81.7500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2852 | MainLoss:0.2167 | SPLoss:6.4084 | CLSLoss:0.4407 | top1:95.7664 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6802 | MainLoss:0.6117 | SPLoss:6.4084 | CLSLoss:0.4407 | top1:59.3846 | AUROC:0.9869\n",
      "\n",
      "Epoch: [354 | 1000] LR: 0.002952\n",
      "Train | 10/10 | Loss:0.4616 | MainLoss:0.3931 | SPLoss:6.4081 | CLSLoss:0.4409 | top1:81.7500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2851 | MainLoss:0.2166 | SPLoss:6.4082 | CLSLoss:0.4411 | top1:95.7664 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6804 | MainLoss:0.6119 | SPLoss:6.4082 | CLSLoss:0.4411 | top1:59.4231 | AUROC:0.9869\n",
      "\n",
      "Epoch: [355 | 1000] LR: 0.002947\n",
      "Train | 10/10 | Loss:0.4809 | MainLoss:0.4124 | SPLoss:6.4094 | CLSLoss:0.4411 | top1:80.7500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2846 | MainLoss:0.2161 | SPLoss:6.4090 | CLSLoss:0.4410 | top1:95.7850 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6814 | MainLoss:0.6129 | SPLoss:6.4090 | CLSLoss:0.4410 | top1:59.3205 | AUROC:0.9869\n",
      "\n",
      "Epoch: [356 | 1000] LR: 0.002941\n",
      "Train | 10/10 | Loss:0.4788 | MainLoss:0.4103 | SPLoss:6.4098 | CLSLoss:0.4409 | top1:81.1000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2845 | MainLoss:0.2160 | SPLoss:6.4104 | CLSLoss:0.4409 | top1:95.7726 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6815 | MainLoss:0.6130 | SPLoss:6.4104 | CLSLoss:0.4409 | top1:59.3590 | AUROC:0.9866\n",
      "\n",
      "Epoch: [357 | 1000] LR: 0.002936\n",
      "Train | 10/10 | Loss:0.4608 | MainLoss:0.3923 | SPLoss:6.4103 | CLSLoss:0.4411 | top1:81.9000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2846 | MainLoss:0.2161 | SPLoss:6.4112 | CLSLoss:0.4413 | top1:95.7757 | AUROC:0.9925\n",
      "Test | 39/10 | Loss:0.6815 | MainLoss:0.6130 | SPLoss:6.4112 | CLSLoss:0.4413 | top1:59.3846 | AUROC:0.9865\n",
      "\n",
      "Epoch: [358 | 1000] LR: 0.002930\n",
      "Train | 10/10 | Loss:0.4791 | MainLoss:0.4105 | SPLoss:6.4114 | CLSLoss:0.4414 | top1:80.5500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2847 | MainLoss:0.2162 | SPLoss:6.4107 | CLSLoss:0.4412 | top1:95.7508 | AUROC:0.9925\n",
      "Test | 39/10 | Loss:0.6812 | MainLoss:0.6127 | SPLoss:6.4107 | CLSLoss:0.4412 | top1:59.3974 | AUROC:0.9865\n",
      "\n",
      "Epoch: [359 | 1000] LR: 0.002925\n",
      "Train | 10/10 | Loss:0.4588 | MainLoss:0.3903 | SPLoss:6.4112 | CLSLoss:0.4413 | top1:82.0000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2845 | MainLoss:0.2160 | SPLoss:6.4121 | CLSLoss:0.4416 | top1:95.7664 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6818 | MainLoss:0.6133 | SPLoss:6.4121 | CLSLoss:0.4416 | top1:59.3846 | AUROC:0.9866\n",
      "\n",
      "Epoch: [360 | 1000] LR: 0.002919\n",
      "Train | 10/10 | Loss:0.4693 | MainLoss:0.4007 | SPLoss:6.4122 | CLSLoss:0.4414 | top1:81.8000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2842 | MainLoss:0.2157 | SPLoss:6.4120 | CLSLoss:0.4414 | top1:95.7726 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6826 | MainLoss:0.6140 | SPLoss:6.4120 | CLSLoss:0.4414 | top1:59.3718 | AUROC:0.9867\n",
      "\n",
      "Epoch: [361 | 1000] LR: 0.002914\n",
      "Train | 10/10 | Loss:0.4778 | MainLoss:0.4092 | SPLoss:6.4125 | CLSLoss:0.4412 | top1:81.1500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2837 | MainLoss:0.2152 | SPLoss:6.4140 | CLSLoss:0.4412 | top1:95.7913 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6837 | MainLoss:0.6151 | SPLoss:6.4140 | CLSLoss:0.4412 | top1:59.3077 | AUROC:0.9867\n",
      "\n",
      "Epoch: [362 | 1000] LR: 0.002908\n",
      "Train | 10/10 | Loss:0.4852 | MainLoss:0.4167 | SPLoss:6.4150 | CLSLoss:0.4411 | top1:80.7000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2833 | MainLoss:0.2147 | SPLoss:6.4141 | CLSLoss:0.4409 | top1:95.8193 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6845 | MainLoss:0.6159 | SPLoss:6.4141 | CLSLoss:0.4409 | top1:59.2692 | AUROC:0.9867\n",
      "\n",
      "Epoch: [363 | 1000] LR: 0.002902\n",
      "Train | 10/10 | Loss:0.4606 | MainLoss:0.3920 | SPLoss:6.4130 | CLSLoss:0.4410 | top1:82.3000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2844 | MainLoss:0.2158 | SPLoss:6.4112 | CLSLoss:0.4412 | top1:95.7695 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6822 | MainLoss:0.6137 | SPLoss:6.4112 | CLSLoss:0.4412 | top1:59.3974 | AUROC:0.9867\n",
      "\n",
      "Epoch: [364 | 1000] LR: 0.002897\n",
      "Train | 10/10 | Loss:0.4806 | MainLoss:0.4121 | SPLoss:6.4119 | CLSLoss:0.4411 | top1:80.6000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2832 | MainLoss:0.2147 | SPLoss:6.4122 | CLSLoss:0.4408 | top1:95.8100 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6847 | MainLoss:0.6162 | SPLoss:6.4122 | CLSLoss:0.4408 | top1:59.2051 | AUROC:0.9865\n",
      "\n",
      "Epoch: [365 | 1000] LR: 0.002891\n",
      "Train | 10/10 | Loss:0.4833 | MainLoss:0.4148 | SPLoss:6.4122 | CLSLoss:0.4405 | top1:81.4500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2835 | MainLoss:0.2149 | SPLoss:6.4122 | CLSLoss:0.4402 | top1:95.8069 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6843 | MainLoss:0.6158 | SPLoss:6.4122 | CLSLoss:0.4402 | top1:59.2051 | AUROC:0.9865\n",
      "\n",
      "Epoch: [366 | 1000] LR: 0.002886\n",
      "Train | 10/10 | Loss:0.4773 | MainLoss:0.4088 | SPLoss:6.4119 | CLSLoss:0.4402 | top1:81.5500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2832 | MainLoss:0.2147 | SPLoss:6.4126 | CLSLoss:0.4400 | top1:95.8287 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6851 | MainLoss:0.6166 | SPLoss:6.4125 | CLSLoss:0.4400 | top1:59.1795 | AUROC:0.9867\n",
      "\n",
      "Epoch: [367 | 1000] LR: 0.002880\n",
      "Train | 10/10 | Loss:0.4767 | MainLoss:0.4082 | SPLoss:6.4122 | CLSLoss:0.4399 | top1:80.8000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2829 | MainLoss:0.2144 | SPLoss:6.4133 | CLSLoss:0.4398 | top1:95.8474 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6859 | MainLoss:0.6173 | SPLoss:6.4133 | CLSLoss:0.4398 | top1:59.1410 | AUROC:0.9867\n",
      "\n",
      "Epoch: [368 | 1000] LR: 0.002874\n",
      "Train | 10/10 | Loss:0.4723 | MainLoss:0.4037 | SPLoss:6.4129 | CLSLoss:0.4399 | top1:81.2000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2832 | MainLoss:0.2147 | SPLoss:6.4134 | CLSLoss:0.4400 | top1:95.8318 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6854 | MainLoss:0.6168 | SPLoss:6.4135 | CLSLoss:0.4400 | top1:59.1923 | AUROC:0.9866\n",
      "\n",
      "Epoch: [369 | 1000] LR: 0.002869\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 10/10 | Loss:0.4711 | MainLoss:0.4026 | SPLoss:6.4131 | CLSLoss:0.4402 | top1:81.4000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2839 | MainLoss:0.2154 | SPLoss:6.4114 | CLSLoss:0.4402 | top1:95.7913 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6838 | MainLoss:0.6152 | SPLoss:6.4114 | CLSLoss:0.4402 | top1:59.2820 | AUROC:0.9867\n",
      "\n",
      "Epoch: [370 | 1000] LR: 0.002863\n",
      "Train | 10/10 | Loss:0.4778 | MainLoss:0.4092 | SPLoss:6.4119 | CLSLoss:0.4401 | top1:81.3000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2836 | MainLoss:0.2150 | SPLoss:6.4129 | CLSLoss:0.4400 | top1:95.8287 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6846 | MainLoss:0.6161 | SPLoss:6.4129 | CLSLoss:0.4400 | top1:59.1923 | AUROC:0.9865\n",
      "\n",
      "Epoch: [371 | 1000] LR: 0.002857\n",
      "Train | 10/10 | Loss:0.4671 | MainLoss:0.3986 | SPLoss:6.4130 | CLSLoss:0.4400 | top1:81.6500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2835 | MainLoss:0.2150 | SPLoss:6.4140 | CLSLoss:0.4401 | top1:95.8162 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6849 | MainLoss:0.6163 | SPLoss:6.4140 | CLSLoss:0.4401 | top1:59.1923 | AUROC:0.9861\n",
      "\n",
      "Epoch: [372 | 1000] LR: 0.002852\n",
      "Train | 10/10 | Loss:0.4617 | MainLoss:0.3932 | SPLoss:6.4138 | CLSLoss:0.4403 | top1:82.2000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2833 | MainLoss:0.2148 | SPLoss:6.4153 | CLSLoss:0.4405 | top1:95.8131 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6853 | MainLoss:0.6167 | SPLoss:6.4153 | CLSLoss:0.4405 | top1:59.2051 | AUROC:0.9867\n",
      "\n",
      "Epoch: [373 | 1000] LR: 0.002846\n",
      "Train | 10/10 | Loss:0.4678 | MainLoss:0.3993 | SPLoss:6.4154 | CLSLoss:0.4407 | top1:81.6500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2838 | MainLoss:0.2153 | SPLoss:6.4143 | CLSLoss:0.4406 | top1:95.8006 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6844 | MainLoss:0.6158 | SPLoss:6.4143 | CLSLoss:0.4406 | top1:59.2436 | AUROC:0.9867\n",
      "\n",
      "Epoch: [374 | 1000] LR: 0.002840\n",
      "Train | 10/10 | Loss:0.4630 | MainLoss:0.3944 | SPLoss:6.4141 | CLSLoss:0.4406 | top1:82.3000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2838 | MainLoss:0.2152 | SPLoss:6.4140 | CLSLoss:0.4409 | top1:95.8069 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6845 | MainLoss:0.6160 | SPLoss:6.4140 | CLSLoss:0.4409 | top1:59.2820 | AUROC:0.9868\n",
      "\n",
      "Epoch: [375 | 1000] LR: 0.002834\n",
      "Train | 10/10 | Loss:0.4658 | MainLoss:0.3973 | SPLoss:6.4146 | CLSLoss:0.4411 | top1:81.6000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2846 | MainLoss:0.2161 | SPLoss:6.4129 | CLSLoss:0.4413 | top1:95.7383 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6829 | MainLoss:0.6144 | SPLoss:6.4129 | CLSLoss:0.4413 | top1:59.3462 | AUROC:0.9867\n",
      "\n",
      "Epoch: [376 | 1000] LR: 0.002829\n",
      "Train | 10/10 | Loss:0.4830 | MainLoss:0.4145 | SPLoss:6.4140 | CLSLoss:0.4409 | top1:80.6500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2837 | MainLoss:0.2151 | SPLoss:6.4148 | CLSLoss:0.4408 | top1:95.7944 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6849 | MainLoss:0.6163 | SPLoss:6.4148 | CLSLoss:0.4408 | top1:59.2692 | AUROC:0.9864\n",
      "\n",
      "Epoch: [377 | 1000] LR: 0.002823\n",
      "Train | 10/10 | Loss:0.4612 | MainLoss:0.3927 | SPLoss:6.4145 | CLSLoss:0.4411 | top1:82.0500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2842 | MainLoss:0.2156 | SPLoss:6.4135 | CLSLoss:0.4412 | top1:95.7632 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6838 | MainLoss:0.6153 | SPLoss:6.4135 | CLSLoss:0.4412 | top1:59.3205 | AUROC:0.9865\n",
      "\n",
      "Epoch: [378 | 1000] LR: 0.002817\n",
      "Train | 10/10 | Loss:0.4784 | MainLoss:0.4099 | SPLoss:6.4137 | CLSLoss:0.4411 | top1:82.2000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2838 | MainLoss:0.2152 | SPLoss:6.4136 | CLSLoss:0.4409 | top1:95.7726 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6845 | MainLoss:0.6159 | SPLoss:6.4136 | CLSLoss:0.4409 | top1:59.2949 | AUROC:0.9865\n",
      "\n",
      "Epoch: [379 | 1000] LR: 0.002812\n",
      "Train | 10/10 | Loss:0.4645 | MainLoss:0.3960 | SPLoss:6.4131 | CLSLoss:0.4410 | top1:81.7500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2845 | MainLoss:0.2159 | SPLoss:6.4130 | CLSLoss:0.4411 | top1:95.7539 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6831 | MainLoss:0.6145 | SPLoss:6.4130 | CLSLoss:0.4411 | top1:59.3846 | AUROC:0.9866\n",
      "\n",
      "Epoch: [380 | 1000] LR: 0.002806\n",
      "Train | 10/10 | Loss:0.4719 | MainLoss:0.4034 | SPLoss:6.4118 | CLSLoss:0.4410 | top1:81.7000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2851 | MainLoss:0.2166 | SPLoss:6.4116 | CLSLoss:0.4412 | top1:95.7446 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6817 | MainLoss:0.6132 | SPLoss:6.4116 | CLSLoss:0.4412 | top1:59.4615 | AUROC:0.9868\n",
      "\n",
      "Epoch: [381 | 1000] LR: 0.002800\n",
      "Train | 10/10 | Loss:0.4723 | MainLoss:0.4038 | SPLoss:6.4127 | CLSLoss:0.4412 | top1:81.4500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2849 | MainLoss:0.2163 | SPLoss:6.4122 | CLSLoss:0.4412 | top1:95.7477 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6824 | MainLoss:0.6138 | SPLoss:6.4122 | CLSLoss:0.4412 | top1:59.4231 | AUROC:0.9864\n",
      "\n",
      "Epoch: [382 | 1000] LR: 0.002794\n",
      "Train | 10/10 | Loss:0.4813 | MainLoss:0.4128 | SPLoss:6.4130 | CLSLoss:0.4413 | top1:80.8500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2845 | MainLoss:0.2160 | SPLoss:6.4134 | CLSLoss:0.4411 | top1:95.7477 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6831 | MainLoss:0.6145 | SPLoss:6.4134 | CLSLoss:0.4411 | top1:59.3462 | AUROC:0.9863\n",
      "\n",
      "Epoch: [383 | 1000] LR: 0.002789\n",
      "Train | 10/10 | Loss:0.4806 | MainLoss:0.4121 | SPLoss:6.4136 | CLSLoss:0.4411 | top1:81.2000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2844 | MainLoss:0.2158 | SPLoss:6.4142 | CLSLoss:0.4409 | top1:95.7508 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6833 | MainLoss:0.6148 | SPLoss:6.4142 | CLSLoss:0.4409 | top1:59.3462 | AUROC:0.9866\n",
      "\n",
      "Epoch: [384 | 1000] LR: 0.002783\n",
      "Train | 10/10 | Loss:0.4591 | MainLoss:0.3905 | SPLoss:6.4144 | CLSLoss:0.4410 | top1:82.4000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2848 | MainLoss:0.2162 | SPLoss:6.4151 | CLSLoss:0.4412 | top1:95.7383 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6827 | MainLoss:0.6142 | SPLoss:6.4151 | CLSLoss:0.4412 | top1:59.3590 | AUROC:0.9868\n",
      "\n",
      "Epoch: [385 | 1000] LR: 0.002777\n",
      "Train | 10/10 | Loss:0.4750 | MainLoss:0.4064 | SPLoss:6.4159 | CLSLoss:0.4414 | top1:81.3000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2843 | MainLoss:0.2157 | SPLoss:6.4161 | CLSLoss:0.4412 | top1:95.7477 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6836 | MainLoss:0.6151 | SPLoss:6.4161 | CLSLoss:0.4412 | top1:59.3333 | AUROC:0.9866\n",
      "\n",
      "Epoch: [386 | 1000] LR: 0.002771\n",
      "Train | 10/10 | Loss:0.4677 | MainLoss:0.3992 | SPLoss:6.4158 | CLSLoss:0.4414 | top1:81.3500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2836 | MainLoss:0.2150 | SPLoss:6.4176 | CLSLoss:0.4413 | top1:95.7850 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6853 | MainLoss:0.6167 | SPLoss:6.4176 | CLSLoss:0.4413 | top1:59.2949 | AUROC:0.9866\n",
      "\n",
      "Epoch: [387 | 1000] LR: 0.002765\n",
      "Train | 10/10 | Loss:0.4787 | MainLoss:0.4102 | SPLoss:6.4175 | CLSLoss:0.4412 | top1:80.3500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2834 | MainLoss:0.2148 | SPLoss:6.4188 | CLSLoss:0.4411 | top1:95.7975 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6856 | MainLoss:0.6170 | SPLoss:6.4188 | CLSLoss:0.4411 | top1:59.2820 | AUROC:0.9865\n",
      "\n",
      "Epoch: [388 | 1000] LR: 0.002760\n",
      "Train | 10/10 | Loss:0.4710 | MainLoss:0.4024 | SPLoss:6.4177 | CLSLoss:0.4412 | top1:81.8000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2841 | MainLoss:0.2155 | SPLoss:6.4177 | CLSLoss:0.4411 | top1:95.7695 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6843 | MainLoss:0.6157 | SPLoss:6.4177 | CLSLoss:0.4411 | top1:59.3077 | AUROC:0.9867\n",
      "\n",
      "Epoch: [389 | 1000] LR: 0.002754\n",
      "Train | 10/10 | Loss:0.4653 | MainLoss:0.3967 | SPLoss:6.4175 | CLSLoss:0.4411 | top1:81.7500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2844 | MainLoss:0.2158 | SPLoss:6.4163 | CLSLoss:0.4412 | top1:95.7601 | AUROC:0.9921\n",
      "Test | 39/10 | Loss:0.6836 | MainLoss:0.6150 | SPLoss:6.4163 | CLSLoss:0.4412 | top1:59.3462 | AUROC:0.9865\n",
      "\n",
      "Epoch: [390 | 1000] LR: 0.002748\n",
      "Train | 10/10 | Loss:0.4875 | MainLoss:0.4190 | SPLoss:6.4156 | CLSLoss:0.4411 | top1:80.5000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2846 | MainLoss:0.2160 | SPLoss:6.4153 | CLSLoss:0.4407 | top1:95.7601 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6832 | MainLoss:0.6146 | SPLoss:6.4153 | CLSLoss:0.4407 | top1:59.3718 | AUROC:0.9865\n",
      "\n",
      "Epoch: [391 | 1000] LR: 0.002742\n",
      "Train | 10/10 | Loss:0.4659 | MainLoss:0.3973 | SPLoss:6.4152 | CLSLoss:0.4406 | top1:82.0000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2840 | MainLoss:0.2155 | SPLoss:6.4161 | CLSLoss:0.4409 | top1:95.7695 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6844 | MainLoss:0.6158 | SPLoss:6.4161 | CLSLoss:0.4409 | top1:59.2820 | AUROC:0.9866\n",
      "\n",
      "Epoch: [392 | 1000] LR: 0.002736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 10/10 | Loss:0.4680 | MainLoss:0.3994 | SPLoss:6.4159 | CLSLoss:0.4409 | top1:81.5000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2840 | MainLoss:0.2154 | SPLoss:6.4160 | CLSLoss:0.4409 | top1:95.7695 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6846 | MainLoss:0.6160 | SPLoss:6.4161 | CLSLoss:0.4409 | top1:59.2820 | AUROC:0.9867\n",
      "\n",
      "Epoch: [393 | 1000] LR: 0.002730\n",
      "Train | 10/10 | Loss:0.4692 | MainLoss:0.4006 | SPLoss:6.4158 | CLSLoss:0.4409 | top1:81.4000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2844 | MainLoss:0.2158 | SPLoss:6.4156 | CLSLoss:0.4410 | top1:95.7477 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6836 | MainLoss:0.6150 | SPLoss:6.4156 | CLSLoss:0.4410 | top1:59.3077 | AUROC:0.9867\n",
      "\n",
      "Epoch: [394 | 1000] LR: 0.002725\n",
      "Train | 10/10 | Loss:0.4706 | MainLoss:0.4021 | SPLoss:6.4152 | CLSLoss:0.4411 | top1:81.4500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2848 | MainLoss:0.2162 | SPLoss:6.4153 | CLSLoss:0.4412 | top1:95.7321 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6827 | MainLoss:0.6142 | SPLoss:6.4153 | CLSLoss:0.4412 | top1:59.3974 | AUROC:0.9868\n",
      "\n",
      "Epoch: [395 | 1000] LR: 0.002719\n",
      "Train | 10/10 | Loss:0.4730 | MainLoss:0.4045 | SPLoss:6.4148 | CLSLoss:0.4412 | top1:81.2500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2848 | MainLoss:0.2162 | SPLoss:6.4153 | CLSLoss:0.4413 | top1:95.7259 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6828 | MainLoss:0.6142 | SPLoss:6.4153 | CLSLoss:0.4413 | top1:59.3846 | AUROC:0.9866\n",
      "\n",
      "Epoch: [396 | 1000] LR: 0.002713\n",
      "Train | 10/10 | Loss:0.4710 | MainLoss:0.4024 | SPLoss:6.4151 | CLSLoss:0.4412 | top1:82.3000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2841 | MainLoss:0.2155 | SPLoss:6.4159 | CLSLoss:0.4413 | top1:95.7508 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6841 | MainLoss:0.6155 | SPLoss:6.4158 | CLSLoss:0.4413 | top1:59.2949 | AUROC:0.9865\n",
      "\n",
      "Epoch: [397 | 1000] LR: 0.002707\n",
      "Train | 10/10 | Loss:0.4698 | MainLoss:0.4012 | SPLoss:6.4165 | CLSLoss:0.4413 | top1:81.2000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2841 | MainLoss:0.2155 | SPLoss:6.4170 | CLSLoss:0.4412 | top1:95.7570 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6844 | MainLoss:0.6158 | SPLoss:6.4170 | CLSLoss:0.4412 | top1:59.3077 | AUROC:0.9866\n",
      "\n",
      "Epoch: [398 | 1000] LR: 0.002701\n",
      "Train | 10/10 | Loss:0.4711 | MainLoss:0.4025 | SPLoss:6.4167 | CLSLoss:0.4413 | top1:80.9000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2844 | MainLoss:0.2158 | SPLoss:6.4160 | CLSLoss:0.4412 | top1:95.7446 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6837 | MainLoss:0.6151 | SPLoss:6.4160 | CLSLoss:0.4412 | top1:59.3590 | AUROC:0.9866\n",
      "\n",
      "Epoch: [399 | 1000] LR: 0.002695\n",
      "Train | 10/10 | Loss:0.4786 | MainLoss:0.4101 | SPLoss:6.4162 | CLSLoss:0.4412 | top1:80.6500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2845 | MainLoss:0.2160 | SPLoss:6.4158 | CLSLoss:0.4410 | top1:95.7414 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6834 | MainLoss:0.6148 | SPLoss:6.4158 | CLSLoss:0.4410 | top1:59.3077 | AUROC:0.9866\n",
      "\n",
      "Epoch: [400 | 1000] LR: 0.002689\n",
      "Train | 10/10 | Loss:0.4683 | MainLoss:0.3997 | SPLoss:6.4161 | CLSLoss:0.4410 | top1:81.8000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2840 | MainLoss:0.2154 | SPLoss:6.4173 | CLSLoss:0.4410 | top1:95.7664 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6845 | MainLoss:0.6159 | SPLoss:6.4173 | CLSLoss:0.4410 | top1:59.2692 | AUROC:0.9866\n",
      "\n",
      "Epoch: [401 | 1000] LR: 0.002683\n",
      "Train | 10/10 | Loss:0.4651 | MainLoss:0.3965 | SPLoss:6.4176 | CLSLoss:0.4411 | top1:81.5500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2839 | MainLoss:0.2153 | SPLoss:6.4175 | CLSLoss:0.4412 | top1:95.7819 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6847 | MainLoss:0.6161 | SPLoss:6.4175 | CLSLoss:0.4412 | top1:59.2692 | AUROC:0.9863\n",
      "\n",
      "Epoch: [402 | 1000] LR: 0.002677\n",
      "Train | 10/10 | Loss:0.4695 | MainLoss:0.4009 | SPLoss:6.4170 | CLSLoss:0.4411 | top1:81.5500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2844 | MainLoss:0.2158 | SPLoss:6.4161 | CLSLoss:0.4412 | top1:95.7414 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6836 | MainLoss:0.6150 | SPLoss:6.4161 | CLSLoss:0.4412 | top1:59.3462 | AUROC:0.9866\n",
      "\n",
      "Epoch: [403 | 1000] LR: 0.002672\n",
      "Train | 10/10 | Loss:0.4617 | MainLoss:0.3931 | SPLoss:6.4159 | CLSLoss:0.4414 | top1:82.3500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2844 | MainLoss:0.2159 | SPLoss:6.4154 | CLSLoss:0.4415 | top1:95.7321 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6834 | MainLoss:0.6148 | SPLoss:6.4154 | CLSLoss:0.4415 | top1:59.3974 | AUROC:0.9864\n",
      "\n",
      "Epoch: [404 | 1000] LR: 0.002666\n",
      "Train | 10/10 | Loss:0.4713 | MainLoss:0.4027 | SPLoss:6.4165 | CLSLoss:0.4414 | top1:81.1000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2836 | MainLoss:0.2150 | SPLoss:6.4169 | CLSLoss:0.4414 | top1:95.7601 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6850 | MainLoss:0.6164 | SPLoss:6.4169 | CLSLoss:0.4414 | top1:59.2692 | AUROC:0.9867\n",
      "\n",
      "Epoch: [405 | 1000] LR: 0.002660\n",
      "Train | 10/10 | Loss:0.4786 | MainLoss:0.4100 | SPLoss:6.4176 | CLSLoss:0.4412 | top1:80.8500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2834 | MainLoss:0.2148 | SPLoss:6.4178 | CLSLoss:0.4411 | top1:95.7726 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6854 | MainLoss:0.6169 | SPLoss:6.4178 | CLSLoss:0.4411 | top1:59.2692 | AUROC:0.9865\n",
      "\n",
      "Epoch: [406 | 1000] LR: 0.002654\n",
      "Train | 10/10 | Loss:0.4763 | MainLoss:0.4078 | SPLoss:6.4169 | CLSLoss:0.4409 | top1:80.8000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2840 | MainLoss:0.2154 | SPLoss:6.4162 | CLSLoss:0.4409 | top1:95.7508 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6841 | MainLoss:0.6156 | SPLoss:6.4162 | CLSLoss:0.4409 | top1:59.3333 | AUROC:0.9864\n",
      "\n",
      "Epoch: [407 | 1000] LR: 0.002648\n",
      "Train | 10/10 | Loss:0.4679 | MainLoss:0.3993 | SPLoss:6.4172 | CLSLoss:0.4409 | top1:81.8500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2835 | MainLoss:0.2149 | SPLoss:6.4177 | CLSLoss:0.4409 | top1:95.7664 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6853 | MainLoss:0.6167 | SPLoss:6.4177 | CLSLoss:0.4409 | top1:59.2692 | AUROC:0.9863\n",
      "\n",
      "Epoch: [408 | 1000] LR: 0.002642\n",
      "Train | 10/10 | Loss:0.4648 | MainLoss:0.3963 | SPLoss:6.4174 | CLSLoss:0.4411 | top1:81.5000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2838 | MainLoss:0.2152 | SPLoss:6.4169 | CLSLoss:0.4412 | top1:95.7477 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6844 | MainLoss:0.6159 | SPLoss:6.4169 | CLSLoss:0.4412 | top1:59.3590 | AUROC:0.9864\n",
      "\n",
      "Epoch: [409 | 1000] LR: 0.002636\n",
      "Train | 10/10 | Loss:0.4795 | MainLoss:0.4110 | SPLoss:6.4172 | CLSLoss:0.4411 | top1:80.5000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2841 | MainLoss:0.2155 | SPLoss:6.4166 | CLSLoss:0.4409 | top1:95.7477 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6839 | MainLoss:0.6153 | SPLoss:6.4167 | CLSLoss:0.4409 | top1:59.3590 | AUROC:0.9863\n",
      "\n",
      "Epoch: [410 | 1000] LR: 0.002630\n",
      "Train | 10/10 | Loss:0.4664 | MainLoss:0.3978 | SPLoss:6.4159 | CLSLoss:0.4410 | top1:81.5500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2846 | MainLoss:0.2161 | SPLoss:6.4160 | CLSLoss:0.4412 | top1:95.7103 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6827 | MainLoss:0.6141 | SPLoss:6.4160 | CLSLoss:0.4412 | top1:59.4231 | AUROC:0.9864\n",
      "\n",
      "Epoch: [411 | 1000] LR: 0.002624\n",
      "Train | 10/10 | Loss:0.4943 | MainLoss:0.4257 | SPLoss:6.4175 | CLSLoss:0.4409 | top1:79.3000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2839 | MainLoss:0.2153 | SPLoss:6.4181 | CLSLoss:0.4406 | top1:95.7570 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6842 | MainLoss:0.6156 | SPLoss:6.4181 | CLSLoss:0.4406 | top1:59.3205 | AUROC:0.9865\n",
      "\n",
      "Epoch: [412 | 1000] LR: 0.002618\n",
      "Train | 10/10 | Loss:0.4857 | MainLoss:0.4171 | SPLoss:6.4180 | CLSLoss:0.4403 | top1:80.6500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2838 | MainLoss:0.2152 | SPLoss:6.4181 | CLSLoss:0.4402 | top1:95.7601 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6843 | MainLoss:0.6157 | SPLoss:6.4182 | CLSLoss:0.4402 | top1:59.3205 | AUROC:0.9865\n",
      "\n",
      "Epoch: [413 | 1000] LR: 0.002612\n",
      "Train | 10/10 | Loss:0.4644 | MainLoss:0.3958 | SPLoss:6.4183 | CLSLoss:0.4403 | top1:82.5000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2845 | MainLoss:0.2159 | SPLoss:6.4172 | CLSLoss:0.4405 | top1:95.7352 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6830 | MainLoss:0.6145 | SPLoss:6.4172 | CLSLoss:0.4405 | top1:59.4103 | AUROC:0.9862\n",
      "\n",
      "Epoch: [414 | 1000] LR: 0.002606\n",
      "Train | 10/10 | Loss:0.4765 | MainLoss:0.4079 | SPLoss:6.4175 | CLSLoss:0.4404 | top1:81.0000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2842 | MainLoss:0.2157 | SPLoss:6.4173 | CLSLoss:0.4403 | top1:95.7446 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6833 | MainLoss:0.6147 | SPLoss:6.4173 | CLSLoss:0.4403 | top1:59.3590 | AUROC:0.9863\n",
      "\n",
      "Epoch: [415 | 1000] LR: 0.002600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 10/10 | Loss:0.4741 | MainLoss:0.4055 | SPLoss:6.4171 | CLSLoss:0.4404 | top1:81.1500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2842 | MainLoss:0.2156 | SPLoss:6.4178 | CLSLoss:0.4404 | top1:95.7477 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6834 | MainLoss:0.6148 | SPLoss:6.4178 | CLSLoss:0.4404 | top1:59.3718 | AUROC:0.9864\n",
      "\n",
      "Epoch: [416 | 1000] LR: 0.002594\n",
      "Train | 10/10 | Loss:0.4578 | MainLoss:0.3892 | SPLoss:6.4184 | CLSLoss:0.4405 | top1:82.7000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2840 | MainLoss:0.2154 | SPLoss:6.4186 | CLSLoss:0.4407 | top1:95.7477 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6841 | MainLoss:0.6155 | SPLoss:6.4186 | CLSLoss:0.4407 | top1:59.3974 | AUROC:0.9861\n",
      "\n",
      "Epoch: [417 | 1000] LR: 0.002588\n",
      "Train | 10/10 | Loss:0.4760 | MainLoss:0.4074 | SPLoss:6.4191 | CLSLoss:0.4407 | top1:80.8000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2838 | MainLoss:0.2152 | SPLoss:6.4189 | CLSLoss:0.4406 | top1:95.7508 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6843 | MainLoss:0.6157 | SPLoss:6.4189 | CLSLoss:0.4406 | top1:59.3974 | AUROC:0.9864\n",
      "\n",
      "Epoch: [418 | 1000] LR: 0.002582\n",
      "Train | 10/10 | Loss:0.4555 | MainLoss:0.3869 | SPLoss:6.4183 | CLSLoss:0.4407 | top1:82.0000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2839 | MainLoss:0.2153 | SPLoss:6.4192 | CLSLoss:0.4410 | top1:95.7446 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6844 | MainLoss:0.6158 | SPLoss:6.4192 | CLSLoss:0.4410 | top1:59.3974 | AUROC:0.9863\n",
      "\n",
      "Epoch: [419 | 1000] LR: 0.002576\n",
      "Train | 10/10 | Loss:0.4756 | MainLoss:0.4070 | SPLoss:6.4187 | CLSLoss:0.4408 | top1:80.9500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2834 | MainLoss:0.2148 | SPLoss:6.4194 | CLSLoss:0.4409 | top1:95.7508 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6849 | MainLoss:0.6163 | SPLoss:6.4193 | CLSLoss:0.4409 | top1:59.3974 | AUROC:0.9862\n",
      "\n",
      "Epoch: [420 | 1000] LR: 0.002570\n",
      "Train | 10/10 | Loss:0.4728 | MainLoss:0.4042 | SPLoss:6.4188 | CLSLoss:0.4406 | top1:81.7000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2836 | MainLoss:0.2151 | SPLoss:6.4185 | CLSLoss:0.4406 | top1:95.7477 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6845 | MainLoss:0.6159 | SPLoss:6.4185 | CLSLoss:0.4406 | top1:59.4231 | AUROC:0.9857\n",
      "\n",
      "Epoch: [421 | 1000] LR: 0.002564\n",
      "Train | 10/10 | Loss:0.4617 | MainLoss:0.3931 | SPLoss:6.4186 | CLSLoss:0.4407 | top1:82.3500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2839 | MainLoss:0.2153 | SPLoss:6.4189 | CLSLoss:0.4410 | top1:95.7290 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6840 | MainLoss:0.6154 | SPLoss:6.4189 | CLSLoss:0.4410 | top1:59.4487 | AUROC:0.9862\n",
      "\n",
      "Epoch: [422 | 1000] LR: 0.002558\n",
      "Train | 10/10 | Loss:0.4845 | MainLoss:0.4159 | SPLoss:6.4185 | CLSLoss:0.4409 | top1:80.6000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2841 | MainLoss:0.2155 | SPLoss:6.4183 | CLSLoss:0.4408 | top1:95.7165 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6836 | MainLoss:0.6151 | SPLoss:6.4182 | CLSLoss:0.4408 | top1:59.4487 | AUROC:0.9861\n",
      "\n",
      "Epoch: [423 | 1000] LR: 0.002552\n",
      "Train | 10/10 | Loss:0.4647 | MainLoss:0.3961 | SPLoss:6.4182 | CLSLoss:0.4408 | top1:82.0500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2841 | MainLoss:0.2155 | SPLoss:6.4187 | CLSLoss:0.4409 | top1:95.7103 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6836 | MainLoss:0.6150 | SPLoss:6.4187 | CLSLoss:0.4409 | top1:59.4615 | AUROC:0.9862\n",
      "\n",
      "Epoch: [424 | 1000] LR: 0.002546\n",
      "Train | 10/10 | Loss:0.4681 | MainLoss:0.3995 | SPLoss:6.4195 | CLSLoss:0.4409 | top1:81.2500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2838 | MainLoss:0.2152 | SPLoss:6.4206 | CLSLoss:0.4410 | top1:95.7321 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6844 | MainLoss:0.6158 | SPLoss:6.4206 | CLSLoss:0.4410 | top1:59.4359 | AUROC:0.9864\n",
      "\n",
      "Epoch: [425 | 1000] LR: 0.002540\n",
      "Train | 10/10 | Loss:0.4824 | MainLoss:0.4138 | SPLoss:6.4210 | CLSLoss:0.4409 | top1:81.6500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2839 | MainLoss:0.2153 | SPLoss:6.4209 | CLSLoss:0.4408 | top1:95.7196 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6841 | MainLoss:0.6155 | SPLoss:6.4209 | CLSLoss:0.4408 | top1:59.4359 | AUROC:0.9863\n",
      "\n",
      "Epoch: [426 | 1000] LR: 0.002534\n",
      "Train | 10/10 | Loss:0.4651 | MainLoss:0.3965 | SPLoss:6.4212 | CLSLoss:0.4407 | top1:81.7000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2841 | MainLoss:0.2155 | SPLoss:6.4209 | CLSLoss:0.4408 | top1:95.7072 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6838 | MainLoss:0.6152 | SPLoss:6.4209 | CLSLoss:0.4408 | top1:59.4487 | AUROC:0.9860\n",
      "\n",
      "Epoch: [427 | 1000] LR: 0.002528\n",
      "Train | 10/10 | Loss:0.4735 | MainLoss:0.4049 | SPLoss:6.4206 | CLSLoss:0.4409 | top1:81.3500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2841 | MainLoss:0.2154 | SPLoss:6.4202 | CLSLoss:0.4408 | top1:95.6947 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6839 | MainLoss:0.6153 | SPLoss:6.4202 | CLSLoss:0.4408 | top1:59.4615 | AUROC:0.9858\n",
      "\n",
      "Epoch: [428 | 1000] LR: 0.002522\n",
      "Train | 10/10 | Loss:0.4629 | MainLoss:0.3943 | SPLoss:6.4204 | CLSLoss:0.4410 | top1:81.7500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2847 | MainLoss:0.2161 | SPLoss:6.4195 | CLSLoss:0.4411 | top1:95.6667 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6825 | MainLoss:0.6139 | SPLoss:6.4195 | CLSLoss:0.4411 | top1:59.5128 | AUROC:0.9861\n",
      "\n",
      "Epoch: [429 | 1000] LR: 0.002516\n",
      "Train | 10/10 | Loss:0.4695 | MainLoss:0.4009 | SPLoss:6.4195 | CLSLoss:0.4410 | top1:81.4500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2844 | MainLoss:0.2157 | SPLoss:6.4205 | CLSLoss:0.4411 | top1:95.6854 | AUROC:0.9925\n",
      "Test | 39/10 | Loss:0.6832 | MainLoss:0.6146 | SPLoss:6.4205 | CLSLoss:0.4411 | top1:59.5128 | AUROC:0.9860\n",
      "\n",
      "Epoch: [430 | 1000] LR: 0.002510\n",
      "Train | 10/10 | Loss:0.4793 | MainLoss:0.4107 | SPLoss:6.4219 | CLSLoss:0.4411 | top1:80.6500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2842 | MainLoss:0.2155 | SPLoss:6.4221 | CLSLoss:0.4409 | top1:95.7009 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6835 | MainLoss:0.6149 | SPLoss:6.4221 | CLSLoss:0.4409 | top1:59.4744 | AUROC:0.9860\n",
      "\n",
      "Epoch: [431 | 1000] LR: 0.002503\n",
      "Train | 10/10 | Loss:0.4695 | MainLoss:0.4008 | SPLoss:6.4226 | CLSLoss:0.4408 | top1:81.5500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2837 | MainLoss:0.2150 | SPLoss:6.4227 | CLSLoss:0.4408 | top1:95.7134 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6845 | MainLoss:0.6158 | SPLoss:6.4227 | CLSLoss:0.4408 | top1:59.4231 | AUROC:0.9859\n",
      "\n",
      "Epoch: [432 | 1000] LR: 0.002497\n",
      "Train | 10/10 | Loss:0.4668 | MainLoss:0.3982 | SPLoss:6.4221 | CLSLoss:0.4409 | top1:81.7500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2841 | MainLoss:0.2155 | SPLoss:6.4216 | CLSLoss:0.4408 | top1:95.6916 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6835 | MainLoss:0.6149 | SPLoss:6.4215 | CLSLoss:0.4408 | top1:59.4744 | AUROC:0.9857\n",
      "\n",
      "Epoch: [433 | 1000] LR: 0.002491\n",
      "Train | 10/10 | Loss:0.4831 | MainLoss:0.4145 | SPLoss:6.4230 | CLSLoss:0.4407 | top1:80.9500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2832 | MainLoss:0.2146 | SPLoss:6.4236 | CLSLoss:0.4405 | top1:95.7477 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6852 | MainLoss:0.6166 | SPLoss:6.4236 | CLSLoss:0.4405 | top1:59.3718 | AUROC:0.9857\n",
      "\n",
      "Epoch: [434 | 1000] LR: 0.002485\n",
      "Train | 10/10 | Loss:0.4753 | MainLoss:0.4067 | SPLoss:6.4233 | CLSLoss:0.4405 | top1:81.7000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2838 | MainLoss:0.2152 | SPLoss:6.4220 | CLSLoss:0.4404 | top1:95.7072 | AUROC:0.9925\n",
      "Test | 39/10 | Loss:0.6839 | MainLoss:0.6153 | SPLoss:6.4220 | CLSLoss:0.4404 | top1:59.4359 | AUROC:0.9858\n",
      "\n",
      "Epoch: [435 | 1000] LR: 0.002479\n",
      "Train | 10/10 | Loss:0.4927 | MainLoss:0.4241 | SPLoss:6.4224 | CLSLoss:0.4401 | top1:80.8000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2833 | MainLoss:0.2146 | SPLoss:6.4226 | CLSLoss:0.4398 | top1:95.7352 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6848 | MainLoss:0.6162 | SPLoss:6.4225 | CLSLoss:0.4398 | top1:59.3590 | AUROC:0.9859\n",
      "\n",
      "Epoch: [436 | 1000] LR: 0.002473\n",
      "Train | 10/10 | Loss:0.4683 | MainLoss:0.3996 | SPLoss:6.4219 | CLSLoss:0.4398 | top1:81.5500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2835 | MainLoss:0.2149 | SPLoss:6.4219 | CLSLoss:0.4398 | top1:95.7321 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6845 | MainLoss:0.6159 | SPLoss:6.4218 | CLSLoss:0.4398 | top1:59.3718 | AUROC:0.9861\n",
      "\n",
      "Epoch: [437 | 1000] LR: 0.002467\n",
      "Train | 10/10 | Loss:0.4722 | MainLoss:0.4036 | SPLoss:6.4218 | CLSLoss:0.4398 | top1:81.5000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2836 | MainLoss:0.2150 | SPLoss:6.4216 | CLSLoss:0.4399 | top1:95.7290 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6844 | MainLoss:0.6158 | SPLoss:6.4216 | CLSLoss:0.4399 | top1:59.3846 | AUROC:0.9861\n",
      "\n",
      "Epoch: [438 | 1000] LR: 0.002461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 10/10 | Loss:0.4696 | MainLoss:0.4009 | SPLoss:6.4212 | CLSLoss:0.4399 | top1:81.3000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2840 | MainLoss:0.2154 | SPLoss:6.4210 | CLSLoss:0.4399 | top1:95.7072 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6838 | MainLoss:0.6152 | SPLoss:6.4210 | CLSLoss:0.4399 | top1:59.4359 | AUROC:0.9862\n",
      "\n",
      "Epoch: [439 | 1000] LR: 0.002455\n",
      "Train | 10/10 | Loss:0.4623 | MainLoss:0.3937 | SPLoss:6.4208 | CLSLoss:0.4401 | top1:82.2500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2839 | MainLoss:0.2153 | SPLoss:6.4208 | CLSLoss:0.4401 | top1:95.7041 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6840 | MainLoss:0.6154 | SPLoss:6.4208 | CLSLoss:0.4401 | top1:59.4359 | AUROC:0.9858\n",
      "\n",
      "Epoch: [440 | 1000] LR: 0.002449\n",
      "Train | 10/10 | Loss:0.4728 | MainLoss:0.4042 | SPLoss:6.4210 | CLSLoss:0.4400 | top1:81.7000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2839 | MainLoss:0.2153 | SPLoss:6.4213 | CLSLoss:0.4399 | top1:95.7041 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6841 | MainLoss:0.6155 | SPLoss:6.4213 | CLSLoss:0.4399 | top1:59.4103 | AUROC:0.9858\n",
      "\n",
      "Epoch: [441 | 1000] LR: 0.002442\n",
      "Train | 10/10 | Loss:0.4736 | MainLoss:0.4050 | SPLoss:6.4221 | CLSLoss:0.4400 | top1:81.4000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2839 | MainLoss:0.2153 | SPLoss:6.4225 | CLSLoss:0.4399 | top1:95.7103 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6841 | MainLoss:0.6154 | SPLoss:6.4225 | CLSLoss:0.4399 | top1:59.3974 | AUROC:0.9862\n",
      "\n",
      "Epoch: [442 | 1000] LR: 0.002436\n",
      "Train | 10/10 | Loss:0.4658 | MainLoss:0.3972 | SPLoss:6.4232 | CLSLoss:0.4400 | top1:81.6500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2837 | MainLoss:0.2151 | SPLoss:6.4233 | CLSLoss:0.4400 | top1:95.7227 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6845 | MainLoss:0.6159 | SPLoss:6.4233 | CLSLoss:0.4400 | top1:59.3846 | AUROC:0.9860\n",
      "\n",
      "Epoch: [443 | 1000] LR: 0.002430\n",
      "Train | 10/10 | Loss:0.4718 | MainLoss:0.4031 | SPLoss:6.4234 | CLSLoss:0.4401 | top1:81.6500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2834 | MainLoss:0.2147 | SPLoss:6.4238 | CLSLoss:0.4400 | top1:95.7477 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6853 | MainLoss:0.6166 | SPLoss:6.4238 | CLSLoss:0.4400 | top1:59.3205 | AUROC:0.9863\n",
      "\n",
      "Epoch: [444 | 1000] LR: 0.002424\n",
      "Train | 10/10 | Loss:0.4649 | MainLoss:0.3962 | SPLoss:6.4230 | CLSLoss:0.4400 | top1:81.9500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2834 | MainLoss:0.2148 | SPLoss:6.4235 | CLSLoss:0.4400 | top1:95.7383 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6852 | MainLoss:0.6166 | SPLoss:6.4235 | CLSLoss:0.4400 | top1:59.3462 | AUROC:0.9860\n",
      "\n",
      "Epoch: [445 | 1000] LR: 0.002418\n",
      "Train | 10/10 | Loss:0.4723 | MainLoss:0.4036 | SPLoss:6.4236 | CLSLoss:0.4400 | top1:81.0500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2835 | MainLoss:0.2149 | SPLoss:6.4230 | CLSLoss:0.4399 | top1:95.7383 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6847 | MainLoss:0.6161 | SPLoss:6.4230 | CLSLoss:0.4399 | top1:59.3974 | AUROC:0.9860\n",
      "\n",
      "Epoch: [446 | 1000] LR: 0.002412\n",
      "Train | 10/10 | Loss:0.4731 | MainLoss:0.4045 | SPLoss:6.4230 | CLSLoss:0.4400 | top1:81.3500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2838 | MainLoss:0.2151 | SPLoss:6.4231 | CLSLoss:0.4399 | top1:95.7227 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6843 | MainLoss:0.6157 | SPLoss:6.4231 | CLSLoss:0.4399 | top1:59.3974 | AUROC:0.9863\n",
      "\n",
      "Epoch: [447 | 1000] LR: 0.002406\n",
      "Train | 10/10 | Loss:0.4759 | MainLoss:0.4072 | SPLoss:6.4224 | CLSLoss:0.4399 | top1:81.3500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2842 | MainLoss:0.2156 | SPLoss:6.4227 | CLSLoss:0.4399 | top1:95.6947 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6833 | MainLoss:0.6147 | SPLoss:6.4227 | CLSLoss:0.4399 | top1:59.4231 | AUROC:0.9863\n",
      "\n",
      "Epoch: [448 | 1000] LR: 0.002399\n",
      "Train | 10/10 | Loss:0.4690 | MainLoss:0.4003 | SPLoss:6.4235 | CLSLoss:0.4401 | top1:81.9000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2840 | MainLoss:0.2154 | SPLoss:6.4240 | CLSLoss:0.4401 | top1:95.7103 | AUROC:0.9925\n",
      "Test | 39/10 | Loss:0.6839 | MainLoss:0.6152 | SPLoss:6.4240 | CLSLoss:0.4401 | top1:59.4103 | AUROC:0.9860\n",
      "\n",
      "Epoch: [449 | 1000] LR: 0.002393\n",
      "Train | 10/10 | Loss:0.4653 | MainLoss:0.3966 | SPLoss:6.4233 | CLSLoss:0.4401 | top1:81.7500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2846 | MainLoss:0.2160 | SPLoss:6.4226 | CLSLoss:0.4403 | top1:95.6822 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6825 | MainLoss:0.6139 | SPLoss:6.4226 | CLSLoss:0.4403 | top1:59.5256 | AUROC:0.9859\n",
      "\n",
      "Epoch: [450 | 1000] LR: 0.002387\n",
      "Train | 10/10 | Loss:0.4690 | MainLoss:0.4004 | SPLoss:6.4235 | CLSLoss:0.4403 | top1:81.4500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2845 | MainLoss:0.2158 | SPLoss:6.4229 | CLSLoss:0.4403 | top1:95.6822 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6828 | MainLoss:0.6142 | SPLoss:6.4229 | CLSLoss:0.4403 | top1:59.5000 | AUROC:0.9861\n",
      "\n",
      "Epoch: [451 | 1000] LR: 0.002381\n",
      "Train | 10/10 | Loss:0.4836 | MainLoss:0.4149 | SPLoss:6.4221 | CLSLoss:0.4402 | top1:81.0000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2848 | MainLoss:0.2162 | SPLoss:6.4211 | CLSLoss:0.4399 | top1:95.6636 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6821 | MainLoss:0.6134 | SPLoss:6.4211 | CLSLoss:0.4399 | top1:59.5000 | AUROC:0.9861\n",
      "\n",
      "Epoch: [452 | 1000] LR: 0.002375\n",
      "Train | 10/10 | Loss:0.4716 | MainLoss:0.4030 | SPLoss:6.4210 | CLSLoss:0.4401 | top1:81.4500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2853 | MainLoss:0.2167 | SPLoss:6.4201 | CLSLoss:0.4400 | top1:95.6480 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6809 | MainLoss:0.6123 | SPLoss:6.4201 | CLSLoss:0.4400 | top1:59.5385 | AUROC:0.9862\n",
      "\n",
      "Epoch: [453 | 1000] LR: 0.002369\n",
      "Train | 10/10 | Loss:0.4752 | MainLoss:0.4066 | SPLoss:6.4202 | CLSLoss:0.4399 | top1:81.4000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2852 | MainLoss:0.2166 | SPLoss:6.4208 | CLSLoss:0.4399 | top1:95.6667 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6811 | MainLoss:0.6125 | SPLoss:6.4208 | CLSLoss:0.4399 | top1:59.5256 | AUROC:0.9861\n",
      "\n",
      "Epoch: [454 | 1000] LR: 0.002362\n",
      "Train | 10/10 | Loss:0.4688 | MainLoss:0.4002 | SPLoss:6.4203 | CLSLoss:0.4400 | top1:81.5000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2856 | MainLoss:0.2170 | SPLoss:6.4195 | CLSLoss:0.4401 | top1:95.6293 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6803 | MainLoss:0.6117 | SPLoss:6.4195 | CLSLoss:0.4401 | top1:59.5897 | AUROC:0.9862\n",
      "\n",
      "Epoch: [455 | 1000] LR: 0.002356\n",
      "Train | 10/10 | Loss:0.4642 | MainLoss:0.3956 | SPLoss:6.4204 | CLSLoss:0.4402 | top1:81.6500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2857 | MainLoss:0.2171 | SPLoss:6.4201 | CLSLoss:0.4403 | top1:95.6168 | AUROC:0.9925\n",
      "Test | 39/10 | Loss:0.6803 | MainLoss:0.6117 | SPLoss:6.4201 | CLSLoss:0.4403 | top1:59.6026 | AUROC:0.9862\n",
      "\n",
      "Epoch: [456 | 1000] LR: 0.002350\n",
      "Train | 10/10 | Loss:0.4800 | MainLoss:0.4114 | SPLoss:6.4198 | CLSLoss:0.4402 | top1:81.5000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2856 | MainLoss:0.2170 | SPLoss:6.4199 | CLSLoss:0.4400 | top1:95.6324 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6802 | MainLoss:0.6116 | SPLoss:6.4199 | CLSLoss:0.4400 | top1:59.6282 | AUROC:0.9865\n",
      "\n",
      "Epoch: [457 | 1000] LR: 0.002344\n",
      "Train | 10/10 | Loss:0.4766 | MainLoss:0.4080 | SPLoss:6.4207 | CLSLoss:0.4399 | top1:80.8500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2857 | MainLoss:0.2171 | SPLoss:6.4207 | CLSLoss:0.4400 | top1:95.6262 | AUROC:0.9925\n",
      "Test | 39/10 | Loss:0.6802 | MainLoss:0.6116 | SPLoss:6.4207 | CLSLoss:0.4400 | top1:59.6154 | AUROC:0.9862\n",
      "\n",
      "Epoch: [458 | 1000] LR: 0.002338\n",
      "Train | 10/10 | Loss:0.4882 | MainLoss:0.4196 | SPLoss:6.4210 | CLSLoss:0.4398 | top1:80.7000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2851 | MainLoss:0.2165 | SPLoss:6.4214 | CLSLoss:0.4395 | top1:95.6698 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6811 | MainLoss:0.6125 | SPLoss:6.4214 | CLSLoss:0.4395 | top1:59.5385 | AUROC:0.9860\n",
      "\n",
      "Epoch: [459 | 1000] LR: 0.002331\n",
      "Train | 10/10 | Loss:0.4673 | MainLoss:0.3987 | SPLoss:6.4211 | CLSLoss:0.4396 | top1:82.0000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2848 | MainLoss:0.2161 | SPLoss:6.4216 | CLSLoss:0.4397 | top1:95.6854 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6816 | MainLoss:0.6130 | SPLoss:6.4216 | CLSLoss:0.4397 | top1:59.5256 | AUROC:0.9865\n",
      "\n",
      "Epoch: [460 | 1000] LR: 0.002325\n",
      "Train | 10/10 | Loss:0.4720 | MainLoss:0.4033 | SPLoss:6.4225 | CLSLoss:0.4397 | top1:81.3000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2843 | MainLoss:0.2156 | SPLoss:6.4233 | CLSLoss:0.4397 | top1:95.7072 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6827 | MainLoss:0.6141 | SPLoss:6.4233 | CLSLoss:0.4397 | top1:59.4872 | AUROC:0.9861\n",
      "\n",
      "Epoch: [461 | 1000] LR: 0.002319\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 10/10 | Loss:0.4761 | MainLoss:0.4075 | SPLoss:6.4237 | CLSLoss:0.4395 | top1:81.7000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2839 | MainLoss:0.2153 | SPLoss:6.4235 | CLSLoss:0.4394 | top1:95.7259 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6836 | MainLoss:0.6150 | SPLoss:6.4235 | CLSLoss:0.4394 | top1:59.4103 | AUROC:0.9863\n",
      "\n",
      "Epoch: [462 | 1000] LR: 0.002313\n",
      "Train | 10/10 | Loss:0.4695 | MainLoss:0.4009 | SPLoss:6.4231 | CLSLoss:0.4394 | top1:81.4500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2841 | MainLoss:0.2155 | SPLoss:6.4229 | CLSLoss:0.4395 | top1:95.7196 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6832 | MainLoss:0.6146 | SPLoss:6.4229 | CLSLoss:0.4395 | top1:59.4359 | AUROC:0.9864\n",
      "\n",
      "Epoch: [463 | 1000] LR: 0.002307\n",
      "Train | 10/10 | Loss:0.4773 | MainLoss:0.4087 | SPLoss:6.4225 | CLSLoss:0.4393 | top1:81.3500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2841 | MainLoss:0.2155 | SPLoss:6.4228 | CLSLoss:0.4393 | top1:95.7227 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6833 | MainLoss:0.6147 | SPLoss:6.4228 | CLSLoss:0.4393 | top1:59.4359 | AUROC:0.9862\n",
      "\n",
      "Epoch: [464 | 1000] LR: 0.002300\n",
      "Train | 10/10 | Loss:0.4694 | MainLoss:0.4008 | SPLoss:6.4229 | CLSLoss:0.4392 | top1:81.9500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2833 | MainLoss:0.2147 | SPLoss:6.4249 | CLSLoss:0.4393 | top1:95.7601 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6851 | MainLoss:0.6165 | SPLoss:6.4249 | CLSLoss:0.4393 | top1:59.3590 | AUROC:0.9861\n",
      "\n",
      "Epoch: [465 | 1000] LR: 0.002294\n",
      "Train | 10/10 | Loss:0.4868 | MainLoss:0.4181 | SPLoss:6.4251 | CLSLoss:0.4391 | top1:80.6500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2829 | MainLoss:0.2143 | SPLoss:6.4261 | CLSLoss:0.4389 | top1:95.7726 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6859 | MainLoss:0.6172 | SPLoss:6.4261 | CLSLoss:0.4389 | top1:59.3205 | AUROC:0.9865\n",
      "\n",
      "Epoch: [466 | 1000] LR: 0.002288\n",
      "Train | 10/10 | Loss:0.4730 | MainLoss:0.4044 | SPLoss:6.4256 | CLSLoss:0.4389 | top1:81.3000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2834 | MainLoss:0.2148 | SPLoss:6.4252 | CLSLoss:0.4389 | top1:95.7570 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6849 | MainLoss:0.6163 | SPLoss:6.4252 | CLSLoss:0.4389 | top1:59.3590 | AUROC:0.9861\n",
      "\n",
      "Epoch: [467 | 1000] LR: 0.002282\n",
      "Train | 10/10 | Loss:0.4743 | MainLoss:0.4056 | SPLoss:6.4258 | CLSLoss:0.4389 | top1:81.3500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2829 | MainLoss:0.2143 | SPLoss:6.4262 | CLSLoss:0.4387 | top1:95.7695 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6858 | MainLoss:0.6171 | SPLoss:6.4262 | CLSLoss:0.4387 | top1:59.2949 | AUROC:0.9863\n",
      "\n",
      "Epoch: [468 | 1000] LR: 0.002276\n",
      "Train | 10/10 | Loss:0.4711 | MainLoss:0.4024 | SPLoss:6.4266 | CLSLoss:0.4387 | top1:81.3500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2821 | MainLoss:0.2134 | SPLoss:6.4275 | CLSLoss:0.4386 | top1:95.8131 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6878 | MainLoss:0.6191 | SPLoss:6.4275 | CLSLoss:0.4386 | top1:59.1667 | AUROC:0.9862\n",
      "\n",
      "Epoch: [469 | 1000] LR: 0.002269\n",
      "Train | 10/10 | Loss:0.4827 | MainLoss:0.4141 | SPLoss:6.4281 | CLSLoss:0.4385 | top1:81.0500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2821 | MainLoss:0.2135 | SPLoss:6.4276 | CLSLoss:0.4383 | top1:95.8131 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6877 | MainLoss:0.6191 | SPLoss:6.4276 | CLSLoss:0.4383 | top1:59.1667 | AUROC:0.9862\n",
      "\n",
      "Epoch: [470 | 1000] LR: 0.002263\n",
      "Train | 10/10 | Loss:0.4826 | MainLoss:0.4140 | SPLoss:6.4267 | CLSLoss:0.4381 | top1:81.1500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2831 | MainLoss:0.2144 | SPLoss:6.4261 | CLSLoss:0.4380 | top1:95.7757 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6857 | MainLoss:0.6171 | SPLoss:6.4261 | CLSLoss:0.4380 | top1:59.2564 | AUROC:0.9862\n",
      "\n",
      "Epoch: [471 | 1000] LR: 0.002257\n",
      "Train | 10/10 | Loss:0.4734 | MainLoss:0.4047 | SPLoss:6.4255 | CLSLoss:0.4380 | top1:81.0500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2831 | MainLoss:0.2144 | SPLoss:6.4256 | CLSLoss:0.4379 | top1:95.7850 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6857 | MainLoss:0.6171 | SPLoss:6.4256 | CLSLoss:0.4379 | top1:59.2692 | AUROC:0.9861\n",
      "\n",
      "Epoch: [472 | 1000] LR: 0.002251\n",
      "Train | 10/10 | Loss:0.4634 | MainLoss:0.3947 | SPLoss:6.4259 | CLSLoss:0.4380 | top1:81.5000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2832 | MainLoss:0.2146 | SPLoss:6.4255 | CLSLoss:0.4381 | top1:95.7664 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6854 | MainLoss:0.6167 | SPLoss:6.4255 | CLSLoss:0.4381 | top1:59.2820 | AUROC:0.9863\n",
      "\n",
      "Epoch: [473 | 1000] LR: 0.002244\n",
      "Train | 10/10 | Loss:0.4671 | MainLoss:0.3985 | SPLoss:6.4256 | CLSLoss:0.4382 | top1:81.6000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2832 | MainLoss:0.2145 | SPLoss:6.4256 | CLSLoss:0.4383 | top1:95.7664 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6854 | MainLoss:0.6168 | SPLoss:6.4256 | CLSLoss:0.4383 | top1:59.3077 | AUROC:0.9863\n",
      "\n",
      "Epoch: [474 | 1000] LR: 0.002238\n",
      "Train | 10/10 | Loss:0.4704 | MainLoss:0.4018 | SPLoss:6.4261 | CLSLoss:0.4384 | top1:81.2000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2835 | MainLoss:0.2149 | SPLoss:6.4251 | CLSLoss:0.4384 | top1:95.7570 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6846 | MainLoss:0.6160 | SPLoss:6.4251 | CLSLoss:0.4384 | top1:59.3462 | AUROC:0.9866\n",
      "\n",
      "Epoch: [475 | 1000] LR: 0.002232\n",
      "Train | 10/10 | Loss:0.4692 | MainLoss:0.4006 | SPLoss:6.4250 | CLSLoss:0.4383 | top1:81.7500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2842 | MainLoss:0.2156 | SPLoss:6.4241 | CLSLoss:0.4384 | top1:95.7290 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6832 | MainLoss:0.6146 | SPLoss:6.4241 | CLSLoss:0.4384 | top1:59.4231 | AUROC:0.9860\n",
      "\n",
      "Epoch: [476 | 1000] LR: 0.002226\n",
      "Train | 10/10 | Loss:0.4796 | MainLoss:0.4110 | SPLoss:6.4236 | CLSLoss:0.4385 | top1:81.2500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2843 | MainLoss:0.2157 | SPLoss:6.4233 | CLSLoss:0.4382 | top1:95.7227 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6829 | MainLoss:0.6143 | SPLoss:6.4233 | CLSLoss:0.4382 | top1:59.4359 | AUROC:0.9864\n",
      "\n",
      "Epoch: [477 | 1000] LR: 0.002219\n",
      "Train | 10/10 | Loss:0.4661 | MainLoss:0.3975 | SPLoss:6.4238 | CLSLoss:0.4383 | top1:82.2500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2839 | MainLoss:0.2153 | SPLoss:6.4250 | CLSLoss:0.4383 | top1:95.7352 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6838 | MainLoss:0.6152 | SPLoss:6.4250 | CLSLoss:0.4383 | top1:59.4231 | AUROC:0.9861\n",
      "\n",
      "Epoch: [478 | 1000] LR: 0.002213\n",
      "Train | 10/10 | Loss:0.4755 | MainLoss:0.4069 | SPLoss:6.4255 | CLSLoss:0.4383 | top1:81.4500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2836 | MainLoss:0.2149 | SPLoss:6.4256 | CLSLoss:0.4381 | top1:95.7539 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6847 | MainLoss:0.6161 | SPLoss:6.4256 | CLSLoss:0.4381 | top1:59.3590 | AUROC:0.9863\n",
      "\n",
      "Epoch: [479 | 1000] LR: 0.002207\n",
      "Train | 10/10 | Loss:0.4715 | MainLoss:0.4029 | SPLoss:6.4253 | CLSLoss:0.4382 | top1:81.0000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2840 | MainLoss:0.2153 | SPLoss:6.4252 | CLSLoss:0.4381 | top1:95.7352 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6838 | MainLoss:0.6152 | SPLoss:6.4252 | CLSLoss:0.4381 | top1:59.3974 | AUROC:0.9863\n",
      "\n",
      "Epoch: [480 | 1000] LR: 0.002201\n",
      "Train | 10/10 | Loss:0.4814 | MainLoss:0.4128 | SPLoss:6.4256 | CLSLoss:0.4381 | top1:81.0500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2839 | MainLoss:0.2152 | SPLoss:6.4256 | CLSLoss:0.4379 | top1:95.7477 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6841 | MainLoss:0.6154 | SPLoss:6.4256 | CLSLoss:0.4379 | top1:59.3718 | AUROC:0.9862\n",
      "\n",
      "Epoch: [481 | 1000] LR: 0.002194\n",
      "Train | 10/10 | Loss:0.4737 | MainLoss:0.4051 | SPLoss:6.4263 | CLSLoss:0.4379 | top1:81.2500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2834 | MainLoss:0.2148 | SPLoss:6.4268 | CLSLoss:0.4378 | top1:95.7726 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6851 | MainLoss:0.6165 | SPLoss:6.4268 | CLSLoss:0.4378 | top1:59.3077 | AUROC:0.9864\n",
      "\n",
      "Epoch: [482 | 1000] LR: 0.002188\n",
      "Train | 10/10 | Loss:0.4748 | MainLoss:0.4062 | SPLoss:6.4266 | CLSLoss:0.4378 | top1:81.0500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2838 | MainLoss:0.2152 | SPLoss:6.4268 | CLSLoss:0.4378 | top1:95.7539 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6843 | MainLoss:0.6156 | SPLoss:6.4268 | CLSLoss:0.4378 | top1:59.3590 | AUROC:0.9860\n",
      "\n",
      "Epoch: [483 | 1000] LR: 0.002182\n",
      "Train | 10/10 | Loss:0.4734 | MainLoss:0.4047 | SPLoss:6.4271 | CLSLoss:0.4379 | top1:81.2500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2841 | MainLoss:0.2155 | SPLoss:6.4265 | CLSLoss:0.4378 | top1:95.7383 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6835 | MainLoss:0.6149 | SPLoss:6.4265 | CLSLoss:0.4378 | top1:59.4359 | AUROC:0.9861\n",
      "\n",
      "Epoch: [484 | 1000] LR: 0.002176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 10/10 | Loss:0.4595 | MainLoss:0.3909 | SPLoss:6.4265 | CLSLoss:0.4379 | top1:82.2000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2843 | MainLoss:0.2157 | SPLoss:6.4259 | CLSLoss:0.4380 | top1:95.7290 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6833 | MainLoss:0.6147 | SPLoss:6.4259 | CLSLoss:0.4380 | top1:59.4359 | AUROC:0.9857\n",
      "\n",
      "Epoch: [485 | 1000] LR: 0.002169\n",
      "Train | 10/10 | Loss:0.4807 | MainLoss:0.4120 | SPLoss:6.4251 | CLSLoss:0.4379 | top1:81.1000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2848 | MainLoss:0.2162 | SPLoss:6.4242 | CLSLoss:0.4379 | top1:95.7009 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6820 | MainLoss:0.6134 | SPLoss:6.4242 | CLSLoss:0.4379 | top1:59.4744 | AUROC:0.9864\n",
      "\n",
      "Epoch: [486 | 1000] LR: 0.002163\n",
      "Train | 10/10 | Loss:0.4710 | MainLoss:0.4024 | SPLoss:6.4251 | CLSLoss:0.4379 | top1:81.3500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2849 | MainLoss:0.2163 | SPLoss:6.4242 | CLSLoss:0.4379 | top1:95.7041 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6820 | MainLoss:0.6134 | SPLoss:6.4242 | CLSLoss:0.4379 | top1:59.4872 | AUROC:0.9863\n",
      "\n",
      "Epoch: [487 | 1000] LR: 0.002157\n",
      "Train | 10/10 | Loss:0.4553 | MainLoss:0.3867 | SPLoss:6.4242 | CLSLoss:0.4381 | top1:82.2000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2848 | MainLoss:0.2162 | SPLoss:6.4247 | CLSLoss:0.4383 | top1:95.6916 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6823 | MainLoss:0.6137 | SPLoss:6.4247 | CLSLoss:0.4383 | top1:59.5000 | AUROC:0.9864\n",
      "\n",
      "Epoch: [488 | 1000] LR: 0.002151\n",
      "Train | 10/10 | Loss:0.4510 | MainLoss:0.3823 | SPLoss:6.4250 | CLSLoss:0.4384 | top1:82.9000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2844 | MainLoss:0.2158 | SPLoss:6.4253 | CLSLoss:0.4387 | top1:95.7009 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6832 | MainLoss:0.6146 | SPLoss:6.4253 | CLSLoss:0.4387 | top1:59.4872 | AUROC:0.9861\n",
      "\n",
      "Epoch: [489 | 1000] LR: 0.002144\n",
      "Train | 10/10 | Loss:0.4740 | MainLoss:0.4053 | SPLoss:6.4246 | CLSLoss:0.4387 | top1:81.1000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2848 | MainLoss:0.2161 | SPLoss:6.4248 | CLSLoss:0.4387 | top1:95.6885 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6825 | MainLoss:0.6138 | SPLoss:6.4248 | CLSLoss:0.4387 | top1:59.5256 | AUROC:0.9860\n",
      "\n",
      "Epoch: [490 | 1000] LR: 0.002138\n",
      "Train | 10/10 | Loss:0.4769 | MainLoss:0.4083 | SPLoss:6.4254 | CLSLoss:0.4386 | top1:81.3500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2842 | MainLoss:0.2156 | SPLoss:6.4265 | CLSLoss:0.4385 | top1:95.7103 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6837 | MainLoss:0.6150 | SPLoss:6.4265 | CLSLoss:0.4385 | top1:59.4487 | AUROC:0.9863\n",
      "\n",
      "Epoch: [491 | 1000] LR: 0.002132\n",
      "Train | 10/10 | Loss:0.4606 | MainLoss:0.3919 | SPLoss:6.4264 | CLSLoss:0.4386 | top1:82.4500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2842 | MainLoss:0.2156 | SPLoss:6.4269 | CLSLoss:0.4387 | top1:95.7041 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6836 | MainLoss:0.6149 | SPLoss:6.4269 | CLSLoss:0.4387 | top1:59.4744 | AUROC:0.9863\n",
      "\n",
      "Epoch: [492 | 1000] LR: 0.002126\n",
      "Train | 10/10 | Loss:0.4721 | MainLoss:0.4034 | SPLoss:6.4275 | CLSLoss:0.4388 | top1:81.6500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2842 | MainLoss:0.2155 | SPLoss:6.4268 | CLSLoss:0.4387 | top1:95.7009 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6837 | MainLoss:0.6151 | SPLoss:6.4268 | CLSLoss:0.4387 | top1:59.4615 | AUROC:0.9860\n",
      "\n",
      "Epoch: [493 | 1000] LR: 0.002119\n",
      "Train | 10/10 | Loss:0.4679 | MainLoss:0.3992 | SPLoss:6.4270 | CLSLoss:0.4388 | top1:80.6500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2844 | MainLoss:0.2157 | SPLoss:6.4266 | CLSLoss:0.4388 | top1:95.6978 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6834 | MainLoss:0.6148 | SPLoss:6.4265 | CLSLoss:0.4388 | top1:59.5000 | AUROC:0.9863\n",
      "\n",
      "Epoch: [494 | 1000] LR: 0.002113\n",
      "Train | 10/10 | Loss:0.4762 | MainLoss:0.4075 | SPLoss:6.4259 | CLSLoss:0.4388 | top1:81.2500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2840 | MainLoss:0.2153 | SPLoss:6.4261 | CLSLoss:0.4387 | top1:95.7196 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6841 | MainLoss:0.6155 | SPLoss:6.4261 | CLSLoss:0.4387 | top1:59.4231 | AUROC:0.9863\n",
      "\n",
      "Epoch: [495 | 1000] LR: 0.002107\n",
      "Train | 10/10 | Loss:0.4655 | MainLoss:0.3968 | SPLoss:6.4262 | CLSLoss:0.4387 | top1:81.3500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2837 | MainLoss:0.2151 | SPLoss:6.4262 | CLSLoss:0.4388 | top1:95.7196 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6846 | MainLoss:0.6160 | SPLoss:6.4262 | CLSLoss:0.4388 | top1:59.3974 | AUROC:0.9861\n",
      "\n",
      "Epoch: [496 | 1000] LR: 0.002100\n",
      "Train | 10/10 | Loss:0.4592 | MainLoss:0.3905 | SPLoss:6.4266 | CLSLoss:0.4389 | top1:82.1000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2840 | MainLoss:0.2154 | SPLoss:6.4258 | CLSLoss:0.4390 | top1:95.7196 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6842 | MainLoss:0.6155 | SPLoss:6.4258 | CLSLoss:0.4390 | top1:59.4487 | AUROC:0.9862\n",
      "\n",
      "Epoch: [497 | 1000] LR: 0.002094\n",
      "Train | 10/10 | Loss:0.4773 | MainLoss:0.4086 | SPLoss:6.4250 | CLSLoss:0.4389 | top1:81.7000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2847 | MainLoss:0.2160 | SPLoss:6.4251 | CLSLoss:0.4389 | top1:95.6854 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6827 | MainLoss:0.6141 | SPLoss:6.4251 | CLSLoss:0.4389 | top1:59.5385 | AUROC:0.9861\n",
      "\n",
      "Epoch: [498 | 1000] LR: 0.002088\n",
      "Train | 10/10 | Loss:0.4668 | MainLoss:0.3982 | SPLoss:6.4251 | CLSLoss:0.4389 | top1:81.3500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2852 | MainLoss:0.2165 | SPLoss:6.4248 | CLSLoss:0.4390 | top1:95.6636 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6818 | MainLoss:0.6131 | SPLoss:6.4248 | CLSLoss:0.4390 | top1:59.6026 | AUROC:0.9863\n",
      "\n",
      "Epoch: [499 | 1000] LR: 0.002082\n",
      "Train | 10/10 | Loss:0.4771 | MainLoss:0.4084 | SPLoss:6.4246 | CLSLoss:0.4388 | top1:81.0500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2847 | MainLoss:0.2160 | SPLoss:6.4253 | CLSLoss:0.4388 | top1:95.6822 | AUROC:0.9921\n",
      "Test | 39/10 | Loss:0.6828 | MainLoss:0.6142 | SPLoss:6.4253 | CLSLoss:0.4388 | top1:59.5128 | AUROC:0.9862\n",
      "\n",
      "Epoch: [500 | 1000] LR: 0.002075\n",
      "Train | 10/10 | Loss:0.4775 | MainLoss:0.4089 | SPLoss:6.4245 | CLSLoss:0.4387 | top1:80.7500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2849 | MainLoss:0.2162 | SPLoss:6.4251 | CLSLoss:0.4387 | top1:95.6916 | AUROC:0.9921\n",
      "Test | 39/10 | Loss:0.6824 | MainLoss:0.6138 | SPLoss:6.4251 | CLSLoss:0.4387 | top1:59.5128 | AUROC:0.9864\n",
      "\n",
      "Epoch: [501 | 1000] LR: 0.002069\n",
      "Train | 10/10 | Loss:0.4653 | MainLoss:0.3966 | SPLoss:6.4259 | CLSLoss:0.4387 | top1:82.1500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2844 | MainLoss:0.2157 | SPLoss:6.4263 | CLSLoss:0.4388 | top1:95.7165 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6834 | MainLoss:0.6148 | SPLoss:6.4263 | CLSLoss:0.4388 | top1:59.4487 | AUROC:0.9860\n",
      "\n",
      "Epoch: [502 | 1000] LR: 0.000206\n",
      "Train | 10/10 | Loss:0.4602 | MainLoss:0.3915 | SPLoss:6.4262 | CLSLoss:0.4388 | top1:82.1500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2844 | MainLoss:0.2158 | SPLoss:6.4262 | CLSLoss:0.4388 | top1:95.7134 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6834 | MainLoss:0.6147 | SPLoss:6.4261 | CLSLoss:0.4388 | top1:59.4872 | AUROC:0.9861\n",
      "\n",
      "Epoch: [503 | 1000] LR: 0.000206\n",
      "Train | 10/10 | Loss:0.4662 | MainLoss:0.3975 | SPLoss:6.4261 | CLSLoss:0.4388 | top1:81.8000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2844 | MainLoss:0.2157 | SPLoss:6.4262 | CLSLoss:0.4388 | top1:95.7134 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6834 | MainLoss:0.6148 | SPLoss:6.4262 | CLSLoss:0.4388 | top1:59.4615 | AUROC:0.9863\n",
      "\n",
      "Epoch: [504 | 1000] LR: 0.000205\n",
      "Train | 10/10 | Loss:0.4719 | MainLoss:0.4033 | SPLoss:6.4262 | CLSLoss:0.4388 | top1:81.4000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2844 | MainLoss:0.2157 | SPLoss:6.4262 | CLSLoss:0.4388 | top1:95.7165 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6835 | MainLoss:0.6148 | SPLoss:6.4262 | CLSLoss:0.4388 | top1:59.4487 | AUROC:0.9863\n",
      "\n",
      "Epoch: [505 | 1000] LR: 0.000204\n",
      "Train | 10/10 | Loss:0.4807 | MainLoss:0.4121 | SPLoss:6.4263 | CLSLoss:0.4388 | top1:80.6500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2843 | MainLoss:0.2157 | SPLoss:6.4264 | CLSLoss:0.4388 | top1:95.7165 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6836 | MainLoss:0.6150 | SPLoss:6.4264 | CLSLoss:0.4388 | top1:59.4359 | AUROC:0.9860\n",
      "\n",
      "Epoch: [506 | 1000] LR: 0.000204\n",
      "Train | 10/10 | Loss:0.4784 | MainLoss:0.4097 | SPLoss:6.4263 | CLSLoss:0.4388 | top1:81.2000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2843 | MainLoss:0.2156 | SPLoss:6.4263 | CLSLoss:0.4387 | top1:95.7165 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6836 | MainLoss:0.6150 | SPLoss:6.4263 | CLSLoss:0.4387 | top1:59.4359 | AUROC:0.9864\n",
      "\n",
      "Epoch: [507 | 1000] LR: 0.000203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 10/10 | Loss:0.4646 | MainLoss:0.3960 | SPLoss:6.4262 | CLSLoss:0.4387 | top1:82.0500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2843 | MainLoss:0.2157 | SPLoss:6.4262 | CLSLoss:0.4387 | top1:95.7165 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6836 | MainLoss:0.6149 | SPLoss:6.4262 | CLSLoss:0.4387 | top1:59.4359 | AUROC:0.9863\n",
      "\n",
      "Epoch: [508 | 1000] LR: 0.000203\n",
      "Train | 10/10 | Loss:0.4670 | MainLoss:0.3983 | SPLoss:6.4262 | CLSLoss:0.4388 | top1:81.7000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2843 | MainLoss:0.2157 | SPLoss:6.4262 | CLSLoss:0.4387 | top1:95.7165 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6836 | MainLoss:0.6149 | SPLoss:6.4262 | CLSLoss:0.4387 | top1:59.4359 | AUROC:0.9862\n",
      "\n",
      "Epoch: [509 | 1000] LR: 0.000202\n",
      "Train | 10/10 | Loss:0.4740 | MainLoss:0.4053 | SPLoss:6.4261 | CLSLoss:0.4387 | top1:80.4500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2843 | MainLoss:0.2157 | SPLoss:6.4262 | CLSLoss:0.4387 | top1:95.7165 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6836 | MainLoss:0.6149 | SPLoss:6.4261 | CLSLoss:0.4387 | top1:59.4359 | AUROC:0.9864\n",
      "\n",
      "Epoch: [510 | 1000] LR: 0.000201\n",
      "Train | 10/10 | Loss:0.4688 | MainLoss:0.4001 | SPLoss:6.4262 | CLSLoss:0.4387 | top1:81.3500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2842 | MainLoss:0.2156 | SPLoss:6.4264 | CLSLoss:0.4388 | top1:95.7165 | AUROC:0.9921\n",
      "Test | 39/10 | Loss:0.6838 | MainLoss:0.6151 | SPLoss:6.4264 | CLSLoss:0.4388 | top1:59.4103 | AUROC:0.9860\n",
      "\n",
      "Epoch: [511 | 1000] LR: 0.000201\n",
      "Train | 10/10 | Loss:0.4677 | MainLoss:0.3991 | SPLoss:6.4263 | CLSLoss:0.4388 | top1:81.6500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2842 | MainLoss:0.2156 | SPLoss:6.4263 | CLSLoss:0.4388 | top1:95.7165 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6838 | MainLoss:0.6152 | SPLoss:6.4263 | CLSLoss:0.4388 | top1:59.4103 | AUROC:0.9863\n",
      "\n",
      "Epoch: [512 | 1000] LR: 0.000200\n",
      "Train | 10/10 | Loss:0.4605 | MainLoss:0.3918 | SPLoss:6.4263 | CLSLoss:0.4388 | top1:82.0500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2842 | MainLoss:0.2156 | SPLoss:6.4263 | CLSLoss:0.4388 | top1:95.7165 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6838 | MainLoss:0.6151 | SPLoss:6.4263 | CLSLoss:0.4388 | top1:59.4103 | AUROC:0.9861\n",
      "\n",
      "Epoch: [513 | 1000] LR: 0.000199\n",
      "Train | 10/10 | Loss:0.4716 | MainLoss:0.4030 | SPLoss:6.4262 | CLSLoss:0.4388 | top1:81.8000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2842 | MainLoss:0.2156 | SPLoss:6.4263 | CLSLoss:0.4388 | top1:95.7165 | AUROC:0.9921\n",
      "Test | 39/10 | Loss:0.6837 | MainLoss:0.6151 | SPLoss:6.4263 | CLSLoss:0.4388 | top1:59.4231 | AUROC:0.9862\n",
      "\n",
      "Epoch: [514 | 1000] LR: 0.000199\n",
      "Train | 10/10 | Loss:0.4652 | MainLoss:0.3965 | SPLoss:6.4263 | CLSLoss:0.4388 | top1:81.6500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2843 | MainLoss:0.2156 | SPLoss:6.4262 | CLSLoss:0.4388 | top1:95.7165 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6837 | MainLoss:0.6150 | SPLoss:6.4262 | CLSLoss:0.4388 | top1:59.4359 | AUROC:0.9859\n",
      "\n",
      "Epoch: [515 | 1000] LR: 0.000198\n",
      "Train | 10/10 | Loss:0.4712 | MainLoss:0.4025 | SPLoss:6.4262 | CLSLoss:0.4388 | top1:81.2500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2843 | MainLoss:0.2156 | SPLoss:6.4262 | CLSLoss:0.4388 | top1:95.7165 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6836 | MainLoss:0.6150 | SPLoss:6.4262 | CLSLoss:0.4388 | top1:59.4359 | AUROC:0.9864\n",
      "\n",
      "Epoch: [516 | 1000] LR: 0.000197\n",
      "Train | 10/10 | Loss:0.4641 | MainLoss:0.3955 | SPLoss:6.4261 | CLSLoss:0.4388 | top1:82.3000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2843 | MainLoss:0.2157 | SPLoss:6.4261 | CLSLoss:0.4388 | top1:95.7165 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6836 | MainLoss:0.6150 | SPLoss:6.4261 | CLSLoss:0.4388 | top1:59.4359 | AUROC:0.9862\n",
      "\n",
      "Epoch: [517 | 1000] LR: 0.000197\n",
      "Train | 10/10 | Loss:0.4616 | MainLoss:0.3930 | SPLoss:6.4261 | CLSLoss:0.4388 | top1:82.0000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2843 | MainLoss:0.2157 | SPLoss:6.4260 | CLSLoss:0.4388 | top1:95.7134 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6836 | MainLoss:0.6149 | SPLoss:6.4260 | CLSLoss:0.4388 | top1:59.4615 | AUROC:0.9861\n",
      "\n",
      "Epoch: [518 | 1000] LR: 0.000196\n",
      "Train | 10/10 | Loss:0.4568 | MainLoss:0.3881 | SPLoss:6.4260 | CLSLoss:0.4388 | top1:82.2500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2843 | MainLoss:0.2157 | SPLoss:6.4260 | CLSLoss:0.4388 | top1:95.7134 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6836 | MainLoss:0.6149 | SPLoss:6.4260 | CLSLoss:0.4388 | top1:59.4615 | AUROC:0.9862\n",
      "\n",
      "Epoch: [519 | 1000] LR: 0.000196\n",
      "Train | 10/10 | Loss:0.4680 | MainLoss:0.3994 | SPLoss:6.4260 | CLSLoss:0.4388 | top1:81.8500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2843 | MainLoss:0.2157 | SPLoss:6.4260 | CLSLoss:0.4388 | top1:95.7103 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6836 | MainLoss:0.6149 | SPLoss:6.4260 | CLSLoss:0.4388 | top1:59.4615 | AUROC:0.9861\n",
      "\n",
      "Epoch: [520 | 1000] LR: 0.000195\n",
      "Train | 10/10 | Loss:0.4588 | MainLoss:0.3901 | SPLoss:6.4260 | CLSLoss:0.4388 | top1:81.7500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2844 | MainLoss:0.2157 | SPLoss:6.4259 | CLSLoss:0.4389 | top1:95.7134 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6835 | MainLoss:0.6149 | SPLoss:6.4259 | CLSLoss:0.4389 | top1:59.4744 | AUROC:0.9863\n",
      "\n",
      "Epoch: [521 | 1000] LR: 0.000194\n",
      "Train | 10/10 | Loss:0.4673 | MainLoss:0.3986 | SPLoss:6.4259 | CLSLoss:0.4389 | top1:81.8000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2844 | MainLoss:0.2157 | SPLoss:6.4260 | CLSLoss:0.4389 | top1:95.7072 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6835 | MainLoss:0.6148 | SPLoss:6.4260 | CLSLoss:0.4389 | top1:59.4615 | AUROC:0.9861\n",
      "\n",
      "Epoch: [522 | 1000] LR: 0.000194\n",
      "Train | 10/10 | Loss:0.4757 | MainLoss:0.4071 | SPLoss:6.4260 | CLSLoss:0.4389 | top1:81.3000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2844 | MainLoss:0.2157 | SPLoss:6.4260 | CLSLoss:0.4389 | top1:95.7103 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6835 | MainLoss:0.6149 | SPLoss:6.4260 | CLSLoss:0.4389 | top1:59.4615 | AUROC:0.9862\n",
      "\n",
      "Epoch: [523 | 1000] LR: 0.000193\n",
      "Train | 10/10 | Loss:0.4702 | MainLoss:0.4016 | SPLoss:6.4260 | CLSLoss:0.4389 | top1:81.3500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2844 | MainLoss:0.2157 | SPLoss:6.4260 | CLSLoss:0.4389 | top1:95.7103 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6835 | MainLoss:0.6149 | SPLoss:6.4260 | CLSLoss:0.4389 | top1:59.4615 | AUROC:0.9859\n",
      "\n",
      "Epoch: [524 | 1000] LR: 0.000192\n",
      "Train | 10/10 | Loss:0.4767 | MainLoss:0.4080 | SPLoss:6.4260 | CLSLoss:0.4388 | top1:81.8500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2844 | MainLoss:0.2157 | SPLoss:6.4259 | CLSLoss:0.4388 | top1:95.7103 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6835 | MainLoss:0.6149 | SPLoss:6.4259 | CLSLoss:0.4388 | top1:59.4744 | AUROC:0.9862\n",
      "\n",
      "Epoch: [525 | 1000] LR: 0.000192\n",
      "Train | 10/10 | Loss:0.4658 | MainLoss:0.3972 | SPLoss:6.4259 | CLSLoss:0.4388 | top1:81.5000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2844 | MainLoss:0.2157 | SPLoss:6.4259 | CLSLoss:0.4388 | top1:95.7103 | AUROC:0.9921\n",
      "Test | 39/10 | Loss:0.6835 | MainLoss:0.6149 | SPLoss:6.4259 | CLSLoss:0.4388 | top1:59.4744 | AUROC:0.9860\n",
      "\n",
      "Epoch: [526 | 1000] LR: 0.000191\n",
      "Train | 10/10 | Loss:0.4641 | MainLoss:0.3954 | SPLoss:6.4260 | CLSLoss:0.4389 | top1:81.8000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2843 | MainLoss:0.2157 | SPLoss:6.4260 | CLSLoss:0.4389 | top1:95.7134 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6836 | MainLoss:0.6150 | SPLoss:6.4260 | CLSLoss:0.4389 | top1:59.4615 | AUROC:0.9861\n",
      "\n",
      "Epoch: [527 | 1000] LR: 0.000191\n",
      "Train | 10/10 | Loss:0.4744 | MainLoss:0.4058 | SPLoss:6.4260 | CLSLoss:0.4389 | top1:81.6500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2844 | MainLoss:0.2157 | SPLoss:6.4260 | CLSLoss:0.4389 | top1:95.7165 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6835 | MainLoss:0.6149 | SPLoss:6.4260 | CLSLoss:0.4389 | top1:59.4744 | AUROC:0.9861\n",
      "\n",
      "Epoch: [528 | 1000] LR: 0.000190\n",
      "Train | 10/10 | Loss:0.4785 | MainLoss:0.4099 | SPLoss:6.4260 | CLSLoss:0.4389 | top1:80.9000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2844 | MainLoss:0.2157 | SPLoss:6.4259 | CLSLoss:0.4388 | top1:95.7165 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6835 | MainLoss:0.6149 | SPLoss:6.4259 | CLSLoss:0.4388 | top1:59.4615 | AUROC:0.9860\n",
      "\n",
      "Epoch: [529 | 1000] LR: 0.000189\n",
      "Train | 10/10 | Loss:0.4762 | MainLoss:0.4076 | SPLoss:6.4259 | CLSLoss:0.4388 | top1:81.5500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2844 | MainLoss:0.2157 | SPLoss:6.4259 | CLSLoss:0.4388 | top1:95.7165 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6835 | MainLoss:0.6149 | SPLoss:6.4259 | CLSLoss:0.4388 | top1:59.4744 | AUROC:0.9863\n",
      "\n",
      "Epoch: [530 | 1000] LR: 0.000189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 10/10 | Loss:0.4824 | MainLoss:0.4138 | SPLoss:6.4259 | CLSLoss:0.4388 | top1:80.0500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2843 | MainLoss:0.2157 | SPLoss:6.4259 | CLSLoss:0.4388 | top1:95.7196 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6836 | MainLoss:0.6149 | SPLoss:6.4259 | CLSLoss:0.4388 | top1:59.4615 | AUROC:0.9863\n",
      "\n",
      "Epoch: [531 | 1000] LR: 0.000188\n",
      "Train | 10/10 | Loss:0.4740 | MainLoss:0.4054 | SPLoss:6.4259 | CLSLoss:0.4388 | top1:80.8500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2843 | MainLoss:0.2157 | SPLoss:6.4260 | CLSLoss:0.4388 | top1:95.7196 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6836 | MainLoss:0.6150 | SPLoss:6.4260 | CLSLoss:0.4388 | top1:59.4615 | AUROC:0.9860\n",
      "\n",
      "Epoch: [532 | 1000] LR: 0.000187\n",
      "Train | 10/10 | Loss:0.4631 | MainLoss:0.3945 | SPLoss:6.4260 | CLSLoss:0.4388 | top1:82.3000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2843 | MainLoss:0.2157 | SPLoss:6.4260 | CLSLoss:0.4388 | top1:95.7196 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6836 | MainLoss:0.6149 | SPLoss:6.4260 | CLSLoss:0.4388 | top1:59.4615 | AUROC:0.9860\n",
      "\n",
      "Epoch: [533 | 1000] LR: 0.000187\n",
      "Train | 10/10 | Loss:0.4637 | MainLoss:0.3950 | SPLoss:6.4260 | CLSLoss:0.4388 | top1:81.8000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2843 | MainLoss:0.2157 | SPLoss:6.4261 | CLSLoss:0.4388 | top1:95.7165 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6836 | MainLoss:0.6149 | SPLoss:6.4261 | CLSLoss:0.4388 | top1:59.4615 | AUROC:0.9863\n",
      "\n",
      "Epoch: [534 | 1000] LR: 0.000186\n",
      "Train | 10/10 | Loss:0.4647 | MainLoss:0.3961 | SPLoss:6.4260 | CLSLoss:0.4388 | top1:81.7500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2843 | MainLoss:0.2157 | SPLoss:6.4261 | CLSLoss:0.4388 | top1:95.7165 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6836 | MainLoss:0.6150 | SPLoss:6.4261 | CLSLoss:0.4388 | top1:59.4615 | AUROC:0.9861\n",
      "\n",
      "Epoch: [535 | 1000] LR: 0.000186\n",
      "Train | 10/10 | Loss:0.4789 | MainLoss:0.4103 | SPLoss:6.4261 | CLSLoss:0.4388 | top1:81.1500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2843 | MainLoss:0.2157 | SPLoss:6.4261 | CLSLoss:0.4388 | top1:95.7165 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6836 | MainLoss:0.6150 | SPLoss:6.4261 | CLSLoss:0.4388 | top1:59.4615 | AUROC:0.9862\n",
      "\n",
      "Epoch: [536 | 1000] LR: 0.000185\n",
      "Train | 10/10 | Loss:0.4786 | MainLoss:0.4100 | SPLoss:6.4262 | CLSLoss:0.4388 | top1:80.3500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2843 | MainLoss:0.2156 | SPLoss:6.4262 | CLSLoss:0.4388 | top1:95.7165 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6837 | MainLoss:0.6151 | SPLoss:6.4262 | CLSLoss:0.4388 | top1:59.4487 | AUROC:0.9864\n",
      "\n",
      "Epoch: [537 | 1000] LR: 0.000184\n",
      "Train | 10/10 | Loss:0.4736 | MainLoss:0.4050 | SPLoss:6.4263 | CLSLoss:0.4388 | top1:81.0500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2842 | MainLoss:0.2156 | SPLoss:6.4263 | CLSLoss:0.4388 | top1:95.7165 | AUROC:0.9921\n",
      "Test | 39/10 | Loss:0.6838 | MainLoss:0.6152 | SPLoss:6.4263 | CLSLoss:0.4388 | top1:59.4359 | AUROC:0.9863\n",
      "\n",
      "Epoch: [538 | 1000] LR: 0.000184\n",
      "Train | 10/10 | Loss:0.4848 | MainLoss:0.4161 | SPLoss:6.4264 | CLSLoss:0.4388 | top1:80.7000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2842 | MainLoss:0.2155 | SPLoss:6.4264 | CLSLoss:0.4388 | top1:95.7165 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6839 | MainLoss:0.6153 | SPLoss:6.4264 | CLSLoss:0.4388 | top1:59.4103 | AUROC:0.9859\n",
      "\n",
      "Epoch: [539 | 1000] LR: 0.000183\n",
      "Train | 10/10 | Loss:0.4685 | MainLoss:0.3999 | SPLoss:6.4264 | CLSLoss:0.4388 | top1:81.9500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2842 | MainLoss:0.2155 | SPLoss:6.4264 | CLSLoss:0.4388 | top1:95.7165 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6839 | MainLoss:0.6152 | SPLoss:6.4264 | CLSLoss:0.4388 | top1:59.4103 | AUROC:0.9862\n",
      "\n",
      "Epoch: [540 | 1000] LR: 0.000182\n",
      "Train | 10/10 | Loss:0.4663 | MainLoss:0.3977 | SPLoss:6.4263 | CLSLoss:0.4388 | top1:81.3000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2842 | MainLoss:0.2155 | SPLoss:6.4264 | CLSLoss:0.4388 | top1:95.7165 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6839 | MainLoss:0.6153 | SPLoss:6.4264 | CLSLoss:0.4388 | top1:59.4103 | AUROC:0.9862\n",
      "\n",
      "Epoch: [541 | 1000] LR: 0.000182\n",
      "Train | 10/10 | Loss:0.4757 | MainLoss:0.4071 | SPLoss:6.4264 | CLSLoss:0.4388 | top1:80.8500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2842 | MainLoss:0.2156 | SPLoss:6.4264 | CLSLoss:0.4388 | top1:95.7165 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6838 | MainLoss:0.6152 | SPLoss:6.4264 | CLSLoss:0.4388 | top1:59.4359 | AUROC:0.9859\n",
      "\n",
      "Epoch: [542 | 1000] LR: 0.000181\n",
      "Train | 10/10 | Loss:0.4681 | MainLoss:0.3994 | SPLoss:6.4264 | CLSLoss:0.4388 | top1:82.0000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2842 | MainLoss:0.2156 | SPLoss:6.4264 | CLSLoss:0.4388 | top1:95.7165 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6838 | MainLoss:0.6152 | SPLoss:6.4264 | CLSLoss:0.4388 | top1:59.4359 | AUROC:0.9863\n",
      "\n",
      "Epoch: [543 | 1000] LR: 0.000181\n",
      "Train | 10/10 | Loss:0.4679 | MainLoss:0.3993 | SPLoss:6.4265 | CLSLoss:0.4388 | top1:82.6500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2842 | MainLoss:0.2156 | SPLoss:6.4265 | CLSLoss:0.4388 | top1:95.7165 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6839 | MainLoss:0.6152 | SPLoss:6.4265 | CLSLoss:0.4388 | top1:59.4359 | AUROC:0.9863\n",
      "\n",
      "Epoch: [544 | 1000] LR: 0.000180\n",
      "Train | 10/10 | Loss:0.4723 | MainLoss:0.4037 | SPLoss:6.4266 | CLSLoss:0.4388 | top1:81.4500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2842 | MainLoss:0.2155 | SPLoss:6.4266 | CLSLoss:0.4388 | top1:95.7165 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6839 | MainLoss:0.6153 | SPLoss:6.4266 | CLSLoss:0.4388 | top1:59.4359 | AUROC:0.9863\n",
      "\n",
      "Epoch: [545 | 1000] LR: 0.000179\n",
      "Train | 10/10 | Loss:0.4704 | MainLoss:0.4017 | SPLoss:6.4266 | CLSLoss:0.4388 | top1:82.1500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2842 | MainLoss:0.2156 | SPLoss:6.4265 | CLSLoss:0.4388 | top1:95.7165 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6839 | MainLoss:0.6152 | SPLoss:6.4265 | CLSLoss:0.4388 | top1:59.4359 | AUROC:0.9860\n",
      "\n",
      "Epoch: [546 | 1000] LR: 0.000179\n",
      "Train | 10/10 | Loss:0.4717 | MainLoss:0.4031 | SPLoss:6.4265 | CLSLoss:0.4388 | top1:81.0000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2842 | MainLoss:0.2156 | SPLoss:6.4266 | CLSLoss:0.4388 | top1:95.7165 | AUROC:0.9921\n",
      "Test | 39/10 | Loss:0.6839 | MainLoss:0.6152 | SPLoss:6.4265 | CLSLoss:0.4388 | top1:59.4359 | AUROC:0.9865\n",
      "\n",
      "Epoch: [547 | 1000] LR: 0.000178\n",
      "Train | 10/10 | Loss:0.4732 | MainLoss:0.4045 | SPLoss:6.4265 | CLSLoss:0.4388 | top1:80.4500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2842 | MainLoss:0.2156 | SPLoss:6.4265 | CLSLoss:0.4388 | top1:95.7165 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6838 | MainLoss:0.6152 | SPLoss:6.4265 | CLSLoss:0.4388 | top1:59.4359 | AUROC:0.9859\n",
      "\n",
      "Epoch: [548 | 1000] LR: 0.000177\n",
      "Train | 10/10 | Loss:0.4761 | MainLoss:0.4074 | SPLoss:6.4265 | CLSLoss:0.4388 | top1:81.5500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2842 | MainLoss:0.2156 | SPLoss:6.4265 | CLSLoss:0.4388 | top1:95.7165 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6838 | MainLoss:0.6152 | SPLoss:6.4265 | CLSLoss:0.4388 | top1:59.4359 | AUROC:0.9861\n",
      "\n",
      "Epoch: [549 | 1000] LR: 0.000177\n",
      "Train | 10/10 | Loss:0.4650 | MainLoss:0.3963 | SPLoss:6.4265 | CLSLoss:0.4388 | top1:82.0000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2842 | MainLoss:0.2156 | SPLoss:6.4265 | CLSLoss:0.4388 | top1:95.7165 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6839 | MainLoss:0.6152 | SPLoss:6.4265 | CLSLoss:0.4388 | top1:59.4359 | AUROC:0.9861\n",
      "\n",
      "Epoch: [550 | 1000] LR: 0.000176\n",
      "Train | 10/10 | Loss:0.4601 | MainLoss:0.3914 | SPLoss:6.4265 | CLSLoss:0.4388 | top1:81.5000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2842 | MainLoss:0.2156 | SPLoss:6.4265 | CLSLoss:0.4388 | top1:95.7165 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6839 | MainLoss:0.6152 | SPLoss:6.4265 | CLSLoss:0.4388 | top1:59.4359 | AUROC:0.9864\n",
      "\n",
      "Epoch: [551 | 1000] LR: 0.000176\n",
      "Train | 10/10 | Loss:0.4635 | MainLoss:0.3949 | SPLoss:6.4265 | CLSLoss:0.4388 | top1:81.6000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2842 | MainLoss:0.2155 | SPLoss:6.4265 | CLSLoss:0.4388 | top1:95.7165 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6839 | MainLoss:0.6153 | SPLoss:6.4265 | CLSLoss:0.4388 | top1:59.4359 | AUROC:0.9862\n",
      "\n",
      "Epoch: [552 | 1000] LR: 0.000175\n",
      "Train | 10/10 | Loss:0.4721 | MainLoss:0.4035 | SPLoss:6.4266 | CLSLoss:0.4388 | top1:80.9000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2842 | MainLoss:0.2155 | SPLoss:6.4266 | CLSLoss:0.4388 | top1:95.7165 | AUROC:0.9921\n",
      "Test | 39/10 | Loss:0.6839 | MainLoss:0.6153 | SPLoss:6.4266 | CLSLoss:0.4388 | top1:59.4359 | AUROC:0.9861\n",
      "\n",
      "Epoch: [553 | 1000] LR: 0.000174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 10/10 | Loss:0.4668 | MainLoss:0.3982 | SPLoss:6.4266 | CLSLoss:0.4388 | top1:81.1000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2842 | MainLoss:0.2155 | SPLoss:6.4266 | CLSLoss:0.4388 | top1:95.7165 | AUROC:0.9920\n",
      "Test | 39/10 | Loss:0.6840 | MainLoss:0.6154 | SPLoss:6.4266 | CLSLoss:0.4388 | top1:59.4103 | AUROC:0.9861\n",
      "\n",
      "Epoch: [554 | 1000] LR: 0.000174\n",
      "Train | 10/10 | Loss:0.4668 | MainLoss:0.3982 | SPLoss:6.4266 | CLSLoss:0.4388 | top1:81.3500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2842 | MainLoss:0.2155 | SPLoss:6.4266 | CLSLoss:0.4388 | top1:95.7165 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6840 | MainLoss:0.6153 | SPLoss:6.4266 | CLSLoss:0.4388 | top1:59.4359 | AUROC:0.9862\n",
      "\n",
      "Epoch: [555 | 1000] LR: 0.000173\n",
      "Train | 10/10 | Loss:0.4787 | MainLoss:0.4100 | SPLoss:6.4266 | CLSLoss:0.4388 | top1:80.8500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2842 | MainLoss:0.2156 | SPLoss:6.4266 | CLSLoss:0.4388 | top1:95.7165 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6839 | MainLoss:0.6152 | SPLoss:6.4265 | CLSLoss:0.4388 | top1:59.4359 | AUROC:0.9859\n",
      "\n",
      "Epoch: [556 | 1000] LR: 0.000172\n",
      "Train | 10/10 | Loss:0.4781 | MainLoss:0.4095 | SPLoss:6.4265 | CLSLoss:0.4388 | top1:81.4500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2843 | MainLoss:0.2156 | SPLoss:6.4265 | CLSLoss:0.4388 | top1:95.7165 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6838 | MainLoss:0.6152 | SPLoss:6.4265 | CLSLoss:0.4388 | top1:59.4359 | AUROC:0.9864\n",
      "\n",
      "Epoch: [557 | 1000] LR: 0.000172\n",
      "Train | 10/10 | Loss:0.4777 | MainLoss:0.4090 | SPLoss:6.4265 | CLSLoss:0.4388 | top1:81.3500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2843 | MainLoss:0.2156 | SPLoss:6.4265 | CLSLoss:0.4388 | top1:95.7196 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6838 | MainLoss:0.6151 | SPLoss:6.4265 | CLSLoss:0.4388 | top1:59.4487 | AUROC:0.9860\n",
      "\n",
      "Epoch: [558 | 1000] LR: 0.000171\n",
      "Train | 10/10 | Loss:0.4697 | MainLoss:0.4010 | SPLoss:6.4265 | CLSLoss:0.4388 | top1:81.9500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2843 | MainLoss:0.2157 | SPLoss:6.4264 | CLSLoss:0.4388 | top1:95.7196 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6837 | MainLoss:0.6151 | SPLoss:6.4264 | CLSLoss:0.4388 | top1:59.4487 | AUROC:0.9863\n",
      "\n",
      "Epoch: [559 | 1000] LR: 0.000171\n",
      "Train | 10/10 | Loss:0.4696 | MainLoss:0.4009 | SPLoss:6.4265 | CLSLoss:0.4388 | top1:81.8500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2843 | MainLoss:0.2156 | SPLoss:6.4265 | CLSLoss:0.4388 | top1:95.7196 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6838 | MainLoss:0.6151 | SPLoss:6.4265 | CLSLoss:0.4388 | top1:59.4487 | AUROC:0.9862\n",
      "\n",
      "Epoch: [560 | 1000] LR: 0.000170\n",
      "Train | 10/10 | Loss:0.4777 | MainLoss:0.4090 | SPLoss:6.4266 | CLSLoss:0.4388 | top1:80.8000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2843 | MainLoss:0.2156 | SPLoss:6.4266 | CLSLoss:0.4388 | top1:95.7165 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6838 | MainLoss:0.6152 | SPLoss:6.4266 | CLSLoss:0.4388 | top1:59.4359 | AUROC:0.9860\n",
      "\n",
      "Epoch: [561 | 1000] LR: 0.000169\n",
      "Train | 10/10 | Loss:0.4698 | MainLoss:0.4011 | SPLoss:6.4267 | CLSLoss:0.4388 | top1:81.5500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2842 | MainLoss:0.2155 | SPLoss:6.4267 | CLSLoss:0.4388 | top1:95.7165 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6840 | MainLoss:0.6153 | SPLoss:6.4267 | CLSLoss:0.4388 | top1:59.4231 | AUROC:0.9863\n",
      "\n",
      "Epoch: [562 | 1000] LR: 0.000169\n",
      "Train | 10/10 | Loss:0.4720 | MainLoss:0.4034 | SPLoss:6.4267 | CLSLoss:0.4388 | top1:81.1000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2842 | MainLoss:0.2156 | SPLoss:6.4266 | CLSLoss:0.4388 | top1:95.7165 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6839 | MainLoss:0.6152 | SPLoss:6.4266 | CLSLoss:0.4388 | top1:59.4359 | AUROC:0.9865\n",
      "\n",
      "Epoch: [563 | 1000] LR: 0.000168\n",
      "Train | 10/10 | Loss:0.4689 | MainLoss:0.4002 | SPLoss:6.4266 | CLSLoss:0.4388 | top1:81.6000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2842 | MainLoss:0.2156 | SPLoss:6.4266 | CLSLoss:0.4388 | top1:95.7165 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6839 | MainLoss:0.6152 | SPLoss:6.4265 | CLSLoss:0.4388 | top1:59.4359 | AUROC:0.9863\n",
      "\n",
      "Epoch: [564 | 1000] LR: 0.000167\n",
      "Train | 10/10 | Loss:0.4683 | MainLoss:0.3996 | SPLoss:6.4266 | CLSLoss:0.4388 | top1:81.0500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2842 | MainLoss:0.2156 | SPLoss:6.4266 | CLSLoss:0.4388 | top1:95.7165 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6839 | MainLoss:0.6153 | SPLoss:6.4266 | CLSLoss:0.4388 | top1:59.4359 | AUROC:0.9865\n",
      "\n",
      "Epoch: [565 | 1000] LR: 0.000167\n",
      "Train | 10/10 | Loss:0.4723 | MainLoss:0.4036 | SPLoss:6.4266 | CLSLoss:0.4388 | top1:81.1500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2842 | MainLoss:0.2155 | SPLoss:6.4266 | CLSLoss:0.4388 | top1:95.7165 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6840 | MainLoss:0.6153 | SPLoss:6.4266 | CLSLoss:0.4388 | top1:59.4231 | AUROC:0.9860\n",
      "\n",
      "Epoch: [566 | 1000] LR: 0.000166\n",
      "Train | 10/10 | Loss:0.4578 | MainLoss:0.3891 | SPLoss:6.4266 | CLSLoss:0.4388 | top1:82.5500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2842 | MainLoss:0.2155 | SPLoss:6.4267 | CLSLoss:0.4388 | top1:95.7165 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6840 | MainLoss:0.6154 | SPLoss:6.4267 | CLSLoss:0.4388 | top1:59.4103 | AUROC:0.9863\n",
      "\n",
      "Epoch: [567 | 1000] LR: 0.000166\n",
      "Train | 10/10 | Loss:0.4772 | MainLoss:0.4085 | SPLoss:6.4267 | CLSLoss:0.4388 | top1:80.5500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2842 | MainLoss:0.2155 | SPLoss:6.4267 | CLSLoss:0.4388 | top1:95.7165 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6841 | MainLoss:0.6154 | SPLoss:6.4267 | CLSLoss:0.4388 | top1:59.4103 | AUROC:0.9862\n",
      "\n",
      "Epoch: [568 | 1000] LR: 0.000165\n",
      "Train | 10/10 | Loss:0.4679 | MainLoss:0.3992 | SPLoss:6.4267 | CLSLoss:0.4388 | top1:81.1500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2842 | MainLoss:0.2155 | SPLoss:6.4267 | CLSLoss:0.4388 | top1:95.7165 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6840 | MainLoss:0.6154 | SPLoss:6.4267 | CLSLoss:0.4388 | top1:59.4103 | AUROC:0.9862\n",
      "\n",
      "Epoch: [569 | 1000] LR: 0.000164\n",
      "Train | 10/10 | Loss:0.4743 | MainLoss:0.4056 | SPLoss:6.4267 | CLSLoss:0.4388 | top1:81.8500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2842 | MainLoss:0.2155 | SPLoss:6.4267 | CLSLoss:0.4388 | top1:95.7165 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6840 | MainLoss:0.6153 | SPLoss:6.4267 | CLSLoss:0.4388 | top1:59.4231 | AUROC:0.9864\n",
      "\n",
      "Epoch: [570 | 1000] LR: 0.000164\n",
      "Train | 10/10 | Loss:0.4665 | MainLoss:0.3978 | SPLoss:6.4267 | CLSLoss:0.4388 | top1:81.2500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2842 | MainLoss:0.2155 | SPLoss:6.4266 | CLSLoss:0.4388 | top1:95.7165 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6840 | MainLoss:0.6153 | SPLoss:6.4266 | CLSLoss:0.4388 | top1:59.4231 | AUROC:0.9861\n",
      "\n",
      "Epoch: [571 | 1000] LR: 0.000163\n",
      "Train | 10/10 | Loss:0.4676 | MainLoss:0.3990 | SPLoss:6.4266 | CLSLoss:0.4388 | top1:81.6500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2842 | MainLoss:0.2156 | SPLoss:6.4266 | CLSLoss:0.4388 | top1:95.7165 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6839 | MainLoss:0.6153 | SPLoss:6.4266 | CLSLoss:0.4388 | top1:59.4359 | AUROC:0.9862\n",
      "\n",
      "Epoch: [572 | 1000] LR: 0.000163\n",
      "Train | 10/10 | Loss:0.4703 | MainLoss:0.4016 | SPLoss:6.4266 | CLSLoss:0.4388 | top1:82.0000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2842 | MainLoss:0.2156 | SPLoss:6.4266 | CLSLoss:0.4388 | top1:95.7165 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6839 | MainLoss:0.6152 | SPLoss:6.4266 | CLSLoss:0.4388 | top1:59.4359 | AUROC:0.9861\n",
      "\n",
      "Epoch: [573 | 1000] LR: 0.000162\n",
      "Train | 10/10 | Loss:0.4765 | MainLoss:0.4079 | SPLoss:6.4267 | CLSLoss:0.4388 | top1:80.4000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2842 | MainLoss:0.2155 | SPLoss:6.4268 | CLSLoss:0.4388 | top1:95.7165 | AUROC:0.9921\n",
      "Test | 39/10 | Loss:0.6841 | MainLoss:0.6154 | SPLoss:6.4268 | CLSLoss:0.4388 | top1:59.4103 | AUROC:0.9862\n",
      "\n",
      "Epoch: [574 | 1000] LR: 0.000161\n",
      "Train | 10/10 | Loss:0.4738 | MainLoss:0.4052 | SPLoss:6.4269 | CLSLoss:0.4388 | top1:80.8000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2842 | MainLoss:0.2155 | SPLoss:6.4269 | CLSLoss:0.4388 | top1:95.7165 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6841 | MainLoss:0.6154 | SPLoss:6.4268 | CLSLoss:0.4388 | top1:59.4103 | AUROC:0.9864\n",
      "\n",
      "Epoch: [575 | 1000] LR: 0.000161\n",
      "Train | 10/10 | Loss:0.4711 | MainLoss:0.4024 | SPLoss:6.4269 | CLSLoss:0.4388 | top1:81.1000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2842 | MainLoss:0.2155 | SPLoss:6.4268 | CLSLoss:0.4388 | top1:95.7165 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6840 | MainLoss:0.6154 | SPLoss:6.4268 | CLSLoss:0.4388 | top1:59.4359 | AUROC:0.9862\n",
      "\n",
      "Epoch: [576 | 1000] LR: 0.000160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 10/10 | Loss:0.4742 | MainLoss:0.4056 | SPLoss:6.4269 | CLSLoss:0.4388 | top1:81.3500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2842 | MainLoss:0.2155 | SPLoss:6.4269 | CLSLoss:0.4388 | top1:95.7165 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6840 | MainLoss:0.6153 | SPLoss:6.4269 | CLSLoss:0.4388 | top1:59.4359 | AUROC:0.9861\n",
      "\n",
      "Epoch: [577 | 1000] LR: 0.000159\n",
      "Train | 10/10 | Loss:0.4695 | MainLoss:0.4008 | SPLoss:6.4269 | CLSLoss:0.4388 | top1:81.5500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2842 | MainLoss:0.2155 | SPLoss:6.4269 | CLSLoss:0.4388 | top1:95.7165 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6840 | MainLoss:0.6153 | SPLoss:6.4269 | CLSLoss:0.4388 | top1:59.4359 | AUROC:0.9859\n",
      "\n",
      "Epoch: [578 | 1000] LR: 0.000159\n",
      "Train | 10/10 | Loss:0.4753 | MainLoss:0.4066 | SPLoss:6.4269 | CLSLoss:0.4388 | top1:80.8500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2842 | MainLoss:0.2156 | SPLoss:6.4268 | CLSLoss:0.4388 | top1:95.7165 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6839 | MainLoss:0.6153 | SPLoss:6.4268 | CLSLoss:0.4388 | top1:59.4359 | AUROC:0.9860\n",
      "\n",
      "Epoch: [579 | 1000] LR: 0.000158\n",
      "Train | 10/10 | Loss:0.4609 | MainLoss:0.3923 | SPLoss:6.4269 | CLSLoss:0.4388 | top1:82.5500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2842 | MainLoss:0.2155 | SPLoss:6.4268 | CLSLoss:0.4388 | top1:95.7165 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6840 | MainLoss:0.6153 | SPLoss:6.4268 | CLSLoss:0.4388 | top1:59.4359 | AUROC:0.9861\n",
      "\n",
      "Epoch: [580 | 1000] LR: 0.000158\n",
      "Train | 10/10 | Loss:0.4795 | MainLoss:0.4108 | SPLoss:6.4267 | CLSLoss:0.4388 | top1:80.3500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2842 | MainLoss:0.2156 | SPLoss:6.4267 | CLSLoss:0.4388 | top1:95.7165 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6839 | MainLoss:0.6153 | SPLoss:6.4267 | CLSLoss:0.4388 | top1:59.4359 | AUROC:0.9862\n",
      "\n",
      "Epoch: [581 | 1000] LR: 0.000157\n",
      "Train | 10/10 | Loss:0.4748 | MainLoss:0.4061 | SPLoss:6.4267 | CLSLoss:0.4388 | top1:81.3500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2842 | MainLoss:0.2156 | SPLoss:6.4267 | CLSLoss:0.4388 | top1:95.7165 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6839 | MainLoss:0.6153 | SPLoss:6.4268 | CLSLoss:0.4388 | top1:59.4359 | AUROC:0.9862\n",
      "\n",
      "Epoch: [582 | 1000] LR: 0.000156\n",
      "Train | 10/10 | Loss:0.4802 | MainLoss:0.4116 | SPLoss:6.4268 | CLSLoss:0.4388 | top1:80.9000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2842 | MainLoss:0.2156 | SPLoss:6.4268 | CLSLoss:0.4387 | top1:95.7165 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6839 | MainLoss:0.6153 | SPLoss:6.4268 | CLSLoss:0.4387 | top1:59.4359 | AUROC:0.9859\n",
      "\n",
      "Epoch: [583 | 1000] LR: 0.000156\n",
      "Train | 10/10 | Loss:0.4712 | MainLoss:0.4026 | SPLoss:6.4267 | CLSLoss:0.4387 | top1:81.5000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2843 | MainLoss:0.2156 | SPLoss:6.4267 | CLSLoss:0.4387 | top1:95.7196 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6838 | MainLoss:0.6151 | SPLoss:6.4267 | CLSLoss:0.4387 | top1:59.4359 | AUROC:0.9860\n",
      "\n",
      "Epoch: [584 | 1000] LR: 0.000155\n",
      "Train | 10/10 | Loss:0.4704 | MainLoss:0.4017 | SPLoss:6.4267 | CLSLoss:0.4387 | top1:81.6500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2843 | MainLoss:0.2156 | SPLoss:6.4267 | CLSLoss:0.4387 | top1:95.7165 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6838 | MainLoss:0.6151 | SPLoss:6.4267 | CLSLoss:0.4387 | top1:59.4359 | AUROC:0.9861\n",
      "\n",
      "Epoch: [585 | 1000] LR: 0.000155\n",
      "Train | 10/10 | Loss:0.4668 | MainLoss:0.3981 | SPLoss:6.4267 | CLSLoss:0.4387 | top1:81.6500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2843 | MainLoss:0.2156 | SPLoss:6.4266 | CLSLoss:0.4387 | top1:95.7165 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6838 | MainLoss:0.6151 | SPLoss:6.4267 | CLSLoss:0.4387 | top1:59.4359 | AUROC:0.9862\n",
      "\n",
      "Epoch: [586 | 1000] LR: 0.000154\n",
      "Train | 10/10 | Loss:0.4725 | MainLoss:0.4038 | SPLoss:6.4266 | CLSLoss:0.4387 | top1:82.3500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2843 | MainLoss:0.2156 | SPLoss:6.4266 | CLSLoss:0.4387 | top1:95.7165 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6838 | MainLoss:0.6151 | SPLoss:6.4267 | CLSLoss:0.4387 | top1:59.4359 | AUROC:0.9862\n",
      "\n",
      "Epoch: [587 | 1000] LR: 0.000153\n",
      "Train | 10/10 | Loss:0.4702 | MainLoss:0.4016 | SPLoss:6.4266 | CLSLoss:0.4387 | top1:81.9000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2843 | MainLoss:0.2156 | SPLoss:6.4266 | CLSLoss:0.4387 | top1:95.7165 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6838 | MainLoss:0.6151 | SPLoss:6.4266 | CLSLoss:0.4387 | top1:59.4359 | AUROC:0.9864\n",
      "\n",
      "Epoch: [588 | 1000] LR: 0.000153\n",
      "Train | 10/10 | Loss:0.4603 | MainLoss:0.3917 | SPLoss:6.4266 | CLSLoss:0.4387 | top1:82.4500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2843 | MainLoss:0.2157 | SPLoss:6.4266 | CLSLoss:0.4387 | top1:95.7134 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6837 | MainLoss:0.6150 | SPLoss:6.4266 | CLSLoss:0.4387 | top1:59.4487 | AUROC:0.9861\n",
      "\n",
      "Epoch: [589 | 1000] LR: 0.000152\n",
      "Train | 10/10 | Loss:0.4681 | MainLoss:0.3995 | SPLoss:6.4266 | CLSLoss:0.4387 | top1:81.5000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2843 | MainLoss:0.2157 | SPLoss:6.4265 | CLSLoss:0.4388 | top1:95.7134 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6837 | MainLoss:0.6150 | SPLoss:6.4265 | CLSLoss:0.4388 | top1:59.4615 | AUROC:0.9862\n",
      "\n",
      "Epoch: [590 | 1000] LR: 0.000151\n",
      "Train | 10/10 | Loss:0.4657 | MainLoss:0.3970 | SPLoss:6.4266 | CLSLoss:0.4388 | top1:82.3000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2843 | MainLoss:0.2157 | SPLoss:6.4266 | CLSLoss:0.4388 | top1:95.7134 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6837 | MainLoss:0.6151 | SPLoss:6.4266 | CLSLoss:0.4388 | top1:59.4615 | AUROC:0.9862\n",
      "\n",
      "Epoch: [591 | 1000] LR: 0.000151\n",
      "Train | 10/10 | Loss:0.4679 | MainLoss:0.3992 | SPLoss:6.4265 | CLSLoss:0.4388 | top1:81.9500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2844 | MainLoss:0.2157 | SPLoss:6.4265 | CLSLoss:0.4388 | top1:95.7134 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6836 | MainLoss:0.6150 | SPLoss:6.4265 | CLSLoss:0.4388 | top1:59.4615 | AUROC:0.9864\n",
      "\n",
      "Epoch: [592 | 1000] LR: 0.000150\n",
      "Train | 10/10 | Loss:0.4740 | MainLoss:0.4053 | SPLoss:6.4266 | CLSLoss:0.4388 | top1:81.2500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2843 | MainLoss:0.2157 | SPLoss:6.4266 | CLSLoss:0.4388 | top1:95.7134 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6837 | MainLoss:0.6151 | SPLoss:6.4266 | CLSLoss:0.4388 | top1:59.4615 | AUROC:0.9863\n",
      "\n",
      "Epoch: [593 | 1000] LR: 0.000150\n",
      "Train | 10/10 | Loss:0.4634 | MainLoss:0.3948 | SPLoss:6.4266 | CLSLoss:0.4388 | top1:82.5500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2844 | MainLoss:0.2157 | SPLoss:6.4266 | CLSLoss:0.4388 | top1:95.7134 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6836 | MainLoss:0.6150 | SPLoss:6.4265 | CLSLoss:0.4388 | top1:59.4615 | AUROC:0.9861\n",
      "\n",
      "Epoch: [594 | 1000] LR: 0.000149\n",
      "Train | 10/10 | Loss:0.4758 | MainLoss:0.4072 | SPLoss:6.4266 | CLSLoss:0.4388 | top1:81.7500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2844 | MainLoss:0.2157 | SPLoss:6.4266 | CLSLoss:0.4388 | top1:95.7134 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6836 | MainLoss:0.6150 | SPLoss:6.4266 | CLSLoss:0.4388 | top1:59.4615 | AUROC:0.9858\n",
      "\n",
      "Epoch: [595 | 1000] LR: 0.000148\n",
      "Train | 10/10 | Loss:0.4644 | MainLoss:0.3957 | SPLoss:6.4265 | CLSLoss:0.4388 | top1:82.0000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2844 | MainLoss:0.2157 | SPLoss:6.4265 | CLSLoss:0.4388 | top1:95.7165 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6836 | MainLoss:0.6149 | SPLoss:6.4265 | CLSLoss:0.4388 | top1:59.4615 | AUROC:0.9860\n",
      "\n",
      "Epoch: [596 | 1000] LR: 0.000148\n",
      "Train | 10/10 | Loss:0.4753 | MainLoss:0.4066 | SPLoss:6.4265 | CLSLoss:0.4388 | top1:80.9500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2844 | MainLoss:0.2157 | SPLoss:6.4266 | CLSLoss:0.4388 | top1:95.7134 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6836 | MainLoss:0.6150 | SPLoss:6.4266 | CLSLoss:0.4388 | top1:59.4615 | AUROC:0.9862\n",
      "\n",
      "Epoch: [597 | 1000] LR: 0.000147\n",
      "Train | 10/10 | Loss:0.4824 | MainLoss:0.4137 | SPLoss:6.4265 | CLSLoss:0.4388 | top1:81.0500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2844 | MainLoss:0.2157 | SPLoss:6.4266 | CLSLoss:0.4388 | top1:95.7165 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6836 | MainLoss:0.6149 | SPLoss:6.4266 | CLSLoss:0.4388 | top1:59.4615 | AUROC:0.9861\n",
      "\n",
      "Epoch: [598 | 1000] LR: 0.000147\n",
      "Train | 10/10 | Loss:0.4804 | MainLoss:0.4118 | SPLoss:6.4265 | CLSLoss:0.4387 | top1:81.3000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2844 | MainLoss:0.2157 | SPLoss:6.4265 | CLSLoss:0.4387 | top1:95.7134 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6836 | MainLoss:0.6149 | SPLoss:6.4265 | CLSLoss:0.4387 | top1:59.4615 | AUROC:0.9862\n",
      "\n",
      "Epoch: [599 | 1000] LR: 0.000146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 10/10 | Loss:0.4711 | MainLoss:0.4025 | SPLoss:6.4265 | CLSLoss:0.4387 | top1:81.3000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2844 | MainLoss:0.2157 | SPLoss:6.4265 | CLSLoss:0.4387 | top1:95.7134 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6836 | MainLoss:0.6150 | SPLoss:6.4265 | CLSLoss:0.4387 | top1:59.4615 | AUROC:0.9863\n",
      "\n",
      "Epoch: [600 | 1000] LR: 0.000145\n",
      "Train | 10/10 | Loss:0.4650 | MainLoss:0.3963 | SPLoss:6.4265 | CLSLoss:0.4387 | top1:82.4500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2844 | MainLoss:0.2157 | SPLoss:6.4265 | CLSLoss:0.4387 | top1:95.7165 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6836 | MainLoss:0.6149 | SPLoss:6.4265 | CLSLoss:0.4387 | top1:59.4615 | AUROC:0.9862\n",
      "\n",
      "Epoch: [601 | 1000] LR: 0.000145\n",
      "Train | 10/10 | Loss:0.4705 | MainLoss:0.4018 | SPLoss:6.4265 | CLSLoss:0.4387 | top1:81.4500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2843 | MainLoss:0.2157 | SPLoss:6.4266 | CLSLoss:0.4387 | top1:95.7134 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6837 | MainLoss:0.6150 | SPLoss:6.4265 | CLSLoss:0.4387 | top1:59.4615 | AUROC:0.9860\n",
      "\n",
      "Epoch: [602 | 1000] LR: 0.000144\n",
      "Train | 10/10 | Loss:0.4708 | MainLoss:0.4021 | SPLoss:6.4266 | CLSLoss:0.4387 | top1:81.4000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2843 | MainLoss:0.2157 | SPLoss:6.4266 | CLSLoss:0.4387 | top1:95.7134 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6837 | MainLoss:0.6150 | SPLoss:6.4266 | CLSLoss:0.4387 | top1:59.4487 | AUROC:0.9860\n",
      "\n",
      "Epoch: [603 | 1000] LR: 0.000144\n",
      "Train | 10/10 | Loss:0.4601 | MainLoss:0.3915 | SPLoss:6.4266 | CLSLoss:0.4387 | top1:82.2000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2843 | MainLoss:0.2157 | SPLoss:6.4266 | CLSLoss:0.4387 | top1:95.7134 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6837 | MainLoss:0.6150 | SPLoss:6.4266 | CLSLoss:0.4387 | top1:59.4487 | AUROC:0.9862\n",
      "\n",
      "Epoch: [604 | 1000] LR: 0.000143\n",
      "Train | 10/10 | Loss:0.4792 | MainLoss:0.4106 | SPLoss:6.4266 | CLSLoss:0.4387 | top1:81.2500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2843 | MainLoss:0.2157 | SPLoss:6.4267 | CLSLoss:0.4387 | top1:95.7134 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6837 | MainLoss:0.6151 | SPLoss:6.4267 | CLSLoss:0.4387 | top1:59.4487 | AUROC:0.9861\n",
      "\n",
      "Epoch: [605 | 1000] LR: 0.000142\n",
      "Train | 10/10 | Loss:0.4771 | MainLoss:0.4085 | SPLoss:6.4267 | CLSLoss:0.4387 | top1:80.8000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2843 | MainLoss:0.2157 | SPLoss:6.4266 | CLSLoss:0.4387 | top1:95.7134 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6837 | MainLoss:0.6150 | SPLoss:6.4266 | CLSLoss:0.4387 | top1:59.4615 | AUROC:0.9861\n",
      "\n",
      "Epoch: [606 | 1000] LR: 0.000142\n",
      "Train | 10/10 | Loss:0.4784 | MainLoss:0.4097 | SPLoss:6.4266 | CLSLoss:0.4387 | top1:81.0000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2843 | MainLoss:0.2157 | SPLoss:6.4266 | CLSLoss:0.4387 | top1:95.7134 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6837 | MainLoss:0.6150 | SPLoss:6.4266 | CLSLoss:0.4387 | top1:59.4615 | AUROC:0.9863\n",
      "\n",
      "Epoch: [607 | 1000] LR: 0.000141\n",
      "Train | 10/10 | Loss:0.4710 | MainLoss:0.4023 | SPLoss:6.4266 | CLSLoss:0.4387 | top1:81.9000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2844 | MainLoss:0.2157 | SPLoss:6.4266 | CLSLoss:0.4387 | top1:95.7134 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6836 | MainLoss:0.6150 | SPLoss:6.4266 | CLSLoss:0.4387 | top1:59.4487 | AUROC:0.9861\n",
      "\n",
      "Epoch: [608 | 1000] LR: 0.000141\n",
      "Train | 10/10 | Loss:0.4788 | MainLoss:0.4101 | SPLoss:6.4266 | CLSLoss:0.4387 | top1:81.3000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2844 | MainLoss:0.2157 | SPLoss:6.4266 | CLSLoss:0.4387 | top1:95.7134 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6836 | MainLoss:0.6150 | SPLoss:6.4267 | CLSLoss:0.4387 | top1:59.4487 | AUROC:0.9862\n",
      "\n",
      "Epoch: [609 | 1000] LR: 0.000140\n",
      "Train | 10/10 | Loss:0.4799 | MainLoss:0.4112 | SPLoss:6.4267 | CLSLoss:0.4387 | top1:80.8500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2843 | MainLoss:0.2156 | SPLoss:6.4268 | CLSLoss:0.4387 | top1:95.7134 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6838 | MainLoss:0.6151 | SPLoss:6.4268 | CLSLoss:0.4387 | top1:59.4359 | AUROC:0.9862\n",
      "\n",
      "Epoch: [610 | 1000] LR: 0.000139\n",
      "Train | 10/10 | Loss:0.4761 | MainLoss:0.4075 | SPLoss:6.4268 | CLSLoss:0.4387 | top1:81.1000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2843 | MainLoss:0.2156 | SPLoss:6.4268 | CLSLoss:0.4387 | top1:95.7134 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6838 | MainLoss:0.6151 | SPLoss:6.4268 | CLSLoss:0.4387 | top1:59.4359 | AUROC:0.9861\n",
      "\n",
      "Epoch: [611 | 1000] LR: 0.000139\n",
      "Train | 10/10 | Loss:0.4817 | MainLoss:0.4130 | SPLoss:6.4269 | CLSLoss:0.4387 | top1:80.8000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2842 | MainLoss:0.2156 | SPLoss:6.4269 | CLSLoss:0.4387 | top1:95.7165 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6839 | MainLoss:0.6153 | SPLoss:6.4269 | CLSLoss:0.4387 | top1:59.4231 | AUROC:0.9860\n",
      "\n",
      "Epoch: [612 | 1000] LR: 0.000138\n",
      "Train | 10/10 | Loss:0.4820 | MainLoss:0.4133 | SPLoss:6.4269 | CLSLoss:0.4387 | top1:81.0500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2842 | MainLoss:0.2156 | SPLoss:6.4269 | CLSLoss:0.4386 | top1:95.7134 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6839 | MainLoss:0.6152 | SPLoss:6.4269 | CLSLoss:0.4386 | top1:59.4231 | AUROC:0.9865\n",
      "\n",
      "Epoch: [613 | 1000] LR: 0.000138\n",
      "Train | 10/10 | Loss:0.4652 | MainLoss:0.3965 | SPLoss:6.4269 | CLSLoss:0.4386 | top1:82.3500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2843 | MainLoss:0.2156 | SPLoss:6.4269 | CLSLoss:0.4387 | top1:95.7134 | AUROC:0.9921\n",
      "Test | 39/10 | Loss:0.6838 | MainLoss:0.6151 | SPLoss:6.4268 | CLSLoss:0.4387 | top1:59.4359 | AUROC:0.9863\n",
      "\n",
      "Epoch: [614 | 1000] LR: 0.000137\n",
      "Train | 10/10 | Loss:0.4678 | MainLoss:0.3991 | SPLoss:6.4268 | CLSLoss:0.4387 | top1:81.5000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2843 | MainLoss:0.2156 | SPLoss:6.4269 | CLSLoss:0.4387 | top1:95.7134 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6838 | MainLoss:0.6151 | SPLoss:6.4268 | CLSLoss:0.4387 | top1:59.4359 | AUROC:0.9861\n",
      "\n",
      "Epoch: [615 | 1000] LR: 0.000136\n",
      "Train | 10/10 | Loss:0.4702 | MainLoss:0.4015 | SPLoss:6.4268 | CLSLoss:0.4387 | top1:81.5000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2843 | MainLoss:0.2157 | SPLoss:6.4268 | CLSLoss:0.4387 | top1:95.7134 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6837 | MainLoss:0.6151 | SPLoss:6.4268 | CLSLoss:0.4387 | top1:59.4359 | AUROC:0.9861\n",
      "\n",
      "Epoch: [616 | 1000] LR: 0.000136\n",
      "Train | 10/10 | Loss:0.4591 | MainLoss:0.3905 | SPLoss:6.4268 | CLSLoss:0.4387 | top1:82.3000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2843 | MainLoss:0.2157 | SPLoss:6.4267 | CLSLoss:0.4387 | top1:95.7134 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6837 | MainLoss:0.6150 | SPLoss:6.4268 | CLSLoss:0.4387 | top1:59.4487 | AUROC:0.9861\n",
      "\n",
      "Epoch: [617 | 1000] LR: 0.000135\n",
      "Train | 10/10 | Loss:0.4674 | MainLoss:0.3988 | SPLoss:6.4267 | CLSLoss:0.4387 | top1:82.0500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2844 | MainLoss:0.2157 | SPLoss:6.4267 | CLSLoss:0.4387 | top1:95.7134 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6837 | MainLoss:0.6150 | SPLoss:6.4267 | CLSLoss:0.4387 | top1:59.4487 | AUROC:0.9863\n",
      "\n",
      "Epoch: [618 | 1000] LR: 0.000135\n",
      "Train | 10/10 | Loss:0.4593 | MainLoss:0.3907 | SPLoss:6.4267 | CLSLoss:0.4387 | top1:82.0000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2843 | MainLoss:0.2157 | SPLoss:6.4268 | CLSLoss:0.4387 | top1:95.7134 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6837 | MainLoss:0.6150 | SPLoss:6.4268 | CLSLoss:0.4387 | top1:59.4487 | AUROC:0.9861\n",
      "\n",
      "Epoch: [619 | 1000] LR: 0.000134\n",
      "Train | 10/10 | Loss:0.4687 | MainLoss:0.4001 | SPLoss:6.4268 | CLSLoss:0.4387 | top1:81.9500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2844 | MainLoss:0.2157 | SPLoss:6.4267 | CLSLoss:0.4387 | top1:95.7134 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6837 | MainLoss:0.6150 | SPLoss:6.4267 | CLSLoss:0.4387 | top1:59.4487 | AUROC:0.9863\n",
      "\n",
      "Epoch: [620 | 1000] LR: 0.000133\n",
      "Train | 10/10 | Loss:0.4743 | MainLoss:0.4057 | SPLoss:6.4268 | CLSLoss:0.4387 | top1:81.4000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2843 | MainLoss:0.2157 | SPLoss:6.4267 | CLSLoss:0.4387 | top1:95.7134 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6837 | MainLoss:0.6150 | SPLoss:6.4268 | CLSLoss:0.4387 | top1:59.4487 | AUROC:0.9863\n",
      "\n",
      "Epoch: [621 | 1000] LR: 0.000133\n",
      "Train | 10/10 | Loss:0.4770 | MainLoss:0.4084 | SPLoss:6.4267 | CLSLoss:0.4387 | top1:81.4500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2844 | MainLoss:0.2157 | SPLoss:6.4267 | CLSLoss:0.4387 | top1:95.7134 | AUROC:0.9922\n",
      "Test | 39/10 | Loss:0.6837 | MainLoss:0.6150 | SPLoss:6.4267 | CLSLoss:0.4387 | top1:59.4487 | AUROC:0.9862\n",
      "\n",
      "Epoch: [622 | 1000] LR: 0.000132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 10/10 | Loss:0.4706 | MainLoss:0.4020 | SPLoss:6.4268 | CLSLoss:0.4387 | top1:81.1500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2843 | MainLoss:0.2157 | SPLoss:6.4268 | CLSLoss:0.4387 | top1:95.7134 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6837 | MainLoss:0.6151 | SPLoss:6.4268 | CLSLoss:0.4387 | top1:59.4487 | AUROC:0.9864\n",
      "\n",
      "Epoch: [623 | 1000] LR: 0.000132\n",
      "Train | 10/10 | Loss:0.4722 | MainLoss:0.4036 | SPLoss:6.4268 | CLSLoss:0.4387 | top1:81.0500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2843 | MainLoss:0.2157 | SPLoss:6.4268 | CLSLoss:0.4387 | top1:95.7134 | AUROC:0.9921\n",
      "Test | 39/10 | Loss:0.6837 | MainLoss:0.6151 | SPLoss:6.4268 | CLSLoss:0.4387 | top1:59.4487 | AUROC:0.9861\n",
      "\n",
      "Epoch: [624 | 1000] LR: 0.000131\n",
      "Train | 10/10 | Loss:0.4588 | MainLoss:0.3901 | SPLoss:6.4268 | CLSLoss:0.4387 | top1:82.5000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2843 | MainLoss:0.2157 | SPLoss:6.4268 | CLSLoss:0.4387 | top1:95.7134 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6837 | MainLoss:0.6151 | SPLoss:6.4268 | CLSLoss:0.4387 | top1:59.4487 | AUROC:0.9862\n",
      "\n",
      "Epoch: [625 | 1000] LR: 0.000130\n",
      "Train | 10/10 | Loss:0.4612 | MainLoss:0.3925 | SPLoss:6.4268 | CLSLoss:0.4387 | top1:81.6000 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2844 | MainLoss:0.2157 | SPLoss:6.4268 | CLSLoss:0.4387 | top1:95.7134 | AUROC:0.9924\n",
      "Test | 39/10 | Loss:0.6837 | MainLoss:0.6150 | SPLoss:6.4268 | CLSLoss:0.4387 | top1:59.4487 | AUROC:0.9862\n",
      "\n",
      "Epoch: [626 | 1000] LR: 0.000130\n",
      "Train | 10/10 | Loss:0.4697 | MainLoss:0.4011 | SPLoss:6.4267 | CLSLoss:0.4387 | top1:81.8500 | AUROC:0.0000\n",
      "Test | 161/10 | Loss:0.2844 | MainLoss:0.2157 | SPLoss:6.4267 | CLSLoss:0.4387 | top1:95.7134 | AUROC:0.9923\n",
      "Test | 39/10 | Loss:0.6836 | MainLoss:0.6150 | SPLoss:6.4267 | CLSLoss:0.4387 | top1:59.4487 | AUROC:0.9861\n",
      "\n",
      "Epoch: [627 | 1000] LR: 0.000129\n",
      "Train | 10/10 | Loss:0.4618 | MainLoss:0.3931 | SPLoss:6.4267 | CLSLoss:0.4387 | top1:81.6500 | AUROC:0.0000\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(start_epoch, epochs):\n",
    "    state['lr'] = optimizer.state_dict()['param_groups'][0]['lr']\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "    print('\\nEpoch: [%d | %d] LR: %f' % (epoch + 1, epochs, state['lr']))\n",
    "    \n",
    "    train_loss, train_acc, train_auroc = train(train_loader, student_model, criterion, optimizer, epoch, use_cuda)\n",
    "    test_loss, test_acc, test_auroc = test(val_target_loader, student_model, criterion, epoch, use_cuda)\n",
    "    source_loss, source_acc, source_auroc = test(val_source_loader, student_model, criterion, epoch, use_cuda)\n",
    "\n",
    "\n",
    "    logger.append([state['lr'], train_loss, test_loss,  source_loss, train_acc, test_acc,source_acc, train_auroc, test_auroc, source_auroc])\n",
    "    is_best = test_acc > best_acc\n",
    "    best_acc = max(test_acc, best_acc)\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'state_dict' : student_model.state_dict(),\n",
    "        'acc': test_acc,\n",
    "        'best_acc': best_acc,\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    }, is_best, checkpoint=checkpoint)\n",
    "    scheduler_warmup.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
