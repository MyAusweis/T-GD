{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import collections\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "\n",
    "from model_pytorch import EfficientNet\n",
    "from utils import Bar,Logger, AverageMeter, accuracy, mkdir_p, savefig\n",
    "from warmup_scheduler import GradualWarmupScheduler\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "import cv2\n",
    "\n",
    "from PIL import ImageFile, ImageOps\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU device 1: True\n"
     ]
    }
   ],
   "source": [
    "# GPU Device\n",
    "gpu_id = 1\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(\"GPU device %d:\" %(gpu_id), use_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = '/media/data2/dataset/GAN_ImageData/PGGAN_128/'\n",
    "target_dir = '/media/data2/dataset/GAN_ImageData/StyleGAN_256/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained = './log/pggan/128/b0/aug/checkpoint.pth.tar'\n",
    "resume = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model_name = 'efficientnet-b0' # b0-b7 scale\n",
    "\n",
    "# Optimization\n",
    "num_classes = 2\n",
    "epochs = 1000\n",
    "start_epoch = 0\n",
    "train_batch = 200\n",
    "test_batch = 200\n",
    "lr = 0.01\n",
    "schedule = [50, 250, 500, 750]\n",
    "momentum = 0.1\n",
    "gamma = 0.1 # LR is multiplied by gamma on schedule\n",
    "\n",
    "# CheckPoint\n",
    "checkpoint = './log/pggan/128/b0/to_style1/2000shot/general' # dir\n",
    "if not os.path.isdir(checkpoint):\n",
    "    os.makedirs(checkpoint)\n",
    "num_workers = 8\n",
    "\n",
    "# Seed\n",
    "manual_seed = 7\n",
    "random.seed(manual_seed)\n",
    "torch.cuda.manual_seed_all(manual_seed)\n",
    "\n",
    "# Image\n",
    "size = (128, 128)\n",
    "\n",
    "# cutmix\n",
    "cm_prob = 0.2\n",
    "cm_beta = 1.0\n",
    "\n",
    "# augmentation\n",
    "blur_prob = 0.2\n",
    "blog_sig = 0.5\n",
    "jpg_prob = 0.2\n",
    "\n",
    "best_acc = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {}\n",
    "state['num_classes'] = num_classes\n",
    "state['epochs'] = epochs\n",
    "state['start_epoch'] = start_epoch\n",
    "state['train_batch'] = train_batch\n",
    "state['test_batch'] = test_batch\n",
    "state['lr'] = lr\n",
    "state['schedule'] = schedule\n",
    "state['momentum'] = momentum\n",
    "state['gamma'] = gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_augment(img):\n",
    "    img = np.array(img)\n",
    "\n",
    "    if random.random() < blur_prob:\n",
    "        sig = np.random.uniform(0.0, 3.0)\n",
    "        gaussian_blur(img, sig)\n",
    "\n",
    "    if random.random() < jpg_prob:\n",
    "        qual = np.random.uniform(30.0, 100.0)\n",
    "        img = cv2_jpg(img, qual)\n",
    "\n",
    "    return Image.fromarray(img)\n",
    "\n",
    "\n",
    "def gaussian_blur(img, sigma):\n",
    "    gaussian_filter(img[:,:,0], output=img[:,:,0], sigma=sigma)\n",
    "    gaussian_filter(img[:,:,1], output=img[:,:,1], sigma=sigma)\n",
    "    gaussian_filter(img[:,:,2], output=img[:,:,2], sigma=sigma)\n",
    "\n",
    "\n",
    "def cv2_jpg(img, compress_val):\n",
    "    img_cv2 = img[:,:,::-1]\n",
    "    encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), compress_val]\n",
    "    result, encimg = cv2.imencode('.jpg', img_cv2, encode_param)\n",
    "    decimg = cv2.imdecode(encimg, 1)\n",
    "    return decimg[:,:,::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_bbox(size, lam):\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = np.int(W * cut_rat)\n",
    "    cut_h = np.int(H * cut_rat)\n",
    "\n",
    "    # uniform\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join(source_dir, 'style1/2000_shot_only')\n",
    "val_target_dir = os.path.join(target_dir, 'validation')\n",
    "val_source_dir = os.path.join(source_dir, 'validation')\n",
    "\n",
    "train_aug = transforms.Compose([\n",
    "    transforms.Lambda(lambda img: data_augment(img)),\n",
    "    transforms.Resize(size),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "#     transforms.RandomErasing(p=0.3, scale=(0.02, 0.10), ratio=(0.3, 3.3), value=0, inplace=True),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "val_aug = transforms.Compose([\n",
    "    transforms.Resize(size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# pin_memory : cuda pin memeory use\n",
    "train_loader = DataLoader(datasets.ImageFolder(train_dir, transform=train_aug),\n",
    "                          batch_size=train_batch, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "val_target_loader = DataLoader(datasets.ImageFolder(val_target_dir, val_aug),\n",
    "                       batch_size=test_batch, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "val_source_loader = DataLoader(datasets.ImageFolder(val_source_dir, val_aug),\n",
    "                       batch_size=test_batch, shuffle=True, num_workers=num_workers, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> using pre-trained model './log/pggan/128/b0/aug/checkpoint.pth.tar'\n"
     ]
    }
   ],
   "source": [
    "student_model = EfficientNet.from_name(model_name, num_classes=num_classes,\n",
    "                              override_params={'dropout_rate':0.2, 'drop_connect_rate':0.2})\n",
    "\n",
    "# Pre-trained\n",
    "if pretrained:\n",
    "    print(\"=> using pre-trained model '{}'\".format(pretrained))\n",
    "    student_model.load_state_dict(torch.load(pretrained)['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Total params: 4.01M\n"
     ]
    }
   ],
   "source": [
    "student_model.to('cuda')\n",
    "cudnn.benchmark = True\n",
    "print('    Total params: %.2fM' % (sum(p.numel() for p in student_model.parameters())/1000000.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, param in enumerate(student_model.parameters()):\n",
    "    param.reqiures_grad = False\n",
    "    if idx == 182:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = optim.SGD(student_model.parameters(), lr=lr, momentum=momentum)\n",
    "# optimizer = optim.Adam(student_model.parameters())\n",
    "scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)\n",
    "scheduler_warmup = GradualWarmupScheduler(optimizer, multiplier=4, total_epoch=10, after_scheduler=scheduler_cosine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resume\n",
    "if resume:\n",
    "    print('==> Resuming from checkpoint..')\n",
    "    checkpoint = os.path.dirname(resume)\n",
    "#     checkpoint = torch.load(resume)\n",
    "    resume = torch.load(resume)\n",
    "    best_acc = resume['best_acc']\n",
    "    start_epoch = resume['epoch']\n",
    "    student_model.load_state_dict(resume['state_dict'])\n",
    "    optimizer.load_state_dict(resume['optimizer'])\n",
    "    logger = Logger(os.path.join(checkpoint, 'log.txt'), resume=True)\n",
    "else:\n",
    "    logger = Logger(os.path.join(checkpoint, 'log.txt'))\n",
    "    logger.set_names(['Learning Rate', 'Train Loss', 'Valid Loss', 'Source Loss', 'Train Acc.', 'Valid Acc.', 'Source ACC.', 'Train AUROC', 'Valid AUROC', 'Source AUROC'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch, use_cuda):\n",
    "    model.train()\n",
    "    \n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    arc = AverageMeter()\n",
    "    end = time.time()\n",
    "    cls_losses = AverageMeter()\n",
    "    sp_losses = AverageMeter()\n",
    "    main_losses = AverageMeter()\n",
    "    \n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        batch_size = inputs.size(0)\n",
    "        if batch_size < train_batch:\n",
    "            continue\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            \n",
    "        r = np.random.rand(1)\n",
    "        if cm_beta > 0 and r < cm_prob:\n",
    "            \n",
    "            rand_index = torch.randperm(inputs.size()[0]).cuda()\n",
    "            tt= targets[rand_index]\n",
    "            boolean = targets==tt\n",
    "            rand_index = rand_index[boolean]\n",
    "            lam = np.random.beta(cm_beta, cm_beta)\n",
    "            bbx1, bby1, bbx2, bby2 = rand_bbox(inputs.size(), lam)\n",
    "            inputs[boolean, :, bbx1:bbx2, bby1:bby2] = inputs[rand_index, :, bbx1:bbx2, bby1:bby2]\n",
    "\n",
    "        # compute output\n",
    "        outputs = model(inputs)\n",
    "        loss_main = criterion(outputs, targets)\n",
    "        loss =  loss_main\n",
    "        loss_cls = 0\n",
    "        loss_sp = 0\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1 = accuracy(outputs.data, targets.data)\n",
    "#         auroc = roc_auc_score(targets.cpu().detach().numpy(), outputs.cpu().detach().numpy()[:,1])\n",
    "        losses.update(loss.data.tolist(), inputs.size(0))\n",
    "        top1.update(prec1[0], inputs.size(0))\n",
    "#         arc.update(auroc, inputs.size(0))\n",
    "        cls_losses.update(loss_cls, inputs.size(0))\n",
    "        sp_losses.update(loss_sp, inputs.size(0))\n",
    "        main_losses.update(loss_main.tolist(), inputs.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        \n",
    "#         if batch_idx % 100 == 0:\n",
    "#             print('{batch}/{size} | Loss:{loss:.4f} | MainLoss:{main:.4f} | SPLoss:{sp:.4f} | CLSLoss:{cls:.4f} | top1:{tp1:.4f} | AUROC:{ac:.4f}'.format(\n",
    "#                      batch=batch_idx+1, size=len(train_loader), loss=losses.avg, main=main_losses.avg, sp=sp_losses.avg, cls=cls_losses.avg, tp1=top1.avg, ac=arc.avg))\n",
    "    print('Train | {batch}/{size} | Loss:{loss:.4f} | MainLoss:{main:.4f} | SPLoss:{sp:.4f} | CLSLoss:{cls:.4f} | top1:{tp1:.4f} | AUROC:{ac:.4f}'.format(\n",
    "                     batch=batch_idx+1, size=len(train_loader), loss=losses.avg, main=main_losses.avg, sp=sp_losses.avg, cls=cls_losses.avg, tp1=top1.avg, ac=arc.avg))\n",
    "    return (losses.avg, top1.avg, arc.avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(val_loader, model, criterion, epoch, use_cuda):\n",
    "    global best_acc\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    arc = AverageMeter()\n",
    "    cls_losses = AverageMeter()\n",
    "    sp_losses = AverageMeter()\n",
    "    main_losses = AverageMeter()\n",
    "\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(val_loader):\n",
    "            # measure data loading time\n",
    "            data_time.update(time.time() - end)\n",
    "\n",
    "            if use_cuda:\n",
    "                inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "            # compute output\n",
    "            outputs = model(inputs)\n",
    "            loss_main = criterion(outputs, targets)\n",
    "            loss = loss_main\n",
    "            loss_cls = 0\n",
    "            loss_sp = 0\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            prec1 = accuracy(outputs.data, targets.data)\n",
    "            auroc = roc_auc_score(targets.cpu().detach().numpy(), outputs.cpu().detach().numpy()[:,1])\n",
    "            losses.update(loss.data.tolist(), inputs.size(0))\n",
    "            top1.update(prec1[0], inputs.size(0))\n",
    "            arc.update(auroc, inputs.size(0))\n",
    "            cls_losses.update(loss_cls, inputs.size(0))\n",
    "            sp_losses.update(loss_sp, inputs.size(0))\n",
    "            main_losses.update(loss_main.tolist(), inputs.size(0))\n",
    "\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "    print('Test | {batch}/{size} | Loss:{loss:.4f} | MainLoss:{main:.4f} | SPLoss:{sp:.4f} | CLSLoss:{cls:.4f} | top1:{tp1:.4f} | AUROC:{ac:.4f}'.format(\n",
    "                     batch=batch_idx+1, size=len(train_loader), loss=losses.avg, main=main_losses.avg, sp=sp_losses.avg, cls=cls_losses.avg, tp1=top1.avg, ac=arc.avg))\n",
    "    return (losses.avg, top1.avg, arc.avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, checkpoint='checkpoint', filename='checkpoint.pth.tar'):\n",
    "    filepath = os.path.join(checkpoint, filename)\n",
    "    torch.save(state, filepath)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filepath, os.path.join(checkpoint, 'model_best.pth.tar'))\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    global state\n",
    "    lr_set = [1, 1e-1, 1e-2, 1e-3, 1e-4, 1e-5]\n",
    "    lr_list = schedule.copy()\n",
    "    lr_list.append(epoch)\n",
    "    lr_list.sort()\n",
    "    idx = lr_list.index(epoch)\n",
    "    state['lr'] *= lr_set[idx]\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = state['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [1 | 1000] LR: 0.010000\n",
      "Train | 20/20 | Loss:1.0094 | MainLoss:1.0094 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:51.6500 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.7066 | MainLoss:0.7066 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:52.7179 | AUROC:0.5373\n",
      "Test | 161/20 | Loss:0.0597 | MainLoss:0.0597 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.9408 | AUROC:1.0000\n",
      "\n",
      "Epoch: [2 | 1000] LR: 0.013000\n",
      "Train | 20/20 | Loss:0.6927 | MainLoss:0.6927 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:54.7000 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.6928 | MainLoss:0.6928 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:53.8333 | AUROC:0.5510\n",
      "Test | 161/20 | Loss:0.1025 | MainLoss:0.1025 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.9595 | AUROC:1.0000\n",
      "\n",
      "Epoch: [3 | 1000] LR: 0.016000\n",
      "Train | 20/20 | Loss:0.6869 | MainLoss:0.6869 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:54.3500 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.6875 | MainLoss:0.6875 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:54.3718 | AUROC:0.5654\n",
      "Test | 161/20 | Loss:0.1268 | MainLoss:0.1268 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.9564 | AUROC:1.0000\n",
      "\n",
      "Epoch: [4 | 1000] LR: 0.019000\n",
      "Train | 20/20 | Loss:0.6800 | MainLoss:0.6800 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:55.7000 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.6827 | MainLoss:0.6827 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:55.5385 | AUROC:0.5818\n",
      "Test | 161/20 | Loss:0.1184 | MainLoss:0.1184 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.9595 | AUROC:1.0000\n",
      "\n",
      "Epoch: [5 | 1000] LR: 0.022000\n",
      "Train | 20/20 | Loss:0.6722 | MainLoss:0.6722 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:58.1500 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.6761 | MainLoss:0.6761 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:57.0897 | AUROC:0.6050\n",
      "Test | 161/20 | Loss:0.0942 | MainLoss:0.0942 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.9564 | AUROC:1.0000\n",
      "\n",
      "Epoch: [6 | 1000] LR: 0.025000\n",
      "Train | 20/20 | Loss:0.6651 | MainLoss:0.6651 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:59.5500 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.6667 | MainLoss:0.6667 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:59.0513 | AUROC:0.6313\n",
      "Test | 161/20 | Loss:0.0781 | MainLoss:0.0781 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.9034 | AUROC:1.0000\n",
      "\n",
      "Epoch: [7 | 1000] LR: 0.028000\n",
      "Train | 20/20 | Loss:0.6458 | MainLoss:0.6458 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:61.5000 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.6501 | MainLoss:0.6501 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:61.7564 | AUROC:0.6704\n",
      "Test | 161/20 | Loss:0.0413 | MainLoss:0.0413 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.8879 | AUROC:1.0000\n",
      "\n",
      "Epoch: [8 | 1000] LR: 0.031000\n",
      "Train | 20/20 | Loss:0.6155 | MainLoss:0.6155 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:65.7250 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.6226 | MainLoss:0.6226 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:65.2821 | AUROC:0.7144\n",
      "Test | 161/20 | Loss:0.0294 | MainLoss:0.0294 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.7944 | AUROC:1.0000\n",
      "\n",
      "Epoch: [9 | 1000] LR: 0.034000\n",
      "Train | 20/20 | Loss:0.5705 | MainLoss:0.5705 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:70.3000 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.5630 | MainLoss:0.5630 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:70.5769 | AUROC:0.7807\n",
      "Test | 161/20 | Loss:0.0335 | MainLoss:0.0335 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.6511 | AUROC:1.0000\n",
      "\n",
      "Epoch: [10 | 1000] LR: 0.037000\n",
      "Train | 20/20 | Loss:0.4871 | MainLoss:0.4871 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:75.8000 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.4954 | MainLoss:0.4954 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:76.2564 | AUROC:0.8431\n",
      "Test | 161/20 | Loss:0.0304 | MainLoss:0.0304 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.3084 | AUROC:1.0000\n",
      "\n",
      "Epoch: [11 | 1000] LR: 0.040000\n",
      "Train | 20/20 | Loss:0.4040 | MainLoss:0.4040 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:81.1500 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.5063 | MainLoss:0.5063 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:74.8205 | AUROC:0.8944\n",
      "Test | 161/20 | Loss:0.1471 | MainLoss:0.1471 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:93.9688 | AUROC:0.9999\n",
      "\n",
      "Epoch: [12 | 1000] LR: 0.040000\n",
      "Train | 20/20 | Loss:0.3235 | MainLoss:0.3235 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:86.1000 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.3444 | MainLoss:0.3444 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:85.4487 | AUROC:0.9294\n",
      "Test | 161/20 | Loss:0.0943 | MainLoss:0.0943 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.2492 | AUROC:0.9997\n",
      "\n",
      "Epoch: [13 | 1000] LR: 0.040000\n",
      "Train | 20/20 | Loss:0.2579 | MainLoss:0.2579 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:89.0500 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.3253 | MainLoss:0.3253 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:85.8462 | AUROC:0.9465\n",
      "Test | 161/20 | Loss:0.2261 | MainLoss:0.2261 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:90.2337 | AUROC:0.9995\n",
      "\n",
      "Epoch: [14 | 1000] LR: 0.040000\n",
      "Train | 20/20 | Loss:0.1974 | MainLoss:0.1974 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:92.1500 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.2715 | MainLoss:0.2715 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:89.2564 | AUROC:0.9594\n",
      "Test | 161/20 | Loss:0.2041 | MainLoss:0.2041 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:91.7695 | AUROC:0.9993\n",
      "\n",
      "Epoch: [15 | 1000] LR: 0.039999\n",
      "Train | 20/20 | Loss:0.1651 | MainLoss:0.1651 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:93.3500 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.2782 | MainLoss:0.2782 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:89.5769 | AUROC:0.9680\n",
      "Test | 161/20 | Loss:0.2109 | MainLoss:0.2109 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:91.3707 | AUROC:0.9984\n",
      "\n",
      "Epoch: [16 | 1000] LR: 0.039998\n",
      "Train | 20/20 | Loss:0.1201 | MainLoss:0.1201 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:95.4750 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.2595 | MainLoss:0.2595 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:91.2179 | AUROC:0.9715\n",
      "Test | 161/20 | Loss:0.3160 | MainLoss:0.3160 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:89.0685 | AUROC:0.9983\n",
      "\n",
      "Epoch: [17 | 1000] LR: 0.039998\n",
      "Train | 20/20 | Loss:0.0988 | MainLoss:0.0988 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.3750 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.2336 | MainLoss:0.2336 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:91.9744 | AUROC:0.9748\n",
      "Test | 161/20 | Loss:0.4925 | MainLoss:0.4925 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:85.1776 | AUROC:0.9973\n",
      "\n",
      "Epoch: [18 | 1000] LR: 0.039996\n",
      "Train | 20/20 | Loss:0.0920 | MainLoss:0.0920 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.5250 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.2131 | MainLoss:0.2131 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:92.1026 | AUROC:0.9773\n",
      "Test | 161/20 | Loss:0.7014 | MainLoss:0.7014 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:79.4548 | AUROC:0.9967\n",
      "\n",
      "Epoch: [19 | 1000] LR: 0.039995\n",
      "Train | 20/20 | Loss:0.0686 | MainLoss:0.0686 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:97.7000 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.2262 | MainLoss:0.2262 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:92.4744 | AUROC:0.9787\n",
      "Test | 161/20 | Loss:0.6294 | MainLoss:0.6294 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:82.5826 | AUROC:0.9954\n",
      "\n",
      "Epoch: [20 | 1000] LR: 0.039994\n",
      "Train | 20/20 | Loss:0.0467 | MainLoss:0.0467 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:98.3250 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.2674 | MainLoss:0.2674 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:91.4231 | AUROC:0.9783\n",
      "Test | 161/20 | Loss:1.1320 | MainLoss:1.1320 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:73.5202 | AUROC:0.9945\n",
      "\n",
      "Epoch: [21 | 1000] LR: 0.039992\n",
      "Train | 20/20 | Loss:0.0538 | MainLoss:0.0538 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:98.0750 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.2119 | MainLoss:0.2119 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:93.0256 | AUROC:0.9809\n",
      "Test | 161/20 | Loss:0.8842 | MainLoss:0.8842 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:77.6075 | AUROC:0.9942\n",
      "\n",
      "Epoch: [22 | 1000] LR: 0.039990\n",
      "Train | 20/20 | Loss:0.0594 | MainLoss:0.0594 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:97.9750 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.2090 | MainLoss:0.2090 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:93.3077 | AUROC:0.9825\n",
      "Test | 161/20 | Loss:0.8685 | MainLoss:0.8685 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:77.5016 | AUROC:0.9921\n",
      "\n",
      "Epoch: [23 | 1000] LR: 0.039988\n",
      "Train | 20/20 | Loss:0.0534 | MainLoss:0.0534 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:98.1750 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.3233 | MainLoss:0.3233 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:89.8974 | AUROC:0.9829\n",
      "Test | 161/20 | Loss:1.7190 | MainLoss:1.7190 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:64.1059 | AUROC:0.9914\n",
      "\n",
      "Epoch: [24 | 1000] LR: 0.039986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 20/20 | Loss:0.0438 | MainLoss:0.0438 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:98.3750 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1930 | MainLoss:0.1930 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:93.8205 | AUROC:0.9841\n",
      "Test | 161/20 | Loss:1.1062 | MainLoss:1.1062 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:73.8847 | AUROC:0.9872\n",
      "\n",
      "Epoch: [25 | 1000] LR: 0.039983\n",
      "Train | 20/20 | Loss:0.0506 | MainLoss:0.0506 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:98.3500 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1767 | MainLoss:0.1767 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:94.0897 | AUROC:0.9857\n",
      "Test | 161/20 | Loss:1.3655 | MainLoss:1.3655 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:69.1090 | AUROC:0.9734\n",
      "\n",
      "Epoch: [26 | 1000] LR: 0.039981\n",
      "Train | 20/20 | Loss:0.0441 | MainLoss:0.0441 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:98.5000 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1706 | MainLoss:0.1706 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:94.1282 | AUROC:0.9872\n",
      "Test | 161/20 | Loss:1.2779 | MainLoss:1.2779 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:70.7321 | AUROC:0.9735\n",
      "\n",
      "Epoch: [27 | 1000] LR: 0.039978\n",
      "Train | 20/20 | Loss:0.0429 | MainLoss:0.0429 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:98.5750 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1687 | MainLoss:0.1687 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:94.4615 | AUROC:0.9868\n",
      "Test | 161/20 | Loss:1.3039 | MainLoss:1.3039 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:70.3396 | AUROC:0.9725\n",
      "\n",
      "Epoch: [28 | 1000] LR: 0.039975\n",
      "Train | 20/20 | Loss:0.0326 | MainLoss:0.0326 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:98.9500 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1846 | MainLoss:0.1846 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:93.9744 | AUROC:0.9875\n",
      "Test | 161/20 | Loss:1.1813 | MainLoss:1.1813 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:72.9564 | AUROC:0.9699\n",
      "\n",
      "Epoch: [29 | 1000] LR: 0.039971\n",
      "Train | 20/20 | Loss:0.0258 | MainLoss:0.0258 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.2250 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1903 | MainLoss:0.1903 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:94.1154 | AUROC:0.9880\n",
      "Test | 161/20 | Loss:1.2033 | MainLoss:1.2033 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:73.1589 | AUROC:0.9743\n",
      "\n",
      "Epoch: [30 | 1000] LR: 0.039968\n",
      "Train | 20/20 | Loss:0.0313 | MainLoss:0.0313 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.1000 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1680 | MainLoss:0.1680 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:94.6667 | AUROC:0.9884\n",
      "Test | 161/20 | Loss:1.5204 | MainLoss:1.5204 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:68.0841 | AUROC:0.9635\n",
      "\n",
      "Epoch: [31 | 1000] LR: 0.039964\n",
      "Train | 20/20 | Loss:0.0289 | MainLoss:0.0289 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.0750 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.2209 | MainLoss:0.2209 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:93.4359 | AUROC:0.9888\n",
      "Test | 161/20 | Loss:1.1915 | MainLoss:1.1915 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:73.7352 | AUROC:0.9655\n",
      "\n",
      "Epoch: [32 | 1000] LR: 0.039961\n",
      "Train | 20/20 | Loss:0.0276 | MainLoss:0.0276 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.2250 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1750 | MainLoss:0.1750 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:94.5641 | AUROC:0.9887\n",
      "Test | 161/20 | Loss:1.4171 | MainLoss:1.4171 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:70.6417 | AUROC:0.9682\n",
      "\n",
      "Epoch: [33 | 1000] LR: 0.039956\n",
      "Train | 20/20 | Loss:0.0191 | MainLoss:0.0191 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.3250 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1693 | MainLoss:0.1693 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:95.1026 | AUROC:0.9890\n",
      "Test | 161/20 | Loss:1.7234 | MainLoss:1.7234 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:67.3863 | AUROC:0.9623\n",
      "\n",
      "Epoch: [34 | 1000] LR: 0.039952\n",
      "Train | 20/20 | Loss:0.0183 | MainLoss:0.0183 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.4250 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1678 | MainLoss:0.1678 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:95.1538 | AUROC:0.9894\n",
      "Test | 161/20 | Loss:1.7488 | MainLoss:1.7488 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:67.2087 | AUROC:0.9658\n",
      "\n",
      "Epoch: [35 | 1000] LR: 0.039948\n",
      "Train | 20/20 | Loss:0.0296 | MainLoss:0.0296 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.0250 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1788 | MainLoss:0.1788 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:94.5769 | AUROC:0.9893\n",
      "Test | 161/20 | Loss:1.3958 | MainLoss:1.3958 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:70.9626 | AUROC:0.9636\n",
      "\n",
      "Epoch: [36 | 1000] LR: 0.039943\n",
      "Train | 20/20 | Loss:0.0152 | MainLoss:0.0152 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.6500 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1907 | MainLoss:0.1907 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:94.6410 | AUROC:0.9899\n",
      "Test | 161/20 | Loss:1.4707 | MainLoss:1.4707 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:71.3302 | AUROC:0.9644\n",
      "\n",
      "Epoch: [37 | 1000] LR: 0.039938\n",
      "Train | 20/20 | Loss:0.0242 | MainLoss:0.0242 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.2000 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1675 | MainLoss:0.1675 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:95.1667 | AUROC:0.9898\n",
      "Test | 161/20 | Loss:1.8224 | MainLoss:1.8224 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:65.9844 | AUROC:0.9582\n",
      "\n",
      "Epoch: [38 | 1000] LR: 0.039933\n",
      "Train | 20/20 | Loss:0.0143 | MainLoss:0.0143 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.4750 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1918 | MainLoss:0.1918 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:94.4103 | AUROC:0.9896\n",
      "Test | 161/20 | Loss:1.4223 | MainLoss:1.4223 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:71.9439 | AUROC:0.9616\n",
      "\n",
      "Epoch: [39 | 1000] LR: 0.039928\n",
      "Train | 20/20 | Loss:0.0153 | MainLoss:0.0153 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.5000 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1733 | MainLoss:0.1733 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:94.9615 | AUROC:0.9902\n",
      "Test | 161/20 | Loss:1.6190 | MainLoss:1.6190 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:69.4019 | AUROC:0.9625\n",
      "\n",
      "Epoch: [40 | 1000] LR: 0.039923\n",
      "Train | 20/20 | Loss:0.0169 | MainLoss:0.0169 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.3750 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1735 | MainLoss:0.1735 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:95.0128 | AUROC:0.9904\n",
      "Test | 161/20 | Loss:1.6987 | MainLoss:1.6987 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:67.9097 | AUROC:0.9526\n",
      "\n",
      "Epoch: [41 | 1000] LR: 0.039917\n",
      "Train | 20/20 | Loss:0.0217 | MainLoss:0.0217 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.2000 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1512 | MainLoss:0.1512 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:95.4231 | AUROC:0.9913\n",
      "Test | 161/20 | Loss:1.8835 | MainLoss:1.8835 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:65.4486 | AUROC:0.9543\n",
      "\n",
      "Epoch: [42 | 1000] LR: 0.039911\n",
      "Train | 20/20 | Loss:0.0110 | MainLoss:0.0110 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.6500 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1575 | MainLoss:0.1575 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:95.4872 | AUROC:0.9912\n",
      "Test | 161/20 | Loss:2.0008 | MainLoss:2.0008 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:65.3738 | AUROC:0.9537\n",
      "\n",
      "Epoch: [43 | 1000] LR: 0.039905\n",
      "Train | 20/20 | Loss:0.0157 | MainLoss:0.0157 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.4750 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1536 | MainLoss:0.1536 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:95.6154 | AUROC:0.9915\n",
      "Test | 161/20 | Loss:1.9721 | MainLoss:1.9721 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:65.1215 | AUROC:0.9594\n",
      "\n",
      "Epoch: [44 | 1000] LR: 0.039899\n",
      "Train | 20/20 | Loss:0.0351 | MainLoss:0.0351 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:98.9250 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1398 | MainLoss:0.1398 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:95.4359 | AUROC:0.9919\n",
      "Test | 161/20 | Loss:1.5168 | MainLoss:1.5168 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:67.6137 | AUROC:0.9525\n",
      "\n",
      "Epoch: [45 | 1000] LR: 0.039893\n",
      "Train | 20/20 | Loss:0.0154 | MainLoss:0.0154 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.6000 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1388 | MainLoss:0.1388 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:95.8333 | AUROC:0.9921\n",
      "Test | 161/20 | Loss:1.9034 | MainLoss:1.9034 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:64.3832 | AUROC:0.9510\n",
      "\n",
      "Epoch: [46 | 1000] LR: 0.039886\n",
      "Train | 20/20 | Loss:0.0223 | MainLoss:0.0223 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.3750 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1438 | MainLoss:0.1438 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:95.5769 | AUROC:0.9917\n",
      "Test | 161/20 | Loss:1.8970 | MainLoss:1.8970 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:64.6885 | AUROC:0.9560\n",
      "\n",
      "Epoch: [47 | 1000] LR: 0.039879\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 20/20 | Loss:0.0199 | MainLoss:0.0199 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.2250 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1462 | MainLoss:0.1462 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:95.6282 | AUROC:0.9922\n",
      "Test | 161/20 | Loss:1.8707 | MainLoss:1.8707 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:64.8692 | AUROC:0.9433\n",
      "\n",
      "Epoch: [48 | 1000] LR: 0.039872\n",
      "Train | 20/20 | Loss:0.0175 | MainLoss:0.0175 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.3250 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1499 | MainLoss:0.1499 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:95.5256 | AUROC:0.9927\n",
      "Test | 161/20 | Loss:1.8164 | MainLoss:1.8164 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:65.1246 | AUROC:0.9445\n",
      "\n",
      "Epoch: [49 | 1000] LR: 0.039865\n",
      "Train | 20/20 | Loss:0.0215 | MainLoss:0.0215 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.3500 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1411 | MainLoss:0.1411 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:95.7051 | AUROC:0.9929\n",
      "Test | 161/20 | Loss:1.9321 | MainLoss:1.9321 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:63.5794 | AUROC:0.9324\n",
      "\n",
      "Epoch: [50 | 1000] LR: 0.039858\n",
      "Train | 20/20 | Loss:0.0116 | MainLoss:0.0116 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.6250 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1401 | MainLoss:0.1401 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.0385 | AUROC:0.9925\n",
      "Test | 161/20 | Loss:2.3117 | MainLoss:2.3117 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:61.1713 | AUROC:0.9324\n",
      "\n",
      "Epoch: [51 | 1000] LR: 0.039850\n",
      "Train | 20/20 | Loss:0.0151 | MainLoss:0.0151 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.5500 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1438 | MainLoss:0.1438 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:95.7821 | AUROC:0.9930\n",
      "Test | 161/20 | Loss:2.1109 | MainLoss:2.1109 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:63.3520 | AUROC:0.9332\n",
      "\n",
      "Epoch: [52 | 1000] LR: 0.003984\n",
      "Train | 20/20 | Loss:0.0192 | MainLoss:0.0192 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.3000 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1437 | MainLoss:0.1437 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:95.7821 | AUROC:0.9931\n",
      "Test | 161/20 | Loss:2.0859 | MainLoss:2.0859 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:63.5171 | AUROC:0.9346\n",
      "\n",
      "Epoch: [53 | 1000] LR: 0.003983\n",
      "Train | 20/20 | Loss:0.0162 | MainLoss:0.0162 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.5250 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1415 | MainLoss:0.1415 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:95.8590 | AUROC:0.9933\n",
      "Test | 161/20 | Loss:2.0868 | MainLoss:2.0868 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:63.4673 | AUROC:0.9353\n",
      "\n",
      "Epoch: [54 | 1000] LR: 0.003983\n",
      "Train | 20/20 | Loss:0.0172 | MainLoss:0.0172 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.4500 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1443 | MainLoss:0.1443 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:95.7051 | AUROC:0.9933\n",
      "Test | 161/20 | Loss:2.0079 | MainLoss:2.0079 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:64.2866 | AUROC:0.9371\n",
      "\n",
      "Epoch: [55 | 1000] LR: 0.003982\n",
      "Train | 20/20 | Loss:0.0092 | MainLoss:0.0092 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.7500 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1431 | MainLoss:0.1431 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:95.7308 | AUROC:0.9932\n",
      "Test | 161/20 | Loss:2.0278 | MainLoss:2.0278 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:64.1340 | AUROC:0.9371\n",
      "\n",
      "Epoch: [56 | 1000] LR: 0.003981\n",
      "Train | 20/20 | Loss:0.0076 | MainLoss:0.0076 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.7250 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1413 | MainLoss:0.1413 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:95.8974 | AUROC:0.9932\n",
      "Test | 161/20 | Loss:2.0769 | MainLoss:2.0769 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:63.7757 | AUROC:0.9361\n",
      "\n",
      "Epoch: [57 | 1000] LR: 0.003980\n",
      "Train | 20/20 | Loss:0.0143 | MainLoss:0.0143 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.5250 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1373 | MainLoss:0.1373 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.0256 | AUROC:0.9932\n",
      "Test | 161/20 | Loss:2.1458 | MainLoss:2.1458 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:63.0685 | AUROC:0.9357\n",
      "\n",
      "Epoch: [58 | 1000] LR: 0.003979\n",
      "Train | 20/20 | Loss:0.0132 | MainLoss:0.0132 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.5750 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1401 | MainLoss:0.1401 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:95.9487 | AUROC:0.9932\n",
      "Test | 161/20 | Loss:2.0762 | MainLoss:2.0762 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:63.8131 | AUROC:0.9361\n",
      "\n",
      "Epoch: [59 | 1000] LR: 0.003978\n",
      "Train | 20/20 | Loss:0.0147 | MainLoss:0.0147 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.5750 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1430 | MainLoss:0.1430 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:95.7051 | AUROC:0.9933\n",
      "Test | 161/20 | Loss:2.0106 | MainLoss:2.0106 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:64.4393 | AUROC:0.9370\n",
      "\n",
      "Epoch: [60 | 1000] LR: 0.003977\n",
      "Train | 20/20 | Loss:0.0142 | MainLoss:0.0142 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.5250 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1390 | MainLoss:0.1390 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:95.9872 | AUROC:0.9933\n",
      "Test | 161/20 | Loss:2.0709 | MainLoss:2.0709 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:63.7477 | AUROC:0.9362\n",
      "\n",
      "Epoch: [61 | 1000] LR: 0.003976\n",
      "Train | 20/20 | Loss:0.0152 | MainLoss:0.0152 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.5750 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1405 | MainLoss:0.1405 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:95.9103 | AUROC:0.9933\n",
      "Test | 161/20 | Loss:2.0231 | MainLoss:2.0231 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:64.2337 | AUROC:0.9376\n",
      "\n",
      "Epoch: [62 | 1000] LR: 0.003975\n",
      "Train | 20/20 | Loss:0.0162 | MainLoss:0.0162 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.4750 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1377 | MainLoss:0.1377 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:95.9487 | AUROC:0.9932\n",
      "Test | 161/20 | Loss:2.0627 | MainLoss:2.0627 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:63.7227 | AUROC:0.9367\n",
      "\n",
      "Epoch: [63 | 1000] LR: 0.003974\n",
      "Train | 20/20 | Loss:0.0131 | MainLoss:0.0131 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.6000 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1400 | MainLoss:0.1400 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:95.8846 | AUROC:0.9933\n",
      "Test | 161/20 | Loss:2.0276 | MainLoss:2.0276 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:64.1340 | AUROC:0.9373\n",
      "\n",
      "Epoch: [64 | 1000] LR: 0.003973\n",
      "Train | 20/20 | Loss:0.0126 | MainLoss:0.0126 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.5000 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1394 | MainLoss:0.1394 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:95.8974 | AUROC:0.9935\n",
      "Test | 161/20 | Loss:2.0310 | MainLoss:2.0310 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:64.0997 | AUROC:0.9382\n",
      "\n",
      "Epoch: [65 | 1000] LR: 0.003972\n",
      "Train | 20/20 | Loss:0.0076 | MainLoss:0.0076 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.7250 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1390 | MainLoss:0.1390 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:95.9231 | AUROC:0.9933\n",
      "Test | 161/20 | Loss:2.0596 | MainLoss:2.0596 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:63.9377 | AUROC:0.9387\n",
      "\n",
      "Epoch: [66 | 1000] LR: 0.003971\n",
      "Train | 20/20 | Loss:0.0125 | MainLoss:0.0125 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.5500 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1373 | MainLoss:0.1373 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.0000 | AUROC:0.9933\n",
      "Test | 161/20 | Loss:2.0906 | MainLoss:2.0906 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:63.6417 | AUROC:0.9390\n",
      "\n",
      "Epoch: [67 | 1000] LR: 0.003970\n",
      "Train | 20/20 | Loss:0.0107 | MainLoss:0.0107 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.6500 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1368 | MainLoss:0.1368 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.0256 | AUROC:0.9932\n",
      "Test | 161/20 | Loss:2.0828 | MainLoss:2.0828 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:63.7259 | AUROC:0.9392\n",
      "\n",
      "Epoch: [68 | 1000] LR: 0.003969\n",
      "Train | 20/20 | Loss:0.0249 | MainLoss:0.0249 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.2250 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1339 | MainLoss:0.1339 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:95.9872 | AUROC:0.9934\n",
      "Test | 161/20 | Loss:2.1011 | MainLoss:2.1011 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:63.3146 | AUROC:0.9395\n",
      "\n",
      "Epoch: [69 | 1000] LR: 0.003968\n",
      "Train | 20/20 | Loss:0.0146 | MainLoss:0.0146 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.5500 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1340 | MainLoss:0.1340 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.0000 | AUROC:0.9931\n",
      "Test | 161/20 | Loss:2.0738 | MainLoss:2.0738 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:63.5732 | AUROC:0.9407\n",
      "\n",
      "Epoch: [70 | 1000] LR: 0.003967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 20/20 | Loss:0.0096 | MainLoss:0.0096 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.6500 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1378 | MainLoss:0.1378 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:95.9103 | AUROC:0.9932\n",
      "Test | 161/20 | Loss:2.0004 | MainLoss:2.0004 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:64.3925 | AUROC:0.9412\n",
      "\n",
      "Epoch: [71 | 1000] LR: 0.003966\n",
      "Train | 20/20 | Loss:0.0167 | MainLoss:0.0167 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.3750 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1339 | MainLoss:0.1339 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.0128 | AUROC:0.9932\n",
      "Test | 161/20 | Loss:2.0736 | MainLoss:2.0736 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:63.6012 | AUROC:0.9411\n",
      "\n",
      "Epoch: [72 | 1000] LR: 0.003965\n",
      "Train | 20/20 | Loss:0.0069 | MainLoss:0.0069 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.7500 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1362 | MainLoss:0.1362 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:95.9872 | AUROC:0.9932\n",
      "Test | 161/20 | Loss:2.0366 | MainLoss:2.0366 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:64.1122 | AUROC:0.9428\n",
      "\n",
      "Epoch: [73 | 1000] LR: 0.003963\n",
      "Train | 20/20 | Loss:0.0116 | MainLoss:0.0116 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.7500 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1379 | MainLoss:0.1379 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:95.9231 | AUROC:0.9935\n",
      "Test | 161/20 | Loss:2.0089 | MainLoss:2.0089 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:64.4237 | AUROC:0.9431\n",
      "\n",
      "Epoch: [74 | 1000] LR: 0.003962\n",
      "Train | 20/20 | Loss:0.0202 | MainLoss:0.0202 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.3750 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1335 | MainLoss:0.1335 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.0513 | AUROC:0.9934\n",
      "Test | 161/20 | Loss:2.0681 | MainLoss:2.0681 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:63.7227 | AUROC:0.9418\n",
      "\n",
      "Epoch: [75 | 1000] LR: 0.003961\n",
      "Train | 20/20 | Loss:0.0075 | MainLoss:0.0075 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.7750 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1351 | MainLoss:0.1351 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.0128 | AUROC:0.9935\n",
      "Test | 161/20 | Loss:2.0482 | MainLoss:2.0482 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:64.0436 | AUROC:0.9423\n",
      "\n",
      "Epoch: [76 | 1000] LR: 0.003960\n",
      "Train | 20/20 | Loss:0.0100 | MainLoss:0.0100 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.6750 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1375 | MainLoss:0.1375 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:95.8974 | AUROC:0.9933\n",
      "Test | 161/20 | Loss:1.9951 | MainLoss:1.9951 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:64.6324 | AUROC:0.9435\n",
      "\n",
      "Epoch: [77 | 1000] LR: 0.003958\n",
      "Train | 20/20 | Loss:0.0082 | MainLoss:0.0082 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.7500 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1350 | MainLoss:0.1350 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:95.9744 | AUROC:0.9935\n",
      "Test | 161/20 | Loss:2.0683 | MainLoss:2.0683 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:63.9626 | AUROC:0.9417\n",
      "\n",
      "Epoch: [78 | 1000] LR: 0.003957\n",
      "Train | 20/20 | Loss:0.0066 | MainLoss:0.0066 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.7750 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1362 | MainLoss:0.1362 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:95.9744 | AUROC:0.9933\n",
      "Test | 161/20 | Loss:2.0573 | MainLoss:2.0573 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:64.1153 | AUROC:0.9429\n",
      "\n",
      "Epoch: [79 | 1000] LR: 0.003956\n",
      "Train | 20/20 | Loss:0.0169 | MainLoss:0.0169 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.4250 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1341 | MainLoss:0.1341 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.1282 | AUROC:0.9933\n",
      "Test | 161/20 | Loss:2.1004 | MainLoss:2.1004 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:63.5981 | AUROC:0.9404\n",
      "\n",
      "Epoch: [80 | 1000] LR: 0.003955\n",
      "Train | 20/20 | Loss:0.0096 | MainLoss:0.0096 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.6250 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1355 | MainLoss:0.1355 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.0000 | AUROC:0.9934\n",
      "Test | 161/20 | Loss:2.0704 | MainLoss:2.0704 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:63.9688 | AUROC:0.9413\n",
      "\n",
      "Epoch: [81 | 1000] LR: 0.003953\n",
      "Train | 20/20 | Loss:0.0100 | MainLoss:0.0100 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.7000 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1347 | MainLoss:0.1347 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.0641 | AUROC:0.9935\n",
      "Test | 161/20 | Loss:2.0990 | MainLoss:2.0990 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:63.6355 | AUROC:0.9409\n",
      "\n",
      "Epoch: [82 | 1000] LR: 0.003952\n",
      "Train | 20/20 | Loss:0.0180 | MainLoss:0.0180 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.5000 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1335 | MainLoss:0.1335 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.0897 | AUROC:0.9935\n",
      "Test | 161/20 | Loss:2.0973 | MainLoss:2.0973 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:63.5545 | AUROC:0.9412\n",
      "\n",
      "Epoch: [83 | 1000] LR: 0.003950\n",
      "Train | 20/20 | Loss:0.0090 | MainLoss:0.0090 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.6500 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1373 | MainLoss:0.1373 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:95.9615 | AUROC:0.9937\n",
      "Test | 161/20 | Loss:2.0284 | MainLoss:2.0284 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:64.3801 | AUROC:0.9427\n",
      "\n",
      "Epoch: [84 | 1000] LR: 0.003949\n",
      "Train | 20/20 | Loss:0.0113 | MainLoss:0.0113 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.7000 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1369 | MainLoss:0.1369 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:95.9744 | AUROC:0.9934\n",
      "Test | 161/20 | Loss:2.0412 | MainLoss:2.0412 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:64.2835 | AUROC:0.9425\n",
      "\n",
      "Epoch: [85 | 1000] LR: 0.003948\n",
      "Train | 20/20 | Loss:0.0084 | MainLoss:0.0084 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.7000 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1390 | MainLoss:0.1390 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:95.9615 | AUROC:0.9936\n",
      "Test | 161/20 | Loss:2.0123 | MainLoss:2.0123 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:64.6355 | AUROC:0.9433\n",
      "\n",
      "Epoch: [86 | 1000] LR: 0.003946\n",
      "Train | 20/20 | Loss:0.0183 | MainLoss:0.0183 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.5500 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1327 | MainLoss:0.1327 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.0641 | AUROC:0.9936\n",
      "Test | 161/20 | Loss:2.1051 | MainLoss:2.1051 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:63.5047 | AUROC:0.9426\n",
      "\n",
      "Epoch: [87 | 1000] LR: 0.003945\n",
      "Train | 20/20 | Loss:0.0137 | MainLoss:0.0137 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.4500 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1317 | MainLoss:0.1317 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.1154 | AUROC:0.9936\n",
      "Test | 161/20 | Loss:2.1063 | MainLoss:2.1063 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:63.4330 | AUROC:0.9435\n",
      "\n",
      "Epoch: [88 | 1000] LR: 0.003943\n",
      "Train | 20/20 | Loss:0.0077 | MainLoss:0.0077 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.7500 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1350 | MainLoss:0.1350 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:95.9872 | AUROC:0.9937\n",
      "Test | 161/20 | Loss:2.0319 | MainLoss:2.0319 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:64.3583 | AUROC:0.9451\n",
      "\n",
      "Epoch: [89 | 1000] LR: 0.003942\n",
      "Train | 20/20 | Loss:0.0063 | MainLoss:0.0063 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.8750 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1355 | MainLoss:0.1355 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.0000 | AUROC:0.9934\n",
      "Test | 161/20 | Loss:2.0510 | MainLoss:2.0510 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:64.2679 | AUROC:0.9443\n",
      "\n",
      "Epoch: [90 | 1000] LR: 0.003940\n",
      "Train | 20/20 | Loss:0.0160 | MainLoss:0.0160 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.5250 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1364 | MainLoss:0.1364 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.0128 | AUROC:0.9936\n",
      "Test | 161/20 | Loss:2.0298 | MainLoss:2.0298 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:64.4393 | AUROC:0.9442\n",
      "\n",
      "Epoch: [91 | 1000] LR: 0.003939\n",
      "Train | 20/20 | Loss:0.0151 | MainLoss:0.0151 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.6000 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1352 | MainLoss:0.1352 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.0000 | AUROC:0.9936\n",
      "Test | 161/20 | Loss:2.0459 | MainLoss:2.0459 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:64.2617 | AUROC:0.9438\n",
      "\n",
      "Epoch: [92 | 1000] LR: 0.003937\n",
      "Train | 20/20 | Loss:0.0109 | MainLoss:0.0109 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.6000 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1348 | MainLoss:0.1348 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.0128 | AUROC:0.9934\n",
      "Test | 161/20 | Loss:2.0630 | MainLoss:2.0630 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:64.1308 | AUROC:0.9438\n",
      "\n",
      "Epoch: [93 | 1000] LR: 0.003936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 20/20 | Loss:0.0186 | MainLoss:0.0186 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.4000 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1342 | MainLoss:0.1342 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.0385 | AUROC:0.9936\n",
      "Test | 161/20 | Loss:2.0208 | MainLoss:2.0208 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:64.3801 | AUROC:0.9448\n",
      "\n",
      "Epoch: [94 | 1000] LR: 0.003934\n",
      "Train | 20/20 | Loss:0.0143 | MainLoss:0.0143 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.5250 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1317 | MainLoss:0.1317 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.1282 | AUROC:0.9936\n",
      "Test | 161/20 | Loss:2.0515 | MainLoss:2.0515 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:63.9875 | AUROC:0.9442\n",
      "\n",
      "Epoch: [95 | 1000] LR: 0.003932\n",
      "Train | 20/20 | Loss:0.0122 | MainLoss:0.0122 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.6250 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1304 | MainLoss:0.1304 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.1154 | AUROC:0.9935\n",
      "Test | 161/20 | Loss:2.0854 | MainLoss:2.0854 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:63.5919 | AUROC:0.9441\n",
      "\n",
      "Epoch: [96 | 1000] LR: 0.003931\n",
      "Train | 20/20 | Loss:0.0075 | MainLoss:0.0075 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.8250 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1298 | MainLoss:0.1298 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.1795 | AUROC:0.9937\n",
      "Test | 161/20 | Loss:2.1406 | MainLoss:2.1406 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:63.1340 | AUROC:0.9427\n",
      "\n",
      "Epoch: [97 | 1000] LR: 0.003929\n",
      "Train | 20/20 | Loss:0.0120 | MainLoss:0.0120 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.5500 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1303 | MainLoss:0.1303 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.1410 | AUROC:0.9936\n",
      "Test | 161/20 | Loss:2.0999 | MainLoss:2.0999 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:63.5514 | AUROC:0.9436\n",
      "\n",
      "Epoch: [98 | 1000] LR: 0.003927\n",
      "Train | 20/20 | Loss:0.0115 | MainLoss:0.0115 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.6750 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1329 | MainLoss:0.1329 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.0769 | AUROC:0.9935\n",
      "Test | 161/20 | Loss:2.0462 | MainLoss:2.0462 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:64.1340 | AUROC:0.9464\n",
      "\n",
      "Epoch: [99 | 1000] LR: 0.003926\n",
      "Train | 20/20 | Loss:0.0151 | MainLoss:0.0151 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.5000 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1329 | MainLoss:0.1329 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.0641 | AUROC:0.9936\n",
      "Test | 161/20 | Loss:2.0274 | MainLoss:2.0274 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:64.2960 | AUROC:0.9460\n",
      "\n",
      "Epoch: [100 | 1000] LR: 0.003924\n",
      "Train | 20/20 | Loss:0.0080 | MainLoss:0.0080 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.8000 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1325 | MainLoss:0.1325 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.0641 | AUROC:0.9936\n",
      "Test | 161/20 | Loss:2.0439 | MainLoss:2.0439 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:64.1682 | AUROC:0.9465\n",
      "\n",
      "Epoch: [101 | 1000] LR: 0.003922\n",
      "Train | 20/20 | Loss:0.0067 | MainLoss:0.0067 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.8000 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1316 | MainLoss:0.1316 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.1282 | AUROC:0.9936\n",
      "Test | 161/20 | Loss:2.0763 | MainLoss:2.0763 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:63.8785 | AUROC:0.9460\n",
      "\n",
      "Epoch: [102 | 1000] LR: 0.003921\n",
      "Train | 20/20 | Loss:0.0103 | MainLoss:0.0103 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.7750 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1331 | MainLoss:0.1331 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.0769 | AUROC:0.9938\n",
      "Test | 161/20 | Loss:2.0370 | MainLoss:2.0370 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:64.3302 | AUROC:0.9467\n",
      "\n",
      "Epoch: [103 | 1000] LR: 0.003919\n",
      "Train | 20/20 | Loss:0.0114 | MainLoss:0.0114 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.7250 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1308 | MainLoss:0.1308 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.1282 | AUROC:0.9937\n",
      "Test | 161/20 | Loss:2.0847 | MainLoss:2.0847 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:63.7695 | AUROC:0.9464\n",
      "\n",
      "Epoch: [104 | 1000] LR: 0.003917\n",
      "Train | 20/20 | Loss:0.0100 | MainLoss:0.0100 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.6500 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1322 | MainLoss:0.1322 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.0897 | AUROC:0.9936\n",
      "Test | 161/20 | Loss:2.0572 | MainLoss:2.0572 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:64.1340 | AUROC:0.9466\n",
      "\n",
      "Epoch: [105 | 1000] LR: 0.003915\n",
      "Train | 20/20 | Loss:0.0105 | MainLoss:0.0105 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.7000 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1333 | MainLoss:0.1333 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.0769 | AUROC:0.9937\n",
      "Test | 161/20 | Loss:2.0419 | MainLoss:2.0419 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:64.3614 | AUROC:0.9466\n",
      "\n",
      "Epoch: [106 | 1000] LR: 0.003913\n",
      "Train | 20/20 | Loss:0.0125 | MainLoss:0.0125 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.7000 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1308 | MainLoss:0.1308 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.1282 | AUROC:0.9938\n",
      "Test | 161/20 | Loss:2.0836 | MainLoss:2.0836 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:63.8100 | AUROC:0.9465\n",
      "\n",
      "Epoch: [107 | 1000] LR: 0.003912\n",
      "Train | 20/20 | Loss:0.0080 | MainLoss:0.0080 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.8000 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1299 | MainLoss:0.1299 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.1410 | AUROC:0.9935\n",
      "Test | 161/20 | Loss:2.1429 | MainLoss:2.1429 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:63.2897 | AUROC:0.9453\n",
      "\n",
      "Epoch: [108 | 1000] LR: 0.003910\n",
      "Train | 20/20 | Loss:0.0096 | MainLoss:0.0096 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.6750 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1319 | MainLoss:0.1319 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.0897 | AUROC:0.9937\n",
      "Test | 161/20 | Loss:2.0839 | MainLoss:2.0839 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:63.9439 | AUROC:0.9466\n",
      "\n",
      "Epoch: [109 | 1000] LR: 0.003908\n",
      "Train | 20/20 | Loss:0.0085 | MainLoss:0.0085 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.7000 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1321 | MainLoss:0.1321 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.1026 | AUROC:0.9938\n",
      "Test | 161/20 | Loss:2.0854 | MainLoss:2.0854 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:63.9564 | AUROC:0.9460\n",
      "\n",
      "Epoch: [110 | 1000] LR: 0.003906\n",
      "Train | 20/20 | Loss:0.0070 | MainLoss:0.0070 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.7500 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1325 | MainLoss:0.1325 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.1154 | AUROC:0.9939\n",
      "Test | 161/20 | Loss:2.0974 | MainLoss:2.0974 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:63.9065 | AUROC:0.9458\n",
      "\n",
      "Epoch: [111 | 1000] LR: 0.003904\n",
      "Train | 20/20 | Loss:0.0142 | MainLoss:0.0142 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.5000 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1310 | MainLoss:0.1310 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.1154 | AUROC:0.9936\n",
      "Test | 161/20 | Loss:2.1085 | MainLoss:2.1085 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:63.6916 | AUROC:0.9450\n",
      "\n",
      "Epoch: [112 | 1000] LR: 0.003902\n",
      "Train | 20/20 | Loss:0.0111 | MainLoss:0.0111 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.6250 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1345 | MainLoss:0.1345 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.0128 | AUROC:0.9939\n",
      "Test | 161/20 | Loss:2.0481 | MainLoss:2.0481 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:64.4486 | AUROC:0.9470\n",
      "\n",
      "Epoch: [113 | 1000] LR: 0.003900\n",
      "Train | 20/20 | Loss:0.0093 | MainLoss:0.0093 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.7500 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1318 | MainLoss:0.1318 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.1282 | AUROC:0.9939\n",
      "Test | 161/20 | Loss:2.1095 | MainLoss:2.1095 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:63.7819 | AUROC:0.9464\n",
      "\n",
      "Epoch: [114 | 1000] LR: 0.003898\n",
      "Train | 20/20 | Loss:0.0099 | MainLoss:0.0099 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.7000 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1315 | MainLoss:0.1315 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.1154 | AUROC:0.9938\n",
      "Test | 161/20 | Loss:2.1122 | MainLoss:2.1122 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:63.8006 | AUROC:0.9463\n",
      "\n",
      "Epoch: [115 | 1000] LR: 0.003896\n",
      "Train | 20/20 | Loss:0.0080 | MainLoss:0.0080 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.8000 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1345 | MainLoss:0.1345 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:95.9744 | AUROC:0.9940\n",
      "Test | 161/20 | Loss:2.0535 | MainLoss:2.0535 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:64.5950 | AUROC:0.9465\n",
      "\n",
      "Epoch: [116 | 1000] LR: 0.003894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 20/20 | Loss:0.0134 | MainLoss:0.0134 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.6000 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1362 | MainLoss:0.1362 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:95.9359 | AUROC:0.9939\n",
      "Test | 161/20 | Loss:2.0111 | MainLoss:2.0111 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:64.9813 | AUROC:0.9480\n",
      "\n",
      "Epoch: [117 | 1000] LR: 0.003892\n",
      "Train | 20/20 | Loss:0.0087 | MainLoss:0.0087 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.8000 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1338 | MainLoss:0.1338 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.0128 | AUROC:0.9939\n",
      "Test | 161/20 | Loss:2.0591 | MainLoss:2.0591 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:64.4891 | AUROC:0.9470\n",
      "\n",
      "Epoch: [118 | 1000] LR: 0.003890\n",
      "Train | 20/20 | Loss:0.0203 | MainLoss:0.0203 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.3750 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1336 | MainLoss:0.1336 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.0000 | AUROC:0.9940\n",
      "Test | 161/20 | Loss:2.0252 | MainLoss:2.0252 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:64.6822 | AUROC:0.9470\n",
      "\n",
      "Epoch: [119 | 1000] LR: 0.003888\n",
      "Train | 20/20 | Loss:0.0110 | MainLoss:0.0110 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.6500 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1326 | MainLoss:0.1326 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.0000 | AUROC:0.9937\n",
      "Test | 161/20 | Loss:2.0446 | MainLoss:2.0446 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:64.5327 | AUROC:0.9459\n",
      "\n",
      "Epoch: [120 | 1000] LR: 0.003886\n",
      "Train | 20/20 | Loss:0.0249 | MainLoss:0.0249 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.1250 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1279 | MainLoss:0.1279 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.2051 | AUROC:0.9940\n",
      "Test | 161/20 | Loss:2.0799 | MainLoss:2.0799 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:63.8131 | AUROC:0.9452\n",
      "\n",
      "Epoch: [121 | 1000] LR: 0.003884\n",
      "Train | 20/20 | Loss:0.0050 | MainLoss:0.0050 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.8000 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1276 | MainLoss:0.1276 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.2436 | AUROC:0.9939\n",
      "Test | 161/20 | Loss:2.1195 | MainLoss:2.1195 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:63.5919 | AUROC:0.9456\n",
      "\n",
      "Epoch: [122 | 1000] LR: 0.003882\n",
      "Train | 20/20 | Loss:0.0099 | MainLoss:0.0099 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.6500 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1315 | MainLoss:0.1315 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.0513 | AUROC:0.9940\n",
      "Test | 161/20 | Loss:2.0343 | MainLoss:2.0343 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:64.5794 | AUROC:0.9465\n",
      "\n",
      "Epoch: [123 | 1000] LR: 0.003880\n",
      "Train | 20/20 | Loss:0.0086 | MainLoss:0.0086 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.6500 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1305 | MainLoss:0.1305 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.0641 | AUROC:0.9938\n",
      "Test | 161/20 | Loss:2.0533 | MainLoss:2.0533 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:64.3925 | AUROC:0.9463\n",
      "\n",
      "Epoch: [124 | 1000] LR: 0.003877\n",
      "Train | 20/20 | Loss:0.0152 | MainLoss:0.0152 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.5500 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1326 | MainLoss:0.1326 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.0769 | AUROC:0.9940\n",
      "Test | 161/20 | Loss:1.9992 | MainLoss:1.9992 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:64.9128 | AUROC:0.9473\n",
      "\n",
      "Epoch: [125 | 1000] LR: 0.003875\n",
      "Train | 20/20 | Loss:0.0096 | MainLoss:0.0096 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.7250 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1301 | MainLoss:0.1301 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.1282 | AUROC:0.9940\n",
      "Test | 161/20 | Loss:2.0523 | MainLoss:2.0523 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:64.3770 | AUROC:0.9463\n",
      "\n",
      "Epoch: [126 | 1000] LR: 0.003873\n",
      "Train | 20/20 | Loss:0.0183 | MainLoss:0.0183 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.4000 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1272 | MainLoss:0.1272 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.1538 | AUROC:0.9942\n",
      "Test | 161/20 | Loss:2.0842 | MainLoss:2.0842 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:63.9252 | AUROC:0.9463\n",
      "\n",
      "Epoch: [127 | 1000] LR: 0.003871\n",
      "Train | 20/20 | Loss:0.0085 | MainLoss:0.0085 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.7250 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1267 | MainLoss:0.1267 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.1923 | AUROC:0.9941\n",
      "Test | 161/20 | Loss:2.0997 | MainLoss:2.0997 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:63.7913 | AUROC:0.9464\n",
      "\n",
      "Epoch: [128 | 1000] LR: 0.003869\n",
      "Train | 20/20 | Loss:0.0129 | MainLoss:0.0129 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.6500 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1241 | MainLoss:0.1241 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.3590 | AUROC:0.9941\n",
      "Test | 161/20 | Loss:2.1502 | MainLoss:2.1502 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:63.1713 | AUROC:0.9464\n",
      "\n",
      "Epoch: [129 | 1000] LR: 0.003866\n",
      "Train | 20/20 | Loss:0.0058 | MainLoss:0.0058 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.8750 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1245 | MainLoss:0.1245 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.3718 | AUROC:0.9940\n",
      "Test | 161/20 | Loss:2.1778 | MainLoss:2.1778 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:63.0031 | AUROC:0.9455\n",
      "\n",
      "Epoch: [130 | 1000] LR: 0.003864\n",
      "Train | 20/20 | Loss:0.0071 | MainLoss:0.0071 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.7250 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1267 | MainLoss:0.1267 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.2051 | AUROC:0.9939\n",
      "Test | 161/20 | Loss:2.1021 | MainLoss:2.1021 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:63.8349 | AUROC:0.9464\n",
      "\n",
      "Epoch: [131 | 1000] LR: 0.003862\n",
      "Train | 20/20 | Loss:0.0145 | MainLoss:0.0145 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.5500 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1251 | MainLoss:0.1251 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.2692 | AUROC:0.9938\n",
      "Test | 161/20 | Loss:2.1169 | MainLoss:2.1169 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:63.5545 | AUROC:0.9469\n",
      "\n",
      "Epoch: [132 | 1000] LR: 0.003860\n",
      "Train | 20/20 | Loss:0.0092 | MainLoss:0.0092 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.7000 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1267 | MainLoss:0.1267 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.2179 | AUROC:0.9940\n",
      "Test | 161/20 | Loss:2.0785 | MainLoss:2.0785 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:64.0031 | AUROC:0.9477\n",
      "\n",
      "Epoch: [133 | 1000] LR: 0.003857\n",
      "Train | 20/20 | Loss:0.0070 | MainLoss:0.0070 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.8000 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1304 | MainLoss:0.1304 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.0513 | AUROC:0.9942\n",
      "Test | 161/20 | Loss:2.0097 | MainLoss:2.0097 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:64.7352 | AUROC:0.9478\n",
      "\n",
      "Epoch: [134 | 1000] LR: 0.003855\n",
      "Train | 20/20 | Loss:0.0108 | MainLoss:0.0108 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.6250 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1303 | MainLoss:0.1303 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.0641 | AUROC:0.9941\n",
      "Test | 161/20 | Loss:2.0098 | MainLoss:2.0098 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:64.7601 | AUROC:0.9481\n",
      "\n",
      "Epoch: [135 | 1000] LR: 0.003853\n",
      "Train | 20/20 | Loss:0.0092 | MainLoss:0.0092 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.7000 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1266 | MainLoss:0.1266 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.2949 | AUROC:0.9941\n",
      "Test | 161/20 | Loss:2.0809 | MainLoss:2.0809 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:64.1090 | AUROC:0.9483\n",
      "\n",
      "Epoch: [136 | 1000] LR: 0.003850\n",
      "Train | 20/20 | Loss:0.0106 | MainLoss:0.0106 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.6750 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1264 | MainLoss:0.1264 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.2949 | AUROC:0.9942\n",
      "Test | 161/20 | Loss:2.0920 | MainLoss:2.0920 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:64.0156 | AUROC:0.9476\n",
      "\n",
      "Epoch: [137 | 1000] LR: 0.003848\n",
      "Train | 20/20 | Loss:0.0132 | MainLoss:0.0132 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.6500 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1256 | MainLoss:0.1256 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.2949 | AUROC:0.9943\n",
      "Test | 161/20 | Loss:2.0889 | MainLoss:2.0889 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:63.9595 | AUROC:0.9480\n",
      "\n",
      "Epoch: [138 | 1000] LR: 0.003845\n",
      "Train | 20/20 | Loss:0.0128 | MainLoss:0.0128 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.5250 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1259 | MainLoss:0.1259 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.2692 | AUROC:0.9940\n",
      "Test | 161/20 | Loss:2.0796 | MainLoss:2.0796 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:64.0685 | AUROC:0.9480\n",
      "\n",
      "Epoch: [139 | 1000] LR: 0.003843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | 20/20 | Loss:0.0086 | MainLoss:0.0086 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.6500 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1311 | MainLoss:0.1311 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.0897 | AUROC:0.9942\n",
      "Test | 161/20 | Loss:1.9997 | MainLoss:1.9997 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:64.9533 | AUROC:0.9490\n",
      "\n",
      "Epoch: [140 | 1000] LR: 0.003840\n",
      "Train | 20/20 | Loss:0.0047 | MainLoss:0.0047 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.8750 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1295 | MainLoss:0.1295 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.1923 | AUROC:0.9942\n",
      "Test | 161/20 | Loss:2.0548 | MainLoss:2.0548 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:64.5358 | AUROC:0.9483\n",
      "\n",
      "Epoch: [141 | 1000] LR: 0.003838\n",
      "Train | 20/20 | Loss:0.0091 | MainLoss:0.0091 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.6750 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1262 | MainLoss:0.1262 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.2564 | AUROC:0.9943\n",
      "Test | 161/20 | Loss:2.1100 | MainLoss:2.1100 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:63.8723 | AUROC:0.9478\n",
      "\n",
      "Epoch: [142 | 1000] LR: 0.003836\n",
      "Train | 20/20 | Loss:0.0216 | MainLoss:0.0216 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.2500 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1240 | MainLoss:0.1240 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.3077 | AUROC:0.9942\n",
      "Test | 161/20 | Loss:2.1149 | MainLoss:2.1149 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:63.6417 | AUROC:0.9481\n",
      "\n",
      "Epoch: [143 | 1000] LR: 0.003833\n",
      "Train | 20/20 | Loss:0.0111 | MainLoss:0.0111 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.6750 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1258 | MainLoss:0.1258 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.2179 | AUROC:0.9943\n",
      "Test | 161/20 | Loss:2.0610 | MainLoss:2.0610 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:64.1776 | AUROC:0.9496\n",
      "\n",
      "Epoch: [144 | 1000] LR: 0.003830\n",
      "Train | 20/20 | Loss:0.0112 | MainLoss:0.0112 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.6250 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1236 | MainLoss:0.1236 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.3590 | AUROC:0.9945\n",
      "Test | 161/20 | Loss:2.1269 | MainLoss:2.1269 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:63.5171 | AUROC:0.9480\n",
      "\n",
      "Epoch: [145 | 1000] LR: 0.003828\n",
      "Train | 20/20 | Loss:0.0054 | MainLoss:0.0054 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.8250 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1250 | MainLoss:0.1250 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.2692 | AUROC:0.9943\n",
      "Test | 161/20 | Loss:2.1119 | MainLoss:2.1119 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:63.7570 | AUROC:0.9483\n",
      "\n",
      "Epoch: [146 | 1000] LR: 0.003825\n",
      "Train | 20/20 | Loss:0.0061 | MainLoss:0.0061 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.7750 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1261 | MainLoss:0.1261 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.2692 | AUROC:0.9942\n",
      "Test | 161/20 | Loss:2.1084 | MainLoss:2.1084 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:63.9128 | AUROC:0.9487\n",
      "\n",
      "Epoch: [147 | 1000] LR: 0.003823\n",
      "Train | 20/20 | Loss:0.0105 | MainLoss:0.0105 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.5500 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1284 | MainLoss:0.1284 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.2436 | AUROC:0.9941\n",
      "Test | 161/20 | Loss:2.0513 | MainLoss:2.0513 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:64.4953 | AUROC:0.9489\n",
      "\n",
      "Epoch: [148 | 1000] LR: 0.003820\n",
      "Train | 20/20 | Loss:0.0085 | MainLoss:0.0085 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.7000 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1265 | MainLoss:0.1265 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.2564 | AUROC:0.9942\n",
      "Test | 161/20 | Loss:2.0929 | MainLoss:2.0929 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:64.0623 | AUROC:0.9480\n",
      "\n",
      "Epoch: [149 | 1000] LR: 0.003818\n",
      "Train | 20/20 | Loss:0.0112 | MainLoss:0.0112 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.6000 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1281 | MainLoss:0.1281 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.1667 | AUROC:0.9941\n",
      "Test | 161/20 | Loss:2.0512 | MainLoss:2.0512 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:64.4984 | AUROC:0.9491\n",
      "\n",
      "Epoch: [150 | 1000] LR: 0.003815\n",
      "Train | 20/20 | Loss:0.0058 | MainLoss:0.0058 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.8500 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1275 | MainLoss:0.1275 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.2308 | AUROC:0.9944\n",
      "Test | 161/20 | Loss:2.0788 | MainLoss:2.0788 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:64.2492 | AUROC:0.9494\n",
      "\n",
      "Epoch: [151 | 1000] LR: 0.003812\n",
      "Train | 20/20 | Loss:0.0055 | MainLoss:0.0055 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.9000 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1313 | MainLoss:0.1313 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.1282 | AUROC:0.9943\n",
      "Test | 161/20 | Loss:2.0376 | MainLoss:2.0376 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:64.7850 | AUROC:0.9494\n",
      "\n",
      "Epoch: [152 | 1000] LR: 0.003810\n",
      "Train | 20/20 | Loss:0.0071 | MainLoss:0.0071 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.7750 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1284 | MainLoss:0.1284 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.2692 | AUROC:0.9943\n",
      "Test | 161/20 | Loss:2.1042 | MainLoss:2.1042 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:64.1277 | AUROC:0.9480\n",
      "\n",
      "Epoch: [153 | 1000] LR: 0.003807\n",
      "Train | 20/20 | Loss:0.0086 | MainLoss:0.0086 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.7000 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1285 | MainLoss:0.1285 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.2949 | AUROC:0.9943\n",
      "Test | 161/20 | Loss:2.1052 | MainLoss:2.1052 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:64.1402 | AUROC:0.9485\n",
      "\n",
      "Epoch: [154 | 1000] LR: 0.003804\n",
      "Train | 20/20 | Loss:0.0076 | MainLoss:0.0076 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:99.8250 | AUROC:0.0000\n",
      "Test | 39/20 | Loss:0.1277 | MainLoss:0.1277 | SPLoss:0.0000 | CLSLoss:0.0000 | top1:96.3077 | AUROC:0.9942\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(start_epoch, epochs):\n",
    "    state['lr'] = optimizer.state_dict()['param_groups'][0]['lr']\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "    print('\\nEpoch: [%d | %d] LR: %f' % (epoch + 1, epochs, state['lr']))\n",
    "    \n",
    "    train_loss, train_acc, train_auroc = train(train_loader, student_model, criterion, optimizer, epoch, use_cuda)\n",
    "    test_loss, test_acc, test_auroc = test(val_target_loader, student_model, criterion, epoch, use_cuda)\n",
    "    source_loss, source_acc, source_auroc = test(val_source_loader, student_model, criterion, epoch, use_cuda)\n",
    "\n",
    "\n",
    "    logger.append([state['lr'], train_loss, test_loss,  source_loss, train_acc, test_acc,source_acc, train_auroc, test_auroc, source_auroc])\n",
    "    is_best = test_acc > best_acc\n",
    "    best_acc = max(test_acc, best_acc)\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'state_dict' : student_model.state_dict(),\n",
    "        'acc': test_acc,\n",
    "        'best_acc': best_acc,\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    }, is_best, checkpoint=checkpoint)\n",
    "    scheduler_warmup.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
