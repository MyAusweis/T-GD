{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import collections\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "\n",
    "from model_pytorch import resnext50_32x4d\n",
    "from utils import Bar,Logger, AverageMeter, accuracy, mkdir_p, savefig\n",
    "from warmup_scheduler import GradualWarmupScheduler\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "import cv2\n",
    "\n",
    "from PIL import ImageFile, ImageOps\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU device 2: True\n"
     ]
    }
   ],
   "source": [
    "# GPU Device\n",
    "gpu_id = 2\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(\"GPU device %d:\" %(gpu_id), use_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/media/data2/dataset/GAN_ImageData/StyleGAN_256'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained = ''\n",
    "resume = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model_name = 'resnext32x4d' # b0-b7 scale\n",
    "\n",
    "# Optimization\n",
    "num_classes = 2\n",
    "epochs = 300\n",
    "start_epoch = 0\n",
    "train_batch = 160\n",
    "test_batch = 160\n",
    "lr = 0.04\n",
    "schedule = [75, 175, 250]\n",
    "momentum = 0.9\n",
    "gamma = 0.1 # LR is multiplied by gamma on schedule\n",
    "\n",
    "# CheckPoint\n",
    "checkpoint = './log/style1/128/32x4d/aug' # dir\n",
    "if not os.path.isdir(checkpoint):\n",
    "    os.makedirs(checkpoint)\n",
    "num_workers = 8\n",
    "\n",
    "# Seed\n",
    "manual_seed = 7\n",
    "random.seed(manual_seed)\n",
    "torch.cuda.manual_seed_all(manual_seed)\n",
    "\n",
    "# Image\n",
    "size = (128, 128)\n",
    "\n",
    "# cutmix\n",
    "cm_prob = 0.5\n",
    "cm_beta = 1.0\n",
    "\n",
    "# augmentation\n",
    "blur_prob = 0.2\n",
    "blog_sig = 0.5\n",
    "jpg_prob = 0.2\n",
    "\n",
    "best_acc = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {}\n",
    "state['num_classes'] = num_classes\n",
    "state['epochs'] = epochs\n",
    "state['start_epoch'] = start_epoch\n",
    "state['train_batch'] = train_batch\n",
    "state['test_batch'] = test_batch\n",
    "state['lr'] = lr\n",
    "state['schedule'] = schedule\n",
    "state['momentum'] = momentum\n",
    "state['gamma'] = gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_augment(img):\n",
    "    img = np.array(img)\n",
    "\n",
    "    if random.random() < blur_prob:\n",
    "        sig = np.random.uniform(0.0, 3.0)\n",
    "        gaussian_blur(img, sig)\n",
    "\n",
    "    if random.random() < jpg_prob:\n",
    "        qual = np.random.uniform(30.0, 100.0)\n",
    "        img = cv2_jpg(img, qual)\n",
    "\n",
    "    return Image.fromarray(img)\n",
    "\n",
    "\n",
    "def gaussian_blur(img, sigma):\n",
    "    gaussian_filter(img[:,:,0], output=img[:,:,0], sigma=sigma)\n",
    "    gaussian_filter(img[:,:,1], output=img[:,:,1], sigma=sigma)\n",
    "    gaussian_filter(img[:,:,2], output=img[:,:,2], sigma=sigma)\n",
    "\n",
    "\n",
    "def cv2_jpg(img, compress_val):\n",
    "    img_cv2 = img[:,:,::-1]\n",
    "    encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), compress_val]\n",
    "    result, encimg = cv2.imencode('.jpg', img_cv2, encode_param)\n",
    "    decimg = cv2.imdecode(encimg, 1)\n",
    "    return decimg[:,:,::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_bbox(size, lam):\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = np.int(W * cut_rat)\n",
    "    cut_h = np.int(H * cut_rat)\n",
    "\n",
    "    # uniform\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join(data_dir, 'train')\n",
    "val_dir = os.path.join(data_dir, 'validation')    \n",
    "\n",
    "train_aug = transforms.Compose([\n",
    "    transforms.Lambda(lambda img: data_augment(img)),\n",
    "    transforms.Resize(size),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "#     transforms.RandomErasing(p=0.3, scale=(0.02, 0.10), ratio=(0.3, 3.3), value=0, inplace=True),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "val_aug = transforms.Compose([\n",
    "    transforms.Resize(size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# pin_memory : cuda pin memeory use\n",
    "train_loader = DataLoader(datasets.ImageFolder(train_dir, transform=train_aug),\n",
    "                          batch_size=train_batch, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "val_loader = DataLoader(datasets.ImageFolder(val_dir, val_aug),\n",
    "                       batch_size=test_batch, shuffle=True, num_workers=num_workers, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnext50_32x4d(pretrained=False, num_classes=2)\n",
    "\n",
    "# Pre-trained\n",
    "if pretrained:\n",
    "    print(\"=> using pre-trained model '{}'\".format(pretrained))\n",
    "    model.load_state_dict(torch.load(pretrained)['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Total params: 22.98M\n"
     ]
    }
   ],
   "source": [
    "model.to('cuda')\n",
    "cudnn.benchmark = True\n",
    "print('    Total params: %.2fM' % (sum(p.numel() for p in model.parameters())/1000000.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=1e-4)\n",
    "scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)\n",
    "scheduler_warmup = GradualWarmupScheduler(optimizer, multiplier=8, total_epoch=10, after_scheduler=scheduler_cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resume\n",
    "if resume:\n",
    "    print('==> Resuming from checkpoint..')\n",
    "    checkpoint = os.path.dirname(resume)\n",
    "#     checkpoint = torch.load(resume)\n",
    "    resume = torch.load(resume)\n",
    "    best_acc = resume['best_acc']\n",
    "    start_epoch = resume['epoch']\n",
    "    model.load_state_dict(resume['state_dict'])\n",
    "    optimizer.load_state_dict(resume['optimizer'])\n",
    "    logger = Logger(os.path.join(checkpoint, 'log.txt'), resume=True)\n",
    "else:\n",
    "    logger = Logger(os.path.join(checkpoint, 'log.txt'))\n",
    "    logger.set_names(['Learning Rate', 'Train Loss', 'Valid Loss', 'Train Acc.', 'Valid Acc.', 'Train AUROC.', 'Valid AUROC.'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch, use_cuda):\n",
    "    model.train()\n",
    "    \n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    arc = AverageMeter()\n",
    "    end = time.time()\n",
    "    \n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        batch_size = inputs.size(0)\n",
    "        if batch_size < train_batch:\n",
    "            continue\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            \n",
    "        r = np.random.rand(1)\n",
    "        if cm_beta > 0 and r < cm_prob:\n",
    "            \n",
    "            rand_index = torch.randperm(inputs.size()[0]).cuda()\n",
    "            tt= targets[rand_index]\n",
    "            boolean = targets==tt\n",
    "            rand_index = rand_index[boolean]\n",
    "            lam = np.random.beta(cm_beta, cm_beta)\n",
    "            bbx1, bby1, bbx2, bby2 = rand_bbox(inputs.size(), lam)\n",
    "            inputs[boolean, :, bbx1:bbx2, bby1:bby2] = inputs[rand_index, :, bbx1:bbx2, bby1:bby2]\n",
    "\n",
    "        # compute output\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1 = accuracy(outputs.data, targets.data)\n",
    "        auroc = roc_auc_score(targets.cpu().detach().numpy(), outputs.cpu().detach().numpy()[:,1])\n",
    "        losses.update(loss.data.tolist(), inputs.size(0))\n",
    "        top1.update(prec1[0], inputs.size(0))\n",
    "        arc.update(auroc, inputs.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print('{batch}/{size} | Loss:{loss:.4f} | top1:{tp1:.4f} | AUROC:{ac:.4f}'.format(\n",
    "                     batch=batch_idx+1, size=len(train_loader), loss=losses.avg, tp1=top1.avg, ac=arc.avg))\n",
    "    print('{batch}/{size} | Loss:{loss:.4f} | top1:{tp1:.4f} | AUROC:{ac:.4f}'.format(\n",
    "                     batch=batch_idx+1, size=len(train_loader), loss=losses.avg, tp1=top1.avg, ac=arc.avg))\n",
    "    return (losses.avg, top1.avg, arc.avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(val_loader, model, criterion, epoch, use_cuda):\n",
    "    global best_acc\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    arc = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(val_loader):\n",
    "            # measure data loading time\n",
    "            data_time.update(time.time() - end)\n",
    "\n",
    "            if use_cuda:\n",
    "                inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "            # compute output\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            prec1 = accuracy(outputs.data, targets.data)\n",
    "            auroc = roc_auc_score(targets.cpu().detach().numpy(), outputs.cpu().detach().numpy()[:,1])\n",
    "            losses.update(loss.data.tolist(), inputs.size(0))\n",
    "            top1.update(prec1[0], inputs.size(0))\n",
    "            arc.update(auroc, inputs.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "    print('{batch}/{size} | Loss:{loss:.4f} | top1:{tp1:.4f} | AUROC:{ac:.4f}'.format(\n",
    "         batch=batch_idx+1, size=len(val_loader), loss=losses.avg, tp1=top1.avg, ac=arc.avg))\n",
    "    return (losses.avg, top1.avg, arc.avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, checkpoint='checkpoint', filename='checkpoint.pth.tar'):\n",
    "    filepath = os.path.join(checkpoint, filename)\n",
    "    torch.save(state, filepath)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filepath, os.path.join(checkpoint, 'model_best.pth.tar'))\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    global state\n",
    "    lr_set = [1, 1e-1, 1e-2, 1e-3, 1e-4, 1e-5]\n",
    "    lr_list = schedule.copy()\n",
    "    lr_list.append(epoch)\n",
    "    lr_list.sort()\n",
    "    idx = lr_list.index(epoch)\n",
    "    state['lr'] *= lr_set[idx]\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = state['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [1 | 300] LR: 0.040000\n",
      "1/431 | Loss:0.8684 | top1:55.0000 | AUROC:0.5464\n",
      "101/431 | Loss:34.3031 | top1:50.3899 | AUROC:0.5122\n",
      "201/431 | Loss:17.5896 | top1:50.2705 | AUROC:0.5126\n",
      "301/431 | Loss:11.9772 | top1:50.0415 | AUROC:0.5130\n",
      "401/431 | Loss:9.1638 | top1:50.1449 | AUROC:0.5132\n",
      "431/431 | Loss:8.5926 | top1:50.1628 | AUROC:0.5127\n",
      "49/49 | Loss:0.6932 | top1:50.4744 | AUROC:0.5076\n",
      "\n",
      "Epoch: [2 | 300] LR: 0.068000\n",
      "1/431 | Loss:0.6905 | top1:56.8750 | AUROC:0.5602\n",
      "101/431 | Loss:0.6966 | top1:50.1238 | AUROC:0.5097\n",
      "201/431 | Loss:0.6965 | top1:50.5597 | AUROC:0.5153\n",
      "301/431 | Loss:0.6969 | top1:50.2824 | AUROC:0.5142\n",
      "401/431 | Loss:0.6965 | top1:50.2587 | AUROC:0.5151\n",
      "431/431 | Loss:0.6965 | top1:50.2079 | AUROC:0.5144\n",
      "49/49 | Loss:0.6937 | top1:50.7564 | AUROC:0.5168\n",
      "\n",
      "Epoch: [3 | 300] LR: 0.096000\n",
      "1/431 | Loss:0.6992 | top1:43.1250 | AUROC:0.5380\n",
      "101/431 | Loss:0.6957 | top1:50.5198 | AUROC:0.5185\n",
      "201/431 | Loss:0.6962 | top1:50.3420 | AUROC:0.5195\n",
      "301/431 | Loss:0.6957 | top1:50.3551 | AUROC:0.5193\n",
      "401/431 | Loss:0.6952 | top1:50.4972 | AUROC:0.5206\n",
      "431/431 | Loss:0.6952 | top1:50.5000 | AUROC:0.5200\n",
      "49/49 | Loss:0.7043 | top1:50.0000 | AUROC:0.5211\n",
      "\n",
      "Epoch: [4 | 300] LR: 0.124000\n",
      "1/431 | Loss:0.7145 | top1:46.8750 | AUROC:0.5123\n",
      "101/431 | Loss:0.6977 | top1:51.0025 | AUROC:0.5169\n",
      "201/431 | Loss:0.6964 | top1:50.7058 | AUROC:0.5156\n",
      "301/431 | Loss:0.6953 | top1:50.9385 | AUROC:0.5192\n",
      "401/431 | Loss:0.6957 | top1:50.8791 | AUROC:0.5179\n",
      "431/431 | Loss:0.6957 | top1:50.8343 | AUROC:0.5176\n",
      "49/49 | Loss:0.6937 | top1:50.0256 | AUROC:0.5194\n",
      "\n",
      "Epoch: [5 | 300] LR: 0.152000\n",
      "1/431 | Loss:0.6902 | top1:54.3750 | AUROC:0.4927\n",
      "101/431 | Loss:0.6947 | top1:50.9530 | AUROC:0.5206\n",
      "201/431 | Loss:0.6946 | top1:50.8893 | AUROC:0.5219\n",
      "301/431 | Loss:0.6943 | top1:50.8783 | AUROC:0.5208\n",
      "401/431 | Loss:0.6941 | top1:50.9835 | AUROC:0.5202\n",
      "431/431 | Loss:0.6945 | top1:50.8866 | AUROC:0.5200\n",
      "49/49 | Loss:0.6990 | top1:49.9744 | AUROC:0.5115\n",
      "\n",
      "Epoch: [6 | 300] LR: 0.180000\n",
      "1/431 | Loss:0.6976 | top1:50.0000 | AUROC:0.5552\n",
      "101/431 | Loss:0.6965 | top1:50.9406 | AUROC:0.5185\n",
      "201/431 | Loss:0.6957 | top1:50.8333 | AUROC:0.5189\n",
      "301/431 | Loss:0.6951 | top1:50.6956 | AUROC:0.5192\n",
      "401/431 | Loss:0.6947 | top1:50.5923 | AUROC:0.5201\n",
      "431/431 | Loss:0.6946 | top1:50.6526 | AUROC:0.5208\n",
      "49/49 | Loss:0.6928 | top1:50.7564 | AUROC:0.5243\n",
      "\n",
      "Epoch: [7 | 300] LR: 0.208000\n",
      "1/431 | Loss:0.6938 | top1:48.1250 | AUROC:0.4937\n",
      "101/431 | Loss:0.6936 | top1:50.6621 | AUROC:0.5179\n",
      "201/431 | Loss:0.6937 | top1:50.7463 | AUROC:0.5203\n",
      "301/431 | Loss:0.6937 | top1:50.8119 | AUROC:0.5221\n",
      "401/431 | Loss:0.6938 | top1:50.7512 | AUROC:0.5238\n",
      "431/431 | Loss:0.6942 | top1:50.6439 | AUROC:0.5246\n",
      "49/49 | Loss:0.6935 | top1:50.0641 | AUROC:0.5209\n",
      "\n",
      "Epoch: [8 | 300] LR: 0.236000\n",
      "1/431 | Loss:0.6899 | top1:53.1250 | AUROC:0.5602\n",
      "101/431 | Loss:0.6951 | top1:50.7240 | AUROC:0.5165\n",
      "201/431 | Loss:0.6945 | top1:50.6716 | AUROC:0.5181\n",
      "301/431 | Loss:0.6946 | top1:50.4194 | AUROC:0.5183\n",
      "401/431 | Loss:0.6948 | top1:50.2868 | AUROC:0.5194\n",
      "431/431 | Loss:0.6948 | top1:50.2791 | AUROC:0.5205\n",
      "49/49 | Loss:0.6932 | top1:50.0000 | AUROC:0.5254\n",
      "\n",
      "Epoch: [9 | 300] LR: 0.264000\n",
      "1/431 | Loss:0.6918 | top1:58.7500 | AUROC:0.4068\n",
      "101/431 | Loss:0.6937 | top1:50.7426 | AUROC:0.5226\n",
      "201/431 | Loss:0.6940 | top1:50.5908 | AUROC:0.5221\n",
      "301/431 | Loss:0.6939 | top1:50.5482 | AUROC:0.5202\n",
      "401/431 | Loss:0.6937 | top1:50.6406 | AUROC:0.5244\n",
      "431/431 | Loss:0.6938 | top1:50.6831 | AUROC:0.5248\n",
      "49/49 | Loss:0.6933 | top1:50.2949 | AUROC:0.5229\n",
      "\n",
      "Epoch: [10 | 300] LR: 0.292000\n",
      "1/431 | Loss:0.6884 | top1:51.2500 | AUROC:0.6255\n",
      "101/431 | Loss:0.6963 | top1:50.4146 | AUROC:0.5311\n",
      "201/431 | Loss:0.6961 | top1:50.5379 | AUROC:0.5276\n",
      "301/431 | Loss:0.6957 | top1:50.4859 | AUROC:0.5235\n",
      "401/431 | Loss:0.6953 | top1:50.5408 | AUROC:0.5237\n",
      "431/431 | Loss:0.6953 | top1:50.5698 | AUROC:0.5234\n",
      "49/49 | Loss:0.6943 | top1:50.0000 | AUROC:0.5236\n",
      "\n",
      "Epoch: [11 | 300] LR: 0.320000\n",
      "1/431 | Loss:0.6922 | top1:52.5000 | AUROC:0.5164\n",
      "101/431 | Loss:0.6958 | top1:50.3465 | AUROC:0.5213\n",
      "201/431 | Loss:0.6955 | top1:50.2550 | AUROC:0.5198\n",
      "301/431 | Loss:0.6959 | top1:50.3364 | AUROC:0.5197\n",
      "401/431 | Loss:0.6955 | top1:50.4068 | AUROC:0.5221\n",
      "431/431 | Loss:0.6953 | top1:50.4942 | AUROC:0.5228\n",
      "49/49 | Loss:0.6938 | top1:50.2564 | AUROC:0.5229\n",
      "\n",
      "Epoch: [12 | 300] LR: 0.320000\n",
      "1/431 | Loss:0.6894 | top1:56.2500 | AUROC:0.5514\n",
      "101/431 | Loss:0.6946 | top1:50.1980 | AUROC:0.5268\n",
      "201/431 | Loss:0.6961 | top1:49.7948 | AUROC:0.5285\n",
      "301/431 | Loss:0.6959 | top1:49.9813 | AUROC:0.5277\n",
      "401/431 | Loss:0.6955 | top1:50.2790 | AUROC:0.5291\n",
      "431/431 | Loss:0.6954 | top1:50.2980 | AUROC:0.5287\n",
      "49/49 | Loss:0.6932 | top1:50.5513 | AUROC:0.5271\n",
      "\n",
      "Epoch: [13 | 300] LR: 0.319991\n",
      "1/431 | Loss:0.6871 | top1:52.5000 | AUROC:0.5501\n",
      "101/431 | Loss:0.6947 | top1:50.2908 | AUROC:0.5307\n",
      "201/431 | Loss:0.6955 | top1:50.6530 | AUROC:0.5293\n",
      "301/431 | Loss:0.6960 | top1:50.4527 | AUROC:0.5274\n",
      "401/431 | Loss:0.6959 | top1:50.4754 | AUROC:0.5273\n",
      "431/431 | Loss:0.6960 | top1:50.4375 | AUROC:0.5267\n",
      "49/49 | Loss:0.6928 | top1:51.0897 | AUROC:0.5237\n",
      "\n",
      "Epoch: [14 | 300] LR: 0.319965\n",
      "1/431 | Loss:0.6927 | top1:52.5000 | AUROC:0.5152\n",
      "101/431 | Loss:0.6936 | top1:50.8663 | AUROC:0.5288\n",
      "201/431 | Loss:0.6935 | top1:50.8955 | AUROC:0.5288\n",
      "301/431 | Loss:0.6937 | top1:50.8160 | AUROC:0.5298\n",
      "401/431 | Loss:0.6940 | top1:50.7996 | AUROC:0.5296\n",
      "431/431 | Loss:0.6939 | top1:50.8401 | AUROC:0.5298\n",
      "49/49 | Loss:0.6936 | top1:50.9872 | AUROC:0.5243\n",
      "\n",
      "Epoch: [15 | 300] LR: 0.319921\n",
      "1/431 | Loss:0.6932 | top1:50.6250 | AUROC:0.5425\n",
      "101/431 | Loss:0.6988 | top1:50.3527 | AUROC:0.5264\n",
      "201/431 | Loss:0.6970 | top1:50.6592 | AUROC:0.5304\n",
      "301/431 | Loss:0.6958 | top1:50.7787 | AUROC:0.5289\n",
      "401/431 | Loss:0.6950 | top1:50.9398 | AUROC:0.5312\n",
      "431/431 | Loss:0.6949 | top1:50.9535 | AUROC:0.5310\n",
      "49/49 | Loss:0.6917 | top1:51.9231 | AUROC:0.5267\n",
      "\n",
      "Epoch: [16 | 300] LR: 0.319860\n",
      "1/431 | Loss:0.6875 | top1:53.7500 | AUROC:0.5672\n",
      "101/431 | Loss:0.6950 | top1:51.0644 | AUROC:0.5426\n",
      "201/431 | Loss:0.6947 | top1:50.8364 | AUROC:0.5378\n",
      "301/431 | Loss:0.6945 | top1:50.8866 | AUROC:0.5346\n",
      "401/431 | Loss:0.6945 | top1:50.7933 | AUROC:0.5346\n",
      "431/431 | Loss:0.6947 | top1:50.8110 | AUROC:0.5340\n",
      "49/49 | Loss:0.6925 | top1:51.3205 | AUROC:0.5183\n",
      "\n",
      "Epoch: [17 | 300] LR: 0.319781\n",
      "1/431 | Loss:0.6936 | top1:49.3750 | AUROC:0.4733\n",
      "101/431 | Loss:0.6919 | top1:52.0854 | AUROC:0.5385\n",
      "201/431 | Loss:0.6926 | top1:51.6947 | AUROC:0.5399\n",
      "301/431 | Loss:0.6938 | top1:51.4701 | AUROC:0.5401\n",
      "401/431 | Loss:0.6938 | top1:51.4698 | AUROC:0.5380\n",
      "431/431 | Loss:0.6938 | top1:51.4012 | AUROC:0.5373\n",
      "49/49 | Loss:0.6965 | top1:50.0000 | AUROC:0.5368\n",
      "\n",
      "Epoch: [18 | 300] LR: 0.319684\n",
      "1/431 | Loss:0.6795 | top1:54.3750 | AUROC:0.6349\n",
      "101/431 | Loss:0.6927 | top1:51.4418 | AUROC:0.5360\n",
      "201/431 | Loss:0.6931 | top1:51.2220 | AUROC:0.5387\n",
      "301/431 | Loss:0.6942 | top1:51.1752 | AUROC:0.5401\n",
      "401/431 | Loss:0.6939 | top1:51.1986 | AUROC:0.5399\n",
      "431/431 | Loss:0.6938 | top1:51.3125 | AUROC:0.5404\n",
      "49/49 | Loss:0.6960 | top1:50.0000 | AUROC:0.5445\n",
      "\n",
      "Epoch: [19 | 300] LR: 0.319570\n",
      "1/431 | Loss:0.6949 | top1:47.5000 | AUROC:0.5611\n",
      "101/431 | Loss:0.6907 | top1:52.8651 | AUROC:0.5585\n",
      "201/431 | Loss:0.6919 | top1:52.0989 | AUROC:0.5497\n",
      "301/431 | Loss:0.6922 | top1:52.0058 | AUROC:0.5478\n",
      "401/431 | Loss:0.6921 | top1:52.1213 | AUROC:0.5498\n",
      "431/431 | Loss:0.6922 | top1:52.1163 | AUROC:0.5492\n",
      "49/49 | Loss:0.7000 | top1:50.0000 | AUROC:0.5459\n",
      "\n",
      "Epoch: [20 | 300] LR: 0.319439\n",
      "1/431 | Loss:0.7136 | top1:45.0000 | AUROC:0.5909\n",
      "101/431 | Loss:0.6926 | top1:52.2463 | AUROC:0.5513\n",
      "201/431 | Loss:0.6935 | top1:51.3557 | AUROC:0.5462\n",
      "301/431 | Loss:0.6935 | top1:51.3808 | AUROC:0.5475\n",
      "401/431 | Loss:0.6935 | top1:51.2827 | AUROC:0.5474\n",
      "431/431 | Loss:0.6936 | top1:51.2195 | AUROC:0.5474\n",
      "49/49 | Loss:0.6884 | top1:54.1154 | AUROC:0.5559\n",
      "\n",
      "Epoch: [21 | 300] LR: 0.319290\n",
      "1/431 | Loss:0.6945 | top1:50.0000 | AUROC:0.5162\n",
      "101/431 | Loss:0.6916 | top1:52.0792 | AUROC:0.5481\n",
      "201/431 | Loss:0.6920 | top1:52.1486 | AUROC:0.5509\n",
      "301/431 | Loss:0.6923 | top1:52.0806 | AUROC:0.5524\n",
      "401/431 | Loss:0.6928 | top1:52.0371 | AUROC:0.5511\n",
      "431/431 | Loss:0.6929 | top1:51.8881 | AUROC:0.5497\n",
      "49/49 | Loss:0.6969 | top1:50.0000 | AUROC:0.5327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [22 | 300] LR: 0.319124\n",
      "1/431 | Loss:0.6912 | top1:53.1250 | AUROC:0.5308\n",
      "101/431 | Loss:0.6908 | top1:52.1411 | AUROC:0.5567\n",
      "201/431 | Loss:0.6927 | top1:51.9963 | AUROC:0.5591\n",
      "301/431 | Loss:0.6926 | top1:51.7629 | AUROC:0.5562\n",
      "401/431 | Loss:0.6920 | top1:52.1010 | AUROC:0.5536\n",
      "431/431 | Loss:0.6918 | top1:52.1584 | AUROC:0.5539\n",
      "49/49 | Loss:0.6861 | top1:53.6923 | AUROC:0.5686\n",
      "\n",
      "Epoch: [23 | 300] LR: 0.318940\n",
      "1/431 | Loss:0.6870 | top1:51.2500 | AUROC:0.5434\n",
      "101/431 | Loss:0.6902 | top1:52.8713 | AUROC:0.5617\n",
      "201/431 | Loss:0.6902 | top1:52.8731 | AUROC:0.5652\n",
      "301/431 | Loss:0.6901 | top1:53.0876 | AUROC:0.5655\n",
      "401/431 | Loss:0.6899 | top1:53.2466 | AUROC:0.5690\n",
      "431/431 | Loss:0.6899 | top1:53.2340 | AUROC:0.5696\n",
      "49/49 | Loss:0.6849 | top1:55.2821 | AUROC:0.5709\n",
      "\n",
      "Epoch: [24 | 300] LR: 0.318738\n",
      "1/431 | Loss:0.6832 | top1:56.2500 | AUROC:0.5652\n",
      "101/431 | Loss:0.6916 | top1:53.2921 | AUROC:0.5713\n",
      "201/431 | Loss:0.6941 | top1:52.2295 | AUROC:0.5682\n",
      "301/431 | Loss:0.6919 | top1:52.9568 | AUROC:0.5709\n",
      "401/431 | Loss:0.6908 | top1:53.3681 | AUROC:0.5728\n",
      "431/431 | Loss:0.6903 | top1:53.5116 | AUROC:0.5736\n",
      "49/49 | Loss:0.6825 | top1:55.2949 | AUROC:0.5998\n",
      "\n",
      "Epoch: [25 | 300] LR: 0.318520\n",
      "1/431 | Loss:0.6907 | top1:50.0000 | AUROC:0.5900\n",
      "101/431 | Loss:0.6856 | top1:54.8639 | AUROC:0.5874\n",
      "201/431 | Loss:0.6838 | top1:55.5442 | AUROC:0.5954\n",
      "301/431 | Loss:0.6821 | top1:56.2978 | AUROC:0.6080\n",
      "401/431 | Loss:0.6731 | top1:57.9302 | AUROC:0.6304\n",
      "431/431 | Loss:0.6692 | top1:58.5436 | AUROC:0.6374\n",
      "49/49 | Loss:0.5829 | top1:70.2051 | AUROC:0.7814\n",
      "\n",
      "Epoch: [26 | 300] LR: 0.318284\n",
      "1/431 | Loss:0.5552 | top1:70.0000 | AUROC:0.8229\n",
      "101/431 | Loss:0.6095 | top1:67.2896 | AUROC:0.7581\n",
      "201/431 | Loss:0.5793 | top1:69.7637 | AUROC:0.7828\n",
      "301/431 | Loss:0.5589 | top1:71.4016 | AUROC:0.7995\n",
      "401/431 | Loss:0.5485 | top1:72.2522 | AUROC:0.8102\n",
      "431/431 | Loss:0.5459 | top1:72.4637 | AUROC:0.8133\n",
      "49/49 | Loss:0.4612 | top1:78.5897 | AUROC:0.8773\n",
      "\n",
      "Epoch: [27 | 300] LR: 0.318030\n",
      "1/431 | Loss:0.4855 | top1:76.2500 | AUROC:0.8538\n",
      "101/431 | Loss:0.4779 | top1:77.3577 | AUROC:0.8634\n",
      "201/431 | Loss:0.4735 | top1:77.6461 | AUROC:0.8677\n",
      "301/431 | Loss:0.4583 | top1:78.4115 | AUROC:0.8744\n",
      "401/431 | Loss:0.4499 | top1:78.9713 | AUROC:0.8792\n",
      "431/431 | Loss:0.4465 | top1:79.1919 | AUROC:0.8808\n",
      "49/49 | Loss:0.3545 | top1:84.6410 | AUROC:0.9207\n",
      "\n",
      "Epoch: [28 | 300] LR: 0.317759\n",
      "1/431 | Loss:0.4676 | top1:80.6250 | AUROC:0.8666\n",
      "101/431 | Loss:0.4096 | top1:81.2067 | AUROC:0.9016\n",
      "201/431 | Loss:0.3932 | top1:82.2077 | AUROC:0.9109\n",
      "301/431 | Loss:0.3850 | top1:82.7139 | AUROC:0.9141\n",
      "401/431 | Loss:0.3779 | top1:83.1624 | AUROC:0.9174\n",
      "431/431 | Loss:0.3762 | top1:83.2587 | AUROC:0.9182\n",
      "49/49 | Loss:0.2961 | top1:87.6154 | AUROC:0.9559\n",
      "\n",
      "Epoch: [29 | 300] LR: 0.317471\n",
      "1/431 | Loss:0.3088 | top1:85.0000 | AUROC:0.9485\n",
      "101/431 | Loss:0.3363 | top1:85.5446 | AUROC:0.9338\n",
      "201/431 | Loss:0.3273 | top1:85.9297 | AUROC:0.9373\n",
      "301/431 | Loss:0.3245 | top1:86.0673 | AUROC:0.9384\n",
      "401/431 | Loss:0.3204 | top1:86.3295 | AUROC:0.9401\n",
      "431/431 | Loss:0.3185 | top1:86.4070 | AUROC:0.9409\n",
      "49/49 | Loss:0.2160 | top1:91.3077 | AUROC:0.9723\n",
      "\n",
      "Epoch: [30 | 300] LR: 0.317166\n",
      "1/431 | Loss:0.2593 | top1:90.0000 | AUROC:0.9520\n",
      "101/431 | Loss:0.2996 | top1:87.1102 | AUROC:0.9477\n",
      "201/431 | Loss:0.2932 | top1:87.3445 | AUROC:0.9510\n",
      "301/431 | Loss:0.2930 | top1:87.4460 | AUROC:0.9521\n",
      "401/431 | Loss:0.2885 | top1:87.7213 | AUROC:0.9538\n",
      "431/431 | Loss:0.2884 | top1:87.7195 | AUROC:0.9541\n",
      "49/49 | Loss:0.1821 | top1:92.8462 | AUROC:0.9788\n",
      "\n",
      "Epoch: [31 | 300] LR: 0.316843\n",
      "1/431 | Loss:0.2490 | top1:90.0000 | AUROC:0.9614\n",
      "101/431 | Loss:0.2472 | top1:89.5978 | AUROC:0.9651\n",
      "201/431 | Loss:0.2531 | top1:89.1542 | AUROC:0.9647\n",
      "301/431 | Loss:0.2501 | top1:89.4622 | AUROC:0.9646\n",
      "401/431 | Loss:0.2497 | top1:89.5184 | AUROC:0.9648\n",
      "431/431 | Loss:0.2490 | top1:89.5480 | AUROC:0.9650\n",
      "49/49 | Loss:0.1871 | top1:92.7436 | AUROC:0.9838\n",
      "\n",
      "Epoch: [32 | 300] LR: 0.316504\n",
      "1/431 | Loss:0.2028 | top1:90.6250 | AUROC:0.9775\n",
      "101/431 | Loss:0.2296 | top1:90.5384 | AUROC:0.9703\n",
      "201/431 | Loss:0.2356 | top1:90.3514 | AUROC:0.9691\n",
      "301/431 | Loss:0.2341 | top1:90.4610 | AUROC:0.9696\n",
      "401/431 | Loss:0.2295 | top1:90.6437 | AUROC:0.9707\n",
      "431/431 | Loss:0.2282 | top1:90.6991 | AUROC:0.9710\n",
      "49/49 | Loss:0.1628 | top1:93.8590 | AUROC:0.9858\n",
      "\n",
      "Epoch: [33 | 300] LR: 0.316147\n",
      "1/431 | Loss:0.2263 | top1:89.3750 | AUROC:0.9683\n",
      "101/431 | Loss:0.2055 | top1:91.5037 | AUROC:0.9776\n",
      "201/431 | Loss:0.2095 | top1:91.4988 | AUROC:0.9762\n",
      "301/431 | Loss:0.2084 | top1:91.5801 | AUROC:0.9762\n",
      "401/431 | Loss:0.2101 | top1:91.5586 | AUROC:0.9759\n",
      "431/431 | Loss:0.2083 | top1:91.6599 | AUROC:0.9762\n",
      "49/49 | Loss:0.1697 | top1:93.3333 | AUROC:0.9914\n",
      "\n",
      "Epoch: [34 | 300] LR: 0.315773\n",
      "1/431 | Loss:0.1841 | top1:91.2500 | AUROC:0.9875\n",
      "101/431 | Loss:0.2051 | top1:91.6522 | AUROC:0.9773\n",
      "201/431 | Loss:0.1967 | top1:91.9652 | AUROC:0.9789\n",
      "301/431 | Loss:0.1946 | top1:92.0598 | AUROC:0.9796\n",
      "401/431 | Loss:0.1914 | top1:92.2413 | AUROC:0.9803\n",
      "431/431 | Loss:0.1908 | top1:92.2747 | AUROC:0.9804\n",
      "49/49 | Loss:0.1393 | top1:94.7308 | AUROC:0.9921\n",
      "\n",
      "Epoch: [35 | 300] LR: 0.315381\n",
      "1/431 | Loss:0.1676 | top1:93.1250 | AUROC:0.9829\n",
      "101/431 | Loss:0.1821 | top1:92.5371 | AUROC:0.9828\n",
      "201/431 | Loss:0.1771 | top1:92.8980 | AUROC:0.9832\n",
      "301/431 | Loss:0.1760 | top1:92.8945 | AUROC:0.9833\n",
      "401/431 | Loss:0.1735 | top1:92.9925 | AUROC:0.9836\n",
      "431/431 | Loss:0.1739 | top1:92.9855 | AUROC:0.9836\n",
      "49/49 | Loss:0.1184 | top1:95.6154 | AUROC:0.9938\n",
      "\n",
      "Epoch: [36 | 300] LR: 0.314973\n",
      "1/431 | Loss:0.2093 | top1:89.3750 | AUROC:0.9847\n",
      "101/431 | Loss:0.1671 | top1:93.3478 | AUROC:0.9847\n",
      "201/431 | Loss:0.1647 | top1:93.3738 | AUROC:0.9849\n",
      "301/431 | Loss:0.1637 | top1:93.4385 | AUROC:0.9854\n",
      "401/431 | Loss:0.1607 | top1:93.6160 | AUROC:0.9857\n",
      "431/431 | Loss:0.1614 | top1:93.5814 | AUROC:0.9856\n",
      "49/49 | Loss:0.1403 | top1:94.5769 | AUROC:0.9933\n",
      "\n",
      "Epoch: [37 | 300] LR: 0.314548\n",
      "1/431 | Loss:0.1847 | top1:93.1250 | AUROC:0.9909\n",
      "101/431 | Loss:0.1525 | top1:93.8181 | AUROC:0.9869\n",
      "201/431 | Loss:0.1532 | top1:93.8029 | AUROC:0.9866\n",
      "301/431 | Loss:0.1541 | top1:93.8642 | AUROC:0.9868\n",
      "401/431 | Loss:0.1512 | top1:93.9807 | AUROC:0.9872\n",
      "431/431 | Loss:0.1529 | top1:93.9317 | AUROC:0.9870\n",
      "49/49 | Loss:0.1126 | top1:95.7051 | AUROC:0.9937\n",
      "\n",
      "Epoch: [38 | 300] LR: 0.314106\n",
      "1/431 | Loss:0.1368 | top1:95.0000 | AUROC:0.9892\n",
      "101/431 | Loss:0.1446 | top1:94.4369 | AUROC:0.9888\n",
      "201/431 | Loss:0.1450 | top1:94.3128 | AUROC:0.9885\n",
      "301/431 | Loss:0.1457 | top1:94.2629 | AUROC:0.9886\n",
      "401/431 | Loss:0.1466 | top1:94.2207 | AUROC:0.9885\n",
      "431/431 | Loss:0.1452 | top1:94.3009 | AUROC:0.9887\n",
      "49/49 | Loss:0.0894 | top1:96.6410 | AUROC:0.9957\n",
      "\n",
      "Epoch: [39 | 300] LR: 0.313647\n",
      "1/431 | Loss:0.1219 | top1:93.1250 | AUROC:0.9950\n",
      "101/431 | Loss:0.1339 | top1:94.7649 | AUROC:0.9905\n",
      "201/431 | Loss:0.1329 | top1:94.8725 | AUROC:0.9905\n",
      "301/431 | Loss:0.1332 | top1:94.8360 | AUROC:0.9905\n",
      "401/431 | Loss:0.1352 | top1:94.7241 | AUROC:0.9904\n",
      "431/431 | Loss:0.1344 | top1:94.7674 | AUROC:0.9905\n",
      "49/49 | Loss:0.0819 | top1:97.0256 | AUROC:0.9961\n",
      "\n",
      "Epoch: [40 | 300] LR: 0.313171\n",
      "1/431 | Loss:0.1002 | top1:95.0000 | AUROC:0.9947\n",
      "101/431 | Loss:0.1310 | top1:94.8082 | AUROC:0.9902\n",
      "201/431 | Loss:0.1299 | top1:94.8912 | AUROC:0.9907\n",
      "301/431 | Loss:0.1259 | top1:95.0893 | AUROC:0.9914\n",
      "401/431 | Loss:0.1269 | top1:95.0234 | AUROC:0.9912\n",
      "431/431 | Loss:0.1254 | top1:95.0698 | AUROC:0.9914\n",
      "49/49 | Loss:0.0757 | top1:97.2436 | AUROC:0.9970\n",
      "\n",
      "Epoch: [41 | 300] LR: 0.312678\n",
      "1/431 | Loss:0.1185 | top1:94.3750 | AUROC:0.9897\n",
      "101/431 | Loss:0.1251 | top1:95.1238 | AUROC:0.9926\n",
      "201/431 | Loss:0.1215 | top1:95.2923 | AUROC:0.9925\n",
      "301/431 | Loss:0.1212 | top1:95.2969 | AUROC:0.9925\n",
      "401/431 | Loss:0.1211 | top1:95.2915 | AUROC:0.9925\n",
      "431/431 | Loss:0.1213 | top1:95.2820 | AUROC:0.9924\n",
      "49/49 | Loss:0.0813 | top1:97.0513 | AUROC:0.9959\n",
      "\n",
      "Epoch: [42 | 300] LR: 0.312169\n",
      "1/431 | Loss:0.1012 | top1:96.8750 | AUROC:0.9937\n",
      "101/431 | Loss:0.1152 | top1:95.3960 | AUROC:0.9929\n",
      "201/431 | Loss:0.1158 | top1:95.4633 | AUROC:0.9929\n",
      "301/431 | Loss:0.1173 | top1:95.4651 | AUROC:0.9927\n",
      "401/431 | Loss:0.1171 | top1:95.4567 | AUROC:0.9928\n",
      "431/431 | Loss:0.1169 | top1:95.4695 | AUROC:0.9928\n",
      "49/49 | Loss:0.0784 | top1:97.0128 | AUROC:0.9961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [43 | 300] LR: 0.311643\n",
      "1/431 | Loss:0.0499 | top1:98.1250 | AUROC:0.9992\n",
      "101/431 | Loss:0.1068 | top1:96.0272 | AUROC:0.9937\n",
      "201/431 | Loss:0.1080 | top1:96.0417 | AUROC:0.9936\n",
      "301/431 | Loss:0.1106 | top1:95.9198 | AUROC:0.9933\n",
      "401/431 | Loss:0.1097 | top1:95.8650 | AUROC:0.9935\n",
      "431/431 | Loss:0.1084 | top1:95.9259 | AUROC:0.9936\n",
      "49/49 | Loss:0.0915 | top1:96.8846 | AUROC:0.9970\n",
      "\n",
      "Epoch: [44 | 300] LR: 0.311100\n",
      "1/431 | Loss:0.1850 | top1:95.6250 | AUROC:0.9847\n",
      "101/431 | Loss:0.1047 | top1:95.9406 | AUROC:0.9942\n",
      "201/431 | Loss:0.1024 | top1:96.0852 | AUROC:0.9943\n",
      "301/431 | Loss:0.1037 | top1:96.0278 | AUROC:0.9942\n",
      "401/431 | Loss:0.1031 | top1:96.0505 | AUROC:0.9943\n",
      "431/431 | Loss:0.1029 | top1:96.0552 | AUROC:0.9943\n",
      "49/49 | Loss:0.0540 | top1:98.1154 | AUROC:0.9981\n",
      "\n",
      "Epoch: [45 | 300] LR: 0.310541\n",
      "1/431 | Loss:0.1163 | top1:95.0000 | AUROC:0.9967\n",
      "101/431 | Loss:0.0950 | top1:96.2809 | AUROC:0.9953\n",
      "201/431 | Loss:0.0969 | top1:96.2282 | AUROC:0.9950\n",
      "301/431 | Loss:0.0950 | top1:96.2895 | AUROC:0.9952\n",
      "401/431 | Loss:0.0974 | top1:96.2391 | AUROC:0.9949\n",
      "431/431 | Loss:0.0976 | top1:96.2413 | AUROC:0.9949\n",
      "49/49 | Loss:0.0565 | top1:98.1795 | AUROC:0.9982\n",
      "\n",
      "Epoch: [46 | 300] LR: 0.309965\n",
      "1/431 | Loss:0.0367 | top1:99.3750 | AUROC:0.9998\n",
      "101/431 | Loss:0.0990 | top1:96.2314 | AUROC:0.9949\n",
      "201/431 | Loss:0.1003 | top1:96.1567 | AUROC:0.9947\n",
      "301/431 | Loss:0.0982 | top1:96.2978 | AUROC:0.9949\n",
      "401/431 | Loss:0.0966 | top1:96.4027 | AUROC:0.9951\n",
      "431/431 | Loss:0.0969 | top1:96.3895 | AUROC:0.9951\n",
      "49/49 | Loss:0.0674 | top1:97.4231 | AUROC:0.9986\n",
      "\n",
      "Epoch: [47 | 300] LR: 0.309373\n",
      "1/431 | Loss:0.0555 | top1:98.1250 | AUROC:1.0000\n",
      "101/431 | Loss:0.0857 | top1:96.7141 | AUROC:0.9960\n",
      "201/431 | Loss:0.0942 | top1:96.4210 | AUROC:0.9955\n",
      "301/431 | Loss:0.0935 | top1:96.4680 | AUROC:0.9953\n",
      "401/431 | Loss:0.0935 | top1:96.4417 | AUROC:0.9954\n",
      "431/431 | Loss:0.0956 | top1:96.3837 | AUROC:0.9953\n",
      "49/49 | Loss:0.0671 | top1:97.5513 | AUROC:0.9982\n",
      "\n",
      "Epoch: [48 | 300] LR: 0.308764\n",
      "1/431 | Loss:0.1299 | top1:93.7500 | AUROC:0.9912\n",
      "101/431 | Loss:0.0977 | top1:96.1757 | AUROC:0.9953\n",
      "201/431 | Loss:0.0918 | top1:96.4801 | AUROC:0.9955\n",
      "301/431 | Loss:0.0920 | top1:96.5386 | AUROC:0.9954\n",
      "401/431 | Loss:0.0911 | top1:96.5789 | AUROC:0.9956\n",
      "431/431 | Loss:0.0906 | top1:96.6032 | AUROC:0.9956\n",
      "49/49 | Loss:0.0568 | top1:97.8974 | AUROC:0.9987\n",
      "\n",
      "Epoch: [49 | 300] LR: 0.308139\n",
      "1/431 | Loss:0.0707 | top1:98.1250 | AUROC:0.9965\n",
      "101/431 | Loss:0.0954 | top1:96.2871 | AUROC:0.9957\n",
      "201/431 | Loss:0.0909 | top1:96.4894 | AUROC:0.9960\n",
      "301/431 | Loss:0.0906 | top1:96.5386 | AUROC:0.9958\n",
      "401/431 | Loss:0.0903 | top1:96.5461 | AUROC:0.9958\n",
      "431/431 | Loss:0.0900 | top1:96.5465 | AUROC:0.9958\n",
      "49/49 | Loss:0.0386 | top1:98.6923 | AUROC:0.9991\n",
      "\n",
      "Epoch: [50 | 300] LR: 0.307498\n",
      "1/431 | Loss:0.0678 | top1:97.5000 | AUROC:0.9969\n",
      "101/431 | Loss:0.0899 | top1:96.5408 | AUROC:0.9960\n",
      "201/431 | Loss:0.0909 | top1:96.5827 | AUROC:0.9956\n",
      "301/431 | Loss:0.0910 | top1:96.5552 | AUROC:0.9956\n",
      "401/431 | Loss:0.0909 | top1:96.5243 | AUROC:0.9957\n",
      "431/431 | Loss:0.0903 | top1:96.5451 | AUROC:0.9958\n",
      "49/49 | Loss:0.0561 | top1:98.0385 | AUROC:0.9980\n",
      "\n",
      "Epoch: [51 | 300] LR: 0.306841\n",
      "1/431 | Loss:0.0703 | top1:97.5000 | AUROC:0.9971\n",
      "101/431 | Loss:0.0865 | top1:96.6151 | AUROC:0.9958\n",
      "201/431 | Loss:0.0874 | top1:96.6822 | AUROC:0.9959\n",
      "301/431 | Loss:0.0896 | top1:96.5988 | AUROC:0.9957\n",
      "401/431 | Loss:0.0911 | top1:96.5461 | AUROC:0.9955\n",
      "431/431 | Loss:0.0906 | top1:96.5756 | AUROC:0.9956\n",
      "49/49 | Loss:0.0770 | top1:96.7692 | AUROC:0.9983\n",
      "\n",
      "Epoch: [52 | 300] LR: 0.306167\n",
      "1/431 | Loss:0.0795 | top1:97.5000 | AUROC:0.9964\n",
      "101/431 | Loss:0.0891 | top1:96.6337 | AUROC:0.9959\n",
      "201/431 | Loss:0.0868 | top1:96.7289 | AUROC:0.9959\n",
      "301/431 | Loss:0.0891 | top1:96.6549 | AUROC:0.9958\n",
      "401/431 | Loss:0.0881 | top1:96.6786 | AUROC:0.9958\n",
      "431/431 | Loss:0.0877 | top1:96.6875 | AUROC:0.9959\n",
      "49/49 | Loss:0.0517 | top1:98.2179 | AUROC:0.9984\n",
      "\n",
      "Epoch: [53 | 300] LR: 0.305478\n",
      "1/431 | Loss:0.0859 | top1:96.8750 | AUROC:0.9961\n",
      "101/431 | Loss:0.0778 | top1:97.0916 | AUROC:0.9968\n",
      "201/431 | Loss:0.0852 | top1:96.7693 | AUROC:0.9964\n",
      "301/431 | Loss:0.0831 | top1:96.8189 | AUROC:0.9965\n",
      "401/431 | Loss:0.0826 | top1:96.8501 | AUROC:0.9965\n",
      "431/431 | Loss:0.0821 | top1:96.8765 | AUROC:0.9966\n",
      "49/49 | Loss:0.0487 | top1:98.2436 | AUROC:0.9986\n",
      "\n",
      "Epoch: [54 | 300] LR: 0.304772\n",
      "1/431 | Loss:0.0434 | top1:98.7500 | AUROC:0.9995\n",
      "101/431 | Loss:0.0814 | top1:96.9369 | AUROC:0.9969\n",
      "201/431 | Loss:0.0887 | top1:96.6263 | AUROC:0.9963\n",
      "301/431 | Loss:0.0887 | top1:96.6217 | AUROC:0.9963\n",
      "401/431 | Loss:0.0861 | top1:96.7363 | AUROC:0.9965\n",
      "431/431 | Loss:0.0865 | top1:96.7238 | AUROC:0.9964\n",
      "49/49 | Loss:0.0576 | top1:97.9359 | AUROC:0.9987\n",
      "\n",
      "Epoch: [55 | 300] LR: 0.304051\n",
      "1/431 | Loss:0.0906 | top1:95.6250 | AUROC:0.9962\n",
      "101/431 | Loss:0.0814 | top1:97.0668 | AUROC:0.9964\n",
      "201/431 | Loss:0.0785 | top1:97.0460 | AUROC:0.9968\n",
      "301/431 | Loss:0.0801 | top1:96.9560 | AUROC:0.9966\n",
      "401/431 | Loss:0.0801 | top1:96.9560 | AUROC:0.9966\n",
      "431/431 | Loss:0.0803 | top1:96.9390 | AUROC:0.9966\n",
      "49/49 | Loss:0.0588 | top1:97.7949 | AUROC:0.9982\n",
      "\n",
      "Epoch: [56 | 300] LR: 0.303314\n",
      "1/431 | Loss:0.1345 | top1:93.1250 | AUROC:0.9940\n",
      "101/431 | Loss:0.0695 | top1:97.4257 | AUROC:0.9972\n",
      "201/431 | Loss:0.0780 | top1:97.0149 | AUROC:0.9971\n",
      "301/431 | Loss:0.0800 | top1:96.9456 | AUROC:0.9969\n",
      "401/431 | Loss:0.0803 | top1:96.9296 | AUROC:0.9968\n",
      "431/431 | Loss:0.0803 | top1:96.9317 | AUROC:0.9968\n",
      "49/49 | Loss:0.0597 | top1:97.7051 | AUROC:0.9986\n",
      "\n",
      "Epoch: [57 | 300] LR: 0.302561\n",
      "1/431 | Loss:0.0382 | top1:99.3750 | AUROC:0.9992\n",
      "101/431 | Loss:0.0785 | top1:97.0359 | AUROC:0.9969\n",
      "201/431 | Loss:0.0785 | top1:97.0336 | AUROC:0.9968\n",
      "301/431 | Loss:0.0812 | top1:96.9414 | AUROC:0.9966\n",
      "401/431 | Loss:0.0819 | top1:96.9358 | AUROC:0.9964\n",
      "431/431 | Loss:0.0819 | top1:96.9331 | AUROC:0.9964\n",
      "49/49 | Loss:0.0538 | top1:98.1282 | AUROC:0.9989\n",
      "\n",
      "Epoch: [58 | 300] LR: 0.301793\n",
      "1/431 | Loss:0.0920 | top1:96.2500 | AUROC:0.9957\n",
      "101/431 | Loss:0.0756 | top1:97.0854 | AUROC:0.9969\n",
      "201/431 | Loss:0.0762 | top1:97.0367 | AUROC:0.9969\n",
      "301/431 | Loss:0.0748 | top1:97.1055 | AUROC:0.9971\n",
      "401/431 | Loss:0.0754 | top1:97.1072 | AUROC:0.9970\n",
      "431/431 | Loss:0.0758 | top1:97.1003 | AUROC:0.9970\n",
      "49/49 | Loss:0.0466 | top1:98.2051 | AUROC:0.9988\n",
      "\n",
      "Epoch: [59 | 300] LR: 0.301009\n",
      "1/431 | Loss:0.0587 | top1:96.8750 | AUROC:0.9984\n",
      "101/431 | Loss:0.0786 | top1:97.0730 | AUROC:0.9965\n",
      "201/431 | Loss:0.0789 | top1:97.0429 | AUROC:0.9969\n",
      "301/431 | Loss:0.0778 | top1:97.1117 | AUROC:0.9969\n",
      "401/431 | Loss:0.0756 | top1:97.2194 | AUROC:0.9970\n",
      "431/431 | Loss:0.0754 | top1:97.2253 | AUROC:0.9970\n",
      "49/49 | Loss:0.0402 | top1:98.4744 | AUROC:0.9990\n",
      "\n",
      "Epoch: [60 | 300] LR: 0.300209\n",
      "1/431 | Loss:0.0857 | top1:96.8750 | AUROC:0.9973\n",
      "101/431 | Loss:0.0878 | top1:96.6894 | AUROC:0.9966\n",
      "201/431 | Loss:0.0814 | top1:96.9403 | AUROC:0.9969\n",
      "301/431 | Loss:0.0829 | top1:96.8978 | AUROC:0.9966\n",
      "401/431 | Loss:0.0843 | top1:96.8672 | AUROC:0.9965\n",
      "431/431 | Loss:0.0831 | top1:96.8939 | AUROC:0.9966\n",
      "49/49 | Loss:0.0403 | top1:98.6410 | AUROC:0.9990\n",
      "\n",
      "Epoch: [61 | 300] LR: 0.299394\n",
      "1/431 | Loss:0.0394 | top1:98.1250 | AUROC:0.9994\n",
      "101/431 | Loss:0.0708 | top1:97.2649 | AUROC:0.9973\n",
      "201/431 | Loss:0.0709 | top1:97.3134 | AUROC:0.9973\n",
      "301/431 | Loss:0.0696 | top1:97.3339 | AUROC:0.9974\n",
      "401/431 | Loss:0.0699 | top1:97.3582 | AUROC:0.9973\n",
      "431/431 | Loss:0.0694 | top1:97.3808 | AUROC:0.9973\n",
      "49/49 | Loss:0.0327 | top1:98.8590 | AUROC:0.9994\n",
      "\n",
      "Epoch: [62 | 300] LR: 0.298564\n",
      "1/431 | Loss:0.1291 | top1:95.6250 | AUROC:0.9928\n",
      "101/431 | Loss:0.0706 | top1:97.3329 | AUROC:0.9974\n",
      "201/431 | Loss:0.0721 | top1:97.3725 | AUROC:0.9971\n",
      "301/431 | Loss:0.0736 | top1:97.3048 | AUROC:0.9971\n",
      "401/431 | Loss:0.0716 | top1:97.3831 | AUROC:0.9972\n",
      "431/431 | Loss:0.0713 | top1:97.3779 | AUROC:0.9973\n",
      "49/49 | Loss:0.0408 | top1:98.6154 | AUROC:0.9989\n",
      "\n",
      "Epoch: [63 | 300] LR: 0.297719\n",
      "1/431 | Loss:0.0650 | top1:96.8750 | AUROC:0.9981\n",
      "101/431 | Loss:0.0722 | top1:97.3948 | AUROC:0.9972\n",
      "201/431 | Loss:0.0697 | top1:97.4036 | AUROC:0.9974\n",
      "301/431 | Loss:0.0708 | top1:97.3609 | AUROC:0.9973\n",
      "401/431 | Loss:0.0711 | top1:97.3348 | AUROC:0.9974\n",
      "431/431 | Loss:0.0719 | top1:97.2965 | AUROC:0.9973\n",
      "49/49 | Loss:0.0490 | top1:98.2564 | AUROC:0.9991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [64 | 300] LR: 0.296858\n",
      "1/431 | Loss:0.0545 | top1:96.8750 | AUROC:1.0000\n",
      "101/431 | Loss:0.0686 | top1:97.4505 | AUROC:0.9975\n",
      "201/431 | Loss:0.0690 | top1:97.4565 | AUROC:0.9974\n",
      "301/431 | Loss:0.0685 | top1:97.4585 | AUROC:0.9974\n",
      "401/431 | Loss:0.0706 | top1:97.3691 | AUROC:0.9972\n",
      "431/431 | Loss:0.0706 | top1:97.3677 | AUROC:0.9972\n",
      "49/49 | Loss:0.0368 | top1:98.8077 | AUROC:0.9993\n",
      "\n",
      "Epoch: [65 | 300] LR: 0.295983\n",
      "1/431 | Loss:0.0721 | top1:96.8750 | AUROC:0.9980\n",
      "101/431 | Loss:0.0687 | top1:97.3577 | AUROC:0.9976\n",
      "201/431 | Loss:0.0680 | top1:97.4689 | AUROC:0.9976\n",
      "301/431 | Loss:0.0688 | top1:97.4543 | AUROC:0.9976\n",
      "401/431 | Loss:0.0694 | top1:97.4189 | AUROC:0.9976\n",
      "431/431 | Loss:0.0696 | top1:97.4172 | AUROC:0.9975\n",
      "49/49 | Loss:0.0352 | top1:98.7051 | AUROC:0.9991\n",
      "\n",
      "Epoch: [66 | 300] LR: 0.295092\n",
      "1/431 | Loss:0.0409 | top1:98.7500 | AUROC:0.9998\n",
      "101/431 | Loss:0.0628 | top1:97.6795 | AUROC:0.9979\n",
      "201/431 | Loss:0.0660 | top1:97.5653 | AUROC:0.9976\n",
      "301/431 | Loss:0.0665 | top1:97.5249 | AUROC:0.9975\n",
      "401/431 | Loss:0.0673 | top1:97.5109 | AUROC:0.9974\n",
      "431/431 | Loss:0.0669 | top1:97.5247 | AUROC:0.9974\n",
      "49/49 | Loss:0.0378 | top1:98.6795 | AUROC:0.9989\n",
      "\n",
      "Epoch: [67 | 300] LR: 0.294187\n",
      "1/431 | Loss:0.0481 | top1:98.1250 | AUROC:0.9986\n",
      "101/431 | Loss:0.0661 | top1:97.5619 | AUROC:0.9975\n",
      "201/431 | Loss:0.0643 | top1:97.6430 | AUROC:0.9977\n",
      "301/431 | Loss:0.0671 | top1:97.5062 | AUROC:0.9976\n",
      "401/431 | Loss:0.0667 | top1:97.4782 | AUROC:0.9976\n",
      "431/431 | Loss:0.0667 | top1:97.4942 | AUROC:0.9977\n",
      "49/49 | Loss:0.0608 | top1:98.0256 | AUROC:0.9984\n",
      "\n",
      "Epoch: [68 | 300] LR: 0.293267\n",
      "1/431 | Loss:0.1064 | top1:96.8750 | AUROC:0.9926\n",
      "101/431 | Loss:0.0705 | top1:97.3144 | AUROC:0.9973\n",
      "201/431 | Loss:0.0693 | top1:97.3818 | AUROC:0.9975\n",
      "301/431 | Loss:0.0685 | top1:97.4045 | AUROC:0.9975\n",
      "401/431 | Loss:0.0700 | top1:97.3457 | AUROC:0.9975\n",
      "431/431 | Loss:0.0701 | top1:97.3430 | AUROC:0.9975\n",
      "49/49 | Loss:0.0380 | top1:98.6154 | AUROC:0.9994\n",
      "\n",
      "Epoch: [69 | 300] LR: 0.292333\n",
      "1/431 | Loss:0.0178 | top1:100.0000 | AUROC:1.0000\n",
      "101/431 | Loss:0.0642 | top1:97.6918 | AUROC:0.9977\n",
      "201/431 | Loss:0.0625 | top1:97.6461 | AUROC:0.9978\n",
      "301/431 | Loss:0.0632 | top1:97.6329 | AUROC:0.9978\n",
      "401/431 | Loss:0.0653 | top1:97.5592 | AUROC:0.9978\n",
      "431/431 | Loss:0.0656 | top1:97.5509 | AUROC:0.9977\n",
      "49/49 | Loss:0.0370 | top1:98.5897 | AUROC:0.9994\n",
      "\n",
      "Epoch: [70 | 300] LR: 0.291384\n",
      "1/431 | Loss:0.0696 | top1:96.2500 | AUROC:0.9989\n",
      "101/431 | Loss:0.0642 | top1:97.5186 | AUROC:0.9978\n",
      "201/431 | Loss:0.0658 | top1:97.4938 | AUROC:0.9978\n",
      "301/431 | Loss:0.0665 | top1:97.4605 | AUROC:0.9977\n",
      "401/431 | Loss:0.0664 | top1:97.5062 | AUROC:0.9977\n",
      "431/431 | Loss:0.0665 | top1:97.5058 | AUROC:0.9977\n",
      "49/49 | Loss:0.0460 | top1:98.7051 | AUROC:0.9991\n",
      "\n",
      "Epoch: [71 | 300] LR: 0.290420\n",
      "1/431 | Loss:0.0454 | top1:99.3750 | AUROC:0.9997\n",
      "101/431 | Loss:0.0588 | top1:97.8094 | AUROC:0.9980\n",
      "201/431 | Loss:0.0600 | top1:97.7799 | AUROC:0.9981\n",
      "301/431 | Loss:0.0607 | top1:97.7159 | AUROC:0.9981\n",
      "401/431 | Loss:0.0668 | top1:97.4938 | AUROC:0.9978\n",
      "431/431 | Loss:0.0662 | top1:97.5116 | AUROC:0.9978\n",
      "49/49 | Loss:0.0297 | top1:98.9103 | AUROC:0.9994\n",
      "\n",
      "Epoch: [72 | 300] LR: 0.289443\n",
      "1/431 | Loss:0.0609 | top1:97.5000 | AUROC:0.9981\n",
      "101/431 | Loss:0.0673 | top1:97.3639 | AUROC:0.9978\n",
      "201/431 | Loss:0.0643 | top1:97.5808 | AUROC:0.9981\n",
      "301/431 | Loss:0.0674 | top1:97.5021 | AUROC:0.9977\n",
      "401/431 | Loss:0.0643 | top1:97.6013 | AUROC:0.9978\n",
      "431/431 | Loss:0.0652 | top1:97.5567 | AUROC:0.9978\n",
      "49/49 | Loss:0.0360 | top1:98.7564 | AUROC:0.9990\n",
      "\n",
      "Epoch: [73 | 300] LR: 0.288451\n",
      "1/431 | Loss:0.0306 | top1:99.3750 | AUROC:0.9997\n",
      "101/431 | Loss:0.0667 | top1:97.5495 | AUROC:0.9974\n",
      "201/431 | Loss:0.0671 | top1:97.5187 | AUROC:0.9976\n",
      "301/431 | Loss:0.0664 | top1:97.5623 | AUROC:0.9975\n",
      "401/431 | Loss:0.0663 | top1:97.5374 | AUROC:0.9976\n",
      "431/431 | Loss:0.0663 | top1:97.5291 | AUROC:0.9977\n",
      "49/49 | Loss:0.0419 | top1:98.5256 | AUROC:0.9993\n",
      "\n",
      "Epoch: [74 | 300] LR: 0.287445\n",
      "1/431 | Loss:0.1046 | top1:97.5000 | AUROC:0.9916\n",
      "101/431 | Loss:0.0646 | top1:97.6300 | AUROC:0.9978\n",
      "201/431 | Loss:0.0635 | top1:97.6337 | AUROC:0.9979\n",
      "301/431 | Loss:0.0623 | top1:97.6910 | AUROC:0.9979\n",
      "401/431 | Loss:0.0664 | top1:97.5062 | AUROC:0.9978\n",
      "431/431 | Loss:0.0666 | top1:97.4986 | AUROC:0.9977\n",
      "49/49 | Loss:0.0288 | top1:98.9744 | AUROC:0.9992\n",
      "\n",
      "Epoch: [75 | 300] LR: 0.286425\n",
      "1/431 | Loss:0.1130 | top1:96.2500 | AUROC:0.9948\n",
      "101/431 | Loss:0.0680 | top1:97.4010 | AUROC:0.9975\n",
      "201/431 | Loss:0.0635 | top1:97.5622 | AUROC:0.9978\n",
      "301/431 | Loss:0.0627 | top1:97.5997 | AUROC:0.9979\n",
      "401/431 | Loss:0.0653 | top1:97.5187 | AUROC:0.9978\n",
      "431/431 | Loss:0.0651 | top1:97.5334 | AUROC:0.9978\n",
      "49/49 | Loss:0.0322 | top1:98.7308 | AUROC:0.9991\n",
      "\n",
      "Epoch: [76 | 300] LR: 0.285391\n",
      "1/431 | Loss:0.0489 | top1:98.1250 | AUROC:0.9987\n",
      "101/431 | Loss:0.0614 | top1:97.6733 | AUROC:0.9982\n",
      "201/431 | Loss:0.0619 | top1:97.7239 | AUROC:0.9981\n",
      "301/431 | Loss:0.0653 | top1:97.5478 | AUROC:0.9978\n",
      "401/431 | Loss:0.0640 | top1:97.5623 | AUROC:0.9979\n",
      "431/431 | Loss:0.0644 | top1:97.5480 | AUROC:0.9979\n",
      "49/49 | Loss:0.0353 | top1:98.7821 | AUROC:0.9992\n",
      "\n",
      "Epoch: [77 | 300] LR: 0.028434\n",
      "1/431 | Loss:0.0670 | top1:96.8750 | AUROC:0.9975\n",
      "101/431 | Loss:0.0455 | top1:98.2488 | AUROC:0.9986\n",
      "201/431 | Loss:0.0373 | top1:98.5572 | AUROC:0.9991\n",
      "301/431 | Loss:0.0331 | top1:98.7479 | AUROC:0.9993\n",
      "401/431 | Loss:0.0316 | top1:98.8061 | AUROC:0.9993\n",
      "431/431 | Loss:0.0311 | top1:98.8358 | AUROC:0.9993\n",
      "49/49 | Loss:0.0144 | top1:99.4487 | AUROC:0.9999\n",
      "\n",
      "Epoch: [78 | 300] LR: 0.028328\n",
      "1/431 | Loss:0.0324 | top1:98.7500 | AUROC:0.9995\n",
      "101/431 | Loss:0.0238 | top1:99.1832 | AUROC:0.9995\n",
      "201/431 | Loss:0.0206 | top1:99.2662 | AUROC:0.9997\n",
      "301/431 | Loss:0.0218 | top1:99.2172 | AUROC:0.9996\n",
      "401/431 | Loss:0.0211 | top1:99.2363 | AUROC:0.9997\n",
      "431/431 | Loss:0.0211 | top1:99.2326 | AUROC:0.9997\n",
      "49/49 | Loss:0.0116 | top1:99.6282 | AUROC:0.9999\n",
      "\n",
      "Epoch: [79 | 300] LR: 0.028221\n",
      "1/431 | Loss:0.0086 | top1:100.0000 | AUROC:1.0000\n",
      "101/431 | Loss:0.0195 | top1:99.2698 | AUROC:0.9997\n",
      "201/431 | Loss:0.0183 | top1:99.2879 | AUROC:0.9998\n",
      "301/431 | Loss:0.0182 | top1:99.3106 | AUROC:0.9998\n",
      "401/431 | Loss:0.0179 | top1:99.3251 | AUROC:0.9998\n",
      "431/431 | Loss:0.0178 | top1:99.3343 | AUROC:0.9998\n",
      "49/49 | Loss:0.0079 | top1:99.6923 | AUROC:0.9999\n",
      "\n",
      "Epoch: [80 | 300] LR: 0.028112\n",
      "1/431 | Loss:0.0047 | top1:100.0000 | AUROC:1.0000\n",
      "101/431 | Loss:0.0156 | top1:99.4431 | AUROC:0.9998\n",
      "201/431 | Loss:0.0166 | top1:99.4092 | AUROC:0.9998\n",
      "301/431 | Loss:0.0169 | top1:99.3833 | AUROC:0.9998\n",
      "401/431 | Loss:0.0168 | top1:99.3906 | AUROC:0.9998\n",
      "431/431 | Loss:0.0168 | top1:99.3939 | AUROC:0.9998\n",
      "49/49 | Loss:0.0085 | top1:99.7179 | AUROC:1.0000\n",
      "\n",
      "Epoch: [81 | 300] LR: 0.028002\n",
      "1/431 | Loss:0.0089 | top1:100.0000 | AUROC:1.0000\n",
      "101/431 | Loss:0.0162 | top1:99.3874 | AUROC:0.9998\n",
      "201/431 | Loss:0.0142 | top1:99.4465 | AUROC:0.9999\n",
      "301/431 | Loss:0.0150 | top1:99.4248 | AUROC:0.9998\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-1594583eaac9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nEpoch: [%d | %d] LR: %f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_auroc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_auroc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-061456a0ae46>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, model, criterion, optimizer, epoch, use_cuda)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m# measure accuracy and record loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mprec1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mauroc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mtop1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprec1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(start_epoch, epochs):\n",
    "    state['lr'] = optimizer.state_dict()['param_groups'][0]['lr']\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "    print('\\nEpoch: [%d | %d] LR: %f' % (epoch + 1, epochs, state['lr']))\n",
    "    \n",
    "    train_loss, train_acc, train_auroc = train(train_loader, model, criterion, optimizer, epoch, use_cuda)\n",
    "    test_loss, test_acc, test_auroc = test(val_loader, model, criterion, epoch, use_cuda)\n",
    "    \n",
    "    logger.append([state['lr'], train_loss, test_loss, train_acc, test_acc, train_auroc, test_auroc])\n",
    "    scheduler_warmup.step()\n",
    "\n",
    "    is_best = test_acc > best_acc\n",
    "    best_acc = max(test_acc, best_acc)\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'state_dict' : model.state_dict(),\n",
    "        'acc': test_acc,\n",
    "        'best_acc': best_acc,\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    }, is_best, checkpoint=checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
