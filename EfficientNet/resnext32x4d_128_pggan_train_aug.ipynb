{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import collections\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "\n",
    "from model_pytorch import resnext50_32x4d\n",
    "from utils import Bar,Logger, AverageMeter, accuracy, mkdir_p, savefig\n",
    "from warmup_scheduler import GradualWarmupScheduler\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "import cv2\n",
    "\n",
    "from PIL import ImageFile, ImageOps\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU device 2: True\n"
     ]
    }
   ],
   "source": [
    "# GPU Device\n",
    "gpu_id = 2\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(\"GPU device %d:\" %(gpu_id), use_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/media/data2/dataset/GAN_ImageData/PGGAN_128'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained = ''\n",
    "resume = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model_name = 'resnext32x4d' # b0-b7 scale\n",
    "\n",
    "# Optimization\n",
    "num_classes = 2\n",
    "epochs = 400\n",
    "start_epoch = 0\n",
    "train_batch = 200\n",
    "test_batch = 200\n",
    "lr = 0.04\n",
    "schedule = [75, 175, 250]\n",
    "momentum = 0.9\n",
    "gamma = 0.1 # LR is multiplied by gamma on schedule\n",
    "\n",
    "# CheckPoint\n",
    "checkpoint = './log/pggan/128/32x4d/aug' # dir\n",
    "if not os.path.isdir(checkpoint):\n",
    "    os.makedirs(checkpoint)\n",
    "num_workers = 8\n",
    "\n",
    "# Seed\n",
    "manual_seed = 7\n",
    "random.seed(manual_seed)\n",
    "torch.cuda.manual_seed_all(manual_seed)\n",
    "\n",
    "# Image\n",
    "size = (128, 128)\n",
    "\n",
    "# cutmix\n",
    "cm_prob = 0.5\n",
    "cm_beta = 1.0\n",
    "\n",
    "# augmentation\n",
    "blur_prob = 0.2\n",
    "blog_sig = 0.5\n",
    "jpg_prob = 0.2\n",
    "\n",
    "best_acc = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {}\n",
    "state['num_classes'] = num_classes\n",
    "state['epochs'] = epochs\n",
    "state['start_epoch'] = start_epoch\n",
    "state['train_batch'] = train_batch\n",
    "state['test_batch'] = test_batch\n",
    "state['lr'] = lr\n",
    "state['schedule'] = schedule\n",
    "state['momentum'] = momentum\n",
    "state['gamma'] = gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_augment(img):\n",
    "    img = np.array(img)\n",
    "\n",
    "    if random.random() < blur_prob:\n",
    "        sig = np.random.uniform(0.0, 3.0)\n",
    "        gaussian_blur(img, sig)\n",
    "\n",
    "    if random.random() < jpg_prob:\n",
    "        qual = np.random.uniform(30.0, 100.0)\n",
    "        img = cv2_jpg(img, qual)\n",
    "\n",
    "    return Image.fromarray(img)\n",
    "\n",
    "\n",
    "def gaussian_blur(img, sigma):\n",
    "    gaussian_filter(img[:,:,0], output=img[:,:,0], sigma=sigma)\n",
    "    gaussian_filter(img[:,:,1], output=img[:,:,1], sigma=sigma)\n",
    "    gaussian_filter(img[:,:,2], output=img[:,:,2], sigma=sigma)\n",
    "\n",
    "\n",
    "def cv2_jpg(img, compress_val):\n",
    "    img_cv2 = img[:,:,::-1]\n",
    "    encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), compress_val]\n",
    "    result, encimg = cv2.imencode('.jpg', img_cv2, encode_param)\n",
    "    decimg = cv2.imdecode(encimg, 1)\n",
    "    return decimg[:,:,::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_bbox(size, lam):\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = np.int(W * cut_rat)\n",
    "    cut_h = np.int(H * cut_rat)\n",
    "\n",
    "    # uniform\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join(data_dir, 'train')\n",
    "val_dir = os.path.join(data_dir, 'validation')    \n",
    "\n",
    "train_aug = transforms.Compose([\n",
    "    transforms.Lambda(lambda img: data_augment(img)),\n",
    "    transforms.Resize(size),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "#     transforms.RandomErasing(p=0.3, scale=(0.02, 0.10), ratio=(0.3, 3.3), value=0, inplace=True),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "val_aug = transforms.Compose([\n",
    "    transforms.Resize(size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# pin_memory : cuda pin memeory use\n",
    "train_loader = DataLoader(datasets.ImageFolder(train_dir, transform=train_aug),\n",
    "                          batch_size=train_batch, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "val_loader = DataLoader(datasets.ImageFolder(val_dir, val_aug),\n",
    "                       batch_size=test_batch, shuffle=True, num_workers=num_workers, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnext50_32x4d(pretrained=False, num_classes=2)\n",
    "\n",
    "# Pre-trained\n",
    "if pretrained:\n",
    "    print(\"=> using pre-trained model '{}'\".format(pretrained))\n",
    "    model.load_state_dict(torch.load(pretrained)['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Total params: 22.98M\n"
     ]
    }
   ],
   "source": [
    "model.to('cuda')\n",
    "cudnn.benchmark = True\n",
    "print('    Total params: %.2fM' % (sum(p.numel() for p in model.parameters())/1000000.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=1e-4)\n",
    "scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)\n",
    "scheduler_warmup = GradualWarmupScheduler(optimizer, multiplier=8, total_epoch=10, after_scheduler=scheduler_cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resume\n",
    "if resume:\n",
    "    print('==> Resuming from checkpoint..')\n",
    "    checkpoint = os.path.dirname(resume)\n",
    "#     checkpoint = torch.load(resume)\n",
    "    resume = torch.load(resume)\n",
    "    best_acc = resume['best_acc']\n",
    "    start_epoch = resume['epoch']\n",
    "    model.load_state_dict(resume['state_dict'])\n",
    "    optimizer.load_state_dict(resume['optimizer'])\n",
    "    logger = Logger(os.path.join(checkpoint, 'log.txt'), resume=True)\n",
    "else:\n",
    "    logger = Logger(os.path.join(checkpoint, 'log.txt'))\n",
    "    logger.set_names(['Learning Rate', 'Train Loss', 'Valid Loss', 'Train Acc.', 'Valid Acc.', 'Train AUROC.', 'Valid AUROC.'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch, use_cuda):\n",
    "    model.train()\n",
    "    \n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    arc = AverageMeter()\n",
    "    end = time.time()\n",
    "    \n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        batch_size = inputs.size(0)\n",
    "        if batch_size < train_batch:\n",
    "            continue\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            \n",
    "        r = np.random.rand(1)\n",
    "        if cm_beta > 0 and r < cm_prob:\n",
    "            \n",
    "            rand_index = torch.randperm(inputs.size()[0]).cuda()\n",
    "            tt= targets[rand_index]\n",
    "            boolean = targets==tt\n",
    "            rand_index = rand_index[boolean]\n",
    "            lam = np.random.beta(cm_beta, cm_beta)\n",
    "            bbx1, bby1, bbx2, bby2 = rand_bbox(inputs.size(), lam)\n",
    "            inputs[boolean, :, bbx1:bbx2, bby1:bby2] = inputs[rand_index, :, bbx1:bbx2, bby1:bby2]\n",
    "\n",
    "        # compute output\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1 = accuracy(outputs.data, targets.data)\n",
    "        auroc = roc_auc_score(targets.cpu().detach().numpy(), outputs.cpu().detach().numpy()[:,1])\n",
    "        losses.update(loss.data.tolist(), inputs.size(0))\n",
    "        top1.update(prec1[0], inputs.size(0))\n",
    "        arc.update(auroc, inputs.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print('{batch}/{size} | Loss:{loss:.4f} | top1:{tp1:.4f} | AUROC:{ac:.4f}'.format(\n",
    "                     batch=batch_idx+1, size=len(train_loader), loss=losses.avg, tp1=top1.avg, ac=arc.avg))\n",
    "    print('{batch}/{size} | Loss:{loss:.4f} | top1:{tp1:.4f} | AUROC:{ac:.4f}'.format(\n",
    "                     batch=batch_idx+1, size=len(train_loader), loss=losses.avg, tp1=top1.avg, ac=arc.avg))\n",
    "    return (losses.avg, top1.avg, arc.avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(val_loader, model, criterion, epoch, use_cuda):\n",
    "    global best_acc\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    arc = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(val_loader):\n",
    "            # measure data loading time\n",
    "            data_time.update(time.time() - end)\n",
    "\n",
    "            if use_cuda:\n",
    "                inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "            # compute output\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            prec1 = accuracy(outputs.data, targets.data)\n",
    "            auroc = roc_auc_score(targets.cpu().detach().numpy(), outputs.cpu().detach().numpy()[:,1])\n",
    "            losses.update(loss.data.tolist(), inputs.size(0))\n",
    "            top1.update(prec1[0], inputs.size(0))\n",
    "            arc.update(auroc, inputs.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "    print('{batch}/{size} | Loss:{loss:.4f} | top1:{tp1:.4f} | AUROC:{ac:.4f}'.format(\n",
    "         batch=batch_idx+1, size=len(val_loader), loss=losses.avg, tp1=top1.avg, ac=arc.avg))\n",
    "    return (losses.avg, top1.avg, arc.avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, checkpoint='checkpoint', filename='checkpoint.pth.tar'):\n",
    "    filepath = os.path.join(checkpoint, filename)\n",
    "    torch.save(state, filepath)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filepath, os.path.join(checkpoint, 'model_best.pth.tar'))\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    global state\n",
    "    lr_set = [1, 1e-1, 1e-2, 1e-3, 1e-4, 1e-5]\n",
    "    lr_list = schedule.copy()\n",
    "    lr_list.append(epoch)\n",
    "    lr_list.sort()\n",
    "    idx = lr_list.index(epoch)\n",
    "    state['lr'] *= lr_set[idx]\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = state['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [1 | 400] LR: 0.040000\n",
      "1/643 | Loss:0.6926 | top1:51.0000 | AUROC:0.4973\n",
      "101/643 | Loss:3.7560 | top1:60.7426 | AUROC:0.6804\n",
      "201/643 | Loss:2.1371 | top1:68.4453 | AUROC:0.7447\n",
      "301/643 | Loss:1.5797 | top1:71.8571 | AUROC:0.7706\n",
      "401/643 | Loss:1.2955 | top1:73.8317 | AUROC:0.7842\n",
      "501/643 | Loss:1.1244 | top1:74.9471 | AUROC:0.7939\n",
      "601/643 | Loss:1.0055 | top1:76.0133 | AUROC:0.8012\n",
      "643/643 | Loss:0.9692 | top1:76.2687 | AUROC:0.8030\n",
      "161/161 | Loss:0.1993 | top1:98.9252 | AUROC:0.9999\n",
      "\n",
      "Epoch: [2 | 400] LR: 0.068000\n",
      "1/643 | Loss:0.4154 | top1:79.5000 | AUROC:0.8716\n",
      "101/643 | Loss:0.4256 | top1:80.5545 | AUROC:0.8313\n",
      "201/643 | Loss:0.4164 | top1:81.0771 | AUROC:0.8374\n",
      "301/643 | Loss:0.4136 | top1:81.2824 | AUROC:0.8393\n",
      "401/643 | Loss:0.4120 | top1:81.2294 | AUROC:0.8397\n",
      "501/643 | Loss:0.4113 | top1:81.2126 | AUROC:0.8397\n",
      "601/643 | Loss:0.4094 | top1:81.3012 | AUROC:0.8411\n",
      "643/643 | Loss:0.4086 | top1:81.3388 | AUROC:0.8415\n",
      "161/161 | Loss:0.1676 | top1:99.5203 | AUROC:1.0000\n",
      "\n",
      "Epoch: [3 | 400] LR: 0.096000\n",
      "1/643 | Loss:0.4090 | top1:82.5000 | AUROC:0.8210\n",
      "101/643 | Loss:0.3886 | top1:82.5396 | AUROC:0.8556\n",
      "201/643 | Loss:0.3916 | top1:82.1567 | AUROC:0.8558\n",
      "301/643 | Loss:0.3945 | top1:81.9751 | AUROC:0.8539\n",
      "401/643 | Loss:0.3936 | top1:81.9589 | AUROC:0.8550\n",
      "501/643 | Loss:0.3943 | top1:81.8104 | AUROC:0.8560\n",
      "601/643 | Loss:0.3913 | top1:81.9676 | AUROC:0.8594\n",
      "643/643 | Loss:0.3910 | top1:81.9790 | AUROC:0.8597\n",
      "161/161 | Loss:0.1216 | top1:99.4984 | AUROC:0.9998\n",
      "\n",
      "Epoch: [4 | 400] LR: 0.124000\n",
      "1/643 | Loss:0.3487 | top1:83.5000 | AUROC:0.9070\n",
      "101/643 | Loss:0.3820 | top1:82.3020 | AUROC:0.8781\n",
      "201/643 | Loss:0.3787 | top1:82.4901 | AUROC:0.8820\n",
      "301/643 | Loss:0.3777 | top1:82.6080 | AUROC:0.8817\n",
      "401/643 | Loss:0.3742 | top1:82.7494 | AUROC:0.8858\n",
      "501/643 | Loss:0.3702 | top1:82.9451 | AUROC:0.8903\n",
      "601/643 | Loss:0.3639 | top1:83.2454 | AUROC:0.8959\n",
      "643/643 | Loss:0.3599 | top1:83.4837 | AUROC:0.8986\n",
      "161/161 | Loss:0.0711 | top1:98.5421 | AUROC:1.0000\n",
      "\n",
      "Epoch: [5 | 400] LR: 0.152000\n",
      "1/643 | Loss:0.2857 | top1:88.0000 | AUROC:0.9403\n",
      "101/643 | Loss:0.3370 | top1:84.8366 | AUROC:0.9183\n",
      "201/643 | Loss:0.3335 | top1:84.7463 | AUROC:0.9220\n",
      "301/643 | Loss:0.3196 | top1:85.4734 | AUROC:0.9295\n",
      "401/643 | Loss:0.3134 | top1:85.8229 | AUROC:0.9324\n",
      "501/643 | Loss:0.3080 | top1:86.1038 | AUROC:0.9354\n",
      "601/643 | Loss:0.2960 | top1:86.7704 | AUROC:0.9405\n",
      "643/643 | Loss:0.2952 | top1:86.8100 | AUROC:0.9412\n",
      "161/161 | Loss:0.0625 | top1:98.7539 | AUROC:0.9999\n",
      "\n",
      "Epoch: [6 | 400] LR: 0.180000\n",
      "1/643 | Loss:0.2793 | top1:89.0000 | AUROC:0.9465\n",
      "101/643 | Loss:0.2397 | top1:89.8663 | AUROC:0.9644\n",
      "201/643 | Loss:0.2259 | top1:90.5373 | AUROC:0.9681\n",
      "301/643 | Loss:0.2175 | top1:90.8854 | AUROC:0.9716\n",
      "401/643 | Loss:0.2091 | top1:91.2843 | AUROC:0.9737\n",
      "501/643 | Loss:0.2092 | top1:91.2884 | AUROC:0.9737\n",
      "601/643 | Loss:0.2024 | top1:91.5657 | AUROC:0.9752\n",
      "643/643 | Loss:0.2003 | top1:91.6425 | AUROC:0.9757\n",
      "161/161 | Loss:0.0497 | top1:98.6542 | AUROC:0.9999\n",
      "\n",
      "Epoch: [7 | 400] LR: 0.208000\n",
      "1/643 | Loss:0.2165 | top1:91.0000 | AUROC:0.9779\n",
      "101/643 | Loss:0.1673 | top1:93.2376 | AUROC:0.9833\n",
      "201/643 | Loss:0.1676 | top1:93.2015 | AUROC:0.9838\n",
      "301/643 | Loss:0.1672 | top1:93.1860 | AUROC:0.9842\n",
      "401/643 | Loss:0.1642 | top1:93.3142 | AUROC:0.9849\n",
      "501/643 | Loss:0.1613 | top1:93.4421 | AUROC:0.9853\n",
      "601/643 | Loss:0.1594 | top1:93.5449 | AUROC:0.9858\n",
      "643/643 | Loss:0.1582 | top1:93.5888 | AUROC:0.9861\n",
      "161/161 | Loss:0.0368 | top1:98.8972 | AUROC:1.0000\n",
      "\n",
      "Epoch: [8 | 400] LR: 0.236000\n",
      "1/643 | Loss:0.0766 | top1:96.0000 | AUROC:0.9988\n",
      "101/643 | Loss:0.1311 | top1:94.7871 | AUROC:0.9905\n",
      "201/643 | Loss:0.1334 | top1:94.6866 | AUROC:0.9902\n",
      "301/643 | Loss:0.1338 | top1:94.6130 | AUROC:0.9902\n",
      "401/643 | Loss:0.1326 | top1:94.6658 | AUROC:0.9903\n",
      "501/643 | Loss:0.1308 | top1:94.7725 | AUROC:0.9905\n",
      "601/643 | Loss:0.1293 | top1:94.8228 | AUROC:0.9907\n",
      "643/643 | Loss:0.1297 | top1:94.8349 | AUROC:0.9907\n",
      "161/161 | Loss:0.0788 | top1:97.0935 | AUROC:0.9999\n",
      "\n",
      "Epoch: [9 | 400] LR: 0.264000\n",
      "1/643 | Loss:0.1129 | top1:96.0000 | AUROC:0.9958\n",
      "101/643 | Loss:0.1292 | top1:95.0545 | AUROC:0.9916\n",
      "201/643 | Loss:0.1323 | top1:94.8607 | AUROC:0.9910\n",
      "301/643 | Loss:0.1296 | top1:94.9252 | AUROC:0.9913\n",
      "401/643 | Loss:0.1270 | top1:95.0411 | AUROC:0.9916\n",
      "501/643 | Loss:0.1261 | top1:95.0519 | AUROC:0.9915\n",
      "601/643 | Loss:0.1233 | top1:95.1689 | AUROC:0.9919\n",
      "643/643 | Loss:0.1225 | top1:95.2017 | AUROC:0.9920\n",
      "161/161 | Loss:0.0518 | top1:98.2087 | AUROC:0.9999\n",
      "\n",
      "Epoch: [10 | 400] LR: 0.292000\n",
      "1/643 | Loss:0.0741 | top1:97.5000 | AUROC:0.9987\n",
      "101/643 | Loss:0.1047 | top1:95.8960 | AUROC:0.9944\n",
      "201/643 | Loss:0.1068 | top1:95.8358 | AUROC:0.9941\n",
      "301/643 | Loss:0.1114 | top1:95.6528 | AUROC:0.9938\n",
      "401/643 | Loss:0.1104 | top1:95.6845 | AUROC:0.9938\n",
      "501/643 | Loss:0.1101 | top1:95.6966 | AUROC:0.9937\n",
      "601/643 | Loss:0.1100 | top1:95.7363 | AUROC:0.9937\n",
      "643/643 | Loss:0.1108 | top1:95.6986 | AUROC:0.9936\n",
      "161/161 | Loss:0.0329 | top1:99.1713 | AUROC:0.9999\n",
      "\n",
      "Epoch: [11 | 400] LR: 0.320000\n",
      "1/643 | Loss:0.0605 | top1:98.0000 | AUROC:0.9993\n",
      "101/643 | Loss:0.1069 | top1:95.7327 | AUROC:0.9943\n",
      "201/643 | Loss:0.1142 | top1:95.4677 | AUROC:0.9934\n",
      "301/643 | Loss:0.1156 | top1:95.4136 | AUROC:0.9934\n",
      "401/643 | Loss:0.1154 | top1:95.4140 | AUROC:0.9933\n",
      "501/643 | Loss:0.1167 | top1:95.3693 | AUROC:0.9931\n",
      "601/643 | Loss:0.1161 | top1:95.3935 | AUROC:0.9933\n",
      "643/643 | Loss:0.1151 | top1:95.4408 | AUROC:0.9934\n",
      "161/161 | Loss:0.0555 | top1:98.2337 | AUROC:0.9999\n",
      "\n",
      "Epoch: [12 | 400] LR: 0.320000\n",
      "1/643 | Loss:0.1348 | top1:93.5000 | AUROC:0.9917\n",
      "101/643 | Loss:0.1045 | top1:95.8416 | AUROC:0.9949\n",
      "201/643 | Loss:0.1070 | top1:95.7761 | AUROC:0.9943\n",
      "301/643 | Loss:0.1076 | top1:95.7608 | AUROC:0.9943\n",
      "401/643 | Loss:0.1040 | top1:95.9377 | AUROC:0.9946\n",
      "501/643 | Loss:0.1122 | top1:95.5699 | AUROC:0.9933\n",
      "601/643 | Loss:0.1123 | top1:95.5724 | AUROC:0.9934\n",
      "643/643 | Loss:0.1111 | top1:95.6301 | AUROC:0.9935\n",
      "161/161 | Loss:0.0153 | top1:99.5203 | AUROC:0.9999\n",
      "\n",
      "Epoch: [13 | 400] LR: 0.319995\n",
      "1/643 | Loss:0.1204 | top1:95.0000 | AUROC:0.9936\n",
      "101/643 | Loss:0.1073 | top1:95.8267 | AUROC:0.9943\n",
      "201/643 | Loss:0.1024 | top1:96.0721 | AUROC:0.9949\n",
      "301/643 | Loss:0.1040 | top1:96.0249 | AUROC:0.9948\n",
      "401/643 | Loss:0.1055 | top1:95.9838 | AUROC:0.9945\n",
      "501/643 | Loss:0.1040 | top1:96.0409 | AUROC:0.9946\n",
      "601/643 | Loss:0.1049 | top1:95.9817 | AUROC:0.9946\n",
      "643/643 | Loss:0.1043 | top1:96.0000 | AUROC:0.9946\n",
      "161/161 | Loss:0.0232 | top1:99.3271 | AUROC:1.0000\n",
      "\n",
      "Epoch: [14 | 400] LR: 0.319980\n",
      "1/643 | Loss:0.1084 | top1:97.0000 | AUROC:0.9938\n",
      "101/643 | Loss:0.1083 | top1:95.7822 | AUROC:0.9947\n",
      "201/643 | Loss:0.1044 | top1:95.9254 | AUROC:0.9949\n",
      "301/643 | Loss:0.1043 | top1:95.8754 | AUROC:0.9950\n",
      "401/643 | Loss:0.1041 | top1:95.9190 | AUROC:0.9950\n",
      "501/643 | Loss:0.1031 | top1:95.9311 | AUROC:0.9951\n",
      "601/643 | Loss:0.1028 | top1:95.9451 | AUROC:0.9951\n",
      "643/643 | Loss:0.1027 | top1:95.9533 | AUROC:0.9950\n",
      "161/161 | Loss:0.0315 | top1:98.9439 | AUROC:0.9999\n",
      "\n",
      "Epoch: [15 | 400] LR: 0.319956\n",
      "1/643 | Loss:0.0974 | top1:95.5000 | AUROC:0.9935\n",
      "101/643 | Loss:0.0943 | top1:96.2871 | AUROC:0.9957\n",
      "201/643 | Loss:0.0987 | top1:96.0896 | AUROC:0.9953\n",
      "301/643 | Loss:0.0973 | top1:96.1910 | AUROC:0.9954\n",
      "401/643 | Loss:0.0986 | top1:96.1771 | AUROC:0.9954\n",
      "501/643 | Loss:0.1004 | top1:96.1098 | AUROC:0.9952\n",
      "601/643 | Loss:0.1023 | top1:96.0366 | AUROC:0.9950\n",
      "643/643 | Loss:0.1020 | top1:96.0553 | AUROC:0.9950\n",
      "161/161 | Loss:0.0054 | top1:99.8567 | AUROC:1.0000\n",
      "\n",
      "Epoch: [16 | 400] LR: 0.319921\n",
      "1/643 | Loss:0.1444 | top1:94.5000 | AUROC:0.9967\n",
      "101/643 | Loss:0.0954 | top1:96.2772 | AUROC:0.9961\n",
      "201/643 | Loss:0.0944 | top1:96.2736 | AUROC:0.9959\n",
      "301/643 | Loss:0.0910 | top1:96.4186 | AUROC:0.9961\n",
      "401/643 | Loss:0.0895 | top1:96.4751 | AUROC:0.9962\n",
      "501/643 | Loss:0.0915 | top1:96.4251 | AUROC:0.9959\n",
      "601/643 | Loss:0.0928 | top1:96.3735 | AUROC:0.9959\n",
      "643/643 | Loss:0.0925 | top1:96.3925 | AUROC:0.9959\n",
      "161/161 | Loss:0.0267 | top1:99.0249 | AUROC:1.0000\n",
      "\n",
      "Epoch: [17 | 400] LR: 0.319877\n",
      "1/643 | Loss:0.0830 | top1:96.0000 | AUROC:0.9971\n",
      "101/643 | Loss:0.0854 | top1:96.6733 | AUROC:0.9962\n",
      "201/643 | Loss:0.0854 | top1:96.6841 | AUROC:0.9962\n",
      "301/643 | Loss:0.0869 | top1:96.6478 | AUROC:0.9961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "401/643 | Loss:0.0887 | top1:96.5648 | AUROC:0.9961\n",
      "501/643 | Loss:0.0902 | top1:96.5240 | AUROC:0.9961\n",
      "601/643 | Loss:0.0924 | top1:96.4301 | AUROC:0.9959\n",
      "643/643 | Loss:0.0915 | top1:96.4572 | AUROC:0.9960\n",
      "161/161 | Loss:0.0052 | top1:99.8598 | AUROC:1.0000\n",
      "\n",
      "Epoch: [18 | 400] LR: 0.319822\n",
      "1/643 | Loss:0.1374 | top1:96.0000 | AUROC:0.9946\n",
      "101/643 | Loss:0.0839 | top1:96.7624 | AUROC:0.9968\n",
      "201/643 | Loss:0.0854 | top1:96.7164 | AUROC:0.9965\n",
      "301/643 | Loss:0.0859 | top1:96.7243 | AUROC:0.9964\n",
      "401/643 | Loss:0.0897 | top1:96.5598 | AUROC:0.9962\n",
      "501/643 | Loss:0.0906 | top1:96.5269 | AUROC:0.9960\n",
      "601/643 | Loss:0.0903 | top1:96.5532 | AUROC:0.9960\n",
      "643/643 | Loss:0.0896 | top1:96.5818 | AUROC:0.9961\n",
      "161/161 | Loss:0.0279 | top1:99.0343 | AUROC:1.0000\n",
      "\n",
      "Epoch: [19 | 400] LR: 0.319758\n",
      "1/643 | Loss:0.0630 | top1:97.5000 | AUROC:0.9978\n",
      "101/643 | Loss:0.0865 | top1:96.7079 | AUROC:0.9965\n",
      "201/643 | Loss:0.0797 | top1:96.9453 | AUROC:0.9968\n",
      "301/643 | Loss:0.0806 | top1:96.9153 | AUROC:0.9966\n",
      "401/643 | Loss:0.0833 | top1:96.7880 | AUROC:0.9965\n",
      "501/643 | Loss:0.0860 | top1:96.6737 | AUROC:0.9963\n",
      "601/643 | Loss:0.0861 | top1:96.6681 | AUROC:0.9963\n",
      "643/643 | Loss:0.0863 | top1:96.6698 | AUROC:0.9963\n",
      "161/161 | Loss:0.0262 | top1:99.0872 | AUROC:1.0000\n",
      "\n",
      "Epoch: [20 | 400] LR: 0.319684\n",
      "1/643 | Loss:0.0802 | top1:97.5000 | AUROC:0.9962\n",
      "101/643 | Loss:0.0751 | top1:97.1040 | AUROC:0.9971\n",
      "201/643 | Loss:0.0791 | top1:97.0000 | AUROC:0.9970\n",
      "301/643 | Loss:0.0812 | top1:96.9236 | AUROC:0.9969\n",
      "401/643 | Loss:0.0829 | top1:96.8441 | AUROC:0.9967\n",
      "501/643 | Loss:0.0850 | top1:96.7335 | AUROC:0.9966\n",
      "601/643 | Loss:0.0842 | top1:96.7637 | AUROC:0.9966\n",
      "643/643 | Loss:0.0839 | top1:96.7788 | AUROC:0.9966\n",
      "161/161 | Loss:0.0198 | top1:99.3209 | AUROC:1.0000\n",
      "\n",
      "Epoch: [21 | 400] LR: 0.319600\n",
      "1/643 | Loss:0.0911 | top1:97.0000 | AUROC:0.9969\n",
      "101/643 | Loss:0.0868 | top1:96.7327 | AUROC:0.9961\n",
      "201/643 | Loss:0.0860 | top1:96.7662 | AUROC:0.9961\n",
      "301/643 | Loss:0.0840 | top1:96.8289 | AUROC:0.9963\n",
      "401/643 | Loss:0.0828 | top1:96.8703 | AUROC:0.9964\n",
      "501/643 | Loss:0.0820 | top1:96.9192 | AUROC:0.9966\n",
      "601/643 | Loss:0.0833 | top1:96.8694 | AUROC:0.9965\n",
      "643/643 | Loss:0.0830 | top1:96.8692 | AUROC:0.9966\n",
      "161/161 | Loss:0.0176 | top1:99.3801 | AUROC:1.0000\n",
      "\n",
      "Epoch: [22 | 400] LR: 0.319507\n",
      "1/643 | Loss:0.0674 | top1:97.0000 | AUROC:0.9967\n",
      "101/643 | Loss:0.0841 | top1:96.7525 | AUROC:0.9963\n",
      "201/643 | Loss:0.0808 | top1:96.8731 | AUROC:0.9966\n",
      "301/643 | Loss:0.0809 | top1:96.9169 | AUROC:0.9967\n",
      "401/643 | Loss:0.0822 | top1:96.8516 | AUROC:0.9966\n",
      "501/643 | Loss:0.0822 | top1:96.8653 | AUROC:0.9966\n",
      "601/643 | Loss:0.0831 | top1:96.8319 | AUROC:0.9966\n",
      "643/643 | Loss:0.0828 | top1:96.8224 | AUROC:0.9966\n",
      "161/161 | Loss:0.0203 | top1:99.2555 | AUROC:0.9999\n",
      "\n",
      "Epoch: [23 | 400] LR: 0.319403\n",
      "1/643 | Loss:0.0862 | top1:96.0000 | AUROC:0.9954\n",
      "101/643 | Loss:0.0758 | top1:96.9752 | AUROC:0.9970\n",
      "201/643 | Loss:0.0755 | top1:97.0373 | AUROC:0.9972\n",
      "301/643 | Loss:0.0786 | top1:96.9352 | AUROC:0.9972\n",
      "401/643 | Loss:0.0771 | top1:96.9875 | AUROC:0.9972\n",
      "501/643 | Loss:0.0784 | top1:96.9411 | AUROC:0.9970\n",
      "601/643 | Loss:0.0799 | top1:96.8993 | AUROC:0.9970\n",
      "643/643 | Loss:0.0806 | top1:96.8832 | AUROC:0.9969\n",
      "161/161 | Loss:0.0313 | top1:98.8474 | AUROC:1.0000\n",
      "\n",
      "Epoch: [24 | 400] LR: 0.319290\n",
      "1/643 | Loss:0.0976 | top1:96.5000 | AUROC:0.9941\n",
      "101/643 | Loss:0.0897 | top1:96.5941 | AUROC:0.9967\n",
      "201/643 | Loss:0.0779 | top1:97.0672 | AUROC:0.9971\n",
      "301/643 | Loss:0.0771 | top1:97.0814 | AUROC:0.9971\n",
      "401/643 | Loss:0.0754 | top1:97.1596 | AUROC:0.9972\n",
      "501/643 | Loss:0.0760 | top1:97.1367 | AUROC:0.9971\n",
      "601/643 | Loss:0.0764 | top1:97.1140 | AUROC:0.9971\n",
      "643/643 | Loss:0.0765 | top1:97.1114 | AUROC:0.9971\n",
      "161/161 | Loss:0.0124 | top1:99.6449 | AUROC:1.0000\n",
      "\n",
      "Epoch: [25 | 400] LR: 0.319167\n",
      "1/643 | Loss:0.0386 | top1:98.0000 | AUROC:0.9995\n",
      "101/643 | Loss:0.0675 | top1:97.4356 | AUROC:0.9981\n",
      "201/643 | Loss:0.0747 | top1:97.1841 | AUROC:0.9976\n",
      "301/643 | Loss:0.0765 | top1:97.1229 | AUROC:0.9974\n",
      "401/643 | Loss:0.0740 | top1:97.2406 | AUROC:0.9974\n",
      "501/643 | Loss:0.0744 | top1:97.2295 | AUROC:0.9974\n",
      "601/643 | Loss:0.0761 | top1:97.1681 | AUROC:0.9973\n",
      "643/643 | Loss:0.0758 | top1:97.1799 | AUROC:0.9973\n",
      "161/161 | Loss:0.0190 | top1:99.3925 | AUROC:0.9999\n",
      "\n",
      "Epoch: [26 | 400] LR: 0.319034\n",
      "1/643 | Loss:0.0496 | top1:97.5000 | AUROC:0.9992\n",
      "101/643 | Loss:0.0810 | top1:96.9010 | AUROC:0.9968\n",
      "201/643 | Loss:0.0793 | top1:96.9826 | AUROC:0.9970\n",
      "301/643 | Loss:0.0808 | top1:96.9153 | AUROC:0.9970\n",
      "401/643 | Loss:0.0798 | top1:96.9177 | AUROC:0.9972\n",
      "501/643 | Loss:0.0811 | top1:96.8822 | AUROC:0.9970\n",
      "601/643 | Loss:0.0793 | top1:96.9750 | AUROC:0.9971\n",
      "643/643 | Loss:0.0789 | top1:96.9977 | AUROC:0.9971\n",
      "161/161 | Loss:0.0393 | top1:98.6293 | AUROC:1.0000\n",
      "\n",
      "Epoch: [27 | 400] LR: 0.318891\n",
      "1/643 | Loss:0.0593 | top1:97.5000 | AUROC:0.9983\n",
      "101/643 | Loss:0.0703 | top1:97.1634 | AUROC:0.9981\n",
      "201/643 | Loss:0.0696 | top1:97.2189 | AUROC:0.9980\n",
      "301/643 | Loss:0.0723 | top1:97.1478 | AUROC:0.9978\n",
      "401/643 | Loss:0.0741 | top1:97.1097 | AUROC:0.9976\n",
      "501/643 | Loss:0.0752 | top1:97.0729 | AUROC:0.9975\n",
      "601/643 | Loss:0.0760 | top1:97.0416 | AUROC:0.9974\n",
      "643/643 | Loss:0.0758 | top1:97.0623 | AUROC:0.9975\n",
      "161/161 | Loss:0.0191 | top1:99.3427 | AUROC:1.0000\n",
      "\n",
      "Epoch: [28 | 400] LR: 0.318738\n",
      "1/643 | Loss:0.0648 | top1:97.5000 | AUROC:0.9980\n",
      "101/643 | Loss:0.0733 | top1:97.1337 | AUROC:0.9977\n",
      "201/643 | Loss:0.0718 | top1:97.2612 | AUROC:0.9978\n",
      "301/643 | Loss:0.0724 | top1:97.2359 | AUROC:0.9976\n",
      "401/643 | Loss:0.0732 | top1:97.1808 | AUROC:0.9975\n",
      "501/643 | Loss:0.0738 | top1:97.1737 | AUROC:0.9974\n",
      "601/643 | Loss:0.0726 | top1:97.2346 | AUROC:0.9974\n",
      "643/643 | Loss:0.0727 | top1:97.2414 | AUROC:0.9975\n",
      "161/161 | Loss:0.0253 | top1:99.1215 | AUROC:1.0000\n",
      "\n",
      "Epoch: [29 | 400] LR: 0.318576\n",
      "1/643 | Loss:0.0419 | top1:98.5000 | AUROC:0.9998\n",
      "101/643 | Loss:0.0828 | top1:96.8020 | AUROC:0.9970\n",
      "201/643 | Loss:0.0778 | top1:96.9702 | AUROC:0.9973\n",
      "301/643 | Loss:0.0768 | top1:97.0515 | AUROC:0.9973\n",
      "401/643 | Loss:0.0750 | top1:97.1259 | AUROC:0.9974\n",
      "501/643 | Loss:0.0750 | top1:97.1208 | AUROC:0.9974\n",
      "601/643 | Loss:0.0745 | top1:97.1631 | AUROC:0.9973\n",
      "643/643 | Loss:0.0744 | top1:97.1830 | AUROC:0.9973\n",
      "161/161 | Loss:0.1078 | top1:95.5919 | AUROC:0.9995\n",
      "\n",
      "Epoch: [30 | 400] LR: 0.318404\n",
      "1/643 | Loss:0.1763 | top1:92.5000 | AUROC:0.9889\n",
      "101/643 | Loss:0.0702 | top1:97.2871 | AUROC:0.9978\n",
      "201/643 | Loss:0.0711 | top1:97.2313 | AUROC:0.9977\n",
      "301/643 | Loss:0.0699 | top1:97.2890 | AUROC:0.9977\n",
      "401/643 | Loss:0.0707 | top1:97.2992 | AUROC:0.9977\n",
      "501/643 | Loss:0.0700 | top1:97.3423 | AUROC:0.9977\n",
      "601/643 | Loss:0.0710 | top1:97.3145 | AUROC:0.9977\n",
      "643/643 | Loss:0.0712 | top1:97.2928 | AUROC:0.9976\n",
      "161/161 | Loss:0.0160 | top1:99.4735 | AUROC:0.9999\n",
      "\n",
      "Epoch: [31 | 400] LR: 0.318222\n",
      "1/643 | Loss:0.0922 | top1:97.0000 | AUROC:0.9941\n",
      "101/643 | Loss:0.0638 | top1:97.6980 | AUROC:0.9979\n",
      "201/643 | Loss:0.0686 | top1:97.4478 | AUROC:0.9977\n",
      "301/643 | Loss:0.0697 | top1:97.3970 | AUROC:0.9977\n",
      "401/643 | Loss:0.0732 | top1:97.2544 | AUROC:0.9975\n",
      "501/643 | Loss:0.0750 | top1:97.1487 | AUROC:0.9974\n",
      "601/643 | Loss:0.0758 | top1:97.1281 | AUROC:0.9973\n",
      "643/643 | Loss:0.0759 | top1:97.1347 | AUROC:0.9973\n",
      "161/161 | Loss:0.0424 | top1:98.6604 | AUROC:1.0000\n",
      "\n",
      "Epoch: [32 | 400] LR: 0.318030\n",
      "1/643 | Loss:0.0431 | top1:100.0000 | AUROC:1.0000\n",
      "101/643 | Loss:0.0612 | top1:97.6634 | AUROC:0.9983\n",
      "201/643 | Loss:0.0647 | top1:97.5473 | AUROC:0.9980\n",
      "301/643 | Loss:0.0666 | top1:97.4817 | AUROC:0.9979\n",
      "401/643 | Loss:0.0686 | top1:97.3853 | AUROC:0.9978\n",
      "501/643 | Loss:0.0687 | top1:97.3513 | AUROC:0.9978\n",
      "601/643 | Loss:0.0719 | top1:97.2263 | AUROC:0.9976\n",
      "643/643 | Loss:0.0735 | top1:97.1713 | AUROC:0.9976\n",
      "161/161 | Loss:0.0289 | top1:99.1028 | AUROC:0.9999\n",
      "\n",
      "Epoch: [33 | 400] LR: 0.317829\n",
      "1/643 | Loss:0.0998 | top1:96.0000 | AUROC:0.9946\n",
      "101/643 | Loss:0.0690 | top1:97.3465 | AUROC:0.9977\n",
      "201/643 | Loss:0.0704 | top1:97.3209 | AUROC:0.9976\n",
      "301/643 | Loss:0.0681 | top1:97.4120 | AUROC:0.9977\n",
      "401/643 | Loss:0.0688 | top1:97.3890 | AUROC:0.9978\n",
      "501/643 | Loss:0.0712 | top1:97.2884 | AUROC:0.9977\n",
      "601/643 | Loss:0.0709 | top1:97.3095 | AUROC:0.9976\n",
      "643/643 | Loss:0.0698 | top1:97.3544 | AUROC:0.9977\n",
      "161/161 | Loss:0.0156 | top1:99.4237 | AUROC:1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [34 | 400] LR: 0.317617\n",
      "1/643 | Loss:0.0336 | top1:98.5000 | AUROC:0.9993\n",
      "101/643 | Loss:0.0685 | top1:97.4653 | AUROC:0.9980\n",
      "201/643 | Loss:0.0650 | top1:97.5920 | AUROC:0.9980\n",
      "301/643 | Loss:0.0650 | top1:97.5615 | AUROC:0.9980\n",
      "401/643 | Loss:0.0662 | top1:97.4913 | AUROC:0.9980\n",
      "501/643 | Loss:0.0686 | top1:97.3842 | AUROC:0.9978\n",
      "601/643 | Loss:0.0691 | top1:97.3677 | AUROC:0.9977\n",
      "643/643 | Loss:0.0686 | top1:97.3910 | AUROC:0.9978\n",
      "161/161 | Loss:0.0218 | top1:99.1838 | AUROC:0.9999\n",
      "\n",
      "Epoch: [35 | 400] LR: 0.317397\n",
      "1/643 | Loss:0.0489 | top1:98.0000 | AUROC:0.9986\n",
      "101/643 | Loss:0.0715 | top1:97.3218 | AUROC:0.9974\n",
      "201/643 | Loss:0.0665 | top1:97.5572 | AUROC:0.9978\n",
      "301/643 | Loss:0.0656 | top1:97.5930 | AUROC:0.9979\n",
      "401/643 | Loss:0.0667 | top1:97.5536 | AUROC:0.9978\n",
      "501/643 | Loss:0.0696 | top1:97.4152 | AUROC:0.9978\n",
      "601/643 | Loss:0.0703 | top1:97.3810 | AUROC:0.9977\n",
      "643/643 | Loss:0.0705 | top1:97.3715 | AUROC:0.9977\n",
      "161/161 | Loss:0.0651 | top1:97.5140 | AUROC:0.9999\n",
      "\n",
      "Epoch: [36 | 400] LR: 0.317166\n",
      "1/643 | Loss:0.0750 | top1:98.5000 | AUROC:0.9934\n",
      "101/643 | Loss:0.0611 | top1:97.8267 | AUROC:0.9982\n",
      "201/643 | Loss:0.0627 | top1:97.7090 | AUROC:0.9981\n",
      "301/643 | Loss:0.0659 | top1:97.5498 | AUROC:0.9979\n",
      "401/643 | Loss:0.0670 | top1:97.4688 | AUROC:0.9978\n",
      "501/643 | Loss:0.0674 | top1:97.4521 | AUROC:0.9978\n",
      "601/643 | Loss:0.0695 | top1:97.3569 | AUROC:0.9977\n",
      "643/643 | Loss:0.0699 | top1:97.3411 | AUROC:0.9978\n",
      "161/161 | Loss:0.0366 | top1:98.7134 | AUROC:1.0000\n",
      "\n",
      "Epoch: [37 | 400] LR: 0.316926\n",
      "1/643 | Loss:0.0357 | top1:99.0000 | AUROC:0.9998\n",
      "101/643 | Loss:0.0679 | top1:97.3861 | AUROC:0.9979\n",
      "201/643 | Loss:0.0682 | top1:97.4304 | AUROC:0.9980\n",
      "301/643 | Loss:0.0681 | top1:97.4784 | AUROC:0.9979\n",
      "401/643 | Loss:0.0689 | top1:97.4214 | AUROC:0.9979\n",
      "501/643 | Loss:0.0670 | top1:97.4910 | AUROC:0.9980\n",
      "601/643 | Loss:0.0675 | top1:97.4742 | AUROC:0.9979\n",
      "643/643 | Loss:0.0672 | top1:97.4774 | AUROC:0.9980\n",
      "161/161 | Loss:0.0112 | top1:99.6667 | AUROC:1.0000\n",
      "\n",
      "Epoch: [38 | 400] LR: 0.316676\n",
      "1/643 | Loss:0.0554 | top1:98.5000 | AUROC:0.9988\n",
      "101/643 | Loss:0.0606 | top1:97.7475 | AUROC:0.9981\n",
      "201/643 | Loss:0.0648 | top1:97.6020 | AUROC:0.9980\n",
      "301/643 | Loss:0.0655 | top1:97.5399 | AUROC:0.9980\n",
      "401/643 | Loss:0.0710 | top1:97.3441 | AUROC:0.9979\n",
      "501/643 | Loss:0.0699 | top1:97.3832 | AUROC:0.9979\n",
      "601/643 | Loss:0.0683 | top1:97.4334 | AUROC:0.9980\n",
      "643/643 | Loss:0.0685 | top1:97.4252 | AUROC:0.9980\n",
      "161/161 | Loss:0.0178 | top1:99.3801 | AUROC:1.0000\n",
      "\n",
      "Epoch: [39 | 400] LR: 0.316416\n",
      "1/643 | Loss:0.0565 | top1:98.0000 | AUROC:0.9972\n",
      "101/643 | Loss:0.0597 | top1:97.8168 | AUROC:0.9981\n",
      "201/643 | Loss:0.0626 | top1:97.6841 | AUROC:0.9982\n",
      "301/643 | Loss:0.0645 | top1:97.5847 | AUROC:0.9981\n",
      "401/643 | Loss:0.0643 | top1:97.5835 | AUROC:0.9980\n",
      "501/643 | Loss:0.0659 | top1:97.5329 | AUROC:0.9979\n",
      "601/643 | Loss:0.0659 | top1:97.5349 | AUROC:0.9979\n",
      "643/643 | Loss:0.0678 | top1:97.4502 | AUROC:0.9978\n",
      "161/161 | Loss:0.0441 | top1:98.5452 | AUROC:0.9999\n",
      "\n",
      "Epoch: [40 | 400] LR: 0.316147\n",
      "1/643 | Loss:0.0612 | top1:98.0000 | AUROC:0.9990\n",
      "101/643 | Loss:0.0645 | top1:97.5990 | AUROC:0.9980\n",
      "201/643 | Loss:0.0600 | top1:97.7662 | AUROC:0.9982\n",
      "301/643 | Loss:0.0630 | top1:97.6329 | AUROC:0.9981\n",
      "401/643 | Loss:0.0650 | top1:97.5586 | AUROC:0.9980\n",
      "501/643 | Loss:0.0648 | top1:97.5749 | AUROC:0.9980\n",
      "601/643 | Loss:0.0645 | top1:97.6081 | AUROC:0.9981\n",
      "643/643 | Loss:0.0655 | top1:97.5584 | AUROC:0.9981\n",
      "161/161 | Loss:0.0744 | top1:97.1932 | AUROC:0.9998\n",
      "\n",
      "Epoch: [41 | 400] LR: 0.315868\n",
      "1/643 | Loss:0.0857 | top1:97.0000 | AUROC:0.9953\n",
      "101/643 | Loss:0.0635 | top1:97.5693 | AUROC:0.9981\n",
      "201/643 | Loss:0.0626 | top1:97.6418 | AUROC:0.9982\n",
      "301/643 | Loss:0.0635 | top1:97.5963 | AUROC:0.9981\n",
      "401/643 | Loss:0.0650 | top1:97.5598 | AUROC:0.9980\n",
      "501/643 | Loss:0.0652 | top1:97.5349 | AUROC:0.9980\n",
      "601/643 | Loss:0.0658 | top1:97.5216 | AUROC:0.9980\n",
      "643/643 | Loss:0.0668 | top1:97.4712 | AUROC:0.9980\n",
      "161/161 | Loss:0.0324 | top1:98.7446 | AUROC:1.0000\n",
      "\n",
      "Epoch: [42 | 400] LR: 0.315579\n",
      "1/643 | Loss:0.0385 | top1:98.0000 | AUROC:0.9993\n",
      "101/643 | Loss:0.0603 | top1:97.8911 | AUROC:0.9983\n",
      "201/643 | Loss:0.0625 | top1:97.7040 | AUROC:0.9983\n",
      "301/643 | Loss:0.0623 | top1:97.6661 | AUROC:0.9982\n",
      "401/643 | Loss:0.0653 | top1:97.5025 | AUROC:0.9981\n",
      "501/643 | Loss:0.0649 | top1:97.5160 | AUROC:0.9981\n",
      "601/643 | Loss:0.0656 | top1:97.4983 | AUROC:0.9980\n",
      "643/643 | Loss:0.0657 | top1:97.4992 | AUROC:0.9980\n",
      "161/161 | Loss:0.0564 | top1:97.7882 | AUROC:1.0000\n",
      "\n",
      "Epoch: [43 | 400] LR: 0.315281\n",
      "1/643 | Loss:0.0629 | top1:97.5000 | AUROC:0.9990\n",
      "101/643 | Loss:0.0696 | top1:97.2822 | AUROC:0.9981\n",
      "201/643 | Loss:0.0673 | top1:97.3806 | AUROC:0.9982\n",
      "301/643 | Loss:0.0670 | top1:97.4169 | AUROC:0.9981\n",
      "401/643 | Loss:0.0676 | top1:97.3865 | AUROC:0.9980\n",
      "501/643 | Loss:0.0666 | top1:97.4311 | AUROC:0.9981\n",
      "601/643 | Loss:0.0673 | top1:97.4226 | AUROC:0.9980\n",
      "643/643 | Loss:0.0669 | top1:97.4393 | AUROC:0.9980\n",
      "161/161 | Loss:0.0131 | top1:99.5639 | AUROC:1.0000\n",
      "\n",
      "Epoch: [44 | 400] LR: 0.314973\n",
      "1/643 | Loss:0.0624 | top1:97.5000 | AUROC:0.9992\n",
      "101/643 | Loss:0.0642 | top1:97.5594 | AUROC:0.9979\n",
      "201/643 | Loss:0.0660 | top1:97.4652 | AUROC:0.9981\n",
      "301/643 | Loss:0.0646 | top1:97.5399 | AUROC:0.9981\n",
      "401/643 | Loss:0.0649 | top1:97.4913 | AUROC:0.9982\n",
      "501/643 | Loss:0.0632 | top1:97.5689 | AUROC:0.9982\n",
      "601/643 | Loss:0.0639 | top1:97.5391 | AUROC:0.9982\n",
      "643/643 | Loss:0.0636 | top1:97.5584 | AUROC:0.9982\n",
      "161/161 | Loss:0.0226 | top1:99.1932 | AUROC:1.0000\n",
      "\n",
      "Epoch: [45 | 400] LR: 0.314656\n",
      "1/643 | Loss:0.0863 | top1:96.0000 | AUROC:0.9968\n",
      "101/643 | Loss:0.0662 | top1:97.3663 | AUROC:0.9981\n",
      "201/643 | Loss:0.0623 | top1:97.5597 | AUROC:0.9981\n",
      "301/643 | Loss:0.0654 | top1:97.4335 | AUROC:0.9981\n",
      "401/643 | Loss:0.0645 | top1:97.5162 | AUROC:0.9981\n",
      "501/643 | Loss:0.0640 | top1:97.5389 | AUROC:0.9981\n",
      "601/643 | Loss:0.0642 | top1:97.5308 | AUROC:0.9981\n",
      "643/643 | Loss:0.0638 | top1:97.5397 | AUROC:0.9981\n",
      "161/161 | Loss:0.0514 | top1:98.0062 | AUROC:0.9999\n",
      "\n",
      "Epoch: [46 | 400] LR: 0.314329\n",
      "1/643 | Loss:0.0641 | top1:97.0000 | AUROC:0.9980\n",
      "101/643 | Loss:0.0604 | top1:97.6733 | AUROC:0.9982\n",
      "201/643 | Loss:0.0627 | top1:97.6443 | AUROC:0.9981\n",
      "301/643 | Loss:0.0605 | top1:97.7027 | AUROC:0.9982\n",
      "401/643 | Loss:0.0622 | top1:97.6347 | AUROC:0.9982\n",
      "501/643 | Loss:0.0632 | top1:97.5928 | AUROC:0.9981\n",
      "601/643 | Loss:0.0630 | top1:97.6032 | AUROC:0.9982\n",
      "643/643 | Loss:0.0627 | top1:97.6246 | AUROC:0.9982\n",
      "161/161 | Loss:0.0481 | top1:98.1526 | AUROC:1.0000\n",
      "\n",
      "Epoch: [47 | 400] LR: 0.313993\n",
      "1/643 | Loss:0.0513 | top1:98.5000 | AUROC:0.9993\n",
      "101/643 | Loss:0.0726 | top1:97.2327 | AUROC:0.9978\n",
      "201/643 | Loss:0.0663 | top1:97.5323 | AUROC:0.9982\n",
      "301/643 | Loss:0.0678 | top1:97.4518 | AUROC:0.9981\n",
      "401/643 | Loss:0.0662 | top1:97.5087 | AUROC:0.9981\n",
      "501/643 | Loss:0.0648 | top1:97.5649 | AUROC:0.9981\n",
      "601/643 | Loss:0.0650 | top1:97.5366 | AUROC:0.9982\n",
      "643/643 | Loss:0.0644 | top1:97.5608 | AUROC:0.9982\n",
      "161/161 | Loss:0.0126 | top1:99.6168 | AUROC:1.0000\n",
      "\n",
      "Epoch: [48 | 400] LR: 0.313647\n",
      "1/643 | Loss:0.0354 | top1:99.0000 | AUROC:0.9998\n",
      "101/643 | Loss:0.0522 | top1:97.9554 | AUROC:0.9988\n",
      "201/643 | Loss:0.0561 | top1:97.7886 | AUROC:0.9986\n",
      "301/643 | Loss:0.0587 | top1:97.7342 | AUROC:0.9985\n",
      "401/643 | Loss:0.0595 | top1:97.7057 | AUROC:0.9984\n",
      "501/643 | Loss:0.0597 | top1:97.7166 | AUROC:0.9984\n",
      "601/643 | Loss:0.0607 | top1:97.6855 | AUROC:0.9983\n",
      "643/643 | Loss:0.0607 | top1:97.6978 | AUROC:0.9982\n",
      "161/161 | Loss:0.0221 | top1:99.3178 | AUROC:1.0000\n",
      "\n",
      "Epoch: [49 | 400] LR: 0.313292\n",
      "1/643 | Loss:0.0447 | top1:98.5000 | AUROC:0.9993\n",
      "101/643 | Loss:0.0579 | top1:97.8317 | AUROC:0.9984\n",
      "201/643 | Loss:0.0606 | top1:97.6891 | AUROC:0.9983\n",
      "301/643 | Loss:0.0654 | top1:97.5166 | AUROC:0.9981\n",
      "401/643 | Loss:0.0674 | top1:97.4564 | AUROC:0.9980\n",
      "501/643 | Loss:0.0674 | top1:97.4681 | AUROC:0.9980\n",
      "601/643 | Loss:0.0663 | top1:97.5125 | AUROC:0.9980\n",
      "643/643 | Loss:0.0660 | top1:97.5280 | AUROC:0.9981\n",
      "161/161 | Loss:0.0212 | top1:99.2804 | AUROC:1.0000\n",
      "\n",
      "Epoch: [50 | 400] LR: 0.312927\n",
      "1/643 | Loss:0.0490 | top1:98.5000 | AUROC:0.9992\n",
      "101/643 | Loss:0.0664 | top1:97.4406 | AUROC:0.9984\n",
      "201/643 | Loss:0.0645 | top1:97.5498 | AUROC:0.9983\n",
      "301/643 | Loss:0.0651 | top1:97.4767 | AUROC:0.9982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "401/643 | Loss:0.0642 | top1:97.5162 | AUROC:0.9983\n",
      "501/643 | Loss:0.0643 | top1:97.5200 | AUROC:0.9983\n",
      "601/643 | Loss:0.0659 | top1:97.4609 | AUROC:0.9982\n",
      "643/643 | Loss:0.0658 | top1:97.4642 | AUROC:0.9982\n",
      "161/161 | Loss:0.0144 | top1:99.6137 | AUROC:1.0000\n",
      "\n",
      "Epoch: [51 | 400] LR: 0.312553\n",
      "1/643 | Loss:0.0777 | top1:97.5000 | AUROC:0.9966\n",
      "101/643 | Loss:0.0592 | top1:97.7525 | AUROC:0.9983\n",
      "201/643 | Loss:0.0595 | top1:97.7438 | AUROC:0.9984\n",
      "301/643 | Loss:0.0575 | top1:97.8173 | AUROC:0.9984\n",
      "401/643 | Loss:0.0587 | top1:97.7544 | AUROC:0.9985\n",
      "501/643 | Loss:0.0606 | top1:97.6607 | AUROC:0.9984\n",
      "601/643 | Loss:0.0600 | top1:97.6930 | AUROC:0.9984\n",
      "643/643 | Loss:0.0602 | top1:97.6877 | AUROC:0.9983\n",
      "161/161 | Loss:0.0135 | top1:99.5389 | AUROC:1.0000\n",
      "\n",
      "Epoch: [52 | 400] LR: 0.312169\n",
      "1/643 | Loss:0.1127 | top1:97.0000 | AUROC:0.9926\n",
      "101/643 | Loss:0.0568 | top1:97.8416 | AUROC:0.9984\n",
      "201/643 | Loss:0.0617 | top1:97.7289 | AUROC:0.9982\n",
      "301/643 | Loss:0.0632 | top1:97.6478 | AUROC:0.9982\n",
      "401/643 | Loss:0.0638 | top1:97.6247 | AUROC:0.9982\n",
      "501/643 | Loss:0.0632 | top1:97.6357 | AUROC:0.9981\n",
      "601/643 | Loss:0.0622 | top1:97.6606 | AUROC:0.9982\n",
      "643/643 | Loss:0.0625 | top1:97.6371 | AUROC:0.9981\n",
      "161/161 | Loss:0.0068 | top1:99.8255 | AUROC:1.0000\n",
      "\n",
      "Epoch: [53 | 400] LR: 0.311776\n",
      "1/643 | Loss:0.1014 | top1:97.5000 | AUROC:0.9944\n",
      "101/643 | Loss:0.0668 | top1:97.4257 | AUROC:0.9980\n",
      "201/643 | Loss:0.0622 | top1:97.6393 | AUROC:0.9983\n",
      "301/643 | Loss:0.0647 | top1:97.5415 | AUROC:0.9982\n",
      "401/643 | Loss:0.0647 | top1:97.5499 | AUROC:0.9981\n",
      "501/643 | Loss:0.0636 | top1:97.5918 | AUROC:0.9982\n",
      "601/643 | Loss:0.0646 | top1:97.5324 | AUROC:0.9982\n",
      "643/643 | Loss:0.0660 | top1:97.4774 | AUROC:0.9981\n",
      "161/161 | Loss:0.0257 | top1:99.0031 | AUROC:1.0000\n",
      "\n",
      "Epoch: [54 | 400] LR: 0.311374\n",
      "1/643 | Loss:0.0678 | top1:97.5000 | AUROC:0.9961\n",
      "101/643 | Loss:0.0575 | top1:97.9109 | AUROC:0.9981\n",
      "201/643 | Loss:0.0633 | top1:97.6219 | AUROC:0.9982\n",
      "301/643 | Loss:0.0645 | top1:97.5880 | AUROC:0.9982\n",
      "401/643 | Loss:0.0631 | top1:97.6421 | AUROC:0.9982\n",
      "501/643 | Loss:0.0638 | top1:97.6168 | AUROC:0.9982\n",
      "601/643 | Loss:0.0631 | top1:97.6256 | AUROC:0.9982\n",
      "643/643 | Loss:0.0626 | top1:97.6441 | AUROC:0.9982\n",
      "161/161 | Loss:0.0753 | top1:97.0966 | AUROC:1.0000\n",
      "\n",
      "Epoch: [55 | 400] LR: 0.310962\n",
      "1/643 | Loss:0.0895 | top1:97.0000 | AUROC:0.9978\n",
      "101/643 | Loss:0.0585 | top1:97.8416 | AUROC:0.9983\n",
      "201/643 | Loss:0.0609 | top1:97.7214 | AUROC:0.9983\n",
      "301/643 | Loss:0.0650 | top1:97.5133 | AUROC:0.9982\n",
      "401/643 | Loss:0.0635 | top1:97.5960 | AUROC:0.9984\n",
      "501/643 | Loss:0.0636 | top1:97.5948 | AUROC:0.9983\n",
      "601/643 | Loss:0.0651 | top1:97.5216 | AUROC:0.9982\n",
      "643/643 | Loss:0.0642 | top1:97.5569 | AUROC:0.9982\n",
      "161/161 | Loss:0.0230 | top1:99.1745 | AUROC:1.0000\n",
      "\n",
      "Epoch: [56 | 400] LR: 0.310541\n",
      "1/643 | Loss:0.0410 | top1:98.5000 | AUROC:0.9991\n",
      "101/643 | Loss:0.0529 | top1:98.0941 | AUROC:0.9986\n",
      "201/643 | Loss:0.0571 | top1:97.9527 | AUROC:0.9985\n",
      "301/643 | Loss:0.0564 | top1:97.9618 | AUROC:0.9985\n",
      "401/643 | Loss:0.0586 | top1:97.8441 | AUROC:0.9984\n",
      "501/643 | Loss:0.0587 | top1:97.8303 | AUROC:0.9984\n",
      "601/643 | Loss:0.0592 | top1:97.8078 | AUROC:0.9984\n",
      "643/643 | Loss:0.0593 | top1:97.8084 | AUROC:0.9984\n",
      "161/161 | Loss:0.0467 | top1:98.3364 | AUROC:1.0000\n",
      "\n",
      "Epoch: [57 | 400] LR: 0.310111\n",
      "1/643 | Loss:0.0403 | top1:98.0000 | AUROC:1.0000\n",
      "101/643 | Loss:0.0548 | top1:97.9802 | AUROC:0.9987\n",
      "201/643 | Loss:0.0581 | top1:97.8408 | AUROC:0.9983\n",
      "301/643 | Loss:0.0579 | top1:97.8621 | AUROC:0.9984\n",
      "401/643 | Loss:0.0582 | top1:97.8479 | AUROC:0.9984\n",
      "501/643 | Loss:0.0604 | top1:97.7515 | AUROC:0.9983\n",
      "601/643 | Loss:0.0611 | top1:97.7047 | AUROC:0.9982\n",
      "643/643 | Loss:0.0614 | top1:97.6939 | AUROC:0.9982\n",
      "161/161 | Loss:0.0165 | top1:99.4393 | AUROC:1.0000\n",
      "\n",
      "Epoch: [58 | 400] LR: 0.309671\n",
      "1/643 | Loss:0.1209 | top1:95.0000 | AUROC:0.9943\n",
      "101/643 | Loss:0.0603 | top1:97.8614 | AUROC:0.9983\n",
      "201/643 | Loss:0.0655 | top1:97.6318 | AUROC:0.9980\n",
      "301/643 | Loss:0.0629 | top1:97.7060 | AUROC:0.9981\n",
      "401/643 | Loss:0.0612 | top1:97.7494 | AUROC:0.9982\n",
      "501/643 | Loss:0.0608 | top1:97.7605 | AUROC:0.9983\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-1594583eaac9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nEpoch: [%d | %d] LR: %f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_auroc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_auroc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-061456a0ae46>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, model, criterion, optimizer, epoch, use_cuda)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m# measure accuracy and record loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mprec1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mauroc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mtop1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprec1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(start_epoch, epochs):\n",
    "    state['lr'] = optimizer.state_dict()['param_groups'][0]['lr']\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "    print('\\nEpoch: [%d | %d] LR: %f' % (epoch + 1, epochs, state['lr']))\n",
    "    \n",
    "    train_loss, train_acc, train_auroc = train(train_loader, model, criterion, optimizer, epoch, use_cuda)\n",
    "    test_loss, test_acc, test_auroc = test(val_loader, model, criterion, epoch, use_cuda)\n",
    "    \n",
    "    logger.append([state['lr'], train_loss, test_loss, train_acc, test_acc, train_auroc, test_auroc])\n",
    "    scheduler_warmup.step()\n",
    "\n",
    "    is_best = test_acc > best_acc\n",
    "    best_acc = max(test_acc, best_acc)\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'state_dict' : model.state_dict(),\n",
    "        'acc': test_acc,\n",
    "        'best_acc': best_acc,\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    }, is_best, checkpoint=checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
